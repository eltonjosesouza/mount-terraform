{
  "accessanalyzer_analyzer.html": {
    "subcategory": "Access Analyzer",
    "layout": "aws",
    "page_title": "AWS: aws_accessanalyzer_analyzer",
    "description": "Manages an Access Analyzer Analyzer",
    "preview": "# Resource: aws_accessanalyzer_analyzer\n\nManages an Access Analyzer …",
    "content": "\n\n# Resource: aws_accessanalyzer_analyzer\n\nManages an Access Analyzer Analyzer. More information can be found in the [Access Analyzer User Guide](https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html).\n\n## Example Usage\n\n### Account Analyzer\n\n```terraform\nresource \"aws_accessanalyzer_analyzer\" \"example\" {\n  analyzer_name = \"example\"\n}\n```\n\n### Organization Analyzer\n\n```terraform\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"access-analyzer.amazonaws.com\"]\n}\n\nresource \"aws_accessanalyzer_analyzer\" \"example\" {\n  depends_on = [aws_organizations_organization.example]\n\n  analyzer_name = \"example\"\n  type          = \"ORGANIZATION\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `analyzer_name` - (Required) Name of the Analyzer.\n\nThe following arguments are optional:\n\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `type` - (Optional) Type of Analyzer. Valid values are `ACCOUNT` or `ORGANIZATION`. Defaults to `ACCOUNT`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Analyzer.\n* `id` - Analyzer name.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAccess Analyzer Analyzers can be imported using the `analyzer_name`, e.g.,\n\n```\n$ terraform import aws_accessanalyzer_analyzer.example example\n```\n",
    "basename": "accessanalyzer_analyzer.html"
  },
  "account_alternate_contact.html": {
    "subcategory": "Account",
    "layout": "aws",
    "page_title": "AWS: aws_account_alternate_contact",
    "description": "Manages the specified alternate contact attached to an AWS Account.",
    "preview": "# Resource: aws_account_alternate_contact\n\nManages the specified …",
    "content": "\n\n# Resource: aws_account_alternate_contact\n\nManages the specified alternate contact attached to an AWS Account.\n\n## Example Usage\n\n```terraform\nresource \"aws_account_alternate_contact\" \"operations\" {\n\n  alternate_contact_type = \"OPERATIONS\"\n\n  name          = \"Example\"\n  title         = \"Example\"\n  email_address = \"test@example.com\"\n  phone_number  = \"+1234567890\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The ID of the target account when managing member accounts. Will manage current user's account by default if omitted.\n* `alternate_contact_type` - (Required) The type of the alternate contact. Allowed values are: `BILLING`, `OPERATIONS`, `SECURITY`.\n* `email_address` - (Required) An email address for the alternate contact.\n* `name` - (Required) The name of the alternate contact.\n* `phone_number` - (Required) A phone number for the alternate contact.\n* `title` - (Required) A title for the alternate contact.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nThe current Alternate Contact can be imported using the `alternate_contact_type`, e.g.,\n\n```\n$ terraform import aws_account_alternate_contact.operations OPERATIONS\n```\n",
    "basename": "account_alternate_contact.html"
  },
  "acm_certificate.html": {
    "subcategory": "ACM",
    "layout": "aws",
    "page_title": "AWS: aws_acm_certificate",
    "description": "Requests and manages a certificate from Amazon Certificate Manager (ACM).",
    "preview": "# Resource: aws_acm_certificate\n\nThe ACM certificate resource allows …",
    "content": "\n\n# Resource: aws_acm_certificate\n\nThe ACM certificate resource allows requesting and management of certificates\nfrom the Amazon Certificate Manager.\n\nIt deals with requesting certificates and managing their attributes and life-cycle.\nThis resource does not deal with validation of a certificate but can provide inputs\nfor other resources implementing the validation. It does not wait for a certificate to be issued.\nUse a [`aws_acm_certificate_validation`](acm_certificate_validation.html) resource for this.\n\nMost commonly, this resource is used together with [`aws_route53_record`](route53_record.html) and\n[`aws_acm_certificate_validation`](acm_certificate_validation.html) to request a DNS validated certificate,\ndeploy the required validation records and wait for validation to complete.\n\nDomain validation through email is also supported but should be avoided as it requires a manual step outside\nof Terraform.\n\nIt's recommended to specify `create_before_destroy = true` in a [lifecycle][1] block to replace a certificate\nwhich is currently in use (eg, by [`aws_lb_listener`](lb_listener.html)).\n\n## Example Usage\n\n### Create Certificate\n\n```terraform\nresource \"aws_acm_certificate\" \"cert\" {\n  domain_name       = \"example.com\"\n  validation_method = \"DNS\"\n\n  tags = {\n    Environment = \"test\"\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n### Existing Certificate Body Import\n\n```terraform\nresource \"tls_private_key\" \"example\" {\n  algorithm = \"RSA\"\n}\n\nresource \"tls_self_signed_cert\" \"example\" {\n  key_algorithm   = \"RSA\"\n  private_key_pem = tls_private_key.example.private_key_pem\n\n  subject {\n    common_name  = \"example.com\"\n    organization = \"ACME Examples, Inc\"\n  }\n\n  validity_period_hours = 12\n\n  allowed_uses = [\n    \"key_encipherment\",\n    \"digital_signature\",\n    \"server_auth\",\n  ]\n}\n\nresource \"aws_acm_certificate\" \"cert\" {\n  private_key      = tls_private_key.example.private_key_pem\n  certificate_body = tls_self_signed_cert.example.cert_pem\n}\n```\n\n### Referencing domain_validation_options With for_each Based Resources\n\nSee the [`aws_acm_certificate_validation` resource](acm_certificate_validation.html) for a full example of performing DNS validation.\n\n```terraform\nresource \"aws_route53_record\" \"example\" {\n  for_each = {\n    for dvo in aws_acm_certificate.example.domain_validation_options : dvo.domain_name => {\n      name   = dvo.resource_record_name\n      record = dvo.resource_record_value\n      type   = dvo.resource_record_type\n    }\n  }\n\n  allow_overwrite = true\n  name            = each.value.name\n  records         = [each.value.record]\n  ttl             = 60\n  type            = each.value.type\n  zone_id         = aws_route53_zone.example.zone_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* Creating an amazon issued certificate\n    * `domain_name` - (Required) A domain name for which the certificate should be issued\n    * `subject_alternative_names` - (Optional) Set of domains that should be SANs in the issued certificate. To remove all elements of a previously configured list, set this value equal to an empty list (`[]`) or use the [`terraform taint` command](https://www.terraform.io/docs/commands/taint.html) to trigger recreation.\n    * `validation_method` - (Required) Which method to use for validation. `DNS` or `EMAIL` are valid, `NONE` can be used for certificates that were imported into ACM and then into Terraform.\n    * `options` - (Optional) Configuration block used to set certificate options. Detailed below.\n* Importing an existing certificate\n    * `private_key` - (Required) The certificate's PEM-formatted private key\n    * `certificate_body` - (Required) The certificate's PEM-formatted public key\n    * `certificate_chain` - (Optional) The certificate's PEM-formatted chain\n* Creating a private CA issued certificate\n    * `domain_name` - (Required) A domain name for which the certificate should be issued\n    * `certificate_authority_arn` - (Required) ARN of an ACM PCA\n    * `subject_alternative_names` - (Optional) Set of domains that should be SANs in the issued certificate. To remove all elements of a previously configured list, set this value equal to an empty list (`[]`) or use the [`terraform taint` command](https://www.terraform.io/docs/commands/taint.html) to trigger recreation.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## options Configuration Block\n\nSupported nested arguments for the `options` configuration block:\n\n* `certificate_transparency_logging_preference` - (Optional) Specifies whether certificate details should be added to a certificate transparency log. Valid values are `ENABLED` or `DISABLED`. See https://docs.aws.amazon.com/acm/latest/userguide/acm-concepts.html#concept-transparency for more details.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the certificate\n* `arn` - The ARN of the certificate\n* `domain_name` - The domain name for which the certificate is issued\n* `domain_validation_options` - Set of domain validation objects which can be used to complete certificate validation. Can have more than one element, e.g., if SANs are defined. Only set if `DNS`-validation was used.\n* `status` - Status of the certificate.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `validation_emails` - A list of addresses that received a validation E-Mail. Only set if `EMAIL`-validation was used.\n\nDomain validation objects export the following attributes:\n\n* `domain_name` - The domain to be validated\n* `resource_record_name` - The name of the DNS record to create to validate the certificate\n* `resource_record_type` - The type of DNS record to create\n* `resource_record_value` - The value the DNS record needs to have\n\n[1]: https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html\n\n## Import\n\nCertificates can be imported using their ARN, e.g.,\n\n```\n$ terraform import aws_acm_certificate.cert arn:aws:acm:eu-central-1:123456789012:certificate/7e7a28d2-163f-4b8f-b9cd-822f96c08d6a\n```\n",
    "basename": "acm_certificate.html"
  },
  "acm_certificate_validation.html": {
    "subcategory": "ACM",
    "layout": "aws",
    "page_title": "AWS: aws_acm_certificate_validation",
    "description": "Waits for and checks successful validation of an ACM certificate.",
    "preview": "# Resource: aws_acm_certificate_validation\n\nThis resource represents …",
    "content": "\n\n# Resource: aws_acm_certificate_validation\n\nThis resource represents a successful validation of an ACM certificate in concert\nwith other resources.\n\nMost commonly, this resource is used together with [`aws_route53_record`](route53_record.html) and\n[`aws_acm_certificate`](acm_certificate.html) to request a DNS validated certificate,\ndeploy the required validation records and wait for validation to complete.\n\n~> **WARNING:** This resource implements a part of the validation workflow. It does not represent a real-world entity in AWS, therefore changing or deleting this resource on its own has no immediate effect.\n\n\n## Example Usage\n\n### DNS Validation with Route 53\n\n```terraform\nresource \"aws_acm_certificate\" \"example\" {\n  domain_name       = \"example.com\"\n  validation_method = \"DNS\"\n}\n\ndata \"aws_route53_zone\" \"example\" {\n  name         = \"example.com\"\n  private_zone = false\n}\n\nresource \"aws_route53_record\" \"example\" {\n  for_each = {\n    for dvo in aws_acm_certificate.example.domain_validation_options : dvo.domain_name => {\n      name   = dvo.resource_record_name\n      record = dvo.resource_record_value\n      type   = dvo.resource_record_type\n    }\n  }\n\n  allow_overwrite = true\n  name            = each.value.name\n  records         = [each.value.record]\n  ttl             = 60\n  type            = each.value.type\n  zone_id         = data.aws_route53_zone.example.zone_id\n}\n\nresource \"aws_acm_certificate_validation\" \"example\" {\n  certificate_arn         = aws_acm_certificate.example.arn\n  validation_record_fqdns = [for record in aws_route53_record.example : record.fqdn]\n}\n\nresource \"aws_lb_listener\" \"example\" {\n  # ... other configuration ...\n\n  certificate_arn = aws_acm_certificate_validation.example.certificate_arn\n}\n```\n\n### Alternative Domains DNS Validation with Route 53\n\n```terraform\nresource \"aws_acm_certificate\" \"example\" {\n  domain_name               = \"example.com\"\n  subject_alternative_names = [\"www.example.com\", \"example.org\"]\n  validation_method         = \"DNS\"\n}\n\ndata \"aws_route53_zone\" \"example_com\" {\n  name         = \"example.com\"\n  private_zone = false\n}\n\ndata \"aws_route53_zone\" \"example_org\" {\n  name         = \"example.org\"\n  private_zone = false\n}\n\nresource \"aws_route53_record\" \"example\" {\n  for_each = {\n    for dvo in aws_acm_certificate.example.domain_validation_options : dvo.domain_name => {\n      name    = dvo.resource_record_name\n      record  = dvo.resource_record_value\n      type    = dvo.resource_record_type\n      zone_id = dvo.domain_name == \"example.org\" ? data.aws_route53_zone.example_org.zone_id : data.aws_route53_zone.example_com.zone_id\n    }\n  }\n\n  allow_overwrite = true\n  name            = each.value.name\n  records         = [each.value.record]\n  ttl             = 60\n  type            = each.value.type\n  zone_id         = each.value.zone_id\n}\n\nresource \"aws_acm_certificate_validation\" \"example\" {\n  certificate_arn         = aws_acm_certificate.example.arn\n  validation_record_fqdns = [for record in aws_route53_record.example : record.fqdn]\n}\n\nresource \"aws_lb_listener\" \"example\" {\n  # ... other configuration ...\n\n  certificate_arn = aws_acm_certificate_validation.example.certificate_arn\n}\n```\n\n### Email Validation\n\nIn this situation, the resource is simply a waiter for manual email approval of ACM certificates.\n\n```terraform\nresource \"aws_acm_certificate\" \"example\" {\n  domain_name       = \"example.com\"\n  validation_method = \"EMAIL\"\n}\n\nresource \"aws_acm_certificate_validation\" \"example\" {\n  certificate_arn = aws_acm_certificate.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `certificate_arn` - (Required) The ARN of the certificate that is being validated.\n* `validation_record_fqdns` - (Optional) List of FQDNs that implement the validation. Only valid for DNS validation method ACM certificates. If this is set, the resource can implement additional sanity checks and has an explicit dependency on the resource that is implementing the validation\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The time at which the certificate was issued\n\n## Timeouts\n\n`acm_certificate_validation` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `45m`) How long to wait for a certificate to be issued.\n",
    "basename": "acm_certificate_validation.html"
  },
  "acmpca_certificate.html": {
    "subcategory": "ACM PCA",
    "layout": "aws",
    "page_title": "AWS: aws_acmpca_certificate",
    "description": "Provides a resource to issue a certificate using AWS Certificate Manager Private Certificate Authority (ACM PCA)",
    "preview": "# Resource: aws_acmpca_certificate\n\nProvides a resource to issue a …",
    "content": "\n\n# Resource: aws_acmpca_certificate\n\nProvides a resource to issue a certificate using AWS Certificate Manager Private Certificate Authority (ACM PCA).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_acmpca_certificate\" \"example\" {\n  certificate_authority_arn   = aws_acmpca_certificate_authority.example.arn\n  certificate_signing_request = tls_cert_request.csr.cert_request_pem\n  signing_algorithm           = \"SHA256WITHRSA\"\n  validity {\n    type  = \"YEARS\"\n    value = 1\n  }\n}\n\nresource \"aws_acmpca_certificate_authority\" \"example\" {\n  private_certificate_configuration {\n    key_algorithm     = \"RSA_4096\"\n    signing_algorithm = \"SHA512WITHRSA\"\n\n    subject {\n      common_name = \"example.com\"\n    }\n  }\n\n  permanent_deletion_time_in_days = 7\n}\n\nresource \"tls_private_key\" \"key\" {\n  algorithm = \"RSA\"\n}\n\nresource \"tls_cert_request\" \"csr\" {\n  key_algorithm   = \"RSA\"\n  private_key_pem = tls_private_key.key.private_key_pem\n\n  subject {\n    common_name = \"example\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `certificate_authority_arn` - (Required) Amazon Resource Name (ARN) of the certificate authority.\n* `certificate_signing_request` - (Required) Certificate Signing Request in PEM format.\n* `signing_algorithm` - (Required) Algorithm to use to sign certificate requests. Valid values: `SHA256WITHRSA`, `SHA256WITHECDSA`, `SHA384WITHRSA`, `SHA384WITHECDSA`, `SHA512WITHRSA`, `SHA512WITHECDSA`\n* `validity` - (Required) Configures end of the validity period for the certificate. See [validity block](#validity-block) below.\n* `template_arn` - (Optional) The template to use when issuing a certificate. See [ACM PCA Documentation](https://docs.aws.amazon.com/acm-pca/latest/userguide/UsingTemplates.html) for more information.\n\n### validity block\n\n* `type` - (Required) Determines how `value` is interpreted. Valid values: `DAYS`, `MONTHS`, `YEARS`, `ABSOLUTE`, `END_DATE`.\n* `value` - (Required) If `type` is `DAYS`, `MONTHS`, or `YEARS`, the relative time until the certificate expires. If `type` is `ABSOLUTE`, the date in seconds since the Unix epoch. If `type` is `END_DATE`, the  date in RFC 3339 format.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the certificate.\n* `certificate` - The PEM-encoded certificate value.\n* `certificate_chain` - The PEM-encoded certificate chain that includes any intermediate certificates and chains up to root CA.\n\n## Import\n\n`aws_acmpca_certificate` can not be imported at this time.\n",
    "basename": "acmpca_certificate.html"
  },
  "acmpca_certificate_authority.html": {
    "subcategory": "ACM PCA",
    "layout": "aws",
    "page_title": "AWS: aws_acmpca_certificate_authority",
    "description": "Provides a resource to manage AWS Certificate Manager Private Certificate Authorities",
    "preview": "# Resource: aws_acmpca_certificate_authority\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_acmpca_certificate_authority\n\nProvides a resource to manage AWS Certificate Manager Private Certificate Authorities (ACM PCA Certificate Authorities).\n\n~> **NOTE:** Creating this resource will leave the certificate authority in a `PENDING_CERTIFICATE` status, which means it cannot yet issue certificates. To complete this setup, you must fully sign the certificate authority CSR available in the `certificate_signing_request` attribute and import the signed certificate outside of Terraform. Terraform can support another resource to manage that workflow automatically in the future.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_acmpca_certificate_authority\" \"example\" {\n  certificate_authority_configuration {\n    key_algorithm     = \"RSA_4096\"\n    signing_algorithm = \"SHA512WITHRSA\"\n\n    subject {\n      common_name = \"example.com\"\n    }\n  }\n\n  permanent_deletion_time_in_days = 7\n}\n```\n\n### Enable Certificate Revocation List\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\ndata \"aws_iam_policy_document\" \"acmpca_bucket_access\" {\n  statement {\n    actions = [\n      \"s3:GetBucketAcl\",\n      \"s3:GetBucketLocation\",\n      \"s3:PutObject\",\n      \"s3:PutObjectAcl\",\n    ]\n\n    resources = [\n      aws_s3_bucket.example.arn,\n      \"${aws_s3_bucket.example.arn}/*\",\n    ]\n\n    principals {\n      identifiers = [\"acm-pca.amazonaws.com\"]\n      type        = \"Service\"\n    }\n  }\n}\n\nresource \"aws_s3_bucket_policy\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n  policy = data.aws_iam_policy_document.acmpca_bucket_access.json\n}\n\nresource \"aws_acmpca_certificate_authority\" \"example\" {\n  certificate_authority_configuration {\n    key_algorithm     = \"RSA_4096\"\n    signing_algorithm = \"SHA512WITHRSA\"\n\n    subject {\n      common_name = \"example.com\"\n    }\n  }\n\n  revocation_configuration {\n    crl_configuration {\n      custom_cname       = \"crl.example.com\"\n      enabled            = true\n      expiration_in_days = 7\n      s3_bucket_name     = aws_s3_bucket.example.id\n    }\n  }\n\n  depends_on = [aws_s3_bucket_policy.example]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `certificate_authority_configuration` - (Required) Nested argument containing algorithms and certificate subject information. Defined below.\n* `enabled` - (Optional) Whether the certificate authority is enabled or disabled. Defaults to `true`.\n* `revocation_configuration` - (Optional) Nested argument containing revocation configuration. Defined below.\n* `tags` - (Optional) Specifies a key-value map of user-defined tags that are attached to the certificate authority. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `type` - (Optional) The type of the certificate authority. Defaults to `SUBORDINATE`. Valid values: `ROOT` and `SUBORDINATE`.\n* `permanent_deletion_time_in_days` - (Optional) The number of days to make a CA restorable after it has been deleted, must be between 7 to 30 days, with default to 30 days.\n\n### certificate_authority_configuration\n\n* `key_algorithm` - (Required) Type of the public key algorithm and size, in bits, of the key pair that your key pair creates when it issues a certificate. Valid values can be found in the [ACM PCA Documentation](https://docs.aws.amazon.com/acm-pca/latest/APIReference/API_CertificateAuthorityConfiguration.html).\n* `signing_algorithm` - (Required) Name of the algorithm your private CA uses to sign certificate requests. Valid values can be found in the [ACM PCA Documentation](https://docs.aws.amazon.com/acm-pca/latest/APIReference/API_CertificateAuthorityConfiguration.html).\n* `subject` - (Required) Nested argument that contains X.500 distinguished name information. At least one nested attribute must be specified.\n\n#### subject\n\nContains information about the certificate subject. Identifies the entity that owns or controls the public key in the certificate. The entity can be a user, computer, device, or service.\n\n* `common_name` - (Optional) Fully qualified domain name (FQDN) associated with the certificate subject. Must be less than or equal to 64 characters in length.\n* `country` - (Optional) Two digit code that specifies the country in which the certificate subject located. Must be less than or equal to 2 characters in length.\n* `distinguished_name_qualifier` - (Optional) Disambiguating information for the certificate subject. Must be less than or equal to 64 characters in length.\n* `generation_qualifier` - (Optional) Typically a qualifier appended to the name of an individual. Examples include Jr. for junior, Sr. for senior, and III for third. Must be less than or equal to 3 characters in length.\n* `given_name` - (Optional) First name. Must be less than or equal to 16 characters in length.\n* `initials` - (Optional) Concatenation that typically contains the first letter of the `given_name`, the first letter of the middle name if one exists, and the first letter of the `surname`. Must be less than or equal to 5 characters in length.\n* `locality` - (Optional) The locality (such as a city or town) in which the certificate subject is located. Must be less than or equal to 128 characters in length.\n* `organization` - (Optional) Legal name of the organization with which the certificate subject is affiliated. Must be less than or equal to 64 characters in length.\n* `organizational_unit` - (Optional) A subdivision or unit of the organization (such as sales or finance) with which the certificate subject is affiliated. Must be less than or equal to 64 characters in length.\n* `pseudonym` - (Optional) Typically a shortened version of a longer `given_name`. For example, Jonathan is often shortened to John. Elizabeth is often shortened to Beth, Liz, or Eliza. Must be less than or equal to 128 characters in length.\n* `state` - (Optional) State in which the subject of the certificate is located. Must be less than or equal to 128 characters in length.\n* `surname` - (Optional) Family name. In the US and the UK for example, the surname of an individual is ordered last. In Asian cultures the surname is typically ordered first. Must be less than or equal to 40 characters in length.\n* `title` - (Optional) A title such as Mr. or Ms. which is pre-pended to the name to refer formally to the certificate subject. Must be less than or equal to 64 characters in length.\n\n### revocation_configuration\n\n* `crl_configuration` - (Optional) Nested argument containing configuration of the certificate revocation list (CRL), if any, maintained by the certificate authority. Defined below.\n\n#### crl_configuration\n\n* `custom_cname` - (Optional) Name inserted into the certificate CRL Distribution Points extension that enables the use of an alias for the CRL distribution point. Use this value if you don't want the name of your S3 bucket to be public. Must be less than or equal to 253 characters in length.\n* `enabled` - (Optional) Boolean value that specifies whether certificate revocation lists (CRLs) are enabled. Defaults to `false`.\n* `expiration_in_days` - (Required) Number of days until a certificate expires. Must be between 1 and 5000.\n* `s3_bucket_name` - (Optional) Name of the S3 bucket that contains the CRL. If you do not provide a value for the `custom_cname` argument, the name of your S3 bucket is placed into the CRL Distribution Points extension of the issued certificate. You must specify a bucket policy that allows ACM PCA to write the CRL to your bucket. Must be less than or equal to 255 characters in length.\n* `s3_object_acl` - (Optional) Determines whether the CRL will be publicly readable or privately held in the CRL Amazon S3 bucket. Defaults to `PUBLIC_READ`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the certificate authority.\n* `arn` - Amazon Resource Name (ARN) of the certificate authority.\n* `certificate` - Base64-encoded certificate authority (CA) certificate. Only available after the certificate authority certificate has been imported.\n* `certificate_chain` - Base64-encoded certificate chain that includes any intermediate certificates and chains up to root on-premises certificate that you used to sign your private CA certificate. The chain does not include your private CA certificate. Only available after the certificate authority certificate has been imported.\n* `certificate_signing_request` - The base64 PEM-encoded certificate signing request (CSR) for your private CA certificate.\n* `not_after` - Date and time after which the certificate authority is not valid. Only available after the certificate authority certificate has been imported.\n* `not_before` - Date and time before which the certificate authority is not valid. Only available after the certificate authority certificate has been imported.\n* `serial` - Serial number of the certificate authority. Only available after the certificate authority certificate has been imported.\n* `status` - Status of the certificate authority.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_acmpca_certificate_authority` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `1m`) How long to wait for a certificate authority to be created.\n\n## Import\n\n`aws_acmpca_certificate_authority` can be imported by using the certificate authority Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_acmpca_certificate_authority.example arn:aws:acm-pca:us-east-1:123456789012:certificate-authority/12345678-1234-1234-1234-123456789012\n```\n",
    "basename": "acmpca_certificate_authority.html"
  },
  "acmpca_certificate_authority_certificate.html": {
    "subcategory": "ACM PCA",
    "layout": "aws",
    "page_title": "AWS: aws_acmpca_certificate_authority_certificate",
    "description": "Associates a certificate with an AWS Certificate Manager Private Certificate Authority",
    "preview": "# Resource: aws_acmpca_certificate_authority_certificate\n\nAssociates …",
    "content": "\n\n# Resource: aws_acmpca_certificate_authority_certificate\n\nAssociates a certificate with an AWS Certificate Manager Private Certificate Authority (ACM PCA Certificate Authority). An ACM PCA Certificate Authority is unable to issue certificates until it has a certificate associated with it. A root level ACM PCA Certificate Authority is able to self-sign its own root certificate.\n\n## Example Usage\n\n### Self-Signed Root Certificate Authority Certificate\n\n```terraform\nresource \"aws_acmpca_certificate_authority_certificate\" \"example\" {\n  certificate_authority_arn = aws_acmpca_certificate_authority.example.arn\n\n  certificate       = aws_acmpca_certificate.example.certificate\n  certificate_chain = aws_acmpca_certificate.example.certificate_chain\n}\n\nresource \"aws_acmpca_certificate\" \"example\" {\n  certificate_authority_arn   = aws_acmpca_certificate_authority.example.arn\n  certificate_signing_request = aws_acmpca_certificate_authority.example.certificate_signing_request\n  signing_algorithm           = \"SHA512WITHRSA\"\n\n  template_arn = \"arn:${data.aws_partition.current.partition}:acm-pca:::template/RootCACertificate/V1\"\n\n  validity {\n    type  = \"YEARS\"\n    value = 1\n  }\n}\n\nresource \"aws_acmpca_certificate_authority\" \"example\" {\n  type = \"ROOT\"\n\n  certificate_authority_configuration {\n    key_algorithm     = \"RSA_4096\"\n    signing_algorithm = \"SHA512WITHRSA\"\n\n    subject {\n      common_name = \"example.com\"\n    }\n  }\n}\n\ndata \"aws_partition\" \"current\" {}\n```\n\n### Certificate for Subordinate Certificate Authority\n\nNote that the certificate for the subordinate certificate authority must be issued by the root certificate authority using a signing request from the subordinate certificate authority.\n\n```terraform\nresource \"aws_acmpca_certificate_authority_certificate\" \"subordinate\" {\n  certificate_authority_arn = aws_acmpca_certificate_authority.subordinate.arn\n\n  certificate       = aws_acmpca_certificate.subordinate.certificate\n  certificate_chain = aws_acmpca_certificate.subordinate.certificate_chain\n}\n\nresource \"aws_acmpca_certificate\" \"subordinate\" {\n  certificate_authority_arn   = aws_acmpca_certificate_authority.root.arn\n  certificate_signing_request = aws_acmpca_certificate_authority.subordinate.certificate_signing_request\n  signing_algorithm           = \"SHA512WITHRSA\"\n\n  template_arn = \"arn:${data.aws_partition.current.partition}:acm-pca:::template/SubordinateCACertificate_PathLen0/V1\"\n\n  validity {\n    type  = \"YEARS\"\n    value = 1\n  }\n}\n\nresource \"aws_acmpca_certificate_authority\" \"subordinate\" {\n  type = \"SUBORDINATE\"\n\n  certificate_authority_configuration {\n    key_algorithm     = \"RSA_2048\"\n    signing_algorithm = \"SHA512WITHRSA\"\n\n    subject {\n      common_name = \"sub.example.com\"\n    }\n  }\n}\n\nresource \"aws_acmpca_certificate_authority\" \"root\" {\n  # ...\n}\n\nresource \"aws_acmpca_certificate_authority_certificate\" \"root\" {\n  # ...\n}\n\nresource \"aws_acmpca_certificate\" \"root\" {\n  # ...\n}\n\ndata \"aws_partition\" \"current\" {}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `certificate` - (Required) The PEM-encoded certificate for the Certificate Authority.\n* `certificate_authority_arn` - (Required) Amazon Resource Name (ARN) of the Certificate Authority.\n* `certificate_chain` - (Optional) The PEM-encoded certificate chain that includes any intermediate certificates and chains up to root CA. Required for subordinate Certificate Authorities. Not allowed for root Certificate Authorities.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "acmpca_certificate_authority_certificate.html"
  },
  "ami.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ami",
    "description": "Creates and manages a custom Amazon Machine Image (AMI).",
    "preview": "# Resource: aws_ami\n\nThe AMI resource allows the creation and …",
    "content": "\n\n# Resource: aws_ami\n\nThe AMI resource allows the creation and management of a completely-custom\n*Amazon Machine Image* (AMI).\n\nIf you just want to duplicate an existing AMI, possibly copying it to another\nregion, it's better to use `aws_ami_copy` instead.\n\nIf you just want to share an existing AMI with another AWS account,\nit's better to use `aws_ami_launch_permission` instead.\n\n## Example Usage\n\n```terraform\n# Create an AMI that will start a machine whose root device is backed by\n# an EBS volume populated from a snapshot. It is assumed that such a snapshot\n# already exists with the id \"snap-xxxxxxxx\".\nresource \"aws_ami\" \"example\" {\n  name                = \"terraform-example\"\n  virtualization_type = \"hvm\"\n  root_device_name    = \"/dev/xvda\"\n\n  ebs_block_device {\n    device_name = \"/dev/xvda\"\n    snapshot_id = \"snap-xxxxxxxx\"\n    volume_size = 8\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A region-unique name for the AMI.\n* `description` - (Optional) A longer, human-readable description for the AMI.\n* `ena_support` - (Optional) Specifies whether enhanced networking with ENA is enabled. Defaults to `false`.\n* `root_device_name` - (Optional) The name of the root device (for example, `/dev/sda1`, or `/dev/xvda`).\n* `virtualization_type` - (Optional) Keyword to choose what virtualization mode created instances\n  will use. Can be either \"paravirtual\" (the default) or \"hvm\". The choice of virtualization type\n  changes the set of further arguments that are required, as described below.\n* `architecture` - (Optional) Machine architecture for created instances. Defaults to \"x86_64\".\n* `ebs_block_device` - (Optional) Nested block describing an EBS block device that should be\n  attached to created instances. The structure of this block is described below.\n* `ephemeral_block_device` - (Optional) Nested block describing an ephemeral block device that\n  should be attached to created instances. The structure of this block is described below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nWhen `virtualization_type` is \"paravirtual\" the following additional arguments apply:\n\n* `image_location` - (Required) Path to an S3 object containing an image manifest, e.g., created\n  by the `ec2-upload-bundle` command in the EC2 command line tools.\n* `kernel_id` - (Required) The id of the kernel image (AKI) that will be used as the paravirtual\n  kernel in created instances.\n* `ramdisk_id` - (Optional) The id of an initrd image (ARI) that will be used when booting the\n  created instances.\n\nWhen `virtualization_type` is \"hvm\" the following additional arguments apply:\n\n* `sriov_net_support` - (Optional) When set to \"simple\" (the default), enables enhanced networking\n  for created instances. No other value is supported at this time.\n\nNested `ebs_block_device` blocks have the following structure:\n\n* `device_name` - (Required) The path at which the device is exposed to created instances.\n* `delete_on_termination` - (Optional) Boolean controlling whether the EBS volumes created to\n  support each created instance will be deleted once that instance is terminated.\n* `encrypted` - (Optional) Boolean controlling whether the created EBS volumes will be encrypted. Can't be used with `snapshot_id`.\n* `iops` - (Required only when `volume_type` is `io1` or `io2`) Number of I/O operations per second the\n  created volumes will support.\n* `snapshot_id` - (Optional) The id of an EBS snapshot that will be used to initialize the created\n  EBS volumes. If set, the `volume_size` attribute must be at least as large as the referenced\n  snapshot.\n* `throughput` - (Optional) The throughput that the EBS volume supports, in MiB/s. Only valid for `volume_type` of `gp3`.\n* `volume_size` - (Required unless `snapshot_id` is set) The size of created volumes in GiB.\n  If `snapshot_id` is set and `volume_size` is omitted then the volume will have the same size\n  as the selected snapshot.\n* `volume_type` - (Optional) The type of EBS volume to create. Can be `standard`, `gp2`, `gp3`, `io1`, `io2`, `sc1` or `st1` (Default: `standard`).\n* `kms_key_id` - (Optional) The full ARN of the AWS Key Management Service (AWS KMS) CMK to use when encrypting the snapshots of\nan image during a copy operation. This parameter is only required if you want to use a non-default CMK;\nif this parameter is not specified, the default CMK for EBS is used\n\n~> **Note:** You can specify `encrypted` or `snapshot_id` but not both.\n\nNested `ephemeral_block_device` blocks have the following structure:\n\n* `device_name` - (Required) The path at which the device is exposed to created instances.\n* `virtual_name` - (Required) A name for the ephemeral device, of the form \"ephemeralN\" where\n  *N* is a volume number starting from zero.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 40 mins) Used when creating the AMI\n* `update` - (Defaults to 40 mins) Used when updating the AMI\n* `delete` - (Defaults to 90 mins) Used when deregistering the AMI\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the AMI.\n* `id` - The ID of the created AMI.\n* `owner_id` - The AWS account ID of the image owner.\n* `root_snapshot_id` - The Snapshot ID for the root volume (for EBS-backed AMIs)\n* `usage_operation` - The operation of the Amazon EC2 instance and the billing code that is associated with the AMI.\n* `platform_details` - The platform details associated with the billing code of the AMI.\n* `image_owner_alias` - The AWS account alias (for example, amazon, self) or the AWS account ID of the AMI owner.\n* `image_type` - The type of image.\n* `hypervisor` - The hypervisor type of the image.\n* `owner_id` - The AWS account ID of the image owner.\n* `platform` - This value is set to windows for Windows AMIs; otherwise, it is blank.\n* `public` - Indicates whether the image has public launch permissions.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_ami` can be imported using the ID of the AMI, e.g.,\n\n```\n$ terraform import aws_ami.example ami-12345678\n```\n",
    "basename": "ami.html"
  },
  "ami_copy.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ami_copy",
    "description": "Duplicates an existing Amazon Machine Image (AMI)",
    "preview": "# Resource: aws_ami_copy\n\nThe \"AMI copy\" resource allows duplication …",
    "content": "\n\n# Resource: aws_ami_copy\n\nThe \"AMI copy\" resource allows duplication of an Amazon Machine Image (AMI),\nincluding cross-region copies.\n\nIf the source AMI has associated EBS snapshots, those will also be duplicated\nalong with the AMI.\n\nThis is useful for taking a single AMI provisioned in one region and making\nit available in another for a multi-region deployment.\n\nCopying an AMI can take several minutes. The creation of this resource will\nblock until the new AMI is available for use on new instances.\n\n## Example Usage\n\n```terraform\nresource \"aws_ami_copy\" \"example\" {\n  name              = \"terraform-example\"\n  description       = \"A copy of ami-xxxxxxxx\"\n  source_ami_id     = \"ami-xxxxxxxx\"\n  source_ami_region = \"us-west-1\"\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A region-unique name for the AMI.\n* `source_ami_id` - (Required) The id of the AMI to copy. This id must be valid in the region\n  given by `source_ami_region`.\n* `source_ami_region` - (Required) The region from which the AMI will be copied. This may be the\n  same as the AWS provider region in order to create a copy within the same region.\n* `destination_outpost_arn` - (Optional) The ARN of the Outpost to which to copy the AMI.\n  Only specify this parameter when copying an AMI from an AWS Region to an Outpost. The AMI must be in the Region of the destination Outpost.  \n* `encrypted` - (Optional) Specifies whether the destination snapshots of the copied image should be encrypted. Defaults to `false`\n* `kms_key_id` - (Optional) The full ARN of the KMS Key to use when encrypting the snapshots of an image during a copy operation. If not specified, then the default AWS KMS Key will be used\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThis resource also exposes the full set of arguments from the [`aws_ami`](ami.html) resource.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 40 mins) Used when creating the AMI\n* `update` - (Defaults to 40 mins) Used when updating the AMI\n* `delete` - (Defaults to 90 mins) Used when deregistering the AMI\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the AMI.\n* `id` - The ID of the created AMI.\n\nThis resource also exports a full set of attributes corresponding to the arguments of the\n[`aws_ami`](/docs/providers/aws/r/ami.html) resource, allowing the properties of the created AMI to be used elsewhere in the\nconfiguration.\n",
    "basename": "ami_copy.html"
  },
  "ami_from_instance.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ami_from_instance",
    "description": "Creates an Amazon Machine Image (AMI) from an EBS-backed EC2 instance",
    "preview": "# Resource: aws_ami_from_instance\n\nThe \"AMI from instance\" resource …",
    "content": "\n\n# Resource: aws_ami_from_instance\n\nThe \"AMI from instance\" resource allows the creation of an Amazon Machine\nImage (AMI) modelled after an existing EBS-backed EC2 instance.\n\nThe created AMI will refer to implicitly-created snapshots of the instance's\nEBS volumes and mimick its assigned block device configuration at the time\nthe resource is created.\n\nThis resource is best applied to an instance that is stopped when this instance\nis created, so that the contents of the created image are predictable. When\napplied to an instance that is running, *the instance will be stopped before taking\nthe snapshots and then started back up again*, resulting in a period of\ndowntime.\n\nNote that the source instance is inspected only at the initial creation of this\nresource. Ongoing updates to the referenced instance will not be propagated into\nthe generated AMI. Users may taint or otherwise recreate the resource in order\nto produce a fresh snapshot.\n\n## Example Usage\n\n```terraform\nresource \"aws_ami_from_instance\" \"example\" {\n  name               = \"terraform-example\"\n  source_instance_id = \"i-xxxxxxxx\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A region-unique name for the AMI.\n* `source_instance_id` - (Required) The id of the instance to use as the basis of the AMI.\n* `snapshot_without_reboot` - (Optional) Boolean that overrides the behavior of stopping\n  the instance before snapshotting. This is risky since it may cause a snapshot of an\n  inconsistent filesystem state, but can be used to avoid downtime if the user otherwise\n  guarantees that no filesystem writes will be underway at the time of snapshot.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 40 mins) Used when creating the AMI\n* `update` - (Defaults to 40 mins) Used when updating the AMI\n* `delete` - (Defaults to 90 mins) Used when deregistering the AMI\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the AMI.\n* `id` - The ID of the created AMI.\n\nThis resource also exports a full set of attributes corresponding to the arguments of the\n[`aws_ami`](/docs/providers/aws/r/ami.html) resource, allowing the properties of the created AMI to be used elsewhere in the\nconfiguration.\n",
    "basename": "ami_from_instance.html"
  },
  "ami_launch_permission.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ami_launch_permission",
    "description": "Adds launch permission to Amazon Machine Image (AMI).",
    "preview": "# Resource: aws_ami_launch_permission\n\nAdds launch permission to …",
    "content": "\n\n# Resource: aws_ami_launch_permission\n\nAdds launch permission to Amazon Machine Image (AMI) from another AWS account.\n\n## Example Usage\n\n```terraform\nresource \"aws_ami_launch_permission\" \"example\" {\n  image_id   = \"ami-12345678\"\n  account_id = \"123456789012\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `image_id` - (required) A region-unique name for the AMI.\n* `account_id` - (required) An AWS Account ID to add launch permissions.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A combination of \"`image_id`-`account_id`\".\n\n## Import\n\nAWS AMI Launch Permission can be imported using the `ACCOUNT-ID/IMAGE-ID`, e.g.,\n\n```sh\n$ terraform import aws_ami_launch_permission.example 123456789012/ami-12345678\n```\n",
    "basename": "ami_launch_permission.html"
  },
  "amplify_app.html": {
    "subcategory": "Amplify Console",
    "layout": "aws",
    "page_title": "AWS: aws_amplify_app",
    "description": "Provides an Amplify App resource.",
    "preview": "# Resource: aws_amplify_app\n\nProvides an Amplify App resource, a …",
    "content": "\n\n# Resource: aws_amplify_app\n\nProvides an Amplify App resource, a fullstack serverless app hosted on the [AWS Amplify Console](https://docs.aws.amazon.com/amplify/latest/userguide/welcome.html).\n\n~> **Note:** When you create/update an Amplify App from Terraform, you may end up with the error \"BadRequestException: You should at least provide one valid token\" because of authentication issues. See the section \"Repository with Tokens\" below.\n\n## Example Usage\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name       = \"example\"\n  repository = \"https://github.com/example/app\"\n\n  # The default build_spec added by the Amplify Console for React.\n  build_spec = <<-EOT\n    version: 0.1\n    frontend:\n      phases:\n        preBuild:\n          commands:\n            - yarn install\n        build:\n          commands:\n            - yarn run build\n      artifacts:\n        baseDirectory: build\n        files:\n          - '**/*'\n      cache:\n        paths:\n          - node_modules/**/*\n  EOT\n\n  # The default rewrites and redirects added by the Amplify Console.\n  custom_rule {\n    source = \"/<*>\"\n    status = \"404\"\n    target = \"/index.html\"\n  }\n\n  environment_variables = {\n    ENV = \"test\"\n  }\n}\n```\n\n### Repository with Tokens\n\nIf you create a new Amplify App with the `repository` argument, you also need to set `oauth_token` or `access_token` for authentication. For GitHub, get a [personal access token](https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line) and set `access_token` as follows:\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name       = \"example\"\n  repository = \"https://github.com/example/app\"\n\n  # GitHub personal access token\n  access_token = \"...\"\n}\n```\n\nYou can omit `access_token` if you import an existing Amplify App created by the Amplify Console (using OAuth for authentication).\n\n### Auto Branch Creation\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"example\"\n\n  enable_auto_branch_creation = true\n\n  # The default patterns added by the Amplify Console.\n  auto_branch_creation_patterns = [\n    \"*\",\n    \"*/**\",\n  ]\n\n  auto_branch_creation_config {\n    # Enable auto build for the created branch.\n    enable_auto_build = true\n  }\n}\n```\n\n### Basic Authorization\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"example\"\n\n  enable_basic_auth      = true\n  basic_auth_credentials = base64encode(\"username1:password1\")\n}\n```\n\n### Rewrites and Redirects\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"example\"\n\n  # Reverse Proxy Rewrite for API requests\n  # https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html#reverse-proxy-rewrite\n  custom_rule {\n    source = \"/api/<*>\"\n    status = \"200\"\n    target = \"https://api.example.com/api/<*>\"\n  }\n\n  # Redirects for Single Page Web Apps (SPA)\n  # https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html#redirects-for-single-page-web-apps-spa\n  custom_rule {\n    source = \"</^[^.]+$|\\\\.(?!(css|gif|ico|jpg|js|png|txt|svg|woff|ttf|map|json)$)([^.]+$)/>\"\n    status = \"200\"\n    target = \"/index.html\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name for an Amplify app.\n* `access_token` - (Optional) The personal access token for a third-party source control system for an Amplify app. The personal access token is used to create a webhook and a read-only deploy key. The token is not stored.\n* `auto_branch_creation_config` - (Optional) The automated branch creation configuration for an Amplify app. An `auto_branch_creation_config` block is documented below.\n* `auto_branch_creation_patterns` - (Optional) The automated branch creation glob patterns for an Amplify app.\n* `basic_auth_credentials` - (Optional) The credentials for basic authorization for an Amplify app.\n* `build_spec` - (Optional) The [build specification](https://docs.aws.amazon.com/amplify/latest/userguide/build-settings.html) (build spec) for an Amplify app.\n* `custom_rule` - (Optional) The custom rewrite and redirect rules for an Amplify app. A `custom_rule` block is documented below.\n* `description` - (Optional) The description for an Amplify app.\n* `enable_auto_branch_creation` - (Optional) Enables automated branch creation for an Amplify app.\n* `enable_basic_auth` - (Optional) Enables basic authorization for an Amplify app. This will apply to all branches that are part of this app.\n* `enable_branch_auto_build` - (Optional) Enables auto-building of branches for the Amplify App.\n* `enable_branch_auto_deletion` - (Optional) Automatically disconnects a branch in the Amplify Console when you delete a branch from your Git repository.\n* `environment_variables` - (Optional) The environment variables map for an Amplify app.\n* `iam_service_role_arn` - (Optional) The AWS Identity and Access Management (IAM) service role for an Amplify app.\n* `oauth_token` - (Optional) The OAuth token for a third-party source control system for an Amplify app. The OAuth token is used to create a webhook and a read-only deploy key. The OAuth token is not stored.\n* `platform` - (Optional) The platform or framework for an Amplify app. Valid values: `WEB`.\n* `repository` - (Optional) The repository for an Amplify app.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\nAn `auto_branch_creation_config` block supports the following arguments:\n\n* `basic_auth_credentials` - (Optional) The basic authorization credentials for the autocreated branch.\n* `build_spec` - (Optional) The build specification (build spec) for the autocreated branch.\n* `enable_auto_build` - (Optional) Enables auto building for the autocreated branch.\n* `enable_basic_auth` - (Optional) Enables basic authorization for the autocreated branch.\n* `enable_performance_mode` - (Optional) Enables performance mode for the branch.\n* `enable_pull_request_preview` - (Optional) Enables pull request previews for the autocreated branch.\n* `environment_variables` - (Optional) The environment variables for the autocreated branch.\n* `framework` - (Optional) The framework for the autocreated branch.\n* `pull_request_environment_name` - (Optional) The Amplify environment name for the pull request.\n* `stage` - (Optional) Describes the current stage for the autocreated branch. Valid values: `PRODUCTION`, `BETA`, `DEVELOPMENT`, `EXPERIMENTAL`, `PULL_REQUEST`.\n\nA `custom_rule` block supports the following arguments:\n\n* `condition` - (Optional) The condition for a URL rewrite or redirect rule, such as a country code.\n* `source` - (Required) The source pattern for a URL rewrite or redirect rule.\n* `status` - (Optional) The status code for a URL rewrite or redirect rule. Valid values: `200`, `301`, `302`, `404`, `404-200`.\n* `target` - (Required) The target pattern for a URL rewrite or redirect rule.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Amplify app.\n* `default_domain` - The default domain for the Amplify app.\n* `id` - The unique ID of the Amplify app.\n* `production_branch` - Describes the information about a production branch for an Amplify app. A `production_branch` block is documented below.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\nA `production_branch` block supports the following attributes:\n\n* `branch_name` - The branch name for the production branch.\n* `last_deploy_time` - The last deploy time of the production branch.\n* `status` - The status of the production branch.\n* `thumbnail_url` - The thumbnail URL for the production branch.\n\n## Import\n\nAmplify App can be imported using Amplify App ID (appId), e.g.,\n\n```\n$ terraform import aws_amplify_app.example d2ypk4k47z8u6\n```\n\nApp ID can be obtained from App ARN (e.g., `arn:aws:amplify:us-east-1:12345678:apps/d2ypk4k47z8u6`).\n",
    "basename": "amplify_app.html"
  },
  "amplify_backend_environment.html": {
    "subcategory": "Amplify Console",
    "layout": "aws",
    "page_title": "AWS: aws_amplify_backend_environment",
    "description": "Provides an Amplify Backend Environment resource.",
    "preview": "# Resource: aws_amplify_backend_environment\n\nProvides an Amplify …",
    "content": "\n\n# Resource: aws_amplify_backend_environment\n\nProvides an Amplify Backend Environment resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_amplify_backend_environment\" \"example\" {\n  app_id           = aws_amplify_app.example.id\n  environment_name = \"example\"\n\n  deployment_artifacts = \"app-example-deployment\"\n  stack_name           = \"amplify-app-example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `app_id` - (Required) The unique ID for an Amplify app.\n* `environment_name` - (Required) The name for the backend environment.\n* `deployment_artifacts` - (Optional) The name of deployment artifacts.\n* `stack_name` - (Optional) The AWS CloudFormation stack name of a backend environment.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) for a backend environment that is part of an Amplify app.\n* `id` - The unique ID of the Amplify backend environment.\n\n## Import\n\nAmplify backend environment can be imported using `app_id` and `environment_name`, e.g.,\n\n```\n$ terraform import aws_amplify_backend_environment.example d2ypk4k47z8u6/example\n```\n",
    "basename": "amplify_backend_environment.html"
  },
  "amplify_branch.html": {
    "subcategory": "Amplify Console",
    "layout": "aws",
    "page_title": "AWS: aws_amplify_branch",
    "description": "Provides an Amplify Branch resource.",
    "preview": "# Resource: aws_amplify_branch\n\nProvides an Amplify Branch resource. …",
    "content": "\n\n# Resource: aws_amplify_branch\n\nProvides an Amplify Branch resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"app\"\n}\n\nresource \"aws_amplify_branch\" \"master\" {\n  app_id      = aws_amplify_app.example.id\n  branch_name = \"master\"\n\n  framework = \"React\"\n  stage     = \"PRODUCTION\"\n\n  environment_variables = {\n    REACT_APP_API_SERVER = \"https://api.example.com\"\n  }\n}\n```\n\n### Basic Authentication\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"app\"\n}\n\nresource \"aws_amplify_branch\" \"master\" {\n  app_id      = aws_amplify_app.example.id\n  branch_name = \"master\"\n\n  basic_auth_config {\n    # Enable basic authentication.\n    enable_basic_auth = true\n\n    username = \"username\"\n    password = \"password\"\n  }\n}\n```\n\n### Notifications\n\nAmplify Console uses EventBridge (formerly known as CloudWatch Events) and SNS for email notifications.  To implement the same functionality, you need to set `enable_notification` in a `aws_amplify_branch` resource, as well as creating an EventBridge Rule, an SNS topic, and SNS subscriptions.\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"app\"\n}\n\nresource \"aws_amplify_branch\" \"master\" {\n  app_id      = aws_amplify_app.example.id\n  branch_name = \"master\"\n\n  # Enable SNS notifications.\n  enable_notification = true\n}\n\n# EventBridge Rule for Amplify notifications\n\nresource \"aws_cloudwatch_event_rule\" \"amplify_app_master\" {\n  name        = \"amplify-${aws_amplify_app.app.id}-${aws_amplify_branch.master.branch_name}-branch-notification\"\n  description = \"AWS Amplify build notifications for :  App: ${aws_amplify_app.app.id} Branch: ${aws_amplify_branch.master.branch_name}\"\n\n  event_pattern = jsonencode({\n    \"detail\" = {\n      \"appId\" = [\n        aws_amplify_app.example.id\n      ]\n      \"branchName\" = [\n        aws_amplify_branch.master.branch_name\n      ],\n      \"jobStatus\" = [\n        \"SUCCEED\",\n        \"FAILED\",\n        \"STARTED\"\n      ]\n    }\n    \"detail-type\" = [\n      \"Amplify Deployment Status Change\"\n    ]\n    \"source\" = [\n      \"aws.amplify\"\n    ]\n  })\n}\n\nresource \"aws_cloudwatch_event_target\" \"amplify_app_master\" {\n  rule      = aws_cloudwatch_event_rule.amplify_app_master.name\n  target_id = aws_amplify_branch.master.branch_name\n  arn       = aws_sns_topic.amplify_app_master.arn\n\n  input_transformer {\n    input_paths = {\n      jobId  = \"$.detail.jobId\"\n      appId  = \"$.detail.appId\"\n      region = \"$.region\"\n      branch = \"$.detail.branchName\"\n      status = \"$.detail.jobStatus\"\n    }\n\n    input_template = \"\\\"Build notification from the AWS Amplify Console for app: https://<branch>.<appId>.amplifyapp.com/. Your build status is <status>. Go to https://console.aws.amazon.com/amplify/home?region=<region>#<appId>/<branch>/<jobId> to view details on your build. \\\"\"\n  }\n}\n\n# SNS Topic for Amplify notifications\n\nresource \"aws_sns_topic\" \"amplify_app_master\" {\n  name = \"amplify-${aws_amplify_app.app.id}_${aws_amplify_branch.master.branch_name}\"\n}\n\ndata \"aws_iam_policy_document\" \"amplify_app_master\" {\n  statement {\n    sid = \"Allow_Publish_Events ${aws_amplify_branch.master.arn}\"\n\n    effect = \"Allow\"\n\n    actions = [\n      \"SNS:Publish\",\n    ]\n\n    principals {\n      type = \"Service\"\n      identifiers = [\n        \"events.amazonaws.com\",\n      ]\n    }\n\n    resources = [\n      aws_sns_topic.amplify_app_master.arn,\n    ]\n  }\n}\n\nresource \"aws_sns_topic_policy\" \"amplify_app_master\" {\n  arn    = aws_sns_topic.amplify_app_master.arn\n  policy = data.aws_iam_policy_document.amplify_app_master.json\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `app_id` - (Required) The unique ID for an Amplify app.\n* `branch_name` - (Required) The name for the branch.\n* `backend_environment_arn` - (Optional) The Amazon Resource Name (ARN) for a backend environment that is part of an Amplify app.\n* `basic_auth_credentials` - (Optional) The basic authorization credentials for the branch.\n* `description` - (Optional) The description for the branch.\n* `display_name` - (Optional) The display name for a branch. This is used as the default domain prefix.\n* `enable_auto_build` - (Optional) Enables auto building for the branch.\n* `enable_basic_auth` - (Optional) Enables basic authorization for the branch.\n* `enable_notification` - (Optional) Enables notifications for the branch.\n* `enable_performance_mode` - (Optional) Enables performance mode for the branch.\n* `enable_pull_request_preview` - (Optional) Enables pull request previews for this branch.\n* `environment_variables` - (Optional) The environment variables for the branch.\n* `framework` - (Optional) The framework for the branch.\n* `pull_request_environment_name` - (Optional) The Amplify environment name for the pull request.\n* `stage` - (Optional) Describes the current stage for the branch. Valid values: `PRODUCTION`, `BETA`, `DEVELOPMENT`, `EXPERIMENTAL`, `PULL_REQUEST`.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `ttl` - (Optional) The content Time To Live (TTL) for the website in seconds.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) for the branch.\n* `associated_resources` - A list of custom resources that are linked to this branch.\n* `custom_domains` - The custom domains for the branch.\n* `destination_branch` - The destination branch if the branch is a pull request branch.\n* `source_branch` - The source branch if the branch is a pull request branch.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAmplify branch can be imported using `app_id` and `branch_name`, e.g.,\n\n```\n$ terraform import aws_amplify_branch.master d2ypk4k47z8u6/master\n```\n",
    "basename": "amplify_branch.html"
  },
  "amplify_domain_association.html": {
    "subcategory": "Amplify Console",
    "layout": "aws",
    "page_title": "AWS: aws_amplify_domain_association",
    "description": "Provides an Amplify Domain Association resource.",
    "preview": "# Resource: aws_amplify_domain_association\n\nProvides an Amplify …",
    "content": "\n\n# Resource: aws_amplify_domain_association\n\nProvides an Amplify Domain Association resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"app\"\n\n  # Setup redirect from https://example.com to https://www.example.com\n  custom_rule {\n    source = \"https://example.com\"\n    status = \"302\"\n    target = \"https://www.example.com\"\n  }\n}\n\nresource \"aws_amplify_branch\" \"master\" {\n  app_id      = aws_amplify_app.example.id\n  branch_name = \"master\"\n}\n\nresource \"aws_amplify_domain_association\" \"example\" {\n  app_id      = aws_amplify_app.example.id\n  domain_name = \"example.com\"\n\n  # https://example.com\n  sub_domain {\n    branch_name = aws_amplify_branch.master.branch_name\n    prefix      = \"\"\n  }\n\n  # https://www.example.com\n  sub_domain {\n    branch_name = aws_amplify_branch.master.branch_name\n    prefix      = \"www\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `app_id` - (Required) The unique ID for an Amplify app.\n* `domain_name` - (Required) The domain name for the domain association.\n* `sub_domain` - (Required) The setting for the subdomain. Documented below.\n* `wait_for_verification` - (Optional) If enabled, the resource will wait for the domain association status to change to `PENDING_DEPLOYMENT` or `AVAILABLE`. Setting this to `false` will skip the process. Default: `true`.\n\nThe `sub_domain` configuration block supports the following arguments:\n\n* `branch_name` - (Required) The branch name setting for the subdomain.\n* `prefix` - (Required) The prefix setting for the subdomain.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) for the domain association.\n* `certificate_verification_dns_record` - The DNS record for certificate verification.\n\nThe `sub_domain` configuration block exports the following attributes:\n\n* `dns_record` - The DNS record for the subdomain.\n* `verified` - The verified status of the subdomain.\n\n## Import\n\nAmplify domain association can be imported using `app_id` and `domain_name`, e.g.,\n\n```\n$ terraform import aws_amplify_domain_association.app d2ypk4k47z8u6/example.com\n```\n",
    "basename": "amplify_domain_association.html"
  },
  "amplify_webhook.html": {
    "subcategory": "Amplify Console",
    "layout": "aws",
    "page_title": "AWS: aws_amplify_webhook",
    "description": "Provides an Amplify Webhook resource.",
    "preview": "# Resource: aws_amplify_webhook\n\nProvides an Amplify Webhook …",
    "content": "\n\n# Resource: aws_amplify_webhook\n\nProvides an Amplify Webhook resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_amplify_app\" \"example\" {\n  name = \"app\"\n}\n\nresource \"aws_amplify_branch\" \"master\" {\n  app_id      = aws_amplify_app.example.id\n  branch_name = \"master\"\n}\n\nresource \"aws_amplify_webhook\" \"master\" {\n  app_id      = aws_amplify_app.example.id\n  branch_name = aws_amplify_branch.master.branch_name\n  description = \"triggermaster\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `app_id` - (Required) The unique ID for an Amplify app.\n* `branch_name` - (Required) The name for a branch that is part of the Amplify app.\n* `description` - (Optional) The description for a webhook.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) for the webhook.\n* `url` - The URL of the webhook.\n\n## Import\n\nAmplify webhook can be imported using a webhook ID, e.g.,\n\n```\n$ terraform import aws_amplify_webhook.master a26b22a0-748b-4b57-b9a0-ae7e601fe4b1\n```\n",
    "basename": "amplify_webhook.html"
  },
  "api_gateway_account.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_account",
    "description": "Provides a settings of an API Gateway Account.",
    "preview": "# Resource: aws_api_gateway_account\n\nProvides a settings of an API …",
    "content": "\n\n# Resource: aws_api_gateway_account\n\nProvides a settings of an API Gateway Account. Settings is applied region-wide per `provider` block.\n\n-> **Note:** As there is no API method for deleting account settings or resetting it to defaults, destroying this resource will keep your account settings intact\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_account\" \"demo\" {\n  cloudwatch_role_arn = aws_iam_role.cloudwatch.arn\n}\n\nresource \"aws_iam_role\" \"cloudwatch\" {\n  name = \"api_gateway_cloudwatch_global\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"apigateway.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"cloudwatch\" {\n  name = \"default\"\n  role = aws_iam_role.cloudwatch.id\n\n  policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\",\n                \"logs:DescribeLogGroups\",\n                \"logs:DescribeLogStreams\",\n                \"logs:PutLogEvents\",\n                \"logs:GetLogEvents\",\n                \"logs:FilterLogEvents\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `cloudwatch_role_arn` - (Optional) The ARN of an IAM role for CloudWatch (to allow logging & monitoring). See more [in AWS Docs](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-stage-settings.html#how-to-stage-settings-console). Logging & monitoring can be enabled/disabled and otherwise tuned on the API Gateway Stage level.\n\n## Attributes Reference\n\nThe following attribute is exported:\n\n* `throttle_settings` - Account-Level throttle settings. See exported fields below.\n\n`throttle_settings` block exports the following:\n\n* `burst_limit` - The absolute maximum number of times API Gateway allows the API to be called per second (RPS).\n* `rate_limit` - The number of times API Gateway allows the API to be called per second on average (RPS).\n\n\n## Import\n\nAPI Gateway Accounts can be imported using the word `api-gateway-account`, e.g.,\n\n```\n$ terraform import aws_api_gateway_account.demo api-gateway-account\n```\n",
    "basename": "api_gateway_account.html"
  },
  "api_gateway_api_key.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_api_key",
    "description": "Provides an API Gateway API Key.",
    "preview": "# Resource: aws_api_gateway_api_key\n\nProvides an API Gateway API …",
    "content": "\n\n# Resource: aws_api_gateway_api_key\n\nProvides an API Gateway API Key.\n\n~> **NOTE:** Since the API Gateway usage plans feature was launched on August 11, 2016, usage plans are now **required** to associate an API key with an API stage.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_api_key\" \"MyDemoApiKey\" {\n  name = \"demo\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the API key\n* `description` - (Optional) The API key description. Defaults to \"Managed by Terraform\".\n* `enabled` - (Optional) Specifies whether the API key can be used by callers. Defaults to `true`.\n* `value` - (Optional) The value of the API key. If not specified, it will be automatically generated by AWS on creation.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the API key\n* `created_date` - The creation date of the API key\n* `last_updated_date` - The last update date of the API key\n* `value` - The value of the API key\n* `arn` - Amazon Resource Name (ARN)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAPI Gateway Keys can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_api_gateway_api_key.my_demo_key 8bklk8bl1k3sB38D9B3l0enyWT8c09B30lkq0blk\n```\n",
    "basename": "api_gateway_api_key.html"
  },
  "api_gateway_authorizer.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_authorizer",
    "description": "Provides an API Gateway Authorizer.",
    "preview": "# Resource: aws_api_gateway_authorizer\n\nProvides an API Gateway …",
    "content": "\n\n# Resource: aws_api_gateway_authorizer\n\nProvides an API Gateway Authorizer.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_authorizer\" \"demo\" {\n  name                   = \"demo\"\n  rest_api_id            = aws_api_gateway_rest_api.demo.id\n  authorizer_uri         = aws_lambda_function.authorizer.invoke_arn\n  authorizer_credentials = aws_iam_role.invocation_role.arn\n}\n\nresource \"aws_api_gateway_rest_api\" \"demo\" {\n  name = \"auth-demo\"\n}\n\nresource \"aws_iam_role\" \"invocation_role\" {\n  name = \"api_gateway_auth_invocation\"\n  path = \"/\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"apigateway.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"invocation_policy\" {\n  name = \"default\"\n  role = aws_iam_role.invocation_role.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"lambda:InvokeFunction\",\n      \"Effect\": \"Allow\",\n      \"Resource\": \"${aws_lambda_function.authorizer.arn}\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role\" \"lambda\" {\n  name = \"demo-lambda\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_lambda_function\" \"authorizer\" {\n  filename      = \"lambda-function.zip\"\n  function_name = \"api_gateway_authorizer\"\n  role          = aws_iam_role.lambda.arn\n  handler       = \"exports.example\"\n\n  source_code_hash = filebase64sha256(\"lambda-function.zip\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `authorizer_uri` - (Optional, required for type `TOKEN`/`REQUEST`) The authorizer's Uniform Resource Identifier (URI). This must be a well-formed Lambda function URI in the form of `arn:aws:apigateway:{region}:lambda:path/{service_api}`,\n e.g., `arn:aws:apigateway:us-west-2:lambda:path/2015-03-31/functions/arn:aws:lambda:us-west-2:012345678912:function:my-function/invocations`\n* `name` - (Required) The name of the authorizer\n* `rest_api_id` - (Required) The ID of the associated REST API\n* `identity_source` - (Optional) The source of the identity in an incoming request. Defaults to `method.request.header.Authorization`. For `REQUEST` type, this may be a comma-separated list of values, including headers, query string parameters and stage variables - e.g., `\"method.request.header.SomeHeaderName,method.request.querystring.SomeQueryStringName,stageVariables.SomeStageVariableName\"`\n* `type` - (Optional) The type of the authorizer. Possible values are `TOKEN` for a Lambda function using a single authorization token submitted in a custom header, `REQUEST` for a Lambda function using incoming request parameters, or `COGNITO_USER_POOLS` for using an Amazon Cognito user pool. Defaults to `TOKEN`.\n* `authorizer_credentials` - (Optional) The credentials required for the authorizer. To specify an IAM Role for API Gateway to assume, use the IAM Role ARN.\n* `authorizer_result_ttl_in_seconds` - (Optional) The TTL of cached authorizer results in seconds. Defaults to `300`.\n* `identity_validation_expression` - (Optional) A validation expression for the incoming identity. For `TOKEN` type, this value should be a regular expression. The incoming token from the client is matched against this expression, and will proceed if the token matches. If the token doesn't match, the client receives a 401 Unauthorized response.\n* `provider_arns` - (Optional, required for type `COGNITO_USER_POOLS`) A list of the Amazon Cognito user pool ARNs. Each element is of this format: `arn:aws:cognito-idp:{region}:{account_id}:userpool/{user_pool_id}`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Authorizer identifier.\n\n## Import\n\nAWS API Gateway Authorizer can be imported using the `REST-API-ID/AUTHORIZER-ID`, e.g.,\n\n```sh\n$ terraform import aws_api_gateway_authorizer.authorizer 12345abcde/example\n```\n",
    "basename": "api_gateway_authorizer.html"
  },
  "api_gateway_base_path_mapping.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_base_path_mapping",
    "description": "Connects a custom domain with a deployed API",
    "preview": "# Resource: aws_api_gateway_base_path_mapping\n\nConnects a custom …",
    "content": "\n\n# Resource: aws_api_gateway_base_path_mapping\n\nConnects a custom domain name registered via `aws_api_gateway_domain_name`\nwith a deployed API so that its methods can be called via the\ncustom domain name.\n\n## Example Usage\n\nAn end-to-end example of a REST API configured with OpenAPI can be found in the [`/examples/api-gateway-rest-api-openapi` directory within the GitHub repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi).\n\n```terraform\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n\nresource \"aws_api_gateway_domain_name\" \"example\" {\n  domain_name = \"example.com\"\n\n  certificate_name        = \"example-api\"\n  certificate_body        = file(\"${path.module}/example.com/example.crt\")\n  certificate_chain       = file(\"${path.module}/example.com/ca.crt\")\n  certificate_private_key = file(\"${path.module}/example.com/example.key\")\n}\n\nresource \"aws_api_gateway_base_path_mapping\" \"example\" {\n  api_id      = aws_api_gateway_rest_api.example.id\n  stage_name  = aws_api_gateway_stage.example.stage_name\n  domain_name = aws_api_gateway_domain_name.example.domain_name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Required) The already-registered domain name to connect the API to.\n* `api_id` - (Required) The id of the API to connect.\n* `stage_name` - (Optional) The name of a specific deployment stage to expose at the given path. If omitted, callers may select any stage by including its name as a path element after the base path.\n* `base_path` - (Optional) Path segment that must be prepended to the path when accessing the API via this mapping. If omitted, the API is exposed at the root of the given domain.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_api_gateway_base_path_mapping` can be imported by using the domain name and base path, e.g.,\n\nFor empty `base_path` (e.g., root path (`/`)):\n\n```\n$ terraform import aws_api_gateway_base_path_mapping.example example.com/\n```\n\nOtherwise:\n\n```\n$ terraform import aws_api_gateway_base_path_mapping.example example.com/base-path\n```\n",
    "basename": "api_gateway_base_path_mapping.html"
  },
  "api_gateway_client_certificate.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_client_certificate",
    "description": "Provides an API Gateway Client Certificate.",
    "preview": "# Resource: aws_api_gateway_client_certificate\n\nProvides an API …",
    "content": "\n\n# Resource: aws_api_gateway_client_certificate\n\nProvides an API Gateway Client Certificate.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_client_certificate\" \"demo\" {\n  description = \"My client certificate\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) The description of the client certificate.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identifier of the client certificate.\n* `created_date` - The date when the client certificate was created.\n* `expiration_date` - The date when the client certificate will expire.\n* `pem_encoded_certificate` - The PEM-encoded public key of the client certificate.\n* `arn` - Amazon Resource Name (ARN)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAPI Gateway Client Certificates can be imported using the id, e.g.,\n\n```\n$ terraform import aws_api_gateway_client_certificate.demo ab1cqe\n```\n",
    "basename": "api_gateway_client_certificate.html"
  },
  "api_gateway_deployment.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_deployment",
    "description": "Manages an API Gateway REST Deployment.",
    "preview": "# Resource: aws_api_gateway_deployment\n\nManages an API Gateway REST …",
    "content": "\n\n# Resource: aws_api_gateway_deployment\n\nManages an API Gateway REST Deployment. A deployment is a snapshot of the REST API configuration. The deployment can then be published to callable endpoints via the [`aws_api_gateway_stage` resource](api_gateway_stage.html) and optionally managed further with the [`aws_api_gateway_base_path_mapping` resource](api_gateway_base_path_mapping.html), [`aws_api_gateway_domain_name` resource](api_gateway_domain_name.html), and [`aws_api_method_settings` resource](api_gateway_method_settings.html). For more information, see the [API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-deploy-api.html).\n\nTo properly capture all REST API configuration in a deployment, this resource must have dependencies on all prior Terraform resources that manage resources/paths, methods, integrations, etc.\n\n* For REST APIs that are configured via OpenAPI specification ([`aws_api_gateway_rest_api` resource](api_gateway_rest_api.html) `body` argument), no special dependency setup is needed beyond referencing the  `id` attribute of that resource unless additional Terraform resources have further customized the REST API.\n* When the REST API configuration involves other Terraform resources ([`aws_api_gateway_integration` resource](api_gateway_integration.html), etc.), the dependency setup can be done with implicit resource references in the `triggers` argument or explicit resource references using the [resource `depends_on` meta-argument](https://www.terraform.io/docs/configuration/meta-arguments/depends_on.html). The `triggers` argument should be preferred over `depends_on`, since `depends_on` can only capture dependency ordering and will not cause the resource to recreate (redeploy the REST API) with upstream configuration changes.\n\n!> **WARNING:** It is recommended to use the [`aws_api_gateway_stage` resource](api_gateway_stage.html) instead of managing an API Gateway Stage via the `stage_name` argument of this resource. When this resource is recreated (REST API redeployment) with the `stage_name` configured, the stage is deleted and recreated. This will cause a temporary service interruption, increase Terraform plan differences, and can require a second Terraform apply to recreate any downstream stage configuration such as associated `aws_api_method_settings` resources.\n\n~> **NOTE:** It is recommended to enable the [resource `lifecycle` configuration block `create_before_destroy` argument](https://www.terraform.io/docs/configuration/resources.html#create_before_destroy) in this resource configuration to properly order redeployments in Terraform. Without enabling `create_before_destroy`, API Gateway can return errors such as `BadRequestException: Active stages pointing to this deployment must be moved or deleted` on recreation.\n\n## Example Usage\n\n### OpenAPI Specification\n\nAn end-to-end example of a REST API configured with OpenAPI can be found in the [`/examples/api-gateway-rest-api-openapi` directory within the GitHub repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi).\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = \"example\"\n      version = \"1.0\"\n    }\n    paths = {\n      \"/path1\" = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n```\n\n### Terraform Resources\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_resource\" \"example\" {\n  parent_id   = aws_api_gateway_rest_api.example.root_resource_id\n  path_part   = \"example\"\n  rest_api_id = aws_api_gateway_rest_api.example.id\n}\n\nresource \"aws_api_gateway_method\" \"example\" {\n  authorization = \"NONE\"\n  http_method   = \"GET\"\n  resource_id   = aws_api_gateway_resource.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n}\n\nresource \"aws_api_gateway_integration\" \"example\" {\n  http_method = aws_api_gateway_method.example.http_method\n  resource_id = aws_api_gateway_resource.example.id\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  type        = \"MOCK\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    # NOTE: The configuration below will satisfy ordering considerations,\n    #       but not pick up all future REST API changes. More advanced patterns\n    #       are possible, such as using the filesha1() function against the\n    #       Terraform configuration file(s) or removing the .id references to\n    #       calculate a hash against whole resources. Be aware that using whole\n    #       resources will show a difference after the initial implementation.\n    #       It will stabilize to only change when resources change afterwards.\n    redeployment = sha1(jsonencode([\n      aws_api_gateway_resource.example.id,\n      aws_api_gateway_method.example.id,\n      aws_api_gateway_integration.example.id,\n    ]))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) REST API identifier.\n* `description` - (Optional) Description of the deployment\n* `stage_name` - (Optional) Name of the stage to create with this deployment. If the specified stage already exists, it will be updated to point to the new deployment. It is recommended to use the [`aws_api_gateway_stage` resource](api_gateway_stage.html) instead to manage stages.\n* `stage_description` - (Optional) Description to set on the stage managed by the `stage_name` argument.\n* `triggers` - (Optional) Map of arbitrary keys and values that, when changed, will trigger a redeployment. To force a redeployment without changing these keys/values, use the [`terraform taint` command](https://www.terraform.io/docs/commands/taint.html).\n* `variables` - (Optional) Map to set on the stage managed by the `stage_name` argument.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the deployment\n* `invoke_url` - The URL to invoke the API pointing to the stage,\n  e.g., `https://z4675bid1j.execute-api.eu-west-2.amazonaws.com/prod`\n* `execution_arn` - The execution ARN to be used in [`lambda_permission`](/docs/providers/aws/r/lambda_permission.html)'s `source_arn`\n  when allowing API Gateway to invoke a Lambda function,\n  e.g., `arn:aws:execute-api:eu-west-2:123456789012:z4675bid1j/prod`\n* `created_date` - The creation date of the deployment\n",
    "basename": "api_gateway_deployment.html"
  },
  "api_gateway_documentation_part.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_documentation_part",
    "description": "Provides a settings of an API Gateway Documentation Part.",
    "preview": "# Resource: aws_api_gateway_documentation_part\n\nProvides a settings …",
    "content": "\n\n# Resource: aws_api_gateway_documentation_part\n\nProvides a settings of an API Gateway Documentation Part.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_documentation_part\" \"example\" {\n  location {\n    type   = \"METHOD\"\n    method = \"GET\"\n    path   = \"/example\"\n  }\n\n  properties  = \"{\\\"description\\\":\\\"Example description\\\"}\"\n  rest_api_id = aws_api_gateway_rest_api.example.id\n}\n\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  name = \"example_api\"\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `location` - (Required) The location of the targeted API entity of the to-be-created documentation part. See below.\n* `properties` - (Required) A content map of API-specific key-value pairs describing the targeted API entity. The map must be encoded as a JSON string, e.g., \"{ \\\"description\\\": \\\"The API does ...\\\" }\". Only Swagger-compliant key-value pairs can be exported and, hence, published.\n* `rest_api_id` - (Required) The ID of the associated Rest API\n\n### Nested fields\n\n#### `location`\n\nSee supported entity types for each field in the [official docs](https://docs.aws.amazon.com/apigateway/api-reference/resource/documentation-part/).\n\n* `method` - (Optional) The HTTP verb of a method. The default value is `*` for any method.\n* `name` - (Optional) The name of the targeted API entity.\n* `path` - (Optional) The URL path of the target. The default value is `/` for the root resource.\n* `status_code` - (Optional) The HTTP status code of a response. The default value is `*` for any status code.\n* `type` - (Required) The type of API entity to which the documentation content appliesE.g., `API`, `METHOD` or `REQUEST_BODY`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique ID of the Documentation Part\n\n## Import\n\nAPI Gateway documentation_parts can be imported using `REST-API-ID/DOC-PART-ID`, e.g.,\n\n```\n$ terraform import aws_api_gateway_documentation_part.example 5i4e1ko720/3oyy3t\n```\n",
    "basename": "api_gateway_documentation_part.html"
  },
  "api_gateway_documentation_version.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_documentation_version",
    "description": "Provides a resource to manage an API Gateway Documentation Version.",
    "preview": "# Resource: aws_api_gateway_documentation_version\n\nProvides a …",
    "content": "\n\n# Resource: aws_api_gateway_documentation_version\n\nProvides a resource to manage an API Gateway Documentation Version.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_documentation_version\" \"example\" {\n  version     = \"example_version\"\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  description = \"Example description\"\n  depends_on  = [aws_api_gateway_documentation_part.example]\n}\n\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  name = \"example_api\"\n}\n\nresource \"aws_api_gateway_documentation_part\" \"example\" {\n  location {\n    type = \"API\"\n  }\n\n  properties  = \"{\\\"description\\\":\\\"Example\\\"}\"\n  rest_api_id = aws_api_gateway_rest_api.example.id\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `version` - (Required) The version identifier of the API documentation snapshot.\n* `rest_api_id` - (Required) The ID of the associated Rest API\n* `description` - (Optional) The description of the API documentation version.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n## Import\n\nAPI Gateway documentation versions can be imported using `REST-API-ID/VERSION`, e.g.,\n\n```\n$ terraform import aws_api_gateway_documentation_version.example 5i4e1ko720/example-version\n```\n",
    "basename": "api_gateway_documentation_version.html"
  },
  "api_gateway_domain_name.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_domain_name",
    "description": "Registers a custom domain name for use with AWS API Gateway.",
    "preview": "# Resource: aws_api_gateway_domain_name\n\nRegisters a custom domain …",
    "content": "\n\n# Resource: aws_api_gateway_domain_name\n\nRegisters a custom domain name for use with AWS API Gateway. Additional information about this functionality\ncan be found in the [API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html).\n\nThis resource just establishes ownership of and the TLS settings for\na particular domain name. An API can be attached to a particular path\nunder the registered domain name using\n[the `aws_api_gateway_base_path_mapping` resource](api_gateway_base_path_mapping.html).\n\nAPI Gateway domains can be defined as either 'edge-optimized' or 'regional'.  In an edge-optimized configuration,\nAPI Gateway internally creates and manages a CloudFront distribution to route requests on the given hostname. In\naddition to this resource it's necessary to create a DNS record corresponding to the given domain name which is an alias\n(either Route53 alias or traditional CNAME) to the Cloudfront domain name exported in the `cloudfront_domain_name`\nattribute.\n\nIn a regional configuration, API Gateway does not create a CloudFront distribution to route requests to the API, though\na distribution can be created if needed. In either case, it is necessary to create a DNS record corresponding to the\ngiven domain name which is an alias (either Route53 alias or traditional CNAME) to the regional domain name exported in\nthe `regional_domain_name` attribute.\n\n~> **Note:** API Gateway requires the use of AWS Certificate Manager (ACM) certificates instead of Identity and Access Management (IAM) certificates in regions that support ACM. Regions that support ACM can be found in the [Regions and Endpoints Documentation](https://docs.aws.amazon.com/general/latest/gr/rande.html#acm_region). To import an existing private key and certificate into ACM or request an ACM certificate, see the [`aws_acm_certificate` resource](/docs/providers/aws/r/acm_certificate.html).\n\n~> **Note:** The `aws_api_gateway_domain_name` resource expects dependency on the `aws_acm_certificate_validation` as\nonly verified certificates can be used. This can be made either explicitly by adding the\n`depends_on = [aws_acm_certificate_validation.cert]` attribute. Or implicitly by referring certificate ARN\nfrom the validation resource where it will be available after the resource creation:\n`regional_certificate_arn = aws_acm_certificate_validation.cert.certificate_arn`.\n\n~> **Note:** All arguments including the private key will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\nAn end-to-end example of a REST API configured with OpenAPI can be found in the [`/examples/api-gateway-rest-api-openapi` directory within the GitHub repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi).\n\n### Edge Optimized (ACM Certificate)\n\n```terraform\nresource \"aws_api_gateway_domain_name\" \"example\" {\n  certificate_arn = aws_acm_certificate_validation.example.certificate_arn\n  domain_name     = \"api.example.com\"\n}\n\n# Example DNS record using Route53.\n# Route53 is not specifically required; any DNS host can be used.\nresource \"aws_route53_record\" \"example\" {\n  name    = aws_api_gateway_domain_name.example.domain_name\n  type    = \"A\"\n  zone_id = aws_route53_zone.example.id\n\n  alias {\n    evaluate_target_health = true\n    name                   = aws_api_gateway_domain_name.example.cloudfront_domain_name\n    zone_id                = aws_api_gateway_domain_name.example.cloudfront_zone_id\n  }\n}\n```\n\n### Edge Optimized (IAM Certificate)\n\n```terraform\nresource \"aws_api_gateway_domain_name\" \"example\" {\n  domain_name = \"api.example.com\"\n\n  certificate_name        = \"example-api\"\n  certificate_body        = file(\"${path.module}/example.com/example.crt\")\n  certificate_chain       = file(\"${path.module}/example.com/ca.crt\")\n  certificate_private_key = file(\"${path.module}/example.com/example.key\")\n}\n\n# Example DNS record using Route53.\n# Route53 is not specifically required; any DNS host can be used.\nresource \"aws_route53_record\" \"example\" {\n  zone_id = aws_route53_zone.example.id # See aws_route53_zone for how to create this\n\n  name = aws_api_gateway_domain_name.example.domain_name\n  type = \"A\"\n\n  alias {\n    name                   = aws_api_gateway_domain_name.example.cloudfront_domain_name\n    zone_id                = aws_api_gateway_domain_name.example.cloudfront_zone_id\n    evaluate_target_health = true\n  }\n}\n```\n\n### Regional (ACM Certificate)\n\n```terraform\nresource \"aws_api_gateway_domain_name\" \"example\" {\n  domain_name              = \"api.example.com\"\n  regional_certificate_arn = aws_acm_certificate_validation.example.certificate_arn\n\n  endpoint_configuration {\n    types = [\"REGIONAL\"]\n  }\n}\n\n# Example DNS record using Route53.\n# Route53 is not specifically required; any DNS host can be used.\nresource \"aws_route53_record\" \"example\" {\n  name    = aws_api_gateway_domain_name.example.domain_name\n  type    = \"A\"\n  zone_id = aws_route53_zone.example.id\n\n  alias {\n    evaluate_target_health = true\n    name                   = aws_api_gateway_domain_name.example.regional_domain_name\n    zone_id                = aws_api_gateway_domain_name.example.regional_zone_id\n  }\n}\n```\n\n### Regional (IAM Certificate)\n\n```terraform\nresource \"aws_api_gateway_domain_name\" \"example\" {\n  certificate_body          = file(\"${path.module}/example.com/example.crt\")\n  certificate_chain         = file(\"${path.module}/example.com/ca.crt\")\n  certificate_private_key   = file(\"${path.module}/example.com/example.key\")\n  domain_name               = \"api.example.com\"\n  regional_certificate_name = \"example-api\"\n\n  endpoint_configuration {\n    types = [\"REGIONAL\"]\n  }\n}\n\n# Example DNS record using Route53.\n# Route53 is not specifically required; any DNS host can be used.\nresource \"aws_route53_record\" \"example\" {\n  name    = aws_api_gateway_domain_name.example.domain_name\n  type    = \"A\"\n  zone_id = aws_route53_zone.example.id\n\n  alias {\n    evaluate_target_health = true\n    name                   = aws_api_gateway_domain_name.example.regional_domain_name\n    zone_id                = aws_api_gateway_domain_name.example.regional_zone_id\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Required) The fully-qualified domain name to register\n* `endpoint_configuration` - (Optional) Configuration block defining API endpoint information including type. Defined below.\n* `mutual_tls_authentication` - (Optional) The mutual TLS authentication configuration for the domain name. Defined below.\n* `security_policy` - (Optional) The Transport Layer Security (TLS) version + cipher suite for this DomainName. The valid values are `TLS_1_0` and `TLS_1_2`. Must be configured to perform drift detection.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nWhen referencing an AWS-managed certificate, the following arguments are supported:\n\n* `certificate_arn` - (Optional) The ARN for an AWS-managed certificate. AWS Certificate Manager is the only supported source. Used when an edge-optimized domain name is desired. Conflicts with `certificate_name`, `certificate_body`, `certificate_chain`, `certificate_private_key`, `regional_certificate_arn`, and `regional_certificate_name`.\n* `regional_certificate_arn` - (Optional) The ARN for an AWS-managed certificate. AWS Certificate Manager is the only supported source. Used when a regional domain name is desired. Conflicts with `certificate_arn`, `certificate_name`, `certificate_body`, `certificate_chain`, and `certificate_private_key`.\n\nWhen uploading a certificate, the following arguments are supported:\n\n* `certificate_name` - (Optional) The unique name to use when registering this\n  certificate as an IAM server certificate. Conflicts with `certificate_arn`, `regional_certificate_arn`, and\n  `regional_certificate_name`. Required if `certificate_arn` is not set.\n* `certificate_body` - (Optional) The certificate issued for the domain name\n  being registered, in PEM format. Only valid for `EDGE` endpoint configuration type. Conflicts with `certificate_arn`, `regional_certificate_arn`, and\n  `regional_certificate_name`.\n* `certificate_chain` - (Optional) The certificate for the CA that issued the\n  certificate, along with any intermediate CA certificates required to\n  create an unbroken chain to a certificate trusted by the intended API clients. Only valid for `EDGE` endpoint configuration type. Conflicts with `certificate_arn`,\n  `regional_certificate_arn`, and `regional_certificate_name`.\n* `certificate_private_key` - (Optional) The private key associated with the\n  domain certificate given in `certificate_body`. Only valid for `EDGE` endpoint configuration type. Conflicts with `certificate_arn`, `regional_certificate_arn`, and `regional_certificate_name`.\n* `regional_certificate_name` - (Optional) The user-friendly name of the certificate that will be used by regional endpoint for this domain name. Conflicts with `certificate_arn`, `certificate_name`, `certificate_body`, `certificate_chain`, and\n  `certificate_private_key`.\n\n### endpoint_configuration\n\n* `types` - (Required) A list of endpoint types. This resource currently only supports managing a single value. Valid values: `EDGE` or `REGIONAL`. If unspecified, defaults to `EDGE`. Must be declared as `REGIONAL` in non-Commercial partitions. Refer to the [documentation](https://docs.aws.amazon.com/apigateway/latest/developerguide/create-regional-api.html) for more information on the difference between edge-optimized and regional APIs.\n\n### mutual_tls_authentication\n\n* `truststore_uri` - (Required) An Amazon S3 URL that specifies the truststore for mutual TLS authentication, for example, `s3://bucket-name/key-name`.\nThe truststore can contain certificates from public or private certificate authorities. To update the truststore, upload a new version to S3, and then update your custom domain name to use the new version.\n* `truststore_version` - (Optional) The version of the S3 object that contains the truststore. To specify a version, you must have versioning enabled for the S3 bucket.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The internal id assigned to this domain name by API Gateway.\n* `certificate_upload_date` - The upload date associated with the domain certificate.\n* `cloudfront_domain_name` - The hostname created by Cloudfront to represent\n  the distribution that implements this domain name mapping.\n* `cloudfront_zone_id` - For convenience, the hosted zone ID (`Z2FDTNDATAQYW2`)\n  that can be used to create a Route53 alias record for the distribution.\n* `regional_domain_name` - The hostname for the custom domain's regional endpoint.\n* `regional_zone_id` - The hosted zone ID that can be used to create a Route53 alias record for the regional endpoint.\n* `arn` - Amazon Resource Name (ARN)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAPI Gateway domain names can be imported using their `name`, e.g.,\n\n```\n$ terraform import aws_api_gateway_domain_name.example dev.example.com\n```\n",
    "basename": "api_gateway_domain_name.html"
  },
  "api_gateway_gateway_response": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_gateway_response",
    "description": "Provides an API Gateway Gateway Response for a REST API Gateway.",
    "preview": "# Resource: aws_api_gateway_gateway_response\n\nProvides an API …",
    "content": "\n\n# Resource: aws_api_gateway_gateway_response\n\nProvides an API Gateway Gateway Response for a REST API Gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"main\" {\n  name = \"MyDemoAPI\"\n}\n\nresource \"aws_api_gateway_gateway_response\" \"test\" {\n  rest_api_id   = aws_api_gateway_rest_api.main.id\n  status_code   = \"401\"\n  response_type = \"UNAUTHORIZED\"\n\n  response_templates = {\n    \"application/json\" = \"{\\\"message\\\":$context.error.messageString}\"\n  }\n\n  response_parameters = {\n    \"gatewayresponse.header.Authorization\" = \"'Basic'\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The string identifier of the associated REST API.\n* `response_type` - (Required) The response type of the associated GatewayResponse.\n* `status_code` - (Optional) The HTTP status code of the Gateway Response.\n* `response_templates` - (Optional) A map specifying the templates used to transform the response body.\n* `response_parameters` - (Optional) A map specifying the parameters (paths, query strings and headers) of the Gateway Response.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_api_gateway_gateway_response` can be imported using `REST-API-ID/RESPONSE-TYPE`, e.g.,\n\n```\n$ terraform import aws_api_gateway_gateway_response.example 12345abcde/UNAUTHORIZED\n```\n",
    "basename": "api_gateway_gateway_response"
  },
  "api_gateway_integration.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_integration",
    "description": "Provides an HTTP Method Integration for an API Gateway Integration.",
    "preview": "# Resource: aws_api_gateway_integration\n\nProvides an HTTP Method …",
    "content": "\n\n# Resource: aws_api_gateway_integration\n\nProvides an HTTP Method Integration for an API Gateway Integration.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"MyDemoAPI\" {\n  name        = \"MyDemoAPI\"\n  description = \"This is my API for demonstration purposes\"\n}\n\nresource \"aws_api_gateway_resource\" \"MyDemoResource\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  parent_id   = aws_api_gateway_rest_api.MyDemoAPI.root_resource_id\n  path_part   = \"mydemoresource\"\n}\n\nresource \"aws_api_gateway_method\" \"MyDemoMethod\" {\n  rest_api_id   = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id   = aws_api_gateway_resource.MyDemoResource.id\n  http_method   = \"GET\"\n  authorization = \"NONE\"\n}\n\nresource \"aws_api_gateway_integration\" \"MyDemoIntegration\" {\n  rest_api_id          = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id          = aws_api_gateway_resource.MyDemoResource.id\n  http_method          = aws_api_gateway_method.MyDemoMethod.http_method\n  type                 = \"MOCK\"\n  cache_key_parameters = [\"method.request.path.param\"]\n  cache_namespace      = \"foobar\"\n  timeout_milliseconds = 29000\n\n  request_parameters = {\n    \"integration.request.header.X-Authorization\" = \"'static'\"\n  }\n\n  # Transforms the incoming XML request to JSON\n  request_templates = {\n    \"application/xml\" = <<EOF\n{\n   \"body\" : $input.json('$')\n}\nEOF\n  }\n}\n```\n\n## Lambda integration\n\n```terraform\n# Variables\nvariable \"myregion\" {}\n\nvariable \"accountId\" {}\n\n# API Gateway\nresource \"aws_api_gateway_rest_api\" \"api\" {\n  name = \"myapi\"\n}\n\nresource \"aws_api_gateway_resource\" \"resource\" {\n  path_part   = \"resource\"\n  parent_id   = aws_api_gateway_rest_api.api.root_resource_id\n  rest_api_id = aws_api_gateway_rest_api.api.id\n}\n\nresource \"aws_api_gateway_method\" \"method\" {\n  rest_api_id   = aws_api_gateway_rest_api.api.id\n  resource_id   = aws_api_gateway_resource.resource.id\n  http_method   = \"GET\"\n  authorization = \"NONE\"\n}\n\nresource \"aws_api_gateway_integration\" \"integration\" {\n  rest_api_id             = aws_api_gateway_rest_api.api.id\n  resource_id             = aws_api_gateway_resource.resource.id\n  http_method             = aws_api_gateway_method.method.http_method\n  integration_http_method = \"POST\"\n  type                    = \"AWS_PROXY\"\n  uri                     = aws_lambda_function.lambda.invoke_arn\n}\n\n# Lambda\nresource \"aws_lambda_permission\" \"apigw_lambda\" {\n  statement_id  = \"AllowExecutionFromAPIGateway\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.lambda.function_name\n  principal     = \"apigateway.amazonaws.com\"\n\n  # More: http://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-control-access-using-iam-policies-to-invoke-api.html\n  source_arn = \"arn:aws:execute-api:${var.myregion}:${var.accountId}:${aws_api_gateway_rest_api.api.id}/*/${aws_api_gateway_method.method.http_method}${aws_api_gateway_resource.resource.path}\"\n}\n\nresource \"aws_lambda_function\" \"lambda\" {\n  filename      = \"lambda.zip\"\n  function_name = \"mylambda\"\n  role          = aws_iam_role.role.arn\n  handler       = \"lambda.lambda_handler\"\n  runtime       = \"python3.6\"\n\n  source_code_hash = filebase64sha256(\"lambda.zip\")\n}\n\n# IAM\nresource \"aws_iam_role\" \"role\" {\n  name = \"myrole\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nPOLICY\n}\n```\n\n## VPC Link\n\n```terraform\nvariable \"name\" {}\nvariable \"subnet_id\" {}\n\nresource \"aws_lb\" \"test\" {\n  name               = var.name\n  internal           = true\n  load_balancer_type = \"network\"\n  subnets            = [var.subnet_id]\n}\n\nresource \"aws_api_gateway_vpc_link\" \"test\" {\n  name        = var.name\n  target_arns = [aws_lb.test.arn]\n}\n\nresource \"aws_api_gateway_rest_api\" \"test\" {\n  name = var.name\n}\n\nresource \"aws_api_gateway_resource\" \"test\" {\n  rest_api_id = aws_api_gateway_rest_api.test.id\n  parent_id   = aws_api_gateway_rest_api.test.root_resource_id\n  path_part   = \"test\"\n}\n\nresource \"aws_api_gateway_method\" \"test\" {\n  rest_api_id   = aws_api_gateway_rest_api.test.id\n  resource_id   = aws_api_gateway_resource.test.id\n  http_method   = \"GET\"\n  authorization = \"NONE\"\n\n  request_models = {\n    \"application/json\" = \"Error\"\n  }\n}\n\nresource \"aws_api_gateway_integration\" \"test\" {\n  rest_api_id = aws_api_gateway_rest_api.test.id\n  resource_id = aws_api_gateway_resource.test.id\n  http_method = aws_api_gateway_method.test.http_method\n\n  request_templates = {\n    \"application/json\" = \"\"\n    \"application/xml\"  = \"#set($inputRoot = $input.path('$'))\\n{ }\"\n  }\n\n  request_parameters = {\n    \"integration.request.header.X-Authorization\" = \"'static'\"\n    \"integration.request.header.X-Foo\"           = \"'Bar'\"\n  }\n\n  type                    = \"HTTP\"\n  uri                     = \"https://www.google.de\"\n  integration_http_method = \"GET\"\n  passthrough_behavior    = \"WHEN_NO_MATCH\"\n  content_handling        = \"CONVERT_TO_TEXT\"\n\n  connection_type = \"VPC_LINK\"\n  connection_id   = aws_api_gateway_vpc_link.test.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the associated REST API.\n* `resource_id` - (Required) The API resource ID.\n* `http_method` - (Required) The HTTP method (`GET`, `POST`, `PUT`, `DELETE`, `HEAD`, `OPTION`, `ANY`)\n  when calling the associated resource.\n* `integration_http_method` - (Optional) The integration HTTP method\n  (`GET`, `POST`, `PUT`, `DELETE`, `HEAD`, `OPTIONs`, `ANY`, `PATCH`) specifying how API Gateway will interact with the back end.\n  **Required** if `type` is `AWS`, `AWS_PROXY`, `HTTP` or `HTTP_PROXY`.\n  Not all methods are compatible with all `AWS` integrations.\n  e.g., Lambda function [can only be invoked](https://github.com/awslabs/aws-apigateway-importer/issues/9#issuecomment-129651005) via `POST`.\n* `type` - (Required) The integration input's [type](https://docs.aws.amazon.com/apigateway/api-reference/resource/integration/). Valid values are `HTTP` (for HTTP backends), `MOCK` (not calling any real backend), `AWS` (for AWS services), `AWS_PROXY` (for Lambda proxy integration) and `HTTP_PROXY` (for HTTP proxy integration). An `HTTP` or `HTTP_PROXY` integration with a `connection_type` of `VPC_LINK` is referred to as a private integration and uses a VpcLink to connect API Gateway to a network load balancer of a VPC.\n* `connection_type` - (Optional) The integration input's [connectionType](https://docs.aws.amazon.com/apigateway/api-reference/resource/integration/#connectionType). Valid values are `INTERNET` (default for connections through the public routable internet), and `VPC_LINK` (for private connections between API Gateway and a network load balancer in a VPC).\n* `connection_id` - (Optional) The id of the VpcLink used for the integration. **Required** if `connection_type` is `VPC_LINK`\n* `uri` - (Optional) The input's URI. **Required** if `type` is `AWS`, `AWS_PROXY`, `HTTP` or `HTTP_PROXY`.\n  For HTTP integrations, the URI must be a fully formed, encoded HTTP(S) URL according to the RFC-3986 specification . For AWS integrations, the URI should be of the form `arn:aws:apigateway:{region}:{subdomain.service|service}:{path|action}/{service_api}`. `region`, `subdomain` and `service` are used to determine the right endpoint.\n  e.g., `arn:aws:apigateway:eu-west-1:lambda:path/2015-03-31/functions/arn:aws:lambda:eu-west-1:012345678901:function:my-func/invocations`. For private integrations, the URI parameter is not used for routing requests to your endpoint, but is used for setting the Host header and for certificate validation.\n* `credentials` - (Optional) The credentials required for the integration. For `AWS` integrations, 2 options are available. To specify an IAM Role for Amazon API Gateway to assume, use the role's ARN. To require that the caller's identity be passed through from the request, specify the string `arn:aws:iam::\\*:user/\\*`.\n* `request_templates` - (Optional) A map of the integration's request templates.\n* `request_parameters` - (Optional) A map of request query string parameters and headers that should be passed to the backend responder.\n  For example: `request_parameters = { \"integration.request.header.X-Some-Other-Header\" = \"method.request.header.X-Some-Header\" }`\n* `passthrough_behavior` - (Optional) The integration passthrough behavior (`WHEN_NO_MATCH`, `WHEN_NO_TEMPLATES`, `NEVER`).  **Required** if `request_templates` is used.\n* `cache_key_parameters` - (Optional) A list of cache key parameters for the integration.\n* `cache_namespace` - (Optional) The integration's cache namespace.\n* `content_handling` - (Optional) Specifies how to handle request payload content type conversions. Supported values are `CONVERT_TO_BINARY` and `CONVERT_TO_TEXT`. If this property is not defined, the request payload will be passed through from the method request to integration request without modification, provided that the passthroughBehaviors is configured to support payload pass-through.\n* `timeout_milliseconds` - (Optional) Custom timeout between 50 and 29,000 milliseconds. The default value is 29,000 milliseconds.\n* `tls_config` - (Optional) Configuration block specifying the TLS configuration for an integration. Defined below.\n\n### tls_config Configuration Block\n\nThe `tls_config` configuration block supports the following arguments:\n\n* `insecure_skip_verification` - (Optional) Specifies whether or not API Gateway skips verification that the certificate for an integration endpoint is issued by a [supported certificate authority](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-supported-certificate-authorities-for-http-endpoints.html). This isn’t recommended, but it enables you to use certificates that are signed by private certificate authorities, or certificates that are self-signed. If enabled, API Gateway still performs basic certificate validation, which includes checking the certificate's expiration date, hostname, and presence of a root certificate authority. Supported only for `HTTP` and `HTTP_PROXY` integrations.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_api_gateway_integration` can be imported using `REST-API-ID/RESOURCE-ID/HTTP-METHOD`, e.g.,\n\n```\n$ terraform import aws_api_gateway_integration.example 12345abcde/67890fghij/GET\n```\n",
    "basename": "api_gateway_integration.html"
  },
  "api_gateway_integration_response.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_integration_response",
    "description": "Provides an HTTP Method Integration Response for an API Gateway Resource.",
    "preview": "# Resource: aws_api_gateway_integration_response\n\nProvides an HTTP …",
    "content": "\n\n# Resource: aws_api_gateway_integration_response\n\nProvides an HTTP Method Integration Response for an API Gateway Resource.\n\n-> **Note:** Depends on having `aws_api_gateway_integration` inside your rest api. To ensure this\nyou might need to add an explicit `depends_on` for clean runs.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"MyDemoAPI\" {\n  name        = \"MyDemoAPI\"\n  description = \"This is my API for demonstration purposes\"\n}\n\nresource \"aws_api_gateway_resource\" \"MyDemoResource\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  parent_id   = aws_api_gateway_rest_api.MyDemoAPI.root_resource_id\n  path_part   = \"mydemoresource\"\n}\n\nresource \"aws_api_gateway_method\" \"MyDemoMethod\" {\n  rest_api_id   = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id   = aws_api_gateway_resource.MyDemoResource.id\n  http_method   = \"GET\"\n  authorization = \"NONE\"\n}\n\nresource \"aws_api_gateway_integration\" \"MyDemoIntegration\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id = aws_api_gateway_resource.MyDemoResource.id\n  http_method = aws_api_gateway_method.MyDemoMethod.http_method\n  type        = \"MOCK\"\n}\n\nresource \"aws_api_gateway_method_response\" \"response_200\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id = aws_api_gateway_resource.MyDemoResource.id\n  http_method = aws_api_gateway_method.MyDemoMethod.http_method\n  status_code = \"200\"\n}\n\nresource \"aws_api_gateway_integration_response\" \"MyDemoIntegrationResponse\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id = aws_api_gateway_resource.MyDemoResource.id\n  http_method = aws_api_gateway_method.MyDemoMethod.http_method\n  status_code = aws_api_gateway_method_response.response_200.status_code\n\n  # Transforms the backend JSON response to XML\n  response_templates = {\n    \"application/xml\" = <<EOF\n#set($inputRoot = $input.path('$'))\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<message>\n    $inputRoot.body\n</message>\nEOF\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the associated REST API\n* `resource_id` - (Required) The API resource ID\n* `http_method` - (Required) The HTTP method (`GET`, `POST`, `PUT`, `DELETE`, `HEAD`, `OPTIONS`, `ANY`)\n* `status_code` - (Required) The HTTP status code\n* `selection_pattern` - (Optional) Specifies the regular expression pattern used to choose\n  an integration response based on the response from the backend. Omit configuring this to make the integration the default one.\n  If the backend is an `AWS` Lambda function, the AWS Lambda function error header is matched.\n  For all other `HTTP` and `AWS` backends, the HTTP status code is matched.\n* `response_templates` - (Optional) A map specifying the templates used to transform the integration response body\n* `response_parameters` - (Optional) A map of response parameters that can be read from the backend response.\n  For example: `response_parameters = { \"method.response.header.X-Some-Header\" = \"integration.response.header.X-Some-Other-Header\" }`\n* `content_handling` - (Optional) Specifies how to handle request payload content type conversions. Supported values are `CONVERT_TO_BINARY` and `CONVERT_TO_TEXT`. If this property is not defined, the response payload will be passed through from the integration response to the method response without modification.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_api_gateway_integration_response` can be imported using `REST-API-ID/RESOURCE-ID/HTTP-METHOD/STATUS-CODE`, e.g.,\n\n```\n$ terraform import aws_api_gateway_integration_response.example 12345abcde/67890fghij/GET/200\n```\n",
    "basename": "api_gateway_integration_response.html"
  },
  "api_gateway_method.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_method",
    "description": "Provides a HTTP Method for an API Gateway Resource.",
    "preview": "# Resource: aws_api_gateway_method\n\nProvides a HTTP Method for an …",
    "content": "\n\n# Resource: aws_api_gateway_method\n\nProvides a HTTP Method for an API Gateway Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"MyDemoAPI\" {\n  name        = \"MyDemoAPI\"\n  description = \"This is my API for demonstration purposes\"\n}\n\nresource \"aws_api_gateway_resource\" \"MyDemoResource\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  parent_id   = aws_api_gateway_rest_api.MyDemoAPI.root_resource_id\n  path_part   = \"mydemoresource\"\n}\n\nresource \"aws_api_gateway_method\" \"MyDemoMethod\" {\n  rest_api_id   = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id   = aws_api_gateway_resource.MyDemoResource.id\n  http_method   = \"GET\"\n  authorization = \"NONE\"\n}\n```\n\n## Usage with Cognito User Pool Authorizer\n\n```terraform\nvariable \"cognito_user_pool_name\" {}\n\ndata \"aws_cognito_user_pools\" \"this\" {\n  name = var.cognito_user_pool_name\n}\n\nresource \"aws_api_gateway_rest_api\" \"this\" {\n  name = \"with-authorizer\"\n}\n\nresource \"aws_api_gateway_resource\" \"this\" {\n  rest_api_id = aws_api_gateway_rest_api.this.id\n  parent_id   = aws_api_gateway_rest_api.this.root_resource_id\n  path_part   = \"{proxy+}\"\n}\n\nresource \"aws_api_gateway_authorizer\" \"this\" {\n  name          = \"CognitoUserPoolAuthorizer\"\n  type          = \"COGNITO_USER_POOLS\"\n  rest_api_id   = aws_api_gateway_rest_api.this.id\n  provider_arns = data.aws_cognito_user_pools.this.arns\n}\n\nresource \"aws_api_gateway_method\" \"any\" {\n  rest_api_id   = aws_api_gateway_rest_api.this.id\n  resource_id   = aws_api_gateway_resource.this.id\n  http_method   = \"ANY\"\n  authorization = \"COGNITO_USER_POOLS\"\n  authorizer_id = aws_api_gateway_authorizer.this.id\n\n  request_parameters = {\n    \"method.request.path.proxy\" = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the associated REST API\n* `resource_id` - (Required) The API resource ID\n* `http_method` - (Required) The HTTP Method (`GET`, `POST`, `PUT`, `DELETE`, `HEAD`, `OPTIONS`, `ANY`)\n* `authorization` - (Required) The type of authorization used for the method (`NONE`, `CUSTOM`, `AWS_IAM`, `COGNITO_USER_POOLS`)\n* `authorizer_id` - (Optional) The authorizer id to be used when the authorization is `CUSTOM` or `COGNITO_USER_POOLS`\n* `authorization_scopes` - (Optional) The authorization scopes used when the authorization is `COGNITO_USER_POOLS`\n* `api_key_required` - (Optional) Specify if the method requires an API key\n* `operation_name` - (Optional) The function name that will be given to the method when generating an SDK through API Gateway. If omitted, API Gateway will generate a function name based on the resource path and HTTP verb.\n* `request_models` - (Optional) A map of the API models used for the request's content type\n  where key is the content type (e.g., `application/json`)\n  and value is either `Error`, `Empty` (built-in models) or `aws_api_gateway_model`'s `name`.\n* `request_validator_id` - (Optional) The ID of a `aws_api_gateway_request_validator`\n* `request_parameters` - (Optional) A map of request parameters (from the path, query string and headers) that should be passed to the integration. The boolean value indicates whether the parameter is required (`true`) or optional (`false`).\n  For example: `request_parameters = {\"method.request.header.X-Some-Header\" = true \"method.request.querystring.some-query-param\" = true}` would define that the header `X-Some-Header` and the query string `some-query-param` must be provided in the request.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_api_gateway_method` can be imported using `REST-API-ID/RESOURCE-ID/HTTP-METHOD`, e.g.,\n\n```\n$ terraform import aws_api_gateway_method.example 12345abcde/67890fghij/GET\n```\n",
    "basename": "api_gateway_method.html"
  },
  "api_gateway_method_response.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_method_response",
    "description": "Provides an HTTP Method Response for an API Gateway Resource.",
    "preview": "# Resource: aws_api_gateway_method_response\n\nProvides an HTTP Method …",
    "content": "\n\n# Resource: aws_api_gateway_method_response\n\nProvides an HTTP Method Response for an API Gateway Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"MyDemoAPI\" {\n  name        = \"MyDemoAPI\"\n  description = \"This is my API for demonstration purposes\"\n}\n\nresource \"aws_api_gateway_resource\" \"MyDemoResource\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  parent_id   = aws_api_gateway_rest_api.MyDemoAPI.root_resource_id\n  path_part   = \"mydemoresource\"\n}\n\nresource \"aws_api_gateway_method\" \"MyDemoMethod\" {\n  rest_api_id   = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id   = aws_api_gateway_resource.MyDemoResource.id\n  http_method   = \"GET\"\n  authorization = \"NONE\"\n}\n\nresource \"aws_api_gateway_integration\" \"MyDemoIntegration\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id = aws_api_gateway_resource.MyDemoResource.id\n  http_method = aws_api_gateway_method.MyDemoMethod.http_method\n  type        = \"MOCK\"\n}\n\nresource \"aws_api_gateway_method_response\" \"response_200\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  resource_id = aws_api_gateway_resource.MyDemoResource.id\n  http_method = aws_api_gateway_method.MyDemoMethod.http_method\n  status_code = \"200\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the associated REST API\n* `resource_id` - (Required) The API resource ID\n* `http_method` - (Required) The HTTP Method (`GET`, `POST`, `PUT`, `DELETE`, `HEAD`, `OPTIONS`, `ANY`)\n* `status_code` - (Required) The HTTP status code\n* `response_models` - (Optional) A map of the API models used for the response's content type\n* `response_parameters` - (Optional) A map of response parameters that can be sent to the caller.\n   For example: `response_parameters = { \"method.response.header.X-Some-Header\" = true }`\n   would define that the header `X-Some-Header` can be provided on the response.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_api_gateway_method_response` can be imported using `REST-API-ID/RESOURCE-ID/HTTP-METHOD/STATUS-CODE`, e.g.,\n\n```\n$ terraform import aws_api_gateway_method_response.example 12345abcde/67890fghij/GET/200\n```\n",
    "basename": "api_gateway_method_response.html"
  },
  "api_gateway_method_settings.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_method_settings",
    "description": "Manages API Gateway Stage Method Settings",
    "preview": "# Resource: aws_api_gateway_method_settings\n\nManages API Gateway …",
    "content": "\n\n# Resource: aws_api_gateway_method_settings\n\nManages API Gateway Stage Method Settings. For example, CloudWatch logging and metrics.\n\n~> **NOTE:** It is recommended to use this resource in conjunction with the [`aws_api_gateway_stage` resource](api_gateway_stage.html) instead of a stage managed by the [`aws_api_gateway_deployment` resource](api_gateway_deployment.html) optional `stage_name` argument. Stages managed by the `aws_api_gateway_deployment` resource are recreated on redeployment and this resource will require a second apply to recreate the method settings.\n\n## Example Usage\n\nAn end-to-end example of a REST API configured with OpenAPI can be found in the [`/examples/api-gateway-rest-api-openapi` directory within the GitHub repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi).\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = \"example\"\n      version = \"1.0\"\n    }\n    paths = {\n      \"/path1\" = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n\nresource \"aws_api_gateway_method_settings\" \"all\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  stage_name  = aws_api_gateway_stage.example.stage_name\n  method_path = \"*/*\"\n\n  settings {\n    metrics_enabled = true\n    logging_level   = \"ERROR\"\n  }\n}\n\nresource \"aws_api_gateway_method_settings\" \"path_specific\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  stage_name  = aws_api_gateway_stage.example.stage_name\n  method_path = \"path1/GET\"\n\n  settings {\n    metrics_enabled = true\n    logging_level   = \"INFO\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the REST API\n* `stage_name` - (Required) The name of the stage\n* `method_path` - (Required) Method path defined as `{resource_path}/{http_method}` for an individual method override, or `*/*` for overriding all methods in the stage. Ensure to trim any leading forward slashes in the path (e.g., `trimprefix(aws_api_gateway_resource.example.path, \"/\")`).\n* `settings` - (Required) The settings block, see below.\n\n### `settings`\n\n* `metrics_enabled` - (Optional) Specifies whether Amazon CloudWatch metrics are enabled for this method.\n* `logging_level` - (Optional) Specifies the logging level for this method, which effects the log entries pushed to Amazon CloudWatch Logs. The available levels are `OFF`, `ERROR`, and `INFO`.\n* `data_trace_enabled` - (Optional) Specifies whether data trace logging is enabled for this method, which effects the log entries pushed to Amazon CloudWatch Logs.\n* `throttling_burst_limit` - (Optional) Specifies the throttling burst limit. Default: `-1` (throttling disabled).\n* `throttling_rate_limit` - (Optional) Specifies the throttling rate limit. Default: `-1` (throttling disabled).\n* `caching_enabled` - (Optional) Specifies whether responses should be cached and returned for requests. A cache cluster must be enabled on the stage for responses to be cached.\n* `cache_ttl_in_seconds` - (Optional) Specifies the time to live (TTL), in seconds, for cached responses. The higher the TTL, the longer the response will be cached.\n* `cache_data_encrypted` - (Optional) Specifies whether the cached responses are encrypted.\n* `require_authorization_for_cache_control` - (Optional) Specifies whether authorization is required for a cache invalidation request.\n* `unauthorized_cache_control_header_strategy` - (Optional) Specifies how to handle unauthorized requests for cache invalidation. The available values are `FAIL_WITH_403`, `SUCCEED_WITH_RESPONSE_HEADER`, `SUCCEED_WITHOUT_RESPONSE_HEADER`.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_api_gateway_method_settings` can be imported using `REST-API-ID/STAGE-NAME/METHOD-PATH`, e.g.,\n\n```\n$ terraform import aws_api_gateway_method_settings.example 12345abcde/example/test/GET\n```\n",
    "basename": "api_gateway_method_settings.html"
  },
  "api_gateway_model.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_model",
    "description": "Provides a Model for a REST API Gateway.",
    "preview": "# Resource: aws_api_gateway_model\n\nProvides a Model for a REST API …",
    "content": "\n\n# Resource: aws_api_gateway_model\n\nProvides a Model for a REST API Gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"MyDemoAPI\" {\n  name        = \"MyDemoAPI\"\n  description = \"This is my API for demonstration purposes\"\n}\n\nresource \"aws_api_gateway_model\" \"MyDemoModel\" {\n  rest_api_id  = aws_api_gateway_rest_api.MyDemoAPI.id\n  name         = \"user\"\n  description  = \"a JSON schema\"\n  content_type = \"application/json\"\n\n  schema = <<EOF\n{\n  \"type\": \"object\"\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the associated REST API\n* `name` - (Required) The name of the model\n* `description` - (Optional) The description of the model\n* `content_type` - (Required) The content type of the model\n* `schema` - (Required) The schema of the model in a JSON form\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the model\n\n## Import\n\n`aws_api_gateway_model` can be imported using `REST-API-ID/NAME`, e.g.,\n\n```\n$ terraform import aws_api_gateway_model.example 12345abcde/example\n```\n",
    "basename": "api_gateway_model.html"
  },
  "api_gateway_request_validator.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_request_validator",
    "description": "Manages an API Gateway Request Validator.",
    "preview": "# Resource: aws_api_gateway_request_validator\n\nManages an API …",
    "content": "\n\n# Resource: aws_api_gateway_request_validator\n\nManages an API Gateway Request Validator.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_request_validator\" \"example\" {\n  name                        = \"example\"\n  rest_api_id                 = aws_api_gateway_rest_api.example.id\n  validate_request_body       = true\n  validate_request_parameters = true\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `name` - (Required) The name of the request validator\n* `rest_api_id` - (Required) The ID of the associated Rest API\n* `validate_request_body` - (Optional) Boolean whether to validate request body. Defaults to `false`.\n* `validate_request_parameters` - (Optional) Boolean whether to validate request parameters. Defaults to `false`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique ID of the request validator\n\n## Import\n\n`aws_api_gateway_request_validator` can be imported using `REST-API-ID/REQUEST-VALIDATOR-ID`, e.g.,\n\n```\n$ terraform import aws_api_gateway_request_validator.example 12345abcde/67890fghij\n```\n",
    "basename": "api_gateway_request_validator.html"
  },
  "api_gateway_resource.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_resource",
    "description": "Provides an API Gateway Resource.",
    "preview": "# Resource: aws_api_gateway_resource\n\nProvides an API Gateway …",
    "content": "\n\n# Resource: aws_api_gateway_resource\n\nProvides an API Gateway Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"MyDemoAPI\" {\n  name        = \"MyDemoAPI\"\n  description = \"This is my API for demonstration purposes\"\n}\n\nresource \"aws_api_gateway_resource\" \"MyDemoResource\" {\n  rest_api_id = aws_api_gateway_rest_api.MyDemoAPI.id\n  parent_id   = aws_api_gateway_rest_api.MyDemoAPI.root_resource_id\n  path_part   = \"mydemoresource\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the associated REST API\n* `parent_id` - (Required) The ID of the parent API resource\n* `path_part` - (Required) The last path segment of this API resource.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The resource's identifier.\n* `path` - The complete path for this API resource, including all parent paths.\n\n## Import\n\n`aws_api_gateway_resource` can be imported using `REST-API-ID/RESOURCE-ID`, e.g.,\n\n```\n$ terraform import aws_api_gateway_resource.example 12345abcde/67890fghij\n```\n",
    "basename": "api_gateway_resource.html"
  },
  "api_gateway_rest_api.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_rest_api",
    "description": "Manages an API Gateway REST API.",
    "preview": "# Resource: aws_api_gateway_rest_api\n\nManages an API Gateway REST …",
    "content": "\n\n# Resource: aws_api_gateway_rest_api\n\nManages an API Gateway REST API. The REST API can be configured via [importing an OpenAPI specification](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-import-api.html) in the `body` argument (with other arguments serving as overrides) or via other Terraform resources to manage the resources ([`aws_api_gateway_resource` resource](api_gateway_resource.html)), methods ([`aws_api_gateway_method` resource](api_gateway_method.html)), integrations ([`aws_api_gateway_integration` resource](api_gateway_integration.html)), etc. of the REST API. Once the REST API is configured, the [`aws_api_gateway_deployment` resource](api_gateway_deployment.html) can be used along with the [`aws_api_gateway_stage` resource](api_gateway_stage.html) to publish the REST API.\n\n-> **Note:** Amazon API Gateway Version 1 resources are used for creating and deploying REST APIs. To create and deploy WebSocket and HTTP APIs, use Amazon API Gateway Version 2 [resources](/docs/providers/aws/r/apigatewayv2_api.html).\n\n## Example Usage\n\n### OpenAPI Specification\n\nAn end-to-end example of a REST API configured with OpenAPI can be found in the [`/examples/api-gateway-rest-api-openapi` directory within the GitHub repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi).\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = \"example\"\n      version = \"1.0\"\n    }\n    paths = {\n      \"/path1\" = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = \"example\"\n\n  endpoint_configuration {\n    types = [\"REGIONAL\"]\n  }\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n```\n\n### Terraform Resources\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_resource\" \"example\" {\n  parent_id   = aws_api_gateway_rest_api.example.root_resource_id\n  path_part   = \"example\"\n  rest_api_id = aws_api_gateway_rest_api.example.id\n}\n\nresource \"aws_api_gateway_method\" \"example\" {\n  authorization = \"NONE\"\n  http_method   = \"GET\"\n  resource_id   = aws_api_gateway_resource.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n}\n\nresource \"aws_api_gateway_integration\" \"example\" {\n  http_method = aws_api_gateway_method.example.http_method\n  resource_id = aws_api_gateway_resource.example.id\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  type        = \"MOCK\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    # NOTE: The configuration below will satisfy ordering considerations,\n    #       but not pick up all future REST API changes. More advanced patterns\n    #       are possible, such as using the filesha1() function against the\n    #       Terraform configuration file(s) or removing the .id references to\n    #       calculate a hash against whole resources. Be aware that using whole\n    #       resources will show a difference after the initial implementation.\n    #       It will stabilize to only change when resources change afterwards.\n    redeployment = sha1(jsonencode([\n      aws_api_gateway_resource.example.id,\n      aws_api_gateway_method.example.id,\n      aws_api_gateway_integration.example.id,\n    ]))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the REST API. If importing an OpenAPI specification via the `body` argument, this corresponds to the `info.title` field. If the argument value is different than the OpenAPI value, the argument value will override the OpenAPI value.\n* `description` - (Optional) Description of the REST API. If importing an OpenAPI specification via the `body` argument, this corresponds to the `info.description` field. If the argument value is provided and is different than the OpenAPI value, the argument value will override the OpenAPI value.\n* `endpoint_configuration` - (Optional) Configuration block defining API endpoint configuration including endpoint type. Defined below.\n* `binary_media_types` - (Optional) List of binary media types supported by the REST API. By default, the REST API supports only UTF-8-encoded text payloads. If importing an OpenAPI specification via the `body` argument, this corresponds to the [`x-amazon-apigateway-binary-media-types` extension](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-swagger-extensions-binary-media-types.html). If the argument value is provided and is different than the OpenAPI value, the argument value will override the OpenAPI value.\n* `minimum_compression_size` - (Optional) Minimum response size to compress for the REST API. Integer between `-1` and `10485760` (10MB). Setting a value greater than `-1` will enable compression, `-1` disables compression (default). If importing an OpenAPI specification via the `body` argument, this corresponds to the [`x-amazon-apigateway-minimum-compression-size` extension](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-openapi-minimum-compression-size.html). If the argument value (_except_ `-1`) is provided and is different than the OpenAPI value, the argument value will override the OpenAPI value.\n* `body` - (Optional) OpenAPI specification that defines the set of routes and integrations to create as part of the REST API. This configuration, and any updates to it, will replace all REST API configuration except values overridden in this resource configuration and other resource updates applied after this resource but before any `aws_api_gateway_deployment` creation. More information about REST API OpenAPI support can be found in the [API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-import-api.html).\n* `parameters` - (Optional) Map of customizations for importing the specification in the `body` argument. For example, to exclude DocumentationParts from an imported API, set `ignore` equal to `documentation`. Additional documentation, including other parameters such as `basepath`, can be found in the [API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-import-api.html).\n* `policy` - (Optional) JSON formatted policy document that controls access to the API Gateway. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy). Terraform will only perform drift detection of its value when present in a configuration. It is recommended to use the [`aws_api_gateway_rest_api_policy` resource](/docs/providers/aws/r/api_gateway_rest_api_policy.html) instead. If importing an OpenAPI specification via the `body` argument, this corresponds to the [`x-amazon-apigateway-policy` extension](https://docs.aws.amazon.com/apigateway/latest/developerguide/openapi-extensions-policy.html). If the argument value is provided and is different than the OpenAPI value, the argument value will override the OpenAPI value.\n* `api_key_source` - (Optional) Source of the API key for requests. Valid values are `HEADER` (default) and `AUTHORIZER`. If importing an OpenAPI specification via the `body` argument, this corresponds to the [`x-amazon-apigateway-api-key-source` extension](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-swagger-extensions-api-key-source.html). If the argument value is provided and is different than the OpenAPI value, the argument value will override the OpenAPI value.\n* `disable_execute_api_endpoint` - (Optional) Specifies whether clients can invoke your API by using the default execute-api endpoint. By default, clients can invoke your API with the default https://{api_id}.execute-api.{region}.amazonaws.com endpoint. To require that clients use a custom domain name to invoke your API, disable the default endpoint. Defaults to `false`. If importing an OpenAPI specification via the `body` argument, this corresponds to the [`x-amazon-apigateway-endpoint-configuration` extension `disableExecuteApiEndpoint` property](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-swagger-extensions-endpoint-configuration.html). If the argument value is `true` and is different than the OpenAPI value, the argument value will override the OpenAPI value.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n__Note__: If the `body` argument is provided, the OpenAPI specification will be used to configure the resources, methods and integrations for the Rest API. If this argument is provided, the following resources should not be managed as separate ones, as updates may cause manual resource updates to be overwritten:\n\n* `aws_api_gateway_resource`\n* `aws_api_gateway_method`\n* `aws_api_gateway_method_response`\n* `aws_api_gateway_method_settings`\n* `aws_api_gateway_integration`\n* `aws_api_gateway_integration_response`\n* `aws_api_gateway_gateway_response`\n* `aws_api_gateway_model`\n\n### endpoint_configuration\n\n* `types` - (Required) A list of endpoint types. This resource currently only supports managing a single value. Valid values: `EDGE`, `REGIONAL` or `PRIVATE`. If unspecified, defaults to `EDGE`. Must be declared as `REGIONAL` in non-Commercial partitions. Refer to the [documentation](https://docs.aws.amazon.com/apigateway/latest/developerguide/create-regional-api.html) for more information on the difference between edge-optimized and regional APIs.\n* `vpc_endpoint_ids` - (Optional) Set of VPC Endpoint identifiers. It is only supported for `PRIVATE` endpoint type. If importing an OpenAPI specification via the `body` argument, this corresponds to the [`x-amazon-apigateway-endpoint-configuration` extension `vpcEndpointIds` property](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-swagger-extensions-endpoint-configuration.html). If the argument value is provided and is different than the OpenAPI value, the argument value will override the OpenAPI value.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the REST API\n* `root_resource_id` - The resource ID of the REST API's root\n* `created_date` - The creation date of the REST API\n* `execution_arn` - The execution ARN part to be used in [`lambda_permission`](/docs/providers/aws/r/lambda_permission.html)'s `source_arn`\n  when allowing API Gateway to invoke a Lambda function,\n  e.g., `arn:aws:execute-api:eu-west-2:123456789012:z4675bid1j`, which can be concatenated with allowed stage, method and resource path.\n* `arn` - Amazon Resource Name (ARN)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_api_gateway_rest_api` can be imported by using the REST API ID, e.g.,\n\n```\n$ terraform import aws_api_gateway_rest_api.example 12345abcde\n```\n\n~> **NOTE:** Resource import does not currently support the `body` attribute.\n",
    "basename": "api_gateway_rest_api.html"
  },
  "api_gateway_rest_api_policy.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_rest_api_policy",
    "description": "Provides an API Gateway REST API Policy.",
    "preview": "# Resource: aws_api_gateway_rest_api_policy\n\nProvides an API Gateway …",
    "content": "\n\n# Resource: aws_api_gateway_rest_api_policy\n\nProvides an API Gateway REST API Policy.\n\n-> **Note:** Amazon API Gateway Version 1 resources are used for creating and deploying REST APIs. To create and deploy WebSocket and HTTP APIs, use Amazon API Gateway Version 2 [resources](/docs/providers/aws/r/apigatewayv2_api.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"test\" {\n  name = \"example-rest-api\"\n}\n\nresource \"aws_api_gateway_rest_api_policy\" \"test\" {\n  rest_api_id = aws_api_gateway_rest_api.test.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"\n      },\n      \"Action\": \"execute-api:Invoke\",\n      \"Resource\": \"${aws_api_gateway_rest_api.test.execution_arn}\",\n      \"Condition\": {\n        \"IpAddress\": {\n          \"aws:SourceIp\": \"123.123.123.123/32\"\n        }\n      }\n    }\n  ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the REST API.\n* `policy` - (Required) JSON formatted policy document that controls access to the API Gateway. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the REST API\n\n## Import\n\n`aws_api_gateway_rest_api_policy` can be imported by using the REST API ID, e.g.,\n\n```\n$ terraform import aws_api_gateway_rest_api_policy.example 12345abcde\n```\n",
    "basename": "api_gateway_rest_api_policy.html"
  },
  "api_gateway_stage.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_stage",
    "description": "Manages an API Gateway Stage.",
    "preview": "# Resource: aws_api_gateway_stage\n\nManages an API Gateway Stage. A …",
    "content": "\n\n# Resource: aws_api_gateway_stage\n\nManages an API Gateway Stage. A stage is a named reference to a deployment, which can be done via the [`aws_api_gateway_deployment` resource](api_gateway_deployment.html). Stages can be optionally managed further with the [`aws_api_gateway_base_path_mapping` resource](api_gateway_base_path_mapping.html), [`aws_api_gateway_domain_name` resource](api_gateway_domain_name.html), and [`aws_api_method_settings` resource](api_gateway_method_settings.html). For more information, see the [API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-stages.html).\n\n## Example Usage\n\nAn end-to-end example of a REST API configured with OpenAPI can be found in the [`/examples/api-gateway-rest-api-openapi` directory within the GitHub repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi).\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = \"example\"\n      version = \"1.0\"\n    }\n    paths = {\n      \"/path1\" = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n\nresource \"aws_api_gateway_method_settings\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  stage_name  = aws_api_gateway_stage.example.stage_name\n  method_path = \"*/*\"\n\n  settings {\n    metrics_enabled = true\n    logging_level   = \"INFO\"\n  }\n}\n```\n\n### Managing the API Logging CloudWatch Log Group\n\nAPI Gateway provides the ability to [enable CloudWatch API logging](https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html). To manage the CloudWatch Log Group when this feature is enabled, the [`aws_cloudwatch_log_group` resource](/docs/providers/aws/r/cloudwatch_log_group.html) can be used where the name matches the API Gateway naming convention. If the CloudWatch Log Group previously exists, the [`aws_cloudwatch_log_group` resource can be imported into Terraform](/docs/providers/aws/r/cloudwatch_log_group.html#import) as a one time operation and recreation of the environment can occur without import.\n\n-> The below configuration uses [`depends_on`](https://www.terraform.io/docs/configuration/meta-arguments/depends_on.html) to prevent ordering issues with API Gateway automatically creating the log group first and a variable for naming consistency. Other ordering and naming methodologies may be more appropriate for your environment.\n\n```terraform\nvariable \"stage_name\" {\n  default = \"example\"\n  type    = string\n}\n\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  # ... other configuration ...\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  depends_on = [aws_cloudwatch_log_group.example]\n\n  stage_name = var.stage_name\n  # ... other configuration ...\n}\n\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name              = \"API-Gateway-Execution-Logs_${aws_api_gateway_rest_api.example.id}/${var.stage_name}\"\n  retention_in_days = 7\n  # ... potentially other configuration ...\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rest_api_id` - (Required) The ID of the associated REST API\n* `stage_name` - (Required) The name of the stage\n* `deployment_id` - (Required) The ID of the deployment that the stage points to\n* `access_log_settings` - (Optional) Enables access logs for the API stage. Detailed below.\n* `cache_cluster_enabled` - (Optional) Specifies whether a cache cluster is enabled for the stage\n* `cache_cluster_size` - (Optional) The size of the cache cluster for the stage, if enabled. Allowed values include `0.5`, `1.6`, `6.1`, `13.5`, `28.4`, `58.2`, `118` and `237`.\n* `client_certificate_id` - (Optional) The identifier of a client certificate for the stage.\n* `description` - (Optional) The description of the stage\n* `documentation_version` - (Optional) The version of the associated API documentation\n* `variables` - (Optional) A map that defines the stage variables\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `xray_tracing_enabled` - (Optional) Whether active tracing with X-ray is enabled. Defaults to `false`.\n\n### Nested Blocks\n\n#### `access_log_settings`\n\n* `destination_arn` - (Required) The Amazon Resource Name (ARN) of the CloudWatch Logs log group or Kinesis Data Firehose delivery stream to receive access logs. If you specify a Kinesis Data Firehose delivery stream, the stream name must begin with `amazon-apigateway-`. Automatically removes trailing `:*` if present.\n* `format` - (Required) The formatting and values recorded in the logs.\nFor more information on configuring the log format rules visit the AWS [documentation](https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN)\n* `id` - The ID of the stage\n* `invoke_url` - The URL to invoke the API pointing to the stage,\n  e.g., `https://z4675bid1j.execute-api.eu-west-2.amazonaws.com/prod`\n* `execution_arn` - The execution ARN to be used in [`lambda_permission`](/docs/providers/aws/r/lambda_permission.html)'s `source_arn`\n  when allowing API Gateway to invoke a Lambda function,\n  e.g., `arn:aws:execute-api:eu-west-2:123456789012:z4675bid1j/prod`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_api_gateway_stage` can be imported using `REST-API-ID/STAGE-NAME`, e.g.,\n\n```\n$ terraform import aws_api_gateway_stage.example 12345abcde/example\n```\n",
    "basename": "api_gateway_stage.html"
  },
  "api_gateway_usage_plan.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_usage_plan",
    "description": "Provides an API Gateway Usage Plan.",
    "preview": "# Resource: aws_api_gateway_usage_plan\n\nProvides an API Gateway …",
    "content": "\n\n# Resource: aws_api_gateway_usage_plan\n\nProvides an API Gateway Usage Plan.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = \"example\"\n      version = \"1.0\"\n    }\n    paths = {\n      \"/path1\" = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"development\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"development\"\n}\n\nresource \"aws_api_gateway_stage\" \"production\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"production\"\n}\n\nresource \"aws_api_gateway_usage_plan\" \"example\" {\n  name         = \"my-usage-plan\"\n  description  = \"my description\"\n  product_code = \"MYCODE\"\n\n  api_stages {\n    api_id = aws_api_gateway_rest_api.example.id\n    stage  = aws_api_gateway_stage.development.stage_name\n  }\n\n  api_stages {\n    api_id = aws_api_gateway_rest_api.example.id\n    stage  = aws_api_gateway_stage.production.stage_name\n  }\n\n  quota_settings {\n    limit  = 20\n    offset = 2\n    period = \"WEEK\"\n  }\n\n  throttle_settings {\n    burst_limit = 5\n    rate_limit  = 10\n  }\n}\n```\n\n## Argument Reference\n\nThe API Gateway Usage Plan argument layout is a structure composed of several sub-resources - these resources are laid out below.\n\n### Top-Level Arguments\n\n* `name` - (Required) The name of the usage plan.\n* `description` - (Optional) The description of a usage plan.\n* `api_stages` - (Optional) The associated [API stages](#api-stages-arguments) of the usage plan.\n* `quota_settings` - (Optional) The [quota settings](#quota-settings-arguments) of the usage plan.\n* `throttle_settings` - (Optional) The [throttling limits](#throttling-settings-arguments) of the usage plan.\n* `product_code` - (Optional) The AWS Marketplace product identifier to associate with the usage plan as a SaaS product on AWS Marketplace.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n#### Api Stages arguments\n\n* `api_id` (Required) - API Id of the associated API stage in a usage plan.\n* `stage` (Required) - API stage name of the associated API stage in a usage plan.\n* `throttle` - (Optional) The [throttling limits](#throttle) of the usage plan.\n\n##### Throttle\n\n* `path` (Required) - The method to apply the throttle settings for. Specfiy the path and method, for example `/test/GET`.\n* `burst_limit` (Optional) - The API request burst limit, the maximum rate limit over a time ranging from one to a few seconds, depending upon whether the underlying token bucket is at its full capacity.\n* `rate_limit` (Optional) - The API request steady-state rate limit.\n\n#### Quota Settings Arguments\n\n* `limit` (Optional) - The maximum number of requests that can be made in a given time period.\n* `offset` (Optional) - The number of requests subtracted from the given limit in the initial time period.\n* `period` (Optional) - The time period in which the limit applies. Valid values are \"DAY\", \"WEEK\" or \"MONTH\".\n\n#### Throttling Settings Arguments\n\n* `burst_limit` (Optional) - The API request burst limit, the maximum rate limit over a time ranging from one to a few seconds, depending upon whether the underlying token bucket is at its full capacity.\n* `rate_limit` (Optional) - The API request steady-state rate limit.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the API resource\n* `name` - The name of the usage plan.\n* `description` - The description of a usage plan.\n* `api_stages` - The associated API stages of the usage plan.\n* `quota_settings` - The quota of the usage plan.\n* `throttle_settings` - The throttling limits of the usage plan.\n* `product_code` - The AWS Marketplace product identifier to associate with the usage plan as a SaaS product on AWS Marketplace.\n* `arn` - Amazon Resource Name (ARN)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAWS API Gateway Usage Plan can be imported using the `id`, e.g.,\n\n```sh\n$ terraform import aws_api_gateway_usage_plan.myusageplan <usage_plan_id>\n```\n",
    "basename": "api_gateway_usage_plan.html"
  },
  "api_gateway_usage_plan_key.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_usage_plan_key",
    "description": "Provides an API Gateway Usage Plan Key.",
    "preview": "# Resource: aws_api_gateway_usage_plan_key\n\nProvides an API Gateway …",
    "content": "\n\n# Resource: aws_api_gateway_usage_plan_key\n\nProvides an API Gateway Usage Plan Key.\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"test\" {\n  name = \"MyDemoAPI\"\n}\n\n# ...\n\nresource \"aws_api_gateway_usage_plan\" \"myusageplan\" {\n  name = \"my_usage_plan\"\n\n  api_stages {\n    api_id = aws_api_gateway_rest_api.test.id\n    stage  = aws_api_gateway_deployment.foo.stage_name\n  }\n}\n\nresource \"aws_api_gateway_api_key\" \"mykey\" {\n  name = \"my_key\"\n}\n\nresource \"aws_api_gateway_usage_plan_key\" \"main\" {\n  key_id        = aws_api_gateway_api_key.mykey.id\n  key_type      = \"API_KEY\"\n  usage_plan_id = aws_api_gateway_usage_plan.myusageplan.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `key_id` - (Required) The identifier of the API key resource.\n* `key_type` - (Required) The type of the API key resource. Currently, the valid key type is API_KEY.\n* `usage_plan_id` - (Required) The Id of the usage plan resource representing to associate the key to.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Id of a usage plan key.\n* `key_id` - The identifier of the API gateway key resource.\n* `key_type` - The type of a usage plan key. Currently, the valid key type is API_KEY.\n* `usage_plan_id` - The ID of the API resource\n* `name` - The name of a usage plan key.\n* `value` - The value of a usage plan key.\n\n## Import\n\nAWS API Gateway Usage Plan Key can be imported using the `USAGE-PLAN-ID/USAGE-PLAN-KEY-ID`, e.g.,\n\n```sh\n$ terraform import aws_api_gateway_usage_plan_key.key 12345abcde/zzz\n```\n",
    "basename": "api_gateway_usage_plan_key.html"
  },
  "api_gateway_vpc_link.html": {
    "subcategory": "API Gateway (REST APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_api_gateway_vpc_link",
    "description": "Provides an API Gateway VPC Link.",
    "preview": "# Resource: aws_api_gateway_vpc_link\n\nProvides an API Gateway VPC …",
    "content": "\n\n# Resource: aws_api_gateway_vpc_link\n\nProvides an API Gateway VPC Link.\n\n-> **Note:** Amazon API Gateway Version 1 VPC Links enable private integrations that connect REST APIs to private resources in a VPC.\nTo enable private integration for HTTP APIs, use the Amazon API Gateway Version 2 VPC Link [resource](/docs/providers/aws/r/apigatewayv2_vpc_link.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_lb\" \"example\" {\n  name               = \"example\"\n  internal           = true\n  load_balancer_type = \"network\"\n\n  subnet_mapping {\n    subnet_id = \"12345\"\n  }\n}\n\nresource \"aws_api_gateway_vpc_link\" \"example\" {\n  name        = \"example\"\n  description = \"example description\"\n  target_arns = [aws_lb.example.arn]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name used to label and identify the VPC link.\n* `description` - (Optional) The description of the VPC link.\n* `target_arns` - (Required, ForceNew) The list of network load balancer arns in the VPC targeted by the VPC link. Currently AWS only supports 1 target.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identifier of the VpcLink.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAPI Gateway VPC Link can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_api_gateway_vpc_link.example <vpc_link_id>\n```\n",
    "basename": "api_gateway_vpc_link.html"
  },
  "apigatewayv2_api.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_api",
    "description": "Manages an Amazon API Gateway Version 2 API.",
    "preview": "# Resource: aws_apigatewayv2_api\n\nManages an Amazon API Gateway …",
    "content": "\n\n# Resource: aws_apigatewayv2_api\n\nManages an Amazon API Gateway Version 2 API.\n\n-> **Note:** Amazon API Gateway Version 2 resources are used for creating and deploying WebSocket and HTTP APIs. To create and deploy REST APIs, use Amazon API Gateway Version 1 [resources](/docs/providers/aws/r/api_gateway_rest_api.html).\n\n## Example Usage\n\n### Basic WebSocket API\n\n```terraform\nresource \"aws_apigatewayv2_api\" \"example\" {\n  name                       = \"example-websocket-api\"\n  protocol_type              = \"WEBSOCKET\"\n  route_selection_expression = \"$request.body.action\"\n}\n```\n\n### Basic HTTP API\n\n```terraform\nresource \"aws_apigatewayv2_api\" \"example\" {\n  name          = \"example-http-api\"\n  protocol_type = \"HTTP\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the API. Must be less than or equal to 128 characters in length.\n* `protocol_type` - (Required) The API protocol. Valid values: `HTTP`, `WEBSOCKET`.\n* `api_key_selection_expression` - (Optional) An [API key selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-apikey-selection-expressions).\nValid values: `$context.authorizer.usageIdentifierKey`, `$request.header.x-api-key`. Defaults to `$request.header.x-api-key`.\nApplicable for WebSocket APIs.\n* `cors_configuration` - (Optional) The cross-origin resource sharing (CORS) [configuration](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-cors.html). Applicable for HTTP APIs.\n* `credentials_arn` - (Optional) Part of _quick create_. Specifies any credentials required for the integration. Applicable for HTTP APIs.\n* `description` - (Optional) The description of the API. Must be less than or equal to 1024 characters in length.\n* `disable_execute_api_endpoint` - (Optional) Whether clients can invoke the API by using the default `execute-api` endpoint.\nBy default, clients can invoke the API with the default `{api_id}.execute-api.{region}.amazonaws.com endpoint`.\nTo require that clients use a custom domain name to invoke the API, disable the default endpoint.\n* `route_key` - (Optional) Part of _quick create_. Specifies any [route key](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-routes.html). Applicable for HTTP APIs.\n* `route_selection_expression` - (Optional) The [route selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-route-selection-expressions) for the API.\nDefaults to `$request.method $request.path`.\n* `tags` - (Optional) A map of tags to assign to the API. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `target` - (Optional) Part of _quick create_. Quick create produces an API with an integration, a default catch-all route, and a default stage which is configured to automatically deploy changes.\nFor HTTP integrations, specify a fully qualified URL. For Lambda integrations, specify a function ARN.\nThe type of the integration will be `HTTP_PROXY` or `AWS_PROXY`, respectively. Applicable for HTTP APIs.\n* `body` - (Optional) An OpenAPI specification that defines the set of routes and integrations to create as part of the HTTP APIs. Supported only for HTTP APIs.\n* `version` - (Optional) A version identifier for the API. Must be between 1 and 64 characters in length.\n* `fail_on_warnings` - (Optional) Whether warnings should return an error while API Gateway is creating or updating the resource using an OpenAPI specification. Defaults to `false`. Applicable for HTTP APIs.\n\n__Note__: If the `body` argument is provided, the OpenAPI specification will be used to configure the integrations and route for the HTTP API. If this argument is provided, the following resources should not be managed as separate ones, as updates may cause manual resource updates to be overwritten:\n\n* `aws_apigatewayv2_integration`\n* `aws_apigatewayv2_route`\n\nFurther more, the `name`, `description`, `cors_configuration`, `tags` and `version` fields should be specified in the Terraform configuration and the values will override any values specified in the OpenAPI document.\n\nThe `cors_configuration` object supports the following:\n\n* `allow_credentials` - (Optional) Whether credentials are included in the CORS request.\n* `allow_headers` - (Optional) The set of allowed HTTP headers.\n* `allow_methods` - (Optional) The set of allowed HTTP methods.\n* `allow_origins` - (Optional) The set of allowed origins.\n* `expose_headers` - (Optional) The set of exposed HTTP headers.\n* `max_age` - (Optional) The number of seconds that the browser should cache preflight request results.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The API identifier.\n* `api_endpoint` - The URI of the API, of the form `https://{api-id}.execute-api.{region}.amazonaws.com` for HTTP APIs and `wss://{api-id}.execute-api.{region}.amazonaws.com` for WebSocket APIs.\n* `arn` - The ARN of the API.\n* `execution_arn` - The ARN prefix to be used in an [`aws_lambda_permission`](/docs/providers/aws/r/lambda_permission.html)'s `source_arn` attribute\nor in an [`aws_iam_policy`](/docs/providers/aws/r/iam_policy.html) to authorize access to the [`@connections` API](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html).\nSee the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-control-access-iam.html) for details.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_apigatewayv2_api` can be imported by using the API identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_api.example aabbccddee\n```\n",
    "basename": "apigatewayv2_api.html"
  },
  "apigatewayv2_api_mapping.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_api_mapping",
    "description": "Manages an Amazon API Gateway Version 2 API mapping.",
    "preview": "# Resource: aws_apigatewayv2_api_mapping\n\nManages an Amazon API …",
    "content": "\n\n# Resource: aws_apigatewayv2_api_mapping\n\nManages an Amazon API Gateway Version 2 API mapping.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_api_mapping\" \"example\" {\n  api_id      = aws_apigatewayv2_api.example.id\n  domain_name = aws_apigatewayv2_domain_name.example.id\n  stage       = aws_apigatewayv2_stage.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `domain_name` - (Required) The domain name. Use the [`aws_apigatewayv2_domain_name`](/docs/providers/aws/r/apigatewayv2_domain_name.html) resource to configure a domain name.\n* `stage` - (Required) The API stage. Use the [`aws_apigatewayv2_stage`](/docs/providers/aws/r/apigatewayv2_stage.html) resource to configure an API stage.\n* `api_mapping_key` - (Optional) The [API mapping key](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-mapping-template-reference.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The API mapping identifier.\n\n## Import\n\n`aws_apigatewayv2_api_mapping` can be imported by using the API mapping identifier and domain name, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_api_mapping.example 1122334/ws-api.example.com\n```\n",
    "basename": "apigatewayv2_api_mapping.html"
  },
  "apigatewayv2_authorizer.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_authorizer",
    "description": "Manages an Amazon API Gateway Version 2 authorizer.",
    "preview": "# Resource: aws_apigatewayv2_authorizer\n\nManages an Amazon API …",
    "content": "\n\n# Resource: aws_apigatewayv2_authorizer\n\nManages an Amazon API Gateway Version 2 authorizer.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html).\n\n## Example Usage\n\n### Basic WebSocket API\n\n```terraform\nresource \"aws_apigatewayv2_authorizer\" \"example\" {\n  api_id           = aws_apigatewayv2_api.example.id\n  authorizer_type  = \"REQUEST\"\n  authorizer_uri   = aws_lambda_function.example.invoke_arn\n  identity_sources = [\"route.request.header.Auth\"]\n  name             = \"example-authorizer\"\n}\n```\n\n### Basic HTTP API\n\n```terraform\nresource \"aws_apigatewayv2_authorizer\" \"example\" {\n  api_id           = aws_apigatewayv2_api.example.id\n  authorizer_type  = \"JWT\"\n  identity_sources = [\"$request.header.Authorization\"]\n  name             = \"example-authorizer\"\n\n  jwt_configuration {\n    audience = [\"example\"]\n    issuer   = \"https://${aws_cognito_user_pool.example.endpoint}\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `authorizer_type` - (Required) The authorizer type. Valid values: `JWT`, `REQUEST`.\nSpecify `REQUEST` for a Lambda function using incoming request parameters.\nFor HTTP APIs, specify `JWT` to use JSON Web Tokens.\n* `name` - (Required) The name of the authorizer. Must be between 1 and 128 characters in length.\n* `authorizer_credentials_arn` - (Optional) The required credentials as an IAM role for API Gateway to invoke the authorizer.\nSupported only for `REQUEST` authorizers.\n* `authorizer_payload_format_version` - (Optional) The format of the payload sent to an HTTP API Lambda authorizer. Required for HTTP API Lambda authorizers.\nValid values: `1.0`, `2.0`.\n* `authorizer_result_ttl_in_seconds` - (Optional) The time to live (TTL) for cached authorizer results, in seconds. If it equals 0, authorization caching is disabled.\nIf it is greater than 0, API Gateway caches authorizer responses. The maximum value is 3600, or 1 hour. Defaults to `300`.\nSupported only for HTTP API Lambda authorizers.\n* `authorizer_uri` - (Optional) The authorizer's Uniform Resource Identifier (URI).\nFor `REQUEST` authorizers this must be a well-formed Lambda function URI, such as the `invoke_arn` attribute of the [`aws_lambda_function`](/docs/providers/aws/r/lambda_function.html) resource.\nSupported only for `REQUEST` authorizers. Must be between 1 and 2048 characters in length.\n* `enable_simple_responses` - (Optional) Whether a Lambda authorizer returns a response in a simple format. If enabled, the Lambda authorizer can return a boolean value instead of an IAM policy.\nSupported only for HTTP APIs.\n* `identity_sources` - (Optional) The identity sources for which authorization is requested.\nFor `REQUEST` authorizers the value is a list of one or more mapping expressions of the specified request parameters.\nFor `JWT` authorizers the single entry specifies where to extract the JSON Web Token (JWT) from inbound requests.\n* `jwt_configuration` - (Optional) The configuration of a JWT authorizer. Required for the `JWT` authorizer type.\nSupported only for HTTP APIs.\n\nThe `jwt_configuration` object supports the following:\n\n* `audience` - (Optional) A list of the intended recipients of the JWT. A valid JWT must provide an aud that matches at least one entry in this list.\n* `issuer` - (Optional) The base domain of the identity provider that issues JSON Web Tokens, such as the `endpoint` attribute of the [`aws_cognito_user_pool`](/docs/providers/aws/r/cognito_user_pool.html) resource.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The authorizer identifier.\n\n## Import\n\n`aws_apigatewayv2_authorizer` can be imported by using the API identifier and authorizer identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_authorizer.example aabbccddee/1122334\n```\n",
    "basename": "apigatewayv2_authorizer.html"
  },
  "apigatewayv2_deployment.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_deployment",
    "description": "Manages an Amazon API Gateway Version 2 deployment.",
    "preview": "# Resource: aws_apigatewayv2_deployment\n\nManages an Amazon API …",
    "content": "\n\n# Resource: aws_apigatewayv2_deployment\n\nManages an Amazon API Gateway Version 2 deployment.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html).\n\n-> **Note:** Creating a deployment for an API requires at least one `aws_apigatewayv2_route` resource associated with that API. To avoid race conditions when all resources are being created together, you need to add implicit resource references via the `triggers` argument or explicit resource references using the [resource `depends_on` meta-argument](https://www.terraform.io/docs/configuration/meta-arguments/depends_on.html).\n\n-> It is recommended to enable the [resource `lifecycle` configuration block `create_before_destroy` argument](https://www.terraform.io/docs/configuration/resources.html#create_before_destroy) in this resource configuration to properly order redeployments in Terraform.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_deployment\" \"example\" {\n  api_id      = aws_apigatewayv2_route.example.api_id\n  description = \"Example deployment\"\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n### Redeployment Triggers\n\n-> **NOTE:** This is an optional and Terraform 0.12 (or later) advanced configuration that shows calculating a hash of the API's Terraform resources to determine changes that should trigger a new deployment. This value will change after the first Terraform apply of new resources, triggering an immediate redeployment, however it will stabilize afterwards except for resource changes. The `triggers` map can also be configured in other, more complex ways to fit the environment, avoiding the immediate redeployment issue.\n\n```terraform\nresource \"aws_apigatewayv2_deployment\" \"example\" {\n  api_id      = aws_apigatewayv2_api.example.id\n  description = \"Example deployment\"\n\n  triggers = {\n    redeployment = sha1(join(\",\", list(\n      jsonencode(aws_apigatewayv2_integration.example),\n      jsonencode(aws_apigatewayv2_route.example),\n    )))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `description` - (Optional) The description for the deployment resource. Must be less than or equal to 1024 characters in length.\n* `triggers` - (Optional) A map of arbitrary keys and values that, when changed, will trigger a redeployment. To force a redeployment without changing these keys/values, use the [`terraform taint` command](https://www.terraform.io/docs/commands/taint.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The deployment identifier.\n* `auto_deployed` - Whether the deployment was automatically released.\n\n## Import\n\n`aws_apigatewayv2_deployment` can be imported by using the API identifier and deployment identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_deployment.example aabbccddee/1122334\n```\n\nThe `triggers` argument cannot be imported.\n",
    "basename": "apigatewayv2_deployment.html"
  },
  "apigatewayv2_domain_name.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_domain_name",
    "description": "Manages an Amazon API Gateway Version 2 domain name.",
    "preview": "# Resource: aws_apigatewayv2_domain_name\n\nManages an Amazon API …",
    "content": "\n\n# Resource: aws_apigatewayv2_domain_name\n\nManages an Amazon API Gateway Version 2 domain name.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html).\n\n-> **Note:** This resource establishes ownership of and the TLS settings for\na particular domain name. An API stage can be associated with the domain name using the `aws_apigatewayv2_api_mapping` resource.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_domain_name\" \"example\" {\n  domain_name = \"ws-api.example.com\"\n\n  domain_name_configuration {\n    certificate_arn = aws_acm_certificate.example.arn\n    endpoint_type   = \"REGIONAL\"\n    security_policy = \"TLS_1_2\"\n  }\n}\n```\n\n### Associated Route 53 Resource Record\n\n```terraform\nresource \"aws_apigatewayv2_domain_name\" \"example\" {\n  domain_name = \"http-api.example.com\"\n\n  domain_name_configuration {\n    certificate_arn = aws_acm_certificate.example.arn\n    endpoint_type   = \"REGIONAL\"\n    security_policy = \"TLS_1_2\"\n  }\n}\n\nresource \"aws_route53_record\" \"example\" {\n  name    = aws_apigatewayv2_domain_name.example.domain_name\n  type    = \"A\"\n  zone_id = aws_route53_zone.example.zone_id\n\n  alias {\n    name                   = aws_apigatewayv2_domain_name.example.domain_name_configuration[0].target_domain_name\n    zone_id                = aws_apigatewayv2_domain_name.example.domain_name_configuration[0].hosted_zone_id\n    evaluate_target_health = false\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Required) The domain name. Must be between 1 and 512 characters in length.\n* `domain_name_configuration` - (Required) The domain name configuration.\n* `mutual_tls_authentication` - (Optional) The mutual TLS authentication configuration for the domain name.\n* `tags` - (Optional) A map of tags to assign to the domain name. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `domain_name_configuration` object supports the following:\n\n* `certificate_arn` - (Required) The ARN of an AWS-managed certificate that will be used by the endpoint for the domain name. AWS Certificate Manager is the only supported source.\nUse the [`aws_acm_certificate`](/docs/providers/aws/r/acm_certificate.html) resource to configure an ACM certificate.\n* `endpoint_type` - (Required) The endpoint type. Valid values: `REGIONAL`.\n* `security_policy` - (Required) The Transport Layer Security (TLS) version of the [security policy](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-custom-domain-tls-version.html) for the domain name. Valid values: `TLS_1_2`.\n* `hosted_zone_id` - (Computed) The Amazon Route 53 Hosted Zone ID of the endpoint.\n* `target_domain_name` - (Computed) The target domain name.\n\nThe `mutual_tls_authentication` object supports the following:\n\n* `truststore_uri` - (Required) An Amazon S3 URL that specifies the truststore for mutual TLS authentication, for example, `s3://bucket-name/key-name`.\nThe truststore can contain certificates from public or private certificate authorities. To update the truststore, upload a new version to S3, and then update your custom domain name to use the new version.\n* `truststore_version` - (Optional) The version of the S3 object that contains the truststore. To specify a version, you must have versioning enabled for the S3 bucket.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The domain name identifier.\n* `api_mapping_selection_expression` - The [API mapping selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-mapping-selection-expressions) for the domain name.\n* `arn` - The ARN of the domain name.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_apigatewayv2_domain_name` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating the domain name\n- `update` - (Default `60 minutes`) Used for updating the domain name\n\n## Import\n\n`aws_apigatewayv2_domain_name` can be imported by using the domain name, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_domain_name.example ws-api.example.com\n```\n",
    "basename": "apigatewayv2_domain_name.html"
  },
  "apigatewayv2_integration.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_integration",
    "description": "Manages an Amazon API Gateway Version 2 integration.",
    "preview": "# Resource: aws_apigatewayv2_integration\n\nManages an Amazon API …",
    "content": "\n\n# Resource: aws_apigatewayv2_integration\n\nManages an Amazon API Gateway Version 2 integration.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_integration\" \"example\" {\n  api_id           = aws_apigatewayv2_api.example.id\n  integration_type = \"MOCK\"\n}\n```\n\n### Lambda Integration\n\n```terraform\nresource \"aws_lambda_function\" \"example\" {\n  filename      = \"example.zip\"\n  function_name = \"Example\"\n  role          = aws_iam_role.example.arn\n  handler       = \"index.handler\"\n  runtime       = \"nodejs12.x\"\n}\n\nresource \"aws_apigatewayv2_integration\" \"example\" {\n  api_id           = aws_apigatewayv2_api.example.id\n  integration_type = \"AWS\"\n\n  connection_type           = \"INTERNET\"\n  content_handling_strategy = \"CONVERT_TO_TEXT\"\n  description               = \"Lambda example\"\n  integration_method        = \"POST\"\n  integration_uri           = aws_lambda_function.example.invoke_arn\n  passthrough_behavior      = \"WHEN_NO_MATCH\"\n}\n```\n\n### AWS Service Integration\n\n```terraform\nresource \"aws_apigatewayv2_integration\" \"example\" {\n  api_id              = aws_apigatewayv2_api.example.id\n  credentials_arn     = aws_iam_role.example.arn\n  description         = \"SQS example\"\n  integration_type    = \"AWS_PROXY\"\n  integration_subtype = \"SQS-SendMessage\"\n\n  request_parameters = {\n    \"QueueUrl\"    = \"$request.header.queueUrl\"\n    \"MessageBody\" = \"$request.body.message\"\n  }\n}\n```\n\n### Private Integration\n\n```terraform\nresource \"aws_apigatewayv2_integration\" \"example\" {\n  api_id           = aws_apigatewayv2_api.example.id\n  credentials_arn  = aws_iam_role.example.arn\n  description      = \"Example with a load balancer\"\n  integration_type = \"HTTP_PROXY\"\n  integration_uri  = aws_lb_listener.example.arn\n\n  integration_method = \"ANY\"\n  connection_type    = \"VPC_LINK\"\n  connection_id      = aws_apigatewayv2_vpc_link.example.id\n\n  tls_config {\n    server_name_to_verify = \"example.com\"\n  }\n\n  request_parameters = {\n    \"append:header.authforintegration\" = \"$context.authorizer.authorizerResponse\"\n    \"overwrite:path\"                   = \"staticValueForIntegration\"\n  }\n\n  response_parameters {\n    status_code = 403\n    mappings = {\n      \"append:header.auth\" = \"$context.authorizer.authorizerResponse\"\n    }\n  }\n\n  response_parameters {\n    status_code = 200\n    mappings = {\n      \"overwrite:statuscode\" = \"204\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `integration_type` - (Required) The integration type of an integration.\nValid values: `AWS` (supported only for WebSocket APIs), `AWS_PROXY`, `HTTP` (supported only for WebSocket APIs), `HTTP_PROXY`, `MOCK` (supported only for WebSocket APIs). For an HTTP API private integration, use `HTTP_PROXY`.\n* `connection_id` - (Optional) The ID of the [VPC link](apigatewayv2_vpc_link.html) for a private integration. Supported only for HTTP APIs. Must be between 1 and 1024 characters in length.\n* `connection_type` - (Optional) The type of the network connection to the integration endpoint. Valid values: `INTERNET`, `VPC_LINK`. Default is `INTERNET`.\n* `content_handling_strategy` - (Optional) How to handle response payload content type conversions. Valid values: `CONVERT_TO_BINARY`, `CONVERT_TO_TEXT`. Supported only for WebSocket APIs.\n* `credentials_arn` - (Optional) The credentials required for the integration, if any.\n* `description` - (Optional) The description of the integration.\n* `integration_method` - (Optional) The integration's HTTP method. Must be specified if `integration_type` is not `MOCK`.\n* `integration_subtype` - (Optional) Specifies the AWS service action to invoke. Supported only for HTTP APIs when `integration_type` is `AWS_PROXY`. See the [AWS service integration reference](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integrations-aws-services-reference.html) documentation for supported values. Must be between 1 and 128 characters in length.\n* `integration_uri` - (Optional) The URI of the Lambda function for a Lambda proxy integration, when `integration_type` is `AWS_PROXY`.\nFor an `HTTP` integration, specify a fully-qualified URL. For an HTTP API private integration, specify the ARN of an Application Load Balancer listener, Network Load Balancer listener, or AWS Cloud Map service.\n* `passthrough_behavior` - (Optional) The pass-through behavior for incoming requests based on the Content-Type header in the request, and the available mapping templates specified as the `request_templates` attribute.\nValid values: `WHEN_NO_MATCH`, `WHEN_NO_TEMPLATES`, `NEVER`. Default is `WHEN_NO_MATCH`. Supported only for WebSocket APIs.\n* `payload_format_version` - (Optional) The [format of the payload](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integrations-lambda.html#http-api-develop-integrations-lambda.proxy-format) sent to an integration. Valid values: `1.0`, `2.0`. Default is `1.0`.\n* `request_parameters` - (Optional) For WebSocket APIs, a key-value map specifying request parameters that are passed from the method request to the backend.\nFor HTTP APIs with a specified `integration_subtype`, a key-value map specifying parameters that are passed to `AWS_PROXY` integrations.\nFor HTTP APIs without a specified `integration_subtype`, a key-value map specifying how to transform HTTP requests before sending them to the backend.\nSee the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-parameter-mapping.html) for details.\n* `request_templates` - (Optional) A map of [Velocity](https://velocity.apache.org/) templates that are applied on the request payload based on the value of the Content-Type header sent by the client. Supported only for WebSocket APIs.\n* `response_parameters` - (Optional) Mappings to transform the HTTP response from a backend integration before returning the response to clients. Supported only for HTTP APIs.\n* `template_selection_expression` - (Optional) The [template selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-template-selection-expressions) for the integration.\n* `timeout_milliseconds` - (Optional) Custom timeout between 50 and 29,000 milliseconds for WebSocket APIs and between 50 and 30,000 milliseconds for HTTP APIs.\nThe default timeout is 29 seconds for WebSocket APIs and 30 seconds for HTTP APIs.\nTerraform will only perform drift detection of its value when present in a configuration.\n* `tls_config` - (Optional) The TLS configuration for a private integration. Supported only for HTTP APIs.\n\nThe `response_parameters` object supports the following:\n\n* `status_code` - (Required) The HTTP status code in the range 200-599.\n* `mappings` - (Required) A key-value map. The key of ths map identifies the location of the request parameter to change, and how to change it. The corresponding value specifies the new data for the parameter.\nSee the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-parameter-mapping.html) for details.\n\nThe `tls_config` object supports the following:\n\n* `server_name_to_verify` - (Optional) If you specify a server name, API Gateway uses it to verify the hostname on the integration's certificate. The server name is also included in the TLS handshake to support Server Name Indication (SNI) or virtual hosting.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The integration identifier.\n* `integration_response_selection_expression` - The [integration response selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-integration-response-selection-expressions) for the integration.\n\n## Import\n\n`aws_apigatewayv2_integration` can be imported by using the API identifier and integration identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_integration.example aabbccddee/1122334\n```\n\n-> **Note:** The API Gateway managed integration created as part of [_quick_create_](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-basic-concept.html#apigateway-definition-quick-create) cannot be imported.\n",
    "basename": "apigatewayv2_integration.html"
  },
  "apigatewayv2_integration_response.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_integration_response",
    "description": "Manages an Amazon API Gateway Version 2 integration response.",
    "preview": "# Resource: aws_apigatewayv2_integration_response\n\nManages an Amazon …",
    "content": "\n\n# Resource: aws_apigatewayv2_integration_response\n\nManages an Amazon API Gateway Version 2 integration response.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_integration_response\" \"example\" {\n  api_id                   = aws_apigatewayv2_api.example.id\n  integration_id           = aws_apigatewayv2_integration.example.id\n  integration_response_key = \"/200/\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `integration_id` - (Required) The identifier of the [`aws_apigatewayv2_integration`](/docs/providers/aws/r/apigatewayv2_integration.html).\n* `integration_response_key` - (Required) The integration response key.\n* `content_handling_strategy` - (Optional) How to handle response payload content type conversions. Valid values: `CONVERT_TO_BINARY`, `CONVERT_TO_TEXT`.\n* `response_templates` - (Optional) A map of Velocity templates that are applied on the request payload based on the value of the Content-Type header sent by the client.\n* `template_selection_expression` - (Optional) The [template selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-template-selection-expressions) for the integration response.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The integration response identifier.\n\n## Import\n\n`aws_apigatewayv2_integration_response` can be imported by using the API identifier, integration identifier and integration response identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_integration_response.example aabbccddee/1122334/998877\n```\n",
    "basename": "apigatewayv2_integration_response.html"
  },
  "apigatewayv2_model.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_model",
    "description": "Manages an Amazon API Gateway Version 2 model.",
    "preview": "# Resource: aws_apigatewayv2_model\n\nManages an Amazon API Gateway …",
    "content": "\n\n# Resource: aws_apigatewayv2_model\n\nManages an Amazon API Gateway Version 2 [model](https://docs.aws.amazon.com/apigateway/latest/developerguide/models-mappings.html#models-mappings-models).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_model\" \"example\" {\n  api_id       = aws_apigatewayv2_api.example.id\n  content_type = \"application/json\"\n  name         = \"example\"\n\n  schema = <<EOF\n{\n  \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n  \"title\": \"ExampleModel\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"id\": { \"type\": \"string\" }\n  }\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `content_type` - (Required)  The content-type for the model, for example, `application/json`. Must be between 1 and 256 characters in length.\n* `name` - (Required) The name of the model. Must be alphanumeric. Must be between 1 and 128 characters in length.\n* `schema` - (Required) The schema for the model. This should be a [JSON schema draft 4](https://tools.ietf.org/html/draft-zyp-json-schema-04) model. Must be less than or equal to 32768 characters in length.\n* `description` - (Optional) The description of the model. Must be between 1 and 128 characters in length.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The model identifier.\n\n## Import\n\n`aws_apigatewayv2_model` can be imported by using the API identifier and model identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_model.example aabbccddee/1122334\n```\n",
    "basename": "apigatewayv2_model.html"
  },
  "apigatewayv2_route.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_route",
    "description": "Manages an Amazon API Gateway Version 2 route.",
    "preview": "# Resource: aws_apigatewayv2_route\n\nManages an Amazon API Gateway …",
    "content": "\n\n# Resource: aws_apigatewayv2_route\n\nManages an Amazon API Gateway Version 2 route.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html) for [WebSocket](https://docs.aws.amazon.com/apigateway/latest/developerguide/websocket-api-develop-routes.html) and [HTTP](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-routes.html) APIs.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_api\" \"example\" {\n  name                       = \"example-websocket-api\"\n  protocol_type              = \"WEBSOCKET\"\n  route_selection_expression = \"$request.body.action\"\n}\n\nresource \"aws_apigatewayv2_route\" \"example\" {\n  api_id    = aws_apigatewayv2_api.example.id\n  route_key = \"$default\"\n}\n```\n\n### HTTP Proxy Integration\n\n```terraform\nresource \"aws_apigatewayv2_api\" \"example\" {\n  name          = \"example-http-api\"\n  protocol_type = \"HTTP\"\n}\n\nresource \"aws_apigatewayv2_integration\" \"example\" {\n  api_id           = aws_apigatewayv2_api.example.id\n  integration_type = \"HTTP_PROXY\"\n\n  integration_method = \"ANY\"\n  integration_uri    = \"https://example.com/{proxy}\"\n}\n\nresource \"aws_apigatewayv2_route\" \"example\" {\n  api_id    = aws_apigatewayv2_api.example.id\n  route_key = \"ANY /example/{proxy+}\"\n\n  target = \"integrations/${aws_apigatewayv2_integration.example.id}\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `route_key` - (Required) The route key for the route. For HTTP APIs, the route key can be either `$default`, or a combination of an HTTP method and resource path, for example, `GET /pets`.\n* `api_key_required` - (Optional) Boolean whether an API key is required for the route. Defaults to `false`. Supported only for WebSocket APIs.\n* `authorization_scopes` - (Optional) The authorization scopes supported by this route. The scopes are used with a JWT authorizer to authorize the method invocation.\n* `authorization_type` - (Optional) The authorization type for the route.\nFor WebSocket APIs, valid values are `NONE` for open access, `AWS_IAM` for using AWS IAM permissions, and `CUSTOM` for using a Lambda authorizer.\nFor HTTP APIs, valid values are `NONE` for open access, `JWT` for using JSON Web Tokens, `AWS_IAM` for using AWS IAM permissions, and `CUSTOM` for using a Lambda authorizer.\nDefaults to `NONE`.\n* `authorizer_id` - (Optional) The identifier of the [`aws_apigatewayv2_authorizer`](apigatewayv2_authorizer.html) resource to be associated with this route.\n* `model_selection_expression` - (Optional) The [model selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-model-selection-expressions) for the route. Supported only for WebSocket APIs.\n* `operation_name` - (Optional) The operation name for the route. Must be between 1 and 64 characters in length.\n* `request_models` - (Optional) The request models for the route. Supported only for WebSocket APIs.\n* `request_parameter` - (Optional) The request parameters for the route. Supported only for WebSocket APIs.\n* `route_response_selection_expression` - (Optional) The [route response selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-route-response-selection-expressions) for the route. Supported only for WebSocket APIs.\n* `target` - (Optional) The target for the route, of the form `integrations/`*`IntegrationID`*, where *`IntegrationID`* is the identifier of an [`aws_apigatewayv2_integration`](apigatewayv2_integration.html) resource.\n\nThe `request_parameter` object supports the following:\n\n* `request_parameter_key` - (Required) Request parameter key. This is a [request data mapping parameter](https://docs.aws.amazon.com/apigateway/latest/developerguide/websocket-api-data-mapping.html#websocket-mapping-request-parameters).\n* `required` - (Required) Boolean whether or not the parameter is required.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The route identifier.\n\n## Import\n\n`aws_apigatewayv2_route` can be imported by using the API identifier and route identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_route.example aabbccddee/1122334\n```\n\n-> **Note:** The API Gateway managed route created as part of [_quick_create_](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-basic-concept.html#apigateway-definition-quick-create) cannot be imported.\n",
    "basename": "apigatewayv2_route.html"
  },
  "apigatewayv2_route_response.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_route_response",
    "description": "Manages an Amazon API Gateway Version 2 route response.",
    "preview": "# Resource: aws_apigatewayv2_route_response\n\nManages an Amazon API …",
    "content": "\n\n# Resource: aws_apigatewayv2_route_response\n\nManages an Amazon API Gateway Version 2 route response.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_route_response\" \"example\" {\n  api_id             = aws_apigatewayv2_api.example.id\n  route_id           = aws_apigatewayv2_route.example.id\n  route_response_key = \"$default\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `route_id` - (Required) The identifier of the [`aws_apigatewayv2_route`](/docs/providers/aws/r/apigatewayv2_route.html).\n* `route_response_key` - (Required) The route response key.\n* `model_selection_expression` - (Optional) The [model selection expression](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-selection-expressions.html#apigateway-websocket-api-model-selection-expressions) for the route response.\n* `response_models` - (Optional) The response models for the route response.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The route response identifier.\n\n## Import\n\n`aws_apigatewayv2_route_response` can be imported by using the API identifier, route identifier and route response identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_route_response.example aabbccddee/1122334/998877\n```\n",
    "basename": "apigatewayv2_route_response.html"
  },
  "apigatewayv2_stage.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_stage",
    "description": "Manages an Amazon API Gateway Version 2 stage.",
    "preview": "# Resource: aws_apigatewayv2_stage\n\nManages an Amazon API Gateway …",
    "content": "\n\n# Resource: aws_apigatewayv2_stage\n\nManages an Amazon API Gateway Version 2 stage.\nMore information can be found in the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_apigatewayv2_stage\" \"example\" {\n  api_id = aws_apigatewayv2_api.example.id\n  name   = \"example-stage\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API identifier.\n* `name` - (Required) The name of the stage. Must be between 1 and 128 characters in length.\n* `access_log_settings` - (Optional) Settings for logging access in this stage.\nUse the [`aws_api_gateway_account`](/docs/providers/aws/r/api_gateway_account.html) resource to configure [permissions for CloudWatch Logging](https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html#set-up-access-logging-permissions).\n* `auto_deploy` - (Optional) Whether updates to an API automatically trigger a new deployment. Defaults to `false`. Applicable for HTTP APIs.\n* `client_certificate_id` - (Optional) The identifier of a client certificate for the stage. Use the [`aws_api_gateway_client_certificate`](/docs/providers/aws/r/api_gateway_client_certificate.html) resource to configure a client certificate.\nSupported only for WebSocket APIs.\n* `default_route_settings` - (Optional) The default route settings for the stage.\n* `deployment_id` - (Optional) The deployment identifier of the stage. Use the [`aws_apigatewayv2_deployment`](/docs/providers/aws/r/apigatewayv2_deployment.html) resource to configure a deployment.\n* `description` - (Optional) The description for the stage. Must be less than or equal to 1024 characters in length.\n* `route_settings` - (Optional) Route settings for the stage.\n* `stage_variables` - (Optional) A map that defines the stage variables for the stage.\n* `tags` - (Optional) A map of tags to assign to the stage. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `access_log_settings` object supports the following:\n\n* `destination_arn` - (Required) The ARN of the CloudWatch Logs log group to receive access logs. Any trailing `:*` is trimmed from the ARN.\n* `format` - (Required) A single line [format](https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html#apigateway-cloudwatch-log-formats) of the access logs of data, as specified by [selected $context variables](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-logging.html).\n\nThe `default_route_settings` object supports the following:\n\n* `data_trace_enabled` - (Optional) Whether data trace logging is enabled for the default route. Affects the log entries pushed to Amazon CloudWatch Logs.\nDefaults to `false`. Supported only for WebSocket APIs.\n* `detailed_metrics_enabled` - (Optional) Whether detailed metrics are enabled for the default route. Defaults to `false`.\n* `logging_level` - (Optional) The logging level for the default route. Affects the log entries pushed to Amazon CloudWatch Logs.\nValid values: `ERROR`, `INFO`, `OFF`. Defaults to `OFF`. Supported only for WebSocket APIs. Terraform will only perform drift detection of its value when present in a configuration.\n* `throttling_burst_limit` - (Optional) The throttling burst limit for the default route.\n* `throttling_rate_limit` - (Optional) The throttling rate limit for the default route.\n\nThe `route_settings` object supports the following:\n\n* `route_key` - (Required) Route key.\n* `data_trace_enabled` - (Optional) Whether data trace logging is enabled for the route. Affects the log entries pushed to Amazon CloudWatch Logs.\nDefaults to `false`. Supported only for WebSocket APIs.\n* `detailed_metrics_enabled` - (Optional) Whether detailed metrics are enabled for the route. Defaults to `false`.\n* `logging_level` - (Optional) The logging level for the route. Affects the log entries pushed to Amazon CloudWatch Logs.\nValid values: `ERROR`, `INFO`, `OFF`. Defaults to `OFF`. Supported only for WebSocket APIs. Terraform will only perform drift detection of its value when present in a configuration.\n* `throttling_burst_limit` - (Optional) The throttling burst limit for the route.\n* `throttling_rate_limit` - (Optional) The throttling rate limit for the route.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The stage identifier.\n* `arn` - The ARN of the stage.\n* `execution_arn` - The ARN prefix to be used in an [`aws_lambda_permission`](/docs/providers/aws/r/lambda_permission.html)'s `source_arn` attribute.\nFor WebSocket APIs this attribute can additionally be used in an [`aws_iam_policy`](/docs/providers/aws/r/iam_policy.html) to authorize access to the [`@connections` API](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-how-to-call-websocket-api-connections.html).\nSee the [Amazon API Gateway Developer Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-control-access-iam.html) for details.\n* `invoke_url` - The URL to invoke the API pointing to the stage,\n  e.g., `wss://z4675bid1j.execute-api.eu-west-2.amazonaws.com/example-stage`, or `https://z4675bid1j.execute-api.eu-west-2.amazonaws.com/`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_apigatewayv2_stage` can be imported by using the API identifier and stage name, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_stage.example aabbccddee/example-stage\n```\n\n-> **Note:** The API Gateway managed stage created as part of [_quick_create_](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-basic-concept.html#apigateway-definition-quick-create) cannot be imported.\n",
    "basename": "apigatewayv2_stage.html"
  },
  "apigatewayv2_vpc_link.html": {
    "subcategory": "API Gateway v2 (WebSocket and HTTP APIs)",
    "layout": "aws",
    "page_title": "AWS: aws_apigatewayv2_vpc_link",
    "description": "Manages an Amazon API Gateway Version 2 VPC Link.",
    "preview": "# Resource: aws_apigatewayv2_vpc_link\n\nManages an Amazon API Gateway …",
    "content": "\n\n# Resource: aws_apigatewayv2_vpc_link\n\nManages an Amazon API Gateway Version 2 VPC Link.\n\n-> **Note:** Amazon API Gateway Version 2 VPC Links enable private integrations that connect HTTP APIs to private resources in a VPC.\nTo enable private integration for REST APIs, use the Amazon API Gateway Version 1 VPC Link [resource](/docs/providers/aws/r/api_gateway_vpc_link.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_apigatewayv2_vpc_link\" \"example\" {\n  name               = \"example\"\n  security_group_ids = [data.aws_security_group.example.id]\n  subnet_ids         = data.aws_subnet_ids.example.ids\n\n  tags = {\n    Usage = \"example\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the VPC Link. Must be between 1 and 128 characters in length.\n* `security_group_ids` - (Required) Security group IDs for the VPC Link.\n* `subnet_ids` - (Required) Subnet IDs for the VPC Link.\n* `tags` - (Optional) A map of tags to assign to the VPC Link. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The VPC Link identifier.\n* `arn` - The VPC Link ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_apigatewayv2_vpc_link` can be imported by using the VPC Link identifier, e.g.,\n\n```\n$ terraform import aws_apigatewayv2_vpc_link.example aabbccddee\n```\n",
    "basename": "apigatewayv2_vpc_link.html"
  },
  "app_cookie_stickiness_policy.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_app_cookie_stickiness_policy",
    "description": "Provides an application cookie stickiness policy, which allows an ELB to wed its stickiness cookie to a cookie generated by your application.",
    "preview": "# Resource: aws_app_cookie_stickiness_policy\n\nProvides an …",
    "content": "\n\n# Resource: aws_app_cookie_stickiness_policy\n\nProvides an application cookie stickiness policy, which allows an ELB to wed its sticky cookie's expiration to a cookie generated by your application.\n\n## Example Usage\n\n```terraform\nresource \"aws_elb\" \"lb\" {\n  name               = \"test-lb\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port     = 8000\n    instance_protocol = \"http\"\n    lb_port           = 80\n    lb_protocol       = \"http\"\n  }\n}\n\nresource \"aws_app_cookie_stickiness_policy\" \"foo\" {\n  name          = \"foo_policy\"\n  load_balancer = aws_elb.lb.name\n  lb_port       = 80\n  cookie_name   = \"MyAppCookie\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the stickiness policy.\n* `load_balancer` - (Required) The name of load balancer to which the policy\n  should be attached.\n* `lb_port` - (Required) The load balancer port to which the policy\n  should be applied. This must be an active listener on the load\nbalancer.\n* `cookie_name` - (Required) The application cookie whose lifetime the ELB's cookie should follow.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the policy.\n* `name` - The name of the stickiness policy.\n* `load_balancer` - The name of load balancer to which the policy is attached.\n* `lb_port` - The load balancer port to which the policy is applied.\n* `cookie_name` - The application cookie whose lifetime the ELB's cookie should follow.\n\n## Import\n\nApplication cookie stickiness policies can be imported using the ELB name, port, and policy name separated by colons (`:`), e.g.,\n\n```sh\n$ terraform import aws_app_cookie_stickiness_policy.example my-elb:80:my-policy\n```\n",
    "basename": "app_cookie_stickiness_policy.html"
  },
  "appautoscaling_policy.html": {
    "subcategory": "Application Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_appautoscaling_policy",
    "description": "Provides an Application AutoScaling Policy resource.",
    "preview": "# Resource: aws_appautoscaling_policy\n\nProvides an Application …",
    "content": "\n\n# Resource: aws_appautoscaling_policy\n\nProvides an Application AutoScaling Policy resource.\n\n## Example Usage\n\n### DynamoDB Table Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"dynamodb_table_read_target\" {\n  max_capacity       = 100\n  min_capacity       = 5\n  resource_id        = \"table/tableName\"\n  scalable_dimension = \"dynamodb:table:ReadCapacityUnits\"\n  service_namespace  = \"dynamodb\"\n}\n\nresource \"aws_appautoscaling_policy\" \"dynamodb_table_read_policy\" {\n  name               = \"DynamoDBReadCapacityUtilization:${aws_appautoscaling_target.dynamodb_table_read_target.resource_id}\"\n  policy_type        = \"TargetTrackingScaling\"\n  resource_id        = aws_appautoscaling_target.dynamodb_table_read_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.dynamodb_table_read_target.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.dynamodb_table_read_target.service_namespace\n\n  target_tracking_scaling_policy_configuration {\n    predefined_metric_specification {\n      predefined_metric_type = \"DynamoDBReadCapacityUtilization\"\n    }\n\n    target_value = 70\n  }\n}\n```\n\n### ECS Service Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"ecs_target\" {\n  max_capacity       = 4\n  min_capacity       = 1\n  resource_id        = \"service/clusterName/serviceName\"\n  scalable_dimension = \"ecs:service:DesiredCount\"\n  service_namespace  = \"ecs\"\n}\n\nresource \"aws_appautoscaling_policy\" \"ecs_policy\" {\n  name               = \"scale-down\"\n  policy_type        = \"StepScaling\"\n  resource_id        = aws_appautoscaling_target.ecs_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace\n\n  step_scaling_policy_configuration {\n    adjustment_type         = \"ChangeInCapacity\"\n    cooldown                = 60\n    metric_aggregation_type = \"Maximum\"\n\n    step_adjustment {\n      metric_interval_upper_bound = 0\n      scaling_adjustment          = -1\n    }\n  }\n}\n```\n\n### Preserve desired count when updating an autoscaled ECS Service\n\n```terraform\nresource \"aws_ecs_service\" \"ecs_service\" {\n  name            = \"serviceName\"\n  cluster         = \"clusterName\"\n  task_definition = \"taskDefinitionFamily:1\"\n  desired_count   = 2\n\n  lifecycle {\n    ignore_changes = [desired_count]\n  }\n}\n```\n\n### Aurora Read Replica Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"replicas\" {\n  service_namespace  = \"rds\"\n  scalable_dimension = \"rds:cluster:ReadReplicaCount\"\n  resource_id        = \"cluster:${aws_rds_cluster.example.id}\"\n  min_capacity       = 1\n  max_capacity       = 15\n}\n\nresource \"aws_appautoscaling_policy\" \"replicas\" {\n  name               = \"cpu-auto-scaling\"\n  service_namespace  = aws_appautoscaling_target.replicas.service_namespace\n  scalable_dimension = aws_appautoscaling_target.replicas.scalable_dimension\n  resource_id        = aws_appautoscaling_target.replicas.resource_id\n  policy_type        = \"TargetTrackingScaling\"\n\n  target_tracking_scaling_policy_configuration {\n    predefined_metric_specification {\n      predefined_metric_type = \"RDSReaderAverageCPUUtilization\"\n    }\n\n    target_value       = 75\n    scale_in_cooldown  = 300\n    scale_out_cooldown = 300\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the policy. Must be between 1 and 255 characters in length.\n* `policy_type` - (Optional) The policy type. Valid values are `StepScaling` and `TargetTrackingScaling`. Defaults to `StepScaling`. Certain services only support only one policy type. For more information see the [Target Tracking Scaling Policies](https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-target-tracking.html) and [Step Scaling Policies](https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-step-scaling-policies.html) documentation.\n* `resource_id` - (Required) The resource type and unique identifier string for the resource associated with the scaling policy. Documentation can be found in the `ResourceId` parameter at: [AWS Application Auto Scaling API Reference](http://docs.aws.amazon.com/ApplicationAutoScaling/latest/APIReference/API_RegisterScalableTarget.html#API_RegisterScalableTarget_RequestParameters)\n* `scalable_dimension` - (Required) The scalable dimension of the scalable target. Documentation can be found in the `ScalableDimension` parameter at: [AWS Application Auto Scaling API Reference](http://docs.aws.amazon.com/ApplicationAutoScaling/latest/APIReference/API_RegisterScalableTarget.html#API_RegisterScalableTarget_RequestParameters)\n* `service_namespace` - (Required) The AWS service namespace of the scalable target. Documentation can be found in the `ServiceNamespace` parameter at: [AWS Application Auto Scaling API Reference](http://docs.aws.amazon.com/ApplicationAutoScaling/latest/APIReference/API_RegisterScalableTarget.html#API_RegisterScalableTarget_RequestParameters)\n* `step_scaling_policy_configuration` - (Optional) Step scaling policy configuration, requires `policy_type = \"StepScaling\"` (default). See supported fields below.\n* `target_tracking_scaling_policy_configuration` - (Optional) A target tracking policy, requires `policy_type = \"TargetTrackingScaling\"`. See supported fields below.\n\n### step_scaling_policy_configuration\n\nThe `step_scaling_policy_configuration` configuration block supports the following arguments:\n\n* `adjustment_type` - (Required) Specifies whether the adjustment is an absolute number or a percentage of the current capacity. Valid values are `ChangeInCapacity`, `ExactCapacity`, and `PercentChangeInCapacity`.\n* `cooldown` - (Required) The amount of time, in seconds, after a scaling activity completes and before the next scaling activity can start.\n* `metric_aggregation_type` - (Optional) The aggregation type for the policy's metrics. Valid values are \"Minimum\", \"Maximum\", and \"Average\". Without a value, AWS will treat the aggregation type as \"Average\".\n* `min_adjustment_magnitude` - (Optional) The minimum number to adjust your scalable dimension as a result of a scaling activity. If the adjustment type is PercentChangeInCapacity, the scaling policy changes the scalable dimension of the scalable target by this amount.\n* `step_adjustment` - (Optional) A set of adjustments that manage scaling. These have the following structure:\n\n ```terraform\nresource \"aws_appautoscaling_policy\" \"ecs_policy\" {\n  # ...\n\n  step_scaling_policy_configuration {\n    # insert config here\n\n    step_adjustment {\n      metric_interval_lower_bound = 1.0\n      metric_interval_upper_bound = 2.0\n      scaling_adjustment          = -1\n    }\n\n    step_adjustment {\n      metric_interval_lower_bound = 2.0\n      metric_interval_upper_bound = 3.0\n      scaling_adjustment          = 1\n    }\n  }\n}\n```\n\n* `metric_interval_lower_bound` - (Optional) The lower bound for the difference between the alarm threshold and the CloudWatch metric. Without a value, AWS will treat this bound as negative infinity.\n* `metric_interval_upper_bound` - (Optional) The upper bound for the difference between the alarm threshold and the CloudWatch metric. Without a value, AWS will treat this bound as infinity. The upper bound must be greater than the lower bound.\n* `scaling_adjustment` - (Required) The number of members by which to scale, when the adjustment bounds are breached. A positive value scales up. A negative value scales down.\n\n### target_tracking_scaling_policy_configuration\n\nThe `target_tracking_scaling_policy_configuration` configuration block supports the following arguments:\n\n* `target_value` - (Required) The target value for the metric.\n* `disable_scale_in` - (Optional) Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the scalable resource. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the scalable resource. The default value is `false`.\n* `scale_in_cooldown` - (Optional) The amount of time, in seconds, after a scale in activity completes before another scale in activity can start.\n* `scale_out_cooldown` - (Optional) The amount of time, in seconds, after a scale out activity completes before another scale out activity can start.\n* `customized_metric_specification` - (Optional) A custom CloudWatch metric. Documentation can be found  at: [AWS Customized Metric Specification](https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_CustomizedMetricSpecification.html). See supported fields below.\n* `predefined_metric_specification` - (Optional) A predefined metric. See supported fields below.\n\n### target_tracking_scaling_policy_configuration customized_metric_specification\n\nExample usage:\n\n```terraform\nresource \"aws_appautoscaling_policy\" \"example\" {\n  policy_type = \"TargetTrackingScaling\"\n\n  # ... other configuration ...\n\n  target_tracking_scaling_policy_configuration {\n    target_value = 40\n\n    # ... potentially other configuration ...\n\n    customized_metric_specification {\n      metric_name = \"MyUtilizationMetric\"\n      namespace   = \"MyNamespace\"\n      statistic   = \"Average\"\n      unit        = \"Percent\"\n\n      dimensions {\n        name  = \"MyOptionalMetricDimensionName\"\n        value = \"MyOptionalMetricDimensionValue\"\n      }\n    }\n  }\n}\n```\n\nThe `target_tracking_scaling_policy_configuration` `customized_metric_specification` configuration block supports the following arguments:\n\n* `dimensions` - (Optional) Configuration block(s) with the dimensions of the metric if the metric was published with dimensions. Detailed below.\n* `metric_name` - (Required) The name of the metric.\n* `namespace` - (Required) The namespace of the metric.\n* `statistic` - (Required) The statistic of the metric. Valid values: `Average`, `Minimum`, `Maximum`, `SampleCount`, and `Sum`.\n* `unit` - (Optional) The unit of the metric.\n\n### target_tracking_scaling_policy_configuration customized_metric_specification dimensions\n\nThe `target_tracking_scaling_policy_configuration` `customized_metric_specification` `dimensions` configuration block supports the following arguments:\n\n* `name` - (Required) Name of the dimension.\n* `value` - (Required) Value of the dimension.\n\n### target_tracking_scaling_policy_configuration predefined_metric_specification\n\nThe `target_tracking_scaling_policy_configuration` `predefined_metric_specification` configuration block supports the following arguments:\n\n* `predefined_metric_type` - (Required) The metric type.\n* `resource_label` - (Optional) Reserved for future use. Must be less than or equal to 1023 characters in length.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS to the scaling policy.\n* `name` - The scaling policy's name.\n* `policy_type` - The scaling policy's type.\n\n## Import\n\nApplication AutoScaling Policy can be imported using the `service-namespace` , `resource-id`, `scalable-dimension` and `policy-name` separated by `/`.\n\n```\n$ terraform import aws_appautoscaling_policy.test-policy service-namespace/resource-id/scalable-dimension/policy-name\n```\n",
    "basename": "appautoscaling_policy.html"
  },
  "appautoscaling_scheduled_action.html": {
    "subcategory": "Application Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_appautoscaling_scheduled_action",
    "description": "Provides an Application AutoScaling ScheduledAction resource.",
    "preview": "# Resource: aws_appautoscaling_scheduled_action\n\nProvides an …",
    "content": "\n\n# Resource: aws_appautoscaling_scheduled_action\n\nProvides an Application AutoScaling ScheduledAction resource.\n\n## Example Usage\n\n### DynamoDB Table Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"dynamodb\" {\n  max_capacity       = 100\n  min_capacity       = 5\n  resource_id        = \"table/tableName\"\n  scalable_dimension = \"dynamodb:table:ReadCapacityUnits\"\n  service_namespace  = \"dynamodb\"\n}\n\nresource \"aws_appautoscaling_scheduled_action\" \"dynamodb\" {\n  name               = \"dynamodb\"\n  service_namespace  = aws_appautoscaling_target.dynamodb.service_namespace\n  resource_id        = aws_appautoscaling_target.dynamodb.resource_id\n  scalable_dimension = aws_appautoscaling_target.dynamodb.scalable_dimension\n  schedule           = \"at(2006-01-02T15:04:05)\"\n\n  scalable_target_action {\n    min_capacity = 1\n    max_capacity = 200\n  }\n}\n```\n\n### ECS Service Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"ecs\" {\n  max_capacity       = 4\n  min_capacity       = 1\n  resource_id        = \"service/clusterName/serviceName\"\n  scalable_dimension = \"ecs:service:DesiredCount\"\n  service_namespace  = \"ecs\"\n}\n\nresource \"aws_appautoscaling_scheduled_action\" \"ecs\" {\n  name               = \"ecs\"\n  service_namespace  = aws_appautoscaling_target.ecs.service_namespace\n  resource_id        = aws_appautoscaling_target.ecs.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension\n  schedule           = \"at(2006-01-02T15:04:05)\"\n\n  scalable_target_action {\n    min_capacity = 1\n    max_capacity = 10\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the scheduled action.\n* `service_namespace` - (Required) The namespace of the AWS service. Documentation can be found in the parameter at: [AWS Application Auto Scaling API Reference](https://docs.aws.amazon.com/ApplicationAutoScaling/latest/APIReference/API_PutScheduledAction.html#ApplicationAutoScaling-PutScheduledAction-request-ServiceNamespace) Example: ecs\n* `resource_id` - (Required) The identifier of the resource associated with the scheduled action. Documentation can be found in the parameter at: [AWS Application Auto Scaling API Reference](https://docs.aws.amazon.com/ApplicationAutoScaling/latest/APIReference/API_PutScheduledAction.html#ApplicationAutoScaling-PutScheduledAction-request-ResourceId)\n* `scalable_dimension` - (Required) The scalable dimension. Documentation can be found in the parameter at: [AWS Application Auto Scaling API Reference](https://docs.aws.amazon.com/ApplicationAutoScaling/latest/APIReference/API_PutScheduledAction.html#ApplicationAutoScaling-PutScheduledAction-request-ScalableDimension) Example: ecs:service:DesiredCount\n* `scalable_target_action` - (Required) The new minimum and maximum capacity. You can set both values or just one. See [below](#scalable-target-action-arguments)\n* `schedule` - (Required) The schedule for this action. The following formats are supported: At expressions - at(yyyy-mm-ddThh:mm:ss), Rate expressions - rate(valueunit), Cron expressions - cron(fields). Times for at expressions and cron expressions are evaluated using the time zone configured in `timezone`. Documentation can be found in the parameter at: [AWS Application Auto Scaling API Reference](https://docs.aws.amazon.com/ApplicationAutoScaling/latest/APIReference/API_PutScheduledAction.html#ApplicationAutoScaling-PutScheduledAction-request-Schedule)\n* `start_time` - (Optional) The date and time for the scheduled action to start in RFC 3339 format. The timezone is not affected by the setting of `timezone`.\n* `end_time` - (Optional) The date and time for the scheduled action to end in RFC 3339 format. The timezone is not affected by the setting of `timezone`.\n* `timezone` - (Optional) The time zone used when setting a scheduled action by using an at or cron expression. Does not affect timezone for `start_time` and `end_time`. Valid values are the [canonical names of the IANA time zones supported by Joda-Time](https://www.joda.org/joda-time/timezones.html), such as `Etc/GMT+9` or `Pacific/Tahiti`. Default is `UTC`.\n\n### Scalable Target Action Arguments\n\n* `max_capacity` - (Optional) The maximum capacity. At least one of `max_capacity` or `min_capacity` must be set.\n* `min_capacity` - (Optional) The minimum capacity. At least one of `min_capacity` or `max_capacity` must be set.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the scheduled action.\n",
    "basename": "appautoscaling_scheduled_action.html"
  },
  "appautoscaling_target.html": {
    "subcategory": "Application Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_appautoscaling_target",
    "description": "Provides an Application AutoScaling ScalableTarget resource.",
    "preview": "# Resource: aws_appautoscaling_target\n\nProvides an Application …",
    "content": "\n\n# Resource: aws_appautoscaling_target\n\nProvides an Application AutoScaling ScalableTarget resource. To manage policies which get attached to the target, see the [`aws_appautoscaling_policy` resource](/docs/providers/aws/r/appautoscaling_policy.html).\n\n~> **NOTE:** The [Application Auto Scaling service automatically attempts to manage IAM Service-Linked Roles](https://docs.aws.amazon.com/autoscaling/application/userguide/security_iam_service-with-iam.html#security_iam_service-with-iam-roles) when registering certain service namespaces for the first time. To manually manage this role, see the [`aws_iam_service_linked_role` resource](/docs/providers/aws/r/iam_service_linked_role.html).\n\n## Example Usage\n\n### DynamoDB Table Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"dynamodb_table_read_target\" {\n  max_capacity       = 100\n  min_capacity       = 5\n  resource_id        = \"table/${aws_dynamodb_table.example.name}\"\n  scalable_dimension = \"dynamodb:table:ReadCapacityUnits\"\n  service_namespace  = \"dynamodb\"\n}\n```\n\n### DynamoDB Index Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"dynamodb_index_read_target\" {\n  max_capacity       = 100\n  min_capacity       = 5\n  resource_id        = \"table/${aws_dynamodb_table.example.name}/index/${var.index_name}\"\n  scalable_dimension = \"dynamodb:index:ReadCapacityUnits\"\n  service_namespace  = \"dynamodb\"\n}\n```\n\n### ECS Service Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"ecs_target\" {\n  max_capacity       = 4\n  min_capacity       = 1\n  resource_id        = \"service/${aws_ecs_cluster.example.name}/${aws_ecs_service.example.name}\"\n  scalable_dimension = \"ecs:service:DesiredCount\"\n  service_namespace  = \"ecs\"\n}\n```\n\n### Aurora Read Replica Autoscaling\n\n```terraform\nresource \"aws_appautoscaling_target\" \"replicas\" {\n  service_namespace  = \"rds\"\n  scalable_dimension = \"rds:cluster:ReadReplicaCount\"\n  resource_id        = \"cluster:${aws_rds_cluster.example.id}\"\n  min_capacity       = 1\n  max_capacity       = 15\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `max_capacity` - (Required) The max capacity of the scalable target.\n* `min_capacity` - (Required) The min capacity of the scalable target.\n* `resource_id` - (Required) The resource type and unique identifier string for the resource associated with the scaling policy. Documentation can be found in the `ResourceId` parameter at: [AWS Application Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/application/APIReference/API_RegisterScalableTarget.html#API_RegisterScalableTarget_RequestParameters)\n* `role_arn` - (Optional) The ARN of the IAM role that allows Application AutoScaling to modify your scalable target on your behalf. This defaults to an IAM Service-Linked Role for most services and custom IAM Roles are ignored by the API for those namespaces. See the [AWS Application Auto Scaling documentation](https://docs.aws.amazon.com/autoscaling/application/userguide/security_iam_service-with-iam.html#security_iam_service-with-iam-roles) for more information about how this service interacts with IAM.\n* `scalable_dimension` - (Required) The scalable dimension of the scalable target. Documentation can be found in the `ScalableDimension` parameter at: [AWS Application Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/application/APIReference/API_RegisterScalableTarget.html#API_RegisterScalableTarget_RequestParameters)\n* `service_namespace` - (Required) The AWS service namespace of the scalable target. Documentation can be found in the `ServiceNamespace` parameter at: [AWS Application Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/application/APIReference/API_RegisterScalableTarget.html#API_RegisterScalableTarget_RequestParameters)\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nApplication AutoScaling Target can be imported using the `service-namespace` , `resource-id` and `scalable-dimension` separated by `/`.\n\n```\n$ terraform import aws_appautoscaling_target.test-target service-namespace/resource-id/scalable-dimension\n```\n",
    "basename": "appautoscaling_target.html"
  },
  "appconfig_application.html": {
    "subcategory": "AppConfig",
    "layout": "aws",
    "page_title": "AWS: aws_appconfig_application",
    "description": "Provides an AppConfig Application resource.",
    "preview": "# Resource: aws_appconfig_application\n\nProvides an AppConfig …",
    "content": "\n\n# Resource: aws_appconfig_application\n\nProvides an AppConfig Application resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_appconfig_application\" \"example\" {\n  name        = \"example-application-tf\"\n  description = \"Example AppConfig Application\"\n\n  tags = {\n    Type = \"AppConfig Application\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name for the application. Must be between 1 and 64 characters in length.\n* `description` - (Optional) The description of the application. Can be at most 1024 characters.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the AppConfig Application.\n* `id` - The AppConfig application ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAppConfig Applications can be imported using their application ID, e.g.,\n\n```\n$ terraform import aws_appconfig_application.example 71rxuzt\n```\n",
    "basename": "appconfig_application.html"
  },
  "appconfig_configuration_profile.html": {
    "subcategory": "AppConfig",
    "layout": "aws",
    "page_title": "AWS: aws_appconfig_configuration_profile",
    "description": "Provides an AppConfig Configuration Profile resource.",
    "preview": "# Resource: aws_appconfig_configuration_profile\n\nProvides an …",
    "content": "\n\n# Resource: aws_appconfig_configuration_profile\n\nProvides an AppConfig Configuration Profile resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_appconfig_configuration_profile\" \"example\" {\n  application_id = aws_appconfig_application.example.id\n  description    = \"Example Configuration Profile\"\n  name           = \"example-configuration-profile-tf\"\n  location_uri   = \"hosted\"\n\n  validator {\n    content = aws_lambda_function.example.arn\n    type    = \"LAMBDA\"\n  }\n\n  tags = {\n    Type = \"AppConfig Configuration Profile\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required, Forces new resource) The application ID. Must be between 4 and 7 characters in length.\n* `location_uri` - (Required, Forces new resource) A URI to locate the configuration. You can specify the AWS AppConfig hosted configuration store, Systems Manager (SSM) document, an SSM Parameter Store parameter, or an Amazon S3 object. For the hosted configuration store, specify `hosted`. For an SSM document, specify either the document name in the format `ssm-document://<Document_name>` or the Amazon Resource Name (ARN). For a parameter, specify either the parameter name in the format `ssm-parameter://<Parameter_name>` or the ARN. For an Amazon S3 object, specify the URI in the following format: `s3://<bucket>/<objectKey>`.\n* `name` - (Required) The name for the configuration profile. Must be between 1 and 64 characters in length.\n* `description` - (Optional) The description of the configuration profile. Can be at most 1024 characters.\n* `retrieval_role_arn` - (Optional) The ARN of an IAM role with permission to access the configuration at the specified `location_uri`. A retrieval role ARN is not required for configurations stored in the AWS AppConfig `hosted` configuration store. It is required for all other sources that store your configuration.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `validator` - (Optional) A set of methods for validating the configuration. Maximum of 2. See [Validator](#validator) below for more details.\n\n### Validator\n\nThe `validator` block supports the following:\n\n* `content` - (Optional, Required when `type` is `LAMBDA`) Either the JSON Schema content or the Amazon Resource Name (ARN) of an AWS Lambda function.\n* `type` - (Optional) The type of validator. Valid values: `JSON_SCHEMA` and `LAMBDA`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the AppConfig Configuration Profile.\n* `configuration_profile_id` - The configuration profile ID.\n* `id` - The AppConfig configuration profile ID and application ID separated by a colon (`:`).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAppConfig Configuration Profiles can be imported by using the configuration profile ID and application ID separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_appconfig_configuration_profile.example 71abcde:11xxxxx\n```\n",
    "basename": "appconfig_configuration_profile.html"
  },
  "appconfig_deployment.html": {
    "subcategory": "AppConfig",
    "layout": "aws",
    "page_title": "AWS: aws_appconfig_deployment",
    "description": "Provides an AppConfig Deployment resource.",
    "preview": "# Resource: aws_appconfig_deployment\n\nProvides an AppConfig …",
    "content": "\n\n# Resource: aws_appconfig_deployment\n\nProvides an AppConfig Deployment resource for an [`aws_appconfig_application` resource](appconfig_application.html.markdown).\n\n## Example Usage\n\n```terraform\nresource \"aws_appconfig_deployment\" \"example\" {\n  application_id           = aws_appconfig_application.example.id\n  configuration_profile_id = aws_appconfig_configuration_profile.example.configuration_profile_id\n  configuration_version    = aws_appconfig_hosted_configuration_version.example.version_number\n  deployment_strategy_id   = aws_appconfig_deployment_strategy.example.id\n  description              = \"My example deployment\"\n  environment_id           = aws_appconfig_environment.example.environment_id\n\n  tags = {\n    Type = \"AppConfig Deployment\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required, Forces new resource) The application ID. Must be between 4 and 7 characters in length.\n* `configuration_profile_id` - (Required, Forces new resource) The configuration profile ID. Must be between 4 and 7 characters in length.\n* `configuration_version` - (Required, Forces new resource) The configuration version to deploy. Can be at most 1024 characters.\n* `deployment_strategy_id` - (Required, Forces new resource) The deployment strategy ID or name of a predefined deployment strategy. See [Predefined Deployment Strategies](https://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-creating-deployment-strategy.html#appconfig-creating-deployment-strategy-predefined) for more details.\n* `description` - (Optional, Forces new resource) The description of the deployment. Can be at most 1024 characters.\n* `environment_id` - (Required, Forces new resource) The environment ID. Must be between 4 and 7 characters in length.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The AppConfig application ID, environment ID, and deployment number separated by a slash (`/`).\n* `arn` - The Amazon Resource Name (ARN) of the AppConfig Deployment.\n* `deployment_number` - The deployment number.\n* `state` - The state of the deployment.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAppConfig Deployments can be imported by using the application ID, environment ID, and deployment number separated by a slash (`/`), e.g.,\n\n```\n$ terraform import aws_appconfig_deployment.example 71abcde/11xxxxx/1\n```\n",
    "basename": "appconfig_deployment.html"
  },
  "appconfig_deployment_strategy.html": {
    "subcategory": "AppConfig",
    "layout": "aws",
    "page_title": "AWS: aws_appconfig_deployment_strategy",
    "description": "Provides an AppConfig Deployment Strategy resource.",
    "preview": "# Resource: aws_appconfig_deployment_strategy\n\nProvides an AppConfig …",
    "content": "\n\n# Resource: aws_appconfig_deployment_strategy\n\nProvides an AppConfig Deployment Strategy resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_appconfig_deployment_strategy\" \"example\" {\n  name                           = \"example-deployment-strategy-tf\"\n  description                    = \"Example Deployment Strategy\"\n  deployment_duration_in_minutes = 3\n  final_bake_time_in_minutes     = 4\n  growth_factor                  = 10\n  growth_type                    = \"LINEAR\"\n  replicate_to                   = \"NONE\"\n\n  tags = {\n    Type = \"AppConfig Deployment Strategy\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `deployment_duration_in_minutes` - (Required) Total amount of time for a deployment to last. Minimum value of 0, maximum value of 1440.\n* `growth_factor` - (Required) The percentage of targets to receive a deployed configuration during each interval. Minimum value of 1.0, maximum value of 100.0.\n* `name` - (Required, Forces new resource) A name for the deployment strategy. Must be between 1 and 64 characters in length.\n* `replicate_to` - (Required, Forces new resource) Where to save the deployment strategy. Valid values: `NONE` and `SSM_DOCUMENT`.\n* `description` - (Optional) A description of the deployment strategy. Can be at most 1024 characters.\n* `final_bake_time_in_minutes` - (Optional) The amount of time AWS AppConfig monitors for alarms before considering the deployment to be complete and no longer eligible for automatic roll back. Minimum value of 0, maximum value of 1440.\n* `growth_type` - (Optional) The algorithm used to define how percentage grows over time. Valid value: `LINEAR` and `EXPONENTIAL`. Defaults to `LINEAR`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The AppConfig deployment strategy ID.\n* `arn` - The Amazon Resource Name (ARN) of the AppConfig Deployment Strategy.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAppConfig Deployment Strategies can be imported by using their deployment strategy ID, e.g.,\n\n```\n$ terraform import aws_appconfig_deployment_strategy.example 11xxxxx\n```\n",
    "basename": "appconfig_deployment_strategy.html"
  },
  "appconfig_environment.html": {
    "subcategory": "AppConfig",
    "layout": "aws",
    "page_title": "AWS: aws_appconfig_environment",
    "description": "Provides an AppConfig Environment resource.",
    "preview": "# Resource: aws_appconfig_environment\n\nProvides an AppConfig …",
    "content": "\n\n# Resource: aws_appconfig_environment\n\nProvides an AppConfig Environment resource for an [`aws_appconfig_application` resource](appconfig_application.html.markdown). One or more environments can be defined for an application.\n\n## Example Usage\n\n```terraform\nresource \"aws_appconfig_environment\" \"example\" {\n  name           = \"example-environment-tf\"\n  description    = \"Example AppConfig Environment\"\n  application_id = aws_appconfig_application.example.id\n\n  monitor {\n    alarm_arn      = aws_cloudwatch_metric_alarm.example.arn\n    alarm_role_arn = aws_iam_role.example.arn\n  }\n\n  tags = {\n    Type = \"AppConfig Environment\"\n  }\n}\n\nresource \"aws_appconfig_application\" \"example\" {\n  name        = \"example-application-tf\"\n  description = \"Example AppConfig Application\"\n\n  tags = {\n    Type = \"AppConfig Application\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required, Forces new resource) The AppConfig application ID. Must be between 4 and 7 characters in length.\n* `name` - (Required) The name for the environment. Must be between 1 and 64 characters in length.\n* `description` - (Optional) The description of the environment. Can be at most 1024 characters.\n* `monitor` - (Optional) Set of Amazon CloudWatch alarms to monitor during the deployment process. Maximum of 5. See [Monitor](#monitor) below for more details.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Monitor\n\nThe `monitor` block supports the following:\n\n* `alarm_arn` - (Required) ARN of the Amazon CloudWatch alarm.\n* `alarm_role_arn` - (Optional) ARN of an IAM role for AWS AppConfig to monitor `alarm_arn`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the AppConfig Environment.\n* `id` - The AppConfig environment ID and application ID separated by a colon (`:`).\n* `environment_id` - The AppConfig environment ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAppConfig Environments can be imported by using the environment ID and application ID separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_appconfig_environment.example 71abcde:11xxxxx\n```\n",
    "basename": "appconfig_environment.html"
  },
  "appconfig_hosted_configuration_version.html": {
    "subcategory": "AppConfig",
    "layout": "aws",
    "page_title": "AWS: aws_appconfig_hosted_configuration_version",
    "description": "Provides an AppConfig Hosted Configuration Version resource.",
    "preview": "# Resource: aws_appconfig_hosted_configuration_version\n\nProvides an …",
    "content": "\n\n# Resource: aws_appconfig_hosted_configuration_version\n\nProvides an AppConfig Hosted Configuration Version resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_appconfig_hosted_configuration_version\" \"example\" {\n  application_id           = aws_appconfig_application.example.id\n  configuration_profile_id = aws_appconfig_configuration_profile.example.configuration_profile_id\n  description              = \"Example Hosted Configuration Version\"\n  content_type             = \"application/json\"\n\n  content = jsonencode({\n    foo = \"bar\"\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required, Forces new resource) The application ID.\n* `configuration_profile_id` - (Required, Forces new resource) The configuration profile ID.\n* `content` - (Required, Forces new resource) The content of the configuration or the configuration data.\n* `content_type` - (Required, Forces new resource) A standard MIME type describing the format of the configuration content. For more information, see [Content-Type](https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.17).\n* `description` - (Optional, Forces new resource) A description of the configuration.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the AppConfig  hosted configuration version.\n* `id` - The AppConfig application ID, configuration profile ID, and version number separated by a slash (`/`).\n* `version_number` - The version number of the hosted configuration.\n\n## Import\n\nAppConfig Hosted Configuration Versions can be imported by using the application ID, configuration profile ID, and version number separated by a slash (`/`), e.g.,\n\n```\n$ terraform import aws_appconfig_hosted_configuration_version.example 71abcde/11xxxxx/2\n```\n",
    "basename": "appconfig_hosted_configuration_version.html"
  },
  "appmesh_gateway_route.html": {
    "subcategory": "AppMesh",
    "layout": "aws",
    "page_title": "AWS: aws_appmesh_gateway_route",
    "description": "Provides an AWS App Mesh gateway route resource.",
    "preview": "# Resource: aws_appmesh_gateway_route\n\nProvides an AWS App Mesh …",
    "content": "\n\n# Resource: aws_appmesh_gateway_route\n\nProvides an AWS App Mesh gateway route resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_appmesh_gateway_route\" \"example\" {\n  name                 = \"example-gateway-route\"\n  mesh_name            = \"example-service-mesh\"\n  virtual_gateway_name = aws_appmesh_virtual_gateway.example.name\n\n  spec {\n    http_route {\n      action {\n        target {\n          virtual_service {\n            virtual_service_name = aws_appmesh_virtual_service.example.name\n          }\n        }\n      }\n\n      match {\n        prefix = \"/\"\n      }\n    }\n  }\n\n  tags = {\n    Environment = \"test\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to use for the gateway route. Must be between 1 and 255 characters in length.\n* `mesh_name` - (Required) The name of the service mesh in which to create the gateway route. Must be between 1 and 255 characters in length.\n* `virtual_gateway_name` - (Required) The name of the [virtual gateway](/docs/providers/aws/r/appmesh_virtual_gateway.html) to associate the gateway route with. Must be between 1 and 255 characters in length.\n* `mesh_owner` - (Optional) The AWS account ID of the service mesh's owner. Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `spec` - (Required) The gateway route specification to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `spec` object supports the following:\n\n* `grpc_route` - (Optional) The specification of a gRPC gateway route.\n* `http_route` - (Optional) The specification of an HTTP gateway route.\n* `http2_route` - (Optional) The specification of an HTTP/2 gateway route.\n\nThe `grpc_route`, `http_route` and `http2_route` objects supports the following:\n\n* `action` - (Required) The action to take if a match is determined.\n* `match` - (Required) The criteria for determining a request match.\n\nThe `grpc_route`, `http_route` and `http2_route`'s `action` object supports the following:\n\n* `target` - (Required) The target that traffic is routed to when a request matches the gateway route.\n\nThe `target` object supports the following:\n\n* `virtual_service` - (Required) The virtual service gateway route target.\n\nThe `virtual_service` object supports the following:\n\n* `virtual_service_name` - (Required) The name of the virtual service that traffic is routed to. Must be between 1 and 255 characters in length.\n\nThe `grpc_route`'s `match` object supports the following:\n\n* `service_name` - (Required) The fully qualified domain name for the service to match from the request.\n\nThe `http_route` and `http2_route`'s `match` object supports the following:\n\n* `prefix` - (Required) Specifies the path to match requests with. This parameter must always start with `/`, which by itself matches all requests to the virtual service name.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the gateway route.\n* `arn` - The ARN of the gateway route.\n* `created_date` - The creation date of the gateway route.\n* `last_updated_date` - The last update date of the gateway route.\n* `resource_owner` - The resource owner's AWS account ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Mesh gateway routes can be imported using `mesh_name` and `virtual_gateway_name` together with the gateway route's `name`,\ne.g.,\n\n```\n$ terraform import aws_appmesh_gateway_route.example mesh/gw1/example-gateway-route\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "appmesh_gateway_route.html"
  },
  "appmesh_mesh.html": {
    "subcategory": "AppMesh",
    "layout": "aws",
    "page_title": "AWS: aws_appmesh_mesh",
    "description": "Provides an AWS App Mesh service mesh resource.",
    "preview": "# Resource: aws_appmesh_mesh\n\nProvides an AWS App Mesh service mesh …",
    "content": "\n\n# Resource: aws_appmesh_mesh\n\nProvides an AWS App Mesh service mesh resource.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_appmesh_mesh\" \"simple\" {\n  name = \"simpleapp\"\n}\n```\n\n### Egress Filter\n\n```terraform\nresource \"aws_appmesh_mesh\" \"simple\" {\n  name = \"simpleapp\"\n\n  spec {\n    egress_filter {\n      type = \"ALLOW_ALL\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to use for the service mesh. Must be between 1 and 255 characters in length.\n* `spec` - (Optional) The service mesh specification to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `spec` object supports the following:\n\n* `egress_filter`- (Optional) The egress filter rules for the service mesh.\n\nThe `egress_filter` object supports the following:\n\n* `type` - (Optional) The egress filter type. By default, the type is `DROP_ALL`.\nValid values are `ALLOW_ALL` and `DROP_ALL`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the service mesh.\n* `arn` - The ARN of the service mesh.\n* `created_date` - The creation date of the service mesh.\n* `last_updated_date` - The last update date of the service mesh.\n* `mesh_owner` - The AWS account ID of the service mesh's owner.\n* `resource_owner` - The resource owner's AWS account ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Mesh service meshes can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_appmesh_mesh.simple simpleapp\n```\n",
    "basename": "appmesh_mesh.html"
  },
  "appmesh_route.html": {
    "subcategory": "AppMesh",
    "layout": "aws",
    "page_title": "AWS: aws_appmesh_route",
    "description": "Provides an AWS App Mesh route resource.",
    "preview": "# Resource: aws_appmesh_route\n\nProvides an AWS App Mesh route …",
    "content": "\n\n# Resource: aws_appmesh_route\n\nProvides an AWS App Mesh route resource.\n\n## Example Usage\n\n### HTTP Routing\n\n```terraform\nresource \"aws_appmesh_route\" \"serviceb\" {\n  name                = \"serviceB-route\"\n  mesh_name           = aws_appmesh_mesh.simple.id\n  virtual_router_name = aws_appmesh_virtual_router.serviceb.name\n\n  spec {\n    http_route {\n      match {\n        prefix = \"/\"\n      }\n\n      action {\n        weighted_target {\n          virtual_node = aws_appmesh_virtual_node.serviceb1.name\n          weight       = 90\n        }\n\n        weighted_target {\n          virtual_node = aws_appmesh_virtual_node.serviceb2.name\n          weight       = 10\n        }\n      }\n    }\n  }\n}\n```\n\n### HTTP Header Routing\n\n```terraform\nresource \"aws_appmesh_route\" \"serviceb\" {\n  name                = \"serviceB-route\"\n  mesh_name           = aws_appmesh_mesh.simple.id\n  virtual_router_name = aws_appmesh_virtual_router.serviceb.name\n\n  spec {\n    http_route {\n      match {\n        method = \"POST\"\n        prefix = \"/\"\n        scheme = \"https\"\n\n        header {\n          name = \"clientRequestId\"\n\n          match {\n            prefix = \"123\"\n          }\n        }\n      }\n\n      action {\n        weighted_target {\n          virtual_node = aws_appmesh_virtual_node.serviceb.name\n          weight       = 100\n        }\n      }\n    }\n  }\n}\n```\n\n### Retry Policy\n\n```terraform\nresource \"aws_appmesh_route\" \"serviceb\" {\n  name                = \"serviceB-route\"\n  mesh_name           = aws_appmesh_mesh.simple.id\n  virtual_router_name = aws_appmesh_virtual_router.serviceb.name\n\n  spec {\n    http_route {\n      match {\n        prefix = \"/\"\n      }\n\n      retry_policy {\n        http_retry_events = [\n          \"server-error\",\n        ]\n        max_retries = 1\n\n        per_retry_timeout {\n          unit  = \"s\"\n          value = 15\n        }\n      }\n\n      action {\n        weighted_target {\n          virtual_node = aws_appmesh_virtual_node.serviceb.name\n          weight       = 100\n        }\n      }\n    }\n  }\n}\n```\n\n### TCP Routing\n\n```terraform\nresource \"aws_appmesh_route\" \"serviceb\" {\n  name                = \"serviceB-route\"\n  mesh_name           = aws_appmesh_mesh.simple.id\n  virtual_router_name = aws_appmesh_virtual_router.serviceb.name\n\n  spec {\n    tcp_route {\n      action {\n        weighted_target {\n          virtual_node = aws_appmesh_virtual_node.serviceb1.name\n          weight       = 100\n        }\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to use for the route. Must be between 1 and 255 characters in length.\n* `mesh_name` - (Required) The name of the service mesh in which to create the route. Must be between 1 and 255 characters in length.\n* `mesh_owner` - (Optional) The AWS account ID of the service mesh's owner. Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `virtual_router_name` - (Required) The name of the virtual router in which to create the route. Must be between 1 and 255 characters in length.\n* `spec` - (Required) The route specification to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `spec` object supports the following:\n\n* `grpc_route` - (Optional) The gRPC routing information for the route.\n* `http2_route` - (Optional) The HTTP/2 routing information for the route.\n* `http_route` - (Optional) The HTTP routing information for the route.\n* `priority` - (Optional) The priority for the route, between `0` and `1000`.\nRoutes are matched based on the specified value, where `0` is the highest priority.\n* `tcp_route` - (Optional) The TCP routing information for the route.\n\nThe `grpc_route` object supports the following:\n\n* `action` - (Required) The action to take if a match is determined.\n* `match` - (Required) The criteria for determining an gRPC request match.\n* `retry_policy` - (Optional) The retry policy.\n* `timeout` - (Optional) The types of timeouts.\n\nThe `http2_route` and `http_route` objects supports the following:\n\n* `action` - (Required) The action to take if a match is determined.\n* `match` - (Required) The criteria for determining an HTTP request match.\n* `retry_policy` - (Optional) The retry policy.\n* `timeout` - (Optional) The types of timeouts.\n\nThe `tcp_route` object supports the following:\n\n* `action` - (Required) The action to take if a match is determined.\n* `timeout` - (Optional) The types of timeouts.\n\nThe `action` object supports the following:\n\n* `weighted_target` - (Required) The targets that traffic is routed to when a request matches the route.\nYou can specify one or more targets and their relative weights with which to distribute traffic.\n\nThe `timeout` object supports the following:\n\n* `idle` - (Optional) The idle timeout. An idle timeout bounds the amount of time that a connection may be idle.\n\nThe `idle` object supports the following:\n\n* `unit` - (Required) The unit of time. Valid values: `ms`, `s`.\n* `value` - (Required) The number of time units. Minimum value of `0`.\n\nThe `grpc_route`'s `match` object supports the following:\n\n* `metadata` - (Optional) The data to match from the gRPC request.\n* `method_name` - (Optional) The method name to match from the request. If you specify a name, you must also specify a `service_name`.\n* `service_name` - (Optional) The fully qualified domain name for the service to match from the request.\n\nThe `metadata` object supports the following:\n\n* `name` - (Required) The name of the route. Must be between 1 and 50 characters in length.\n* `invert` - (Optional) If `true`, the match is on the opposite of the `match` criteria. Default is `false`.\n* `match` - (Optional) The data to match from the request.\n\nThe `metadata`'s `match` object supports the following:\n\n* `exact` - (Optional) The value sent by the client must match the specified value exactly. Must be between 1 and 255 characters in length.\n* `prefix` - (Optional) The value sent by the client must begin with the specified characters. Must be between 1 and 255 characters in length.\n* `range`- (Optional) The object that specifies the range of numbers that the value sent by the client must be included in.\n* `regex` - (Optional) The value sent by the client must include the specified characters. Must be between 1 and 255 characters in length.\n* `suffix` - (Optional) The value sent by the client must end with the specified characters. Must be between 1 and 255 characters in length.\n\nThe `grpc_route`'s `retry_policy` object supports the following:\n\n* `grpc_retry_events` - (Optional) List of gRPC retry events.\nValid values: `cancelled`, `deadline-exceeded`, `internal`, `resource-exhausted`, `unavailable`.\n* `http_retry_events` - (Optional) List of HTTP retry events.\nValid values: `client-error` (HTTP status code 409), `gateway-error` (HTTP status codes 502, 503, and 504), `server-error` (HTTP status codes 500, 501, 502, 503, 504, 505, 506, 507, 508, 510, and 511), `stream-error` (retry on refused stream).\n* `max_retries` - (Required) The maximum number of retries.\n* `per_retry_timeout` - (Required) The per-retry timeout.\n* `tcp_retry_events` - (Optional) List of TCP retry events. The only valid value is `connection-error`.\n\nThe `grpc_route`'s `timeout` object supports the following:\n\n* `idle` - (Optional) The idle timeout. An idle timeout bounds the amount of time that a connection may be idle.\n* `per_request` - (Optional) The per request timeout.\n\nThe `idle` and `per_request` objects support the following:\n\n* `unit` - (Required) The unit of time. Valid values: `ms`, `s`.\n* `value` - (Required) The number of time units. Minimum value of `0`.\n\nThe `http2_route` and `http_route`'s `match` object supports the following:\n\n* `prefix` - (Required) Specifies the path with which to match requests.\nThis parameter must always start with /, which by itself matches all requests to the virtual router service name.\n* `header` - (Optional) The client request headers to match on.\n* `method` - (Optional) The client request header method to match on. Valid values: `GET`, `HEAD`, `POST`, `PUT`, `DELETE`, `CONNECT`, `OPTIONS`, `TRACE`, `PATCH`.\n* `scheme` - (Optional) The client request header scheme to match on. Valid values: `http`, `https`.\n\nThe `http2_route` and `http_route`'s `retry_policy` object supports the following:\n\n* `http_retry_events` - (Optional) List of HTTP retry events.\nValid values: `client-error` (HTTP status code 409), `gateway-error` (HTTP status codes 502, 503, and 504), `server-error` (HTTP status codes 500, 501, 502, 503, 504, 505, 506, 507, 508, 510, and 511), `stream-error` (retry on refused stream).\n* `max_retries` - (Required) The maximum number of retries.\n* `per_retry_timeout` - (Required) The per-retry timeout.\n* `tcp_retry_events` - (Optional) List of TCP retry events. The only valid value is `connection-error`.\n\nYou must specify at least one value for `http_retry_events`, or at least one value for `tcp_retry_events`.\n\nThe `http2_route` and `http_route`'s `timeout` object supports the following:\n\n* `idle` - (Optional) The idle timeout. An idle timeout bounds the amount of time that a connection may be idle.\n* `per_request` - (Optional) The per request timeout.\n\nThe `idle` and `per_request` objects support the following:\n\n* `unit` - (Required) The unit of time. Valid values: `ms`, `s`.\n* `value` - (Required) The number of time units. Minimum value of `0`.\n\nThe `per_retry_timeout` object supports the following:\n\n* `unit` - (Required) Retry unit. Valid values: `ms`, `s`.\n* `value` - (Required) Retry value.\n\nThe `weighted_target` object supports the following:\n\n* `virtual_node` - (Required) The virtual node to associate with the weighted target. Must be between 1 and 255 characters in length.\n* `weight` - (Required) The relative weight of the weighted target. An integer between 0 and 100.\n\nThe `header` object supports the following:\n\n* `name` - (Required) A name for the HTTP header in the client request that will be matched on.\n* `invert` - (Optional) If `true`, the match is on the opposite of the `match` method and value. Default is `false`.\n* `match` - (Optional) The method and value to match the header value sent with a request. Specify one match method.\n\nThe `header`'s `match` object supports the following:\n\n* `exact` - (Optional) The header value sent by the client must match the specified value exactly.\n* `prefix` - (Optional) The header value sent by the client must begin with the specified characters.\n* `range`- (Optional) The object that specifies the range of numbers that the header value sent by the client must be included in.\n* `regex` - (Optional) The header value sent by the client must include the specified characters.\n* `suffix` - (Optional) The header value sent by the client must end with the specified characters.\n\nThe `range` object supports the following:\n\n* `end` - (Required) The end of the range.\n* `start` - (Requited) The start of the range.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the route.\n* `arn` - The ARN of the route.\n* `created_date` - The creation date of the route.\n* `last_updated_date` - The last update date of the route.\n* `resource_owner` - The resource owner's AWS account ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Mesh virtual routes can be imported using `mesh_name` and `virtual_router_name` together with the route's `name`,\ne.g.,\n\n```\n$ terraform import aws_appmesh_route.serviceb simpleapp/serviceB/serviceB-route\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "appmesh_route.html"
  },
  "appmesh_virtual_gateway.html": {
    "subcategory": "AppMesh",
    "layout": "aws",
    "page_title": "AWS: aws_appmesh_virtual_gateway",
    "description": "Provides an AWS App Mesh virtual gateway resource.",
    "preview": "# Resource: aws_appmesh_virtual_gateway\n\nProvides an AWS App Mesh …",
    "content": "\n\n# Resource: aws_appmesh_virtual_gateway\n\nProvides an AWS App Mesh virtual gateway resource.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_appmesh_virtual_gateway\" \"example\" {\n  name      = \"example-virtual-gateway\"\n  mesh_name = \"example-service-mesh\"\n\n  spec {\n    listener {\n      port_mapping {\n        port     = 8080\n        protocol = \"http\"\n      }\n    }\n  }\n\n  tags = {\n    Environment = \"test\"\n  }\n}\n```\n\n### Access Logs and TLS\n\n```terraform\nresource \"aws_appmesh_virtual_gateway\" \"example\" {\n  name      = \"example-virtual-gateway\"\n  mesh_name = \"example-service-mesh\"\n\n  spec {\n    listener {\n      port_mapping {\n        port     = 8080\n        protocol = \"http\"\n      }\n\n      tls {\n        certificate {\n          acm {\n            certificate_arn = aws_acm_certificate.example.arn\n          }\n        }\n\n        mode = \"STRICT\"\n      }\n    }\n\n    logging {\n      access_log {\n        file {\n          path = \"/var/log/access.log\"\n        }\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to use for the virtual gateway. Must be between 1 and 255 characters in length.\n* `mesh_name` - (Required) The name of the service mesh in which to create the virtual gateway. Must be between 1 and 255 characters in length.\n* `mesh_owner` - (Optional) The AWS account ID of the service mesh's owner. Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `spec` - (Required) The virtual gateway specification to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `spec` object supports the following:\n\n* `listener` - (Required) The listeners that the mesh endpoint is expected to receive inbound traffic from. You can specify one listener.\n* `backend_defaults` - (Optional) The defaults for backends.\n* `logging` - (Optional) The inbound and outbound access logging information for the virtual gateway.\n\nThe `backend_defaults` object supports the following:\n\n* `client_policy` - (Optional) The default client policy for virtual gateway backends.\n\nThe `client_policy` object supports the following:\n\n* `tls` - (Optional) The Transport Layer Security (TLS) client policy.\n\nThe `tls` object supports the following:\n\n* `certificate` (Optional) The virtual gateway's client's Transport Layer Security (TLS) certificate.\n* `enforce` - (Optional) Whether the policy is enforced. Default is `true`.\n* `ports` - (Optional) One or more ports that the policy is enforced for.\n* `validation` - (Required) The TLS validation context.\n\nThe `certificate` object supports the following:\n\n* `file` - (Optional) A local file certificate.\n* `sds` - (Optional) A [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate chain for the certificate.\n* `private_key` - (Required) The private key for a certificate stored on the file system of the mesh endpoint that the proxy is running on.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret secret requested from the Secret Discovery Service provider representing Transport Layer Security (TLS) materials like a certificate or certificate chain.\n\nThe `validation` object supports the following:\n\n* `subject_alternative_names` - (Optional) The SANs for a virtual gateway's listener's Transport Layer Security (TLS) validation context.\n* `trust` - (Required) The TLS validation context trust.\n\nThe `subject_alternative_names` object supports the following:\n\n* `match` - (Required) The criteria for determining a SAN's match.\n\nThe `match` object supports the following:\n\n* `exact` - (Required) The values sent must match the specified values exactly.\n\nThe `trust` object supports the following:\n\n* `acm` - (Optional) The TLS validation context trust for an AWS Certificate Manager (ACM) certificate.\n* `file` - (Optional) The TLS validation context trust for a local file certificate.\n* `sds` - (Optional) The TLS validation context trust for a [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `acm` object supports the following:\n\n* `certificate_authority_arns` - (Required) One or more ACM Amazon Resource Name (ARN)s.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate trust chain for a certificate stored on the file system of the mesh endpoint that the proxy is running on. Must be between 1 and 255 characters in length.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret for a virtual gateway's Transport Layer Security (TLS) Secret Discovery Service validation context trust.\n\nThe `listener` object supports the following:\n\n* `port_mapping` - (Required) The port mapping information for the listener.\n* `connection_pool` - (Optional) The connection pool information for the listener.\n* `health_check` - (Optional) The health check information for the listener.\n* `tls` - (Optional) The Transport Layer Security (TLS) properties for the listener\n\nThe `logging` object supports the following:\n\n* `access_log` - (Optional) The access log configuration for a virtual gateway.\n\nThe `access_log` object supports the following:\n\n* `file` - (Optional) The file object to send virtual gateway access logs to.\n\nThe `file` object supports the following:\n\n* `path` - (Required) The file path to write access logs to. You can use `/dev/stdout` to send access logs to standard out. Must be between 1 and 255 characters in length.\n\nThe `port_mapping` object supports the following:\n\n* `port` - (Required) The port used for the port mapping.\n* `protocol` - (Required) The protocol used for the port mapping. Valid values are `http`, `http2`, `tcp` and `grpc`.\n\nThe `connection_pool` object supports the following:\n\n* `grpc` - (Optional) Connection pool information for gRPC listeners.\n* `http` - (Optional) Connection pool information for HTTP listeners.\n* `http2` - (Optional) Connection pool information for HTTP2 listeners.\n\nThe `grpc` connection pool object supports the following:\n\n* `max_requests` - (Required) Maximum number of inflight requests Envoy can concurrently support across hosts in upstream cluster. Minimum value of `1`.\n\nThe `http` connection pool object supports the following:\n\n* `max_connections` - (Required) Maximum number of outbound TCP connections Envoy can establish concurrently with all hosts in upstream cluster. Minimum value of `1`.\n* `max_pending_requests` - (Optional) Number of overflowing requests after `max_connections` Envoy will queue to upstream cluster. Minimum value of `1`.\n\nThe `http2` connection pool object supports the following:\n\n* `max_requests` - (Required) Maximum number of inflight requests Envoy can concurrently support across hosts in upstream cluster. Minimum value of `1`.\n\nThe `health_check` object supports the following:\n\n* `healthy_threshold` - (Required) The number of consecutive successful health checks that must occur before declaring listener healthy.\n* `interval_millis`- (Required) The time period in milliseconds between each health check execution.\n* `protocol` - (Required) The protocol for the health check request. Valid values are `http`, `http2`, and `grpc`.\n* `timeout_millis` - (Required) The amount of time to wait when receiving a response from the health check, in milliseconds.\n* `unhealthy_threshold` - (Required) The number of consecutive failed health checks that must occur before declaring a virtual gateway unhealthy.\n* `path` - (Optional) The destination path for the health check request. This is only required if the specified protocol is `http` or `http2`.\n* `port` - (Optional) The destination port for the health check request. This port must match the port defined in the `port_mapping` for the listener.\n\nThe `tls` object supports the following:\n\n* `certificate` - (Required) The listener's TLS certificate.\n* `mode`- (Required) The listener's TLS mode. Valid values: `DISABLED`, `PERMISSIVE`, `STRICT`.\n* `validation`- (Optional) The listener's Transport Layer Security (TLS) validation context.\n\nThe `certificate` object supports the following:\n\n* `acm` - (Optional) An AWS Certificate Manager (ACM) certificate.\n* `file` - (optional) A local file certificate.\n* `sds` - (Optional) A [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `acm` object supports the following:\n\n* `certificate_arn` - (Required) The Amazon Resource Name (ARN) for the certificate.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate chain for the certificate. Must be between 1 and 255 characters in length.\n* `private_key` - (Required) The private key for a certificate stored on the file system of the mesh endpoint that the proxy is running on. Must be between 1 and 255 characters in length.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret secret requested from the Secret Discovery Service provider representing Transport Layer Security (TLS) materials like a certificate or certificate chain.\n\nThe `validation` object supports the following:\n\n* `subject_alternative_names` - (Optional) The SANs for a virtual gateway's listener's Transport Layer Security (TLS) validation context.\n* `trust` - (Required) The TLS validation context trust.\n\nThe `subject_alternative_names` object supports the following:\n\n* `match` - (Required) The criteria for determining a SAN's match.\n\nThe `match` object supports the following:\n\n* `exact` - (Required) The values sent must match the specified values exactly.\n\nThe `trust` object supports the following:\n\n* `file` - (Optional) The TLS validation context trust for a local file certificate.\n* `sds` - (Optional) The TLS validation context trust for a [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate trust chain for a certificate stored on the file system of the mesh endpoint that the proxy is running on. Must be between 1 and 255 characters in length.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret for a virtual gateway's Transport Layer Security (TLS) Secret Discovery Service validation context trust.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual gateway.\n* `arn` - The ARN of the virtual gateway.\n* `created_date` - The creation date of the virtual gateway.\n* `last_updated_date` - The last update date of the virtual gateway.\n* `resource_owner` - The resource owner's AWS account ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Mesh virtual gateway can be imported using `mesh_name` together with the virtual gateway's `name`,\ne.g.,\n\n```\n$ terraform import aws_appmesh_virtual_gateway.example mesh/gw1\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "appmesh_virtual_gateway.html"
  },
  "appmesh_virtual_node.html": {
    "subcategory": "AppMesh",
    "layout": "aws",
    "page_title": "AWS: aws_appmesh_virtual_node",
    "description": "Provides an AWS App Mesh virtual node resource.",
    "preview": "# Resource: aws_appmesh_virtual_node\n\nProvides an AWS App Mesh …",
    "content": "\n\n# Resource: aws_appmesh_virtual_node\n\nProvides an AWS App Mesh virtual node resource.\n\n## Breaking Changes\n\nBecause of backward incompatible API changes (read [here](https://github.com/awslabs/aws-app-mesh-examples/issues/92)), `aws_appmesh_virtual_node` resource definitions created with provider versions earlier than v2.3.0 will need to be modified:\n\n* Rename the `service_name` attribute of the `dns` object to `hostname`.\n\n* Replace the `backends` attribute of the `spec` object with one or more `backend` configuration blocks,\nsetting `virtual_service_name` to the name of the service.\n\nThe Terraform state associated with existing resources will automatically be migrated.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_appmesh_virtual_node\" \"serviceb1\" {\n  name      = \"serviceBv1\"\n  mesh_name = aws_appmesh_mesh.simple.id\n\n  spec {\n    backend {\n      virtual_service {\n        virtual_service_name = \"servicea.simpleapp.local\"\n      }\n    }\n\n    listener {\n      port_mapping {\n        port     = 8080\n        protocol = \"http\"\n      }\n    }\n\n    service_discovery {\n      dns {\n        hostname = \"serviceb.simpleapp.local\"\n      }\n    }\n  }\n}\n```\n\n### AWS Cloud Map Service Discovery\n\n```terraform\nresource \"aws_service_discovery_http_namespace\" \"example\" {\n  name = \"example-ns\"\n}\n\nresource \"aws_appmesh_virtual_node\" \"serviceb1\" {\n  name      = \"serviceBv1\"\n  mesh_name = aws_appmesh_mesh.simple.id\n\n  spec {\n    backend {\n      virtual_service {\n        virtual_service_name = \"servicea.simpleapp.local\"\n      }\n    }\n\n    listener {\n      port_mapping {\n        port     = 8080\n        protocol = \"http\"\n      }\n    }\n\n    service_discovery {\n      aws_cloud_map {\n        attributes = {\n          stack = \"blue\"\n        }\n\n        service_name   = \"serviceb1\"\n        namespace_name = aws_service_discovery_http_namespace.example.name\n      }\n    }\n  }\n}\n```\n\n### Listener Health Check\n\n```terraform\nresource \"aws_appmesh_virtual_node\" \"serviceb1\" {\n  name      = \"serviceBv1\"\n  mesh_name = aws_appmesh_mesh.simple.id\n\n  spec {\n    backend {\n      virtual_service {\n        virtual_service_name = \"servicea.simpleapp.local\"\n      }\n    }\n\n    listener {\n      port_mapping {\n        port     = 8080\n        protocol = \"http\"\n      }\n\n      health_check {\n        protocol            = \"http\"\n        path                = \"/ping\"\n        healthy_threshold   = 2\n        unhealthy_threshold = 2\n        timeout_millis      = 2000\n        interval_millis     = 5000\n      }\n    }\n\n    service_discovery {\n      dns {\n        hostname = \"serviceb.simpleapp.local\"\n      }\n    }\n  }\n}\n```\n\n### Logging\n\n```terraform\nresource \"aws_appmesh_virtual_node\" \"serviceb1\" {\n  name      = \"serviceBv1\"\n  mesh_name = aws_appmesh_mesh.simple.id\n\n  spec {\n    backend {\n      virtual_service {\n        virtual_service_name = \"servicea.simpleapp.local\"\n      }\n    }\n\n    listener {\n      port_mapping {\n        port     = 8080\n        protocol = \"http\"\n      }\n    }\n\n    service_discovery {\n      dns {\n        hostname = \"serviceb.simpleapp.local\"\n      }\n    }\n\n    logging {\n      access_log {\n        file {\n          path = \"/dev/stdout\"\n        }\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to use for the virtual node. Must be between 1 and 255 characters in length.\n* `mesh_name` - (Required) The name of the service mesh in which to create the virtual node. Must be between 1 and 255 characters in length.\n* `mesh_owner` - (Optional) The AWS account ID of the service mesh's owner. Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `spec` - (Required) The virtual node specification to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `spec` object supports the following:\n\n* `backend` - (Optional) The backends to which the virtual node is expected to send outbound traffic.\n* `backend_defaults` - (Optional) The defaults for backends.\n* `listener` - (Optional) The listeners from which the virtual node is expected to receive inbound traffic.\n* `logging` - (Optional) The inbound and outbound access logging information for the virtual node.\n* `service_discovery` - (Optional) The service discovery information for the virtual node.\n\nThe `backend` object supports the following:\n\n* `virtual_service` - (Required) Specifies a virtual service to use as a backend for a virtual node.\n\nThe `virtual_service` object supports the following:\n\n* `client_policy` - (Optional) The client policy for the backend.\n* `virtual_service_name` - (Required) The name of the virtual service that is acting as a virtual node backend. Must be between 1 and 255 characters in length.\n\nThe `client_policy` object supports the following:\n\n* `tls` - (Optional) The Transport Layer Security (TLS) client policy.\n\nThe `tls` object supports the following:\n\n* `certificate` (Optional) The virtual node's client's Transport Layer Security (TLS) certificate.\n* `enforce` - (Optional) Whether the policy is enforced. Default is `true`.\n* `ports` - (Optional) One or more ports that the policy is enforced for.\n* `validation` - (Required) The TLS validation context.\n\nThe `certificate` object supports the following:\n\n* `file` - (Optional) A local file certificate.\n* `sds` - (Optional) A [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate chain for the certificate.\n* `private_key` - (Required) The private key for a certificate stored on the file system of the mesh endpoint that the proxy is running on.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret secret requested from the Secret Discovery Service provider representing Transport Layer Security (TLS) materials like a certificate or certificate chain.\n\nThe `validation` object supports the following:\n\n* `subject_alternative_names` - (Optional) The SANs for a TLS validation context.\n* `trust` - (Required) The TLS validation context trust.\n\nThe `subject_alternative_names` object supports the following:\n\n* `match` - (Required) The criteria for determining a SAN's match.\n\nThe `match` object supports the following:\n\n* `exact` - (Required) The values sent must match the specified values exactly.\n\nThe `trust` object supports the following:\n\n* `acm` - (Optional) The TLS validation context trust for an AWS Certificate Manager (ACM) certificate.\n* `file` - (Optional) The TLS validation context trust for a local file certificate.\n* `sds` - (Optional) The TLS validation context trust for a [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `acm` object supports the following:\n\n* `certificate_authority_arns` - (Required) One or more ACM Amazon Resource Name (ARN)s.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate trust chain for a certificate stored on the file system of the virtual node that the proxy is running on. Must be between 1 and 255 characters in length.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret secret requested from the Secret Discovery Service provider representing Transport Layer Security (TLS) materials like a certificate or certificate chain.\n\nThe `backend_defaults` object supports the following:\n\n* `client_policy` - (Optional) The default client policy for virtual service backends. See above for details.\n\nThe `listener` object supports the following:\n\n* `port_mapping` - (Required) The port mapping information for the listener.\n* `connection_pool` - (Optional) The connection pool information for the listener.\n* `health_check` - (Optional) The health check information for the listener.\n* `outlier_detection` - (Optional) The outlier detection information for the listener.\n* `timeout` - (Optional) Timeouts for different protocols.\n* `tls` - (Optional) The Transport Layer Security (TLS) properties for the listener\n\nThe `logging` object supports the following:\n\n* `access_log` - (Optional) The access log configuration for a virtual node.\n\nThe `access_log` object supports the following:\n\n* `file` - (Optional) The file object to send virtual node access logs to.\n\nThe `file` object supports the following:\n\n* `path` - (Required) The file path to write access logs to. You can use `/dev/stdout` to send access logs to standard out. Must be between 1 and 255 characters in length.\n\nThe `service_discovery` object supports the following:\n\n* `aws_cloud_map` - (Optional) Specifies any AWS Cloud Map information for the virtual node.\n* `dns` - (Optional) Specifies the DNS service name for the virtual node.\n\nThe `aws_cloud_map` object supports the following:\n\n* `attributes` - (Optional) A string map that contains attributes with values that you can use to filter instances by any custom attribute that you specified when you registered the instance. Only instances that match all of the specified key/value pairs will be returned.\n* `namespace_name` - (Required) The name of the AWS Cloud Map namespace to use.\nUse the [`aws_service_discovery_http_namespace`](/docs/providers/aws/r/service_discovery_http_namespace.html) resource to configure a Cloud Map namespace. Must be between 1 and 1024 characters in length.\n* `service_name` - (Required) The name of the AWS Cloud Map service to use. Use the [`aws_service_discovery_service`](/docs/providers/aws/r/service_discovery_service.html) resource to configure a Cloud Map service. Must be between 1 and 1024 characters in length.\n\nThe `dns` object supports the following:\n\n* `hostname` - (Required) The DNS host name for your virtual node.\n\nThe `port_mapping` object supports the following:\n\n* `port` - (Required) The port used for the port mapping.\n* `protocol` - (Required) The protocol used for the port mapping. Valid values are `http`, `http2`, `tcp` and `grpc`.\n\nThe `connection_pool` object supports the following:\n\n* `grpc` - (Optional) Connection pool information for gRPC listeners.\n* `http` - (Optional) Connection pool information for HTTP listeners.\n* `http2` - (Optional) Connection pool information for HTTP2 listeners.\n* `tcp` - (Optional) Connection pool information for TCP listeners.\n\nThe `grpc` connection pool object supports the following:\n\n* `max_requests` - (Required) Maximum number of inflight requests Envoy can concurrently support across hosts in upstream cluster. Minimum value of `1`.\n\nThe `http` connection pool object supports the following:\n\n* `max_connections` - (Required) Maximum number of outbound TCP connections Envoy can establish concurrently with all hosts in upstream cluster. Minimum value of `1`.\n* `max_pending_requests` - (Optional) Number of overflowing requests after `max_connections` Envoy will queue to upstream cluster. Minimum value of `1`.\n\nThe `http2` connection pool object supports the following:\n\n* `max_requests` - (Required) Maximum number of inflight requests Envoy can concurrently support across hosts in upstream cluster. Minimum value of `1`.\n\nThe `tcp` connection pool object supports the following:\n\n* `max_connections` - (Required) Maximum number of outbound TCP connections Envoy can establish concurrently with all hosts in upstream cluster. Minimum value of `1`.\n\nThe `health_check` object supports the following:\n\n* `healthy_threshold` - (Required) The number of consecutive successful health checks that must occur before declaring listener healthy.\n* `interval_millis`- (Required) The time period in milliseconds between each health check execution.\n* `protocol` - (Required) The protocol for the health check request. Valid values are `http`, `http2`, `tcp` and `grpc`.\n* `timeout_millis` - (Required) The amount of time to wait when receiving a response from the health check, in milliseconds.\n* `unhealthy_threshold` - (Required) The number of consecutive failed health checks that must occur before declaring a virtual node unhealthy.\n* `path` - (Optional) The destination path for the health check request. This is only required if the specified protocol is `http` or `http2`.\n* `port` - (Optional) The destination port for the health check request. This port must match the port defined in the `port_mapping` for the listener.\n\nThe `outlier_detection` object supports the following:\n\n* `base_ejection_duration` - (Required) The base amount of time for which a host is ejected.\n* `interval` - (Required) The time interval between ejection sweep analysis.\n* `max_ejection_percent` - (Required) Maximum percentage of hosts in load balancing pool for upstream service that can be ejected. Will eject at least one host regardless of the value.\nMinimum value of `0`. Maximum value of `100`.\n* `max_server_errors` - (Required) Number of consecutive `5xx` errors required for ejection. Minimum value of `1`.\n\nThe `base_ejection_duration` and `interval` objects support the following:\n\n* `unit` - (Required) The unit of time. Valid values: `ms`, `s`.\n* `value` - (Required) The number of time units. Minimum value of `0`.\n\nThe `timeout` object supports the following:\n\n* `grpc` - (Optional) Timeouts for gRPC listeners.\n* `http` - (Optional) Timeouts for HTTP listeners.\n* `http2` - (Optional) Timeouts for HTTP2 listeners.\n* `tcp` - (Optional) Timeouts for TCP listeners.\n\nThe `grpc` timeout object supports the following:\n\n* `idle` - (Optional) The idle timeout. An idle timeout bounds the amount of time that a connection may be idle.\n* `per_request` - (Optional) The per request timeout.\n\nThe `idle` and `per_request` objects support the following:\n\n* `unit` - (Required) The unit of time. Valid values: `ms`, `s`.\n* `value` - (Required) The number of time units. Minimum value of `0`.\n\nThe `http` and `http2` timeout objects support the following:\n\n* `idle` - (Optional) The idle timeout. An idle timeout bounds the amount of time that a connection may be idle.\n* `per_request` - (Optional) The per request timeout.\n\nThe `idle` and `per_request` objects support the following:\n\n* `unit` - (Required) The unit of time. Valid values: `ms`, `s`.\n* `value` - (Required) The number of time units. Minimum value of `0`.\n\nThe `tcp` timeout object supports the following:\n\n* `idle` - (Optional) The idle timeout. An idle timeout bounds the amount of time that a connection may be idle.\n\nThe `idle` object supports the following:\n\n* `unit` - (Required) The unit of time. Valid values: `ms`, `s`.\n* `value` - (Required) The number of time units. Minimum value of `0`.\n\nThe `tls` object supports the following:\n\n* `certificate` - (Required) The listener's TLS certificate.\n* `mode`- (Required) The listener's TLS mode. Valid values: `DISABLED`, `PERMISSIVE`, `STRICT`.\n* `validation`- (Optional) The listener's Transport Layer Security (TLS) validation context.\n\nThe `certificate` object supports the following:\n\n* `acm` - (Optional) An AWS Certificate Manager (ACM) certificate.\n* `file` - (optional) A local file certificate.\n* `sds` - (Optional) A [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `acm` object supports the following:\n\n* `certificate_arn` - (Required) The Amazon Resource Name (ARN) for the certificate.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate chain for the certificate. Must be between 1 and 255 characters in length.\n* `private_key` - (Required) The private key for a certificate stored on the file system of the virtual node that the proxy is running on. Must be between 1 and 255 characters in length.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret secret requested from the Secret Discovery Service provider representing Transport Layer Security (TLS) materials like a certificate or certificate chain.\n\nThe `validation` object supports the following:\n\n* `subject_alternative_names` - (Optional) The SANs for a TLS validation context.\n* `trust` - (Required) The TLS validation context trust.\n\nThe `subject_alternative_names` object supports the following:\n\n* `match` - (Required) The criteria for determining a SAN's match.\n\nThe `match` object supports the following:\n\n* `exact` - (Required) The values sent must match the specified values exactly.\n\nThe `trust` object supports the following:\n\n* `file` - (Optional) The TLS validation context trust for a local file certificate.\n* `sds` - (Optional) The TLS validation context trust for a [Secret Discovery Service](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) certificate.\n\nThe `file` object supports the following:\n\n* `certificate_chain` - (Required) The certificate trust chain for a certificate stored on the file system of the mesh endpoint that the proxy is running on. Must be between 1 and 255 characters in length.\n\nThe `sds` object supports the following:\n\n* `secret_name` - (Required) The name of the secret for a virtual node's Transport Layer Security (TLS) Secret Discovery Service validation context trust.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual node.\n* `arn` - The ARN of the virtual node.\n* `created_date` - The creation date of the virtual node.\n* `last_updated_date` - The last update date of the virtual node.\n* `resource_owner` - The resource owner's AWS account ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Mesh virtual nodes can be imported using `mesh_name` together with the virtual node's `name`,\ne.g.,\n\n```\n$ terraform import aws_appmesh_virtual_node.serviceb1 simpleapp/serviceBv1\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "appmesh_virtual_node.html"
  },
  "appmesh_virtual_router.html": {
    "subcategory": "AppMesh",
    "layout": "aws",
    "page_title": "AWS: aws_appmesh_virtual_router",
    "description": "Provides an AWS App Mesh virtual router resource.",
    "preview": "# Resource: aws_appmesh_virtual_router\n\nProvides an AWS App Mesh …",
    "content": "\n\n# Resource: aws_appmesh_virtual_router\n\nProvides an AWS App Mesh virtual router resource.\n\n## Breaking Changes\n\nBecause of backward incompatible API changes (read [here](https://github.com/awslabs/aws-app-mesh-examples/issues/92) and [here](https://github.com/awslabs/aws-app-mesh-examples/issues/94)), `aws_appmesh_virtual_router` resource definitions created with provider versions earlier than v2.3.0 will need to be modified:\n\n* Remove service `service_names` from the `spec` argument.\nAWS has created a `aws_appmesh_virtual_service` resource for each of service names.\nThese resource can be imported using `terraform import`.\n\n* Add a `listener` configuration block to the `spec` argument.\n\nThe Terraform state associated with existing resources will automatically be migrated.\n\n## Example Usage\n\n```terraform\nresource \"aws_appmesh_virtual_router\" \"serviceb\" {\n  name      = \"serviceB\"\n  mesh_name = aws_appmesh_mesh.simple.id\n\n  spec {\n    listener {\n      port_mapping {\n        port     = 8080\n        protocol = \"http\"\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to use for the virtual router. Must be between 1 and 255 characters in length.\n* `mesh_name` - (Required) The name of the service mesh in which to create the virtual router. Must be between 1 and 255 characters in length.\n* `mesh_owner` - (Optional) The AWS account ID of the service mesh's owner. Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `spec` - (Required) The virtual router specification to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `spec` object supports the following:\n\n* `listener` - (Required) The listeners that the virtual router is expected to receive inbound traffic from.\nCurrently only one listener is supported per virtual router.\n\nThe `listener` object supports the following:\n\n* `port_mapping` - (Required) The port mapping information for the listener.\n\nThe `port_mapping` object supports the following:\n\n* `port` - (Required) The port used for the port mapping.\n* `protocol` - (Required) The protocol used for the port mapping. Valid values are `http`,`http2`, `tcp` and `grpc`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual router.\n* `arn` - The ARN of the virtual router.\n* `created_date` - The creation date of the virtual router.\n* `last_updated_date` - The last update date of the virtual router.\n* `resource_owner` - The resource owner's AWS account ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Mesh virtual routers can be imported using `mesh_name` together with the virtual router's `name`,\ne.g.,\n\n```\n$ terraform import aws_appmesh_virtual_router.serviceb simpleapp/serviceB\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "appmesh_virtual_router.html"
  },
  "appmesh_virtual_service.html": {
    "subcategory": "AppMesh",
    "layout": "aws",
    "page_title": "AWS: aws_appmesh_virtual_service",
    "description": "Provides an AWS App Mesh virtual service resource.",
    "preview": "# Resource: aws_appmesh_virtual_service\n\nProvides an AWS App Mesh …",
    "content": "\n\n# Resource: aws_appmesh_virtual_service\n\nProvides an AWS App Mesh virtual service resource.\n\n## Example Usage\n\n### Virtual Node Provider\n\n```terraform\nresource \"aws_appmesh_virtual_service\" \"servicea\" {\n  name      = \"servicea.simpleapp.local\"\n  mesh_name = aws_appmesh_mesh.simple.id\n\n  spec {\n    provider {\n      virtual_node {\n        virtual_node_name = aws_appmesh_virtual_node.serviceb1.name\n      }\n    }\n  }\n}\n```\n\n### Virtual Router Provider\n\n```terraform\nresource \"aws_appmesh_virtual_service\" \"servicea\" {\n  name      = \"servicea.simpleapp.local\"\n  mesh_name = aws_appmesh_mesh.simple.id\n\n  spec {\n    provider {\n      virtual_router {\n        virtual_router_name = aws_appmesh_virtual_router.serviceb.name\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to use for the virtual service. Must be between 1 and 255 characters in length.\n* `mesh_name` - (Required) The name of the service mesh in which to create the virtual service. Must be between 1 and 255 characters in length.\n* `mesh_owner` - (Optional) The AWS account ID of the service mesh's owner. Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `spec` - (Required) The virtual service specification to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `spec` object supports the following:\n\n* `provider`- (Optional) The App Mesh object that is acting as the provider for a virtual service. You can specify a single virtual node or virtual router.\n\nThe `provider` object supports the following:\n\n* `virtual_node` - (Optional) The virtual node associated with a virtual service.\n* `virtual_router` - (Optional) The virtual router associated with a virtual service.\n\nThe `virtual_node` object supports the following:\n\n* `virtual_node_name` - (Required) The name of the virtual node that is acting as a service provider. Must be between 1 and 255 characters in length.\n\nThe `virtual_router` object supports the following:\n\n* `virtual_router_name` - (Required) The name of the virtual router that is acting as a service provider. Must be between 1 and 255 characters in length.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual service.\n* `arn` - The ARN of the virtual service.\n* `created_date` - The creation date of the virtual service.\n* `last_updated_date` - The last update date of the virtual service.\n* `resource_owner` - The resource owner's AWS account ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Mesh virtual services can be imported using `mesh_name` together with the virtual service's `name`,\ne.g.,\n\n```\n$ terraform import aws_appmesh_virtual_service.servicea simpleapp/servicea.simpleapp.local\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "appmesh_virtual_service.html"
  },
  "apprunner_auto_scaling_configuration_version.html": {
    "subcategory": "App Runner",
    "layout": "aws",
    "page_title": "AWS: aws_apprunner_auto_scaling_configuration_version",
    "description": "Manages an App Runner AutoScaling Configuration Version.",
    "preview": "# Resource: aws_apprunner_auto_scaling_configuration_version\n …",
    "content": "\n\n# Resource: aws_apprunner_auto_scaling_configuration_version\n\nManages an App Runner AutoScaling Configuration Version.\n\n## Example Usage\n\n```terraform\nresource \"aws_apprunner_auto_scaling_configuration_version\" \"example\" {\n  auto_scaling_configuration_name = \"example\"\n\n  max_concurrency = 50\n  max_size        = 10\n  min_size        = 2\n\n  tags = {\n    Name = \"example-apprunner-autoscaling\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments supported:\n\n* `auto_scaling_configuration_name` - (Required, Forces new resource) Name of the auto scaling configuration.\n* `max_concurrency` - (Optional, Forces new resource) The maximal number of concurrent requests that you want an instance to process. When the number of concurrent requests goes over this limit, App Runner scales up your service.\n* `max_size` - (Optional, Forces new resource) The maximal number of instances that App Runner provisions for your service.\n* `min_size` - (Optional, Forces new resource) The minimal number of instances that App Runner provisions for your service.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of this auto scaling configuration version.\n* `auto_scaling_configuration_revision` - The revision of this auto scaling configuration.\n* `latest` - Whether the auto scaling configuration has the highest `auto_scaling_configuration_revision` among all configurations that share the same `auto_scaling_configuration_name`.\n* `status` - The current state of the auto scaling configuration. An INACTIVE configuration revision has been deleted and can't be used. It is permanently removed some time after deletion.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Runner AutoScaling Configuration Versions can be imported by using the `arn`, e.g.,\n\n```\n$ terraform import aws_apprunner_auto_scaling_configuration_version.example \"arn:aws:apprunner:us-east-1:1234567890:autoscalingconfiguration/example/1/69bdfe0115224b0db49398b7beb68e0f\n```\n",
    "basename": "apprunner_auto_scaling_configuration_version.html"
  },
  "apprunner_connection.html": {
    "subcategory": "App Runner",
    "layout": "aws",
    "page_title": "AWS: aws_apprunner_connection",
    "description": "Manages an App Runner Connection.",
    "preview": "# Resource: aws_apprunner_connection\n\nManages an App Runner …",
    "content": "\n\n# Resource: aws_apprunner_connection\n\nManages an App Runner Connection.\n\n~> **NOTE:** After creation, you must complete the authentication handshake using the App Runner console.\n\n## Example Usage\n\n```terraform\nresource \"aws_apprunner_connection\" \"example\" {\n  connection_name = \"example\"\n  provider_type   = \"GITHUB\"\n\n  tags = {\n    Name = \"example-apprunner-connection\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments supported:\n\n* `connection_name` - (Required) Name of the connection.\n* `provider_type` - (Required) The source repository provider. Valid values: `GITHUB`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the connection.\n* `status` - The current state of the App Runner connection. When the state is `AVAILABLE`, you can use the connection to create an [`aws_apprunner_service` resource](apprunner_service.html).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Runner Connections can be imported by using the `connection_name`, e.g.,\n\n```\n$ terraform import aws_apprunner_connection.example example\n```\n",
    "basename": "apprunner_connection.html"
  },
  "apprunner_custom_domain_association.html": {
    "subcategory": "App Runner",
    "layout": "aws",
    "page_title": "AWS: aws_apprunner_custom_domain_association",
    "description": "Manages an App Runner Custom Domain association.",
    "preview": "# Resource: aws_apprunner_custom_domain_association\n\nManages an App …",
    "content": "\n\n# Resource: aws_apprunner_custom_domain_association\n\nManages an App Runner Custom Domain association.\n\n~> **NOTE:** After creation, you must use the information in the `certification_validation_records` attribute to add CNAME records to your Domain Name System (DNS). For each mapped domain name, add a mapping to the target App Runner subdomain (found in the `dns_target` attribute) and one or more certificate validation records. App Runner then performs DNS validation to verify that you own or control the domain name you associated. App Runner tracks domain validity in a certificate stored in AWS Certificate Manager (ACM).\n\n## Example Usage\n\n```terraform\nresource \"aws_apprunner_custom_domain_association\" \"example\" {\n  domain_name = \"example.com\"\n  service_arn = aws_apprunner_service.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments supported:\n\n* `domain_name` - (Required) The custom domain endpoint to association. Specify a base domain e.g., `example.com` or a subdomain e.g., `subdomain.example.com`.\n* `enable_www_subdomain` (Optional) Whether to associate the subdomain with the App Runner service in addition to the base domain. Defaults to `true`.\n* `service_arn` - (Required) The ARN of the App Runner service.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The `domain_name` and `service_arn` separated by a comma (`,`).\n* `certificate_validation_records` - A set of certificate CNAME records used for this domain name. See [Certificate Validation Records](#certificate-validation-records) below for more details.\n* `dns_target` - The App Runner subdomain of the App Runner service. The custom domain name is mapped to this target name. Attribute only available if resource created (not imported) with Terraform.\n\n### Certificate Validation Records\n\nThe configuration block consists of the following arguments:\n\n* `name` - The certificate CNAME record name.\n* `status` - The current state of the certificate CNAME record validation. It should change to `SUCCESS` after App Runner completes validation with your DNS.\n* `type` - The record type, always `CNAME`.\n* `value` - The certificate CNAME record value.\n\n## Import\n\nApp Runner Custom Domain Associations can be imported by using the `domain_name` and `service_arn` separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_apprunner_custom_domain_association.example example.com,arn:aws:apprunner:us-east-1:123456789012:service/example-\napp/8fe1e10304f84fd2b0df550fe98a71fa\n```\n",
    "basename": "apprunner_custom_domain_association.html"
  },
  "apprunner_service.html": {
    "subcategory": "App Runner",
    "layout": "aws",
    "page_title": "AWS: aws_apprunner_service",
    "description": "Manages an App Runner Service.",
    "preview": "# Resource: aws_apprunner_service\n\nManages an App Runner Service.\n …",
    "content": "\n\n# Resource: aws_apprunner_service\n\nManages an App Runner Service.\n\n## Example Usage\n\n### Service with a Code Repository Source\n\n```terraform\nresource \"aws_apprunner_service\" \"example\" {\n  service_name = \"example\"\n\n  source_configuration {\n    authentication_configuration {\n      connection_arn = aws_apprunner_connection.example.arn\n    }\n    code_repository {\n      code_configuration {\n        code_configuration_values {\n          build_command = \"python setup.py develop\"\n          port          = \"8000\"\n          runtime       = \"PYTHON_3\"\n          start_command = \"python runapp.py\"\n        }\n        configuration_source = \"API\"\n      }\n      repository_url = \"https://github.com/example/my-example-python-app\"\n      source_code_version {\n        type  = \"BRANCH\"\n        value = \"main\"\n      }\n    }\n  }\n\n  tags = {\n    Name = \"example-apprunner-service\"\n  }\n}\n```\n\n### Service with an Image Repository Source\n\n```terraform\nresource \"aws_apprunner_service\" \"example\" {\n  service_name = \"example\"\n\n  source_configuration {\n    image_repository {\n      image_configuration {\n        port = \"8000\"\n      }\n      image_identifier      = \"public.ecr.aws/jg/hello:latest\"\n      image_repository_type = \"ECR_PUBLIC\"\n    }\n  }\n\n  tags = {\n    Name = \"example-apprunner-service\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `service_name` - (Forces new resource) Name of the service.\n* `source_configuration` - The source to deploy to the App Runner service. Can be a code or an image repository. See [Source Configuration](#source-configuration) below for more details.\n\nThe following arguments are optional:\n\n* `auto_scaling_configuration_arn` - ARN of an App Runner automatic scaling configuration resource that you want to associate with your service. If not provided, App Runner associates the latest revision of a default auto scaling configuration.\n* `encryption_configuration` - (Forces new resource) An optional custom encryption key that App Runner uses to encrypt the copy of your source repository that it maintains and your service logs. By default, App Runner uses an AWS managed CMK. See [Encryption Configuration](#encryption-configuration) below for more details.\n* `health_check_configuration` - (Forces new resource) Settings of the health check that AWS App Runner performs to monitor the health of your service. See [Health Check Configuration](#health-check-configuration) below for more details.\n* `instance_configuration` - The runtime configuration of instances (scaling units) of the App Runner service. See [Instance Configuration](#instance-configuration) below for more details.\n* `tags` - Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Encryption Configuration\n\nThe `encryption_configuration` block supports the following argument:\n\n* `kms_key` - (Required) The ARN of the KMS key used for encryption.\n\n### Health Check Configuration\n\nThe `health_check_configuration` block supports the following arguments:\n\n* `healthy_threshold` - (Optional) The number of consecutive checks that must succeed before App Runner decides that the service is healthy. Defaults to 1. Minimum value of 1. Maximum value of 20.\n* `interval` - (Optional) The time interval, in seconds, between health checks. Defaults to 5. Minimum value of 1. Maximum value of 20.\n* `path` - (Optional) The URL to send requests to for health checks. Defaults to `/`. Minimum length of 0. Maximum length of 51200.\n* `protocol` - (Optional) The IP protocol that App Runner uses to perform health checks for your service. Valid values: `TCP`, `HTTP`. Defaults to `TCP`. If you set protocol to `HTTP`, App Runner sends health check requests to the HTTP path specified by `path`.\n* `timeout` - (Optional) The time, in seconds, to wait for a health check response before deciding it failed. Defaults to 2. Minimum value of  1. Maximum value of 20.\n* `unhealthy_threshold` - (Optional) The number of consecutive checks that must fail before App Runner decides that the service is unhealthy. Defaults to 5. Minimum value of  1. Maximum value of 20.\n\n### Instance Configuration\n\nThe `instance_configuration` block supports the following arguments:\n\n* `cpu` - (Optional) The number of CPU units reserved for each instance of your App Runner service represented as a String. Defaults to `1024`. Valid values: `1024|2048|(1|2) vCPU`.\n* `instance_role_arn` - (Optional) The Amazon Resource Name (ARN) of an IAM role that provides permissions to your App Runner service. These are permissions that your code needs when it calls any AWS APIs.\n* `memory` - (Optional) The amount of memory, in MB or GB, reserved for each instance of your App Runner service. Defaults to `2048`. Valid values: `2048|3072|4096|(2|3|4) GB`.\n\n### Source Configuration\n\nThe `source_configuration` block supports the following arguments:\n\n~>**Note:** Either `code_repository` or `image_repository` must be specified (but not both).\n\n* `authentication_configuration` - (Optional) Describes resources needed to authenticate access to some source repositories. See [Authentication Configuration](#authentication-configuration) below for more details.\n* `auto_deployments_enabled` - (Optional) Whether continuous integration from the source repository is enabled for the App Runner service. If set to `true`, each repository change (source code commit or new image version) starts a deployment. Defaults to `true`.\n* `code_repository` - (Optional) Description of a source code repository. See [Code Repository](#code-repository) below for more details.\n* `image_repository` - (Optional) Description of a source image repository. See [Image Repository](#image-repository) below for more details.\n\n### Authentication Configuration\n\nThe `authentication_configuration` block supports the following arguments:\n\n* `access_role_arn` - (Optional) ARN of the IAM role that grants the App Runner service access to a source repository. Required for ECR image repositories (but not for ECR Public)\n* `connection_arn` - (Optional) ARN of the App Runner connection that enables the App Runner service to connect to a source repository. Required for GitHub code repositories.\n\n### Code Repository\n\nThe `code_repository` block supports the following arguments:\n\n* `code_configuration` - (Optional) Configuration for building and running the service from a source code repository. See [Code Configuration](#code-configuration) below for more details.\n* `repository_url` - (Required) The location of the repository that contains the source code.\n* `source_code_version` - (Required) The version that should be used within the source code repository. See [Source Code Version](#source-code-version) below for more details.\n\n### Image Repository\n\nThe `image_repository` block supports the following arguments:\n\n* `image_configuration` - (Optional) Configuration for running the identified image. See [Image Configuration](#image-configuration) below for more details.\n* `image_identifier` - (Required) The identifier of an image. For an image in Amazon Elastic Container Registry (Amazon ECR), this is an image name. For the\n  image name format, see Pulling an image in the Amazon ECR User Guide.\n* `image_repository_type` - (Required) The type of the image repository. This reflects the repository provider and whether the repository is private or public. Valid values: `ECR` , `ECR_PUBLIC`.\n\n### Code Configuration\n\nThe `code_configuration` block supports the following arguments:\n\n* `code_configuration_values` - (Optional) Basic configuration for building and running the App Runner service. Use this parameter to quickly launch an App Runner service without providing an apprunner.yaml file in the source code repository (or ignoring the file if it exists). See [Code Configuration Values](#code-configuration-values) below for more details.\n* `configuration_source` - (Required) The source of the App Runner configuration. Valid values: `REPOSITORY`, `API`. Values are interpreted as follows:\n    * `REPOSITORY` - App Runner reads configuration values from the apprunner.yaml file in the\n    source code repository and ignores the CodeConfigurationValues parameter.\n    * `API` - App Runner uses configuration values provided in the CodeConfigurationValues\n    parameter and ignores the apprunner.yaml file in the source code repository.\n\n### Code Configuration Values\n\nThe `code_configuration_values` blocks supports the following arguments:\n\n* `build_command` - (Optional) The command App Runner runs to build your application.\n* `port` - (Optional) The port that your application listens to in the container. Defaults to `\"8080\"`.\n* `runtime` - (Required) A runtime environment type for building and running an App Runner service. Represents a programming language runtime. Valid values: `PYTHON_3`, `NODEJS_12`.\n* `runtime_environment_variables` - (Optional) Environment variables available to your running App Runner service. A map of key/value pairs. Keys with a prefix of `AWSAPPRUNNER` are reserved for system use and aren't valid.\n* `start_command` - (Optional) The command App Runner runs to start your application.\n\n### Image Configuration\n\nThe `image_configuration` block supports the following arguments:\n\n* `port` - (Optional) The port that your application listens to in the container. Defaults to `\"8080\"`.\n* `runtime_environment_variables` - (Optional) Environment variables available to your running App Runner service. A map of key/value pairs. Keys with a prefix of `AWSAPPRUNNER` are reserved for system use and aren't valid.\n* `start_command` - (Optional) A command App Runner runs to start the application in the source image. If specified, this command overrides the Docker image’s default start command.\n\n### Source Code Version\n\nThe `source_code_version` block supports the following arguments:\n\n* `type` - (Required) The type of version identifier. For a git-based repository, branches represent versions. Valid values: `BRANCH`.\n* `value`- (Required) A source code version. For a git-based repository, a branch name maps to a specific version. App Runner uses the most recent commit to the branch.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the App Runner service.\n* `service_id` - An alphanumeric ID that App Runner generated for this service. Unique within the AWS Region.\n* `service_url` - A subdomain URL that App Runner generated for this service. You can use this URL to access your service web application.\n* `status` - The current state of the App Runner service.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nApp Runner Services can be imported by using the `arn`, e.g.,\n\n```\n$ terraform import aws_apprunner_service.example arn:aws:apprunner:us-east-1:1234567890:service/example/0a03292a89764e5882c41d8f991c82fe\n```\n",
    "basename": "apprunner_service.html"
  },
  "appstream_directory_config.html": {
    "subcategory": "AppStream",
    "layout": "aws",
    "page_title": "AWS: aws_appstream_directory_config",
    "description": "Provides an AppStream Directory Config",
    "preview": "# Resource: aws_appstream_directory_config\n\nProvides an AppStream …",
    "content": "\n\n# Resource: aws_appstream_directory_config\n\nProvides an AppStream Directory Config.\n\n## Example Usage\n\n```terraform\nresource \"aws_appstream_directory_config\" \"example\" {\n  directory_name                          = \"NAME OF DIRECTORY\"\n  organizational_unit_distinguished_names = [\"DISTINGUISHED NAME\"]\n\n  service_account_credentials {\n    account_name     = \"NAME OF ACCOUNT\"\n    account_password = \"PASSWORD OF ACCOUNT\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `directory_name` - (Required) Fully qualified name of the directory.\n* `organizational_unit_distinguished_names` - (Required) Distinguished names of the organizational units for computer accounts.\n* `service_account_credentials` - (Required) Configuration block for the name of the directory and organizational unit (OU) to use to join the directory config to a Microsoft Active Directory domain. See [`service_account_credentials`](#service_account_credentials) below.\n\n### `service_account_credentials`\n\n* `account_name` - (Required) User name of the account. This account must have the following privileges: create computer objects, join computers to the domain, and change/reset the password on descendant computer objects for the organizational units specified.\n* `account_password` - (Required) Password for the account.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Unique identifier (ID) of the appstream directory config.\n* `created_time` -  Date and time, in UTC and extended RFC 3339 format, when the directory config was created.\n\n## Import\n\n`aws_appstream_directory_config` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_appstream_directory_config.example directoryNameExample\n```\n",
    "basename": "appstream_directory_config.html"
  },
  "appstream_fleet.html": {
    "subcategory": "AppStream",
    "layout": "aws",
    "page_title": "AWS: aws_appstream_fleet",
    "description": "Provides an AppStream fleet",
    "preview": "# Resource: aws_appstream_fleet\n\nProvides an AppStream fleet.\n\n## …",
    "content": "\n\n# Resource: aws_appstream_fleet\n\nProvides an AppStream fleet.\n\n## Example Usage\n\n```terraform\nresource \"aws_appstream_fleet\" \"test_fleet\" {\n  name = \"test-fleet\"\n\n  compute_capacity {\n    desired_instances = 1\n  }\n\n  description                        = \"test fleet\"\n  idle_disconnect_timeout_in_seconds = 15\n  display_name                       = \"test-fleet\"\n  enable_default_internet_access     = false\n  fleet_type                         = \"ON_DEMAND\"\n  image_name                         = \"Amazon-AppStream2-Sample-Image-02-04-2019\"\n  instance_type                      = \"stream.standard.large\"\n  max_user_duration_in_seconds       = 600\n\n  vpc_config {\n    subnet_ids = [\"subnet-06e9b13400c225127\"]\n  }\n\n  tags = {\n    TagName = \"tag-value\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `compute_capacity` - (Required) Configuration block for the desired capacity of the fleet. See below.\n* `instance_type` - (Required) Instance type to use when launching fleet instances.\n* `name` - (Required) Unique name for the fleet.\n\nThe following arguments are optional:\n\n* `description` - (Optional) Description to display.\n* `disconnect_timeout_in_seconds` - (Optional) Amount of time that a streaming session remains active after users disconnect.\n* `display_name` - (Optional) Human-readable friendly name for the AppStream fleet.\n* `domain_join_info` - (Optional) Configuration block for the name of the directory and organizational unit (OU) to use to join the fleet to a Microsoft Active Directory domain. See below.\n* `enable_default_internet_access` - (Optional) Enables or disables default internet access for the fleet.\n* `fleet_type` - (Optional) Fleet type. Valid values are: `ON_DEMAND`, `ALWAYS_ON`\n* `iam_role_arn` - (Optional) ARN of the IAM role to apply to the fleet.\n* `idle_disconnect_timeout_in_seconds` - (Optional) Amount of time that users can be idle (inactive) before they are disconnected from their streaming session and the `disconnect_timeout_in_seconds` time interval begins.\n* `image_name` - (Optional) Name of the image used to create the fleet.\n* `image_arn` - (Optional) ARN of the public, private, or shared image to use.\n* `stream_view` - (Optional) AppStream 2.0 view that is displayed to your users when they stream from the fleet. When `APP` is specified, only the windows of applications opened by users display. When `DESKTOP` is specified, the standard desktop that is provided by the operating system displays.\n* `max_user_duration_in_seconds` - (Optional) Maximum amount of time that a streaming session can remain active, in seconds.\n* `vpc_config` - (Optional) Configuration block for the VPC configuration for the image builder. See below.\n* `tags` - (Optional) Map of tags to attach to AppStream instances.\n\n### `compute_capacity`\n\n* `desired_instances` - (Required) Desired number of streaming instances.\n\n### `domain_join_info`\n\n* `directory_name` - (Optional) Fully qualified name of the directory (for example, corp.example.com).\n* `organizational_unit_distinguished_name` - (Optional) Distinguished name of the organizational unit for computer accounts.\n\n### `vpc_config`\n\n* `security_group_ids` - Identifiers of the security groups for the fleet or image builder.\n* `subnet_ids` - Identifiers of the subnets to which a network interface is attached from the fleet instance or image builder instance.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Unique identifier (ID) of the appstream fleet.\n* `arn` - ARN of the appstream fleet.\n* `state` - State of the fleet. Can be `STARTING`, `RUNNING`, `STOPPING` or `STOPPED`\n* `created_time` -  Date and time, in UTC and extended RFC 3339 format, when the fleet was created.\n* `compute_capacity` - Describes the capacity status for a fleet.\n\n### `compute_capacity`\n\n* `available` - Number of currently available instances that can be used to stream sessions.\n* `in_use` - Number of instances in use for streaming.\n* `running` - Total number of simultaneous streaming instances that are running.\n\n\n## Import\n\n`aws_appstream_fleet` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_appstream_fleet.example fleetNameExample\n```\n",
    "basename": "appstream_fleet.html"
  },
  "appstream_fleet_stack_association.html": {
    "subcategory": "AppStream",
    "layout": "aws",
    "page_title": "AWS: aws_appstream_fleet_stack_association",
    "description": "Manages an AppStream Fleet Stack association.",
    "preview": "# Resource: aws_appstream_fleet_stack_association\n\nManages an …",
    "content": "\n\n# Resource: aws_appstream_fleet_stack_association\n\nManages an AppStream Fleet Stack association.\n\n## Example Usage\n\n```terraform\nresource \"aws_appstream_fleet\" \"example\" {\n  name          = \"FLEET NAME\"\n  image_name    = \"Amazon-AppStream2-Sample-Image-02-04-2019\"\n  instance_type = \"stream.standard.small\"\n\n  compute_capacity {\n    desired_instances = 1\n  }\n}\n\nresource \"aws_appstream_stack\" \"example\" {\n  name = \"STACK NAME\"\n}\n\nresource \"aws_appstream_fleet_stack_association\" \"example\" {\n  fleet_name = aws_appstream_fleet.example.name\n  stack_name = aws_appstream_stack.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `fleet_name` - (Required) Name of the fleet.\n* `stack_name` (Required) Name of the stack.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Unique ID of the appstream stack fleet association, composed of the `fleet_name` and `stack_name` separated by a slash (`/`).\n\n## Import\n\nAppStream Stack Fleet Association can be imported by using the `fleet_name` and `stack_name` separated by a slash (`/`), e.g.,\n\n```\n$ terraform import aws_appstream_fleet_stack_association.example fleetName/stackName\n```\n",
    "basename": "appstream_fleet_stack_association.html"
  },
  "appstream_image_builder.html": {
    "subcategory": "AppStream",
    "layout": "aws",
    "page_title": "AWS: aws_appstream_image_builder",
    "description": "Provides an AppStream image builder",
    "preview": "# Resource: aws_appstream_image_builder\n\nProvides an AppStream image …",
    "content": "\n\n# Resource: aws_appstream_image_builder\n\nProvides an AppStream image builder.\n\n## Example Usage\n\n```terraform\nresource \"aws_appstream_image_builder\" \"test_fleet\" {\n  name                           = \"Image Builder Name\"\n  description                    = \"Description of a ImageBuilder\"\n  display_name                   = \"Display name of a ImageBuilder\"\n  enable_default_internet_access = false\n  image_name                     = \"AppStream-WinServer2012R2-07-19-2021\"\n  instance_type                  = \"stream.standard.large\"\n\n  vpc_config {\n    subnet_ids = [aws_subnet.example.id]\n  }\n\n  tags = {\n    Name = \"Example Image Builder\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `instance_type` - (Required) The instance type to use when launching the image builder.\n* `name` - (Required) Unique name for the image builder.\n\nThe following arguments are optional:\n\n* `access_endpoint` - (Optional) Set of interface VPC endpoint (interface endpoint) objects. Maximum of 4. See below.\n* `appstream_agent_version` - (Optional) The version of the AppStream 2.0 agent to use for this image builder.\n* `description` - (Optional) Description to display.\n* `display_name` - (Optional) Human-readable friendly name for the AppStream image builder.\n* `domain_join_info` - (Optional) Configuration block for the name of the directory and organizational unit (OU) to use to join the image builder to a Microsoft Active Directory domain. See below.\n* `enable_default_internet_access` - (Optional) Enables or disables default internet access for the image builder.\n* `iam_role_arn` - (Optional) ARN of the IAM role to apply to the image builder.\n* `image_arn` - (Optional, Required if `image_name` not provided) ARN of the public, private, or shared image to use.\n* `image_name` - (Optional, Required if `image_arn` not provided) Name of the image used to create the image builder.\n* `vpc_config` - (Optional) Configuration block for the VPC configuration for the image builder. See below.\n* `tags` - (Optional) A map of tags to assign to the instance. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `access_endpoint`\n\nThe `access_endpoint` block supports the following arguments:\n\n* `endpoint_type` - (Required) Type of interface endpoint.\n* `vpce_id` - (Optional) Identifier (ID) of the VPC in which the interface endpoint is used.\n\n### `domain_join_info`\n\nThe `domain_join_info` block supports the following arguments:\n\n* `directory_name` - (Optional) Fully qualified name of the directory (for example, corp.example.com).\n* `organizational_unit_distinguished_name` - (Optional) Distinguished name of the organizational unit for computer accounts.\n\n### `vpc_config`\n\nThe `vpc_config` block supports the following arguments:\n\n* `security_group_ids` - (Optional) Identifiers of the security groups for the image builder or image builder.\n* `subnet_ids` - (Optional) Identifiers of the subnets to which a network interface is attached from the image builder instance or image builder instance.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the appstream image builder.\n* `created_time` -  Date and time, in UTC and extended RFC 3339 format, when the image builder was created.\n* `id` - The name of the image builder.\n* `state` - State of the image builder. Can be: `PENDING`, `UPDATING_AGENT`, `RUNNING`, `STOPPING`, `STOPPED`, `REBOOTING`, `SNAPSHOTTING`, `DELETING`, `FAILED`, `UPDATING`, `PENDING_QUALIFICATION`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_appstream_image_builder` can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_appstream_image_builder.example imageBuilderExample\n```\n",
    "basename": "appstream_image_builder.html"
  },
  "appstream_stack.html": {
    "subcategory": "AppStream",
    "layout": "aws",
    "page_title": "AWS: aws_appstream_stack",
    "description": "Provides an AppStream stack",
    "preview": "# Resource: aws_appstream_stack\n\nProvides an AppStream stack.\n\n## …",
    "content": "\n\n# Resource: aws_appstream_stack\n\nProvides an AppStream stack.\n\n## Example Usage\n\n```terraform\nresource \"aws_appstream_stack\" \"example\" {\n  name         = \"stack name\"\n  description  = \"stack description\"\n  display_name = \"stack display name\"\n  feedback_url = \"http://your-domain/feedback\"\n  redirect_url = \"http://your-domain/redirect\"\n\n  storage_connectors {\n    connector_type = \"HOMEFOLDERS\"\n  }\n\n  user_settings {\n    action     = \"CLIPBOARD_COPY_FROM_LOCAL_DEVICE\"\n    permission = \"ENABLED\"\n  }\n  user_settings {\n    action     = \"CLIPBOARD_COPY_TO_LOCAL_DEVICE\"\n    permission = \"ENABLED\"\n  }\n  user_settings {\n    action     = \"FILE_UPLOAD\"\n    permission = \"ENABLED\"\n  }\n  user_settings {\n    action     = \"FILE_DOWNLOAD\"\n    permission = \"ENABLED\"\n  }\n\n  application_settings {\n    enabled        = true\n    settings_group = \"SettingsGroup\"\n  }\n\n  tags = {\n    TagName = \"TagValue\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Unique name for the AppStream stack.\n\nThe following arguments are optional:\n\n* `application_settings` - (Optional) Settings for application settings persistence.\n* `description` - (Optional) Description for the AppStream stack.\n* `display_name` - (Optional) Stack name to display.\n* `embed_host_domains` - (Optional) Domains where AppStream 2.0 streaming sessions can be embedded in an iframe. You must approve the domains that you want to host embedded AppStream 2.0 streaming sessions.\n* `feedback_url` - (Optional) URL that users are redirected to after they click the Send Feedback link. If no URL is specified, no Send Feedback link is displayed. .\n* `redirect_url` - (Optional) URL that users are redirected to after their streaming session ends.\n* `storage_connectors` - (Optional) Configuration block for the storage connectors to enable. See below.\n* `user_settings` - (Optional) Configuration block for the actions that are enabled or disabled for users during their streaming sessions. By default, these actions are enabled. See below.\n\n### `storage_connectors`\n\n* `connector_type` - (Required) Type of storage connector. Valid values are: `HOMEFOLDERS`, `GOOGLE_DRIVE`, `ONE_DRIVE`.\n* `domains` - (Optional) Names of the domains for the account.\n* `resource_identifier` - (Optional) ARN of the storage connector.\n\n### `user_settings`\n\n* `action` - (Required) Action that is enabled or disabled. Valid values are: `CLIPBOARD_COPY_FROM_LOCAL_DEVICE`,  `CLIPBOARD_COPY_TO_LOCAL_DEVICE`, `FILE_UPLOAD`, `FILE_DOWNLOAD`, `PRINTING_TO_LOCAL_DEVICE`, `DOMAIN_PASSWORD_SIGNIN`, `DOMAIN_SMART_CARD_SIGNIN`.\n* `permission` - (Required) Indicates whether the action is enabled or disabled. Valid values are: `ENABLED`, `DISABLED`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the appstream stack.\n* `created_time` - Date and time, in UTC and extended RFC 3339 format, when the stack was created.\n* `id` - Unique ID of the appstream stack.\n\n\n## Import\n\n`aws_appstream_stack` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_appstream_stack.example stackID\n```\n",
    "basename": "appstream_stack.html"
  },
  "appstream_user.html": {
    "subcategory": "AppStream",
    "layout": "aws",
    "page_title": "AWS: aws_appstream_user",
    "description": "Provides an AppStream user",
    "preview": "# Resource: aws_appstream_user\n\nProvides an AppStream user.\n\n## …",
    "content": "\n\n# Resource: aws_appstream_user\n\nProvides an AppStream user.\n\n## Example Usage\n\n```terraform\nresource \"aws_appstream_user\" \"example\" {\n  authentication_type = \"USERPOOL\"\n  user_name           = \"EMAIL ADDRESS\"\n  first_name          = \"FIRST NAME\"\n  last_name           = \"LAST NAME\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `authentication_type` - (Required) Authentication type for the user. You must specify USERPOOL. Valid values: `API`, `SAML`, `USERPOOL`\n* `user_name` - (Required) Email address of the user.\n\nThe following arguments are optional:\n\n* `enabled` - (Optional) Specifies whether the user in the user pool is enabled.\n* `first_name` - (Optional) First name, or given name, of the user.\n* `last_name` - (Optional) Last name, or surname, of the user.\n* `send_email_notification` - (Optional) Send an email notification.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the appstream user.\n* `created_time` - Date and time, in UTC and extended RFC 3339 format, when the user was created.\n* `id` - Unique ID of the appstream user.\n* `status` - Status of the user in the user pool.\n\n\n## Import\n\n`aws_appstream_user` can be imported using the `user_name` and `authentication_type` separated by a slash (`/`), e.g.,\n\n```\n$ terraform import aws_appstream_user.example UserName/AuthenticationType\n```\n",
    "basename": "appstream_user.html"
  },
  "appstream_user_stack_association.html": {
    "subcategory": "AppStream",
    "layout": "aws",
    "page_title": "AWS: aws_appstream_user_stack_association",
    "description": "Manages an AppStream User Stack association.",
    "preview": "# Resource: aws_appstream_user_stack_association\n\nManages an …",
    "content": "\n\n# Resource: aws_appstream_user_stack_association\n\nManages an AppStream User Stack association.\n\n## Example Usage\n\n```terraform\nresource \"aws_appstream_stack\" \"test\" {\n  name = \"STACK NAME\"\n}\n\nresource \"aws_appstream_user\" \"test\" {\n  authentication_type = \"USERPOOL\"\n  user_name           = \"EMAIL\"\n}\n\nresource \"aws_appstream_user_stack_association\" \"test\" {\n  authentication_type = aws_appstream_user.test.authentication_type\n  stack_name          = aws_appstream_stack.test.name\n  user_name           = aws_appstream_user.test.user_name\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `authentication_type` - (Required) Authentication type for the user.\n* `stack_name` (Required) Name of the stack that is associated with the user.\n* `user_name` (Required) Email address of the user who is associated with the stack.\n\nThe following arguments are optional:\n\n* `send_email_notification` - (Optional) Specifies whether a welcome email is sent to a user after the user is created in the user pool.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Unique ID of the appstream User Stack association.\n\n\n## Import\n\nAppStream User Stack Association can be imported by using the `user_name`, `authentication_type`, and `stack_name`, separated by a slash (`/`), e.g.,\n\n```\n$ terraform import aws_appstream_user_stack_association.example userName/auhtenticationType/stackName\n```\n",
    "basename": "appstream_user_stack_association.html"
  },
  "appsync_api_key.html": {
    "subcategory": "AppSync",
    "layout": "aws",
    "page_title": "AWS: aws_appsync_api_key",
    "description": "Provides an AppSync API Key.",
    "preview": "# Resource: aws_appsync_api_key\n\nProvides an AppSync API Key.\n\n## …",
    "content": "\n\n# Resource: aws_appsync_api_key\n\nProvides an AppSync API Key.\n\n## Example Usage\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"API_KEY\"\n  name                = \"example\"\n}\n\nresource \"aws_appsync_api_key\" \"example\" {\n  api_id  = aws_appsync_graphql_api.example.id\n  expires = \"2018-05-03T04:00:00Z\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The ID of the associated AppSync API\n* `description` - (Optional) The API key description. Defaults to \"Managed by Terraform\".\n* `expires` - (Optional) RFC3339 string representation of the expiry date. Rounded down to nearest hour. By default, it is 7 days from the date of creation.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - API Key ID (Formatted as ApiId:Key)\n* `key` - The API key\n\n## Import\n\n`aws_appsync_api_key` can be imported using the AppSync API ID and key separated by `:`, e.g.,\n\n```\n$ terraform import aws_appsync_api_key.example xxxxx:yyyyy\n```\n",
    "basename": "appsync_api_key.html"
  },
  "appsync_datasource.html": {
    "subcategory": "AppSync",
    "layout": "aws",
    "page_title": "AWS: aws_appsync_datasource",
    "description": "Provides an AppSync DataSource.",
    "preview": "# Resource: aws_appsync_datasource\n\nProvides an AppSync DataSource.\n …",
    "content": "\n\n# Resource: aws_appsync_datasource\n\nProvides an AppSync DataSource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dynamodb_table\" \"example\" {\n  name           = \"example\"\n  read_capacity  = 1\n  write_capacity = 1\n  hash_key       = \"UserId\"\n\n  attribute {\n    name = \"UserId\"\n    type = \"S\"\n  }\n}\n\nresource \"aws_iam_role\" \"example\" {\n  name = \"example\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"appsync.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"example\" {\n  name = \"example\"\n  role = aws_iam_role.example.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"dynamodb:*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"${aws_dynamodb_table.example.arn}\"\n      ]\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"API_KEY\"\n  name                = \"tf_appsync_example\"\n}\n\nresource \"aws_appsync_datasource\" \"example\" {\n  api_id           = aws_appsync_graphql_api.example.id\n  name             = \"tf_appsync_example\"\n  service_role_arn = aws_iam_role.example.arn\n  type             = \"AMAZON_DYNAMODB\"\n\n  dynamodb_config {\n    table_name = aws_dynamodb_table.example.name\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API ID for the GraphQL API for the DataSource.\n* `name` - (Required) A user-supplied name for the DataSource.\n* `type` - (Required) The type of the DataSource. Valid values: `AWS_LAMBDA`, `AMAZON_DYNAMODB`, `AMAZON_ELASTICSEARCH`, `HTTP`, `NONE`.\n* `description` - (Optional) A description of the DataSource.\n* `service_role_arn` - (Optional) The IAM service role ARN for the data source.\n* `dynamodb_config` - (Optional) DynamoDB settings. See [below](#dynamodb_config)\n* `elasticsearch_config` - (Optional) Amazon Elasticsearch settings. See [below](#elasticsearch_config)\n* `http_config` - (Optional) HTTP settings. See [below](#http_config)\n* `lambda_config` - (Optional) AWS Lambda settings. See [below](#lambda_config)\n\n### dynamodb_config\n\nThe following arguments are supported:\n\n* `table_name` - (Required) Name of the DynamoDB table.\n* `region` - (Optional) AWS region of the DynamoDB table. Defaults to current region.\n* `use_caller_credentials` - (Optional) Set to `true` to use Amazon Cognito credentials with this data source.\n\n### elasticsearch_config\n\nThe following arguments are supported:\n\n* `endpoint` - (Required) HTTP endpoint of the Elasticsearch domain.\n* `region` - (Optional) AWS region of Elasticsearch domain. Defaults to current region.\n\n### http_config\n\nThe following arguments are supported:\n\n* `endpoint` - (Required) HTTP URL.\n\n### lambda_config\n\nThe following arguments are supported:\n\n* `function_arn` - (Required) The ARN for the Lambda function.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN\n\n## Import\n\n`aws_appsync_datasource` can be imported with their `api_id`, a hyphen, and `name`, e.g.,\n\n```\n$ terraform import aws_appsync_datasource.example abcdef123456-example\n```\n",
    "basename": "appsync_datasource.html"
  },
  "appsync_function.html": {
    "subcategory": "AppSync",
    "layout": "aws",
    "page_title": "AWS: aws_appsync_function",
    "description": "Provides an AppSync Function.",
    "preview": "# Resource: aws_appsync_function\n\nProvides an AppSync Function.\n\n## …",
    "content": "\n\n# Resource: aws_appsync_function\n\nProvides an AppSync Function.\n\n## Example Usage\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"API_KEY\"\n  name                = \"example\"\n  schema              = <<EOF\ntype Mutation {\n  putPost(id: ID!, title: String!): Post\n}\n\ntype Post {\n  id: ID!\n  title: String!\n}\n\ntype Query {\n  singlePost(id: ID!): Post\n}\n\nschema {\n  query: Query\n  mutation: Mutation\n}\nEOF\n}\n\nresource \"aws_appsync_datasource\" \"example\" {\n  api_id = aws_appsync_graphql_api.example.id\n  name   = \"example\"\n  type   = \"HTTP\"\n\n  http_config {\n    endpoint = \"http://example.com\"\n  }\n}\n\nresource \"aws_appsync_function\" \"example\" {\n  api_id                   = aws_appsync_graphql_api.example.id\n  data_source              = aws_appsync_datasource.example.name\n  name                     = \"example\"\n  request_mapping_template = <<EOF\n{\n    \"version\": \"2018-05-29\",\n    \"method\": \"GET\",\n    \"resourcePath\": \"/\",\n    \"params\":{\n        \"headers\": $utils.http.copyheaders($ctx.request.headers)\n    }\n}\nEOF\n\n  response_mapping_template = <<EOF\n#if($ctx.result.statusCode == 200)\n    $ctx.result.body\n#else\n    $utils.appendError($ctx.result.body, $ctx.result.statusCode)\n#end\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The ID of the associated AppSync API.\n* `data_source` - (Required) The Function DataSource name.\n* `name` - (Required) The Function name. The function name does not have to be unique.\n* `request_mapping_template` - (Required) The Function request mapping template. Functions support only the 2018-05-29 version of the request mapping template.\n* `response_mapping_template` - (Required) The Function response mapping template.\n* `description` - (Optional) The Function description.\n* `function_version` - (Optional) The version of the request mapping template. Currently the supported value is `2018-05-29`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - API Function ID (Formatted as ApiId-FunctionId)\n* `arn` - The ARN of the Function object.\n* `function_id` - A unique ID representing the Function object.\n\n## Import\n\n`aws_appsync_function` can be imported using the AppSync API ID and Function ID separated by `-`, e.g.,\n\n```\n$ terraform import aws_appsync_function.example xxxxx-yyyyy\n```\n",
    "basename": "appsync_function.html"
  },
  "appsync_graphql_api.html": {
    "subcategory": "AppSync",
    "layout": "aws",
    "page_title": "AWS: aws_appsync_graphql_api",
    "description": "Provides an AppSync GraphQL API.",
    "preview": "# Resource: aws_appsync_graphql_api\n\nProvides an AppSync GraphQL …",
    "content": "\n\n# Resource: aws_appsync_graphql_api\n\nProvides an AppSync GraphQL API.\n\n## Example Usage\n\n### API Key Authentication\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"API_KEY\"\n  name                = \"example\"\n}\n```\n\n### AWS IAM Authentication\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"AWS_IAM\"\n  name                = \"example\"\n}\n```\n\n### AWS Cognito User Pool Authentication\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"AMAZON_COGNITO_USER_POOLS\"\n  name                = \"example\"\n\n  user_pool_config {\n    aws_region     = data.aws_region.current.name\n    default_action = \"DENY\"\n    user_pool_id   = aws_cognito_user_pool.example.id\n  }\n}\n```\n\n### OpenID Connect Authentication\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"OPENID_CONNECT\"\n  name                = \"example\"\n\n  openid_connect_config {\n    issuer = \"https://example.com\"\n  }\n}\n```\n\n### AWS Lambda Authorizer Authentication\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"AWS_LAMBDA\"\n  name                = \"example\"\n\n  lambda_authorizer_config {\n    authorizer_uri = \"arn:aws:lambda:us-east-1:123456789012:function:custom_lambda_authorizer\"\n  }\n}\n\nresource \"aws_lambda_permission\" \"appsync_lambda_authorizer\" {\n  statement_id  = \"appsync_lambda_authorizer\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = \"custom_lambda_authorizer\"\n  principal     = \"appsync.amazonaws.com\"\n  source_arn    = aws_appsync_graphql_api.example.arn\n}\n```\n\n### With Multiple Authentication Providers\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"API_KEY\"\n  name                = \"example\"\n\n  additional_authentication_provider {\n    authentication_type = \"AWS_IAM\"\n  }\n}\n```\n\n### With Schema\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"AWS_IAM\"\n  name                = \"example\"\n\n  schema = <<EOF\nschema {\n\tquery: Query\n}\ntype Query {\n  test: Int\n}\nEOF\n}\n```\n\n### Enabling Logging\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name = \"example\"\n\n  assume_role_policy = <<POLICY\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"appsync.amazonaws.com\"\n        },\n        \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example\" {\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSAppSyncPushToCloudWatchLogs\"\n  role       = aws_iam_role.example.name\n}\n\nresource \"aws_appsync_graphql_api\" \"example\" {\n  # ... other configuration ...\n\n  log_config {\n    cloudwatch_logs_role_arn = aws_iam_role.example.arn\n    field_log_level          = \"ERROR\"\n  }\n}\n```\n\n### Associate Web ACL (v2)\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"example\" {\n  authentication_type = \"API_KEY\"\n  name                = \"example\"\n}\n\nresource \"aws_wafv2_web_acl_association\" \"example\" {\n  resource_arn = aws_appsync_graphql_api.example.arn\n  web_acl_arn  = aws_wafv2_web_acl.example.arn\n}\n\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"managed-rule-example\"\n  description = \"Example of a managed rule.\"\n  scope       = \"REGIONAL\"\n\n  default_action {\n    allow {}\n  }\n\n  rule {\n    name     = \"rule-1\"\n    priority = 1\n\n    override_action {\n      block {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesCommonRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `authentication_type` - (Required) The authentication type. Valid values: `API_KEY`, `AWS_IAM`, `AMAZON_COGNITO_USER_POOLS`, `OPENID_CONNECT`, `AWS_LAMBDA`\n* `name` - (Required) A user-supplied name for the GraphqlApi.\n* `log_config` - (Optional) Nested argument containing logging configuration. Defined below.\n* `openid_connect_config` - (Optional) Nested argument containing OpenID Connect configuration. Defined below.\n* `user_pool_config` - (Optional) The Amazon Cognito User Pool configuration. Defined below.\n* `lambda_authorizer_config` - (Optional) Nested argument containing Lambda authorizer configuration. Defined below.\n* `schema` - (Optional) The schema definition, in GraphQL schema language format. Terraform cannot perform drift detection of this configuration.\n* `additional_authentication_provider` - (Optional) One or more additional authentication providers for the GraphqlApi. Defined below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `xray_enabled` - (Optional) Whether tracing with X-ray is enabled. Defaults to false.\n\n### log_config\n\nThe following arguments are supported:\n\n* `cloudwatch_logs_role_arn` - (Required) Amazon Resource Name of the service role that AWS AppSync will assume to publish to Amazon CloudWatch logs in your account.\n* `field_log_level` - (Required) Field logging level. Valid values: `ALL`, `ERROR`, `NONE`.\n* `exclude_verbose_content` - (Optional) Set to TRUE to exclude sections that contain information such as headers, context, and evaluated mapping templates, regardless of logging  level. Valid values: `true`, `false`. Default value: `false`\n\n### additional_authentication_provider\n\nThe following arguments are supported:\n\n* `authentication_type` - (Required) The authentication type. Valid values: `API_KEY`, `AWS_IAM`, `AMAZON_COGNITO_USER_POOLS`, `OPENID_CONNECT`, `AWS_LAMBDA`\n* `openid_connect_config` - (Optional) Nested argument containing OpenID Connect configuration. Defined below.\n* `user_pool_config` - (Optional) The Amazon Cognito User Pool configuration. Defined below.\n\n### openid_connect_config\n\nThe following arguments are supported:\n\n* `issuer` - (Required) Issuer for the OpenID Connect configuration. The issuer returned by discovery MUST exactly match the value of iss in the ID Token.\n* `auth_ttl` - (Optional) Number of milliseconds a token is valid after being authenticated.\n* `client_id` - (Optional) Client identifier of the Relying party at the OpenID identity provider. This identifier is typically obtained when the Relying party is registered with the OpenID identity provider. You can specify a regular expression so the AWS AppSync can validate against multiple client identifiers at a time.\n* `iat_ttl` - (Optional) Number of milliseconds a token is valid after being issued to a user.\n\n### user_pool_config\n\nThe following arguments are supported:\n\n* `default_action` - (Required only if Cognito is used as the default auth provider) The action that you want your GraphQL API to take when a request that uses Amazon Cognito User Pool authentication doesn't match the Amazon Cognito User Pool configuration. Valid: `ALLOW` and `DENY`\n* `user_pool_id` - (Required) The user pool ID.\n* `app_id_client_regex` - (Optional) A regular expression for validating the incoming Amazon Cognito User Pool app client ID.\n* `aws_region` - (Optional) The AWS region in which the user pool was created.\n\n### lambda_authorizer_config\n\nThe following arguments are supported:\n\n* `authorizer_uri` - (Required) The ARN of the Lambda function to be called for authorization. Note: This Lambda function must have a resource-based policy assigned to it, to allow `lambda:InvokeFunction` from service principal `appsync.amazonaws.com`.\n* `authorizer_result_ttl_in_seconds` - (Optional) The number of seconds a response should be cached for. The default is 5 minutes (300 seconds). The Lambda function can override this by returning a `ttlOverride` key in its response. A value of 0 disables caching of responses. Minimum value of 0. Maximum value of 3600.\n* `identity_validation_expression` - (Optional) A regular expression for validation of tokens before the Lambda function is called.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - API ID\n* `arn` - The ARN\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `uris` - Map of URIs associated with the APIE.g., `uris[\"GRAPHQL\"] = https://ID.appsync-api.REGION.amazonaws.com/graphql`\n\n## Import\n\nAppSync GraphQL API can be imported using the GraphQL API ID, e.g.,\n\n```\n$ terraform import aws_appsync_graphql_api.example 0123456789\n```\n",
    "basename": "appsync_graphql_api.html"
  },
  "appsync_resolver.html": {
    "subcategory": "AppSync",
    "layout": "aws",
    "page_title": "AWS: aws_appsync_resolver",
    "description": "Provides an AppSync Resolver.",
    "preview": "# Resource: aws_appsync_resolver\n\nProvides an AppSync Resolver.\n\n## …",
    "content": "\n\n# Resource: aws_appsync_resolver\n\nProvides an AppSync Resolver.\n\n## Example Usage\n\n```terraform\nresource \"aws_appsync_graphql_api\" \"test\" {\n  authentication_type = \"API_KEY\"\n  name                = \"tf-example\"\n\n  schema = <<EOF\ntype Mutation {\n\tputPost(id: ID!, title: String!): Post\n}\n\ntype Post {\n\tid: ID!\n\ttitle: String!\n}\n\ntype Query {\n\tsinglePost(id: ID!): Post\n}\n\nschema {\n\tquery: Query\n\tmutation: Mutation\n}\nEOF\n}\n\nresource \"aws_appsync_datasource\" \"test\" {\n  api_id = aws_appsync_graphql_api.test.id\n  name   = \"tf_example\"\n  type   = \"HTTP\"\n\n  http_config {\n    endpoint = \"http://example.com\"\n  }\n}\n\n# UNIT type resolver (default)\nresource \"aws_appsync_resolver\" \"test\" {\n  api_id      = aws_appsync_graphql_api.test.id\n  field       = \"singlePost\"\n  type        = \"Query\"\n  data_source = aws_appsync_datasource.test.name\n\n  request_template = <<EOF\n{\n    \"version\": \"2018-05-29\",\n    \"method\": \"GET\",\n    \"resourcePath\": \"/\",\n    \"params\":{\n        \"headers\": $utils.http.copyheaders($ctx.request.headers)\n    }\n}\nEOF\n\n  response_template = <<EOF\n#if($ctx.result.statusCode == 200)\n    $ctx.result.body\n#else\n    $utils.appendError($ctx.result.body, $ctx.result.statusCode)\n#end\nEOF\n\n  caching_config {\n    caching_keys = [\n      \"$context.identity.sub\",\n      \"$context.arguments.id\",\n    ]\n    ttl = 60\n  }\n}\n\n# PIPELINE type resolver\nresource \"aws_appsync_resolver\" \"Mutation_pipelineTest\" {\n  type              = \"Mutation\"\n  api_id            = aws_appsync_graphql_api.test.id\n  field             = \"pipelineTest\"\n  request_template  = \"{}\"\n  response_template = \"$util.toJson($ctx.result)\"\n  kind              = \"PIPELINE\"\n  pipeline_config {\n    functions = [\n      aws_appsync_function.test1.function_id,\n      aws_appsync_function.test2.function_id,\n      aws_appsync_function.test3.function_id,\n    ]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `api_id` - (Required) The API ID for the GraphQL API.\n* `type` - (Required) The type name from the schema defined in the GraphQL API.\n* `field` - (Required) The field name from the schema defined in the GraphQL API.\n* `request_template` - (Optional) The request mapping template for UNIT resolver or 'before mapping template' for PIPELINE resolver. Required for non-Lambda resolvers.\n* `response_template` - (Optional) The response mapping template for UNIT resolver or 'after mapping template' for PIPELINE resolver. Required for non-Lambda resolvers.\n* `data_source` - (Optional) The DataSource name.\n* `kind`  - (Optional) The resolver type. Valid values are `UNIT` and `PIPELINE`.\n* `pipeline_config` - (Optional) The PipelineConfig.\n    * `functions` - (Required) The list of Function ID.\n* `caching_config` - (Optional) The CachingConfig.\n    * `caching_keys` - (Optional) The list of caching key.\n    * `ttl` - (Optional) The TTL in seconds.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN\n\n## Import\n\n`aws_appsync_resolver` can be imported with their `api_id`, a hyphen, `type`, a hypen and `field` e.g.,\n\n```\n$ terraform import aws_appsync_resolver.example abcdef123456-exampleType-exampleField\n```\n",
    "basename": "appsync_resolver.html"
  },
  "athena_database.html": {
    "subcategory": "Athena",
    "layout": "aws",
    "page_title": "AWS: aws_athena_database",
    "description": "Provides an Athena database.",
    "preview": "# Resource: aws_athena_database\n\nProvides an Athena database.\n\n## …",
    "content": "\n\n# Resource: aws_athena_database\n\nProvides an Athena database.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"hoge\" {\n  bucket = \"hoge\"\n}\n\nresource \"aws_athena_database\" \"hoge\" {\n  name   = \"database_name\"\n  bucket = aws_s3_bucket.hoge.bucket\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the database to create.\n* `bucket` - (Required) Name of s3 bucket to save the results of the query execution.\n* `encryption_configuration` - (Optional) The encryption key block AWS Athena uses to decrypt the data in S3, such as an AWS Key Management Service (AWS KMS) key. An `encryption_configuration` block is documented below.\n* `force_destroy` - (Optional, Default: false) A boolean that indicates all tables should be deleted from the database so that the database can be destroyed without error. The tables are *not* recoverable.\n\nAn `encryption_configuration` block supports the following arguments:\n\n* `encryption_option` - (Required) The type of key; one of `SSE_S3`, `SSE_KMS`, `CSE_KMS`\n* `kms_key` - (Optional) The KMS key ARN or ID; required for key types `SSE_KMS` and `CSE_KMS`.\n\n~> **NOTE:** When Athena queries are executed, result files may be created in the specified bucket. Consider using `force_destroy` on the bucket too in order to avoid any problems when destroying the bucket.  \n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The database name\n",
    "basename": "athena_database.html"
  },
  "athena_named_query.html": {
    "subcategory": "Athena",
    "layout": "aws",
    "page_title": "AWS: aws_athena_named_query",
    "description": "Provides an Athena Named Query resource.",
    "preview": "# Resource: aws_athena_named_query\n\nProvides an Athena Named Query …",
    "content": "\n\n# Resource: aws_athena_named_query\n\nProvides an Athena Named Query resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"hoge\" {\n  bucket = \"tf-test\"\n}\n\nresource \"aws_kms_key\" \"test\" {\n  deletion_window_in_days = 7\n  description             = \"Athena KMS Key\"\n}\n\nresource \"aws_athena_workgroup\" \"test\" {\n  name = \"example\"\n\n  configuration {\n    result_configuration {\n      encryption_configuration {\n        encryption_option = \"SSE_KMS\"\n        kms_key_arn       = aws_kms_key.test.arn\n      }\n    }\n  }\n}\n\nresource \"aws_athena_database\" \"hoge\" {\n  name   = \"users\"\n  bucket = aws_s3_bucket.hoge.id\n}\n\nresource \"aws_athena_named_query\" \"foo\" {\n  name      = \"bar\"\n  workgroup = aws_athena_workgroup.test.id\n  database  = aws_athena_database.hoge.name\n  query     = \"SELECT * FROM ${aws_athena_database.hoge.name} limit 10;\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The plain language name for the query. Maximum length of 128.\n* `workgroup` - (Optional) The workgroup to which the query belongs. Defaults to `primary`\n* `database` - (Required) The database to which the query belongs.\n* `query` - (Required) The text of the query itself. In other words, all query statements. Maximum length of 262144.\n* `description` - (Optional) A brief explanation of the query. Maximum length of 1024.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique ID of the query.\n\n## Import\n\nAthena Named Query can be imported using the query ID, e.g.,\n\n```\n$ terraform import aws_athena_named_query.example 0123456789\n```\n",
    "basename": "athena_named_query.html"
  },
  "athena_workgroup.html": {
    "subcategory": "Athena",
    "layout": "aws",
    "page_title": "AWS: aws_athena_workgroup",
    "description": "Manages an Athena Workgroup.",
    "preview": "# Resource: aws_athena_workgroup\n\nProvides an Athena Workgroup.\n\n## …",
    "content": "\n\n# Resource: aws_athena_workgroup\n\nProvides an Athena Workgroup.\n\n## Example Usage\n\n```terraform\nresource \"aws_athena_workgroup\" \"example\" {\n  name = \"example\"\n\n  configuration {\n    enforce_workgroup_configuration    = true\n    publish_cloudwatch_metrics_enabled = true\n\n    result_configuration {\n      output_location = \"s3://${aws_s3_bucket.example.bucket}/output/\"\n\n      encryption_configuration {\n        encryption_option = \"SSE_KMS\"\n        kms_key_arn       = aws_kms_key.example.arn\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the workgroup.\n* `configuration` - (Optional) Configuration block with various settings for the workgroup. Documented below.\n* `description` - (Optional) Description of the workgroup.\n* `state` - (Optional) State of the workgroup. Valid values are `DISABLED` or `ENABLED`. Defaults to `ENABLED`.\n* `tags` - (Optional) Key-value map of resource tags for the workgroup. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `force_destroy` - (Optional) The option to delete the workgroup and its contents even if the workgroup contains any named queries.\n\n### configuration Argument Reference\n\nThe `configuration` configuration block supports the following arguments:\n\n* `bytes_scanned_cutoff_per_query` - (Optional) Integer for the upper data usage limit (cutoff) for the amount of bytes a single query in a workgroup is allowed to scan. Must be at least `10485760`.\n* `enforce_workgroup_configuration` - (Optional) Boolean whether the settings for the workgroup override client-side settings. For more information, see [Workgroup Settings Override Client-Side Settings](https://docs.aws.amazon.com/athena/latest/ug/workgroups-settings-override.html). Defaults to `true`.\n* `engine_version` - (Optional) Configuration block for the Athena Engine Versioning. For more information, see [Athena Engine Versioning](https://docs.aws.amazon.com/athena/latest/ug/engine-versions.html). Documented below.\n* `publish_cloudwatch_metrics_enabled` - (Optional) Boolean whether Amazon CloudWatch metrics are enabled for the workgroup. Defaults to `true`.\n* `result_configuration` - (Optional) Configuration block with result settings. Documented below.\n* `requester_pays_enabled` - (Optional) If set to true , allows members assigned to a workgroup to reference Amazon S3 Requester Pays buckets in queries. If set to false , workgroup members cannot query data from Requester Pays buckets, and queries that retrieve data from Requester Pays buckets cause an error. The default is false . For more information about Requester Pays buckets, see [Requester Pays Buckets](https://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html) in the Amazon Simple Storage Service Developer Guide.\n\n#### engine_version Argument Reference\n\nThe `engine_version` configuration block within the `configuration` supports the following arguments:\n\n* `selected_engine_version` - (Optional) The requested engine version. Defaults to `AUTO`.\n\n#### result_configuration Argument Reference\n\nThe `result_configuration` configuration block within the `configuration` supports the following arguments:\n\n* `encryption_configuration` - (Optional) Configuration block with encryption settings. Documented below.\n* `output_location` - (Optional) The location in Amazon S3 where your query results are stored, such as `s3://path/to/query/bucket/`. For more information, see [Queries and Query Result Files](https://docs.aws.amazon.com/athena/latest/ug/querying.html).\n\n##### encryption_configuration Argument Reference\n\nThe `encryption_configuration` configuration block within the `result_configuration` of the `configuration` supports the following arguments:\n\n* `encryption_option` - (Required) Indicates whether Amazon S3 server-side encryption with Amazon S3-managed keys (`SSE_S3`), server-side encryption with KMS-managed keys (`SSE_KMS`), or client-side encryption with KMS-managed keys (`CSE_KMS`) is used. If a query runs in a workgroup and the workgroup overrides client-side settings, then the workgroup's setting for encryption is used. It specifies whether query results must be encrypted, for all queries that run in this workgroup.\n* `kms_key_arn` - (Optional) For `SSE_KMS` and `CSE_KMS`, this is the KMS key Amazon Resource Name (ARN).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the workgroup\n* `configuration` - Configuration block with various settings for the workgroup\n    * `engine_version` - Configuration block for the Athena Engine Versioning\n        * `effective_engine_version` -  The engine version on which the query runs. If `selected_engine_version` is set to `AUTO`, the effective engine version is chosen by Athena.\n* `id` - The workgroup name\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAthena Workgroups can be imported using their name, e.g.,\n\n```\n$ terraform import aws_athena_workgroup.example example\n```\n",
    "basename": "athena_workgroup.html"
  },
  "autoscaling_attachment.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_autoscaling_attachment",
    "description": "Provides an AutoScaling Group Attachment resource.",
    "preview": "# Resource: aws_autoscaling_attachment\n\nProvides an Auto Scaling …",
    "content": "\n\n# Resource: aws_autoscaling_attachment\n\nProvides an Auto Scaling Attachment resource.\n\n~> **NOTE on Auto Scaling Groups and ASG Attachments:** Terraform currently provides\nboth a standalone [`aws_autoscaling_attachment`](autoscaling_attachment.html) resource\n(describing an ASG attached to an ELB or ALB), and an [`aws_autoscaling_group`](autoscaling_group.html)\nwith `load_balancers` and `target_group_arns` defined in-line. These two methods are not\nmutually-exclusive. If `aws_autoscaling_attachment` resources are used, either alone or with inline\n`load_balancers` or `target_group_arns`, the `aws_autoscaling_group` resource must be configured\nto ignore changes to the `load_balancers` and `target_group_arns` arguments within a\n[`lifecycle` configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html).\n\n## Example Usage\n\n```terraform\n# Create a new load balancer attachment\nresource \"aws_autoscaling_attachment\" \"asg_attachment_bar\" {\n  autoscaling_group_name = aws_autoscaling_group.asg.id\n  elb                    = aws_elb.bar.id\n}\n```\n\n```terraform\n# Create a new ALB Target Group attachment\nresource \"aws_autoscaling_attachment\" \"asg_attachment_bar\" {\n  autoscaling_group_name = aws_autoscaling_group.asg.id\n  alb_target_group_arn   = aws_lb_target_group.test.arn\n}\n```\n\n## With An AutoScaling Group Resource\n\n```terraform\nresource \"aws_autoscaling_group\" \"asg\" {\n  # ... other configuration ...\n\n  lifecycle {\n    ignore_changes = [load_balancers, target_group_arns]\n  }\n}\n\nresource \"aws_autoscaling_attachment\" \"asg_attachment_bar\" {\n  autoscaling_group_name = aws_autoscaling_group.asg.id\n  elb                    = aws_elb.test.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `autoscaling_group_name` - (Required) Name of ASG to associate with the ELB.\n* `elb` - (Optional) The name of the ELB.\n* `alb_target_group_arn` - (Optional) The ARN of an ALB Target Group.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "autoscaling_attachment.html"
  },
  "autoscaling_group.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_autoscaling_group",
    "description": "Provides an Auto Scaling Group resource.",
    "preview": "# Resource: aws_autoscaling_group\n\nProvides an Auto Scaling Group …",
    "content": "\n\n# Resource: aws_autoscaling_group\n\nProvides an Auto Scaling Group resource.\n\n-> **Note:** You must specify either `launch_configuration`, `launch_template`, or `mixed_instances_policy`.\n\n~> **NOTE on Auto Scaling Groups and ASG Attachments:** Terraform currently provides\nboth a standalone [`aws_autoscaling_attachment`](autoscaling_attachment.html) resource\n(describing an ASG attached to an ELB or ALB), and an [`aws_autoscaling_group`](autoscaling_group.html)\nwith `load_balancers` and `target_group_arns` defined in-line. These two methods are not\nmutually-exclusive. If `aws_autoscaling_attachment` resources are used, either alone or with inline\n`load_balancers` or `target_group_arns`, the `aws_autoscaling_group` resource must be configured\nto ignore changes to the `load_balancers` and `target_group_arns` arguments within a\n[`lifecycle` configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_placement_group\" \"test\" {\n  name     = \"test\"\n  strategy = \"cluster\"\n}\n\nresource \"aws_autoscaling_group\" \"bar\" {\n  name                      = \"foobar3-terraform-test\"\n  max_size                  = 5\n  min_size                  = 2\n  health_check_grace_period = 300\n  health_check_type         = \"ELB\"\n  desired_capacity          = 4\n  force_delete              = true\n  placement_group           = aws_placement_group.test.id\n  launch_configuration      = aws_launch_configuration.foobar.name\n  vpc_zone_identifier       = [aws_subnet.example1.id, aws_subnet.example2.id]\n\n  initial_lifecycle_hook {\n    name                 = \"foobar\"\n    default_result       = \"CONTINUE\"\n    heartbeat_timeout    = 2000\n    lifecycle_transition = \"autoscaling:EC2_INSTANCE_LAUNCHING\"\n\n    notification_metadata = <<EOF\n{\n  \"foo\": \"bar\"\n}\nEOF\n\n    notification_target_arn = \"arn:aws:sqs:us-east-1:444455556666:queue1*\"\n    role_arn                = \"arn:aws:iam::123456789012:role/S3Access\"\n  }\n\n  tag {\n    key                 = \"foo\"\n    value               = \"bar\"\n    propagate_at_launch = true\n  }\n\n  timeouts {\n    delete = \"15m\"\n  }\n\n  tag {\n    key                 = \"lorem\"\n    value               = \"ipsum\"\n    propagate_at_launch = false\n  }\n}\n```\n\n### With Latest Version Of Launch Template\n\n```terraform\nresource \"aws_launch_template\" \"foobar\" {\n  name_prefix   = \"foobar\"\n  image_id      = \"ami-1a2b3c\"\n  instance_type = \"t2.micro\"\n}\n\nresource \"aws_autoscaling_group\" \"bar\" {\n  availability_zones = [\"us-east-1a\"]\n  desired_capacity   = 1\n  max_size           = 1\n  min_size           = 1\n\n  launch_template {\n    id      = aws_launch_template.foobar.id\n    version = \"$Latest\"\n  }\n}\n```\n\n### Mixed Instances Policy\n\n```terraform\nresource \"aws_launch_template\" \"example\" {\n  name_prefix   = \"example\"\n  image_id      = data.aws_ami.example.id\n  instance_type = \"c5.large\"\n}\n\nresource \"aws_autoscaling_group\" \"example\" {\n  availability_zones = [\"us-east-1a\"]\n  desired_capacity   = 1\n  max_size           = 1\n  min_size           = 1\n\n  mixed_instances_policy {\n    launch_template {\n      launch_template_specification {\n        launch_template_id = aws_launch_template.example.id\n      }\n\n      override {\n        instance_type     = \"c4.large\"\n        weighted_capacity = \"3\"\n      }\n\n      override {\n        instance_type     = \"c3.large\"\n        weighted_capacity = \"2\"\n      }\n    }\n  }\n}\n```\n\n### Mixed Instances Policy with Spot Instances and Capacity Rebalance\n\n```terraform\nresource \"aws_launch_template\" \"example\" {\n  name_prefix   = \"example\"\n  image_id      = data.aws_ami.example.id\n  instance_type = \"c5.large\"\n}\n\nresource \"aws_autoscaling_group\" \"example\" {\n  capacity_rebalance  = true\n  desired_capacity    = 12\n  max_size            = 15\n  min_size            = 12\n  vpc_zone_identifier = [aws_subnet.example1.id, aws_subnet.example2.id]\n\n  mixed_instances_policy {\n    instances_distribution {\n      on_demand_base_capacity                  = 0\n      on_demand_percentage_above_base_capacity = 25\n      spot_allocation_strategy                 = \"capacity-optimized\"\n    }\n\n    launch_template {\n      launch_template_specification {\n        launch_template_id = aws_launch_template.example.id\n      }\n\n      override {\n        instance_type     = \"c4.large\"\n        weighted_capacity = \"3\"\n      }\n\n      override {\n        instance_type     = \"c3.large\"\n        weighted_capacity = \"2\"\n      }\n    }\n  }\n}\n```\n\n### Mixed Instances Policy with Instance level LaunchTemplateSpecification Overrides\n\nWhen using a diverse instance set, some instance types might require a launch template with configuration values unique to that instance type such as a different AMI (Graviton2), architecture specific user data script, different EBS configuration, or different networking configuration.\n\n```terraform\nresource \"aws_launch_template\" \"example\" {\n  name_prefix   = \"example\"\n  image_id      = data.aws_ami.example.id\n  instance_type = \"c5.large\"\n}\n\nresource \"aws_launch_template\" \"example2\" {\n  name_prefix = \"example2\"\n  image_id    = data.aws_ami.example2.id\n}\n\nresource \"aws_autoscaling_group\" \"example\" {\n  availability_zones = [\"us-east-1a\"]\n  desired_capacity   = 1\n  max_size           = 1\n  min_size           = 1\n\n  mixed_instances_policy {\n    launch_template {\n      launch_template_specification {\n        launch_template_id = aws_launch_template.example.id\n      }\n\n      override {\n        instance_type     = \"c4.large\"\n        weighted_capacity = \"3\"\n      }\n\n      override {\n        instance_type = \"c6g.large\"\n        launch_template_specification {\n          launch_template_id = aws_launch_template.example2.id\n        }\n        weighted_capacity = \"2\"\n      }\n    }\n  }\n}\n```\n\n### Interpolated tags\n\n```terraform\nvariable \"extra_tags\" {\n  default = [\n    {\n      key                 = \"Foo\"\n      value               = \"Bar\"\n      propagate_at_launch = true\n    },\n    {\n      key                 = \"Baz\"\n      value               = \"Bam\"\n      propagate_at_launch = true\n    },\n  ]\n}\n\nresource \"aws_autoscaling_group\" \"bar\" {\n  name                 = \"foobar3-terraform-test\"\n  max_size             = 5\n  min_size             = 2\n  launch_configuration = aws_launch_configuration.foobar.name\n  vpc_zone_identifier  = [aws_subnet.example1.id, aws_subnet.example2.id]\n\n  tags = concat(\n    [\n      {\n        \"key\"                 = \"interpolation1\"\n        \"value\"               = \"value3\"\n        \"propagate_at_launch\" = true\n      },\n      {\n        \"key\"                 = \"interpolation2\"\n        \"value\"               = \"value4\"\n        \"propagate_at_launch\" = true\n      },\n    ],\n    var.extra_tags,\n  )\n}\n```\n\n### Automatically refresh all instances after the group is updated\n\n```terraform\nresource \"aws_autoscaling_group\" \"example\" {\n  availability_zones = [\"us-east-1a\"]\n  desired_capacity   = 1\n  max_size           = 2\n  min_size           = 1\n\n  launch_template {\n    id      = aws_launch_template.example.id\n    version = aws_launch_template.example.latest_version\n  }\n\n  tag {\n    key                 = \"Key\"\n    value               = \"Value\"\n    propagate_at_launch = true\n  }\n\n  instance_refresh {\n    strategy = \"Rolling\"\n    preferences {\n      min_healthy_percentage = 50\n    }\n    triggers = [\"tag\"]\n  }\n}\n\ndata \"aws_ami\" \"example\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"amzn-ami-hvm-*-x86_64-gp2\"]\n  }\n}\n\nresource \"aws_launch_template\" \"example\" {\n  image_id      = data.aws_ami.example.id\n  instance_type = \"t3.nano\"\n}\n```\n\n### Auto Scaling group with Warm Pool\n\n```terraform\nresource \"aws_launch_template\" \"example\" {\n  name_prefix   = \"example\"\n  image_id      = data.aws_ami.example.id\n  instance_type = \"c5.large\"\n}\n\nresource \"aws_autoscaling_group\" \"example\" {\n  availability_zones = [\"us-east-1a\"]\n  desired_capacity   = 1\n  max_size           = 5\n  min_size           = 1\n\n  warm_pool {\n    pool_state                  = \"Stopped\"\n    min_size                    = 1\n    max_group_prepared_capacity = 10\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the Auto Scaling Group. By default generated by Terraform. Conflicts with `name_prefix`.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified\n  prefix. Conflicts with `name`.\n* `max_size` - (Required) The maximum size of the Auto Scaling Group.\n* `min_size` - (Required) The minimum size of the Auto Scaling Group.\n    (See also [Waiting for Capacity](#waiting-for-capacity) below.)\n* `availability_zones` - (Optional) A list of one or more availability zones for the group. Used for EC2-Classic, attaching a network interface via id from a launch template and default subnets when not specified with `vpc_zone_identifier` argument. Conflicts with `vpc_zone_identifier`.\n* `capacity_rebalance` - (Optional) Indicates whether capacity rebalance is enabled. Otherwise, capacity rebalance is disabled.\n* `default_cooldown` - (Optional) The amount of time, in seconds, after a scaling activity completes before another scaling activity can start.\n* `launch_configuration` - (Optional) The name of the launch configuration to use.\n* `launch_template` - (Optional) Nested argument with Launch template specification to use to launch instances. See [Launch Template](#launch_template) below for more details.\n* `mixed_instances_policy` (Optional) Configuration block containing settings to define launch targets for Auto Scaling groups. See [Mixed Instances Policy](#mixed_instances_policy) below for more details.\n* `initial_lifecycle_hook` - (Optional) One or more\n  [Lifecycle Hooks](http://docs.aws.amazon.com/autoscaling/latest/userguide/lifecycle-hooks.html)\n  to attach to the Auto Scaling Group **before** instances are launched. The\n  syntax is exactly the same as the separate\n  [`aws_autoscaling_lifecycle_hook`](/docs/providers/aws/r/autoscaling_lifecycle_hook.html)\n  resource, without the `autoscaling_group_name` attribute. Please note that this will only work when creating\n  a new Auto Scaling Group. For all other use-cases, please use `aws_autoscaling_lifecycle_hook` resource.\n* `health_check_grace_period` - (Optional, Default: 300) Time (in seconds) after instance comes into service before checking health.\n* `health_check_type` - (Optional) \"EC2\" or \"ELB\". Controls how health checking is done.\n* `desired_capacity` - (Optional) The number of Amazon EC2 instances that\n    should be running in the group. (See also [Waiting for\n    Capacity](#waiting-for-capacity) below.)\n* `force_delete` - (Optional) Allows deleting the Auto Scaling Group without waiting\n   for all instances in the pool to terminate.  You can force an Auto Scaling Group to delete\n   even if it's in the process of scaling a resource. Normally, Terraform\n   drains all the instances before deleting the group.  This bypasses that\n   behavior and potentially leaves resources dangling.\n* `load_balancers` (Optional) A list of elastic load balancer names to add to the autoscaling\n   group names. Only valid for classic load balancers. For ALBs, use `target_group_arns` instead.\n* `vpc_zone_identifier` (Optional) A list of subnet IDs to launch resources in. Subnets automatically determine which availability zones the group will reside. Conflicts with `availability_zones`.\n* `target_group_arns` (Optional) A set of `aws_alb_target_group` ARNs, for use with Application or Network Load Balancing.\n* `termination_policies` (Optional) A list of policies to decide how the instances in the Auto Scaling Group should be terminated. The allowed values are `OldestInstance`, `NewestInstance`, `OldestLaunchConfiguration`, `ClosestToNextInstanceHour`, `OldestLaunchTemplate`, `AllocationStrategy`, `Default`.\n* `suspended_processes` - (Optional) A list of processes to suspend for the Auto Scaling Group. The allowed values are `Launch`, `Terminate`, `HealthCheck`, `ReplaceUnhealthy`, `AZRebalance`, `AlarmNotification`, `ScheduledActions`, `AddToLoadBalancer`.\nNote that if you suspend either the `Launch` or `Terminate` process types, it can prevent your Auto Scaling Group from functioning properly.\n* `tag` (Optional) Configuration block(s) containing resource tags. Conflicts with `tags`. See [Tag](#tag-and-tags) below for more details.\n* `tags` (Optional) Set of maps containing resource tags. Conflicts with `tag`. See [Tags](#tag-and-tags) below for more details.\n* `placement_group` (Optional) The name of the placement group into which you'll launch your instances, if any.\n* `metrics_granularity` - (Optional) The granularity to associate with the metrics to collect. The only valid value is `1Minute`. Default is `1Minute`.\n* `enabled_metrics` - (Optional) A list of metrics to collect. The allowed values are defined by the [underlying AWS API](https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_EnableMetricsCollection.html).\n* `wait_for_capacity_timeout` (Default: \"10m\") A maximum\n  [duration](https://golang.org/pkg/time/#ParseDuration) that Terraform should\n  wait for ASG instances to be healthy before timing out.  (See also [Waiting\n  for Capacity](#waiting-for-capacity) below.) Setting this to \"0\" causes\n  Terraform to skip all Capacity Waiting behavior.\n* `min_elb_capacity` - (Optional) Setting this causes Terraform to wait for\n  this number of instances from this Auto Scaling Group to show up healthy in the\n  ELB only on creation. Updates will not wait on ELB instance number changes.\n  (See also [Waiting for Capacity](#waiting-for-capacity) below.)\n* `wait_for_elb_capacity` - (Optional) Setting this will cause Terraform to wait\n  for exactly this number of healthy instances from this Auto Scaling Group in\n  all attached load balancers on both create and update operations. (Takes\n  precedence over `min_elb_capacity` behavior.)\n  (See also [Waiting for Capacity](#waiting-for-capacity) below.)\n* `protect_from_scale_in` (Optional) Allows setting instance protection. The\n   Auto Scaling Group will not select instances with this setting for termination\n   during scale in events.\n* `service_linked_role_arn` (Optional) The ARN of the service-linked role that the ASG will use to call other AWS services\n* `max_instance_lifetime` (Optional) The maximum amount of time, in seconds, that an instance can be in service, values must be either equal to 0 or between 86400 and 31536000 seconds.\n* `instance_refresh` - (Optional) If this block is configured, start an\n   [Instance Refresh](https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-instance-refresh.html)\n   when this Auto Scaling Group is updated. Defined [below](#instance_refresh).\n* `warm_pool` - (Optional) If this block is configured, add a [Warm Pool](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-warm-pools.html)\n   to the specified Auto Scaling group. Defined [below](#warm_pool)\n\n### launch_template\n\n~> **NOTE:** Either `id` or `name` must be specified.\n\nThe top-level `launch_template` block supports the following:\n\n* `id` - (Optional) The ID of the launch template. Conflicts with `name`.\n* `name` - (Optional) The name of the launch template. Conflicts with `id`.\n* `version` - (Optional) Template version. Can be version number, `$Latest`, or `$Default`. (Default: `$Default`).\n\n### mixed_instances_policy\n\n* `instances_distribution` - (Optional) Nested argument containing settings on how to mix on-demand and Spot instances in the Auto Scaling group. Defined below.\n* `launch_template` - (Required) Nested argument containing launch template settings along with the overrides to specify multiple instance types and weights. Defined below.\n\n#### mixed_instances_policy instances_distribution\n\nThis configuration block supports the following:\n\n* `on_demand_allocation_strategy` - (Optional) Strategy to use when launching on-demand instances. Valid values: `prioritized`. Default: `prioritized`.\n* `on_demand_base_capacity` - (Optional) Absolute minimum amount of desired capacity that must be fulfilled by on-demand instances. Default: `0`.\n* `on_demand_percentage_above_base_capacity` - (Optional) Percentage split between on-demand and Spot instances above the base on-demand capacity. Default: `100`.\n* `spot_allocation_strategy` - (Optional) How to allocate capacity across the Spot pools. Valid values: `lowest-price`, `capacity-optimized`, `capacity-optimized-prioritized`. Default: `lowest-price`.\n* `spot_instance_pools` - (Optional) Number of Spot pools per availability zone to allocate capacity. EC2 Auto Scaling selects the cheapest Spot pools and evenly allocates Spot capacity across the number of Spot pools that you specify. Only available with `spot_allocation_strategy` set to `lowest-price`. Otherwise it must be set to `0`, if it has been defined before. Default: `2`.\n* `spot_max_price` - (Optional) Maximum price per unit hour that the user is willing to pay for the Spot instances. Default: an empty string which means the on-demand price.\n\n#### mixed_instances_policy launch_template\n\nThis configuration block supports the following:\n\n* `launch_template_specification` - (Required) Nested argument defines the Launch Template. Defined below.\n* `override` - (Optional) List of nested arguments provides the ability to specify multiple instance types. This will override the same parameter in the launch template. For on-demand instances, Auto Scaling considers the order of preference of instance types to launch based on the order specified in the overrides list. Defined below.\n\n##### mixed_instances_policy launch_template launch_template_specification\n\n~> **NOTE:** Either `launch_template_id` or `launch_template_name` must be specified.\n\nThis configuration block supports the following:\n\n* `launch_template_id` - (Optional) The ID of the launch template. Conflicts with `launch_template_name`.\n* `launch_template_name` - (Optional) The name of the launch template. Conflicts with `launch_template_id`.\n* `version` - (Optional) Template version. Can be version number, `$Latest`, or `$Default`. (Default: `$Default`).\n\n##### mixed_instances_policy launch_template override\n\nThis configuration block supports the following:\n\n* `instance_type` - (Optional) Override the instance type in the Launch Template.\n* `launch_template_specification` - (Optional) Override the instance launch template specification in the Launch Template.\n* `weighted_capacity` - (Optional) The number of capacity units, which gives the instance type a proportional weight to other instance types.\n\n### tag and tags\n\nThe `tag` attribute accepts exactly one tag declaration with the following fields:\n\n* `key` - (Required) Key\n* `value` - (Required) Value\n* `propagate_at_launch` - (Required) Enables propagation of the tag to\n   Amazon EC2 instances launched via this ASG\n\nTo declare multiple tags additional `tag` blocks can be specified.\nAlternatively the `tags` attributes can be used, which accepts a list of maps containing the above field names as keys and their respective values.\nThis allows the construction of dynamic lists of tags which is not possible using the single `tag` attribute.\n`tag` and `tags` are mutually exclusive, only one of them can be specified.\n\n~> **NOTE:** Other AWS APIs may automatically add special tags to their associated Auto Scaling Group for management purposes, such as ECS Capacity Providers adding the `AmazonECSManaged` tag. These generally should be included in the configuration so Terraform does not attempt to remove them and so if the `min_size` was greater than zero on creation, that these tag(s) are applied to any initial EC2 Instances in the Auto Scaling Group. If these tag(s) were missing in the Auto Scaling Group configuration on creation, affected EC2 Instances missing the tags may require manual intervention of adding the tags to ensure they work properly with the other AWS service.\n\n### instance_refresh\n\nThis configuration block supports the following:\n\n* `strategy` - (Required) The strategy to use for instance refresh. The only allowed value is `Rolling`. See [StartInstanceRefresh Action](https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_StartInstanceRefresh.html#API_StartInstanceRefresh_RequestParameters) for more information.\n* `preferences` - (Optional) Override default parameters for Instance Refresh.\n    * `checkpoint_delay` - (Optional) The number of seconds to wait after a checkpoint. Defaults to `3600`.\n    * `checkpoint_percentages` - (Optional) List of percentages for each checkpoint. Values must be unique and in ascending order. To replace all instances, the final number must be `100`.\n    * `instance_warmup` - (Optional) The number of seconds until a newly launched instance is configured and ready to use. Default behavior is to use the Auto Scaling Group's health check grace period.\n    * `min_healthy_percentage` - (Optional) The amount of capacity in the Auto Scaling group that must remain healthy during an instance refresh to allow the operation to continue, as a percentage of the desired capacity of the Auto Scaling group. Defaults to `90`.\n* `triggers` - (Optional) Set of additional property names that will trigger an Instance Refresh. A refresh will always be triggered by a change in any of `launch_configuration`, `launch_template`, or `mixed_instances_policy`.\n\n~> **NOTE:** A refresh is started when any of the following Auto Scaling Group properties change: `launch_configuration`, `launch_template`, `mixed_instances_policy`. Additional properties can be specified in the `triggers` property of `instance_refresh`.\n\n~> **NOTE:** Auto Scaling Groups support up to one active instance refresh at a time. When this resource is updated, any existing refresh is cancelled.\n\n~> **NOTE:** Depending on health check settings and group size, an instance refresh may take a long time or fail. This resource does not wait for the instance refresh to complete.\n\n### warm_pool\n\nThis configuration block supports the following:\n\n* `pool_state` - (Optional) Sets the instance state to transition to after the lifecycle hooks finish. Valid values are: Stopped (default) or Running.\n* `min_size` - (Optional) Specifies the minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.\n* `max_group_prepared_capacity` - (Optional) Specifies the total maximum number of instances that are allowed to be in the warm pool or in any state except Terminated for the Auto Scaling group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Auto Scaling Group id.\n* `arn` - The ARN for this Auto Scaling Group\n* `availability_zones` - The availability zones of the Auto Scaling Group.\n* `min_size` - The minimum size of the Auto Scaling Group\n* `max_size` - The maximum size of the Auto Scaling Group\n* `default_cooldown` - Time between a scaling activity and the succeeding scaling activity.\n* `name` - The name of the Auto Scaling Group\n* `health_check_grace_period` - Time after instance comes into service before checking health.\n* `health_check_type` - \"EC2\" or \"ELB\". Controls how health checking is done.\n* `desired_capacity` -The number of Amazon EC2 instances that should be running in the group.\n* `launch_configuration` - The launch configuration of the Auto Scaling Group\n* `vpc_zone_identifier` (Optional) - The VPC zone identifier\n\n~> **NOTE:** When using `ELB` as the `health_check_type`, `health_check_grace_period` is required.\n\n~> **NOTE:** Terraform has two types of ways you can add lifecycle hooks - via\nthe `initial_lifecycle_hook` attribute from this resource, or via the separate\n[`aws_autoscaling_lifecycle_hook`](/docs/providers/aws/r/autoscaling_lifecycle_hook.html)\nresource. `initial_lifecycle_hook` exists here because any lifecycle hooks\nadded with `aws_autoscaling_lifecycle_hook` will not be added until the\nAuto Scaling Group has been created, and depending on your\n[capacity](#waiting-for-capacity) settings, after the initial instances have\nbeen launched, creating unintended behavior. If you need hooks to run on all\ninstances, add them with `initial_lifecycle_hook` here, but take\ncare to not duplicate these hooks in `aws_autoscaling_lifecycle_hook`.\n\n## Timeouts\n\n`autoscaling_group` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `delete` - (Default `10 minutes`) Used for destroying ASG.\n\n\n## Waiting for Capacity\n\nA newly-created ASG is initially empty and begins to scale to `min_size` (or\n`desired_capacity`, if specified) by launching instances using the provided\nLaunch Configuration. These instances take time to launch and boot.\n\nOn ASG Update, changes to these values also take time to result in the target\nnumber of instances providing service.\n\nTerraform provides two mechanisms to help consistently manage ASG scale up\ntime across dependent resources.\n\n#### Waiting for ASG Capacity\n\nThe first is default behavior. Terraform waits after ASG creation for\n`min_size` (or `desired_capacity`, if specified) healthy instances to show up\nin the ASG before continuing.\n\nIf `min_size` or `desired_capacity` are changed in a subsequent update,\nTerraform will also wait for the correct number of healthy instances before\ncontinuing.\n\nTerraform considers an instance \"healthy\" when the ASG reports `HealthStatus:\n\"Healthy\"` and `LifecycleState: \"InService\"`. See the [AWS AutoScaling\nDocs](https://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/AutoScalingGroupLifecycle.html)\nfor more information on an ASG's lifecycle.\n\nTerraform will wait for healthy instances for up to\n`wait_for_capacity_timeout`. If ASG creation is taking more than a few minutes,\nit's worth investigating for scaling activity errors, which can be caused by\nproblems with the selected Launch Configuration.\n\nSetting `wait_for_capacity_timeout` to `\"0\"` disables ASG Capacity waiting.\n\n#### Waiting for ELB Capacity\n\nThe second mechanism is optional, and affects ASGs with attached ELBs specified\nvia the `load_balancers` attribute or with ALBs specified with `target_group_arns`.\n\nThe `min_elb_capacity` parameter causes Terraform to wait for at least the\nrequested number of instances to show up `\"InService\"` in all attached ELBs\nduring ASG creation.  It has no effect on ASG updates.\n\nIf `wait_for_elb_capacity` is set, Terraform will wait for exactly that number\nof Instances to be `\"InService\"` in all attached ELBs on both creation and\nupdates.\n\nThese parameters can be used to ensure that service is being provided before\nTerraform moves on. If new instances don't pass the ELB's health checks for any\nreason, the Terraform apply will time out, and the ASG will be marked as\ntainted (i.e., marked to be destroyed in a follow up run).\n\nAs with ASG Capacity, Terraform will wait for up to `wait_for_capacity_timeout`\nfor the proper number of instances to be healthy.\n\n#### Troubleshooting Capacity Waiting Timeouts\n\nIf ASG creation takes more than a few minutes, this could indicate one of a\nnumber of configuration problems. See the [AWS Docs on Load Balancer\nTroubleshooting](https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-troubleshooting.html)\nfor more information.\n\n\n## Import\n\nAuto Scaling Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_autoscaling_group.web web-asg\n```\n",
    "basename": "autoscaling_group.html"
  },
  "autoscaling_group_tag.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_autoscaling_group_tag",
    "description": "Manages an individual Autoscaling Group tag",
    "preview": "# Resource: aws_autoscaling_group_tag\n\nManages an individual …",
    "content": "\n\n# Resource: aws_autoscaling_group_tag\n\nManages an individual Autoscaling Group (ASG) tag. This resource should only be used in cases where ASGs are created outside Terraform (e.g., ASGs implicitly created by EKS Node Groups).\n\n~> **NOTE:** This tagging resource should not be combined with the Terraform resource for managing the parent resource. For example, using `aws_autoscaling_group` and `aws_autoscaling_group_tag` to manage tags of the same ASG will cause a perpetual difference where the `aws_autoscaling_group` resource will try to remove the tag being added by the `aws_autoscaling_group_tag` resource.\n\n~> **NOTE:** This tagging resource does not use the [provider `ignore_tags` configuration](/docs/providers/aws/index.html#ignore_tags).\n\n## Example Usage\n\n```terraform\nresource \"aws_eks_node_group\" \"example\" {\n  cluster_name    = \"example\"\n  node_group_name = \"example\"\n\n  # ... other configuration ...\n}\n\nresource \"aws_autoscaling_group_tag\" \"example\" {\n  for_each = toset(\n    [for asg in flatten(\n      [for resources in aws_eks_node_group.example.resources : resources.autoscaling_groups]\n    ) : asg.name]\n  )\n\n  autoscaling_group_name = each.value\n\n  tag {\n    key   = \"k8s.io/cluster-autoscaler/node-template/label/eks.amazonaws.com/capacityType\"\n    value = \"SPOT\"\n\n    propagate_at_launch = false\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `autoscaling_group_name` - (Required) The name of the Autoscaling Group to apply the tag to.\n* `tag` - (Required) The tag to create. The `tag` block is documented below.\n\nThe `tag` block supports the following arguments:\n\n* `key` - (Required) Tag name.\n* `value` - (Required) Tag value.\n* `propagate_at_launch` - (Required) Whether to propagate the tags to instances launched by the ASG.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ASG name and key, separated by a comma (`,`)\n\n## Import\n\n`aws_autoscaling_group_tag` can be imported by using the ASG name and key, separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_autoscaling_group_tag.example asg-example,k8s.io/cluster-autoscaler/node-template/label/eks.amazonaws.com/capacityType\n```\n",
    "basename": "autoscaling_group_tag.html"
  },
  "autoscaling_lifecycle_hook.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_autoscaling_lifecycle_hook",
    "description": "Provides an AutoScaling Lifecycle Hook resource.",
    "preview": "# Resource: aws_autoscaling_lifecycle_hook\n\nProvides an AutoScaling …",
    "content": "\n\n# Resource: aws_autoscaling_lifecycle_hook\n\nProvides an AutoScaling Lifecycle Hook resource.\n\n~> **NOTE:** Terraform has two types of ways you can add lifecycle hooks - via\nthe `initial_lifecycle_hook` attribute from the\n[`aws_autoscaling_group`](/docs/providers/aws/r/autoscaling_group.html)\nresource, or via this one. Hooks added via this resource will not be added\nuntil the autoscaling group has been created, and depending on your\n[capacity](/docs/providers/aws/r/autoscaling_group.html#waiting-for-capacity)\nsettings, after the initial instances have been launched, creating unintended\nbehavior. If you need hooks to run on all instances, add them with\n`initial_lifecycle_hook` in\n[`aws_autoscaling_group`](/docs/providers/aws/r/autoscaling_group.html),\nbut take care to not duplicate those hooks with this resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_autoscaling_group\" \"foobar\" {\n  availability_zones   = [\"us-west-2a\"]\n  name                 = \"terraform-test-foobar5\"\n  health_check_type    = \"EC2\"\n  termination_policies = [\"OldestInstance\"]\n\n  tag {\n    key                 = \"Foo\"\n    value               = \"foo-bar\"\n    propagate_at_launch = true\n  }\n}\n\nresource \"aws_autoscaling_lifecycle_hook\" \"foobar\" {\n  name                   = \"foobar\"\n  autoscaling_group_name = aws_autoscaling_group.foobar.name\n  default_result         = \"CONTINUE\"\n  heartbeat_timeout      = 2000\n  lifecycle_transition   = \"autoscaling:EC2_INSTANCE_LAUNCHING\"\n\n  notification_metadata = <<EOF\n{\n  \"foo\": \"bar\"\n}\nEOF\n\n  notification_target_arn = \"arn:aws:sqs:us-east-1:444455556666:queue1*\"\n  role_arn                = \"arn:aws:iam::123456789012:role/S3Access\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the lifecycle hook.\n* `autoscaling_group_name` - (Required) The name of the Auto Scaling group to which you want to assign the lifecycle hook\n* `default_result` - (Optional) Defines the action the Auto Scaling group should take when the lifecycle hook timeout elapses or if an unexpected failure occurs. The value for this parameter can be either CONTINUE or ABANDON. The default value for this parameter is ABANDON.\n* `heartbeat_timeout` - (Optional) Defines the amount of time, in seconds, that can elapse before the lifecycle hook times out. When the lifecycle hook times out, Auto Scaling performs the action defined in the DefaultResult parameter\n* `lifecycle_transition` - (Required) The instance state to which you want to attach the lifecycle hook. For a list of lifecycle hook types, see [describe-lifecycle-hook-types](https://docs.aws.amazon.com/cli/latest/reference/autoscaling/describe-lifecycle-hook-types.html#examples)\n* `notification_metadata` - (Optional) Contains additional information that you want to include any time Auto Scaling sends a message to the notification target.\n* `notification_target_arn` - (Optional) The ARN of the notification target that Auto Scaling will use to notify you when an instance is in the transition state for the lifecycle hook. This ARN target can be either an SQS queue or an SNS topic.\n* `role_arn` - (Optional) The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nAutoScaling Lifecycle Hooks can be imported using the role autoscaling_group_name and name separated by `/`.\n\n```\n$ terraform import aws_autoscaling_lifecycle_hook.test-lifecycle-hook asg-name/lifecycle-hook-name\n```\n",
    "basename": "autoscaling_lifecycle_hook.html"
  },
  "autoscaling_notification.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_autoscaling_notification",
    "description": "Provides an AutoScaling Group with Notification support",
    "preview": "# Resource: aws_autoscaling_notification\n\nProvides an AutoScaling …",
    "content": "\n\n# Resource: aws_autoscaling_notification\n\nProvides an AutoScaling Group with Notification support, via SNS Topics. Each of\nthe `notifications` map to a [Notification Configuration][2] inside Amazon Web\nServices, and are applied to each AutoScaling Group you supply.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_autoscaling_notification\" \"example_notifications\" {\n  group_names = [\n    aws_autoscaling_group.bar.name,\n    aws_autoscaling_group.foo.name,\n  ]\n\n  notifications = [\n    \"autoscaling:EC2_INSTANCE_LAUNCH\",\n    \"autoscaling:EC2_INSTANCE_TERMINATE\",\n    \"autoscaling:EC2_INSTANCE_LAUNCH_ERROR\",\n    \"autoscaling:EC2_INSTANCE_TERMINATE_ERROR\",\n  ]\n\n  topic_arn = aws_sns_topic.example.arn\n}\n\nresource \"aws_sns_topic\" \"example\" {\n  name = \"example-topic\"\n\n  # arn is an exported attribute\n}\n\nresource \"aws_autoscaling_group\" \"bar\" {\n  name = \"foobar1-terraform-test\"\n\n  # ...\n}\n\nresource \"aws_autoscaling_group\" \"foo\" {\n  name = \"barfoo-terraform-test\"\n\n  # ...\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `group_names` - (Required) A list of AutoScaling Group Names\n* `notifications` - (Required) A list of Notification Types that trigger\nnotifications. Acceptable values are documented [in the AWS documentation here][1]\n* `topic_arn` - (Required) The Topic ARN for notifications to be sent through\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `group_names`\n* `notifications`\n* `topic_arn`\n\n\n[1]: https://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_NotificationConfiguration.html\n[2]: https://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_DescribeNotificationConfigurations.html\n",
    "basename": "autoscaling_notification.html"
  },
  "autoscaling_policy.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_autoscaling_policy",
    "description": "Provides an AutoScaling Scaling Group resource.",
    "preview": "# Resource: aws_autoscaling_policy\n\nProvides an AutoScaling Scaling …",
    "content": "\n\n# Resource: aws_autoscaling_policy\n\nProvides an AutoScaling Scaling Policy resource.\n\n~> **NOTE:** You may want to omit `desired_capacity` attribute from attached `aws_autoscaling_group`\nwhen using autoscaling policies. It's good practice to pick either\n[manual](https://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/as-manual-scaling.html)\nor [dynamic](https://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/as-scale-based-on-demand.html)\n(policy-based) scaling.\n\n## Example Usage\n\n```terraform\nresource \"aws_autoscaling_policy\" \"bat\" {\n  name                   = \"foobar3-terraform-test\"\n  scaling_adjustment     = 4\n  adjustment_type        = \"ChangeInCapacity\"\n  cooldown               = 300\n  autoscaling_group_name = aws_autoscaling_group.bar.name\n}\n\nresource \"aws_autoscaling_group\" \"bar\" {\n  availability_zones        = [\"us-east-1a\"]\n  name                      = \"foobar3-terraform-test\"\n  max_size                  = 5\n  min_size                  = 2\n  health_check_grace_period = 300\n  health_check_type         = \"ELB\"\n  force_delete              = true\n  launch_configuration      = aws_launch_configuration.foo.name\n}\n```\n\n## Argument Reference\n\n* `name` - (Required) The name of the policy.\n* `autoscaling_group_name` - (Required) The name of the autoscaling group.\n* `adjustment_type` - (Optional) Specifies whether the adjustment is an absolute number or a percentage of the current capacity. Valid values are `ChangeInCapacity`, `ExactCapacity`, and `PercentChangeInCapacity`.\n* `policy_type` - (Optional) The policy type, either \"SimpleScaling\", \"StepScaling\", \"TargetTrackingScaling\", or \"PredictiveScaling\". If this value isn't provided, AWS will default to \"SimpleScaling.\"\n* `predictive_scaling_configuration` - (Optional) The predictive scaling policy configuration to use with Amazon EC2 Auto Scaling.\n* `estimated_instance_warmup` - (Optional) The estimated time, in seconds, until a newly launched instance will contribute CloudWatch metrics. Without a value, AWS will default to the group's specified cooldown period.\n\nThe following argument is only available to \"SimpleScaling\" and \"StepScaling\" type policies:\n\n* `min_adjustment_magnitude` - (Optional) Minimum value to scale by when `adjustment_type` is set to `PercentChangeInCapacity`.\n\nThe following arguments are only available to \"SimpleScaling\" type policies:\n\n* `cooldown` - (Optional) The amount of time, in seconds, after a scaling activity completes and before the next scaling activity can start.\n* `scaling_adjustment` - (Optional) The number of instances by which to scale. `adjustment_type` determines the interpretation of this number (e.g., as an absolute number or as a percentage of the existing Auto Scaling group size). A positive increment adds to the current capacity and a negative value removes from the current capacity.\n\nThe following arguments are only available to \"StepScaling\" type policies:\n\n* `metric_aggregation_type` - (Optional) The aggregation type for the policy's metrics. Valid values are \"Minimum\", \"Maximum\", and \"Average\". Without a value, AWS will treat the aggregation type as \"Average\".\n* `step_adjustment` - (Optional) A set of adjustments that manage\ngroup scaling. These have the following structure:\n\n```terraform\nresource \"aws_autoscaling_policy\" \"example\" {\n  # ... other configuration ...\n\n  step_adjustment {\n    scaling_adjustment          = -1\n    metric_interval_lower_bound = 1.0\n    metric_interval_upper_bound = 2.0\n  }\n\n  step_adjustment {\n    scaling_adjustment          = 1\n    metric_interval_lower_bound = 2.0\n    metric_interval_upper_bound = 3.0\n  }\n}\n```\n\nThe following fields are available in step adjustments:\n\n* `scaling_adjustment` - (Required) The number of members by which to\nscale, when the adjustment bounds are breached. A positive value scales\nup. A negative value scales down.\n* `metric_interval_lower_bound` - (Optional) The lower bound for the\ndifference between the alarm threshold and the CloudWatch metric.\nWithout a value, AWS will treat this bound as infinity.\n* `metric_interval_upper_bound` - (Optional) The upper bound for the\ndifference between the alarm threshold and the CloudWatch metric.\nWithout a value, AWS will treat this bound as infinity. The upper bound\nmust be greater than the lower bound.\n\nNotice the bounds are **relative** to the alarm threshold, meaning that the starting point is not 0%, but the alarm threshold. Check the official [docs](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-steps) for a detailed example.\n\nThe following arguments are only available to \"TargetTrackingScaling\" type policies:\n\n* `target_tracking_configuration` - (Optional) A target tracking policy. These have the following structure:\n\n```terraform\nresource \"aws_autoscaling_policy\" \"example\" {\n  # ... other configuration ...\n\n  target_tracking_configuration {\n    predefined_metric_specification {\n      predefined_metric_type = \"ASGAverageCPUUtilization\"\n    }\n\n    target_value = 40.0\n  }\n}\n```\n\nThe following fields are available in target tracking configuration:\n\n* `predefined_metric_specification` - (Optional) A predefined metric. Conflicts with `customized_metric_specification`.\n* `customized_metric_specification` - (Optional) A customized metric. Conflicts with `predefined_metric_specification`.\n* `target_value` - (Required) The target value for the metric.\n* `disable_scale_in` - (Optional, Default: false) Indicates whether scale in by the target tracking policy is disabled.\n\n### predefined_metric_specification\n\nThe following arguments are supported:\n\n* `predefined_metric_type` - (Required) The metric type.\n* `resource_label` - (Optional) Identifies the resource associated with the metric type.\n\n### customized_metric_specification\n\nThe following arguments are supported:\n\n* `metric_dimension` - (Optional) The dimensions of the metric.\n* `metric_name` - (Required) The name of the metric.\n* `namespace` - (Required) The namespace of the metric.\n* `statistic` - (Required) The statistic of the metric.\n* `unit` - (Optional) The unit of the metric.\n\n#### metric_dimension\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the dimension.\n* `value` - (Required) The value of the dimension.\n\n### predictive_scaling_configuration\n\nThe following arguments are supported:\n\n* `max_capacity_breach_behavior` - (Optional) Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity of the Auto Scaling group. Valid values are `HonorMaxCapacity` or `IncreaseMaxCapacity`. Default is `HonorMaxCapacity`.\n* `max_capacity_buffer` - (Optional) The size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity. Valid range is `0` to `100`. If set to `0`, Amazon EC2 Auto Scaling may scale capacity higher than the maximum capacity to equal but not exceed forecast capacity.\n* `metric_specification` - (Required) This structure includes the metrics and target utilization to use for predictive scaling.\n* `mode` - (Optional) The predictive scaling mode. Valid values are `ForecastAndScale` and `ForecastOnly`. Default is `ForecastOnly`.\n* `scheduling_buffer_time` - (Optional) The amount of time, in seconds, by which the instance launch time can be advanced. Minimum is `0`.\n\n#### metric_specification\n\nThe following arguments are supported:\n\n* `predefined_load_metric_specification` - (Optional) The load metric specification.\n* `predefined_metric_pair_specification` - (Optional) The metric pair specification from which Amazon EC2 Auto Scaling determines the appropriate scaling metric and load metric to use.\n* `predefined_scaling_metric_specification` - (Optional) The scaling metric specification.\n\n##### predefined_load_metric_specification\n\nThe following arguments are supported:\n\n* `predefined_metric_type` - (Required) The metric type. Valid values are `ASGTotalCPUUtilization`, `ASGTotalNetworkIn`, `ASGTotalNetworkOut`, or `ALBTargetGroupRequestCount`.\n* `resource_label` - (Required) A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group.\n\n##### predefined_metric_pair_specification\n\nThe following arguments are supported:\n\n* `predefined_metric_type` - (Required) Indicates which metrics to use. There are two different types of metrics for each metric type: one is a load metric and one is a scaling metric. For example, if the metric type is `ASGCPUUtilization`, the Auto Scaling group's total CPU metric is used as the load metric, and the average CPU metric is used for the scaling metric. Valid values are `ASGCPUUtilization`, `ASGNetworkIn`, `ASGNetworkOut`, or `ALBRequestCount`.\n* `resource_label` - (Required) A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group.\n\n##### predefined_scaling_metric_specification\n\nThe following arguments are supported:\n\n* `predefined_metric_type` - (Required) Describes a scaling metric for a predictive scaling policy. Valid values are `ASGAverageCPUUtilization`, `ASGAverageNetworkIn`, `ASGAverageNetworkOut`, or `ALBRequestCountPerTarget`.\n* `resource_label` - (Required) A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS to the scaling policy.\n* `name` - The scaling policy's name.\n* `autoscaling_group_name` - The scaling policy's assigned autoscaling group.\n* `adjustment_type` - The scaling policy's adjustment type.\n* `policy_type` - The scaling policy's type.\n\n## Import\n\nAutoScaling scaling policy can be imported using the role autoscaling_group_name and name separated by `/`.\n\n```\n$ terraform import aws_autoscaling_policy.test-policy asg-name/policy-name\n```\n",
    "basename": "autoscaling_policy.html"
  },
  "autoscaling_schedule.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_autoscaling_schedule",
    "description": "Provides an AutoScaling Schedule resource.",
    "preview": "# Resource: aws_autoscaling_schedule\n\nProvides an AutoScaling …",
    "content": "\n\n# Resource: aws_autoscaling_schedule\n\nProvides an AutoScaling Schedule resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_autoscaling_group\" \"foobar\" {\n  availability_zones        = [\"us-west-2a\"]\n  name                      = \"terraform-test-foobar5\"\n  max_size                  = 1\n  min_size                  = 1\n  health_check_grace_period = 300\n  health_check_type         = \"ELB\"\n  force_delete              = true\n  termination_policies      = [\"OldestInstance\"]\n}\n\nresource \"aws_autoscaling_schedule\" \"foobar\" {\n  scheduled_action_name  = \"foobar\"\n  min_size               = 0\n  max_size               = 1\n  desired_capacity       = 0\n  start_time             = \"2016-12-11T18:00:00Z\"\n  end_time               = \"2016-12-12T06:00:00Z\"\n  autoscaling_group_name = aws_autoscaling_group.foobar.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `autoscaling_group_name` - (Required) The name or Amazon Resource Name (ARN) of the Auto Scaling group.\n* `scheduled_action_name` - (Required) The name of this scaling action.\n* `start_time` - (Optional) The time for this action to start, in \"YYYY-MM-DDThh:mm:ssZ\" format in UTC/GMT only (for example, 2014-06-01T00:00:00Z ).\n                            If you try to schedule your action in the past, Auto Scaling returns an error message.\n* `end_time` - (Optional) The time for this action to end, in \"YYYY-MM-DDThh:mm:ssZ\" format in UTC/GMT only (for example, 2014-06-01T00:00:00Z ).\n                          If you try to schedule your action in the past, Auto Scaling returns an error message.\n* `recurrence` - (Optional) The time when recurring future actions will start. Start time is specified by the user following the Unix cron syntax format.\n* `time_zone` - (Optional)  The timezone for the cron expression. Valid values are the canonical names of the IANA time zones (such as Etc/GMT+9 or Pacific/Tahiti).\n* `min_size` - (Optional) The minimum size for the Auto Scaling group. Default 0.\nSet to -1 if you don't want to change the minimum size at the scheduled time.\n* `max_size` - (Optional) The maximum size for the Auto Scaling group. Default 0.\nSet to -1 if you don't want to change the maximum size at the scheduled time.\n* `desired_capacity` - (Optional) The number of EC2 instances that should be running in the group. Default 0.  Set to -1 if you don't want to change the desired capacity at the scheduled time.\n\n~> **NOTE:** When `start_time` and `end_time` are specified with `recurrence` , they form the boundaries of when the recurring action will start and stop.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS to the autoscaling schedule.\n\n## Import\n\nAutoScaling ScheduledAction can be imported using the `auto-scaling-group-name` and `scheduled-action-name`, e.g.,\n\n```\n$ terraform import aws_autoscaling_schedule.resource-name auto-scaling-group-name/scheduled-action-name\n```\n",
    "basename": "autoscaling_schedule.html"
  },
  "autoscalingplans_scaling_plan.html": {
    "subcategory": "Autoscaling Plans",
    "layout": "aws",
    "page_title": "AWS: aws_autoscalingplans_scaling_plan",
    "description": "Manages an AWS Auto Scaling scaling plan.",
    "preview": "# Resource: aws_autoscalingplans_scaling_plan\n\nManages an AWS Auto …",
    "content": "\n\n# Resource: aws_autoscalingplans_scaling_plan\n\nManages an AWS Auto Scaling scaling plan.\nMore information can be found in the [AWS Auto Scaling User Guide](https://docs.aws.amazon.com/autoscaling/plans/userguide/what-is-aws-auto-scaling.html).\n\n~> **NOTE:** The AWS Auto Scaling service uses an AWS IAM service-linked role to manage predictive scaling of Amazon EC2 Auto Scaling groups. The service attempts to automatically create this role the first time a scaling plan with predictive scaling enabled is created.\nAn [`aws_iam_service_linked_role`](/docs/providers/aws/r/iam_service_linked_role.html) resource can be used to manually manage this role.\nSee the [AWS documentation](https://docs.aws.amazon.com/autoscaling/plans/userguide/aws-auto-scaling-service-linked-roles.html#create-service-linked-role-manual) for more details.\n\n## Example Usage\n\n### Basic Dynamic Scaling\n\n```terraform\ndata \"aws_availability_zones\" \"available\" {}\n\nresource \"aws_autoscaling_group\" \"example\" {\n  name_prefix = \"example\"\n\n  launch_configuration = aws_launch_configuration.example.name\n  availability_zones   = [data.aws_availability_zones.available.names[0]]\n\n  min_size = 0\n  max_size = 3\n\n  tags = [\n    {\n      key                 = \"application\"\n      value               = \"example\"\n      propagate_at_launch = true\n    },\n  ]\n}\n\nresource \"aws_autoscalingplans_scaling_plan\" \"example\" {\n  name = \"example-dynamic-cost-optimization\"\n\n  application_source {\n    tag_filter {\n      key    = \"application\"\n      values = [\"example\"]\n    }\n  }\n\n  scaling_instruction {\n    max_capacity       = 3\n    min_capacity       = 0\n    resource_id        = format(\"autoScalingGroup/%s\", aws_autoscaling_group.example.name)\n    scalable_dimension = \"autoscaling:autoScalingGroup:DesiredCapacity\"\n    service_namespace  = \"autoscaling\"\n\n    target_tracking_configuration {\n      predefined_scaling_metric_specification {\n        predefined_scaling_metric_type = \"ASGAverageCPUUtilization\"\n      }\n\n      target_value = 70\n    }\n  }\n}\n```\n\n### Basic Predictive Scaling\n\n```terraform\ndata \"aws_availability_zones\" \"available\" {}\n\nresource \"aws_autoscaling_group\" \"example\" {\n  name_prefix = \"example\"\n\n  launch_configuration = aws_launch_configuration.example.name\n  availability_zones   = [data.aws_availability_zones.available.names[0]]\n\n  min_size = 0\n  max_size = 3\n\n  tags = [\n    {\n      key                 = \"application\"\n      value               = \"example\"\n      propagate_at_launch = true\n    },\n  ]\n}\n\nresource \"aws_autoscalingplans_scaling_plan\" \"example\" {\n  name = \"example-predictive-cost-optimization\"\n\n  application_source {\n    tag_filter {\n      key    = \"application\"\n      values = [\"example\"]\n    }\n  }\n\n  scaling_instruction {\n    disable_dynamic_scaling = true\n\n    max_capacity       = 3\n    min_capacity       = 0\n    resource_id        = format(\"autoScalingGroup/%s\", aws_autoscaling_group.example.name)\n    scalable_dimension = \"autoscaling:autoScalingGroup:DesiredCapacity\"\n    service_namespace  = \"autoscaling\"\n\n    target_tracking_configuration {\n      predefined_scaling_metric_specification {\n        predefined_scaling_metric_type = \"ASGAverageCPUUtilization\"\n      }\n\n      target_value = 70\n    }\n\n    predictive_scaling_max_capacity_behavior = \"SetForecastCapacityToMaxCapacity\"\n    predictive_scaling_mode                  = \"ForecastAndScale\"\n\n    predefined_load_metric_specification {\n      predefined_load_metric_type = \"ASGTotalCPUUtilization\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the scaling plan. Names cannot contain vertical bars, colons, or forward slashes.\n* `application_source` - (Required) A CloudFormation stack or set of tags. You can create one scaling plan per application source.\n* `scaling_instruction` - (Required) The scaling instructions. More details can be found in the [AWS Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/plans/APIReference/API_ScalingInstruction.html).\n\nThe `application_source` object supports the following:\n\n* `cloudformation_stack_arn` - (Optional) The Amazon Resource Name (ARN) of a AWS CloudFormation stack.\n* `tag_filter` - (Optional) A set of tags.\n\nThe `tag_filter` object supports the following:\n\n* `key` - (Required) The tag key.\n* `values` - (Optional) The tag values.\n\nThe `scaling_instruction` object supports the following:\n\n* `max_capacity` - (Required) The maximum capacity of the resource. The exception to this upper limit is if you specify a non-default setting for `predictive_scaling_max_capacity_behavior`.\n* `min_capacity` - (Required) The minimum capacity of the resource.\n* `resource_id` - (Required) The ID of the resource. This string consists of the resource type and unique identifier.\n* `scalable_dimension` - (Required) The scalable dimension associated with the resource. Valid values: `autoscaling:autoScalingGroup:DesiredCapacity`, `dynamodb:index:ReadCapacityUnits`, `dynamodb:index:WriteCapacityUnits`, `dynamodb:table:ReadCapacityUnits`, `dynamodb:table:WriteCapacityUnits`, `ecs:service:DesiredCount`, `ec2:spot-fleet-request:TargetCapacity`, `rds:cluster:ReadReplicaCount`.\n* `service_namespace` - (Required) The namespace of the AWS service. Valid values: `autoscaling`, `dynamodb`, `ecs`, `ec2`, `rds`.\n* `target_tracking_configuration` - (Required) The structure that defines new target tracking configurations. Each of these structures includes a specific scaling metric and a target value for the metric, along with various parameters to use with dynamic scaling.\nMore details can be found in the [AWS Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/plans/APIReference/API_TargetTrackingConfiguration.html).\n* `customized_load_metric_specification` - (Optional) The customized load metric to use for predictive scaling. You must specify either `customized_load_metric_specification` or `predefined_load_metric_specification` when configuring predictive scaling.\nMore details can be found in the [AWS Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/plans/APIReference/API_CustomizedLoadMetricSpecification.html).\n* `disable_dynamic_scaling` - (Optional) Boolean controlling whether dynamic scaling by AWS Auto Scaling is disabled. Defaults to `false`.\n* `predefined_load_metric_specification` - (Optional) The predefined load metric to use for predictive scaling. You must specify either `predefined_load_metric_specification` or `customized_load_metric_specification` when configuring predictive scaling.\nMore details can be found in the [AWS Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/plans/APIReference/API_PredefinedLoadMetricSpecification.html).\n* `predictive_scaling_max_capacity_behavior`- (Optional) Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity specified for the resource.\nValid values: `SetForecastCapacityToMaxCapacity`, `SetMaxCapacityAboveForecastCapacity`, `SetMaxCapacityToForecastCapacity`.\n* `predictive_scaling_max_capacity_buffer` - (Optional) The size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity.\n* `predictive_scaling_mode` - (Optional) The predictive scaling mode. Valid values: `ForecastAndScale`, `ForecastOnly`.\n* `scaling_policy_update_behavior` - (Optional) Controls whether a resource's externally created scaling policies are kept or replaced. Valid values: `KeepExternalPolicies`, `ReplaceExternalPolicies`. Defaults to `KeepExternalPolicies`.\n* `scheduled_action_buffer_time` - (Optional) The amount of time, in seconds, to buffer the run time of scheduled scaling actions when scaling out.\n\nThe `customized_load_metric_specification` object supports the following:\n\n* `metric_name` - (Required) The name of the metric.\n* `namespace` - (Required) The namespace of the metric.\n* `statistic` - (Required) The statistic of the metric. Currently, the value must always be `Sum`.\n* `dimensions` - (Optional) The dimensions of the metric.\n* `unit` - (Optional) The unit of the metric.\n\nThe `predefined_load_metric_specification` object supports the following:\n\n* `predefined_load_metric_type` - (Required) The metric type. Valid values: `ALBTargetGroupRequestCount`, `ASGTotalCPUUtilization`, `ASGTotalNetworkIn`, `ASGTotalNetworkOut`.\n* `resource_label` - (Optional) Identifies the resource associated with the metric type.\n\nThe `target_tracking_configuration` object supports the following:\n\n* `target_value` - (Required) The target value for the metric.\n* `customized_scaling_metric_specification` - (Optional) A customized metric. You can specify either `customized_scaling_metric_specification` or `predefined_scaling_metric_specification`.\nMore details can be found in the [AWS Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/plans/APIReference/API_CustomizedScalingMetricSpecification.html).\n* `disable_scale_in` - (Optional) Boolean indicating whether scale in by the target tracking scaling policy is disabled. Defaults to `false`.\n* `predefined_scaling_metric_specification` - (Optional) A predefined metric. You can specify either `predefined_scaling_metric_specification` or `customized_scaling_metric_specification`.\nMore details can be found in the [AWS Auto Scaling API Reference](https://docs.aws.amazon.com/autoscaling/plans/APIReference/API_PredefinedScalingMetricSpecification.html).\n* `estimated_instance_warmup` - (Optional) The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics.\nThis value is used only if the resource is an Auto Scaling group.\n* `scale_in_cooldown` - (Optional) The amount of time, in seconds, after a scale in activity completes before another scale in activity can start.\nThis value is not used if the scalable resource is an Auto Scaling group.\n* `scale_out_cooldown` - (Optional) The amount of time, in seconds, after a scale-out activity completes before another scale-out activity can start.\nThis value is not used if the scalable resource is an Auto Scaling group.\n\nThe `customized_scaling_metric_specification` object supports the following:\n\n* `metric_name` - (Required) The name of the metric.\n* `namespace` - (Required) The namespace of the metric.\n* `statistic` - (Required) The statistic of the metric. Valid values: `Average`, `Maximum`, `Minimum`, `SampleCount`, `Sum`.\n* `dimensions` - (Optional) The dimensions of the metric.\n* `unit` - (Optional) The unit of the metric.\n\nThe `predefined_scaling_metric_specification` object supports the following:\n\n* `predefined_scaling_metric_type` - (Required) The metric type. Valid values: `ALBRequestCountPerTarget`, `ASGAverageCPUUtilization`, `ASGAverageNetworkIn`, `ASGAverageNetworkOut`, `DynamoDBReadCapacityUtilization`, `DynamoDBWriteCapacityUtilization`, `ECSServiceAverageCPUUtilization`, `ECSServiceAverageMemoryUtilization`, `EC2SpotFleetRequestAverageCPUUtilization`, `EC2SpotFleetRequestAverageNetworkIn`, `EC2SpotFleetRequestAverageNetworkOut`, `RDSReaderAverageCPUUtilization`, `RDSReaderAverageDatabaseConnections`.\n* `resource_label` - (Optional) Identifies the resource associated with the metric type.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The scaling plan identifier.\n* `scaling_plan_version` - The version number of the scaling plan. This value is always 1.\n\n## Import\n\nAuto Scaling scaling plans can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_autoscalingplans_scaling_plan.example MyScale1\n```\n",
    "basename": "autoscalingplans_scaling_plan.html"
  },
  "backup_global_settings.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_global_settings",
    "description": "Provides an AWS Backup Global Settings resource.",
    "preview": "# Resource: aws_backup_global_settings\n\nProvides an AWS Backup …",
    "content": "\n\n# Resource: aws_backup_global_settings\n\nProvides an AWS Backup Global Settings resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_backup_global_settings\" \"test\" {\n  global_settings = {\n    \"isCrossAccountBackupEnabled\" = \"true\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `global_settings` - (Required) A list of resources along with the opt-in preferences for the account.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The AWS Account ID.\n\n## Import\n\nBackup Global Settings can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_backup_global_settings.example 123456789012\n```\n",
    "basename": "backup_global_settings.html"
  },
  "backup_plan.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_plan",
    "description": "Provides an AWS Backup plan resource.",
    "preview": "# Resource: aws_backup_plan\n\nProvides an AWS Backup plan resource.\n …",
    "content": "\n\n# Resource: aws_backup_plan\n\nProvides an AWS Backup plan resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_backup_plan\" \"example\" {\n  name = \"tf_example_backup_plan\"\n\n  rule {\n    rule_name         = \"tf_example_backup_rule\"\n    target_vault_name = aws_backup_vault.test.name\n    schedule          = \"cron(0 12 * * ? *)\"\n  }\n\n  advanced_backup_setting {\n    backup_options = {\n      WindowsVSS = \"enabled\"\n    }\n    resource_type = \"EC2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The display name of a backup plan.\n* `rule` - (Required) A rule object that specifies a scheduled task that is used to back up a selection of resources.\n* `advanced_backup_setting` - (Optional) An object that specifies backup options for each resource type.\n* `tags` - (Optional) Metadata that you can assign to help organize the plans you create. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Rule Arguments\nFor **rule** the following attributes are supported:\n\n* `rule_name` - (Required) An display name for a backup rule.\n* `target_vault_name` - (Required) The name of a logical container where backups are stored.\n* `schedule` - (Optional) A CRON expression specifying when AWS Backup initiates a backup job.\n* `enable_continuous_backup` - (Optional) Enable continuous backups for supported resources.\n* `start_window` - (Optional) The amount of time in minutes before beginning a backup.\n* `completion_window` - (Optional) The amount of time AWS Backup attempts a backup before canceling the job and returning an error.\n* `lifecycle` - (Optional) The lifecycle defines when a protected resource is transitioned to cold storage and when it expires.  Fields documented below.\n* `recovery_point_tags` - (Optional) Metadata that you can assign to help organize the resources that you create.\n* `copy_action` - (Optional) Configuration block(s) with copy operation settings. Detailed below.\n\n### Lifecycle Arguments\nFor **lifecycle** the following attributes are supported:\n\n* `cold_storage_after` - (Optional) Specifies the number of days after creation that a recovery point is moved to cold storage.\n* `delete_after` - (Optional) Specifies the number of days after creation that a recovery point is deleted. Must be 90 days greater than `cold_storage_after`.\n\n### Copy Action Arguments\nFor **copy_action** the following attributes are supported:\n\n* `lifecycle` - (Optional) The lifecycle defines when a protected resource is copied over to a backup vault and when it expires.  Fields documented above.\n* `destination_vault_arn` - (Required) An Amazon Resource Name (ARN) that uniquely identifies the destination backup vault for the copied backup.\n\n### Advanced Backup Setting Arguments\nFor `advanced_backup_setting` the following attibutes are supported:\n\n* `backup_options` - (Required) Specifies the backup option for a selected resource. This option is only available for Windows VSS backup jobs. Set to `{ WindowsVSS = \"enabled\" }` to enable Windows VSS backup option and create a VSS Windows backup.\n* `resource_type` - (Required) The type of AWS resource to be backed up. For VSS Windows backups, the only supported resource type is Amazon EC2. Valid values: `EC2`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the backup plan.\n* `arn` - The ARN of the backup plan.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version` - Unique, randomly generated, Unicode, UTF-8 encoded string that serves as the version ID of the backup plan.\n\n## Import\n\nBackup Plan can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_backup_plan.test <id>\n```\n",
    "basename": "backup_plan.html"
  },
  "backup_region_settings.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_region_settings",
    "description": "Provides an AWS Backup Region Settings resource.",
    "preview": "# Resource: aws_backup_region_settings\n\nProvides an AWS Backup …",
    "content": "\n\n# Resource: aws_backup_region_settings\n\nProvides an AWS Backup Region Settings resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_backup_region_settings\" \"test\" {\n  resource_type_opt_in_preference = {\n    \"Aurora\"          = true\n    \"DocumentDB\"      = true\n    \"DynamoDB\"        = true\n    \"EBS\"             = true\n    \"EC2\"             = true\n    \"EFS\"             = true\n    \"FSx\"             = true\n    \"Neptune\"         = true\n    \"RDS\"             = true\n    \"Storage Gateway\" = true\n    \"VirtualMachine\"  = true\n  }\n\n  resource_type_management_preference = {\n    \"DynamoDB\" = true\n    \"EFS\"      = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resource_type_opt_in_preference` - (Required) A map of services along with the opt-in preferences for the Region.\n* `resource_type_management_preference` - (Optional) A map of services along with the management preferences for the Region.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The AWS region.\n\n## Import\n\nBackup Region Settings can be imported using the `region`, e.g.,\n\n```\n$ terraform import aws_backup_region_settings.test us-west-2\n```\n",
    "basename": "backup_region_settings.html"
  },
  "backup_selection.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_selection",
    "description": "Manages selection conditions for AWS Backup plan resources.",
    "preview": "# Resource: aws_backup_selection\n\nManages selection conditions for …",
    "content": "\n\n# Resource: aws_backup_selection\n\nManages selection conditions for AWS Backup plan resources.\n\n## Example Usage\n\n### IAM Role\n\n-> For more information about creating and managing IAM Roles for backups and restores, see the [AWS Backup Developer Guide](https://docs.aws.amazon.com/aws-backup/latest/devguide/iam-service-roles.html).\n\nThe below example creates an IAM role with the default managed IAM Policy for allowing AWS Backup to create backups.\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name               = \"example\"\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\"sts:AssumeRole\"],\n      \"Effect\": \"allow\",\n      \"Principal\": {\n        \"Service\": [\"backup.amazonaws.com\"]\n      }\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example\" {\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSBackupServiceRolePolicyForBackup\"\n  role       = aws_iam_role.example.name\n}\n\nresource \"aws_backup_selection\" \"example\" {\n  # ... other configuration ...\n\n  iam_role_arn = aws_iam_role.example.arn\n}\n```\n\n### Selecting Backups By Tag\n\n```terraform\nresource \"aws_backup_selection\" \"example\" {\n  iam_role_arn = aws_iam_role.example.arn\n  name         = \"tf_example_backup_selection\"\n  plan_id      = aws_backup_plan.example.id\n\n  selection_tag {\n    type  = \"STRINGEQUALS\"\n    key   = \"foo\"\n    value = \"bar\"\n  }\n}\n```\n\n### Selecting Backups By Resource\n\n```terraform\nresource \"aws_backup_selection\" \"example\" {\n  iam_role_arn = aws_iam_role.example.arn\n  name         = \"tf_example_backup_selection\"\n  plan_id      = aws_backup_plan.example.id\n\n  resources = [\n    aws_db_instance.example.arn,\n    aws_ebs_volume.example.arn,\n    aws_efs_file_system.example.arn,\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The display name of a resource selection document.\n* `plan_id` - (Required) The backup plan ID to be associated with the selection of resources.\n* `iam_role_arn` - (Required) The ARN of the IAM role that AWS Backup uses to authenticate when restoring and backing up the target resource. See the [AWS Backup Developer Guide](https://docs.aws.amazon.com/aws-backup/latest/devguide/access-control.html#managed-policies) for additional information about using AWS managed policies or creating custom policies attached to the IAM role.\n* `selection_tag` - (Optional) Tag-based conditions used to specify a set of resources to assign to a backup plan.\n* `resources` - (Optional) An array of strings that either contain Amazon Resource Names (ARNs) or match patterns of resources to assign to a backup plan..\n\nTag conditions (`selection_tag`) support the following:\n\n* `type` - (Required) An operation, such as `StringEquals`, that is applied to a key-value pair used to filter resources in a selection.\n* `key` - (Required) The key in a key-value pair.\n* `value` - (Required) The value in a key-value pair.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Backup Selection identifier\n\n## Import\n\nBackup selection can be imported using the role plan_id and id separated by `|`.\n\n```\n$ terraform import aws_backup_selection.example plan-id|selection-id\n```\n",
    "basename": "backup_selection.html"
  },
  "backup_vault.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_vault",
    "description": "Provides an AWS Backup vault resource.",
    "preview": "# Resource: aws_backup_vault\n\nProvides an AWS Backup vault resource. …",
    "content": "\n\n# Resource: aws_backup_vault\n\nProvides an AWS Backup vault resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_backup_vault\" \"example\" {\n  name        = \"example_backup_vault\"\n  kms_key_arn = aws_kms_key.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the backup vault to create.\n* `tags` - (Optional) Metadata that you can assign to help organize the resources that you create. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `kms_key_arn` - (Optional) The server-side encryption key that is used to protect your backups.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the vault.\n* `arn` - The ARN of the vault.\n* `recovery_points` - The number of recovery points that are stored in a backup vault.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nBackup vault can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_backup_vault.test-vault TestVault\n```\n",
    "basename": "backup_vault.html"
  },
  "backup_vault_lock_configuration.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_vault_lock_configuration",
    "description": "Provides an AWS Backup vault lock configuration resource.",
    "preview": "# Resource: aws_backup_vault_lock_configuration\n\nProvides an AWS …",
    "content": "\n\n# Resource: aws_backup_vault_lock_configuration\n\nProvides an AWS Backup vault lock configuration resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_backup_vault_lock_configuration\" \"test\" {\n  backup_vault_name   = \"example_backup_vault\"\n  changeable_for_days = 3\n  max_retention_days  = 1200\n  min_retention_days  = 7\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `backup_vault_name` - (Required) Name of the backup vault to add a lock configuration for.\n* `changeable_for_days` - (Optional) The number of days before the lock date.\n* `max_retention_days` - (Optional) The maximum retention period that the vault retains its recovery points.\n* `min_retention_days` - (Optional) The minimum retention period that the vault retains its recovery points.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `backup_vault_name` - The name of the vault.\n* `backup_vault_arn` - The ARN of the vault.\n\n## Import\n\nBackup vault lock configuration can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_backup_vault_lock_configuration.test TestVault\n```\n",
    "basename": "backup_vault_lock_configuration.html"
  },
  "backup_vault_notifications.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_vault_notifications",
    "description": "Provides an AWS Backup vault notifications resource.",
    "preview": "# Resource: aws_backup_vault_notifications\n\nProvides an AWS Backup …",
    "content": "\n\n# Resource: aws_backup_vault_notifications\n\nProvides an AWS Backup vault notifications resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_sns_topic\" \"test\" {\n  name = \"backup-vault-events\"\n}\n\ndata \"aws_iam_policy_document\" \"test\" {\n  policy_id = \"__default_policy_ID\"\n\n  statement {\n    actions = [\n      \"SNS:Publish\",\n    ]\n\n    effect = \"Allow\"\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"backup.amazonaws.com\"]\n    }\n\n    resources = [\n      aws_sns_topic.test.arn,\n    ]\n\n    sid = \"__default_statement_ID\"\n  }\n}\n\nresource \"aws_sns_topic_policy\" \"test\" {\n  arn    = aws_sns_topic.test.arn\n  policy = data.aws_iam_policy_document.test.json\n}\n\nresource \"aws_backup_vault_notifications\" \"test\" {\n  backup_vault_name   = \"example_backup_vault\"\n  sns_topic_arn       = aws_sns_topic.test.arn\n  backup_vault_events = [\"BACKUP_JOB_STARTED\", \"RESTORE_JOB_COMPLETED\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `backup_vault_name` - (Required) Name of the backup vault to add notifications for.\n* `sns_topic_arn` - (Required) The Amazon Resource Name (ARN) that specifies the topic for a backup vault’s events\n* `backup_vault_events` - (Required) An array of events that indicate the status of jobs to back up resources to the backup vault.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the vault.\n* `backup_vault_arn` - The ARN of the vault.\n\n## Import\n\nBackup vault notifications can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_backup_vault_notifications.test TestVault\n```\n",
    "basename": "backup_vault_notifications.html"
  },
  "backup_vault_policy.html": {
    "subcategory": "Backup",
    "layout": "aws",
    "page_title": "AWS: aws_backup_vault_policy",
    "description": "Provides an AWS Backup vault policy resource.",
    "preview": "# Resource: aws_backup_vault_policy\n\nProvides an AWS Backup vault …",
    "content": "\n\n# Resource: aws_backup_vault_policy\n\nProvides an AWS Backup vault policy resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_backup_vault\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_backup_vault_policy\" \"example\" {\n  backup_vault_name = aws_backup_vault.example.name\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Id\": \"default\",\n  \"Statement\": [\n    {\n      \"Sid\": \"default\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"\n      },\n      \"Action\": [\n\t\t\"backup:DescribeBackupVault\",\n\t\t\"backup:DeleteBackupVault\",\n\t\t\"backup:PutBackupVaultAccessPolicy\",\n\t\t\"backup:DeleteBackupVaultAccessPolicy\",\n\t\t\"backup:GetBackupVaultAccessPolicy\",\n\t\t\"backup:StartBackupJob\",\n\t\t\"backup:GetBackupVaultNotifications\",\n\t\t\"backup:PutBackupVaultNotifications\"\n      ],\n      \"Resource\": \"${aws_backup_vault.example.arn}\"\n    }\n  ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `backup_vault_name` - (Required) Name of the backup vault to add policy for.\n* `policy` - (Required) The backup vault access policy document in JSON format.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the vault.\n* `backup_vault_arn` - The ARN of the vault.\n\n## Import\n\nBackup vault policy can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_backup_vault_policy.test TestVault\n```\n",
    "basename": "backup_vault_policy.html"
  },
  "batch_compute_environment.html": {
    "subcategory": "Batch",
    "layout": "aws",
    "page_title": "AWS: aws_batch_compute_environment",
    "description": "Creates a AWS Batch compute environment.",
    "preview": "# Resource: aws_batch_compute_environment\n\nCreates a AWS Batch …",
    "content": "\n\n# Resource: aws_batch_compute_environment\n\nCreates a AWS Batch compute environment. Compute environments contain the Amazon ECS container instances that are used to run containerized batch jobs.\n\nFor information about AWS Batch, see [What is AWS Batch?][1] .\nFor information about compute environment, see [Compute Environments][2] .\n\n~> **Note:** To prevent a race condition during environment deletion, make sure to set `depends_on` to the related `aws_iam_role_policy_attachment`;\notherwise, the policy may be destroyed too soon and the compute environment will then get stuck in the `DELETING` state, see [Troubleshooting AWS Batch][3] .\n\n## Example Usage\n\n### EC2 Type\n\n```terraform\nresource \"aws_iam_role\" \"ecs_instance_role\" {\n  name = \"ecs_instance_role\"\n\n  assume_role_policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n\t{\n\t    \"Action\": \"sts:AssumeRole\",\n\t    \"Effect\": \"Allow\",\n\t    \"Principal\": {\n\t        \"Service\": \"ec2.amazonaws.com\"\n\t    }\n\t}\n    ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ecs_instance_role\" {\n  role       = aws_iam_role.ecs_instance_role.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\"\n}\n\nresource \"aws_iam_instance_profile\" \"ecs_instance_role\" {\n  name = \"ecs_instance_role\"\n  role = aws_iam_role.ecs_instance_role.name\n}\n\nresource \"aws_iam_role\" \"aws_batch_service_role\" {\n  name = \"aws_batch_service_role\"\n\n  assume_role_policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n\t{\n\t    \"Action\": \"sts:AssumeRole\",\n\t    \"Effect\": \"Allow\",\n\t    \"Principal\": {\n\t\t\"Service\": \"batch.amazonaws.com\"\n\t    }\n\t}\n    ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"aws_batch_service_role\" {\n  role       = aws_iam_role.aws_batch_service_role.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole\"\n}\n\nresource \"aws_security_group\" \"sample\" {\n  name = \"aws_batch_compute_environment_security_group\"\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_vpc\" \"sample\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_subnet\" \"sample\" {\n  vpc_id     = aws_vpc.sample.id\n  cidr_block = \"10.1.1.0/24\"\n}\n\nresource \"aws_batch_compute_environment\" \"sample\" {\n  compute_environment_name = \"sample\"\n\n  compute_resources {\n    instance_role = aws_iam_instance_profile.ecs_instance_role.arn\n\n    instance_type = [\n      \"c4.large\",\n    ]\n\n    max_vcpus = 16\n    min_vcpus = 0\n\n    security_group_ids = [\n      aws_security_group.sample.id,\n    ]\n\n    subnets = [\n      aws_subnet.sample.id,\n    ]\n\n    type = \"EC2\"\n  }\n\n  service_role = aws_iam_role.aws_batch_service_role.arn\n  type         = \"MANAGED\"\n  depends_on   = [aws_iam_role_policy_attachment.aws_batch_service_role]\n}\n```\n\n### Fargate Type\n\n```hcl\nresource \"aws_batch_compute_environment\" \"sample\" {\n  compute_environment_name = \"sample\"\n\n  compute_resources {\n    max_vcpus = 16\n\n    security_group_ids = [\n      aws_security_group.sample.id\n    ]\n\n    subnets = [\n      aws_subnet.sample.id\n    ]\n\n    type = \"FARGATE\"\n  }\n\n  service_role = aws_iam_role.aws_batch_service_role.arn\n  type         = \"MANAGED\"\n  depends_on   = [aws_iam_role_policy_attachment.aws_batch_service_role]\n}\n```\n\n## Argument Reference\n\n* `compute_environment_name` - (Optional, Forces new resource) The name for your compute environment. Up to 128 letters (uppercase and lowercase), numbers, and underscores are allowed. If omitted, Terraform will assign a random, unique name.\n* `compute_environment_name_prefix` - (Optional, Forces new resource) Creates a unique compute environment name beginning with the specified prefix. Conflicts with `compute_environment_name`.\n* `compute_resources` - (Optional) Details of the compute resources managed by the compute environment. This parameter is required for managed compute environments. See details below.\n* `service_role` - (Required) The full Amazon Resource Name (ARN) of the IAM role that allows AWS Batch to make calls to other AWS services on your behalf.\n* `state` - (Optional) The state of the compute environment. If the state is `ENABLED`, then the compute environment accepts jobs from a queue and can scale out automatically based on queues. Valid items are `ENABLED` or `DISABLED`. Defaults to `ENABLED`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `type` - (Required) The type of the compute environment. Valid items are `MANAGED` or `UNMANAGED`.\n\n**compute_resources** is a child block with a single argument:\n\n* `allocation_strategy` - (Optional) The allocation strategy to use for the compute resource in case not enough instances of the best fitting instance type can be allocated. Valid items are `BEST_FIT_PROGRESSIVE`, `SPOT_CAPACITY_OPTIMIZED` or `BEST_FIT`. Defaults to `BEST_FIT`. See [AWS docs](https://docs.aws.amazon.com/batch/latest/userguide/allocation-strategies.html) for details. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `bid_percentage` - (Optional) Integer of maximum percentage that a Spot Instance price can be when compared with the On-Demand price for that instance type before instances are launched. For example, if your bid percentage is 20% (`20`), then the Spot price must be below 20% of the current On-Demand price for that EC2 instance. If you leave this field empty, the default value is 100% of the On-Demand price. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `desired_vcpus` - (Optional) The desired number of EC2 vCPUS in the compute environment. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `ec2_configuration` - (Optional) Provides information used to select Amazon Machine Images (AMIs) for EC2 instances in the compute environment. If Ec2Configuration isn't specified, the default is ECS_AL2. This parameter isn't applicable to jobs that are running on Fargate resources, and shouldn't be specified.\n* `ec2_key_pair` - (Optional) The EC2 key pair that is used for instances launched in the compute environment. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `image_id` - (Optional) The Amazon Machine Image (AMI) ID used for instances launched in the compute environment. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified. (Deprecated, use [`image_id_override`](#image_id_override) instead)\n* `instance_role` - (Optional) The Amazon ECS instance role applied to Amazon EC2 instances in a compute environment. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `instance_type` - (Optional) A list of instance types that may be launched. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `launch_template` - (Optional) The launch template to use for your compute resources. See details below. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `max_vcpus` - (Required) The maximum number of EC2 vCPUs that an environment can reach.\n* `min_vcpus` - (Optional) The minimum number of EC2 vCPUs that an environment should maintain. For `EC2` or `SPOT` compute environments, if the parameter is not explicitly defined, a `0` default value will be set. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `security_group_ids` - (Required) A list of EC2 security group that are associated with instances launched in the compute environment.\n* `spot_iam_fleet_role` - (Optional) The Amazon Resource Name (ARN) of the Amazon EC2 Spot Fleet IAM role applied to a SPOT compute environment. This parameter is required for SPOT compute environments. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `subnets` - (Required) A list of VPC subnets into which the compute resources are launched.\n* `tags` - (Optional) Key-value pair tags to be applied to resources that are launched in the compute environment. This parameter isn't applicable to jobs running on Fargate resources, and shouldn't be specified.\n* `type` - (Required) The type of compute environment. Valid items are `EC2`, `SPOT`, `FARGATE` or `FARGATE_SPOT`.\n\n### ec2_configuration\n\n`ec2_configuration` supports the following:\n\n* `image_id_override` - (Optional) The AMI ID used for instances launched in the compute environment that match the image type. This setting overrides the [`image_id` argument](#image_id) in the `compute_resourcess block.\n* `image_type` - (Optional) The image type to match with the instance type to select an AMI. If the `image_id_override` parameter isn't specified, then a recent [Amazon ECS-optimized Amazon Linux 2 AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html#al2ami) (`ECS_AL2`) is used.\n\n### launch_template\n\n`launch_template` supports the following:\n\n* `launch_template_id` - (Optional) ID of the launch template. You must specify either the launch template ID or launch template name in the request, but not both.\n* `launch_template_name` - (Optional) Name of the launch template.\n* `version` - (Optional) The version number of the launch template. Default: The default version of the launch template.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the compute environment.\n* `ecs_cluster_arn` - The Amazon Resource Name (ARN) of the underlying Amazon ECS cluster used by the compute environment.\n* `status` - The current status of the compute environment (for example, CREATING or VALID).\n* `status_reason` - A short, human-readable string to provide additional details about the current status of the compute environment.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAWS Batch compute can be imported using the `compute_environment_name`, e.g.,\n\n```\n$ terraform import aws_batch_compute_environment.sample sample\n```\n\n[1]: http://docs.aws.amazon.com/batch/latest/userguide/what-is-batch.html\n[2]: http://docs.aws.amazon.com/batch/latest/userguide/compute_environments.html\n[3]: http://docs.aws.amazon.com/batch/latest/userguide/troubleshooting.html\n[4]: https://docs.aws.amazon.com/batch/latest/userguide/allocation-strategies.html\n",
    "basename": "batch_compute_environment.html"
  },
  "batch_job_definition.html": {
    "subcategory": "Batch",
    "layout": "aws",
    "page_title": "AWS: aws_batch_job_definition",
    "description": "Provides a Batch Job Definition resource.",
    "preview": "# Resource: aws_batch_job_definition\n\nProvides a Batch Job …",
    "content": "\n\n# Resource: aws_batch_job_definition\n\nProvides a Batch Job Definition resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_batch_job_definition\" \"test\" {\n  name = \"tf_test_batch_job_definition\"\n  type = \"container\"\n\n  container_properties = <<CONTAINER_PROPERTIES\n{\n\t\"command\": [\"ls\", \"-la\"],\n\t\"image\": \"busybox\",\n\t\"memory\": 1024,\n\t\"vcpus\": 1,\n\t\"volumes\": [\n      {\n        \"host\": {\n          \"sourcePath\": \"/tmp\"\n        },\n        \"name\": \"tmp\"\n      }\n    ],\n\t\"environment\": [\n\t\t{\"name\": \"VARNAME\", \"value\": \"VARVAL\"}\n\t],\n\t\"mountPoints\": [\n\t\t{\n          \"sourceVolume\": \"tmp\",\n          \"containerPath\": \"/tmp\",\n          \"readOnly\": false\n        }\n\t],\n    \"ulimits\": [\n      {\n        \"hardLimit\": 1024,\n        \"name\": \"nofile\",\n        \"softLimit\": 1024\n      }\n    ]\n}\nCONTAINER_PROPERTIES\n}\n```\n\n### Fargate Platform Capability\n\n```terraform\nresource \"aws_iam_role\" \"ecs_task_execution_role\" {\n  name               = \"tf_test_batch_exec_role\"\n  assume_role_policy = data.aws_iam_policy_document.assume_role_policy.json\n}\n\ndata \"aws_iam_policy_document\" \"assume_role_policy\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ecs-tasks.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ecs_task_execution_role_policy\" {\n  role       = aws_iam_role.ecs_task_execution_role.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\n}\n\nresource \"aws_batch_job_definition\" \"test\" {\n  name = \"tf_test_batch_job_definition\"\n  type = \"container\"\n  platform_capabilities = [\n    \"FARGATE\",\n  ]\n\n  container_properties = <<CONTAINER_PROPERTIES\n{\n  \"command\": [\"echo\", \"test\"],\n  \"image\": \"busybox\",\n  \"fargatePlatformConfiguration\": {\n    \"platformVersion\": \"LATEST\"\n  },\n  \"resourceRequirements\": [\n    {\"type\": \"VCPU\", \"value\": \"0.25\"},\n    {\"type\": \"MEMORY\", \"value\": \"512\"}\n  ],\n  \"executionRoleArn\": \"${aws_iam_role.ecs_task_execution_role.arn}\"\n}\nCONTAINER_PROPERTIES\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Specifies the name of the job definition.\n* `container_properties` - (Optional) A valid [container properties](http://docs.aws.amazon.com/batch/latest/APIReference/API_RegisterJobDefinition.html)\n    provided as a single valid JSON document. This parameter is required if the `type` parameter is `container`.\n* `parameters` - (Optional) Specifies the parameter substitution placeholders to set in the job definition.\n* `platform_capabilities` - (Optional) The platform capabilities required by the job definition. If no value is specified, it defaults to `EC2`. To run the job on Fargate resources, specify `FARGATE`.\n* `propagate_tags` - (Optional) Specifies whether to propagate the tags from the job definition to the corresponding Amazon ECS task. Default is `false`.\n* `retry_strategy` - (Optional) Specifies the retry strategy to use for failed jobs that are submitted with this job definition.\n    Maximum number of `retry_strategy` is `1`.  Defined below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `timeout` - (Optional) Specifies the timeout for jobs so that if a job runs longer, AWS Batch terminates the job. Maximum number of `timeout` is `1`. Defined below.\n* `type` - (Required) The type of job definition.  Must be `container`.\n\n## retry_strategy\n\n`retry_strategy` supports the following:\n\n* `attempts` - (Optional) The number of times to move a job to the `RUNNABLE` status. You may specify between `1` and `10` attempts.\n* `evaluate_on_exit` - (Optional) The [evaluate on exit](#evaluate_on_exit) conditions under which the job should be retried or failed. If this parameter is specified, then the `attempts` parameter must also be specified. You may specify up to 5 configuration blocks.\n\n## timeout\n\n`timeout` supports the following:\n\n* `attempt_duration_seconds` - (Optional) The time duration in seconds after which AWS Batch terminates your jobs if they have not finished. The minimum value for the timeout is `60` seconds.\n\n### evaluate_on_exit\n\n* `action` - (Required) Specifies the action to take if all of the specified conditions are met. The values are not case sensitive. Valid values: `RETRY`, `EXIT`.\n* `on_exit_code` - (Optional) A glob pattern to match against the decimal representation of the exit code returned for a job.\n* `on_reason` - (Optional) A glob pattern to match against the reason returned for a job.\n* `on_status_reason` - (Optional) A glob pattern to match against the status reason returned for a job.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name of the job definition.\n* `revision` - The revision of the job definition.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nBatch Job Definition can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_batch_job_definition.test arn:aws:batch:us-east-1:123456789012:job-definition/sample\n```\n",
    "basename": "batch_job_definition.html"
  },
  "batch_job_queue.html": {
    "subcategory": "Batch",
    "layout": "aws",
    "page_title": "AWS: aws_batch_job_queue",
    "description": "Provides a Batch Job Queue resource.",
    "preview": "# Resource: aws_batch_job_queue\n\nProvides a Batch Job Queue …",
    "content": "\n\n# Resource: aws_batch_job_queue\n\nProvides a Batch Job Queue resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_batch_job_queue\" \"test_queue\" {\n  name     = \"tf-test-batch-job-queue\"\n  state    = \"ENABLED\"\n  priority = 1\n  compute_environments = [\n    aws_batch_compute_environment.test_environment_1.arn,\n    aws_batch_compute_environment.test_environment_2.arn,\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Specifies the name of the job queue.\n* `compute_environments` - (Required) Specifies the set of compute environments\n    mapped to a job queue and their order.  The position of the compute environments\n    in the list will dictate the order.\n* `priority` - (Required) The priority of the job queue. Job queues with a higher priority\n    are evaluated first when associated with the same compute environment.\n* `state` - (Required) The state of the job queue. Must be one of: `ENABLED` or `DISABLED`\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name of the job queue.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nBatch Job Queue can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_batch_job_queue.test_queue arn:aws:batch:us-east-1:123456789012:job-queue/sample\n```\n",
    "basename": "batch_job_queue.html"
  },
  "budgets_budget.html": {
    "subcategory": "Budgets",
    "layout": "aws",
    "page_title": "AWS: aws_budgets_budget",
    "description": "Provides a budgets budget resource.",
    "preview": "# Resource: aws_budgets_budget\n\nProvides a budgets budget resource. …",
    "content": "\n\n# Resource: aws_budgets_budget\n\nProvides a budgets budget resource. Budgets use the cost visualisation provided by Cost Explorer to show you the status of your budgets, to provide forecasts of your estimated costs, and to track your AWS usage, including your free tier usage.\n\n## Example Usage\n\n```terraform\nresource \"aws_budgets_budget\" \"ec2\" {\n  name              = \"budget-ec2-monthly\"\n  budget_type       = \"COST\"\n  limit_amount      = \"1200\"\n  limit_unit        = \"USD\"\n  time_period_end   = \"2087-06-15_00:00\"\n  time_period_start = \"2017-07-01_00:00\"\n  time_unit         = \"MONTHLY\"\n\n  cost_filter {\n    name = \"Service\"\n    values = [\n      \"Amazon Elastic Compute Cloud - Compute\",\n    ]\n  }\n\n  notification {\n    comparison_operator        = \"GREATER_THAN\"\n    threshold                  = 100\n    threshold_type             = \"PERCENTAGE\"\n    notification_type          = \"FORECASTED\"\n    subscriber_email_addresses = [\"test@example.com\"]\n  }\n}\n```\n\nCreate a budget for *$100*.\n\n```terraform\nresource \"aws_budgets_budget\" \"cost\" {\n  # ...\n  budget_type  = \"COST\"\n  limit_amount = \"100\"\n  limit_unit   = \"USD\"\n}\n```\n\nCreate a budget for s3 with a limit of *3 GB* of storage.\n\n```terraform\nresource \"aws_budgets_budget\" \"s3\" {\n  # ...\n  budget_type  = \"USAGE\"\n  limit_amount = \"3\"\n  limit_unit   = \"GB\"\n}\n```\n\nCreate a Savings Plan Utilization Budget\n\n```terraform\nresource \"aws_budgets_budget\" \"savings_plan_utilization\" {\n  # ...\n  budget_type  = \"SAVINGS_PLANS_UTILIZATION\"\n  limit_amount = \"100.0\"\n  limit_unit   = \"PERCENTAGE\"\n\n  cost_types {\n    include_credit             = false\n    include_discount           = false\n    include_other_subscription = false\n    include_recurring          = false\n    include_refund             = false\n    include_subscription       = true\n    include_support            = false\n    include_tax                = false\n    include_upfront            = false\n    use_blended                = false\n  }\n}\n```\n\nCreate a RI Utilization Budget\n\n```terraform\nresource \"aws_budgets_budget\" \"ri_utilization\" {\n  # ...\n  budget_type  = \"RI_UTILIZATION\"\n  limit_amount = \"100.0\" # RI utilization must be 100\n  limit_unit   = \"PERCENTAGE\"\n\n  #Cost types must be defined for RI budgets because the settings conflict with the defaults\n  cost_types {\n    include_credit             = false\n    include_discount           = false\n    include_other_subscription = false\n    include_recurring          = false\n    include_refund             = false\n    include_subscription       = true\n    include_support            = false\n    include_tax                = false\n    include_upfront            = false\n    use_blended                = false\n  }\n\n  # RI Utilization plans require a service cost filter to be set\n  cost_filters = {\n    Service = \"Amazon Relational Database Service\"\n  }\n}\n```\n\n## Argument Reference\n\n~> **NOTE:** The `cost_filters` attribute will be deprecated and eventually removed in future releases, please use `cost_filter` instead.\n\nFor more detailed documentation about each argument, refer to the [AWS official\ndocumentation](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/data-type-budget.html).\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The ID of the target account for budget. Will use current user's account_id by default if omitted.\n* `name` - (Optional) The name of a budget. Unique within accounts.\n* `name_prefix` - (Optional) The prefix of the name of a budget. Unique within accounts.\n* `budget_type` - (Required) Whether this budget tracks monetary cost or usage.\n* `cost_filter` - (Optional) A list of [CostFilter](#Cost-Filter) name/values pair to apply to budget.\n* `cost_filters` - (Optional) Map of [CostFilters](#Cost-Filters) key/value pairs to apply to the budget.\n* `cost_types` - (Optional) Object containing [CostTypes](#Cost-Types) The types of cost included in a budget, such as tax and subscriptions.\n* `limit_amount` - (Required) The amount of cost or usage being measured for a budget.\n* `limit_unit` - (Required) The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. See [Spend](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/data-type-spend.html) documentation.\n* `time_period_end` - (Optional) The end of the time period covered by the budget. There are no restrictions on the end date. Format: `2017-01-01_12:00`.\n* `time_period_start` - (Optional) The start of the time period covered by the budget. If you don't specify a start date, AWS defaults to the start of your chosen time period. The start date must come before the end date. Format: `2017-01-01_12:00`.\n* `time_unit` - (Required) The length of time until a budget resets the actual and forecasted spend. Valid values: `MONTHLY`, `QUARTERLY`, `ANNUALLY`, and `DAILY`.\n* `notification` - (Optional) Object containing [Budget Notifications](#Budget-Notification). Can be used multiple times to define more than one budget notification\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - id of resource.\n* `arn` - The ARN of the budget.\n\n### Cost Types\n\nValid keys for `cost_types` parameter.\n\n* `include_credit` - A boolean value whether to include credits in the cost budget. Defaults to `true`\n* `include_discount` - Specifies whether a budget includes discounts. Defaults to `true`\n* `include_other_subscription` - A boolean value whether to include other subscription costs in the cost budget. Defaults to `true`\n* `include_recurring` - A boolean value whether to include recurring costs in the cost budget. Defaults to `true`\n* `include_refund` - A boolean value whether to include refunds in the cost budget. Defaults to `true`\n* `include_subscription` - A boolean value whether to include subscriptions in the cost budget. Defaults to `true`\n* `include_support` - A boolean value whether to include support costs in the cost budget. Defaults to `true`\n* `include_tax` - A boolean value whether to include tax in the cost budget. Defaults to `true`\n* `include_upfront` - A boolean value whether to include upfront costs in the cost budget. Defaults to `true`\n* `use_amortized` - Specifies whether a budget uses the amortized rate. Defaults to `false`\n* `use_blended` - A boolean value whether to use blended costs in the cost budget. Defaults to `false`\n\nRefer to [AWS CostTypes documentation](https://docs.aws.amazon.com/aws-cost-management/latest/APIReference/API_budgets_CostTypes.html) for further detail.\n\n### Cost Filter\n\nValid name for `cost_filter` parameter vary depending on the `budget_type` value.\n\n* `cost`\n    * `AZ`\n    * `LinkedAccount`\n    * `Operation`\n    * `PurchaseType`\n    * `Service`\n    * `TagKeyValue`\n* `usage`\n    * `AZ`\n    * `LinkedAccount`\n    * `Operation`\n    * `PurchaseType`\n    * `UsageType:<service name>`\n    * `TagKeyValue`\n\nRefer to [AWS CostFilter documentation](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/data-type-filter.html) for further detail.\n\n### Cost Filters\n\nValid key for `cost_filters` is same as `cost_filter`. Please refer to [Cost Filter](#Cost-Filter).\n\n### Budget Notification\n\nValid keys for `notification` parameter.\n\n* `comparison_operator` - (Required) Comparison operator to use to evaluate the condition. Can be `LESS_THAN`, `EQUAL_TO` or `GREATER_THAN`.\n* `threshold` - (Required) Threshold when the notification should be sent.\n* `threshold_type` - (Required) What kind of threshold is defined. Can be `PERCENTAGE` OR `ABSOLUTE_VALUE`.\n* `notification_type` - (Required) What kind of budget value to notify on. Can be `ACTUAL` or `FORECASTED`\n* `subscriber_email_addresses` - (Optional) E-Mail addresses to notify. Either this or `subscriber_sns_topic_arns` is required.\n* `subscriber_sns_topic_arns` - (Optional) SNS topics to notify. Either this or `subscriber_email_addresses` is required.\n\n## Import\n\nBudgets can be imported using `AccountID:BudgetName`, e.g.,\n\n`$ terraform import aws_budgets_budget.myBudget 123456789012:myBudget`\n",
    "basename": "budgets_budget.html"
  },
  "budgets_budget_action.html": {
    "subcategory": "Budgets",
    "layout": "aws",
    "page_title": "AWS: aws_budgets_budget_action",
    "description": "Provides a budget action resource.",
    "preview": "# Resource: aws_budgets_budget_action\n\nProvides a budget action …",
    "content": "\n\n# Resource: aws_budgets_budget_action\n\nProvides a budget action resource. Budget actions are cost savings controls that run either automatically on your behalf or by using a workflow approval process.\n\n## Example Usage\n\n```terraform\nresource \"aws_budgets_budget_action\" \"example\" {\n  budget_name        = aws_budgets_budget.example.name\n  action_type        = \"APPLY_IAM_POLICY\"\n  approval_model     = \"AUTOMATIC\"\n  notification_type  = \"ACTUAL\"\n  execution_role_arn = aws_iam_role.example.arn\n\n  action_threshold {\n    action_threshold_type  = \"ABSOLUTE_VALUE\"\n    action_threshold_value = 100\n  }\n\n  definition {\n    iam_action_definition {\n      policy_arn = aws_iam_policy.example.arn\n      roles      = [aws_iam_role.example.name]\n    }\n  }\n\n  subscriber {\n    address           = \"example@example.example\"\n    subscription_type = \"EMAIL\"\n  }\n}\n\nresource \"aws_iam_policy\" \"example\" {\n  name        = \"example\"\n  description = \"My example policy\"\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:Describe*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n\ndata \"aws_partition\" \"current\" {}\n\nresource \"aws_iam_role\" \"example\" {\n  name = \"example\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": [\n          \"budgets.${data.aws_partition.current.dns_suffix}\"\n        ]\n      },\n      \"Action\": [\n        \"sts:AssumeRole\"\n      ]\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_budgets_budget\" \"example\" {\n  name              = \"example\"\n  budget_type       = \"USAGE\"\n  limit_amount      = \"10.0\"\n  limit_unit        = \"dollars\"\n  time_period_start = \"2006-01-02_15:04\"\n  time_unit         = \"MONTHLY\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The ID of the target account for budget. Will use current user's account_id by default if omitted.\n* `budget_name` - (Required) The name of a budget.\n* `action_threshold` - (Required) The trigger threshold of the action. See [Action Threshold](#action-threshold).\n* `action_type` - (Required) The type of action. This defines the type of tasks that can be carried out by this action. This field also determines the format for definition. Valid values are `APPLY_IAM_POLICY`, `APPLY_SCP_POLICY`, and `RUN_SSM_DOCUMENTS`.\n* `approval_model` - (Required) This specifies if the action needs manual or automatic approval. Valid values are `AUTOMATIC` and `MANUAL`.\n* `definition` - (Required) Specifies all of the type-specific parameters. See [Definition](#definition).\n* `execution_role_arn` - (Required) The role passed for action execution and reversion. Roles and actions must be in the same account.\n* `notification_type` - (Required) The type of a notification. Valid values are `ACTUAL` or `FORECASTED`.\n* `subscriber` - (Required) A list of subscribers. See [Subscriber](#subscriber).\n\n### Action Threshold\n\n* `action_threshold_type` - (Required) The type of threshold for a notification. Valid values are `PERCENTAGE` or `ABSOLUTE_VALUE`.\n* `action_threshold_value` - (Required) The threshold of a notification.\n\n### Subscriber\n\n* `address` - (Required) The address that AWS sends budget notifications to, either an SNS topic or an email.\n* `subscription_type` - (Required) The type of notification that AWS sends to a subscriber. Valid values are `SNS` or `EMAIL`.\n\n### Definition\n\n* `iam_action_definition` - (Optional) The AWS Identity and Access Management (IAM) action definition details. See [IAM Action Definition](#iam-action-definition).\n* `ssm_action_definition` - (Optional) The AWS Systems Manager (SSM) action definition details. See [SSM Action Definition](#ssm-action-definition).\n* `scp_action_definition` - (Optional) The service control policies (SCPs) action definition details. See [SCP Action Definition](#scp-action-definition).\n\n#### IAM Action Definition\n\n* `policy_arn` - (Required) The Amazon Resource Name (ARN) of the policy to be attached.\n* `groups` - (Optional) A list of groups to be attached. There must be at least one group.\n* `roles` - (Optional) A list of roles to be attached. There must be at least one role.\n* `users` - (Optional) A list of users to be attached. There must be at least one user.\n\n#### SCP Action Definition\n\n* `policy_id` - (Required) The policy ID attached.\n* `target_ids` - (Optional) A list of target IDs.\n\n#### SSM Action Definition\n\n* `action_sub_type` - (Required) The action subType. Valid values are `STOP_EC2_INSTANCES` or `STOP_RDS_INSTANCES`.\n* `instance_ids` - (Required) The EC2 and RDS instance IDs.\n* `region` - (Required) The Region to run the SSM document.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `action_id` - The id of the budget action.\n* `id` - ID of resource.\n* `arn` - The ARN of the budget action.\n* `status` - The status of the budget action.\n\n## Import\n\nBudgets can be imported using `AccountID:ActionID:BudgetName`, e.g.,\n\n`$ terraform import aws_budgets_budget_action.myBudget 123456789012:some-id:myBudget`\n",
    "basename": "budgets_budget_action.html"
  },
  "chime_voice_connector.html": {
    "subcategory": "Chime",
    "layout": "aws",
    "page_title": "AWS: aws_chime_voice_connector",
    "description": "Enables you to connect your phone system to the telephone network at a substantial cost savings by using SIP trunking.",
    "preview": "# Resource: aws_chime_voice_connector\n\nEnables you to connect your …",
    "content": "\n\n# Resource: aws_chime_voice_connector\n\nEnables you to connect your phone system to the telephone network at a substantial cost savings by using SIP trunking.\n\n## Example Usage\n\n```terraform\nresource \"aws_chime_voice_connector\" \"test\" {\n  name               = \"connector-test-1\"\n  require_encryption = true\n  aws_region         = \"us-east-1\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Amazon Chime Voice Connector.\n* `require_encryption` - (Required) When enabled, requires encryption for the Amazon Chime Voice Connector.\n* `aws_region` - (Optional) The AWS Region in which the Amazon Chime Voice Connector is created. Default value: `us-east-1`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `outbound_host_name` - The outbound host name for the Amazon Chime Voice Connector.\n\n## Import\n\nConfiguration Recorder can be imported using the name, e.g.,\n\n```\n$ terraform import aws_chime_voice_connector.test example\n```\n",
    "basename": "chime_voice_connector.html"
  },
  "chime_voice_connector_group.html": {
    "subcategory": "Chime",
    "layout": "aws",
    "page_title": "AWS: aws_chime_voice_connector_group",
    "description": "Creates an Amazon Chime Voice Connector group under the administrator's AWS account.",
    "preview": "# Resource: aws_chime_voice_connector_group\n\nCreates an Amazon Chime …",
    "content": "\n\n# Resource: aws_chime_voice_connector_group\n\nCreates an Amazon Chime Voice Connector group under the administrator's AWS account. You can associate Amazon Chime Voice Connectors with the Amazon Chime Voice Connector group by including VoiceConnectorItems in the request.\n\nYou can include Amazon Chime Voice Connectors from different AWS Regions in your group. This creates a fault tolerant mechanism for fallback in case of availability events.\n\n## Example Usage\n\n```terraform\nresource \"aws_chime_voice_connector\" \"vc1\" {\n  name               = \"connector-test-1\"\n  require_encryption = true\n  aws_region         = \"us-east-1\"\n}\n\nresource \"aws_chime_voice_connector\" \"vc2\" {\n  name               = \"connector-test-2\"\n  require_encryption = true\n  aws_region         = \"us-west-2\"\n}\n\nresource \"aws_chime_voice_connector_group\" \"group\" {\n  name = \"test-group\"\n\n  connector {\n    voice_connector_id = aws_chime_voice_connector.vc1.id\n    priority           = 1\n  }\n\n  connector {\n    voice_connector_id = aws_chime_voice_connector.vc2.id\n    priority           = 3\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Amazon Chime Voice Connector group.\n* `connector` - (Optional) The Amazon Chime Voice Connectors to route inbound calls to.\n\n### `connector`\n\nFor Amazon Chime Voice Connector groups, the Amazon Chime Voice Connectors to which to route inbound calls. Includes priority configuration settings. Limit: 3 VoiceConnectorItems per Amazon Chime Voice Connector group.\n\n* `voice_connector_id` - (Required) The Amazon Chime Voice Connector ID.\n* `priority` - (Required) The priority associated with the Amazon Chime Voice Connector, with 1 being the highest priority. Higher priority Amazon Chime Voice Connectors are attempted first.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Chime Voice Connector group ID.\n\n## Import\n\nConfiguration Recorder can be imported using the name, e.g.,\n\n```\n$ terraform import aws_chime_voice_connector_group.default example\n```\n",
    "basename": "chime_voice_connector_group.html"
  },
  "chime_voice_connector_logging.html": {
    "subcategory": "Chime",
    "layout": "aws",
    "page_title": "AWS: aws_chime_voice_connector_logging",
    "description": "Adds a logging configuration for the specified Amazon Chime Voice Connector. The logging configuration specifies whether SIP message logs are enabled for sending to Amazon CloudWatch Logs.",
    "preview": "# Resource: aws_chime_voice_connector_logging\n\nAdds a logging …",
    "content": "\n\n# Resource: aws_chime_voice_connector_logging\n\nAdds a logging configuration for the specified Amazon Chime Voice Connector. The logging configuration specifies whether SIP message logs are enabled for sending to Amazon CloudWatch Logs.\n\n## Example Usage\n\n```terraform\nresource \"aws_chime_voice_connector\" \"default\" {\n  name               = \"vc-name-test\"\n  require_encryption = true\n}\n\nresource \"aws_chime_voice_connector_logging\" \"default\" {\n  enable_sip_logs    = true\n  voice_connector_id = aws_chime_voice_connector.default.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `voice_connector_id` - (Required) The Amazon Chime Voice Connector ID.\n* `enable_sip_logs` - (Optional) When true, enables SIP message logs for sending to Amazon CloudWatch Logs.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Chime Voice Connector ID.\n\n## Import\n\nChime Voice Connector Logging can be imported using the `voice_connector_id`, e.g.,\n\n```\n$ terraform import aws_chime_voice_connector_logging.default abcdef1ghij2klmno3pqr4\n```\n",
    "basename": "chime_voice_connector_logging.html"
  },
  "chime_voice_connector_origination.html": {
    "subcategory": "Chime",
    "layout": "aws",
    "page_title": "AWS: aws_chime_voice_connector_origination",
    "description": "Enable origination settings to control inbound calling to your SIP infrastructure.",
    "preview": "# Resource: aws_chime_voice_connector_origination\n\nEnable …",
    "content": "\n\n# Resource: aws_chime_voice_connector_origination\n\nEnable origination settings to control inbound calling to your SIP infrastructure.\n\n## Example Usage\n\n```terraform\nresource \"aws_chime_voice_connector\" \"default\" {\n  name               = \"test\"\n  require_encryption = true\n}\n\nresource \"aws_chime_voice_connector_origination\" \"default\" {\n  disabled           = false\n  voice_connector_id = aws_chime_voice_connector.default.id\n\n  route {\n    host     = \"127.0.0.1\"\n    port     = 8081\n    protocol = \"TCP\"\n    priority = 1\n    weight   = 1\n  }\n\n  route {\n    host     = \"127.0.0.2\"\n    port     = 8082\n    protocol = \"TCP\"\n    priority = 2\n    weight   = 10\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `voice_connector_id` - (Required) The Amazon Chime Voice Connector ID.\n* `route` - (Required) Set of call distribution properties defined for your SIP hosts. See [route](#route) below for more details. Minimum of 1. Maximum of 20.\n* `disabled` - (Optional) When origination settings are disabled, inbound calls are not enabled for your Amazon Chime Voice Connector.\n\n### `route`\n\nOrigination routes define call distribution properties for your SIP hosts to receive inbound calls using your Amazon Chime Voice Connector. Limit: Ten origination routes for each Amazon Chime Voice Connector.\n\n* `host` - (Required) The FQDN or IP address to contact for origination traffic.\n* `port` - (Required) The designated origination route port. Defaults to `5060`.\n* `priority` - (Required) The priority associated with the host, with 1 being the highest priority. Higher priority hosts are attempted first.\n* `protocol` - (Required) The protocol to use for the origination route. Encryption-enabled Amazon Chime Voice Connectors use TCP protocol by default.\n* `weight` - (Required) The weight associated with the host. If hosts are equal in priority, calls are redistributed among them based on their relative weight.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Chime Voice Connector ID.\n\n## Import\n\nChime Voice Connector Origination can be imported using the `voice_connector_id`, e.g.,\n\n```\n$ terraform import aws_chime_voice_connector_origination.default abcdef1ghij2klmno3pqr4\n```\n",
    "basename": "chime_voice_connector_origination.html"
  },
  "chime_voice_connector_streaming.html": {
    "subcategory": "Chime",
    "layout": "aws",
    "page_title": "AWS: aws_chime_voice_connector_streaming",
    "description": "The streaming configuration associated with an Amazon Chime Voice Connector. Specifies whether media streaming is enabled for sending to Amazon Kinesis, and shows the retention period for the Amazon Kinesis data, in hours.",
    "preview": "# Resource: aws_chime_voice_connector_streaming\n\nAdds a streaming …",
    "content": "\n\n# Resource: aws_chime_voice_connector_streaming\n\nAdds a streaming configuration for the specified Amazon Chime Voice Connector. The streaming configuration specifies whether media streaming is enabled for sending to Amazon Kinesis.\nIt also sets the retention period, in hours, for the Amazon Kinesis data.\n\n## Example Usage\n\n```terraform\nresource \"aws_chime_voice_connector\" \"default\" {\n  name               = \"vc-name-test\"\n  require_encryption = true\n}\n\nresource \"aws_chime_voice_connector_streaming\" \"default\" {\n  disabled                       = false\n  voice_connector_id             = aws_chime_voice_connector.default.id\n  data_retention                 = 7\n  streaming_notification_targets = [\"SQS\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `voice_connector_id` - (Required) The Amazon Chime Voice Connector ID.\n* `data_retention`  - (Required) The retention period, in hours, for the Amazon Kinesis data.\n* `disabled` - (Optional) When true, media streaming to Amazon Kinesis is turned off. Default: `false`\n* `streaming_notification_targets` - (Optional) The streaming notification targets. Valid Values: `EventBridge | SNS | SQS`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Chime Voice Connector ID.\n\n## Import\n\nChime Voice Connector Streaming can be imported using the `voice_connector_id`, e.g.,\n\n```\n$ terraform import aws_chime_voice_connector_streaming.default abcdef1ghij2klmno3pqr4\n```\n",
    "basename": "chime_voice_connector_streaming.html"
  },
  "chime_voice_connector_termination.html": {
    "subcategory": "Chime",
    "layout": "aws",
    "page_title": "AWS: aws_chime_voice_connector_termination",
    "description": "Enable Termination settings to control outbound calling from your SIP infrastructure.",
    "preview": "# Resource: aws_chime_voice_connector_termination\n\nEnable …",
    "content": "\n\n# Resource: aws_chime_voice_connector_termination\n\nEnable Termination settings to control outbound calling from your SIP infrastructure.\n\n## Example Usage\n\n```terraform\nresource \"aws_chime_voice_connector\" \"default\" {\n  name               = \"vc-name-test\"\n  require_encryption = true\n}\n\nresource \"aws_chime_voice_connector_termination\" \"default\" {\n  disabled           = false\n  cps_limit          = 1\n  cidr_allow_list    = [\"50.35.78.96/31\"]\n  calling_regions    = [\"US\", \"CA\"]\n  voice_connector_id = aws_chime_voice_connector.default.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `voice_connector_id` - (Required) The Amazon Chime Voice Connector ID.\n* `cidr_allow_list` - (Required) The IP addresses allowed to make calls, in CIDR format.\n* `calling_regions` - (Required) The countries to which calls are allowed, in ISO 3166-1 alpha-2 format.\n* `disabled` - (Optional) When termination settings are disabled, outbound calls can not be made.\n* `default_phone_number` - (Optional) The default caller ID phone number.\n* `cps_limit` - (Optional) The limit on calls per second. Max value based on account service quota. Default value of `1`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Chime Voice Connector ID.\n\n## Import\n\nChime Voice Connector Termination can be imported using the `voice_connector_id`, e.g.,\n\n```\n$ terraform import aws_chime_voice_connector_termination.default abcdef1ghij2klmno3pqr4\n```",
    "basename": "chime_voice_connector_termination.html"
  },
  "chime_voice_connector_termination_credentials.html": {
    "subcategory": "Chime",
    "layout": "aws",
    "page_title": "AWS: aws_chime_voice_connector_termination_credentials",
    "description": "Adds termination SIP credentials for the specified Amazon Chime Voice Connector.",
    "preview": "# Resource: aws_chime_voice_connector_termination_credentials\n\nAdds …",
    "content": "\n\n# Resource: aws_chime_voice_connector_termination_credentials\n\nAdds termination SIP credentials for the specified Amazon Chime Voice Connector.\n\n~> **Note:** Voice Connector Termination Credentials requires a [Voice Connector Termination](/docs/providers/aws/r/chime_voice_connector_termination.html) to be present. Use of `depends_on` (as shown below) is recommended to avoid race conditions.\n\n## Example Usage\n\n```terraform\nresource \"aws_chime_voice_connector\" \"default\" {\n  name               = \"test\"\n  require_encryption = true\n}\n\nresource \"aws_chime_voice_connector_termination\" \"default\" {\n  disabled           = true\n  cps_limit          = 1\n  cidr_allow_list    = [\"50.35.78.96/31\"]\n  calling_regions    = [\"US\", \"CA\"]\n  voice_connector_id = aws_chime_voice_connector.default.id\n}\n\nresource \"aws_chime_voice_connector_termination_credentials\" \"default\" {\n  voice_connector_id = aws_chime_voice_connector.default.id\n\n  credentials {\n    username = \"test\"\n    password = \"test!\"\n  }\n\n  depends_on = [aws_chime_voice_connector_termination.default]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `voice_connector_id` - (Required) Amazon Chime Voice Connector ID.\n* `credentials` - (Required) List of termination SIP credentials.\n\n### `credentials`\n\nThe SIP credentials used to authenticate requests to your Amazon Chime Voice Connector.\n\n* `username` - (Required) RFC2617 compliant username associated with the SIP credentials.\n* `password` - (Required) RFC2617 compliant password associated with the SIP credentials.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Chime Voice Connector ID.\n\n## Import\n\nChime Voice Connector Termination Credentials can be imported using the `voice_connector_id`, e.g.,\n\n```\n$ terraform import aws_chime_voice_connector_termination_credentials.default abcdef1ghij2klmno3pqr4\n```\n",
    "basename": "chime_voice_connector_termination_credentials.html"
  },
  "cloud9_environment_ec2.html": {
    "subcategory": "Cloud9",
    "layout": "aws",
    "page_title": "AWS: aws_cloud9_environment_ec2",
    "description": "Provides a Cloud9 EC2 Development Environment.",
    "preview": "# Resource: aws_cloud9_environment_ec2\n\nProvides a Cloud9 EC2 …",
    "content": "\n\n# Resource: aws_cloud9_environment_ec2\n\nProvides a Cloud9 EC2 Development Environment.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_cloud9_environment_ec2\" \"example\" {\n  instance_type = \"t2.micro\"\n  name          = \"example-env\"\n}\n```\n\nGet the URL of the Cloud9 environment after creation:\n\n```terraform\nresource \"aws_cloud9_environment_ec2\" \"example\" {\n  instance_type = \"t2.micro\"\n}\n\ndata \"aws_instance\" \"cloud9_instance\" {\n  filter {\n    name = \"tag:aws:cloud9:environment\"\n    values = [\n    aws_cloud9_environment_ec2.example.id]\n  }\n}\n\noutput \"cloud9_url\" {\n  value = \"https://${var.region}.console.aws.amazon.com/cloud9/ide/${aws_cloud9_environment_ec2.example.id}\"\n}\n```\n\nAllocate a static IP to the Cloud9 environment:\n\n```terraform\nresource \"aws_cloud9_environment_ec2\" \"example\" {\n  instance_type = \"t2.micro\"\n}\n\ndata \"aws_instance\" \"cloud9_instance\" {\n  filter {\n    name = \"tag:aws:cloud9:environment\"\n    values = [\n    aws_cloud9_environment_ec2.example.id]\n  }\n}\n\nresource \"aws_eip\" \"cloud9_eip\" {\n  instance = data.aws_instance.cloud9_instance.id\n  vpc      = true\n}\n\noutput \"cloud9_public_ip\" {\n  value = aws_eip.cloud9_eip.public_ip\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the environment.\n* `instance_type` - (Required) The type of instance to connect to the environment, e.g., `t2.micro`.\n* `automatic_stop_time_minutes` - (Optional) The number of minutes until the running instance is shut down after the environment has last been used.\n* `description` - (Optional) The description of the environment.\n* `owner_arn` - (Optional) The ARN of the environment owner. This can be ARN of any AWS IAM principal. Defaults to the environment's creator.\n* `subnet_id` - (Optional) The ID of the subnet in Amazon VPC that AWS Cloud9 will use to communicate with the Amazon EC2 instance.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the environment.\n* `arn` - The ARN of the environment.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `type` - The type of the environment (e.g., `ssh` or `ec2`)\n",
    "basename": "cloud9_environment_ec2.html"
  },
  "cloudcontrolapi_resource.html": {
    "subcategory": "Cloud Control API",
    "layout": "aws",
    "page_title": "AWS: aws_cloudcontrolapi_resource",
    "description": "Manages a Cloud Control API Resource.",
    "preview": "# Resource: aws_cloudcontrolapi_resource\n\nManages a Cloud Control …",
    "content": "\n\n# Resource: aws_cloudcontrolapi_resource\n\nManages a Cloud Control API Resource. The configuration and lifecycle handling of these resources is proxied through Cloud Control API handlers to the backend service.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudcontrolapi_resource\" \"example\" {\n  type_name = \"AWS::ECS::Cluster\"\n\n  desired_state = jsonencode({\n    ClusterName = \"example\"\n    Tags = [\n      {\n        Key   = \"CostCenter\"\n        Value = \"IT\"\n      }\n    ]\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `desired_state` - (Required) JSON string matching the CloudFormation resource type schema with desired configuration. Terraform configuration expressions can be converted into JSON using the [`jsonencode()` function](https://www.terraform.io/docs/language/functions/jsonencode.html).\n* `type_name` - (Required) CloudFormation resource type name. For example, `AWS::EC2::VPC`.\n\nThe following arguments are optional:\n\n* `role_arn` - (Optional) Amazon Resource Name (ARN) of the IAM Role to assume for operations.\n* `schema` - (Optional) JSON string of the CloudFormation resource type schema which is used for plan time validation where possible. Automatically fetched if not provided. In large scale environments with multiple resources using the same `type_name`, it is recommended to fetch the schema once via the [`aws_cloudformation_type` data source](/docs/providers/aws/d/cloudformation_type.html) and use this argument to reduce `DescribeType` API operation throttling. This value is marked sensitive only to prevent large plan differences from showing.\n* `type_version_id` - (Optional) Identifier of the CloudFormation resource type version.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `properties` - JSON string matching the CloudFormation resource type schema with current configuration. Underlying attributes can be referenced via the [`jsondecode()` function](https://www.terraform.io/docs/language/functions/jsondecode.html), for example, `jsondecode(data.aws_cloudcontrolapi_resource.example.properties)[\"example\"]`.\n",
    "basename": "cloudcontrolapi_resource.html"
  },
  "cloudformation_stack.html": {
    "subcategory": "CloudFormation",
    "layout": "aws",
    "page_title": "AWS: aws_cloudformation_stack",
    "description": "Provides a CloudFormation Stack resource.",
    "preview": "# Resource: aws_cloudformation_stack\n\nProvides a CloudFormation …",
    "content": "\n\n# Resource: aws_cloudformation_stack\n\nProvides a CloudFormation Stack resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudformation_stack\" \"network\" {\n  name = \"networking-stack\"\n\n  parameters = {\n    VPCCidr = \"10.0.0.0/16\"\n  }\n\n  template_body = <<STACK\n{\n  \"Parameters\" : {\n    \"VPCCidr\" : {\n      \"Type\" : \"String\",\n      \"Default\" : \"10.0.0.0/16\",\n      \"Description\" : \"Enter the CIDR block for the VPC. Default is 10.0.0.0/16.\"\n    }\n  },\n  \"Resources\" : {\n    \"myVpc\": {\n      \"Type\" : \"AWS::EC2::VPC\",\n      \"Properties\" : {\n        \"CidrBlock\" : { \"Ref\" : \"VPCCidr\" },\n        \"Tags\" : [\n          {\"Key\": \"Name\", \"Value\": \"Primary_CF_VPC\"}\n        ]\n      }\n    }\n  }\n}\nSTACK\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Stack name.\n* `template_body` - (Optional) Structure containing the template body (max size: 51,200 bytes).\n* `template_url` - (Optional) Location of a file containing the template body (max size: 460,800 bytes).\n* `capabilities` - (Optional) A list of capabilities.\n  Valid values: `CAPABILITY_IAM`, `CAPABILITY_NAMED_IAM`, or `CAPABILITY_AUTO_EXPAND`\n* `disable_rollback` - (Optional) Set to true to disable rollback of the stack if stack creation failed.\n  Conflicts with `on_failure`.\n* `notification_arns` - (Optional) A list of SNS topic ARNs to publish stack related events.\n* `on_failure` - (Optional) Action to be taken if stack creation fails. This must be\n  one of: `DO_NOTHING`, `ROLLBACK`, or `DELETE`. Conflicts with `disable_rollback`.\n* `parameters` - (Optional) A map of Parameter structures that specify input parameters for the stack.\n* `policy_body` - (Optional) Structure containing the stack policy body.\n  Conflicts w/ `policy_url`.\n* `policy_url` - (Optional) Location of a file containing the stack policy.\n  Conflicts w/ `policy_body`.\n* `tags` - (Optional) Map of resource tags to associate with this stack. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `iam_role_arn` - (Optional) The ARN of an IAM role that AWS CloudFormation assumes to create the stack. If you don't specify a value, AWS CloudFormation uses the role that was previously associated with the stack. If no role is available, AWS CloudFormation uses a temporary session that is generated from your user credentials.\n* `timeout_in_minutes` - (Optional) The amount of time that can pass before the stack status becomes `CREATE_FAILED`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A unique identifier of the stack.\n* `outputs` - A map of outputs from the stack.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nCloudformation Stacks can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_cloudformation_stack.stack networking-stack\n```\n\n## Timeouts\n\n`aws_cloudformation_stack` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `30 minutes`) Used for Creating Stacks\n- `update` - (Default `30 minutes`) Used for Stack modifications\n- `delete` - (Default `30 minutes`) Used for destroying stacks.\n",
    "basename": "cloudformation_stack.html"
  },
  "cloudformation_stack_set.html": {
    "subcategory": "CloudFormation",
    "layout": "aws",
    "page_title": "AWS: aws_cloudformation_stack_set",
    "description": "Manages a CloudFormation StackSet.",
    "preview": "# Resource: aws_cloudformation_stack_set\n\nManages a CloudFormation …",
    "content": "\n\n# Resource: aws_cloudformation_stack_set\n\nManages a CloudFormation StackSet. StackSets allow CloudFormation templates to be easily deployed across multiple accounts and regions via StackSet Instances ([`aws_cloudformation_stack_set_instance` resource](/docs/providers/aws/r/cloudformation_stack_set_instance.html)). Additional information about StackSets can be found in the [AWS CloudFormation User Guide](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/what-is-cfnstacksets.html).\n\n~> **NOTE:** All template parameters, including those with a `Default`, must be configured or ignored with the `lifecycle` configuration block `ignore_changes` argument.\n\n~> **NOTE:** All `NoEcho` template parameters must be ignored with the `lifecycle` configuration block `ignore_changes` argument.\n\n## Example Usage\n\n```terraform\ndata \"aws_iam_policy_document\" \"AWSCloudFormationStackSetAdministrationRole_assume_role_policy\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n    effect  = \"Allow\"\n\n    principals {\n      identifiers = [\"cloudformation.amazonaws.com\"]\n      type        = \"Service\"\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"AWSCloudFormationStackSetAdministrationRole\" {\n  assume_role_policy = data.aws_iam_policy_document.AWSCloudFormationStackSetAdministrationRole_assume_role_policy.json\n  name               = \"AWSCloudFormationStackSetAdministrationRole\"\n}\n\nresource \"aws_cloudformation_stack_set\" \"example\" {\n  administration_role_arn = aws_iam_role.AWSCloudFormationStackSetAdministrationRole.arn\n  name                    = \"example\"\n\n  parameters = {\n    VPCCidr = \"10.0.0.0/16\"\n  }\n\n  template_body = <<TEMPLATE\n{\n  \"Parameters\" : {\n    \"VPCCidr\" : {\n      \"Type\" : \"String\",\n      \"Default\" : \"10.0.0.0/16\",\n      \"Description\" : \"Enter the CIDR block for the VPC. Default is 10.0.0.0/16.\"\n    }\n  },\n  \"Resources\" : {\n    \"myVpc\": {\n      \"Type\" : \"AWS::EC2::VPC\",\n      \"Properties\" : {\n        \"CidrBlock\" : { \"Ref\" : \"VPCCidr\" },\n        \"Tags\" : [\n          {\"Key\": \"Name\", \"Value\": \"Primary_CF_VPC\"}\n        ]\n      }\n    }\n  }\n}\nTEMPLATE\n}\n\ndata \"aws_iam_policy_document\" \"AWSCloudFormationStackSetAdministrationRole_ExecutionPolicy\" {\n  statement {\n    actions   = [\"sts:AssumeRole\"]\n    effect    = \"Allow\"\n    resources = [\"arn:aws:iam::*:role/${aws_cloudformation_stack_set.example.execution_role_name}\"]\n  }\n}\n\nresource \"aws_iam_role_policy\" \"AWSCloudFormationStackSetAdministrationRole_ExecutionPolicy\" {\n  name   = \"ExecutionPolicy\"\n  policy = data.aws_iam_policy_document.AWSCloudFormationStackSetAdministrationRole_ExecutionPolicy.json\n  role   = aws_iam_role.AWSCloudFormationStackSetAdministrationRole.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `administration_role_arn` - (Optional) Amazon Resource Number (ARN) of the IAM Role in the administrator account. This must be defined when using the `SELF_MANAGED` permission model.\n* `auto_deployment` - (Optional) Configuration block containing the auto-deployment model for your StackSet. This can only be defined when using the `SERVICE_MANAGED` permission model.\n    * `enabled` - (Optional) Whether or not auto-deployment is enabled.\n    * `retain_stacks_on_account_removal` - (Optional) Whether or not to retain stacks when the account is removed.\n* `name` - (Required) Name of the StackSet. The name must be unique in the region where you create your StackSet. The name can contain only alphanumeric characters (case-sensitive) and hyphens. It must start with an alphabetic character and cannot be longer than 128 characters.\n* `capabilities` - (Optional) A list of capabilities. Valid values: `CAPABILITY_IAM`, `CAPABILITY_NAMED_IAM`, `CAPABILITY_AUTO_EXPAND`.\n* `description` - (Optional) Description of the StackSet.\n* `execution_role_name` - (Optional) Name of the IAM Role in all target accounts for StackSet operations. Defaults to `AWSCloudFormationStackSetExecutionRole` when using the `SELF_MANAGED` permission model. This should not be defined when using the `SERVICE_MANAGED` permission model.\n* `parameters` - (Optional) Key-value map of input parameters for the StackSet template. All template parameters, including those with a `Default`, must be configured or ignored with `lifecycle` configuration block `ignore_changes` argument. All `NoEcho` template parameters must be ignored with the `lifecycle` configuration block `ignore_changes` argument.\n* `permission_model` - (Optional) Describes how the IAM roles required for your StackSet are created. Valid values: `SELF_MANAGED` (default), `SERVICE_MANAGED`.\n* `tags` - (Optional) Key-value map of tags to associate with this StackSet and the Stacks created from it. AWS CloudFormation also propagates these tags to supported resources that are created in the Stacks. A maximum number of 50 tags can be specified. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `template_body` - (Optional) String containing the CloudFormation template body. Maximum size: 51,200 bytes. Conflicts with `template_url`.\n* `template_url` - (Optional) String containing the location of a file containing the CloudFormation template body. The URL must point to a template that is located in an Amazon S3 bucket. Maximum location file size: 460,800 bytes. Conflicts with `template_body`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the StackSet.\n* `id` - Name of the StackSet.\n* `stack_set_id` - Unique identifier of the StackSet.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_cloudformation_stack_set` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `update` - (Default `30m`) How long to wait for a StackSet to be updated.\n\n## Import\n\nCloudFormation StackSets can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_cloudformation_stack_set.example example\n```\n",
    "basename": "cloudformation_stack_set.html"
  },
  "cloudformation_stack_set_instance.html": {
    "subcategory": "CloudFormation",
    "layout": "aws",
    "page_title": "AWS: aws_cloudformation_stack_set_instance",
    "description": "Manages a CloudFormation StackSet Instance.",
    "preview": "# Resource: aws_cloudformation_stack_set_instance\n\nManages a …",
    "content": "\n\n# Resource: aws_cloudformation_stack_set_instance\n\nManages a CloudFormation StackSet Instance. Instances are managed in the account and region of the StackSet after the target account permissions have been configured. Additional information about StackSets can be found in the [AWS CloudFormation User Guide](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/what-is-cfnstacksets.html).\n\n~> **NOTE:** All target accounts must have an IAM Role created that matches the name of the execution role configured in the StackSet (the `execution_role_name` argument in the `aws_cloudformation_stack_set` resource) in a trust relationship with the administrative account or administration IAM Role. The execution role must have appropriate permissions to manage resources defined in the template along with those required for StackSets to operate. See the [AWS CloudFormation User Guide](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-prereqs.html) for more details.\n\n~> **NOTE:** To retain the Stack during Terraform resource destroy, ensure `retain_stack = true` has been successfully applied into the Terraform state first. This must be completed _before_ an apply that would destroy the resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudformation_stack_set_instance\" \"example\" {\n  account_id     = \"123456789012\"\n  region         = \"us-east-1\"\n  stack_set_name = aws_cloudformation_stack_set.example.name\n}\n```\n\n### Example IAM Setup in Target Account\n\n```terraform\ndata \"aws_iam_policy_document\" \"AWSCloudFormationStackSetExecutionRole_assume_role_policy\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n    effect  = \"Allow\"\n\n    principals {\n      identifiers = [aws_iam_role.AWSCloudFormationStackSetAdministrationRole.arn]\n      type        = \"AWS\"\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"AWSCloudFormationStackSetExecutionRole\" {\n  assume_role_policy = data.aws_iam_policy_document.AWSCloudFormationStackSetExecutionRole_assume_role_policy.json\n  name               = \"AWSCloudFormationStackSetExecutionRole\"\n}\n\n# Documentation: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-prereqs.html\n# Additional IAM permissions necessary depend on the resources defined in the StackSet template\ndata \"aws_iam_policy_document\" \"AWSCloudFormationStackSetExecutionRole_MinimumExecutionPolicy\" {\n  statement {\n    actions = [\n      \"cloudformation:*\",\n      \"s3:*\",\n      \"sns:*\",\n    ]\n\n    effect    = \"Allow\"\n    resources = [\"*\"]\n  }\n}\n\nresource \"aws_iam_role_policy\" \"AWSCloudFormationStackSetExecutionRole_MinimumExecutionPolicy\" {\n  name   = \"MinimumExecutionPolicy\"\n  policy = data.aws_iam_policy_document.AWSCloudFormationStackSetExecutionRole_MinimumExecutionPolicy.json\n  role   = aws_iam_role.AWSCloudFormationStackSetExecutionRole.name\n}\n```\n\n### Example Deployment across Organizations account\n\n```terraform\nresource \"aws_cloudformation_stack_set_instance\" \"example\" {\n  deployment_targets {\n    organizational_unit_ids = [aws_organizations_organization.example.roots[0].id]\n  }\n\n  region         = \"us-east-1\"\n  stack_set_name = aws_cloudformation_stack_set.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_set_name` - (Required) Name of the StackSet.\n* `account_id` - (Optional) Target AWS Account ID to create a Stack based on the StackSet. Defaults to current account.\n* `deployment_targets` - (Optional) The AWS Organizations accounts to which StackSets deploys. StackSets doesn't deploy stack instances to the organization management account, even if the organization management account is in your organization or in an OU in your organization. Drift detection is not possible for this argument. See [deployment_targets](#deployment_targets-argument-reference) below.\n* `parameter_overrides` - (Optional) Key-value map of input parameters to override from the StackSet for this Instance.\n* `region` - (Optional) Target AWS Region to create a Stack based on the StackSet. Defaults to current region.\n* `retain_stack` - (Optional) During Terraform resource destroy, remove Instance from StackSet while keeping the Stack and its associated resources. Must be enabled in Terraform state _before_ destroy operation to take effect. You cannot reassociate a retained Stack or add an existing, saved Stack to a new StackSet. Defaults to `false`.\n\n### `deployment_targets` Argument Reference\n\nThe `deployment_targets` configuration block supports the following arguments:\n\n*`organizational_unit_ids` - (Optional) The organization root ID or organizational unit (OU) IDs to which StackSets deploys.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - StackSet name, target AWS account ID, and target AWS region separated by commas (`,`)\n* `organizational_unit_id` - The organization root ID or organizational unit (OU) IDs specified for `deployment_targets`.\n* `stack_id` - Stack identifier\n\n## Timeouts\n\n`aws_cloudformation_stack_set_instance` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `30m`) How long to wait for a Stack to be created.\n* `update` - (Default `30m`) How long to wait for a Stack to be updated.\n* `delete` - (Default `30m`) How long to wait for a Stack to be deleted.\n\n## Import\n\nCloudFormation StackSet Instances can be imported using the StackSet name, target AWS account ID, and target AWS region separated by commas (`,`) e.g.,\n\n```\n$ terraform import aws_cloudformation_stack_set_instance.example example,123456789012,us-east-1\n```\n",
    "basename": "cloudformation_stack_set_instance.html"
  },
  "cloudformation_type.html": {
    "subcategory": "CloudFormation",
    "layout": "aws",
    "page_title": "AWS: aws_cloudformation_type",
    "description": "Manages a version of a CloudFormation Type.",
    "preview": "# Resource: aws_cloudformation_type\n\nManages a version of a …",
    "content": "\n\n# Resource: aws_cloudformation_type\n\nManages a version of a CloudFormation Type.\n\n~> **NOTE:** The destroy operation of this resource marks the version as deprecated. If this was the only `LIVE` version, the type is marked as deprecated. It is recommended to enable the [resource `lifecycle` configuration block `create_before_destroy` argument](https://www.terraform.io/docs/configuration/resources.html#create_before_destroy) in this resource configuration to properly order redeployments in Terraform.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudformation_type\" \"example\" {\n  schema_handler_package = \"s3://${aws_s3_bucket_object.example.bucket}/${aws_s3_bucket_object.example.key}\"\n  type                   = \"RESOURCE\"\n  type_name              = \"ExampleCompany::ExampleService::ExampleResource\"\n\n  logging_config {\n    log_group_name = aws_cloudwatch_log_group.example.name\n    log_role_arn   = aws_iam_role.example.arn\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `execution_role_arn` - (Optional) Amazon Resource Name (ARN) of the IAM Role for CloudFormation to assume when invoking the extension. If your extension calls AWS APIs in any of its handlers, you must create an IAM execution role that includes the necessary permissions to call those AWS APIs, and provision that execution role in your account. When CloudFormation needs to invoke the extension handler, CloudFormation assumes this execution role to create a temporary session token, which it then passes to the extension handler, thereby supplying your extension with the appropriate credentials.\n* `logging_config` - (Optional) Configuration block containing logging configuration.\n* `schema_handler_package` - (Required) URL to the S3 bucket containing the extension project package that contains the necessary files for the extension you want to register. Must begin with `s3://` or `https://`. For example, `s3://example-bucket/example-object`.\n* `type` - (Optional) CloudFormation Registry Type. For example, `RESOURCE` or `MODULE`.\n* `type_name` - (Optional) CloudFormation Type name. For example, `ExampleCompany::ExampleService::ExampleResource`.\n\n### logging_config\n\nThe following arguments are supported in the `logging_config` configuration block:\n\n* `log_group_name` - (Required) Name of the CloudWatch Log Group where CloudFormation sends error logging information when invoking the type's handlers.\n* `log_role_arn` - (Required) Amazon Resource Name (ARN) of the IAM Role CloudFormation assumes when sending error logging information to CloudWatch Logs.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - (Optional) Amazon Resource Name (ARN) of the CloudFormation Type version. See also `type_arn`.\n* `default_version_id` - Identifier of the CloudFormation Type default version.\n* `deprecated_status` - Deprecation status of the version.\n* `description` - Description of the version.\n* `documentation_url` - URL of the documentation for the CloudFormation Type.\n* `is_default_version` - Whether the CloudFormation Type version is the default version.\n* `provisioning_type` - Provisioning behavior of the CloudFormation Type.\n* `schema` - JSON document of the CloudFormation Type schema.\n* `source_url` - URL of the source code for the CloudFormation Type.\n* `type_arn` - (Optional) Amazon Resource Name (ARN) of the CloudFormation Type. See also `arn`.\n* `version_id` - (Optional) Identifier of the CloudFormation Type version.\n* `visibility` - Scope of the CloudFormation Type.\n\n## Import\n\n`aws_cloudformation_type` can be imported with their type version Amazon Resource Name (ARN), e.g.,\n\n```\nterraform import aws_cloudformation_type.example arn:aws:cloudformation:us-east-1:123456789012:type/resource/ExampleCompany-ExampleService-ExampleType/1\n```\n",
    "basename": "cloudformation_type.html"
  },
  "cloudfront_cache_policy.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_cache_policy",
    "description": "Provides a cache policy for a CloudFront ditribution. When it’s attached to a cache behavior, \nthe cache policy determines the the values that CloudFront includes in the cache key. These \nvalues can include HTTP headers, cookies, and URL query strings. CloudFront uses the cache \nkey to find an object in its cache that it can return to the viewer. It also determines the \ndefault, minimum, and maximum time to live (TTL) values that you want objects to stay in the \nCloudFront cache. ",
    "preview": "# Resource: aws_cloudfront_cache_policy\n\n## Example Usage\n\nThe …",
    "content": "\n\n# Resource: aws_cloudfront_cache_policy\n\n## Example Usage\n\nThe following example below creates a CloudFront cache policy.\n\n```terraform\nresource \"aws_cloudfront_cache_policy\" \"example\" {\n  name        = \"example-policy\"\n  comment     = \"test comment\"\n  default_ttl = 50\n  max_ttl     = 100\n  min_ttl     = 1\n  parameters_in_cache_key_and_forwarded_to_origin {\n    cookies_config {\n      cookie_behavior = \"whitelist\"\n      cookies {\n        items = [\"example\"]\n      }\n    }\n    headers_config {\n      header_behavior = \"whitelist\"\n      headers {\n        items = [\"example\"]\n      }\n    }\n    query_strings_config {\n      query_string_behavior = \"whitelist\"\n      query_strings {\n        items = [\"example\"]\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A unique name to identify the cache policy.\n* `min_ttl` - (Required) The minimum amount of time, in seconds, that you want objects to stay in the CloudFront cache before CloudFront sends another request to the origin to see if the object has been updated.\n* `max_ttl` - (Optional) The maximum amount of time, in seconds, that objects stay in the CloudFront cache before CloudFront sends another request to the origin to see if the object has been updated.\n* `default_ttl` - (Optional) The default amount of time, in seconds, that you want objects to stay in the CloudFront cache before CloudFront sends another request to the origin to see if the object has been updated.\n* `comment` - (Optional) A comment to describe the cache policy.\n* `parameters_in_cache_key_and_forwarded_to_origin` - (Required) The HTTP headers, cookies, and URL query strings to include in the cache key. See [Parameters In Cache Key And Forwarded To Origin](#parameters-in-cache-key-and-forwarded-to-origin) for more information.\n\n### Parameters In Cache Key And Forwarded To Origin\n\n* `cookies_config` - (Required) Object that determines whether any cookies in viewer requests (and if so, which cookies) are included in the cache key and automatically included in requests that CloudFront sends to the origin. See [Cookies Config](#cookies-config) for more information.\n* `headers_config` - (Required) Object that determines whether any HTTP headers (and if so, which headers) are included in the cache key and automatically included in requests that CloudFront sends to the origin. See [Headers Config](#headers-config) for more information.\n* `query_strings_config` - (Required) Object that determines whether any URL query strings in viewer requests (and if so, which query strings) are included in the cache key and automatically included in requests that CloudFront sends to the origin. See [Query Strings Config](#query-strings-config) for more information.\n* `enable_accept_encoding_brotli` - (Optional) A flag that can affect whether the Accept-Encoding HTTP header is included in the cache key and included in requests that CloudFront sends to the origin.\n* `enable_accept_encoding_gzip` - (Optional) A flag that can affect whether the Accept-Encoding HTTP header is included in the cache key and included in requests that CloudFront sends to the origin.\n\n### Cookies Config\n\n* `cookie_behavior` - (Required) Determines whether any cookies in viewer requests are included in the cache key and automatically included in requests that CloudFront sends to the origin. Valid values are `none`, `whitelist`, `allExcept`, `all`.\n* `cookies` - (Optional) Object that contains a list of cookie names. See [Items](#items) for more information.\n\n### Headers Config\n\n* `header_behavior` - (Required) Determines whether any HTTP headers are included in the cache key and automatically included in requests that CloudFront sends to the origin. Valid values are `none`, `whitelist`.\n* `headers` - (Optional) Object that contains a list of header names. See [Items](#items) for more information.\n\n### Query String Config\n\n* `query_string_behavior` - (Required) Determines whether any URL query strings in viewer requests are included in the cache key and automatically included in requests that CloudFront sends to the origin. Valid values are `none`, `whitelist`, `allExcept`, `all`.\n* `query_strings` - (Optional) Object that contains a list of query string names. See [Items](#items) for more information.\n\n### Items\n\n* `items` - (Required) A list of item names (cookies, headers, or query strings).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `etag` - The current version of the cache policy.\n* `id` - The identifier for the cache policy.\n\n## Import\n\nCloudfront Cache Policies can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_cloudfront_cache_policy.policy 658327ea-f89d-4fab-a63d-7e88639e58f6\n```",
    "basename": "cloudfront_cache_policy.html"
  },
  "cloudfront_distribution.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_distribution",
    "description": "Provides a CloudFront web distribution resource.",
    "preview": "# Resource: aws_cloudfront_distribution\n\nCreates an Amazon …",
    "content": "\n\n# Resource: aws_cloudfront_distribution\n\nCreates an Amazon CloudFront web distribution.\n\nFor information about CloudFront distributions, see the\n[Amazon CloudFront Developer Guide][1]. For specific information about creating\nCloudFront web distributions, see the [POST Distribution][2] page in the Amazon\nCloudFront API Reference.\n\n~> **NOTE:** CloudFront distributions take about 15 minutes to a deployed state\nafter creation or modification. During this time, deletes to resources will be\nblocked. If you need to delete a distribution that is enabled and you do not\nwant to wait, you need to use the `retain_on_delete` flag.\n\n## Example Usage\n\nThe following example below creates a CloudFront distribution with an S3 origin.\n\n```terraform\nresource \"aws_s3_bucket\" \"b\" {\n  bucket = \"mybucket\"\n  acl    = \"private\"\n\n  tags = {\n    Name = \"My bucket\"\n  }\n}\n\nlocals {\n  s3_origin_id = \"myS3Origin\"\n}\n\nresource \"aws_cloudfront_distribution\" \"s3_distribution\" {\n  origin {\n    domain_name = aws_s3_bucket.b.bucket_regional_domain_name\n    origin_id   = local.s3_origin_id\n\n    s3_origin_config {\n      origin_access_identity = \"origin-access-identity/cloudfront/ABCDEFG1234567\"\n    }\n  }\n\n  enabled             = true\n  is_ipv6_enabled     = true\n  comment             = \"Some comment\"\n  default_root_object = \"index.html\"\n\n  logging_config {\n    include_cookies = false\n    bucket          = \"mylogs.s3.amazonaws.com\"\n    prefix          = \"myprefix\"\n  }\n\n  aliases = [\"mysite.example.com\", \"yoursite.example.com\"]\n\n  default_cache_behavior {\n    allowed_methods  = [\"DELETE\", \"GET\", \"HEAD\", \"OPTIONS\", \"PATCH\", \"POST\", \"PUT\"]\n    cached_methods   = [\"GET\", \"HEAD\"]\n    target_origin_id = local.s3_origin_id\n\n    forwarded_values {\n      query_string = false\n\n      cookies {\n        forward = \"none\"\n      }\n    }\n\n    viewer_protocol_policy = \"allow-all\"\n    min_ttl                = 0\n    default_ttl            = 3600\n    max_ttl                = 86400\n  }\n\n  # Cache behavior with precedence 0\n  ordered_cache_behavior {\n    path_pattern     = \"/content/immutable/*\"\n    allowed_methods  = [\"GET\", \"HEAD\", \"OPTIONS\"]\n    cached_methods   = [\"GET\", \"HEAD\", \"OPTIONS\"]\n    target_origin_id = local.s3_origin_id\n\n    forwarded_values {\n      query_string = false\n      headers      = [\"Origin\"]\n\n      cookies {\n        forward = \"none\"\n      }\n    }\n\n    min_ttl                = 0\n    default_ttl            = 86400\n    max_ttl                = 31536000\n    compress               = true\n    viewer_protocol_policy = \"redirect-to-https\"\n  }\n\n  # Cache behavior with precedence 1\n  ordered_cache_behavior {\n    path_pattern     = \"/content/*\"\n    allowed_methods  = [\"GET\", \"HEAD\", \"OPTIONS\"]\n    cached_methods   = [\"GET\", \"HEAD\"]\n    target_origin_id = local.s3_origin_id\n\n    forwarded_values {\n      query_string = false\n\n      cookies {\n        forward = \"none\"\n      }\n    }\n\n    min_ttl                = 0\n    default_ttl            = 3600\n    max_ttl                = 86400\n    compress               = true\n    viewer_protocol_policy = \"redirect-to-https\"\n  }\n\n  price_class = \"PriceClass_200\"\n\n  restrictions {\n    geo_restriction {\n      restriction_type = \"whitelist\"\n      locations        = [\"US\", \"CA\", \"GB\", \"DE\"]\n    }\n  }\n\n  tags = {\n    Environment = \"production\"\n  }\n\n  viewer_certificate {\n    cloudfront_default_certificate = true\n  }\n}\n```\n\nThe following example below creates a Cloudfront distribution with an origin group for failover routing:\n\n```terraform\nresource \"aws_cloudfront_distribution\" \"s3_distribution\" {\n  origin_group {\n    origin_id = \"groupS3\"\n\n    failover_criteria {\n      status_codes = [403, 404, 500, 502]\n    }\n\n    member {\n      origin_id = \"primaryS3\"\n    }\n\n    member {\n      origin_id = \"failoverS3\"\n    }\n  }\n\n  origin {\n    domain_name = aws_s3_bucket.primary.bucket_regional_domain_name\n    origin_id   = \"primaryS3\"\n\n    s3_origin_config {\n      origin_access_identity = aws_cloudfront_origin_access_identity.default.cloudfront_access_identity_path\n    }\n  }\n\n  origin {\n    domain_name = aws_s3_bucket.failover.bucket_regional_domain_name\n    origin_id   = \"failoverS3\"\n\n    s3_origin_config {\n      origin_access_identity = aws_cloudfront_origin_access_identity.default.cloudfront_access_identity_path\n    }\n  }\n\n  default_cache_behavior {\n    # ... other configuration ...\n    target_origin_id = \"groupS3\"\n  }\n\n  # ... other configuration ...\n}\n```\n\n## Argument Reference\n\nThe CloudFront distribution argument layout is a complex structure composed\nof several sub-resources - these resources are laid out below.\n\n### Top-Level Arguments\n\n* `aliases` (Optional) - Extra CNAMEs (alternate domain names), if any, for\n    this distribution.\n\n* `comment` (Optional) - Any comments you want to include about the\n    distribution.\n\n* `custom_error_response` (Optional) - One or more [custom error response](#custom-error-response-arguments) elements (multiples allowed).\n\n* `default_cache_behavior` (Required) - The [default cache behavior](#default-cache-behavior-arguments) for this distribution (maximum\n    one).\n\n* `default_root_object` (Optional) - The object that you want CloudFront to\n    return (for example, index.html) when an end user requests the root URL.\n\n* `enabled` (Required) - Whether the distribution is enabled to accept end\n    user requests for content.\n\n* `is_ipv6_enabled` (Optional) - Whether the IPv6 is enabled for the distribution.\n\n* `http_version` (Optional) - The maximum HTTP version to support on the\n    distribution. Allowed values are `http1.1` and `http2`. The default is\n    `http2`.\n\n* `logging_config` (Optional) - The [logging\n    configuration](#logging-config-arguments) that controls how logs are written\n    to your distribution (maximum one).\n\n* `ordered_cache_behavior` (Optional) - An ordered list of [cache behaviors](#cache-behavior-arguments)\n    resource for this distribution. List from top to bottom\n    in order of precedence. The topmost cache behavior will have precedence 0.\n\n* `origin` (Required) - One or more [origins](#origin-arguments) for this\n    distribution (multiples allowed).\n\n* `origin_group` (Optional) - One or more [origin_group](#origin-group-arguments) for this\n  distribution (multiples allowed).\n\n* `price_class` (Optional) - The price class for this distribution. One of\n    `PriceClass_All`, `PriceClass_200`, `PriceClass_100`\n\n* `restrictions` (Required) - The [restriction\n    configuration](#restrictions-arguments) for this distribution (maximum one).\n\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n* `viewer_certificate` (Required) - The [SSL\n    configuration](#viewer-certificate-arguments) for this distribution (maximum\n    one).\n\n* `web_acl_id` (Optional) - A unique identifier that specifies the AWS WAF web ACL,\n    if any, to associate with this distribution.  \n    To specify a web ACL created using the latest version of AWS WAF (WAFv2), use the ACL ARN,\n    for example `aws_wafv2_web_acl.example.arn`. To specify a web\n    ACL created using AWS WAF Classic, use the ACL ID, for example `aws_waf_web_acl.example.id`.\n    The WAF Web ACL must exist in the WAF Global (CloudFront) region and the\n    credentials configuring this argument must have `waf:GetWebACL` permissions assigned.\n\n* `retain_on_delete` (Optional) - Disables the distribution instead of\n    deleting it when destroying the resource through Terraform. If this is set,\n    the distribution needs to be deleted manually afterwards. Default: `false`.\n\n* `wait_for_deployment` (Optional) - If enabled, the resource will wait for\n    the distribution status to change from `InProgress` to `Deployed`. Setting\n    this to`false` will skip the process. Default: `true`.\n\n#### Cache Behavior Arguments\n\n* `allowed_methods` (Required) - Controls which HTTP methods CloudFront\n    processes and forwards to your Amazon S3 bucket or your custom origin.\n\n* `cached_methods` (Required) - Controls whether CloudFront caches the\n    response to requests using the specified HTTP methods.\n\n* `cache_policy_id` (Optional) - The unique identifier of the cache policy that\n    is attached to the cache behavior.\n\n* `compress` (Optional) - Whether you want CloudFront to automatically\n    compress content for web requests that include `Accept-Encoding: gzip` in\n    the request header (default: `false`).\n\n* `default_ttl` (Optional) - The default amount of time (in seconds) that an\n    object is in a CloudFront cache before CloudFront forwards another request\n    in the absence of an `Cache-Control max-age` or `Expires` header.\n\n* `field_level_encryption_id` (Optional) - Field level encryption configuration ID\n\n* `forwarded_values` (Optional) - The [forwarded values configuration](#forwarded-values-arguments) that specifies how CloudFront\n    handles query strings, cookies and headers (maximum one).\n\n* `lambda_function_association` (Optional) - A [config block](#lambda-function-association) that triggers a lambda\n    function with specific actions (maximum 4).\n\n* `function_association` (Optional) - A [config block](#function-association) that triggers a cloudfront\n    function with specific actions (maximum 2).\n\n* `max_ttl` (Optional) - The maximum amount of time (in seconds) that an\n    object is in a CloudFront cache before CloudFront forwards another request\n    to your origin to determine whether the object has been updated. Only\n    effective in the presence of `Cache-Control max-age`, `Cache-Control\n    s-maxage`, and `Expires` headers.\n\n* `min_ttl` (Optional) - The minimum amount of time that you want objects to\n    stay in CloudFront caches before CloudFront queries your origin to see\n    whether the object has been updated. Defaults to 0 seconds.\n\n* `origin_request_policy_id` (Optional) - The unique identifier of the origin request policy\n    that is attached to the behavior.\n\n* `path_pattern` (Required) - The pattern (for example, `images/*.jpg`) that\n    specifies which requests you want this cache behavior to apply to.\n\n* `realtime_log_config_arn` (Optional) - The ARN of the [real-time log configuration](cloudfront_realtime_log_config.html)\n    that is attached to this cache behavior.\n  \n* `response_headers_policy_id` (Optional) - The identifier for a response headers policy.\n\n* `smooth_streaming` (Optional) - Indicates whether you want to distribute\n    media files in Microsoft Smooth Streaming format using the origin that is\n    associated with this cache behavior.\n\n* `target_origin_id` (Required) - The value of ID for the origin that you want\n    CloudFront to route requests to when a request matches the path pattern\n    either for a cache behavior or for the default cache behavior.\n\n* `trusted_key_groups` (Optional) - A list of key group IDs that CloudFront can use to validate signed URLs or signed cookies.\nSee the [CloudFront User Guide](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-trusted-signers.html) for more information about this feature.\n\n* `trusted_signers` (Optional) - List of AWS account IDs (or `self`) that you want to allow to create signed URLs for private content.\nSee the [CloudFront User Guide](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-trusted-signers.html) for more information about this feature.\n\n* `viewer_protocol_policy` (Required) - Use this element to specify the\n    protocol that users can use to access the files in the origin specified by\n    TargetOriginId when a request matches the path pattern in PathPattern. One\n    of `allow-all`, `https-only`, or `redirect-to-https`.\n\n##### Forwarded Values Arguments\n\n* `cookies` (Required) - The [forwarded values cookies](#cookies-arguments)\n    that specifies how CloudFront handles cookies (maximum one).\n\n* `headers` (Optional) - Specifies the Headers, if any, that you want\n    CloudFront to vary upon for this cache behavior. Specify `*` to include all\n    headers.\n\n* `query_string` (Required) - Indicates whether you want CloudFront to forward\n    query strings to the origin that is associated with this cache behavior.\n\n* `query_string_cache_keys` (Optional) - When specified, along with a value of\n    `true` for `query_string`, all query strings are forwarded, however only the\n    query string keys listed in this argument are cached. When omitted with a\n    value of `true` for `query_string`, all query string keys are cached.\n\n##### Lambda Function Association\n\nLambda@Edge allows you to associate an AWS Lambda Function with a predefined\nevent. You can associate a single function per event type. See [What is\nLambda@Edge](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/what-is-lambda-at-edge.html)\nfor more information.\n\nExample configuration:\n\n```terraform\nresource \"aws_cloudfront_distribution\" \"example\" {\n  # ... other configuration ...\n\n  # lambda_function_association is also supported by default_cache_behavior\n  ordered_cache_behavior {\n    # ... other configuration ...\n\n    lambda_function_association {\n      event_type   = \"viewer-request\"\n      lambda_arn   = aws_lambda_function.example.qualified_arn\n      include_body = false\n    }\n  }\n}\n```\n\n* `event_type` (Required) - The specific event to trigger this function.\n  Valid values: `viewer-request`, `origin-request`, `viewer-response`,\n  `origin-response`\n* `lambda_arn` (Required) - ARN of the Lambda function.\n* `include_body` (Optional) - When set to true it exposes the request body to the lambda function. Defaults to false. Valid values: `true`, `false`.\n\n##### Function Association\n\nWith CloudFront Functions in Amazon CloudFront, you can write lightweight functions in JavaScript for high-scale, latency-sensitive CDN customizations. You can associate a single function per event type. See [Cloudfront Functions](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cloudfront-functions.html)\nfor more information.\n\nExample configuration:\n\n```terraform\nresource \"aws_cloudfront_distribution\" \"example\" {\n  # ... other configuration ...\n\n  # function_association is also supported by default_cache_behavior\n  ordered_cache_behavior {\n    # ... other configuration ...\n\n    function_association {\n      event_type   = \"viewer-request\"\n      function_arn = aws_cloudfront_function.example.arn\n    }\n  }\n}\n```\n\n* `event_type` (Required) - The specific event to trigger this function.\n  Valid values: `viewer-request` or `viewer-response`\n* `function_arn` (Required) - ARN of the Cloudfront function.\n\n##### Cookies Arguments\n\n* `forward` (Required) - Specifies whether you want CloudFront to forward\n    cookies to the origin that is associated with this cache behavior. You can\n    specify `all`, `none` or `whitelist`. If `whitelist`, you must include the\n    subsequent `whitelisted_names`\n\n* `whitelisted_names` (Optional) - If you have specified `whitelist` to\n    `forward`, the whitelisted cookies that you want CloudFront to forward to\n    your origin.\n\n#### Custom Error Response Arguments\n\n* `error_caching_min_ttl` (Optional) - The minimum amount of time you want\n    HTTP error codes to stay in CloudFront caches before CloudFront queries your\n    origin to see whether the object has been updated.\n\n* `error_code` (Required) - The 4xx or 5xx HTTP status code that you want to\n    customize.\n\n* `response_code` (Optional) - The HTTP status code that you want CloudFront\n    to return with the custom error page to the viewer.\n\n* `response_page_path` (Optional) - The path of the custom error page (for\n    example, `/custom_404.html`).\n\n#### Default Cache Behavior Arguments\n\nThe arguments for `default_cache_behavior` are the same as for\n[`ordered_cache_behavior`](#cache-behavior-arguments), except for the `path_pattern`\nargument should not be specified.\n\n#### Logging Config Arguments\n\n* `bucket` (Required) - The Amazon S3 bucket to store the access logs in, for\n    example, `myawslogbucket.s3.amazonaws.com`.\n\n* `include_cookies` (Optional) - Specifies whether you want CloudFront to\n    include cookies in access logs (default: `false`).\n\n* `prefix` (Optional) - An optional string that you want CloudFront to prefix\n    to the access log filenames for this distribution, for example, `myprefix/`.\n\n#### Origin Arguments\n\n* `connection_attempts` (Optional) - The number of times that CloudFront attempts to connect to the origin. Must be between 1-3. Defaults to 3.\n\n* `connection_timeout` (Optional) - The number of seconds that CloudFront waits when trying to establish a connection to the origin. Must be between 1-10. Defaults to 10.\n\n* `custom_origin_config` - The [CloudFront custom\n    origin](#custom-origin-config-arguments) configuration information. If an S3\n    origin is required, use `s3_origin_config` instead.\n\n* `domain_name` (Required) - The DNS domain name of either the S3 bucket, or\n    web site of your custom origin.\n\n* `custom_header` (Optional) - One or more sub-resources with `name` and\n    `value` parameters that specify header data that will be sent to the origin\n    (multiples allowed).\n\n* `origin_id` (Required) - A unique identifier for the origin.\n\n* `origin_path` (Optional) - An optional element that causes CloudFront to\n    request your content from a directory in your Amazon S3 bucket or your\n    custom origin.\n\n* `origin_shield` - The [CloudFront Origin Shield](#origin-shield-arguments)\n    configuration information. Using Origin Shield can help reduce the load on your origin. For more information, see [Using Origin Shield](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/origin-shield.html) in the Amazon CloudFront Developer Guide.\n\n* `s3_origin_config` - The [CloudFront S3 origin](#s3-origin-config-arguments)\n    configuration information. If a custom origin is required, use\n    `custom_origin_config` instead.\n\n##### Custom Origin Config Arguments\n\n* `http_port` (Required) - The HTTP port the custom origin listens on.\n\n* `https_port` (Required) - The HTTPS port the custom origin listens on.\n\n* `origin_protocol_policy` (Required) - The origin protocol policy to apply to\n    your origin. One of `http-only`, `https-only`, or `match-viewer`.\n\n* `origin_ssl_protocols` (Required) - The SSL/TLS protocols that you want\n    CloudFront to use when communicating with your origin over HTTPS. A list of\n    one or more of `SSLv3`, `TLSv1`, `TLSv1.1`, and `TLSv1.2`.\n\n* `origin_keepalive_timeout` - (Optional) The Custom KeepAlive timeout, in seconds. By default, AWS enforces a limit of `60`. But you can request an [increase](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorCustomOrigin.html#request-custom-request-timeout).\n\n* `origin_read_timeout` - (Optional) The Custom Read timeout, in seconds. By default, AWS enforces a limit of `60`. But you can request an [increase](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorCustomOrigin.html#request-custom-request-timeout).\n\n##### Origin Shield Arguments\n\n* `enabled` (Required) - A flag that specifies whether Origin Shield is enabled.\n\n* `origin_shield_region` (Required) - The AWS Region for Origin Shield. To specify a region, use the region code, not the region name. For example, specify the US East (Ohio) region as us-east-2.\n\n##### S3 Origin Config Arguments\n\n* `origin_access_identity` (Optional) - The [CloudFront origin access\n  identity][5] to associate with the origin.\n\n#### Origin Group Arguments\n\n* `origin_id` (Required) - A unique identifier for the origin group.\n\n* `failover_criteria` (Required) - The [failover criteria](#failover-criteria-arguments) for when to failover to the secondary origin\n\n* `member` (Required) - Ordered [member](#member-arguments) configuration blocks assigned to the origin group, where the first member is the primary origin. You must specify two members.\n\n##### Failover Criteria Arguments\n\n* `status_codes` (Required) - A list of HTTP status codes for the origin group\n\n##### Member Arguments\n\n* `origin_id` (Required) - The unique identifier of the member origin\n\n#### Restrictions Arguments\n\nThe `restrictions` sub-resource takes another single sub-resource named\n`geo_restriction` (see the example for usage).\n\nThe arguments of `geo_restriction` are:\n\n* `locations` (Optional) - The [ISO 3166-1-alpha-2 codes][4] for which you\n    want CloudFront either to distribute your content (`whitelist`) or not\n    distribute your content (`blacklist`).\n\n* `restriction_type` (Required) - The method that you want to use to restrict\n    distribution of your content by country: `none`, `whitelist`, or\n    `blacklist`.\n\n#### Viewer Certificate Arguments\n\n* `acm_certificate_arn` - The ARN of the [AWS Certificate Manager][6]\n    certificate that you wish to use with this distribution. Specify this,\n    `cloudfront_default_certificate`, or `iam_certificate_id`.  The ACM\n    certificate must be in  US-EAST-1.\n\n* `cloudfront_default_certificate` - `true` if you want viewers to use HTTPS\n    to request your objects and you're using the CloudFront domain name for your\n    distribution. Specify this, `acm_certificate_arn`, or `iam_certificate_id`.\n\n* `iam_certificate_id` - The IAM certificate identifier of the custom viewer\n    certificate for this distribution if you are using a custom domain. Specify\n    this, `acm_certificate_arn`, or `cloudfront_default_certificate`.\n\n* `minimum_protocol_version` - The minimum version of the SSL protocol that\n    you want CloudFront to use for HTTPS connections. Can only be set if\n    `cloudfront_default_certificate = false`. See all possible values in\n    [this](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/secure-connections-supported-viewer-protocols-ciphers.html)\n    table under \"Security policy.\" Some examples include: `TLSv1.2_2019` and\n    `TLSv1.2_2021`. Default: `TLSv1`. **NOTE**:\n    If you are using a custom certificate (specified with `acm_certificate_arn`\n    or `iam_certificate_id`), and have specified `sni-only` in\n    `ssl_support_method`, `TLSv1` or later must be specified. If you have\n    specified `vip` in `ssl_support_method`, only `SSLv3` or `TLSv1` can be\n    specified. If you have specified `cloudfront_default_certificate`, `TLSv1`\n    must be specified.\n\n* `ssl_support_method`: Specifies how you want CloudFront to serve HTTPS\n    requests. One of `vip` or `sni-only`. Required if you specify\n    `acm_certificate_arn` or `iam_certificate_id`. **NOTE:** `vip` causes\n    CloudFront to use a dedicated IP address and may incur extra charges.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identifier for the distribution. For example: `EDFDVBD632BHDS5`.\n\n* `arn` - The ARN (Amazon Resource Name) for the distribution. For example: `arn:aws:cloudfront::123456789012:distribution/EDFDVBD632BHDS5`, where `123456789012` is your AWS account ID.\n\n* `caller_reference` - Internal value used by CloudFront to allow future\n    updates to the distribution configuration.\n\n* `status` - The current status of the distribution. `Deployed` if the\n    distribution's information is fully propagated throughout the Amazon\n    CloudFront system.\n\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n* `trusted_key_groups` - List of nested attributes for active trusted key groups, if the distribution is set up to serve private content with signed URLs\n    * `enabled` - `true` if any of the key groups have public keys that CloudFront can use to verify the signatures of signed URLs and signed cookies\n    * `items` - List of nested attributes for each key group\n        * `key_group_id` - The ID of the key group that contains the public keys\n        * `key_pair_ids` - Set of CloudFront key pair IDs\n\n* `trusted_signers` - List of nested attributes for active trusted signers, if the distribution is set up to serve private content with signed URLs\n    * `enabled` - `true` if any of the AWS accounts listed as trusted signers have active CloudFront key pairs\n    * `items` - List of nested attributes for each trusted signer\n        * `aws_account_number` - AWS account ID or `self`\n        * `key_pair_ids` - Set of active CloudFront key pairs associated with the signer account\n\n* `domain_name` - The domain name corresponding to the distribution. For\n    example: `d604721fxaaqy9.cloudfront.net`.\n\n* `last_modified_time` - The date and time the distribution was last modified.\n\n* `in_progress_validation_batches` - The number of invalidation batches\n    currently in progress.\n\n* `etag` - The current version of the distribution's information. For example:\n    `E2QWRUHAPOMQZL`.\n\n* `hosted_zone_id` - The CloudFront Route 53 zone ID that can be used to\n     route an [Alias Resource Record Set][7] to. This attribute is simply an\n     alias for the zone ID `Z2FDTNDATAQYW2`.\n\n[1]: http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html\n[2]: https://docs.aws.amazon.com/cloudfront/latest/APIReference/API_CreateDistribution.html\n[3]: http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html\n[4]: http://www.iso.org/iso/country_codes/iso_3166_code_lists/country_names_and_code_elements.htm\n[5]: /docs/providers/aws/r/cloudfront_origin_access_identity.html\n[6]: https://aws.amazon.com/certificate-manager/\n[7]: http://docs.aws.amazon.com/Route53/latest/APIReference/CreateAliasRRSAPI.html\n\n## Import\n\nCloudfront Distributions can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_cloudfront_distribution.distribution E74FTE3EXAMPLE\n```\n",
    "basename": "cloudfront_distribution.html"
  },
  "cloudfront_field_level_encryption_config.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: cloudfront_field_level_encryption_config",
    "description": "Provides a CloudFront Field-level Encryption Config resource.",
    "preview": "# Resource: aws_cloudfront_field_level_encryption_config\n\nProvides a …",
    "content": "\n\n# Resource: aws_cloudfront_field_level_encryption_config\n\nProvides a CloudFront Field-level Encryption Config resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudfront_field_level_encryption_config\" \"test\" {\n  comment = \"test comment\"\n\n  content_type_profile_config {\n    forward_when_content_type_is_unknown = true\n\n    content_type_profiles {\n      items {\n        content_type = \"application/x-www-form-urlencoded\"\n        format       = \"URLEncoded\"\n      }\n    }\n  }\n\n  query_arg_profile_config {\n    forward_when_query_arg_profile_is_unknown = true\n\n    query_arg_profiles {\n      items {\n        profile_id = aws_cloudfront_field_level_encryption_profile.test.id\n        query_arg  = \"Arg1\"\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `comment` - (Optional) An optional comment about the Field Level Encryption Config.\n* `content_type_profile_config` - (Required) [Content Type Profile Config](#content-type-profile-config) specifies when to forward content if a content type isn't recognized and profiles to use as by default in a request if a query argument doesn't specify a profile to use.\n* `query_arg_profile_config` - (Required) [Query Arg Profile Config](#query-arg-profile-config) that specifies when to forward content if a profile isn't found and the profile that can be provided as a query argument in a request.\n\n### Content Type Profile Config\n\n* `forward_when_content_type_is_unknown` - (Required) specifies what to do when an unknown content type is provided for the profile. If true, content is forwarded without being encrypted when the content type is unknown. If false (the default), an error is returned when the content type is unknown.\n* `content_type_profiles` - (Required) Object that contains an attribute `items` that contains the list of configurations for a field-level encryption content type-profile. See [Content Type Profile](#content-type-profile).\n\n### Content Type Profile\n\n* `content_type` - (Required) he content type for a field-level encryption content type-profile mapping. Valid value is `application/x-www-form-urlencoded`.\n* `format` - (Required) The format for a field-level encryption content type-profile mapping. Valid value is `URLEncoded`.\n* `profile_id` - (Optional) The profile ID for a field-level encryption content type-profile mapping.\n\n### Query Arg Profile Config\n\n* `forward_when_query_arg_profile_is_unknown` - (Required) Flag to set if you want a request to be forwarded to the origin even if the profile specified by the field-level encryption query argument, fle-profile, is unknown.\n* `query_arg_profiles` - (Optional) Object that contains an attribute `items` that contains the list ofrofiles specified for query argument-profile mapping for field-level encryption. see [Query Arg Profile](#query-arg-profile).\n\n### Query Arg Profile\n\n* `profile_id` - (Required) ID of profile to use for field-level encryption query argument-profile mapping\n* `query_arg` - (Required) Query argument for field-level encryption query argument-profile mapping.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `caller_reference` - Internal value used by CloudFront to allow future updates to the Field Level Encryption Config.\n* `etag` - The current version of the Field Level Encryption Config. For example: `E2QWRUHAPOMQZL`.\n* `id` - The identifier for the Field Level Encryption Config. For example: `K3D5EWEUDCCXON`.\n\n## Import\n\nCloudfront Field Level Encryption Config can be imported using the `id`, e.g.\n\n```\n$ terraform import aws_cloudfront_field_level_encryption_config.config E74FTE3AEXAMPLE\n```",
    "basename": "cloudfront_field_level_encryption_config.html"
  },
  "cloudfront_field_level_encryption_profile.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: cloudfront_field_level_encryption_profile",
    "description": "Provides a CloudFront Field-level Encryption Profile resource.",
    "preview": "# Resource: aws_cloudfront_field_level_encryption_profile\n\nProvides …",
    "content": "\n\n# Resource: aws_cloudfront_field_level_encryption_profile\n\nProvides a CloudFront Field-level Encryption Profile resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudfront_public_key\" \"example\" {\n  comment     = \"test public key\"\n  encoded_key = file(\"public_key.pem\")\n  name        = \"test_key\"\n}\n\nresource \"aws_cloudfront_field_level_encryption_profile\" \"test\" {\n  comment = \"test comment\"\n  name    = \"test profile\"\n\n  encryption_entities {\n    items {\n      public_key_id = aws_cloudfront_public_key.example.id\n      provider_id   = \"test provider\"\n\n      field_patterns {\n        items = [\"DateOfBirth\"]\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Field Level Encryption Profile.\n* `comment` - (Optional) An optional comment about the Field Level Encryption Profile.\n* `encryption_entities` - (Required) The [encryption entities](#encryption-entities) config block for field-level encryption profiles that contains an attribute `items` which includes the encryption key and field pattern specifications.\n\n### Encryption Entities\n\n* `public_key_id` - (Required) The public key associated with a set of field-level encryption patterns, to be used when encrypting the fields that match the patterns.\n* `provider_id` - (Required) The provider associated with the public key being used for encryption.\n* `field_patterns` - (Required) Object that contains an attribute `items` that contains the list of field patterns in a field-level encryption content type profile specify the fields that you want to be encrypted.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `caller_reference` - Internal value used by CloudFront to allow future updates to the Field Level Encryption Profile.\n* `etag` - The current version of the Field Level Encryption Profile. For example: `E2QWRUHAPOMQZL`.\n* `id` - The identifier for the Field Level Encryption Profile. For example: `K3D5EWEUDCCXON`.\n\n## Import\n\nCloudfront Field Level Encryption Profile can be imported using the `id`, e.g.\n\n```\n$ terraform import aws_cloudfront_field_level_encryption_profile.profile K3D5EWEUDCCXON\n```",
    "basename": "cloudfront_field_level_encryption_profile.html"
  },
  "cloudfront_function.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_function",
    "description": "Provides a CloudFront Function resource. With CloudFront Functions in Amazon CloudFront, you can write lightweight functions in JavaScript for high-scale, latency-sensitive CDN customizations.",
    "preview": "# Resource: aws_cloudfront_function\n\nProvides a CloudFront Function …",
    "content": "\n\n# Resource: aws_cloudfront_function\n\nProvides a CloudFront Function resource. With CloudFront Functions in Amazon CloudFront, you can write lightweight functions in JavaScript for high-scale, latency-sensitive CDN customizations.\n\nSee [CloudFront Functions](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cloudfront-functions.html)\n\n~> **NOTE:** You cannot delete a function if it’s associated with a cache behavior. First, update your distributions to remove the function association from all cache behaviors, then delete the function.\n\n## Example Usage\n\n### Basic Example\n\n```terraform\nresource \"aws_cloudfront_function\" \"test\" {\n  name    = \"test\"\n  runtime = \"cloudfront-js-1.0\"\n  comment = \"my function\"\n  publish = true\n  code    = file(\"${path.module}/function.js\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Unique name for your CloudFront Function.\n* `code` - (Required) Source code of the function\n* `runtime` - (Required) Identifier of the function's runtime. Currently only `cloudfront-js-1.0` is valid.\n\nThe following arguments are optional:\n\n* `comment` - (Optional) Comment.\n* `publish` - (Optional) Whether to publish creation/change as Live CloudFront Function Version. Defaults to `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) identifying your CloudFront Function.\n* `etag` - ETag hash of the function. This is the value for the `DEVELOPMENT` stage of the function.\n* `live_stage_etag` - ETag hash of any `LIVE` stage of the function.\n* `status` - Status of the function. Can be `UNPUBLISHED`, `UNASSOCIATED` or `ASSOCIATED`.\n\n## Import\n\nCloudFront Functions can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_cloudfront_function.test my_test_function\n```\n",
    "basename": "cloudfront_function.html"
  },
  "cloudfront_key_group.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_key_group",
    "description": "Provides a CloudFront key group.",
    "preview": "# Resource: aws_cloudfront_key_group\n\n## Example Usage\n\nThe …",
    "content": "\n\n# Resource: aws_cloudfront_key_group\n\n## Example Usage\n\nThe following example below creates a CloudFront key group.\n\n```terraform\nresource \"aws_cloudfront_public_key\" \"example\" {\n  comment     = \"example public key\"\n  encoded_key = file(\"public_key.pem\")\n  name        = \"example-key\"\n}\n\nresource \"aws_cloudfront_key_group\" \"example\" {\n  comment = \"example key group\"\n  items   = [aws_cloudfront_public_key.example.id]\n  name    = \"example-key-group\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `comment` - (Optional) A comment to describe the key group..\n* `items` - (Required) A list of the identifiers of the public keys in the key group.\n* `name` - (Required) A name to identify the key group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `etag` - The identifier for this version of the key group.\n* `id` - The identifier for the key group.\n\n## Import\n\nCloudFront Key Group can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_cloudfront_key_group.example 4b4f2r1c-315d-5c2e-f093-216t50jed10f\n```\n",
    "basename": "cloudfront_key_group.html"
  },
  "cloudfront_monitoring_subscription.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_monitoring_subscription",
    "description": "Provides a CloudFront monitoring subscription resource.",
    "preview": "# Resource: aws_cloudfront_monitoring_subscription\n\nProvides a …",
    "content": "\n\n# Resource: aws_cloudfront_monitoring_subscription\n\nProvides a CloudFront real-time log configuration resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudfront_monitoring_subscription\" \"example\" {\n  distribution_id = aws_cloudfront_distribution.example.id\n\n  monitoring_subscription {\n    realtime_metrics_subscription_config {\n      realtime_metrics_subscription_status = \"Enabled\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `distribution_id` - (Required) The ID of the distribution that you are enabling metrics for.\n* `monitoring_subscription` - (Required) A monitoring subscription. This structure contains information about whether additional CloudWatch metrics are enabled for a given CloudFront distribution.\n\n### monitoring_subscription\n\n* `realtime_metrics_subscription_config` - (Required) A subscription configuration for additional CloudWatch metrics. See below.\n\n### realtime_metrics_subscription_config\n\n* `realtime_metrics_subscription_status` - (Required) A flag that indicates whether additional CloudWatch metrics are enabled for a given CloudFront distribution. Valid values are `Enabled` and `Disabled`. See below.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the CloudFront monitoring subscription, which corresponds to the `distribution_id`.\n\n## Import\n\nCloudFront monitoring subscription can be imported using the id, e.g.,\n\n```\n$ terraform import aws_cloudfront_monitoring_subscription.example E3QYSUHO4VYRGB\n```\n",
    "basename": "cloudfront_monitoring_subscription.html"
  },
  "cloudfront_origin_access_identity.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_origin_access_identity",
    "description": "Provides a CloudFront origin access identity.",
    "preview": "# Resource: aws_cloudfront_origin_access_identity\n\nCreates an Amazon …",
    "content": "\n\n# Resource: aws_cloudfront_origin_access_identity\n\nCreates an Amazon CloudFront origin access identity.\n\nFor information about CloudFront distributions, see the\n[Amazon CloudFront Developer Guide][1]. For more information on generating\norigin access identities, see\n[Using an Origin Access Identity to Restrict Access to Your Amazon S3 Content][2].\n\n## Example Usage\n\nThe following example below creates a CloudFront origin access identity.\n\n```terraform\nresource \"aws_cloudfront_origin_access_identity\" \"example\" {\n  comment = \"Some comment\"\n}\n```\n\n## Argument Reference\n\n* `comment` (Optional) - An optional comment for the origin access identity.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identifier for the distribution. For example: `EDFDVBD632BHDS5`.\n* `caller_reference` - Internal value used by CloudFront to allow future\n   updates to the origin access identity.\n* `cloudfront_access_identity_path` - A shortcut to the full path for the\n   origin access identity to use in CloudFront, see below.\n* `etag` - The current version of the origin access identity's information.\n   For example: `E2QWRUHAPOMQZL`.\n* `iam_arn` - A pre-generated ARN for use in S3 bucket policies (see below).\n   Example: `arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity\n   E2QWRUHAPOMQZL`.\n* `s3_canonical_user_id` - The Amazon S3 canonical user ID for the origin\n   access identity, which you use when giving the origin access identity read\n   permission to an object in Amazon S3.\n\n## Using With CloudFront\n\nNormally, when referencing an origin access identity in CloudFront, you need to\nprefix the ID with the `origin-access-identity/cloudfront/` special path.\nThe `cloudfront_access_identity_path` allows this to be circumvented.\nThe below snippet demonstrates use with the `s3_origin_config` structure for the\n[`aws_cloudfront_distribution`][3] resource:\n\n```terraform\nresource \"aws_cloudfront_distribution\" \"example\" {\n  # ... other configuration ...\n\n  origin {\n    s3_origin_config {\n      origin_access_identity = aws_cloudfront_origin_access_identity.example.cloudfront_access_identity_path\n    }\n  }\n}\n```\n\n### Updating your bucket policy\n\nNote that the AWS API may translate the `s3_canonical_user_id` `CanonicalUser`\nprincipal into an `AWS` IAM ARN principal when supplied in an\n[`aws_s3_bucket`][4] bucket policy, causing spurious diffs in Terraform. If\nyou see this behaviour, use the `iam_arn` instead:\n\n```terraform\ndata \"aws_iam_policy_document\" \"s3_policy\" {\n  statement {\n    actions   = [\"s3:GetObject\"]\n    resources = [\"${aws_s3_bucket.example.arn}/*\"]\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [aws_cloudfront_origin_access_identity.example.iam_arn]\n    }\n  }\n}\n\nresource \"aws_s3_bucket_policy\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n  policy = data.aws_iam_policy_document.s3_policy.json\n}\n```\n\n[1]: http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html\n[2]: http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html\n[3]: /docs/providers/aws/r/cloudfront_distribution.html\n[4]: /docs/providers/aws/r/s3_bucket.html\n\n\n## Import\n\nCloudfront Origin Access Identities can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_cloudfront_origin_access_identity.origin_access E74FTE3AEXAMPLE\n```\n",
    "basename": "cloudfront_origin_access_identity.html"
  },
  "cloudfront_origin_request_policy.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_origin_request_policy",
    "description": "Determines the values that CloudFront includes in requests that it sends to the origin.",
    "preview": "# Resource: aws_cloudfront_origin_request_policy\n\n## Example Usage\n …",
    "content": "\n\n# Resource: aws_cloudfront_origin_request_policy\n\n## Example Usage\n\nThe following example below creates a CloudFront origin request policy.\n\n```terraform\nresource \"aws_cloudfront_origin_request_policy\" \"example\" {\n  name    = \"example-policy\"\n  comment = \"example comment\"\n  cookies_config {\n    cookie_behavior = \"whitelist\"\n    cookies {\n      items = [\"example\"]\n    }\n  }\n  headers_config {\n    header_behavior = \"whitelist\"\n    headers {\n      items = [\"example\"]\n    }\n  }\n  query_strings_config {\n    query_string_behavior = \"whitelist\"\n    query_strings {\n      items = [\"example\"]\n    }\n  }\n}\n\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Unique name to identify the origin request policy.\n* `comment` - (Optional) Comment to describe the origin request policy.\n* `cookies_config` - (Required) Object that determines whether any cookies in viewer requests (and if so, which cookies) are included in the origin request key and automatically included in requests that CloudFront sends to the origin. See [Cookies Config](#cookies-config) for more information.\n* `headers_config` - (Required) Object that determines whether any HTTP headers (and if so, which headers) are included in the origin request key and automatically included in requests that CloudFront sends to the origin. See [Headers Config](#headers-config) for more information.\n* `query_strings_config` - (Required) Object that determines whether any URL query strings in viewer requests (and if so, which query strings) are included in the origin request key and automatically included in requests that CloudFront sends to the origin. See [Query Strings Config](#query-strings-config) for more information.\n\n### Cookies Config\n\n`cookie_behavior` - (Required) Determines whether any cookies in viewer requests are included in the origin request key and automatically included in requests that CloudFront sends to the origin. Valid values are `none`, `whitelist` `all`.\n`cookies` - (Optional) Object that contains a list of cookie names. See [Items](#items) for more information.\n\n### Headers Config\n\n`header_behavior` - (Required) Determines whether any HTTP headers are included in the origin request key and automatically included in requests that CloudFront sends to the origin. Valid values are `none`, `whitelist`, `allViewer`, `allViewerAndWhitelistCloudFront`.\n`headers` - (Optional) Object that contains a list of header names. See [Items](#items) for more information.\n\n### Query String Config\n\n`query_string_behavior` - (Required) Determines whether any URL query strings in viewer requests are included in the origin request key and automatically included in requests that CloudFront sends to the origin. Valid values are `none`, `whitelist`, `all`.\n`query_strings` - (Optional) Object that contains a list of query string names. See [Items](#items) for more information.\n\n### Items\n\n`items` - (Required) List of item names (cookies, headers, or query strings).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `etag` - The current version of the origin request policy.\n* `id` - The identifier for the origin request policy.\n",
    "basename": "cloudfront_origin_request_policy.html"
  },
  "cloudfront_public_key.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_public_key",
    "description": "Provides a CloudFront Public Key which you add to CloudFront to use with features like field-level encryption.",
    "preview": "# Resource: aws_cloudfront_public_key\n\n## Example Usage\n\nThe …",
    "content": "\n\n# Resource: aws_cloudfront_public_key\n\n## Example Usage\n\nThe following example below creates a CloudFront public key.\n\n```terraform\nresource \"aws_cloudfront_public_key\" \"example\" {\n  comment     = \"test public key\"\n  encoded_key = file(\"public_key.pem\")\n  name        = \"test_key\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `comment` - (Optional) An optional comment about the public key.\n* `encoded_key` - (Required) The encoded public key that you want to add to CloudFront to use with features like field-level encryption.\n* `name` - (Optional) The name for the public key. By default generated by Terraform.\n* `name_prefix` - (Optional) The name for the public key. Conflicts with `name`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `caller_reference` - Internal value used by CloudFront to allow future updates to the public key configuration.\n* `etag` - The current version of the public key. For example: `E2QWRUHAPOMQZL`.\n* `id` - The identifier for the public key. For example: `K3D5EWEUDCCXON`.\n\n## Import\n\nCloudFront Public Key can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_cloudfront_public_key.example K3D5EWEUDCCXON\n```\n",
    "basename": "cloudfront_public_key.html"
  },
  "cloudfront_realtime_log_config.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_realtime_log_config",
    "description": "Provides a CloudFront real-time log configuration resource.",
    "preview": "# Resource: aws_cloudfront_realtime_log_config\n\nProvides a …",
    "content": "\n\n# Resource: aws_cloudfront_realtime_log_config\n\nProvides a CloudFront real-time log configuration resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name = \"cloudfront-realtime-log-config-example\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"cloudfront.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"example\" {\n  name = \"cloudfront-realtime-log-config-example\"\n  role = aws_iam_role.example.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n          \"kinesis:DescribeStreamSummary\",\n          \"kinesis:DescribeStream\",\n          \"kinesis:PutRecord\",\n          \"kinesis:PutRecords\"\n        ],\n        \"Resource\": \"${aws_kinesis_stream.example.arn}\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_cloudfront_realtime_log_config\" \"example\" {\n  name          = \"example\"\n  sampling_rate = 75\n  fields        = [\"timestamp\", \"c-ip\"]\n\n  endpoint {\n    stream_type = \"Kinesis\"\n\n    kinesis_stream_config {\n      role_arn   = aws_iam_role.example.arn\n      stream_arn = aws_kinesis_stream.example.arn\n    }\n  }\n\n  depends_on = [aws_iam_role_policy.example]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `endpoint` - (Required) The Amazon Kinesis data streams where real-time log data is sent.\n* `fields` - (Required) The fields that are included in each real-time log record. See the [AWS documentation](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/real-time-logs.html#understand-real-time-log-config-fields) for supported values.\n* `name` - (Required) The unique name to identify this real-time log configuration.\n* `sampling_rate` - (Required) The sampling rate for this real-time log configuration. The sampling rate determines the percentage of viewer requests that are represented in the real-time log data. An integer between `1` and `100`, inclusive.\n\nThe `endpoint` object supports the following:\n\n* `kinesis_stream_config` - (Required) The Amazon Kinesis data stream configuration.\n* `stream_type` - (Required) The type of data stream where real-time log data is sent. The only valid value is `Kinesis`.\n\nThe `kinesis_stream_config` object supports the following:\n\n* `role_arn` - (Required) The ARN of an [IAM role](iam_role.html) that CloudFront can use to send real-time log data to the Kinesis data stream.\nSee the [AWS documentation](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/real-time-logs.html#understand-real-time-log-config-iam-role) for more information.\n* `stream_arn` - (Required) The ARN of the [Kinesis data stream](kinesis_stream.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the CloudFront real-time log configuration.\n* `arn` - The ARN (Amazon Resource Name) of the CloudFront real-time log configuration.\n\n## Import\n\nCloudFront real-time log configurations can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_cloudfront_realtime_log_config.example arn:aws:cloudfront::111122223333:realtime-log-config/ExampleNameForRealtimeLogConfig\n```\n",
    "basename": "cloudfront_realtime_log_config.html"
  },
  "cloudfront_response_headers_policy.html": {
    "subcategory": "CloudFront",
    "layout": "aws",
    "page_title": "AWS: aws_cloudfront_response_headers_policy",
    "description": "Provides a CloudFront response headers policy resource.",
    "preview": "# Resource: aws_cloudfront_response_headers_policy\n\nProvides a …",
    "content": "\n\n# Resource: aws_cloudfront_response_headers_policy\n\nProvides a CloudFront response headers policy resource.\nA response headers policy contains information about a set of HTTP response headers and their values.\nAfter you create a response headers policy, you can use its ID to attach it to one or more cache behaviors in a CloudFront distribution.\nWhen it’s attached to a cache behavior, CloudFront adds the headers in the policy to every response that it sends for requests that match the cache behavior.\n\n## Example Usage\n\nThe example below creates a CloudFront response headers policy.\n\n```terraform\nresource \"aws_cloudfront_response_headers_policy\" \"example\" {\n  name    = \"example-policy\"\n  comment = \"test comment\"\n\n  cors_config {\n    access_control_allow_credentials = true\n\n    access_control_allow_headers {\n      items = [\"test\"]\n    }\n\n    access_control_allow_methods {\n      items = [\"GET\"]\n    }\n\n    access_control_allow_origins {\n      items = [\"test.example.comtest\"]\n    }\n\n    origin_override = true\n  }\n}\n```\n\nThe example below creates a CloudFront response headers policy with a custom headers config.\n\n```terraform\nresource \"aws_cloudfront_response_headers_policy\" \"example\" {\n  name = \"example-headers-policy\"\n\n  custom_headers_config {\n    items {\n      header   = \"X-Permitted-Cross-Domain-Policies\"\n      override = true\n      value    = \"none\"\n    }\n\n    items {\n      header   = \"X-Test\"\n      override = true\n      value    = \"none\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A unique name to identify the response headers policy.\n* `comment` - (Optional) A comment to describe the response headers policy. The comment cannot be longer than 128 characters.\n* `cors_config` - (Optional) A configuration for a set of HTTP response headers that are used for Cross-Origin Resource Sharing (CORS). See [Cors Config](#cors_config) for more information.\n* `custom_headers_config` - (Optional) Object that contains an attribute `items` that contains a list of custom headers. See [Custom Header](#custom_header) for more information.\n* `security_headers_config` - (Optional) A configuration for a set of security-related HTTP response headers. See [Security Headers Config](#security_headers_config) for more information.\n\n### Cors Config\n\n* `access_control_allow_credentials` - (Required) A Boolean value that CloudFront uses as the value for the `Access-Control-Allow-Credentials` HTTP response header.\n* `access_control_allow_headers` - (Required) Object that contains an attribute `items` that contains a list of HTTP header names that CloudFront includes as values for the `Access-Control-Allow-Headers` HTTP response header.\n* `access_control_allow_methods` - (Required) Object that contains an attribute `items` that contains a list of HTTP methods that CloudFront includes as values for the `Access-Control-Allow-Methods` HTTP response header. Valid values: `GET` | `POST` | `OPTIONS` | `PUT` | `DELETE` | `HEAD` | `ALL`\n* `access_control_allow_origins` - (Optional) Object that contains an attribute `items` that contains a list of origins that CloudFront can use as the value for the `Access-Control-Allow-Origin` HTTP response header.\n* `access_control_expose_headers` - (Optional) Object that contains an attribute `items` that contains a list of HTTP headers that CloudFront includes as values for the `Access-Control-Expose-Headers` HTTP response header.\n* `access_control_max_age_sec` - (Required) A number that CloudFront uses as the value for the `Access-Control-Max-Age` HTTP response header.\n\n### Custom Header\n\n* `header` - (Required) The HTTP response header name.\n* `override` - (Required) A Boolean value that determines whether CloudFront overrides a response header with the same name received from the origin with the header specifies here.\n* `value` - (Required) The value for the HTTP response header.\n\n### Security Headers Config\n\n* `content_security_policy` - (Optional) The policy directives and their values that CloudFront includes as values for the `Content-Security-Policy` HTTP response header. See [Content Security Policy](#content_security_policy) for more information.\n* `content_type_options` - (Optional) Determines whether CloudFront includes the `X-Content-Type-Options` HTTP response header with its value set to `nosniff`. See [Content Type Options](#content_type_options) for more information.\n* `frame_options` - (Optional) Determines whether CloudFront includes the `X-Frame-Options` HTTP response header and the header’s value. See [Frame Options](#frame_options) for more information.\n* `referrer_policy` - (Optional) Determines whether CloudFront includes the `Referrer-Policy` HTTP response header and the header’s value. See [Referrer Policy](#referrer_policy) for more information.\n* `strict_transport_security` - (Optional) Determines whether CloudFront includes the `Strict-Transport-Security` HTTP response header and the header’s value. See [Strict Transport Security](#strict_transport_security) for more information.\n* `xss_protection` - (Optional) Determine whether CloudFront includes the `X-XSS-Protection` HTTP response header and the header’s value. See [XSS Protection](#xss_protection) for more information.\n\n### Content Security Policy\n\n* `content_security_policy` - (Required) The policy directives and their values that CloudFront includes as values for the `Content-Security-Policy` HTTP response header.\n* `override` - (Required) A Boolean value that determines whether CloudFront overrides the `Content-Security-Policy` HTTP response header received from the origin with the one specified in this response headers policy.\n\n### Content Type Options\n\n* `override` - (Required) A Boolean value that determines whether CloudFront overrides the `X-Content-Type-Options` HTTP response header received from the origin with the one specified in this response headers policy.\n\n### Frame Options\n\n* `frame_option` - (Required) The value of the `X-Frame-Options` HTTP response header. Valid values: `DENY` | `SAMEORIGIN`\n* `override` - (Required) A Boolean value that determines whether CloudFront overrides the `X-Frame-Options` HTTP response header received from the origin with the one specified in this response headers policy.\n\n### Referrer Policy\n\n* `referrer_policy` - (Required) The value of the `Referrer-Policy` HTTP response header. Valid Values: `no-referrer` | `no-referrer-when-downgrade` | `origin` | `origin-when-cross-origin` | `same-origin` | `strict-origin` | `strict-origin-when-cross-origin` | `unsafe-url`\n* `override` - (Required) A Boolean value that determines whether CloudFront overrides the `Referrer-Policy` HTTP response header received from the origin with the one specified in this response headers policy.\n\n### Strict Transport Security\n\n* `access_control_max_age_sec` - (Required) A number that CloudFront uses as the value for the `max-age` directive in the `Strict-Transport-Security` HTTP response header.\n* `include_subdomains` - (Optional) A Boolean value that determines whether CloudFront includes the `includeSubDomains` directive in the `Strict-Transport-Security` HTTP response header.\n* `override` - (Required) A Boolean value that determines whether CloudFront overrides the `Strict-Transport-Security` HTTP response header received from the origin with the one specified in this response headers policy.\n* `preload` - (Optional) A Boolean value that determines whether CloudFront includes the `preload` directive in the `Strict-Transport-Security` HTTP response header.\n\n### XSS Protection\n\n* `mode_block` - (Required) A Boolean value that determines whether CloudFront includes the `mode=block` directive in the `X-XSS-Protection` header.\n* `override` - (Required) A Boolean value that determines whether CloudFront overrides the `X-XSS-Protection` HTTP response header received from the origin with the one specified in this response headers policy.\n* `protection` - (Required) A Boolean value that determines the value of the `X-XSS-Protection` HTTP response header. When this setting is `true`, the value of the `X-XSS-Protection` header is `1`. When this setting is `false`, the value of the `X-XSS-Protection` header is `0`.\n* `report_uri` - (Optional) A reporting URI, which CloudFront uses as the value of the report directive in the `X-XSS-Protection` header. You cannot specify a `report_uri` when `mode_block` is `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `etag` - The current version of the response headers policy.\n* `id` - The identifier for the response headers policy.\n\n## Import\n\nCloudfront Response Headers Policies can be imported using the `id`, e.g.\n\n```\n$ terraform import aws_cloudfront_response_headers_policy.policy 658327ea-f89d-4fab-a63d-7e88639e58f9\n```\n",
    "basename": "cloudfront_response_headers_policy.html"
  },
  "cloudhsm_v2_cluster.html": {
    "subcategory": "CloudHSM v2",
    "layout": "aws",
    "page_title": "AWS: aws_cloudhsm_v2_cluster",
    "description": "Provides a CloudHSM v2 resource.",
    "preview": "# Resource: aws_cloudhsm_v2_cluster\n\nCreates an Amazon CloudHSM v2 …",
    "content": "\n\n# Resource: aws_cloudhsm_v2_cluster\n\nCreates an Amazon CloudHSM v2 cluster.\n\nFor information about CloudHSM v2, see the\n[AWS CloudHSM User Guide][1] and the [Amazon\nCloudHSM API Reference][2].\n\n~> **NOTE:** A CloudHSM Cluster can take several minutes to set up.\nPractically no single attribute can be updated, except for `tags`.\nIf you need to delete a cluster, you have to remove its HSM modules first.\nTo initialize cluster, you have to add an HSM instance to the cluster, then sign CSR and upload it.\n\n## Example Usage\n\nThe following example below creates a CloudHSM cluster.\n\n```terraform\nprovider \"aws\" {\n  region = var.aws_region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nresource \"aws_vpc\" \"cloudhsm_v2_vpc\" {\n  cidr_block = \"10.0.0.0/16\"\n\n  tags = {\n    Name = \"example-aws_cloudhsm_v2_cluster\"\n  }\n}\n\nresource \"aws_subnet\" \"cloudhsm_v2_subnets\" {\n  count                   = 2\n  vpc_id                  = aws_vpc.cloudhsm_v2_vpc.id\n  cidr_block              = element(var.subnets, count.index)\n  map_public_ip_on_launch = false\n  availability_zone       = element(data.aws_availability_zones.available.names, count.index)\n\n  tags = {\n    Name = \"example-aws_cloudhsm_v2_cluster\"\n  }\n}\n\nresource \"aws_cloudhsm_v2_cluster\" \"cloudhsm_v2_cluster\" {\n  hsm_type   = \"hsm1.medium\"\n  subnet_ids = aws_subnet.cloudhsm_v2_subnets.*.id\n\n  tags = {\n    Name = \"example-aws_cloudhsm_v2_cluster\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `source_backup_identifier` - (Optional) The id of Cloud HSM v2 cluster backup to be restored.\n* `hsm_type` - (Required) The type of HSM module in the cluster. Currently, only `hsm1.medium` is supported.\n* `subnet_ids` - (Required) The IDs of subnets in which cluster will operate.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `cluster_id` - The id of the CloudHSM cluster.\n* `cluster_state` - The state of the CloudHSM cluster.\n* `vpc_id` - The id of the VPC that the CloudHSM cluster resides in.\n* `security_group_id` - The ID of the security group associated with the CloudHSM cluster.\n* `cluster_certificates` - The list of cluster certificates.\n    * `cluster_certificates.0.cluster_certificate` - The cluster certificate issued (signed) by the issuing certificate authority (CA) of the cluster's owner.\n    * `cluster_certificates.0.cluster_csr` - The certificate signing request (CSR). Available only in `UNINITIALIZED` state after an HSM instance is added to the cluster.\n    * `cluster_certificates.0.aws_hardware_certificate` - The HSM hardware certificate issued (signed) by AWS CloudHSM.\n    * `cluster_certificates.0.hsm_certificate` - The HSM certificate issued (signed) by the HSM hardware.\n    * `cluster_certificates.0.manufacturer_hardware_certificate` - The HSM hardware certificate issued (signed) by the hardware manufacturer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[1]: https://docs.aws.amazon.com/cloudhsm/latest/userguide/introduction.html\n[2]: https://docs.aws.amazon.com/cloudhsm/latest/APIReference/Welcome.html\n\n## Import\n\nCloudHSM v2 Clusters can be imported using the `cluster id`, e.g.,\n\n```\n$ terraform import aws_cloudhsm_v2_cluster.test_cluster cluster-aeb282a201\n```\n",
    "basename": "cloudhsm_v2_cluster.html"
  },
  "cloudhsm_v2_hsm.html": {
    "subcategory": "CloudHSM v2",
    "layout": "aws",
    "page_title": "AWS: aws_cloudhsm_v2_hsm",
    "description": "Provides a CloudHSM v2 HSM module resource.",
    "preview": "# Resource: aws_cloudhsm_v2_hsm\n\nCreates an HSM module in Amazon …",
    "content": "\n\n# Resource: aws_cloudhsm_v2_hsm\n\nCreates an HSM module in Amazon CloudHSM v2 cluster.\n\n## Example Usage\n\nThe following example below creates an HSM module in CloudHSM cluster.\n\n```terraform\ndata \"aws_cloudhsm_v2_cluster\" \"cluster\" {\n  cluster_id = var.cloudhsm_cluster_id\n}\n\nresource \"aws_cloudhsm_v2_hsm\" \"cloudhsm_v2_hsm\" {\n  subnet_id  = data.aws_cloudhsm_v2_cluster.cluster.subnet_ids[0]\n  cluster_id = data.aws_cloudhsm_v2_cluster.cluster.cluster_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_id` - (Required) The ID of Cloud HSM v2 cluster to which HSM will be added.\n* `subnet_id` - (Optional) The ID of subnet in which HSM module will be located.\n* `availability_zone` - (Optional) The IDs of AZ in which HSM module will be located. Do not use together with subnet_id.\n* `ip_address` - (Optional) The IP address of HSM module. Must be within the CIDR of selected subnet.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `hsm_id` - The id of the HSM module.\n* `hsm_state` - The state of the HSM module.\n* `hsm_eni_id` - The id of the ENI interface allocated for HSM module.\n\n## Import\n\nHSM modules can be imported using their HSM ID, e.g.,\n\n```\n$ terraform import aws_cloudhsm_v2_hsm.bar hsm-quo8dahtaca\n```\n",
    "basename": "cloudhsm_v2_hsm.html"
  },
  "cloudtrail.html": {
    "subcategory": "CloudTrail",
    "layout": "aws",
    "page_title": "AWS: aws_cloudtrail",
    "description": "Provides a CloudTrail resource.",
    "preview": "# Resource: aws_cloudtrail\n\nProvides a CloudTrail resource.\n\n-> …",
    "content": "\n\n# Resource: aws_cloudtrail\n\nProvides a CloudTrail resource.\n\n-> **Tip:** For a multi-region trail, this resource must be in the home region of the trail.\n\n-> **Tip:** For an organization trail, this resource must be in the master account of the organization.\n\n## Example Usage\n\n### Basic\n\nEnable CloudTrail to capture all compatible management events in region.\nFor capturing events from services like IAM, `include_global_service_events` must be enabled.\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_cloudtrail\" \"foobar\" {\n  name                          = \"tf-trail-foobar\"\n  s3_bucket_name                = aws_s3_bucket.foo.id\n  s3_key_prefix                 = \"prefix\"\n  include_global_service_events = false\n}\n\nresource \"aws_s3_bucket\" \"foo\" {\n  bucket        = \"tf-test-trail\"\n  force_destroy = true\n\n  policy = <<POLICY\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSCloudTrailAclCheck\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n              \"Service\": \"cloudtrail.amazonaws.com\"\n            },\n            \"Action\": \"s3:GetBucketAcl\",\n            \"Resource\": \"arn:aws:s3:::tf-test-trail\"\n        },\n        {\n            \"Sid\": \"AWSCloudTrailWrite\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n              \"Service\": \"cloudtrail.amazonaws.com\"\n            },\n            \"Action\": \"s3:PutObject\",\n            \"Resource\": \"arn:aws:s3:::tf-test-trail/prefix/AWSLogs/${data.aws_caller_identity.current.account_id}/*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"s3:x-amz-acl\": \"bucket-owner-full-control\"\n                }\n            }\n        }\n    ]\n}\nPOLICY\n}\n```\n\n### Data Event Logging\n\nCloudTrail can log [Data Events](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-with-cloudtrail.html) for certain services such as S3 bucket objects and Lambda function invocations. Additional information about data event configuration can be found in the following links:\n\n* [CloudTrail API DataResource documentation](https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/API_DataResource.html) (for basic event selector).\n* [CloudTrail API AdvancedFieldSelector documentation](https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/API_AdvancedFieldSelector.html) (for advanced event selector).\n\n#### Logging All Lambda Function Invocations By Using Basic Event Selectors\n\n```terraform\nresource \"aws_cloudtrail\" \"example\" {\n  # ... other configuration ...\n\n  event_selector {\n    read_write_type           = \"All\"\n    include_management_events = true\n\n    data_resource {\n      type   = \"AWS::Lambda::Function\"\n      values = [\"arn:aws:lambda\"]\n    }\n  }\n}\n```\n\n#### Logging All S3 Bucket Object Events By Using Basic Event Selectors\n\n```terraform\nresource \"aws_cloudtrail\" \"example\" {\n  # ... other configuration ...\n\n  event_selector {\n    read_write_type           = \"All\"\n    include_management_events = true\n\n    data_resource {\n      type   = \"AWS::S3::Object\"\n      values = [\"arn:aws:s3:::\"]\n    }\n  }\n}\n```\n\n#### Logging Individual S3 Bucket Events By Using Basic Event Selectors\n\n```terraform\ndata \"aws_s3_bucket\" \"important-bucket\" {\n  bucket = \"important-bucket\"\n}\n\nresource \"aws_cloudtrail\" \"example\" {\n  # ... other configuration ...\n\n  event_selector {\n    read_write_type           = \"All\"\n    include_management_events = true\n\n    data_resource {\n      type = \"AWS::S3::Object\"\n\n      # Make sure to append a trailing '/' to your ARN if you want\n      # to monitor all objects in a bucket.\n      values = [\"${data.aws_s3_bucket.important-bucket.arn}/\"]\n    }\n  }\n}\n```\n\n#### Logging All S3 Bucket Object Events Except For Two S3 Buckets By Using Advanced Event Selectors\n\n```terraform\ndata \"aws_s3_bucket\" \"not-important-bucket-1\" {\n  bucket = \"not-important-bucket-1\"\n}\n\ndata \"aws_s3_bucket\" \"not-important-bucket-2\" {\n  bucket = \"not-important-bucket-2\"\n}\n\nresource \"aws_cloudtrail\" \"example\" {\n  # ... other configuration ...\n\n  advanced_event_selector {\n    name = \"Log all S3 buckets objects events except for two S3 buckets\"\n\n    field_selector {\n      field  = \"eventCategory\"\n      equals = [\"Data\"]\n    }\n\n    field_selector {\n      field = \"resources.ARN\"\n\n      not_equals = [\n        \"${data.aws_s3_bucket.not-important-bucket-1.arn}/\",\n        \"${data.aws_s3_bucket.not-important-bucket-2.arn}/\"\n      ]\n    }\n\n    field_selector {\n      field  = \"resources.type\"\n      equals = [\"AWS::S3::Object\"]\n    }\n  }\n\n  advanced_event_selector {\n    name = \"Log readOnly and writeOnly management events\"\n\n    field_selector {\n      field  = \"eventCategory\"\n      equals = [\"Management\"]\n    }\n  }\n}\n```\n\n#### Logging Individual S3 Buckets And Specific Event Names By Using Advanced Event Selectors\n\n```terraform\ndata \"aws_s3_bucket\" \"important-bucket-1\" {\n  bucket = \"important-bucket-1\"\n}\n\ndata \"aws_s3_bucket\" \"important-bucket-2\" {\n  bucket = \"important-bucket-2\"\n}\n\ndata \"aws_s3_bucket\" \"important-bucket-3\" {\n  bucket = \"important-bucket-3\"\n}\n\nresource \"aws_cloudtrail\" \"example\" {\n  # ... other configuration ...\n\n  advanced_event_selector {\n    name = \"Log PutObject and DeleteObject events for two S3 buckets\"\n\n    field_selector {\n      field  = \"eventCategory\"\n      equals = [\"Data\"]\n    }\n\n    field_selector {\n      field = \"eventName\"\n\n      equals = [\n        \"PutObject\",\n        \"DeleteObject\"\n      ]\n    }\n\n    field_selector {\n      field = \"resources.ARN\"\n\n      #The trailing slash is intentional; do not exclude it.\n      equals = [\n        \"${data.aws_s3_bucket.important-bucket-1.arn}/\",\n        \"${data.aws_s3_bucket.important-bucket-2.arn}/\"\n      ]\n    }\n\n    field_selector {\n      field  = \"readOnly\"\n      equals = [\"false\"]\n    }\n\n    field_selector {\n      field  = \"resources.type\"\n      equals = [\"AWS::S3::Object\"]\n    }\n  }\n\n  advanced_event_selector {\n    name = \"Log Delete* events for one S3 bucket\"\n\n    field_selector {\n      field  = \"eventCategory\"\n      equals = [\"Data\"]\n    }\n\n    field_selector {\n      field       = \"eventName\"\n      starts_with = [\"Delete\"]\n    }\n\n    field_selector {\n      field = \"resources.ARN\"\n\n      #The trailing slash is intentional; do not exclude it.\n      equals = [\n        \"${data.aws_s3_bucket.important-bucket-3.arn}/important-prefix\"\n      ]\n    }\n\n    field_selector {\n      field  = \"readOnly\"\n      equals = [\"false\"]\n    }\n\n    field_selector {\n      field  = \"resources.type\"\n      equals = [\"AWS::S3::Object\"]\n    }\n  }\n}\n```\n\n#### Sending Events to CloudWatch Logs\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name = \"Example\"\n}\n\nresource \"aws_cloudtrail\" \"example\" {\n  # ... other configuration ...\n\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\" # CloudTrail requires the Log Stream wildcard\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the trail.\n* `s3_bucket_name` - (Required) Name of the S3 bucket designated for publishing log files.\n\nThe following arguments are optional:\n\n* `cloud_watch_logs_group_arn` - (Optional) Log group name using an ARN that represents the log group to which CloudTrail logs will be delivered. Note that CloudTrail requires the Log Stream wildcard.\n* `cloud_watch_logs_role_arn` - (Optional) Role for the CloudWatch Logs endpoint to assume to write to a user’s log group.\n* `enable_log_file_validation` - (Optional) Whether log file integrity validation is enabled. Defaults to `false`.\n* `enable_logging` - (Optional) Enables logging for the trail. Defaults to `true`. Setting this to `false` will pause logging.\n* `event_selector` - (Optional) Specifies an event selector for enabling data event logging. Fields documented below. Please note the [CloudTrail limits](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/WhatIsCloudTrail-Limits.html) when configuring these. Conflicts with `advanced_event_selector`.\n* `advanced_event_selector` - (Optional) Specifies an advanced event selector for enabling data event logging. Fields documented below. Conflicts with `event_selector`.\n* `include_global_service_events` - (Optional) Whether the trail is publishing events from global services such as IAM to the log files. Defaults to `true`.\n* `insight_selector` - (Optional) Configuration block for identifying unusual operational activity. See details below.\n* `is_multi_region_trail` - (Optional) Whether the trail is created in the current region or in all regions. Defaults to `false`.\n* `is_organization_trail` - (Optional) Whether the trail is an AWS Organizations trail. Organization trails log events for the master account and all member accounts. Can only be created in the organization master account. Defaults to `false`.\n* `kms_key_id` - (Optional) KMS key ARN to use to encrypt the logs delivered by CloudTrail.\n* `s3_key_prefix` - (Optional) S3 key prefix that follows the name of the bucket you have designated for log file delivery.\n* `sns_topic_name` - (Optional) Name of the Amazon SNS topic defined for notification of log file delivery.\n* `tags` - (Optional) Map of tags to assign to the trail. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### event_selector\n\nThis configuration block supports the following attributes:\n\n* `data_resource` - (Optional) Configuration block for data events. See details below.\n* `exclude_management_event_sources` (Optional) -  A set of event sources to exclude. Valid values include: `kms.amazonaws.com` and `rdsdata.amazonaws.com`. `include_management_events` must be set to`true` to allow this.\n* `include_management_events` - (Optional) Whether to include management events for your trail. Defaults to `true`.\n* `read_write_type` - (Optional) Type of events to log. Valid values are `ReadOnly`, `WriteOnly`, `All`. Default value is `All`.\n\n#### data_resource\n\nThis configuration block supports the following attributes:\n\n* `type` - (Required) Resource type in which you want to log data events. You can specify only the following value: \"AWS::S3::Object\", \"AWS::Lambda::Function\" and \"AWS::DynamoDB::Table\".\n* `values` - (Required) List of ARN strings or partial ARN strings to specify selectors for data audit events over data resources. ARN list is specific to single-valued `type`. For example, `arn:aws:s3:::<bucket name>/` for all objects in a bucket, `arn:aws:s3:::<bucket name>/key` for specific objects, `arn:aws:lambda` for all lambda events within an account, `arn:aws:lambda:<region>:<account number>:function:<function name>` for a specific Lambda function, `arn:aws:dynamodb` for all DDB events for all tables within an account, or `arn:aws:dynamodb:<region>:<account number>:table/<table name>` for a specific DynamoDB table.\n\n\n### insight_selector\n\nThis configuration block supports the following attributes:\n\n* `insight_type` - (Optional) Type of insights to log on a trail. The valid value is `ApiCallRateInsight`.\n\n### Advanced Event Selector Arguments\nFor **advanced_event_selector** the following attributes are supported.\n\n* `name` (Optional) - Specifies the name of the advanced event selector.\n* `field_selector` (Required) - Specifies the selector statements in an advanced event selector. Fields documented below.\n\n#### Field Selector Arguments\nFor **field_selector** the following attributes are supported.\n\n* `field` (Required) - Specifies a field in an event record on which to filter events to be logged. You can specify only the following values: `readOnly`, `eventSource`, `eventName`, `eventCategory`, `resources.type`, `resources.ARN`.\n* `equals` (Optional) - A list of values that includes events that match the exact value of the event record field specified as the value of `field`. This is the only valid operator that you can use with the `readOnly`, `eventCategory`, and `resources.type` fields.\n* `not_equals` (Optional) - A list of values that excludes events that match the exact value of the event record field specified as the value of `field`.\n* `starts_with` (Optional) - A list of values that includes events that match the first few characters of the event record field specified as the value of `field`.\n* `not_starts_with` (Optional) - A list of values that excludes events that match the first few characters of the event record field specified as the value of `field`.\n* `ends_with` (Optional) - A list of values that includes events that match the last few characters of the event record field specified as the value of `field`.\n* `not_ends_with` (Optional) - A list of values that excludes events that match the last few characters of the event record field specified as the value of `field`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the trail.\n* `home_region` - Region in which the trail was created.\n* `id` - Name of the trail.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCloudtrails can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_cloudtrail.sample my-sample-trail\n```\n",
    "basename": "cloudtrail.html"
  },
  "cloudwatch_composite_alarm.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_composite_alarm",
    "description": "Provides a CloudWatch Composite Alarm resource.",
    "preview": "# Resource: aws_cloudwatch_composite_alarm\n\nProvides a CloudWatch …",
    "content": "\n\n# Resource: aws_cloudwatch_composite_alarm\n\nProvides a CloudWatch Composite Alarm resource.\n\n~> **NOTE:** An alarm (composite or metric) cannot be destroyed when there are other composite alarms depending on it. This can lead to a cyclical dependency on update, as Terraform will unsuccessfully attempt to destroy alarms before updating the rule. Consider using `depends_on`, references to alarm names, and two-stage updates.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_composite_alarm\" \"example\" {\n  alarm_description = \"This is a composite alarm!\"\n  alarm_name        = \"example-composite-alarm\"\n\n  alarm_actions = aws_sns_topic.example.arn\n  ok_actions    = aws_sns_topic.example.arn\n\n  alarm_rule = <<EOF\nALARM(${aws_cloudwatch_metric_alarm.alpha.alarm_name}) OR\nALARM(${aws_cloudwatch_metric_alarm.bravo.alarm_name})\nEOF\n}\n```\n\n## Argument Reference\n\n* `actions_enabled` - (Optional, Forces new resource) Indicates whether actions should be executed during any changes to the alarm state of the composite alarm. Defaults to `true`.\n* `alarm_actions` - (Optional) The set of actions to execute when this alarm transitions to the `ALARM` state from any other state. Each action is specified as an ARN. Up to 5 actions are allowed.\n* `alarm_description` - (Optional) The description for the composite alarm.\n* `alarm_name` - (Required) The name for the composite alarm. This name must be unique within the region.\n* `alarm_rule` - (Required) An expression that specifies which other alarms are to be evaluated to determine this composite alarm's state. For syntax, see [Creating a Composite Alarm](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Create_Composite_Alarm.html). The maximum length is 10240 characters.\n* `insufficient_data_actions` - (Optional) The set of actions to execute when this alarm transitions to the `INSUFFICIENT_DATA` state from any other state. Each action is specified as an ARN. Up to 5 actions are allowed.\n* `ok_actions` - (Optional) The set of actions to execute when this alarm transitions to an `OK` state from any other state. Each action is specified as an ARN. Up to 5 actions are allowed.\n* `tags` - (Optional) A map of tags to associate with the alarm. Up to 50 tags are allowed. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the composite alarm.\n* `id` - The ID of the composite alarm resource, which is equivalent to its `alarm_name`.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nUse the `alarm_name` to import a CloudWatch Composite Alarm. For example:\n\n```\n$ terraform import aws_cloudwatch_composite_alarm.test my-alarm\n```\n",
    "basename": "cloudwatch_composite_alarm.html"
  },
  "cloudwatch_dashboard.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_dashboard",
    "description": "Provides a CloudWatch Dashboard resource.",
    "preview": "# Resource: aws_cloudwatch_dashboard\n\nProvides a CloudWatch …",
    "content": "\n\n# Resource: aws_cloudwatch_dashboard\n\nProvides a CloudWatch Dashboard resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_dashboard\" \"main\" {\n  dashboard_name = \"my-dashboard\"\n\n  dashboard_body = <<EOF\n{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"x\": 0,\n      \"y\": 0,\n      \"width\": 12,\n      \"height\": 6,\n      \"properties\": {\n        \"metrics\": [\n          [\n            \"AWS/EC2\",\n            \"CPUUtilization\",\n            \"InstanceId\",\n            \"i-012345\"\n          ]\n        ],\n        \"period\": 300,\n        \"stat\": \"Average\",\n        \"region\": \"us-east-1\",\n        \"title\": \"EC2 Instance CPU\"\n      }\n    },\n    {\n      \"type\": \"text\",\n      \"x\": 0,\n      \"y\": 7,\n      \"width\": 3,\n      \"height\": 3,\n      \"properties\": {\n        \"markdown\": \"Hello world\"\n      }\n    }\n  ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `dashboard_name` - (Required) The name of the dashboard.\n* `dashboard_body` - (Required) The detailed information about the dashboard, including what widgets are included and their location on the dashboard. You can read more about the body structure in the [documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/CloudWatch-Dashboard-Body-Structure.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `dashboard_arn` - The Amazon Resource Name (ARN) of the dashboard.\n\n## Import\n\nCloudWatch dashboards can be imported using the `dashboard_name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_dashboard.sample <dashboard_name>\n```\n",
    "basename": "cloudwatch_dashboard.html"
  },
  "cloudwatch_event_api_destination.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_api_destination",
    "description": "Provides an EventBridge event API Destination resource.",
    "preview": "# Resource: aws_cloudwatch_event_api_destination\n\nProvides an …",
    "content": "\n\n# Resource: aws_cloudwatch_event_api_destination\n\nProvides an EventBridge event API Destination resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_event_api_destination\" \"test\" {\n  name                             = \"api-destination\"\n  description                      = \"An API Destination\"\n  invocation_endpoint              = \"https://api.destination.com/endpoint\"\n  http_method                      = \"POST\"\n  invocation_rate_limit_per_second = 20\n  connection_arn                   = aws_cloudwatch_event_connection.test.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the new API Destination. The name must be unique for your account. Maximum of 64 characters consisting of numbers, lower/upper case letters, .,-,_.\n* `description` - (Optional) The description of the new API Destination. Maximum of 512 characters.\n* `invocation_endpoint` - (Required) URL endpoint to invoke as a target. This could be a valid endpoint generated by a partner service. You can include \"*\" as path parameters wildcards to be set from the Target HttpParameters.\n* `http_method` - (Required) Select the HTTP method used for the invocation endpoint, such as GET, POST, PUT, etc.\n* `invocation_rate_limit_per_second` - (Optional) Enter the maximum number of invocations per second to allow for this destination. Enter a value greater than 0 (default 300).\n* `connection_arn` - (Required) ARN of the EventBridge Connection to use for the API Destination.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the event API Destination.\n\n\n## Import\n\nEventBridge API Destinations can be imported using the `name`, e.g.,\n\n```console\n$ terraform import aws_cloudwatch_event_api_destination.test api-destination\n```\n",
    "basename": "cloudwatch_event_api_destination.html"
  },
  "cloudwatch_event_archive.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_archive",
    "description": "Provides an EventBridge event archive resource.",
    "preview": "# Resource: aws_cloudwatch_event_archive\n\nProvides an EventBridge …",
    "content": "\n\n# Resource: aws_cloudwatch_event_archive\n\nProvides an EventBridge event archive resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_event_bus\" \"order\" {\n  name = \"orders\"\n}\n\nresource \"aws_cloudwatch_event_archive\" \"order\" {\n  name             = \"order-archive\"\n  event_source_arn = aws_cloudwatch_event_bus.order.arn\n}\n```\n\n## Example all optional arguments\n\n```terraform\nresource \"aws_cloudwatch_event_bus\" \"order\" {\n  name = \"orders\"\n}\n\nresource \"aws_cloudwatch_event_archive\" \"order\" {\n  name             = \"order-archive\"\n  description      = \"Archived events from order service\"\n  event_source_arn = aws_cloudwatch_event_bus.order.arn\n  retention_days   = 7\n  event_pattern    = <<PATTERN\n{\n  \"source\": [\"company.team.order\"]\n}\nPATTERN\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the new event archive. The archive name cannot exceed 48 characters.\n* `event_source_arn` - (Required) Event bus source ARN from where these events should be archived.\n* `description` - (Optional) The description of the new event archive.\n* `event_pattern` - (Optional) Instructs the new event archive to only capture events matched by this pattern. By default, it attempts to archive every event received in the `event_source_arn`.\n* `retention_days` - (Optional) The maximum number of days to retain events in the new event archive. By default, it archives indefinitely.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the event archive.\n\n## Import\n\nEvent Archive can be imported using their name, for example\n\n```bash\nterraform import aws_cloudwatch_event_archive.imported_event_archive order-archive\n```\n",
    "basename": "cloudwatch_event_archive.html"
  },
  "cloudwatch_event_bus.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_bus",
    "description": "Provides an EventBridge event bus resource.",
    "preview": "# Resource: aws_cloudwatch_event_bus\n\nProvides an EventBridge event …",
    "content": "\n\n# Resource: aws_cloudwatch_event_bus\n\nProvides an EventBridge event bus resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_event_bus\" \"messenger\" {\n  name = \"chat-messages\"\n}\n```\n\n```terraform\ndata \"aws_cloudwatch_event_source\" \"examplepartner\" {\n  name_prefix = \"aws.partner/examplepartner.com\"\n}\n\nresource \"aws_cloudwatch_event_bus\" \"examplepartner\" {\n  name              = data.aws_cloudwatch_event_source.examplepartner.name\n  event_source_name = data.aws_cloudwatch_event_source.examplepartner.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the new event bus. The names of custom event buses can't contain the / character. To create a partner event bus, ensure the `name` matches the `event_source_name`.\n* `event_source_name` (Optional) The partner event source that the new event bus will be matched with. Must match `name`.\n* `tags` - (Optional)  A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the event bus.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEventBridge event buses can be imported using the `name` (which can also be a partner event source name), e.g.,\n\n```console\n$ terraform import aws_cloudwatch_event_bus.messenger chat-messages\n```\n",
    "basename": "cloudwatch_event_bus.html"
  },
  "cloudwatch_event_bus_policy.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_bus_policy",
    "description": "Provides a resource to create an EventBridge policy to support cross-account events.",
    "preview": "# Resource: aws_cloudwatch_event_bus_policy\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_cloudwatch_event_bus_policy\n\nProvides a resource to create an EventBridge resource policy to support cross-account events.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n~> **Note:** The EventBridge bus policy resource  (`aws_cloudwatch_event_bus_policy`) is incompatible with the EventBridge permission resource (`aws_cloudwatch_event_permission`) and will overwrite permissions.\n\n## Example Usage\n\n### Account Access\n\n```hcl\ndata \"aws_iam_policy_document\" \"test\" {\n  statement {\n    sid    = \"DevAccountAccess\"\n    effect = \"Allow\"\n    actions = [\n      \"events:PutEvents\",\n    ]\n    resources = [\n      \"arn:aws:events:eu-west-1:123456789012:event-bus/default\"\n    ]\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"123456789012\"]\n    }\n  }\n}\n\nresource \"aws_cloudwatch_event_bus_policy\" \"test\" {\n  policy         = data.aws_iam_policy_document.test.json\n  event_bus_name = aws_cloudwatch_event_bus.test.name\n}\n```\n\n### Organization Access\n\n```hcl\ndata \"aws_iam_policy_document\" \"test\" {\n  statement {\n    sid    = \"OrganizationAccess\"\n    effect = \"Allow\"\n    actions = [\n      \"events:DescribeRule\",\n      \"events:ListRules\",\n      \"events:ListTargetsByRule\",\n      \"events:ListTagsForResource\",\n    ]\n    resources = [\n      \"arn:aws:events:eu-west-1:123456789012:rule/*\",\n      \"arn:aws:events:eu-west-1:123456789012:event-bus/default\"\n    ]\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"*\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"aws:PrincipalOrgID\"\n      values   = aws_organizations_organization.example.id\n    }\n  }\n}\n\nresource \"aws_cloudwatch_event_bus_policy\" \"test\" {\n  policy         = data.aws_iam_policy_document.test.json\n  event_bus_name = aws_cloudwatch_event_bus.test.name\n}\n```\n\n### Multiple Statements\n\n```hcl\ndata \"aws_iam_policy_document\" \"test\" {\n\n  statement {\n    sid    = \"DevAccountAccess\"\n    effect = \"Allow\"\n    actions = [\n      \"events:PutEvents\",\n    ]\n    resources = [\n      \"arn:aws:events:eu-west-1:123456789012:event-bus/default\"\n    ]\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"123456789012\"]\n    }\n  }\n\n  statement {\n    sid    = \"OrganizationAccess\"\n    effect = \"Allow\"\n    actions = [\n      \"events:DescribeRule\",\n      \"events:ListRules\",\n      \"events:ListTargetsByRule\",\n      \"events:ListTagsForResource\",\n    ]\n    resources = [\n      \"arn:aws:events:eu-west-1:123456789012:rule/*\",\n      \"arn:aws:events:eu-west-1:123456789012:event-bus/default\"\n    ]\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"*\"]\n    }\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"aws:PrincipalOrgID\"\n      values   = aws_organizations_organization.example.id\n    }\n  }\n}\n\nresource \"aws_cloudwatch_event_bus_policy\" \"test\" {\n  policy         = data.aws_iam_policy_document.test.json\n  event_bus_name = aws_cloudwatch_event_bus.test.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy` - (Required) The text of the policy. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `event_bus_name` - (Optional) The event bus to set the permissions on. If you omit this, the permissions are set on the `default` event bus.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the EventBridge event bus.\n\n## Import\n\nEventBridge permissions can be imported using the `event_bus_name`, e.g.,\n\n```shell\n$ terraform import aws_cloudwatch_event_bus_policy.DevAccountAccess example-event-bus\n```\n",
    "basename": "cloudwatch_event_bus_policy.html"
  },
  "cloudwatch_event_connection.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_connection",
    "description": "Provides an EventBridge connection resource.",
    "preview": "# Resource: aws_cloudwatch_event_connection\n\nProvides an EventBridge …",
    "content": "\n\n# Resource: aws_cloudwatch_event_connection\n\nProvides an EventBridge connection resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_event_connection\" \"test\" {\n  name               = \"ngrok-connection\"\n  description        = \"A connection description\"\n  authorization_type = \"API_KEY\"\n\n  auth_parameters {\n    api_key {\n      key   = \"x-signature\"\n      value = \"1234\"\n    }\n  }\n}\n```\n\n## Example Usage Basic Authorization\n\n```terraform\nresource \"aws_cloudwatch_event_connection\" \"test\" {\n  name               = \"ngrok-connection\"\n  description        = \"A connection description\"\n  authorization_type = \"BASIC\"\n\n  auth_parameters {\n    basic {\n      username = \"user\"\n      password = \"Pass1234!\"\n    }\n  }\n}\n```\n\n## Example Usage OAuth Authorization\n\n```terraform\nresource \"aws_cloudwatch_event_connection\" \"test\" {\n  name               = \"ngrok-connection\"\n  description        = \"A connection description\"\n  authorization_type = \"OAUTH_CLIENT_CREDENTIALS\"\n\n  auth_parameters {\n    oauth {\n      authorization_endpoint = \"https://auth.url.com/endpoint\"\n      http_method            = \"GET\"\n\n      client_parameters {\n        client_id     = \"1234567890\"\n        client_secret = \"Pass1234!\"\n      }\n\n      oauth_http_parameters {\n        body {\n          key             = \"body-parameter-key\"\n          value           = \"body-parameter-value\"\n          is_value_secret = false\n        }\n\n        header {\n          key             = \"header-parameter-key\"\n          value           = \"header-parameter-value\"\n          is_value_secret = false\n        }\n\n        query_string {\n          key             = \"query-string-parameter-key\"\n          value           = \"query-string-parameter-value\"\n          is_value_secret = false\n        }\n      }\n    }\n  }\n}\n```\n\n## Example Usage Invocation Http Parameters\n\n```terraform\nresource \"aws_cloudwatch_event_connection\" \"test\" {\n  name               = \"ngrok-connection\"\n  description        = \"A connection description\"\n  authorization_type = \"BASIC\"\n\n  auth_parameters {\n    basic {\n      username = \"user\"\n      password = \"Pass1234!\"\n    }\n\n    invocation_http_parameters {\n      body {\n        key             = \"body-parameter-key\"\n        value           = \"body-parameter-value\"\n        is_value_secret = false\n      }\n\n      body {\n        key             = \"body-parameter-key2\"\n        value           = \"body-parameter-value2\"\n        is_value_secret = true\n      }\n\n      header {\n        key             = \"header-parameter-key\"\n        value           = \"header-parameter-value\"\n        is_value_secret = false\n      }\n\n      query_string {\n        key             = \"query-string-parameter-key\"\n        value           = \"query-string-parameter-value\"\n        is_value_secret = false\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the new connection. Maximum of 64 characters consisting of numbers, lower/upper case letters, .,-,_.\n* `description` - (Optional) Enter a description for the connection. Maximum of 512 characters.\n* `authorization_type` - (Required) Choose the type of authorization to use for the connection. One of `API_KEY`,`BASIC`,`OAUTH_CLIENT_CREDENTIALS`.\n* `auth_parameters` - (Required) Parameters used for authorization. A maximum of 1 are allowed. Documented below.\n* `invocation_http_parameters` - (Optional) Invocation Http Parameters are additional credentials used to sign each Invocation of the ApiDestination created from this Connection. If the ApiDestination Rule Target has additional HttpParameters, the values will be merged together, with the Connection Invocation Http Parameters taking precedence. Secret values are stored and managed by AWS Secrets Manager. A maximum of 1 are allowed. Documented below.\n\n`auth_parameters` support the following:\n\n* `api_key` - (Optional) Parameters used for API_KEY authorization. An API key to include in the header for each authentication request. A maximum of 1 are allowed. Conflicts with `basic` and `oauth`. Documented below.\n* `basic` - (Optional) Parameters used for BASIC authorization. A maximum of 1 are allowed. Conflicts with `api_key` and `oauth`. Documented below.\n* `oauth` - (Optional) Parameters used for OAUTH_CLIENT_CREDENTIALS authorization. A maximum of 1 are allowed. Conflicts with `basic` and `api_key`. Documented below.\n\n`api_key` support the following:\n\n* `key` - (Required) Header Name.\n* `value` - (Required) Header Value. Created and stored in AWS Secrets Manager.\n\n`basic` support the following:\n\n* `username` - (Required) A username for the authorization.\n* `password` - (Required) A password for the authorization. Created and stored in AWS Secrets Manager.\n\n`oauth` support the following:\n\n* `authorization_endpoint` - (Required) The URL to the authorization endpoint.\n* `http_method` - (Required) A password for the authorization. Created and stored in AWS Secrets Manager.\n* `client_parameters` - (Required) Contains the client parameters for OAuth authorization. Contains the following two parameters.\n    * `client_id` - (Required) The client ID for the credentials to use for authorization. Created and stored in AWS Secrets Manager.\n    * `client_secret` - (Required) The client secret for the credentials to use for authorization. Created and stored in AWS Secrets Manager.\n* `oauth_http_parameters` - (Required) OAuth Http Parameters are additional credentials used to sign the request to the authorization endpoint to exchange the OAuth Client information for an access token. Secret values are stored and managed by AWS Secrets Manager. A maximum of 1 are allowed. Documented below.\n\n`invocation_http_parameters` and `oauth_http_parameters` support the following:\n\n* `body` - (Optional) Contains additional body string parameters for the connection. You can include up to 100 additional body string parameters per request. Each additional parameter counts towards the event payload size, which cannot exceed 64 KB. Each parameter can contain the following:\n    * `key` - (Required) The key for the parameter.\n    * `value` - (Required) The value associated with the key. Created and stored in AWS Secrets Manager if is secret.\n    * `is_value_secret` - (Optional) Specified whether the value is secret.\n\n* `header` - (Optional) Contains additional header parameters for the connection. You can include up to 100 additional body string parameters per request. Each additional parameter counts towards the event payload size, which cannot exceed 64 KB. Each parameter can contain the following:\n    * `key` - (Required) The key for the parameter.\n    * `value` - (Required) The value associated with the key. Created and stored in AWS Secrets Manager if is secret.\n    * `is_value_secret` - (Optional) Specified whether the value is secret.\n\n* `query_string` - (Optional) Contains additional query string parameters for the connection. You can include up to 100 additional body string parameters per request. Each additional parameter counts towards the event payload size, which cannot exceed 64 KB. Each parameter can contain the following:\n    * `key` - (Required) The key for the parameter.\n    * `value` - (Required) The value associated with the key. Created and stored in AWS Secrets Manager if is secret.\n    * `is_value_secret` - (Optional) Specified whether the value is secret.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the connection.\n* `secret_arn` - The Amazon Resource Name (ARN) of the secret created from the authorization parameters specified for the connection.\n\n\n## Import\n\nEventBridge Connection can be imported using the `name`, e.g.,\n\n```console\n$ terraform import aws_cloudwatch_event_connection.test ngrok-connection\n```\n",
    "basename": "cloudwatch_event_connection.html"
  },
  "cloudwatch_event_permission.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_permission",
    "description": "Provides a resource to create an EventBridge permission to support cross-account events in the current account default event bus.",
    "preview": "# Resource: aws_cloudwatch_event_permission\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_cloudwatch_event_permission\n\nProvides a resource to create an EventBridge permission to support cross-account events in the current account default event bus.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n~> **Note:** The EventBridge bus policy resource  (`aws_cloudwatch_event_bus_policy`) is incompatible with the EventBridge permission resource (`aws_cloudwatch_event_permission`) and will overwrite permissions.\n\n## Example Usage\n\n### Account Access\n\n```terraform\nresource \"aws_cloudwatch_event_permission\" \"DevAccountAccess\" {\n  principal    = \"123456789012\"\n  statement_id = \"DevAccountAccess\"\n}\n```\n\n### Organization Access\n\n```terraform\nresource \"aws_cloudwatch_event_permission\" \"OrganizationAccess\" {\n  principal    = \"*\"\n  statement_id = \"OrganizationAccess\"\n\n  condition {\n    key   = \"aws:PrincipalOrgID\"\n    type  = \"StringEquals\"\n    value = aws_organizations_organization.example.id\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `principal` - (Required) The 12-digit AWS account ID that you are permitting to put events to your default event bus. Specify `*` to permit any account to put events to your default event bus, optionally limited by `condition`.\n* `statement_id` - (Required) An identifier string for the external account that you are granting permissions to.\n* `action` - (Optional) The action that you are enabling the other account to perform. Defaults to `events:PutEvents`.\n* `condition` - (Optional) Configuration block to limit the event bus permissions you are granting to only accounts that fulfill the condition. Specified below.\n* `event_bus_name` - (Optional) The event bus to set the permissions on. If you omit this, the permissions are set on the `default` event bus.\n\n### condition\n\n* `key` - (Required) Key for the condition. Valid values: `aws:PrincipalOrgID`.\n* `type` - (Required) Type of condition. Value values: `StringEquals`.\n* `value` - (Required) Value for the key.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The statement ID of the EventBridge permission.\n\n## Import\n\nEventBridge permissions can be imported using the `event_bus_name/statement_id` (if you omit `event_bus_name`, the `default` event bus will be used), e.g.,\n\n```shell\n$ terraform import aws_cloudwatch_event_permission.DevAccountAccess example-event-bus/DevAccountAccess\n```\n",
    "basename": "cloudwatch_event_permission.html"
  },
  "cloudwatch_event_rule.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_rule",
    "description": "Provides an EventBridge Rule resource.",
    "preview": "# Resource: aws_cloudwatch_event_rule\n\nProvides an EventBridge Rule …",
    "content": "\n\n# Resource: aws_cloudwatch_event_rule\n\nProvides an EventBridge Rule resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_event_rule\" \"console\" {\n  name        = \"capture-aws-sign-in\"\n  description = \"Capture each AWS Console Sign In\"\n\n  event_pattern = <<EOF\n{\n  \"detail-type\": [\n    \"AWS Console Sign In via CloudTrail\"\n  ]\n}\nEOF\n}\n\nresource \"aws_cloudwatch_event_target\" \"sns\" {\n  rule      = aws_cloudwatch_event_rule.console.name\n  target_id = \"SendToSNS\"\n  arn       = aws_sns_topic.aws_logins.arn\n}\n\nresource \"aws_sns_topic\" \"aws_logins\" {\n  name = \"aws-console-logins\"\n}\n\nresource \"aws_sns_topic_policy\" \"default\" {\n  arn    = aws_sns_topic.aws_logins.arn\n  policy = data.aws_iam_policy_document.sns_topic_policy.json\n}\n\ndata \"aws_iam_policy_document\" \"sns_topic_policy\" {\n  statement {\n    effect  = \"Allow\"\n    actions = [\"SNS:Publish\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"events.amazonaws.com\"]\n    }\n\n    resources = [aws_sns_topic.aws_logins.arn]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the rule. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `schedule_expression` - (Optional) The scheduling expression. For example, `cron(0 20 * * ? *)` or `rate(5 minutes)`. At least one of `schedule_expression` or `event_pattern` is required. Can only be used on the default event bus. For more information, refer to the AWS documentation [Schedule Expressions for Rules](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html).\n* `event_bus_name` - (Optional) The event bus to associate with this rule. If you omit this, the `default` event bus is used.\n* `event_pattern` - (Optional) The event pattern described a JSON object. At least one of `schedule_expression` or `event_pattern` is required. See full documentation of [Events and Event Patterns in EventBridge](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) for details.\n* `description` - (Optional) The description of the rule.\n* `role_arn` - (Optional) The Amazon Resource Name (ARN) associated with the role that is used for target invocation.\n* `is_enabled` - (Optional) Whether the rule should be enabled (defaults to `true`).\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the rule.\n* `arn` - The Amazon Resource Name (ARN) of the rule.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEventBridge Rules can be imported using the `event_bus_name/rule_name` (if you omit `event_bus_name`, the `default` event bus will be used), e.g.,\n\n```\n$ terraform import aws_cloudwatch_event_rule.console example-event-bus/capture-console-sign-in\n```\n",
    "basename": "cloudwatch_event_rule.html"
  },
  "cloudwatch_event_target.html": {
    "subcategory": "EventBridge (CloudWatch Events)",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_event_target",
    "description": "Provides an EventBridge Target resource.",
    "preview": "# Resource: aws_cloudwatch_event_target\n\nProvides an EventBridge …",
    "content": "\n\n# Resource: aws_cloudwatch_event_target\n\nProvides an EventBridge Target resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_event_target\" \"yada\" {\n  target_id = \"Yada\"\n  rule      = aws_cloudwatch_event_rule.console.name\n  arn       = aws_kinesis_stream.test_stream.arn\n\n  run_command_targets {\n    key    = \"tag:Name\"\n    values = [\"FooBar\"]\n  }\n\n  run_command_targets {\n    key    = \"InstanceIds\"\n    values = [\"i-162058cd308bffec2\"]\n  }\n}\n\nresource \"aws_cloudwatch_event_rule\" \"console\" {\n  name        = \"capture-ec2-scaling-events\"\n  description = \"Capture all EC2 scaling events\"\n\n  event_pattern = <<PATTERN\n{\n  \"source\": [\n    \"aws.autoscaling\"\n  ],\n  \"detail-type\": [\n    \"EC2 Instance Launch Successful\",\n    \"EC2 Instance Terminate Successful\",\n    \"EC2 Instance Launch Unsuccessful\",\n    \"EC2 Instance Terminate Unsuccessful\"\n  ]\n}\nPATTERN\n}\n\nresource \"aws_kinesis_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-test\"\n  shard_count = 1\n}\n```\n\n## Example SSM Document Usage\n\n```terraform\ndata \"aws_iam_policy_document\" \"ssm_lifecycle_trust\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"events.amazonaws.com\"]\n    }\n  }\n}\n\ndata \"aws_iam_policy_document\" \"ssm_lifecycle\" {\n  statement {\n    effect    = \"Allow\"\n    actions   = [\"ssm:SendCommand\"]\n    resources = [\"arn:aws:ec2:eu-west-1:1234567890:instance/*\"]\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"ec2:ResourceTag/Terminate\"\n      values   = [\"*\"]\n    }\n  }\n\n  statement {\n    effect    = \"Allow\"\n    actions   = [\"ssm:SendCommand\"]\n    resources = [aws_ssm_document.stop_instance.arn]\n  }\n}\n\nresource \"aws_iam_role\" \"ssm_lifecycle\" {\n  name               = \"SSMLifecycle\"\n  assume_role_policy = data.aws_iam_policy_document.ssm_lifecycle_trust.json\n}\n\nresource \"aws_iam_policy\" \"ssm_lifecycle\" {\n  name   = \"SSMLifecycle\"\n  policy = data.aws_iam_policy_document.ssm_lifecycle.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ssm_lifecycle\" {\n  policy_arn = aws_iam_policy.ssm_lifecycle.arn\n  role       = aws_iam_role.ssm_lifecycle.name\n}\n\nresource \"aws_ssm_document\" \"stop_instance\" {\n  name          = \"stop_instance\"\n  document_type = \"Command\"\n\n  content = <<DOC\n  {\n    \"schemaVersion\": \"1.2\",\n    \"description\": \"Stop an instance\",\n    \"parameters\": {\n\n    },\n    \"runtimeConfig\": {\n      \"aws:runShellScript\": {\n        \"properties\": [\n          {\n            \"id\": \"0.aws:runShellScript\",\n            \"runCommand\": [\"halt\"]\n          }\n        ]\n      }\n    }\n  }\nDOC\n}\n\nresource \"aws_cloudwatch_event_rule\" \"stop_instances\" {\n  name                = \"StopInstance\"\n  description         = \"Stop instances nightly\"\n  schedule_expression = \"cron(0 0 * * ? *)\"\n}\n\nresource \"aws_cloudwatch_event_target\" \"stop_instances\" {\n  target_id = \"StopInstance\"\n  arn       = aws_ssm_document.stop_instance.arn\n  rule      = aws_cloudwatch_event_rule.stop_instances.name\n  role_arn  = aws_iam_role.ssm_lifecycle.arn\n\n  run_command_targets {\n    key    = \"tag:Terminate\"\n    values = [\"midnight\"]\n  }\n}\n```\n\n## Example RunCommand Usage\n\n```terraform\nresource \"aws_cloudwatch_event_rule\" \"stop_instances\" {\n  name                = \"StopInstance\"\n  description         = \"Stop instances nightly\"\n  schedule_expression = \"cron(0 0 * * ? *)\"\n}\n\nresource \"aws_cloudwatch_event_target\" \"stop_instances\" {\n  target_id = \"StopInstance\"\n  arn       = \"arn:aws:ssm:${var.aws_region}::document/AWS-RunShellScript\"\n  input     = \"{\\\"commands\\\":[\\\"halt\\\"]}\"\n  rule      = aws_cloudwatch_event_rule.stop_instances.name\n  role_arn  = aws_iam_role.ssm_lifecycle.arn\n\n  run_command_targets {\n    key    = \"tag:Terminate\"\n    values = [\"midnight\"]\n  }\n}\n```\n\n## Example ECS Run Task with Role and Task Override Usage\n\n```terraform\nresource \"aws_iam_role\" \"ecs_events\" {\n  name = \"ecs_events\"\n\n  assume_role_policy = <<DOC\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"events.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nDOC\n}\n\nresource \"aws_iam_role_policy\" \"ecs_events_run_task_with_any_role\" {\n  name = \"ecs_events_run_task_with_any_role\"\n  role = aws_iam_role.ecs_events.id\n\n  policy = <<DOC\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"iam:PassRole\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"ecs:RunTask\",\n            \"Resource\": \"${replace(aws_ecs_task_definition.task_name.arn, \"/:\\\\d+$/\", \":*\")}\"\n        }\n    ]\n}\nDOC\n}\n\nresource \"aws_cloudwatch_event_target\" \"ecs_scheduled_task\" {\n  target_id = \"run-scheduled-task-every-hour\"\n  arn       = aws_ecs_cluster.cluster_name.arn\n  rule      = aws_cloudwatch_event_rule.every_hour.name\n  role_arn  = aws_iam_role.ecs_events.arn\n\n  ecs_target {\n    task_count          = 1\n    task_definition_arn = aws_ecs_task_definition.task_name.arn\n  }\n\n  input = <<DOC\n{\n  \"containerOverrides\": [\n    {\n      \"name\": \"name-of-container-to-override\",\n      \"command\": [\"bin/console\", \"scheduled-task\"]\n    }\n  ]\n}\nDOC\n}\n```\n\n## Example API Gateway target\n\n```terraform\nresource \"aws_cloudwatch_event_target\" \"example\" {\n  arn  = \"${aws_api_gateway_stage.example.execution_arn}/GET\"\n  rule = aws_cloudwatch_event_rule.example.id\n\n  http_target {\n    query_string_parameters = {\n      Body = \"$.detail.body\"\n    }\n    header_parameters = {\n      Env = \"Test\"\n    }\n  }\n}\n\nresource \"aws_cloudwatch_event_rule\" \"example\" {\n  # ...\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  # ...\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  deployment_id = aws_api_gateway_deployment.example.id\n  # ...\n}\n```\n\n## Example Input Transformer Usage - JSON Object\n\n```terraform\nresource \"aws_cloudwatch_event_target\" \"example\" {\n  arn  = aws_lambda_function.example.arn\n  rule = aws_cloudwatch_event_rule.example.id\n\n  input_transformer {\n    input_paths = {\n      instance = \"$.detail.instance\",\n      status   = \"$.detail.status\",\n    }\n    input_template = <<EOF\n{\n  \"instance_id\": <instance>,\n  \"instance_status\": <status>\n}\nEOF\n  }\n}\n\nresource \"aws_cloudwatch_event_rule\" \"example\" {\n  # ...\n}\n```\n\n## Example Input Transformer Usage - Simple String\n\n```terraform\nresource \"aws_cloudwatch_event_target\" \"example\" {\n  arn  = aws_lambda_function.example.arn\n  rule = aws_cloudwatch_event_rule.example.id\n\n  input_transformer {\n    input_paths = {\n      instance = \"$.detail.instance\",\n      status   = \"$.detail.status\",\n    }\n    input_template = \"\\\"<instance> is in state <status>\\\"\"\n  }\n}\n\nresource \"aws_cloudwatch_event_rule\" \"example\" {\n  # ...\n}\n```\n\n## Argument Reference\n\n-> **Note:** In order to be able to have your AWS Lambda function or\n   SNS topic invoked by an EventBridge rule, you must setup the right permissions\n   using [`aws_lambda_permission`](/docs/providers/aws/r/lambda_permission.html)\n   or [`aws_sns_topic.policy`](/docs/providers/aws/r/sns_topic.html#policy).\n   More info [here](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/resource-based-policies-cwe.html).\n\nThe following arguments are supported:\n\n* `rule` - (Required) The name of the rule you want to add targets to.\n* `event_bus_name` - (Optional) The event bus to associate with the rule. If you omit this, the `default` event bus is used.\n* `target_id` - (Optional) The unique target assignment ID.  If missing, will generate a random, unique id.\n* `arn` - (Required) The Amazon Resource Name (ARN) of the target.\n* `input` - (Optional) Valid JSON text passed to the target. Conflicts with `input_path` and `input_transformer`.\n* `input_path` - (Optional) The value of the [JSONPath](http://goessner.net/articles/JsonPath/) that is used for extracting part of the matched event when passing it to the target. Conflicts with `input` and `input_transformer`.\n* `role_arn` - (Optional) The Amazon Resource Name (ARN) of the IAM role to be used for this target when the rule is triggered. Required if `ecs_target` is used or target in `arn` is EC2 instance, Kinesis data stream or Step Functions state machine.\n* `run_command_targets` - (Optional) Parameters used when you are using the rule to invoke Amazon EC2 Run Command. Documented below. A maximum of 5 are allowed.\n* `ecs_target` - (Optional) Parameters used when you are using the rule to invoke Amazon ECS Task. Documented below. A maximum of 1 are allowed.\n* `batch_target` - (Optional) Parameters used when you are using the rule to invoke an Amazon Batch Job. Documented below. A maximum of 1 are allowed.\n* `kinesis_target` - (Optional) Parameters used when you are using the rule to invoke an Amazon Kinesis Stream. Documented below. A maximum of 1 are allowed.\n* `redshift_target` - (Optional) Parameters used when you are using the rule to invoke an Amazon Redshift Statement. Documented below. A maximum of 1 are allowed.\n* `sqs_target` - (Optional) Parameters used when you are using the rule to invoke an Amazon SQS Queue. Documented below. A maximum of 1 are allowed.\n* `http_target` - (Optional) Parameters used when you are using the rule to invoke an API Gateway REST endpoint. Documented below. A maximum of 1 is allowed.\n* `input_transformer` - (Optional) Parameters used when you are providing a custom input to a target based on certain event data. Conflicts with `input` and `input_path`.\n* `retry_policy` - (Optional)  Parameters used when you are providing retry policies. Documented below. A maximum of 1 are allowed.\n* `dead_letter_config` - (Optional)  Parameters used when you are providing a dead letter config. Documented below. A maximum of 1 are allowed.\n\n### run_command_targets\n\n* `key` - (Required) Can be either `tag:tag-key` or `InstanceIds`.\n* `values` - (Required) If Key is `tag:tag-key`, Values is a list of tag values. If Key is `InstanceIds`, Values is a list of Amazon EC2 instance IDs.\n\n### ecs_target\n\n* `group` - (Optional) Specifies an ECS task group for the task. The maximum length is 255 characters.\n* `launch_type` - (Optional) Specifies the launch type on which your task is running. The launch type that you specify here must match one of the launch type (compatibilities) of the target task. Valid values include: an empty string `\"\"` (to specify no launch type), `EC2`, or `FARGATE`.\n* `network_configuration` - (Optional) Use this if the ECS task uses the awsvpc network mode. This specifies the VPC subnets and security groups associated with the task, and whether a public IP address is to be used. Required if launch_type is FARGATE because the awsvpc mode is required for Fargate tasks.\n* `platform_version` - (Optional) Specifies the platform version for the task. Specify only the numeric portion of the platform version, such as 1.1.0. This is used only if LaunchType is FARGATE. For more information about valid platform versions, see [AWS Fargate Platform Versions](http://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html).\n* `task_count` - (Optional) The number of tasks to create based on the TaskDefinition. The default is 1.\n* `task_definition_arn` - (Required) The ARN of the task definition to use if the event target is an Amazon ECS cluster.\n* `tags` - (Optional) A map of tags to assign to ecs resources.\n* `propagate_tags` - (Optional) Specifies whether to propagate the tags from the task definition to the task. If no value is specified, the tags are not propagated. Tags can only be propagated to the task during task creation.\n* `placement_constraint` - (Optional) An array of placement constraint objects to use for the task. You can specify up to 10 constraints per task (including constraints in the task definition and those specified at runtime). See Below.\n* `enable_execute_command` - (Optional) Whether or not to enable the execute command functionality for the containers in this task. If true, this enables execute command functionality on all containers in the task.\n* `enable_ecs_managed_tags` - (Optional) Specifies whether to enable Amazon ECS managed tags for the task.\n\n#### network_configuration\n\n* `subnets` - (Required) The subnets associated with the task or service.\n* `security_groups` - (Optional) The security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used.\n* `assign_public_ip` - (Optional) Assign a public IP address to the ENI (Fargate launch type only). Valid values are `true` or `false`. Default `false`.\n\nFor more information, see [Task Networking](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-networking.html)\n\n#### placement_constraint\n\n* `type` - (Required) Type of constraint. The only valid values at this time are `memberOf` and `distinctInstance`.\n* `expression` -  (Optional) Cluster Query Language expression to apply to the constraint. Does not need to be specified for the `distinctInstance` type. For more information, see [Cluster Query Language in the Amazon EC2 Container Service Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html).\n\n### batch_target\n\n* `job_definition` - (Required) The ARN or name of the job definition to use if the event target is an AWS Batch job. This job definition must already exist.\n* `job_name` - (Required) The name to use for this execution of the job, if the target is an AWS Batch job.\n* `array_size` - (Optional) The size of the array, if this is an array batch job. Valid values are integers between 2 and 10,000.\n* `job_attempts` - (Optional) The number of times to attempt to retry, if the job fails. Valid values are 1 to 10.\n\n### kinesis_target\n\n* `partition_key_path` - (Optional) The JSON path to be extracted from the event and used as the partition key.\n\n### redshift_target\n\n* `database` - (Required) The name of the database.\n* `db_user` - (Optional) The database user name.\n* `secrets_manager_arn` - (Optional) The name or ARN of the secret that enables access to the database.\n* `sql` - (Optional) The SQL statement text to run.\n* `statement_name` - (Optional) The name of the SQL statement.\n* `with_event` - (Optional) Indicates whether to send an event back to EventBridge after the SQL statement runs.\n\n### sqs_target\n\n* `message_group_id` - (Optional) The FIFO message group ID to use as the target.\n\n`http_target`support the following:\n\n* `path_parameter_values` - (Optional) The list of values that correspond sequentially to any path variables in your endpoint ARN (for example `arn:aws:execute-api:us-east-1:123456:myapi/*/POST/pets/*`).\n* `query_string_parameters` - (Optional) Represents keys/values of query string parameters that are appended to the invoked endpoint.\n* `header_parameters` - (Optional) Enables you to specify HTTP headers to add to the request.\n\n### input_transformer\n\n* `input_paths` - (Optional) Key value pairs specified in the form of JSONPath (for example, time = $.time)\n    * You can have as many as 100 key-value pairs.\n    * You must use JSON dot notation, not bracket notation.\n    * The keys can't start with \"AWS\".\n\n* `input_template` - (Required) Template to customize data sent to the target. Must be valid JSON. To send a string value, the string value must include double quotes. Values must be escaped for both JSON and Terraform, e.g., `\"\\\"Your string goes here.\\\\nA new line.\\\"\"`\n\n### retry_policy\n\n* `maximum_event_age_in_seconds` - (Optional) The age in seconds to continue to make retry attempts.\n* `maximum_retry_attempts` - (Optional) maximum number of retry attempts to make before the request fails\n\n### dead_letter_config\n\n* `arn` - (Optional) - ARN of the SQS queue specified as the target for the dead-letter queue.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nEventBridge Targets can be imported using `event_bus_name/rule-name/target-id` (if you omit `event_bus_name`, the `default` event bus will be used).\n\n ```\n$ terraform import aws_cloudwatch_event_target.test-event-target rule-name/target-id\n```\n",
    "basename": "cloudwatch_event_target.html"
  },
  "cloudwatch_log_destination.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_log_destination",
    "description": "Provides a CloudWatch Logs destination.",
    "preview": "# Resource: aws_cloudwatch_log_destination\n\nProvides a CloudWatch …",
    "content": "\n\n# Resource: aws_cloudwatch_log_destination\n\nProvides a CloudWatch Logs destination resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_log_destination\" \"test_destination\" {\n  name       = \"test_destination\"\n  role_arn   = aws_iam_role.iam_for_cloudwatch.arn\n  target_arn = aws_kinesis_stream.kinesis_for_cloudwatch.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A name for the log destination\n* `role_arn` - (Required) The ARN of an IAM role that grants Amazon CloudWatch Logs permissions to put data into the target\n* `target_arn` - (Required) The ARN of the target Amazon Kinesis stream resource for the destination\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) specifying the log destination.\n\n## Import\n\nCloudWatch Logs destinations can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_log_destination.test_destination test_destination\n```\n",
    "basename": "cloudwatch_log_destination.html"
  },
  "cloudwatch_log_destination_policy.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_log_destination_policy",
    "description": "Provides a CloudWatch Logs destination policy.",
    "preview": "# Resource: aws_cloudwatch_log_destination_policy\n\nProvides a …",
    "content": "\n\n# Resource: aws_cloudwatch_log_destination_policy\n\nProvides a CloudWatch Logs destination policy resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_log_destination\" \"test_destination\" {\n  name       = \"test_destination\"\n  role_arn   = aws_iam_role.iam_for_cloudwatch.arn\n  target_arn = aws_kinesis_stream.kinesis_for_cloudwatch.arn\n}\n\ndata \"aws_iam_policy_document\" \"test_destination_policy\" {\n  statement {\n    effect = \"Allow\"\n\n    principals {\n      type = \"AWS\"\n\n      identifiers = [\n        \"123456789012\",\n      ]\n    }\n\n    actions = [\n      \"logs:PutSubscriptionFilter\",\n    ]\n\n    resources = [\n      aws_cloudwatch_log_destination.test_destination.arn,\n    ]\n  }\n}\n\nresource \"aws_cloudwatch_log_destination_policy\" \"test_destination_policy\" {\n  destination_name = aws_cloudwatch_log_destination.test_destination.name\n  access_policy    = data.aws_iam_policy_document.test_destination_policy.json\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `destination_name` - (Required) A name for the subscription filter\n* `access_policy` - (Required) The policy document. This is a JSON formatted string.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nCloudWatch Logs destination policies can be imported using the `destination_name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_log_destination_policy.test_destination_policy test_destination\n```\n",
    "basename": "cloudwatch_log_destination_policy.html"
  },
  "cloudwatch_log_group.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_log_group",
    "description": "Provides a CloudWatch Log Group resource.",
    "preview": "# Resource: aws_cloudwatch_log_group\n\nProvides a CloudWatch Log …",
    "content": "\n\n# Resource: aws_cloudwatch_log_group\n\nProvides a CloudWatch Log Group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"yada\" {\n  name = \"Yada\"\n\n  tags = {\n    Environment = \"production\"\n    Application = \"serviceA\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the log group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `retention_in_days` - (Optional) Specifies the number of days\n  you want to retain log events in the specified log group.  Possible values are: 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, 3653, and 0.\n  If you select 0, the events in the log group are always retained and never expire.\n* `kms_key_id` - (Optional) The ARN of the KMS Key to use when encrypting log data. Please note, after the AWS KMS CMK is disassociated from the log group,\nAWS CloudWatch Logs stops encrypting newly ingested data for the log group. All previously ingested data remains encrypted, and AWS CloudWatch Logs requires\npermissions for the CMK whenever the encrypted data is requested.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) specifying the log group. Any `:*` suffix added by the API, denoting all CloudWatch Log Streams under the CloudWatch Log Group, is removed for greater compatibility with other AWS services that do not accept the suffix.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCloudwatch Log Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_log_group.test_group yada\n```\n",
    "basename": "cloudwatch_log_group.html"
  },
  "cloudwatch_log_metric_filter.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_log_metric_filter",
    "description": "Provides a CloudWatch Log Metric Filter resource.",
    "preview": "# Resource: aws_cloudwatch_log_metric_filter\n\nProvides a CloudWatch …",
    "content": "\n\n# Resource: aws_cloudwatch_log_metric_filter\n\nProvides a CloudWatch Log Metric Filter resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_log_metric_filter\" \"yada\" {\n  name           = \"MyAppAccessCount\"\n  pattern        = \"\"\n  log_group_name = aws_cloudwatch_log_group.dada.name\n\n  metric_transformation {\n    name      = \"EventCount\"\n    namespace = \"YourNamespace\"\n    value     = \"1\"\n  }\n}\n\nresource \"aws_cloudwatch_log_group\" \"dada\" {\n  name = \"MyApp/access.log\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A name for the metric filter.\n* `pattern` - (Required) A valid [CloudWatch Logs filter pattern](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/FilterAndPatternSyntax.html)\n  for extracting metric data out of ingested log events.\n* `log_group_name` - (Required) The name of the log group to associate the metric filter with.\n* `metric_transformation` - (Required) A block defining collection of information needed to define how metric data gets emitted. See below.\n\nThe `metric_transformation` block supports the following arguments:\n\n* `name` - (Required) The name of the CloudWatch metric to which the monitored log information should be published (e.g., `ErrorCount`)\n* `namespace` - (Required) The destination namespace of the CloudWatch metric.\n* `value` - (Required) What to publish to the metric. For example, if you're counting the occurrences of a particular term like \"Error\", the value will be \"1\" for each occurrence. If you're counting the bytes transferred the published value will be the value in the log event.\n* `default_value` - (Optional) The value to emit when a filter pattern does not match a log event. Conflicts with `dimensions`.\n* `dimensions` - (Optional) Map of fields to use as dimensions for the metric. Up to 3 dimensions are allowed. Conflicts with `default_value`.\n* `unit` - (Optional) The unit to assign to the metric. If you omit this, the unit is set as `None`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the metric filter.\n\n## Import\n\nCloudWatch Log Metric Filter can be imported using the `log_group_name:name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_log_metric_filter.test /aws/lambda/function:test\n```\n",
    "basename": "cloudwatch_log_metric_filter.html"
  },
  "cloudwatch_log_resource_policy.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_log_resource_policy",
    "description": "Provides a resource to manage a CloudWatch log resource policy",
    "preview": "# Resource: aws_cloudwatch_log_resource_policy\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_cloudwatch_log_resource_policy\n\nProvides a resource to manage a CloudWatch log resource policy.\n\n## Example Usage\n\n### Elasticsearch Log Publishing\n\n```terraform\ndata \"aws_iam_policy_document\" \"elasticsearch-log-publishing-policy\" {\n  statement {\n    actions = [\n      \"logs:CreateLogStream\",\n      \"logs:PutLogEvents\",\n      \"logs:PutLogEventsBatch\",\n    ]\n\n    resources = [\"arn:aws:logs:*\"]\n\n    principals {\n      identifiers = [\"es.amazonaws.com\"]\n      type        = \"Service\"\n    }\n  }\n}\n\nresource \"aws_cloudwatch_log_resource_policy\" \"elasticsearch-log-publishing-policy\" {\n  policy_document = data.aws_iam_policy_document.elasticsearch-log-publishing-policy.json\n  policy_name     = \"elasticsearch-log-publishing-policy\"\n}\n```\n\n### Route53 Query Logging\n\n```terraform\ndata \"aws_iam_policy_document\" \"route53-query-logging-policy\" {\n  statement {\n    actions = [\n      \"logs:CreateLogStream\",\n      \"logs:PutLogEvents\",\n    ]\n\n    resources = [\"arn:aws:logs:*:*:log-group:/aws/route53/*\"]\n\n    principals {\n      identifiers = [\"route53.amazonaws.com\"]\n      type        = \"Service\"\n    }\n  }\n}\n\nresource \"aws_cloudwatch_log_resource_policy\" \"route53-query-logging-policy\" {\n  policy_document = data.aws_iam_policy_document.route53-query-logging-policy.json\n  policy_name     = \"route53-query-logging-policy\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy_document` - (Required) Details of the resource policy, including the identity of the principal that is enabled to put logs to this account. This is formatted as a JSON string. Maximum length of 5120 characters.\n* `policy_name` - (Required) Name of the resource policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the CloudWatch log resource policy\n\n## Import\n\nCloudWatch log resource policies can be imported using the policy name, e.g.,\n\n```\n$ terraform import aws_cloudwatch_log_resource_policy.MyPolicy MyPolicy\n```\n",
    "basename": "cloudwatch_log_resource_policy.html"
  },
  "cloudwatch_log_stream.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_log_stream",
    "description": "Provides a CloudWatch Log Stream resource.",
    "preview": "# Resource: aws_cloudwatch_log_stream\n\nProvides a CloudWatch Log …",
    "content": "\n\n# Resource: aws_cloudwatch_log_stream\n\nProvides a CloudWatch Log Stream resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"yada\" {\n  name = \"Yada\"\n}\n\nresource \"aws_cloudwatch_log_stream\" \"foo\" {\n  name           = \"SampleLogStream1234\"\n  log_group_name = aws_cloudwatch_log_group.yada.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the log stream. Must not be longer than 512 characters and must not contain `:`\n* `log_group_name` - (Required) The name of the log group under which the log stream is to be created.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) specifying the log stream.\n\n## Import\n\nCloudwatch Log Stream can be imported using the stream's `log_group_name` and `name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_log_stream.foo Yada:SampleLogStream1234\n```\n",
    "basename": "cloudwatch_log_stream.html"
  },
  "cloudwatch_log_subscription_filter.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_log_subscription_filter",
    "description": "Provides a CloudWatch Logs subscription filter.",
    "preview": "# Resource: aws_cloudwatch_log_subscription_filter\n\nProvides a …",
    "content": "\n\n# Resource: aws_cloudwatch_log_subscription_filter\n\nProvides a CloudWatch Logs subscription filter resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_log_subscription_filter\" \"test_lambdafunction_logfilter\" {\n  name            = \"test_lambdafunction_logfilter\"\n  role_arn        = aws_iam_role.iam_for_lambda.arn\n  log_group_name  = \"/aws/lambda/example_lambda_name\"\n  filter_pattern  = \"logtype test\"\n  destination_arn = aws_kinesis_stream.test_logstream.arn\n  distribution    = \"Random\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A name for the subscription filter\n* `destination_arn` - (Required) The ARN of the destination to deliver matching log events to. Kinesis stream or Lambda function ARN.\n* `filter_pattern` - (Required) A valid CloudWatch Logs filter pattern for subscribing to a filtered stream of log events.\n* `log_group_name` - (Required) The name of the log group to associate the subscription filter with\n* `role_arn` - (Optional) The ARN of an IAM role that grants Amazon CloudWatch Logs permissions to deliver ingested log events to the destination. If you use Lambda as a destination, you should skip this argument and use `aws_lambda_permission` resource for granting access from CloudWatch logs to the destination Lambda function.\n* `distribution` - (Optional) The method used to distribute log data to the destination. By default log data is grouped by log stream, but the grouping can be set to random for a more even distribution. This property is only applicable when the destination is an Amazon Kinesis stream. Valid values are \"Random\" and \"ByLogStream\".\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nCloudWatch Logs subscription filter can be imported using the log group name and subscription filter name separated by `|`.\n\n```\n$ terraform import aws_cloudwatch_log_subscription_filter.test_lambdafunction_logfilter /aws/lambda/example_lambda_name|test_lambdafunction_logfilter\n```\n",
    "basename": "cloudwatch_log_subscription_filter.html"
  },
  "cloudwatch_metric_alarm.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_metric_alarm",
    "description": "Provides a CloudWatch Metric Alarm resource.",
    "preview": "# Resource: aws_cloudwatch_metric_alarm\n\nProvides a CloudWatch …",
    "content": "\n\n# Resource: aws_cloudwatch_metric_alarm\n\nProvides a CloudWatch Metric Alarm resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_metric_alarm\" \"foobar\" {\n  alarm_name                = \"terraform-test-foobar5\"\n  comparison_operator       = \"GreaterThanOrEqualToThreshold\"\n  evaluation_periods        = \"2\"\n  metric_name               = \"CPUUtilization\"\n  namespace                 = \"AWS/EC2\"\n  period                    = \"120\"\n  statistic                 = \"Average\"\n  threshold                 = \"80\"\n  alarm_description         = \"This metric monitors ec2 cpu utilization\"\n  insufficient_data_actions = []\n}\n```\n\n## Example in Conjunction with Scaling Policies\n\n```terraform\nresource \"aws_autoscaling_policy\" \"bat\" {\n  name                   = \"foobar3-terraform-test\"\n  scaling_adjustment     = 4\n  adjustment_type        = \"ChangeInCapacity\"\n  cooldown               = 300\n  autoscaling_group_name = aws_autoscaling_group.bar.name\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"bat\" {\n  alarm_name          = \"terraform-test-foobar5\"\n  comparison_operator = \"GreaterThanOrEqualToThreshold\"\n  evaluation_periods  = \"2\"\n  metric_name         = \"CPUUtilization\"\n  namespace           = \"AWS/EC2\"\n  period              = \"120\"\n  statistic           = \"Average\"\n  threshold           = \"80\"\n\n  dimensions = {\n    AutoScalingGroupName = aws_autoscaling_group.bar.name\n  }\n\n  alarm_description = \"This metric monitors ec2 cpu utilization\"\n  alarm_actions     = [aws_autoscaling_policy.bat.arn]\n}\n```\n\n## Example with an Expression\n\n```terraform\nresource \"aws_cloudwatch_metric_alarm\" \"foobar\" {\n  alarm_name                = \"terraform-test-foobar\"\n  comparison_operator       = \"GreaterThanOrEqualToThreshold\"\n  evaluation_periods        = \"2\"\n  threshold                 = \"10\"\n  alarm_description         = \"Request error rate has exceeded 10%\"\n  insufficient_data_actions = []\n\n  metric_query {\n    id          = \"e1\"\n    expression  = \"m2/m1*100\"\n    label       = \"Error Rate\"\n    return_data = \"true\"\n  }\n\n  metric_query {\n    id = \"m1\"\n\n    metric {\n      metric_name = \"RequestCount\"\n      namespace   = \"AWS/ApplicationELB\"\n      period      = \"120\"\n      stat        = \"Sum\"\n      unit        = \"Count\"\n\n      dimensions = {\n        LoadBalancer = \"app/web\"\n      }\n    }\n  }\n\n  metric_query {\n    id = \"m2\"\n\n    metric {\n      metric_name = \"HTTPCode_ELB_5XX_Count\"\n      namespace   = \"AWS/ApplicationELB\"\n      period      = \"120\"\n      stat        = \"Sum\"\n      unit        = \"Count\"\n\n      dimensions = {\n        LoadBalancer = \"app/web\"\n      }\n    }\n  }\n}\n```\n\n```terraform\nresource \"aws_cloudwatch_metric_alarm\" \"xx_anomaly_detection\" {\n  alarm_name                = \"terraform-test-foobar\"\n  comparison_operator       = \"GreaterThanUpperThreshold\"\n  evaluation_periods        = \"2\"\n  threshold_metric_id       = \"e1\"\n  alarm_description         = \"This metric monitors ec2 cpu utilization\"\n  insufficient_data_actions = []\n\n  metric_query {\n    id          = \"e1\"\n    expression  = \"ANOMALY_DETECTION_BAND(m1)\"\n    label       = \"CPUUtilization (Expected)\"\n    return_data = \"true\"\n  }\n\n  metric_query {\n    id          = \"m1\"\n    return_data = \"true\"\n    metric {\n      metric_name = \"CPUUtilization\"\n      namespace   = \"AWS/EC2\"\n      period      = \"120\"\n      stat        = \"Average\"\n      unit        = \"Count\"\n\n      dimensions = {\n        InstanceId = \"i-abc123\"\n      }\n    }\n  }\n}\n```\n\n## Example of monitoring Healthy Hosts on NLB using Target Group and NLB\n\n```terraform\nresource \"aws_cloudwatch_metric_alarm\" \"nlb_healthyhosts\" {\n  alarm_name          = \"alarmname\"\n  comparison_operator = \"LessThanThreshold\"\n  evaluation_periods  = \"1\"\n  metric_name         = \"HealthyHostCount\"\n  namespace           = \"AWS/NetworkELB\"\n  period              = \"60\"\n  statistic           = \"Average\"\n  threshold           = var.logstash_servers_count\n  alarm_description   = \"Number of healthy nodes in Target Group\"\n  actions_enabled     = \"true\"\n  alarm_actions       = [aws_sns_topic.sns.arn]\n  ok_actions          = [aws_sns_topic.sns.arn]\n  dimensions = {\n    TargetGroup  = aws_lb_target_group.lb-tg.arn_suffix\n    LoadBalancer = aws_lb.lb.arn_suffix\n  }\n}\n```\n\n~> **NOTE:**  You cannot create a metric alarm consisting of both `statistic` and `extended_statistic` parameters.\nYou must choose one or the other\n\n## Argument Reference\n\nSee [related part of AWS Docs](https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_PutMetricAlarm.html)\nfor details about valid values.\n\nThe following arguments are supported:\n\n* `alarm_name` - (Required) The descriptive name for the alarm. This name must be unique within the user's AWS account\n* `comparison_operator` - (Required) The arithmetic operation to use when comparing the specified Statistic and Threshold. The specified Statistic value is used as the first operand. Either of the following is supported: `GreaterThanOrEqualToThreshold`, `GreaterThanThreshold`, `LessThanThreshold`, `LessThanOrEqualToThreshold`. Additionally, the values  `LessThanLowerOrGreaterThanUpperThreshold`, `LessThanLowerThreshold`, and `GreaterThanUpperThreshold` are used only for alarms based on anomaly detection models.\n* `evaluation_periods` - (Required) The number of periods over which data is compared to the specified threshold.\n* `metric_name` - (Optional) The name for the alarm's associated metric.\n  See docs for [supported metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/CW_Support_For_AWS.html).\n* `namespace` - (Optional) The namespace for the alarm's associated metric. See docs for the [list of namespaces](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/aws-namespaces.html).\n  See docs for [supported metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/CW_Support_For_AWS.html).\n* `period` - (Optional) The period in seconds over which the specified `statistic` is applied.\n* `statistic` - (Optional) The statistic to apply to the alarm's associated metric.\n   Either of the following is supported: `SampleCount`, `Average`, `Sum`, `Minimum`, `Maximum`\n* `threshold` - (Optional) The value against which the specified statistic is compared. This parameter is required for alarms based on static thresholds, but should not be used for alarms based on anomaly detection models.\n* `threshold_metric_id` - (Optional) If this is an alarm based on an anomaly detection model, make this value match the ID of the ANOMALY_DETECTION_BAND function.\n* `actions_enabled` - (Optional) Indicates whether or not actions should be executed during any changes to the alarm's state. Defaults to `true`.\n* `alarm_actions` - (Optional) The list of actions to execute when this alarm transitions into an ALARM state from any other state. Each action is specified as an Amazon Resource Name (ARN).\n* `alarm_description` - (Optional) The description for the alarm.\n* `datapoints_to_alarm` - (Optional) The number of datapoints that must be breaching to trigger the alarm.\n* `dimensions` - (Optional) The dimensions for the alarm's associated metric.  For the list of available dimensions see the AWS documentation [here](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/CW_Support_For_AWS.html).\n* `insufficient_data_actions` - (Optional) The list of actions to execute when this alarm transitions into an INSUFFICIENT_DATA state from any other state. Each action is specified as an Amazon Resource Name (ARN).\n* `ok_actions` - (Optional) The list of actions to execute when this alarm transitions into an OK state from any other state. Each action is specified as an Amazon Resource Name (ARN).\n* `unit` - (Optional) The unit for the alarm's associated metric.\n* `extended_statistic` - (Optional) The percentile statistic for the metric associated with the alarm. Specify a value between p0.0 and p100.\n* `treat_missing_data` - (Optional) Sets how this alarm is to handle missing data points. The following values are supported: `missing`, `ignore`, `breaching` and `notBreaching`. Defaults to `missing`.\n* `evaluate_low_sample_count_percentiles` - (Optional) Used only for alarms\nbased on percentiles. If you specify `ignore`, the alarm state will not\nchange during periods with too few data points to be statistically significant.\nIf you specify `evaluate` or omit this parameter, the alarm will always be\nevaluated and possibly change state no matter how many data points are available.\nThe following values are supported: `ignore`, and `evaluate`.\n* `metric_query` (Optional) Enables you to create an alarm based on a metric math expression. You may specify at most 20.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n~> **NOTE:**  If you specify at least one `metric_query`, you may not specify a `metric_name`, `namespace`, `period` or `statistic`. If you do not specify a `metric_query`, you must specify each of these (although you may use `extended_statistic` instead of `statistic`).\n\n### Nested fields\n\n#### `metric_query`\n\n* `id` - (Required) A short name used to tie this object to the results in the response. If you are performing math expressions on this set of data, this name represents that data and can serve as a variable in the mathematical expression. The valid characters are letters, numbers, and underscore. The first character must be a lowercase letter.\n* `account_id` - (Optional) The ID of the account where the metrics are located, if this is a cross-account alarm.\n* `expression` - (Optional) The math expression to be performed on the returned data, if this object is performing a math expression. This expression can use the id of the other metrics to refer to those metrics, and can also use the id of other expressions to use the result of those expressions. For more information about metric math expressions, see Metric Math Syntax and Functions in the [Amazon CloudWatch User Guide](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/using-metric-math.html#metric-math-syntax).\n* `label` - (Optional) A human-readable label for this metric or expression. This is especially useful if this is an expression, so that you know what the value represents.\n* `return_data` (Optional) Specify exactly one `metric_query` to be `true` to use that `metric_query` result as the alarm.\n* `metric` (Optional) The metric to be returned, along with statistics, period, and units. Use this parameter only if this object is retrieving a metric and not performing a math expression on returned data.\n\n~> **NOTE:**  You must specify either `metric` or `expression`. Not both.\n\n#### `metric`\n\n* `dimensions` - (Optional) The dimensions for this metric.  For the list of available dimensions see the AWS documentation [here](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/CW_Support_For_AWS.html).\n* `metric_name` - (Required) The name for this metric.\n  See docs for [supported metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/CW_Support_For_AWS.html).\n* `namespace` - (Required) The namespace for this metric. See docs for the [list of namespaces](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/aws-namespaces.html).\n  See docs for [supported metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/CW_Support_For_AWS.html).\n* `period` - (Required) The period in seconds over which the specified `stat` is applied.\n* `stat` - (Required) The statistic to apply to this metric.\n   See docs for [supported statistics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Statistics-definitions.html).\n* `unit` - (Optional) The unit for this metric.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the CloudWatch Metric Alarm.\n* `id` - The ID of the health check.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCloudWatch Metric Alarm can be imported using the `alarm_name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_metric_alarm.test alarm-12345\n```\n",
    "basename": "cloudwatch_metric_alarm.html"
  },
  "cloudwatch_metric_stream.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_metric_stream",
    "description": "Provides a CloudWatch Metric Stream resource.",
    "preview": "# Resource: aws_cloudwatch_metric_stream\n\nProvides a CloudWatch …",
    "content": "\n\n# Resource: aws_cloudwatch_metric_stream\n\nProvides a CloudWatch Metric Stream resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_metric_stream\" \"main\" {\n  name          = \"my-metric-stream\"\n  role_arn      = aws_iam_role.metric_stream_to_firehose.arn\n  firehose_arn  = aws_kinesis_firehose_delivery_stream.s3_stream.arn\n  output_format = \"json\"\n\n  include_filter {\n    namespace = \"AWS/EC2\"\n  }\n\n  include_filter {\n    namespace = \"AWS/EBS\"\n  }\n}\n\n# https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-trustpolicy.html\nresource \"aws_iam_role\" \"metric_stream_to_firehose\" {\n  name = \"metric_stream_to_firehose_role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"streams.metrics.cloudwatch.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\n# https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-trustpolicy.html\nresource \"aws_iam_role_policy\" \"metric_stream_to_firehose\" {\n  name = \"default\"\n  role = aws_iam_role.metric_stream_to_firehose.id\n\n  policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"firehose:PutRecord\",\n                \"firehose:PutRecordBatch\"\n            ],\n            \"Resource\": \"${aws_kinesis_firehose_delivery_stream.s3_stream.arn}\"\n        }\n    ]\n}\nEOF\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"metric-stream-test-bucket\"\n  acl    = \"private\"\n}\n\nresource \"aws_iam_role\" \"firehose_to_s3\" {\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"firehose.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"firehose_to_s3\" {\n  name = \"default\"\n  role = aws_iam_role.firehose_to_s3.id\n\n  policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:AbortMultipartUpload\",\n                \"s3:GetBucketLocation\",\n                \"s3:GetObject\",\n                \"s3:ListBucket\",\n                \"s3:ListBucketMultipartUploads\",\n                \"s3:PutObject\"\n            ],\n            \"Resource\": [\n                \"${aws_s3_bucket.bucket.arn}\",\n                \"${aws_s3_bucket.bucket.arn}/*\"\n            ]\n        }\n    ]\n}\nEOF\n}\n\nresource \"aws_kinesis_firehose_delivery_stream\" \"s3_stream\" {\n  name        = \"metric-stream-test-stream\"\n  destination = \"s3\"\n\n  s3_configuration {\n    role_arn   = aws_iam_role.firehose_to_s3.arn\n    bucket_arn = aws_s3_bucket.bucket.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `firehose_arn` - (Required) ARN of the Amazon Kinesis Firehose delivery stream to use for this metric stream.\n* `role_arn` - (Required) ARN of the IAM role that this metric stream will use to access Amazon Kinesis Firehose resources. For more information about role permissions, see [Trust between CloudWatch and Kinesis Data Firehose](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-trustpolicy.html).\n* `output_format` - (Required) Output format for the stream. Possible values are `json` and `opentelemetry0.7`. For more information about output formats, see [Metric streams output formats](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-formats.html).\n\nThe following arguments are optional:\n\n* `exclude_filter` - (Optional) List of exclusive metric filters. If you specify this parameter, the stream sends metrics from all metric namespaces except for the namespaces that you specify here. Conflicts with `include_filter`.\n* `include_filter` - (Optional) List of inclusive metric filters. If you specify this parameter, the stream sends only the metrics from the metric namespaces that you specify here. Conflicts with `exclude_filter`.\n* `name` - (Optional, Forces new resource) Friendly name of the metric stream. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique friendly name beginning with the specified prefix. Conflicts with `name`.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `exclude_filter`\n\n* `namespace` - (Required) Name of the metric namespace in the filter.\n\n### `include_filter`\n\n* `namespace` - (Required) Name of the metric namespace in the filter.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the metric stream.\n* `creation_date` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) that the metric stream was created.\n* `last_update_date` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) that the metric stream was last updated.\n* `state` - State of the metric stream. Possible values are `running` and `stopped`.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCloudWatch metric streams can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_cloudwatch_metric_stream.sample <name>\n```\n",
    "basename": "cloudwatch_metric_stream.html"
  },
  "cloudwatch_query_definition.html": {
    "subcategory": "CloudWatch",
    "layout": "aws",
    "page_title": "AWS: aws_cloudwatch_query_definition",
    "description": "Provides a CloudWatch Logs query definition resource.",
    "preview": "# Resource: aws_cloudwatch_query_definition\n\nProvides a CloudWatch …",
    "content": "\n\n# Resource: aws_cloudwatch_query_definition\n\nProvides a CloudWatch Logs query definition resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_query_definition\" \"example\" {\n  name = \"custom_query\"\n\n  log_group_names = [\n    \"/aws/logGroup1\",\n    \"/aws/logGroup2\"\n  ]\n\n  query_string = <<EOF\nfields @timestamp, @message\n| sort @timestamp desc\n| limit 25\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the query.\n* `query_string` - (Required) The query to save. You can read more about CloudWatch Logs Query Syntax in the [documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html).\n* `log_group_names` - (Optional) Specific log groups to use with the query.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `query_definition_id` - The query definition ID.\n\n## Import\n\nCloudWatch query definitions can be imported using the query definition ARN. The ARN can be found on the \"Edit Query\" page for the query in the AWS Console.\n\n```\n$ terraform import aws_cloudwatch_query_definition.example arn:aws:logs:us-west-2:123456789012:query-definition:269951d7-6f75-496d-9d7b-6b7a5486bdbd\n```\n",
    "basename": "cloudwatch_query_definition.html"
  },
  "codeartifact_domain.html": {
    "subcategory": "CodeArtifact",
    "layout": "aws",
    "page_title": "AWS: aws_codeartifact_domain",
    "description": "Provides a CodeArtifact Domain resource.",
    "preview": "# Resource: aws_codeartifact_domain\n\nProvides a CodeArtifact Domain …",
    "content": "\n\n# Resource: aws_codeartifact_domain\n\nProvides a CodeArtifact Domain Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_codeartifact_domain\" \"example\" {\n  domain = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain` - (Required) The name of the domain to create. All domain names in an AWS Region that are in the same AWS account must be unique. The domain name is used as the prefix in DNS hostnames. Do not use sensitive information in a domain name because it is publicly discoverable.\n* `encryption_key` - (Optional) The encryption key for the domain. This is used to encrypt content stored in a domain. The KMS Key Amazon Resource Name (ARN). The default aws/codeartifact AWS KMS master key is used if this element is absent.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the Domain.\n* `arn` - The ARN of the Domain.\n* `owner` - The AWS account ID that owns the domain.\n* `repository_count` - The number of repositories in the domain.\n* `created_time` - A timestamp that represents the date and time the domain was created in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `asset_size_bytes` - The total size of all assets in the domain.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeArtifact Domain can be imported using the CodeArtifact Domain arn, e.g.,\n\n```\n$ terraform import aws_codeartifact_domain.example arn:aws:codeartifact:us-west-2:012345678912:domain/tf-acc-test-8593714120730241305\n```\n",
    "basename": "codeartifact_domain.html"
  },
  "codeartifact_domain_permissions_policy.html": {
    "subcategory": "CodeArtifact",
    "layout": "aws",
    "page_title": "AWS: aws_codeartifact_domain_permissions_policy",
    "description": "Provides a CodeArtifact Domain Permissions Policy resource.",
    "preview": "# Resource: aws_codeartifact_domain_permissions_policy\n\nProvides a …",
    "content": "\n\n# Resource: aws_codeartifact_domain_permissions_policy\n\nProvides a CodeArtifact Domains Permissions Policy Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"example\" {\n  description = \"domain key\"\n}\n\nresource \"aws_codeartifact_domain\" \"example\" {\n  domain         = \"example.com\"\n  encryption_key = aws_kms_key.example.arn\n}\n\nresource \"aws_codeartifact_domain_permissions_policy\" \"test\" {\n  domain          = aws_codeartifact_domain.example.domain\n  policy_document = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"codeartifact:CreateRepository\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Resource\": \"${aws_codeartifact_domain.example.arn}\"\n        }\n    ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain` - (Required) The name of the domain on which to set the resource policy.\n* `policy_document` - (Required) A JSON policy string to be set as the access control resource policy on the provided domain.\n* `domain_owner` - (Optional) The account number of the AWS account that owns the domain.\n* `policy_revision` - (Optional) The current revision of the resource policy to be set. This revision is used for optimistic locking, which prevents others from overwriting your changes to the domain's resource policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Name of Domain.\n* `resource_arn` - The ARN of the resource associated with the resource policy.\n\n## Import\n\nCodeArtifact Domain Permissions Policies can be imported using the CodeArtifact Domain ARN, e.g.,\n\n```\n$ terraform import aws_codeartifact_domain_permissions_policy.example arn:aws:codeartifact:us-west-2:012345678912:domain/tf-acc-test-1928056699409417367\n```\n",
    "basename": "codeartifact_domain_permissions_policy.html"
  },
  "codeartifact_repository.html": {
    "subcategory": "CodeArtifact",
    "layout": "aws",
    "page_title": "AWS: aws_codeartifact_repository",
    "description": "Provides a CodeArtifact Repository resource.",
    "preview": "# Resource: aws_codeartifact_repository\n\nProvides a CodeArtifact …",
    "content": "\n\n# Resource: aws_codeartifact_repository\n\nProvides a CodeArtifact Repository Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"example\" {\n  description = \"domain key\"\n}\n\nresource \"aws_codeartifact_domain\" \"example\" {\n  domain         = \"example\"\n  encryption_key = aws_kms_key.example.arn\n}\n\nresource \"aws_codeartifact_repository\" \"test\" {\n  repository = \"example\"\n  domain     = aws_codeartifact_domain.example.domain\n}\n```\n\n## Example Usage with upstream repository\n\n```terraform\nresource \"aws_codeartifact_repository\" \"upstream\" {\n  repository = \"upstream\"\n  domain     = aws_codeartifact_domain.test.domain\n}\n\nresource \"aws_codeartifact_repository\" \"test\" {\n  repository = \"example\"\n  domain     = aws_codeartifact_domain.example.domain\n\n  upstream {\n    repository_name = aws_codeartifact_repository.upstream.repository\n  }\n}\n```\n\n## Example Usage with external connection\n\n```terraform\nresource \"aws_codeartifact_repository\" \"upstream\" {\n  repository = \"upstream\"\n  domain     = aws_codeartifact_domain.test.domain\n}\n\nresource \"aws_codeartifact_repository\" \"test\" {\n  repository = \"example\"\n  domain     = aws_codeartifact_domain.example.domain\n\n  external_connections {\n    external_connection_name = \"public:npmjs\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain` - (Required) The domain that contains the created repository.\n* `repository` - (Required) The name of the repository to create.\n* `domain_owner` - (Optional) The account number of the AWS account that owns the domain.\n* `description` - (Optional) The description of the repository.\n* `upstream` - (Optional) A list of upstream repositories to associate with the repository. The order of the upstream repositories in the list determines their priority order when AWS CodeArtifact looks for a requested package version. see [Upstream](#upstream)\n* `external_connections` - An array of external connections associated with the repository. Only one external connection can be set per repository. see [External Connections](#external-connections).\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Upstream\n\n* `repository_name` - (Required) The name of an upstream repository.\n\n### External Connections\n\n* `external_connection_name` - (Required) The name of the external connection associated with a repository.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the repository.\n* `arn` - The ARN of the repository.\n* `administrator_account` - The account number of the AWS account that manages the repository.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeArtifact Repository can be imported using the CodeArtifact Repository ARN, e.g.,\n\n```\n$ terraform import aws_codeartifact_repository.example arn:aws:codeartifact:us-west-2:012345678912:repository/tf-acc-test-6968272603913957763/tf-acc-test-6968272603913957763\n```\n",
    "basename": "codeartifact_repository.html"
  },
  "codeartifact_repository_permissions_policy.html": {
    "subcategory": "CodeArtifact",
    "layout": "aws",
    "page_title": "AWS: aws_codeartifact_repository_permissions_policy",
    "description": "Provides a CodeArtifact Repository Permissions Policy resource.",
    "preview": "# Resource: aws_codeartifact_repository_permissions_policy\n\nProvides …",
    "content": "\n\n# Resource: aws_codeartifact_repository_permissions_policy\n\nProvides a CodeArtifact Repostory Permissions Policy Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"example\" {\n  description = \"domain key\"\n}\n\nresource \"aws_codeartifact_domain\" \"example\" {\n  domain         = \"example.com\"\n  encryption_key = aws_kms_key.example.arn\n}\n\nresource \"aws_codeartifact_repository\" \"example\" {\n  repository = \"example\"\n  domain     = aws_codeartifact_domain.example.domain\n}\n\nresource \"aws_codeartifact_repository_permissions_policy\" \"example\" {\n  repository      = aws_codeartifact_repository.example.repository\n  domain          = aws_codeartifact_domain.example.domain\n  policy_document = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"codeartifact:CreateRepository\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Resource\": \"${aws_codeartifact_domain.example.arn}\"\n        }\n    ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `repository` - (Required) The name of the repository to set the resource policy on.\n* `domain` - (Required) The name of the domain on which to set the resource policy.\n* `policy_document` - (Required) A JSON policy string to be set as the access control resource policy on the provided domain.\n* `domain_owner` - (Optional) The account number of the AWS account that owns the domain.\n* `policy_revision` - (Optional) The current revision of the resource policy to be set. This revision is used for optimistic locking, which prevents others from overwriting your changes to the domain's resource policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the resource associated with the resource policy.\n* `resource_arn` - The ARN of the resource associated with the resource policy.\n\n## Import\n\nCodeArtifact Repository Permissions Policies can be imported using the CodeArtifact Repository ARN, e.g.,\n\n```\n$ terraform import aws_codeartifact_repository_permissions_policy.example arn:aws:codeartifact:us-west-2:012345678912:repository/tf-acc-test-6968272603913957763/tf-acc-test-6968272603913957763\n```\n",
    "basename": "codeartifact_repository_permissions_policy.html"
  },
  "codebuild_project.html": {
    "subcategory": "CodeBuild",
    "layout": "aws",
    "page_title": "AWS: aws_codebuild_project",
    "description": "Provides a CodeBuild Project resource.",
    "preview": "# Resource: aws_codebuild_project\n\nProvides a CodeBuild Project …",
    "content": "\n\n# Resource: aws_codebuild_project\n\nProvides a CodeBuild Project resource. See also the [`aws_codebuild_webhook` resource](/docs/providers/aws/r/codebuild_webhook.html), which manages the webhook to the source (e.g., the \"rebuild every time a code change is pushed\" option in the CodeBuild web console).\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n  acl    = \"private\"\n}\n\nresource \"aws_iam_role\" \"example\" {\n  name = \"example\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"codebuild.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"example\" {\n  role = aws_iam_role.example.name\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"*\"\n      ],\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:CreateNetworkInterface\",\n        \"ec2:DescribeDhcpOptions\",\n        \"ec2:DescribeNetworkInterfaces\",\n        \"ec2:DeleteNetworkInterface\",\n        \"ec2:DescribeSubnets\",\n        \"ec2:DescribeSecurityGroups\",\n        \"ec2:DescribeVpcs\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:CreateNetworkInterfacePermission\"\n      ],\n      \"Resource\": [\n        \"arn:aws:ec2:us-east-1:123456789012:network-interface/*\"\n      ],\n      \"Condition\": {\n        \"StringEquals\": {\n          \"ec2:Subnet\": [\n            \"${aws_subnet.example1.arn}\",\n            \"${aws_subnet.example2.arn}\"\n          ],\n          \"ec2:AuthorizedService\": \"codebuild.amazonaws.com\"\n        }\n      }\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:*\"\n      ],\n      \"Resource\": [\n        \"${aws_s3_bucket.example.arn}\",\n        \"${aws_s3_bucket.example.arn}/*\"\n      ]\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_codebuild_project\" \"example\" {\n  name          = \"test-project\"\n  description   = \"test_codebuild_project\"\n  build_timeout = \"5\"\n  service_role  = aws_iam_role.example.arn\n\n  artifacts {\n    type = \"NO_ARTIFACTS\"\n  }\n\n  cache {\n    type     = \"S3\"\n    location = aws_s3_bucket.example.bucket\n  }\n\n  environment {\n    compute_type                = \"BUILD_GENERAL1_SMALL\"\n    image                       = \"aws/codebuild/standard:1.0\"\n    type                        = \"LINUX_CONTAINER\"\n    image_pull_credentials_type = \"CODEBUILD\"\n\n    environment_variable {\n      name  = \"SOME_KEY1\"\n      value = \"SOME_VALUE1\"\n    }\n\n    environment_variable {\n      name  = \"SOME_KEY2\"\n      value = \"SOME_VALUE2\"\n      type  = \"PARAMETER_STORE\"\n    }\n  }\n\n  logs_config {\n    cloudwatch_logs {\n      group_name  = \"log-group\"\n      stream_name = \"log-stream\"\n    }\n\n    s3_logs {\n      status   = \"ENABLED\"\n      location = \"${aws_s3_bucket.example.id}/build-log\"\n    }\n  }\n\n  source {\n    type            = \"GITHUB\"\n    location        = \"https://github.com/mitchellh/packer.git\"\n    git_clone_depth = 1\n\n    git_submodules_config {\n      fetch_submodules = true\n    }\n  }\n\n  source_version = \"master\"\n\n  vpc_config {\n    vpc_id = aws_vpc.example.id\n\n    subnets = [\n      aws_subnet.example1.id,\n      aws_subnet.example2.id,\n    ]\n\n    security_group_ids = [\n      aws_security_group.example1.id,\n      aws_security_group.example2.id,\n    ]\n  }\n\n  tags = {\n    Environment = \"Test\"\n  }\n}\n\nresource \"aws_codebuild_project\" \"project-with-cache\" {\n  name           = \"test-project-cache\"\n  description    = \"test_codebuild_project_cache\"\n  build_timeout  = \"5\"\n  queued_timeout = \"5\"\n\n  service_role = aws_iam_role.example.arn\n\n  artifacts {\n    type = \"NO_ARTIFACTS\"\n  }\n\n  cache {\n    type  = \"LOCAL\"\n    modes = [\"LOCAL_DOCKER_LAYER_CACHE\", \"LOCAL_SOURCE_CACHE\"]\n  }\n\n  environment {\n    compute_type                = \"BUILD_GENERAL1_SMALL\"\n    image                       = \"aws/codebuild/standard:1.0\"\n    type                        = \"LINUX_CONTAINER\"\n    image_pull_credentials_type = \"CODEBUILD\"\n\n    environment_variable {\n      name  = \"SOME_KEY1\"\n      value = \"SOME_VALUE1\"\n    }\n  }\n\n  source {\n    type            = \"GITHUB\"\n    location        = \"https://github.com/mitchellh/packer.git\"\n    git_clone_depth = 1\n  }\n\n  tags = {\n    Environment = \"Test\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `artifacts` - (Required) Configuration block. Detailed below.\n* `environment` - (Required) Configuration block. Detailed below.\n* `name` - (Required) Project's name.\n* `source` - (Required) Configuration block. Detailed below.\n\nThe following arguments are optional:\n\n* `badge_enabled` - (Optional) Generates a publicly-accessible URL for the projects build badge. Available as `badge_url` attribute when enabled.\n* `build_batch_config` - (Optional) Defines the batch build options for the project.\n* `build_timeout` - (Optional) Number of minutes, from 5 to 480 (8 hours), for AWS CodeBuild to wait until timing out any related build that does not get marked as completed. The default is 60 minutes.\n* `cache` - (Optional) Configuration block. Detailed below.\n* `concurrent_build_limit` - (Optional) Specify a maximum number of concurrent builds for the project. The value specified must be greater than 0 and less than the account concurrent running builds limit.\n* `description` - (Optional) Short description of the project.\n* `file_system_locations` - (Optional) A set of file system locations to to mount inside the build. File system locations are documented below.\n* `encryption_key` - (Optional) AWS Key Management Service (AWS KMS) customer master key (CMK) to be used for encrypting the build project's build output artifacts.\n* `logs_config` - (Optional) Configuration block. Detailed below.\n* `queued_timeout` - (Optional) Number of minutes, from 5 to 480 (8 hours), a build is allowed to be queued before it times out. The default is 8 hours.\n* `secondary_artifacts` - (Optional) Configuration block. Detailed below.\n* `secondary_sources` - (Optional) Configuration block. Detailed below.\n* `service_role` - (Required) Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that enables AWS CodeBuild to interact with dependent AWS services on behalf of the AWS account.\n* `source_version` - (Optional) Version of the build input to be built for this project. If not specified, the latest version is used.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_config` - (Optional) Configuration block. Detailed below.\n\n### artifacts\n\n* `artifact_identifier` - (Optional) Artifact identifier. Must be the same specified inside the AWS CodeBuild build specification.\n* `encryption_disabled` - (Optional) Whether to disable encrypting output artifacts. If `type` is set to `NO_ARTIFACTS`, this value is ignored. Defaults to `false`.\n* `location` - (Optional) Information about the build output artifact location. If `type` is set to `CODEPIPELINE` or `NO_ARTIFACTS`, this value is ignored. If `type` is set to `S3`, this is the name of the output bucket.\n* `name` - (Optional) Name of the project. If `type` is set to `S3`, this is the name of the output artifact object\n* `namespace_type` - (Optional) Namespace to use in storing build artifacts. If `type` is set to `S3`, then valid values are `BUILD_ID`, `NONE`.\n* `override_artifact_name` (Optional) Whether a name specified in the build specification overrides the artifact name.\n* `packaging` - (Optional) Type of build output artifact to create. If `type` is set to `S3`, valid values are `NONE`, `ZIP`\n* `path` - (Optional) If `type` is set to `S3`, this is the path to the output artifact.\n* `type` - (Required) Build output artifact's type. Valid values: `CODEPIPELINE`, `NO_ARTIFACTS`, `S3`.\n\n### build_batch_config\n\n* `combine_artifacts` - (Optional) Specifies if the build artifacts for the batch build should be combined into a single artifact location.\n* `restrictions` - (Optional) Specifies the restrictions for the batch build.\n* `service_role` - (Required) Specifies the service role ARN for the batch build project.\n* `timeout_in_mins` - (Optional) Specifies the maximum amount of time, in minutes, that the batch build must be completed in.\n\n#### restrictions\n\n* `compute_types_allowed` - (Optional) An array of strings that specify the compute types that are allowed for the batch build. See [Build environment compute types](https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-compute-types.html) in the AWS CodeBuild User Guide for these values.\n* `maximum_builds_allowed` - (Optional) Specifies the maximum number of builds allowed.\n\n### cache\n\n* `location` - (Required when cache type is `S3`) Location where the AWS CodeBuild project stores cached resources. For type `S3`, the value must be a valid S3 bucket name/prefix.\n* `modes` - (Required when cache type is `LOCAL`) Specifies settings that AWS CodeBuild uses to store and reuse build dependencies. Valid values:  `LOCAL_SOURCE_CACHE`, `LOCAL_DOCKER_LAYER_CACHE`, `LOCAL_CUSTOM_CACHE`.\n* `type` - (Optional) Type of storage that will be used for the AWS CodeBuild project cache. Valid values: `NO_CACHE`, `LOCAL`, `S3`. Defaults to `NO_CACHE`.\n\n### environment\n\n* `certificate` - (Optional) ARN of the S3 bucket, path prefix and object key that contains the PEM-encoded certificate.\n* `compute_type` - (Required) Information about the compute resources the build project will use. Valid values: `BUILD_GENERAL1_SMALL`, `BUILD_GENERAL1_MEDIUM`, `BUILD_GENERAL1_LARGE`, `BUILD_GENERAL1_2XLARGE`. `BUILD_GENERAL1_SMALL` is only valid if `type` is set to `LINUX_CONTAINER`. When `type` is set to `LINUX_GPU_CONTAINER`, `compute_type` must be `BUILD_GENERAL1_LARGE`.\n* `environment_variable` - (Optional) Configuration block. Detailed below.\n* `image_pull_credentials_type` - (Optional) Type of credentials AWS CodeBuild uses to pull images in your build. Valid values: `CODEBUILD`, `SERVICE_ROLE`. When you use a cross-account or private registry image, you must use SERVICE_ROLE credentials. When you use an AWS CodeBuild curated image, you must use CodeBuild credentials. Defaults to `CODEBUILD`.\n* `image` - (Required) Docker image to use for this build project. Valid values include [Docker images provided by CodeBuild](https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html) (e.g `aws/codebuild/standard:2.0`), [Docker Hub images](https://hub.docker.com/) (e.g., `hashicorp/terraform:latest`), and full Docker repository URIs such as those for ECR (e.g., `137112412989.dkr.ecr.us-west-2.amazonaws.com/amazonlinux:latest`).\n* `privileged_mode` - (Optional) Whether to enable running the Docker daemon inside a Docker container. Defaults to `false`.\n* `registry_credential` - (Optional) Configuration block. Detailed below.\n* `type` - (Required) Type of build environment to use for related builds. Valid values: `LINUX_CONTAINER`, `LINUX_GPU_CONTAINER`, `WINDOWS_CONTAINER` (deprecated), `WINDOWS_SERVER_2019_CONTAINER`, `ARM_CONTAINER`. For additional information, see the [CodeBuild User Guide](https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-compute-types.html).\n\n#### environment: environment_variable\n\n* `name` - (Required) Environment variable's name or key.\n* `type` - (Optional) Type of environment variable. Valid values: `PARAMETER_STORE`, `PLAINTEXT`, `SECRETS_MANAGER`.\n* `value` - (Required) Environment variable's value.\n\n#### environment: registry_credential\n\nCredentials for access to a private Docker registry.\n\n* `credential` - (Required) ARN or name of credentials created using AWS Secrets Manager.\n* `credential_provider` - (Required) Service that created the credentials to access a private Docker registry. Valid value: `SECRETS_MANAGER` (AWS Secrets Manager).\n\n### logs_config\n\n* `cloudwatch_logs` - (Optional) Configuration block. Detailed below.\n* `s3_logs` - (Optional) Configuration block. Detailed below.\n\n#### logs_config: cloudwatch_logs\n\n* `group_name` - (Optional) Group name of the logs in CloudWatch Logs.\n* `status` - (Optional) Current status of logs in CloudWatch Logs for a build project. Valid values: `ENABLED`, `DISABLED`. Defaults to `ENABLED`.\n* `stream_name` - (Optional) Stream name of the logs in CloudWatch Logs.\n\n#### logs_config: s3_logs\n\n* `encryption_disabled` - (Optional) Whether to disable encrypting S3 logs. Defaults to `false`.\n* `location` - (Optional) Name of the S3 bucket and the path prefix for S3 logs. Must be set if status is `ENABLED`, otherwise it must be empty.\n* `status` - (Optional) Current status of logs in S3 for a build project. Valid values: `ENABLED`, `DISABLED`. Defaults to `DISABLED`.\n\n### secondary_artifacts\n\n* `artifact_identifier` - (Required) Artifact identifier. Must be the same specified inside the AWS CodeBuild build specification.\n* `encryption_disabled` - (Optional) Whether to disable encrypting output artifacts. If `type` is set to `NO_ARTIFACTS`, this value is ignored. Defaults to `false`.\n* `location` - (Optional) Information about the build output artifact location. If `type` is set to `CODEPIPELINE` or `NO_ARTIFACTS`, this value is ignored. If `type` is set to `S3`, this is the name of the output bucket. If `path` is not also specified, then `location` can also specify the path of the output artifact in the output bucket.\n* `name` - (Optional) Name of the project. If `type` is set to `S3`, this is the name of the output artifact object\n* `namespace_type` - (Optional) Namespace to use in storing build artifacts. If `type` is set to `S3`, then valid values are `BUILD_ID` or `NONE`.\n* `override_artifact_name` (Optional) Whether a name specified in the build specification overrides the artifact name.\n* `packaging` - (Optional) Type of build output artifact to create. If `type` is set to `S3`, valid values are `NONE`, `ZIP`\n* `path` - (Optional) If `type` is set to `S3`, this is the path to the output artifact.\n* `type` - (Required) Build output artifact's type. The only valid value is `S3`.\n\n### secondary_sources\n\n* `auth` - (Optional, **Deprecated**) Configuration block with the authorization settings for AWS CodeBuild to access the source code to be built. This information is for the AWS CodeBuild console's use only. Use the [`aws_codebuild_source_credential` resource](codebuild_source_credential.html) instead. Auth blocks are documented below.\n* `buildspec` - (Optional) The build spec declaration to use for this build project's related builds. This must be set when `type` is `NO_SOURCE`. It can either be a path to a file residing in the repository to be built or a local file path leveraging the `file()` built-in.\n* `git_clone_depth` - (Optional) Truncate git history to this many commits. Use `0` for a `Full` checkout which you need to run commands like `git branch --show-current`. See [AWS CodePipeline User Guide: Tutorial: Use full clone with a GitHub pipeline source](https://docs.aws.amazon.com/codepipeline/latest/userguide/tutorials-github-gitclone.html) for details.\n* `git_submodules_config` - (Optional) Configuration block. Detailed below.\n* `insecure_ssl` - (Optional) Ignore SSL warnings when connecting to source control.\n* `location` - (Optional) Location of the source code from git or s3.\n* `report_build_status` - (Optional) Whether to report the status of a build's start and finish to your source provider. This option is only valid when your source provider is `GITHUB`, `BITBUCKET`, or `GITHUB_ENTERPRISE`.\n* `build_status_config` - (Optional) Contains information that defines how the build project reports the build status to the source provider. This option is only used when the source provider is `GITHUB`, `GITHUB_ENTERPRISE`, or `BITBUCKET`.\n* `source_identifier` - (Required) Source identifier. Source data will be put inside a folder named as this parameter inside AWS CodeBuild source directory\n* `type` - (Required) Type of repository that contains the source code to be built. Valid values: `CODECOMMIT`, `CODEPIPELINE`, `GITHUB`, `GITHUB_ENTERPRISE`, `BITBUCKET` or `S3`.\n\n#### secondary_sources: auth\n\n* `resource` - (Optional, **Deprecated**) Resource value that applies to the specified authorization type. Use the [`aws_codebuild_source_credential` resource](codebuild_source_credential.html) instead.\n* `type` - (Required, **Deprecated**) Authorization type to use. The only valid value is `OAUTH`. This data type is deprecated and is no longer accurate or used. Use the [`aws_codebuild_source_credential` resource](codebuild_source_credential.html) instead.\n\n#### secondary_sources: git_submodules_config\n\nThis block is only valid when the `type` is `CODECOMMIT`, `GITHUB` or `GITHUB_ENTERPRISE`.\n\n* `fetch_submodules` - (Required) Whether to fetch Git submodules for the AWS CodeBuild build project.\n\n#### secondary_sources: build_status_config\n\n* `context` - (Optional) Specifies the context of the build status CodeBuild sends to the source provider. The usage of this parameter depends on the source provider.\n* `target_url` - (Optional) Specifies the target url of the build status CodeBuild sends to the source provider. The usage of this parameter depends on the source provider.\n\n### source\n\n* `auth` - (Optional, **Deprecated**) Configuration block with the authorization settings for AWS CodeBuild to access the source code to be built. This information is for the AWS CodeBuild console's use only. Use the [`aws_codebuild_source_credential` resource](codebuild_source_credential.html) instead. Auth blocks are documented below.\n* `buildspec` - (Optional) Build specification to use for this build project's related builds. This must be set when `type` is `NO_SOURCE`.\n* `git_clone_depth` - (Optional) Truncate git history to this many commits. Use `0` for a `Full` checkout which you need to run commands like `git branch --show-current`. See [AWS CodePipeline User Guide: Tutorial: Use full clone with a GitHub pipeline source](https://docs.aws.amazon.com/codepipeline/latest/userguide/tutorials-github-gitclone.html) for details.\n* `git_submodules_config` - (Optional) Configuration block. Detailed below.\n* `insecure_ssl` - (Optional) Ignore SSL warnings when connecting to source control.\n* `location` - (Optional) Location of the source code from git or s3.\n* `report_build_status` - (Optional) Whether to report the status of a build's start and finish to your source provider. This option is only valid when the `type` is `BITBUCKET` or `GITHUB`.\n* `type` - (Required) Type of repository that contains the source code to be built. Valid values: `CODECOMMIT`, `CODEPIPELINE`, `GITHUB`, `GITHUB_ENTERPRISE`, `BITBUCKET`, `S3`, `NO_SOURCE`.\n\n`file_system_locations` supports the following:\n\nSee [ProjectFileSystemLocation](https://docs.aws.amazon.com/codebuild/latest/APIReference/API_ProjectFileSystemLocation.html) for more details of the fields.\n\n* `identifier` - (Optional) The name used to access a file system created by Amazon EFS. CodeBuild creates an environment variable by appending the identifier in all capital letters to CODEBUILD\\_. For example, if you specify my-efs for identifier, a new environment variable is create named CODEBUILD_MY-EFS.\n* `location` - (Optional) A string that specifies the location of the file system created by Amazon EFS. Its format is `efs-dns-name:/directory-path`.\n* `mount_options` - (Optional) The mount options for a file system created by AWS EFS.\n* `mount_point` - (Optional) The location in the container where you mount the file system.\n* `type` - (Optional) The type of the file system. The one supported type is `EFS`.\n\n#### source: auth\n\n* `resource` - (Optional, **Deprecated**) Resource value that applies to the specified authorization type. Use the [`aws_codebuild_source_credential` resource](codebuild_source_credential.html) instead.\n* `type` - (Required, **Deprecated**) Authorization type to use. The only valid value is `OAUTH`. This data type is deprecated and is no longer accurate or used. Use the [`aws_codebuild_source_credential` resource](codebuild_source_credential.html) instead.\n\n#### source: git_submodules_config\n\nThis block is only valid when the `type` is `CODECOMMIT`, `GITHUB` or `GITHUB_ENTERPRISE`.\n\n* `fetch_submodules` - (Required) Whether to fetch Git submodules for the AWS CodeBuild build project.\n\n### vpc_config\n\n* `security_group_ids` - (Required) Security group IDs to assign to running builds.\n* `subnets` - (Required) Subnet IDs within which to run builds.\n* `vpc_id` - (Required) ID of the VPC within which to run builds.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the CodeBuild project.\n* `badge_url` - URL of the build badge when `badge_enabled` is enabled.\n* `id` - Name (if imported via `name`) or ARN (if created via Terraform or imported via ARN) of the CodeBuild project.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeBuild Project can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_codebuild_project.name project-name\n```",
    "basename": "codebuild_project.html"
  },
  "codebuild_report_group.html": {
    "subcategory": "CodeBuild",
    "layout": "aws",
    "page_title": "AWS: aws_codebuild_report_group",
    "description": "Provides a CodeBuild Report Group resource.",
    "preview": "# Resource: aws_codebuild_report_group\n\nProvides a CodeBuild Report …",
    "content": "\n\n# Resource: aws_codebuild_report_group\n\nProvides a CodeBuild Report Groups Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"example\" {\n  description             = \"my test kms key\"\n  deletion_window_in_days = 7\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Id\": \"kms-tf-1\",\n  \"Statement\": [\n    {\n      \"Sid\": \"Enable IAM User Permissions\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"\n      },\n      \"Action\": \"kms:*\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"my-test\"\n}\n\nresource \"aws_codebuild_report_group\" \"example\" {\n  name = \"my test report group\"\n  type = \"TEST\"\n\n  export_config {\n    type = \"S3\"\n\n    s3_destination {\n      bucket              = aws_s3_bucket.example.id\n      encryption_disabled = false\n      encryption_key      = aws_kms_key.example.arn\n      packaging           = \"NONE\"\n      path                = \"/some\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of a Report Group.\n* `type` - (Required) The type of the Report Group. Valid value are `TEST` and `CODE_COVERAGE`.\n* `export_config` - (Required) Information about the destination where the raw data of this Report Group is exported. see [Export Config](#export-config) documented below.\n* `delete_reports` - (Optional) If `true`, deletes any reports that belong to a report group before deleting the report group. If `false`, you must delete any reports in the report group before deleting it. Default value is `false`.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Export Config\n\n* `type` - (Required) The export configuration type. Valid values are `S3` and `NO_EXPORT`.\n* `s3_destination` - (Required) contains information about the S3 bucket where the run of a report is exported. see [S3 Destination](#s3-destination) documented below.\n\n#### S3 Destination\n\n* `bucket`- (Required) The name of the S3 bucket where the raw data of a report are exported.\n* `encryption_key` - (Required) The encryption key for the report's encrypted raw data. The KMS key ARN.\n* `encryption_disabled`- (Optional) A boolean value that specifies if the results of a report are encrypted.\n **Note: the API does not currently allow setting encryption as disabled**\n* `packaging` - (Optional) The type of build output artifact to create. Valid values are: `NONE` (default) and `ZIP`.\n* `path` - (Optional) The path to the exported report's raw data results.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of Report Group.\n* `arn` - The ARN of Report Group.\n* `created` - The date and time this Report Group was created.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeBuild Report Group can be imported using the CodeBuild Report Group arn, e.g.,\n\n```\n$ terraform import aws_codebuild_report_group.example arn:aws:codebuild:us-west-2:123456789:report-group/report-group-name\n```\n",
    "basename": "codebuild_report_group.html"
  },
  "codebuild_source_credential.html": {
    "subcategory": "CodeBuild",
    "layout": "aws",
    "page_title": "AWS: aws_codebuild_source_credential",
    "description": "Provides a CodeBuild Source Credential resource.",
    "preview": "# Resource: aws_codebuild_source_credential\n\nProvides a CodeBuild …",
    "content": "\n\n# Resource: aws_codebuild_source_credential\n\nProvides a CodeBuild Source Credentials Resource.\n\n~> **NOTE:**\n[Codebuild only allows a single credential per given server type in a given region](https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_codebuild.GitHubSourceCredentials.html). Therefore, when you define `aws_codebuild_source_credential`, [`aws_codebuild_project` resource](/docs/providers/aws/r/codebuild_project.html) defined in the same module will use it.\n\n## Example Usage\n\n```terraform\nresource \"aws_codebuild_source_credential\" \"example\" {\n  auth_type   = \"PERSONAL_ACCESS_TOKEN\"\n  server_type = \"GITHUB\"\n  token       = \"example\"\n}\n```\n\n### Bitbucket Server Usage\n\n```terraform\nresource \"aws_codebuild_source_credential\" \"example\" {\n  auth_type   = \"BASIC_AUTH\"\n  server_type = \"BITBUCKET\"\n  token       = \"example\"\n  user_name   = \"test-user\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `auth_type` - (Required) The type of authentication used to connect to a GitHub, GitHub Enterprise, or Bitbucket repository. An OAUTH connection is not supported by the API.\n* `server_type` - (Required) The source provider used for this project.\n* `token` - (Required) For `GitHub` or `GitHub Enterprise`, this is the personal access token. For `Bitbucket`, this is the app password.\n* `user_name` - (Optional) The Bitbucket username when the authType is `BASIC_AUTH`. This parameter is not valid for other types of source providers or connections.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of Source Credential.\n* `arn` - The ARN of Source Credential.\n\n## Import\n\nCodeBuild Source Credential can be imported using the CodeBuild Source Credential arn, e.g.,\n\n```\n$ terraform import aws_codebuild_source_credential.example arn:aws:codebuild:us-west-2:123456789:token:github\n```\n",
    "basename": "codebuild_source_credential.html"
  },
  "codebuild_webhook.html": {
    "subcategory": "CodeBuild",
    "layout": "aws",
    "page_title": "AWS: aws_codebuild_webhook",
    "description": "Provides a CodeBuild Webhook resource.",
    "preview": "# Resource: aws_codebuild_webhook\n\nManages a CodeBuild webhook, …",
    "content": "\n\n# Resource: aws_codebuild_webhook\n\nManages a CodeBuild webhook, which is an endpoint accepted by the CodeBuild service to trigger builds from source code repositories. Depending on the source type of the CodeBuild project, the CodeBuild service may also automatically create and delete the actual repository webhook as well.\n\n## Example Usage\n\n### Bitbucket and GitHub\n\nWhen working with [Bitbucket](https://bitbucket.org) and [GitHub](https://github.com) source CodeBuild webhooks, the CodeBuild service will automatically create (on `aws_codebuild_webhook` resource creation) and delete (on `aws_codebuild_webhook` resource deletion) the Bitbucket/GitHub repository webhook using its granted OAuth permissions. This behavior cannot be controlled by Terraform.\n\n~> **Note:** The AWS account that Terraform uses to create this resource *must* have authorized CodeBuild to access Bitbucket/GitHub's OAuth API in each applicable region. This is a manual step that must be done *before* creating webhooks with this resource. If OAuth is not configured, AWS will return an error similar to `ResourceNotFoundException: Could not find access token for server type github`. More information can be found in the CodeBuild User Guide for [Bitbucket](https://docs.aws.amazon.com/codebuild/latest/userguide/sample-bitbucket-pull-request.html) and [GitHub](https://docs.aws.amazon.com/codebuild/latest/userguide/sample-github-pull-request.html).\n\n~> **Note:** Further managing the automatically created Bitbucket/GitHub webhook with the `bitbucket_hook`/`github_repository_webhook` resource is only possible with importing that resource after creation of the `aws_codebuild_webhook` resource. The CodeBuild API does not ever provide the `secret` attribute for the `aws_codebuild_webhook` resource in this scenario.\n\n```terraform\nresource \"aws_codebuild_webhook\" \"example\" {\n  project_name = aws_codebuild_project.example.name\n  build_type   = \"BUILD\"\n  filter_group {\n    filter {\n      type    = \"EVENT\"\n      pattern = \"PUSH\"\n    }\n\n    filter {\n      type    = \"HEAD_REF\"\n      pattern = \"master\"\n    }\n  }\n}\n```\n\n### GitHub Enterprise\n\nWhen working with [GitHub Enterprise](https://enterprise.github.com/) source CodeBuild webhooks, the GHE repository webhook must be separately managed (e.g., manually or with the `github_repository_webhook` resource).\n\nMore information creating webhooks with GitHub Enterprise can be found in the [CodeBuild User Guide](https://docs.aws.amazon.com/codebuild/latest/userguide/sample-github-enterprise.html).\n\n```terraform\nresource \"aws_codebuild_webhook\" \"example\" {\n  project_name = aws_codebuild_project.example.name\n}\n\nresource \"github_repository_webhook\" \"example\" {\n  active     = true\n  events     = [\"push\"]\n  name       = \"example\"\n  repository = github_repository.example.name\n\n  configuration {\n    url          = aws_codebuild_webhook.example.payload_url\n    secret       = aws_codebuild_webhook.example.secret\n    content_type = \"json\"\n    insecure_ssl = false\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `project_name` - (Required) The name of the build project.\n* `build_type` - (Optional) The type of build this webhook will trigger. Valid values for this parameter are: `BUILD`, `BUILD_BATCH`.\n* `branch_filter` - (Optional) A regular expression used to determine which branches get built. Default is all branches are built. It is recommended to use `filter_group` over `branch_filter`.\n* `filter_group` - (Optional) Information about the webhook's trigger. Filter group blocks are documented below.\n\n`filter_group` supports the following:\n\n* `filter` - (Required) A webhook filter for the group. Filter blocks are documented below.\n\n`filter` supports the following:\n\n* `type` - (Required) The webhook filter group's type. Valid values for this parameter are: `EVENT`, `BASE_REF`, `HEAD_REF`, `ACTOR_ACCOUNT_ID`, `FILE_PATH`, `COMMIT_MESSAGE`. At least one filter group must specify `EVENT` as its type.\n* `pattern` - (Required) For a filter that uses `EVENT` type, a comma-separated string that specifies one event: `PUSH`, `PULL_REQUEST_CREATED`, `PULL_REQUEST_UPDATED`, `PULL_REQUEST_REOPENED`. `PULL_REQUEST_MERGED` works with GitHub & GitHub Enterprise only. For a filter that uses any of the other filter types, a regular expression.\n* `exclude_matched_pattern` - (Optional) If set to `true`, the specified filter does *not* trigger a build. Defaults to `false`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the build project.\n* `payload_url` - The CodeBuild endpoint where webhook events are sent.\n* `secret` - The secret token of the associated repository. Not returned by the CodeBuild API for all source types.\n* `url` - The URL to the webhook.\n\n~> **Note:** The `secret` attribute is only set on resource creation, so if the secret is manually rotated, terraform will not pick up the change on subsequent runs.  In that case, the webhook resource should be tainted and re-created to get the secret back in sync.\n\n## Import\n\nCodeBuild Webhooks can be imported using the CodeBuild Project name, e.g.,\n\n```\n$ terraform import aws_codebuild_webhook.example MyProjectName\n```\n",
    "basename": "codebuild_webhook.html"
  },
  "codecommit_approval_rule_template.html": {
    "subcategory": "CodeCommit",
    "layout": "aws",
    "page_title": "AWS: aws_codecommit_approval_rule_template",
    "description": "Provides a CodeCommit Approval Rule Template Resource.",
    "preview": "# Resource: aws_codecommit_approval_rule_template\n\nProvides a …",
    "content": "\n\n# Resource: aws_codecommit_approval_rule_template\n\nProvides a CodeCommit Approval Rule Template Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_codecommit_approval_rule_template\" \"example\" {\n  name        = \"MyExampleApprovalRuleTemplate\"\n  description = \"This is an example approval rule template\"\n\n  content = <<EOF\n{\n    \"Version\": \"2018-11-08\",\n    \"DestinationReferences\": [\"refs/heads/master\"],\n    \"Statements\": [{\n        \"Type\": \"Approvers\",\n        \"NumberOfApprovalsNeeded\": 2,\n        \"ApprovalPoolMembers\": [\"arn:aws:sts::123456789012:assumed-role/CodeCommitReview/*\"]\n    }]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `content` - (Required) The content of the approval rule template. Maximum of 3000 characters.\n* `name` - (Required) The name for the approval rule template. Maximum of 100 characters.\n* `description` - (Optional) The description of the approval rule template. Maximum of 1000 characters.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `approval_rule_template_id` - The ID of the approval rule template\n* `creation_date` - The date the approval rule template was created, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `last_modified_date` - The date the approval rule template was most recently changed, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `last_modified_user` - The Amazon Resource Name (ARN) of the user who made the most recent changes to the approval rule template.\n* `rule_content_sha256` - The SHA-256 hash signature for the content of the approval rule template.\n\n## Import\n\nCodeCommit approval rule templates can be imported using the `name`, e.g.\n\n```\n$ terraform import aws_codecommit_approval_rule_template.imported ExistingApprovalRuleTemplateName\n```\n",
    "basename": "codecommit_approval_rule_template.html"
  },
  "codecommit_approval_rule_template_association.html": {
    "subcategory": "CodeCommit",
    "layout": "aws",
    "page_title": "AWS: aws_codecommit_approval_rule_template_association",
    "description": "Associates a CodeCommit Approval Rule Template with a Repository.",
    "preview": "# Resource: aws_codecommit_approval_rule_template_association\n …",
    "content": "\n\n# Resource: aws_codecommit_approval_rule_template_association\n\nAssociates a CodeCommit Approval Rule Template with a Repository.\n\n## Example Usage\n\n```terraform\nresource \"aws_codecommit_approval_rule_template_association\" \"example\" {\n  approval_rule_template_name = aws_codecommit_approval_rule_template.example.name\n  repository_name             = aws_codecommit_repository.example.repository_name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `approval_rule_template_name` - (Required) The name for the approval rule template.\n* `repository_name` - (Required) The name of the repository that you want to associate with the template.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the approval rule template and name of the repository, separated by a comma (`,`).\n\n## Import\n\nCodeCommit approval rule template associations can be imported using the `approval_rule_template_name` and `repository_name` separated by a comma (`,`), e.g.\n\n```\n$ terraform import aws_codecommit_approval_rule_template_association.example approver-rule-for-example,MyExampleRepo\n```\n",
    "basename": "codecommit_approval_rule_template_association.html"
  },
  "codecommit_repository.html": {
    "subcategory": "CodeCommit",
    "layout": "aws",
    "page_title": "AWS: aws_codecommit_repository",
    "description": "Provides a CodeCommit Repository Resource.",
    "preview": "# Resource: aws_codecommit_repository\n\nProvides a CodeCommit …",
    "content": "\n\n# Resource: aws_codecommit_repository\n\nProvides a CodeCommit Repository Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_codecommit_repository\" \"test\" {\n  repository_name = \"MyTestRepository\"\n  description     = \"This is the Sample App Repository\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `repository_name` - (Required) The name for the repository. This needs to be less than 100 characters.\n* `description` - (Optional) The description of the repository. This needs to be less than 1000 characters\n* `default_branch` - (Optional) The default branch of the repository. The branch specified here needs to exist.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `repository_id` - The ID of the repository\n* `arn` - The ARN of the repository\n* `clone_url_http` - The URL to use for cloning the repository over HTTPS.\n* `clone_url_ssh` - The URL to use for cloning the repository over SSH.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodecommit repository can be imported using repository name, e.g.,\n\n```\n$ terraform import aws_codecommit_repository.imported ExistingRepo\n```\n",
    "basename": "codecommit_repository.html"
  },
  "codecommit_trigger.html": {
    "subcategory": "CodeCommit",
    "layout": "aws",
    "page_title": "AWS: aws_codecommit_trigger",
    "description": "Provides a CodeCommit Trigger Resource.",
    "preview": "# Resource: aws_codecommit_trigger\n\nProvides a CodeCommit Trigger …",
    "content": "\n\n# Resource: aws_codecommit_trigger\n\nProvides a CodeCommit Trigger Resource.\n\n~> **NOTE:** Terraform currently can create only one trigger per repository, even if multiple aws_codecommit_trigger resources are defined. Moreover, creating triggers with Terraform will delete all other triggers in the repository (also manually-created triggers).\n\n## Example Usage\n\n```terraform\nresource \"aws_codecommit_repository\" \"test\" {\n  repository_name = \"test\"\n}\n\nresource \"aws_codecommit_trigger\" \"test\" {\n  repository_name = aws_codecommit_repository.test.repository_name\n\n  trigger {\n    name            = \"all\"\n    events          = [\"all\"]\n    destination_arn = aws_sns_topic.test.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `repository_name` - (Required) The name for the repository. This needs to be less than 100 characters.\n* `name` - (Required) The name of the trigger.\n* `destination_arn` - (Required) The ARN of the resource that is the target for a trigger. For example, the ARN of a topic in Amazon Simple Notification Service (SNS).\n* `custom_data` - (Optional) Any custom data associated with the trigger that will be included in the information sent to the target of the trigger.\n* `branches` - (Optional) The branches that will be included in the trigger configuration. If no branches are specified, the trigger will apply to all branches.\n* `events` - (Required) The repository events that will cause the trigger to run actions in another service, such as sending a notification through Amazon Simple Notification Service (SNS). If no events are specified, the trigger will run for all repository events. Event types include: `all`, `updateReference`, `createReference`, `deleteReference`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `configuration_id` - System-generated unique identifier.\n",
    "basename": "codecommit_trigger.html"
  },
  "codedeploy_app.html": {
    "subcategory": "CodeDeploy",
    "layout": "aws",
    "page_title": "AWS: aws_codedeploy_app",
    "description": "Provides a CodeDeploy application.",
    "preview": "# Resource: aws_codedeploy_app\n\nProvides a CodeDeploy application to …",
    "content": "\n\n# Resource: aws_codedeploy_app\n\nProvides a CodeDeploy application to be used as a basis for deployments\n\n## Example Usage\n\n### ECS Application\n\n```terraform\nresource \"aws_codedeploy_app\" \"example\" {\n  compute_platform = \"ECS\"\n  name             = \"example\"\n}\n```\n\n### Lambda Application\n\n```terraform\nresource \"aws_codedeploy_app\" \"example\" {\n  compute_platform = \"Lambda\"\n  name             = \"example\"\n}\n```\n\n### Server Application\n\n```terraform\nresource \"aws_codedeploy_app\" \"example\" {\n  compute_platform = \"Server\"\n  name             = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the application.\n* `compute_platform` - (Optional) The compute platform can either be `ECS`, `Lambda`, or `Server`. Default is `Server`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the CodeDeploy application.\n* `application_id` - The application ID.\n* `id` - Amazon's assigned ID for the application.\n* `name` - The application's name.\n* `github_account_name` - The name for a connection to a GitHub account.\n* `linked_to_github` - Whether the user has authenticated with GitHub for the specified application.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeDeploy Applications can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_codedeploy_app.example my-application\n```\n",
    "basename": "codedeploy_app.html"
  },
  "codedeploy_deployment_config.html": {
    "subcategory": "CodeDeploy",
    "layout": "aws",
    "page_title": "AWS: aws_codedeploy_deployment_config",
    "description": "Provides a CodeDeploy deployment config.",
    "preview": "# Resource: aws_codedeploy_deployment_config\n\nProvides a CodeDeploy …",
    "content": "\n\n# Resource: aws_codedeploy_deployment_config\n\nProvides a CodeDeploy deployment config for an application\n\n## Example Usage\n\n### Server Usage\n\n```terraform\nresource \"aws_codedeploy_deployment_config\" \"foo\" {\n  deployment_config_name = \"test-deployment-config\"\n\n  minimum_healthy_hosts {\n    type  = \"HOST_COUNT\"\n    value = 2\n  }\n}\n\nresource \"aws_codedeploy_deployment_group\" \"foo\" {\n  app_name               = aws_codedeploy_app.foo_app.name\n  deployment_group_name  = \"bar\"\n  service_role_arn       = aws_iam_role.foo_role.arn\n  deployment_config_name = aws_codedeploy_deployment_config.foo.id\n\n  ec2_tag_filter {\n    key   = \"filterkey\"\n    type  = \"KEY_AND_VALUE\"\n    value = \"filtervalue\"\n  }\n\n  trigger_configuration {\n    trigger_events     = [\"DeploymentFailure\"]\n    trigger_name       = \"foo-trigger\"\n    trigger_target_arn = \"foo-topic-arn\"\n  }\n\n  auto_rollback_configuration {\n    enabled = true\n    events  = [\"DEPLOYMENT_FAILURE\"]\n  }\n\n  alarm_configuration {\n    alarms  = [\"my-alarm-name\"]\n    enabled = true\n  }\n}\n```\n\n### Lambda Usage\n\n```terraform\nresource \"aws_codedeploy_deployment_config\" \"foo\" {\n  deployment_config_name = \"test-deployment-config\"\n  compute_platform       = \"Lambda\"\n\n  traffic_routing_config {\n    type = \"TimeBasedLinear\"\n\n    time_based_linear {\n      interval   = 10\n      percentage = 10\n    }\n  }\n}\n\nresource \"aws_codedeploy_deployment_group\" \"foo\" {\n  app_name               = aws_codedeploy_app.foo_app.name\n  deployment_group_name  = \"bar\"\n  service_role_arn       = aws_iam_role.foo_role.arn\n  deployment_config_name = aws_codedeploy_deployment_config.foo.id\n\n  auto_rollback_configuration {\n    enabled = true\n    events  = [\"DEPLOYMENT_STOP_ON_ALARM\"]\n  }\n\n  alarm_configuration {\n    alarms  = [\"my-alarm-name\"]\n    enabled = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `deployment_config_name` - (Required) The name of the deployment config.\n* `compute_platform` - (Optional) The compute platform can be `Server`, `Lambda`, or `ECS`. Default is `Server`.\n* `minimum_healthy_hosts` - (Optional) A minimum_healthy_hosts block. Required for `Server` compute platform. Minimum Healthy Hosts are documented below.\n* `traffic_routing_config` - (Optional) A traffic_routing_config block. Traffic Routing Config is documented below.\n\nThe `minimum_healthy_hosts` block supports the following:\n\n* `type` - (Required) The type can either be `FLEET_PERCENT` or `HOST_COUNT`.\n* `value` - (Required) The value when the type is `FLEET_PERCENT` represents the minimum number of healthy instances as\na percentage of the total number of instances in the deployment. If you specify FLEET_PERCENT, at the start of the\ndeployment, AWS CodeDeploy converts the percentage to the equivalent number of instance and rounds up fractional instances.\nWhen the type is `HOST_COUNT`, the value represents the minimum number of healthy instances as an absolute value.\n\nThe `traffic_routing_config` block supports the following:\n\n* `type` - (Optional) Type of traffic routing config. One of `TimeBasedCanary`, `TimeBasedLinear`, `AllAtOnce`.\n* `time_based_canary` - (Optional) The time based canary configuration information. If `type` is `TimeBasedLinear`, use `time_based_linear` instead.\n* `time_based_linear` - (Optional) The time based linear configuration information. If `type` is `TimeBasedCanary`, use `time_based_canary` instead.\n\nThe `time_based_canary` block supports the following:\n\n* `interval` - (Optional) The number of minutes between the first and second traffic shifts of a `TimeBasedCanary` deployment.\n* `percentage` - (Optional) The percentage of traffic to shift in the first increment of a `TimeBasedCanary` deployment.\n\nThe `time_based_linear` block supports the following:\n\n* `interval` - (Optional) The number of minutes between each incremental traffic shift of a `TimeBasedLinear` deployment.\n* `percentage` - (Optional) The percentage of traffic that is shifted at the start of each increment of a `TimeBasedLinear` deployment.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The deployment group's config name.\n* `deployment_config_id` - The AWS Assigned deployment config id\n\n## Import\n\nCodeDeploy Deployment Configurations can be imported using the `deployment_config_name`, e.g.,\n\n```\n$ terraform import aws_codedeploy_deployment_config.example my-deployment-config\n```\n",
    "basename": "codedeploy_deployment_config.html"
  },
  "codedeploy_deployment_group.html": {
    "subcategory": "CodeDeploy",
    "layout": "aws",
    "page_title": "AWS: aws_codedeploy_deployment_group",
    "description": "Provides a CodeDeploy deployment group.",
    "preview": "# Resource: aws_codedeploy_deployment_group\n\nProvides a CodeDeploy …",
    "content": "\n\n# Resource: aws_codedeploy_deployment_group\n\nProvides a CodeDeploy Deployment Group for a CodeDeploy Application\n\n~> **NOTE on blue/green deployments:** When using `green_fleet_provisioning_option` with the `COPY_AUTO_SCALING_GROUP` action, CodeDeploy will create a new ASG with a different name. This ASG is _not_ managed by terraform and will conflict with existing configuration and state. You may want to use a different approach to managing deployments that involve multiple ASG, such as `DISCOVER_EXISTING` with separate blue and green ASG.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name = \"example-role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"codedeploy.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"AWSCodeDeployRole\" {\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSCodeDeployRole\"\n  role       = aws_iam_role.example.name\n}\n\nresource \"aws_codedeploy_app\" \"example\" {\n  name = \"example-app\"\n}\n\nresource \"aws_sns_topic\" \"example\" {\n  name = \"example-topic\"\n}\n\nresource \"aws_codedeploy_deployment_group\" \"example\" {\n  app_name              = aws_codedeploy_app.example.name\n  deployment_group_name = \"example-group\"\n  service_role_arn      = aws_iam_role.example.arn\n\n  ec2_tag_set {\n    ec2_tag_filter {\n      key   = \"filterkey1\"\n      type  = \"KEY_AND_VALUE\"\n      value = \"filtervalue\"\n    }\n\n    ec2_tag_filter {\n      key   = \"filterkey2\"\n      type  = \"KEY_AND_VALUE\"\n      value = \"filtervalue\"\n    }\n  }\n\n  trigger_configuration {\n    trigger_events     = [\"DeploymentFailure\"]\n    trigger_name       = \"example-trigger\"\n    trigger_target_arn = aws_sns_topic.example.arn\n  }\n\n  auto_rollback_configuration {\n    enabled = true\n    events  = [\"DEPLOYMENT_FAILURE\"]\n  }\n\n  alarm_configuration {\n    alarms  = [\"my-alarm-name\"]\n    enabled = true\n  }\n}\n```\n\n### Blue Green Deployments with ECS\n\n```terraform\nresource \"aws_codedeploy_app\" \"example\" {\n  compute_platform = \"ECS\"\n  name             = \"example\"\n}\n\nresource \"aws_codedeploy_deployment_group\" \"example\" {\n  app_name               = aws_codedeploy_app.example.name\n  deployment_config_name = \"CodeDeployDefault.ECSAllAtOnce\"\n  deployment_group_name  = \"example\"\n  service_role_arn       = aws_iam_role.example.arn\n\n  auto_rollback_configuration {\n    enabled = true\n    events  = [\"DEPLOYMENT_FAILURE\"]\n  }\n\n  blue_green_deployment_config {\n    deployment_ready_option {\n      action_on_timeout = \"CONTINUE_DEPLOYMENT\"\n    }\n\n    terminate_blue_instances_on_deployment_success {\n      action                           = \"TERMINATE\"\n      termination_wait_time_in_minutes = 5\n    }\n  }\n\n  deployment_style {\n    deployment_option = \"WITH_TRAFFIC_CONTROL\"\n    deployment_type   = \"BLUE_GREEN\"\n  }\n\n  ecs_service {\n    cluster_name = aws_ecs_cluster.example.name\n    service_name = aws_ecs_service.example.name\n  }\n\n  load_balancer_info {\n    target_group_pair_info {\n      prod_traffic_route {\n        listener_arns = [aws_lb_listener.example.arn]\n      }\n\n      target_group {\n        name = aws_lb_target_group.blue.name\n      }\n\n      target_group {\n        name = aws_lb_target_group.green.name\n      }\n    }\n  }\n}\n```\n\n### Blue Green Deployments with Servers and Classic ELB\n\n```terraform\nresource \"aws_codedeploy_app\" \"example\" {\n  name = \"example-app\"\n}\n\nresource \"aws_codedeploy_deployment_group\" \"example\" {\n  app_name              = aws_codedeploy_app.example.name\n  deployment_group_name = \"example-group\"\n  service_role_arn      = aws_iam_role.example.arn\n\n  deployment_style {\n    deployment_option = \"WITH_TRAFFIC_CONTROL\"\n    deployment_type   = \"BLUE_GREEN\"\n  }\n\n  load_balancer_info {\n    elb_info {\n      name = aws_elb.example.name\n    }\n  }\n\n  blue_green_deployment_config {\n    deployment_ready_option {\n      action_on_timeout    = \"STOP_DEPLOYMENT\"\n      wait_time_in_minutes = 60\n    }\n\n    green_fleet_provisioning_option {\n      action = \"DISCOVER_EXISTING\"\n    }\n\n    terminate_blue_instances_on_deployment_success {\n      action = \"KEEP_ALIVE\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `app_name` - (Required) The name of the application.\n* `deployment_group_name` - (Required) The name of the deployment group.\n* `service_role_arn` - (Required) The service role ARN that allows deployments.\n* `alarm_configuration` - (Optional) Configuration block of alarms associated with the deployment group (documented below).\n* `auto_rollback_configuration` - (Optional) Configuration block of the automatic rollback configuration associated with the deployment group (documented below).\n* `autoscaling_groups` - (Optional) Autoscaling groups associated with the deployment group.\n* `blue_green_deployment_config` - (Optional) Configuration block of the blue/green deployment options for a deployment group (documented below).\n* `deployment_config_name` - (Optional) The name of the group's deployment config. The default is \"CodeDeployDefault.OneAtATime\".\n* `deployment_style` - (Optional) Configuration block of the type of deployment, either in-place or blue/green, you want to run and whether to route deployment traffic behind a load balancer (documented below).\n* `ec2_tag_filter` - (Optional) Tag filters associated with the deployment group. See the AWS docs for details.\n* `ec2_tag_set` - (Optional) Configuration block(s) of Tag filters associated with the deployment group, which are also referred to as tag groups (documented below). See the AWS docs for details.\n* `ecs_service` - (Optional) Configuration block(s) of the ECS services for a deployment group (documented below).\n* `load_balancer_info` - (Optional) Single configuration block of the load balancer to use in a blue/green deployment (documented below).\n* `on_premises_instance_tag_filter` - (Optional) On premise tag filters associated with the group. See the AWS docs for details.\n* `trigger_configuration` - (Optional) Configuration block(s) of the triggers for the deployment group (documented below).\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### alarm_configuration Argument Reference\n\nYou can configure a deployment to stop when a **CloudWatch** alarm detects that a metric has fallen below or exceeded a defined threshold. `alarm_configuration` supports the following:\n\n* `alarms` - (Optional) A list of alarms configured for the deployment group. _A maximum of 10 alarms can be added to a deployment group_.\n* `enabled` - (Optional) Indicates whether the alarm configuration is enabled. This option is useful when you want to temporarily deactivate alarm monitoring for a deployment group without having to add the same alarms again later.\n* `ignore_poll_alarm_failure` - (Optional) Indicates whether a deployment should continue if information about the current state of alarms cannot be retrieved from CloudWatch. The default value is `false`.\n    * `true`: The deployment will proceed even if alarm status information can't be retrieved.\n    * `false`: The deployment will stop if alarm status information can't be retrieved.\n\n_Only one `alarm_configuration` is allowed_.\n\n### auto_rollback_configuration Argument Reference\n\nYou can configure a deployment group to automatically rollback when a deployment fails or when a monitoring threshold you specify is met. In this case, the last known good version of an application revision is deployed. `auto_rollback_configuration` supports the following:\n\n* `enabled` - (Optional) Indicates whether a defined automatic rollback configuration is currently enabled for this Deployment Group. If you enable automatic rollback, you must specify at least one event type.\n* `events` - (Optional) The event type or types that trigger a rollback. Supported types are `DEPLOYMENT_FAILURE` and `DEPLOYMENT_STOP_ON_ALARM`.\n\n_Only one `auto_rollback_configuration` is allowed_.\n\n### blue_green_deployment_config Argument Reference\n\nYou can configure options for a blue/green deployment. `blue_green_deployment_config` supports the following:\n\n* `deployment_ready_option` - (Optional) Information about the action to take when newly provisioned instances are ready to receive traffic in a blue/green deployment (documented below).\n* `green_fleet_provisioning_option` - (Optional) Information about how instances are provisioned for a replacement environment in a blue/green deployment (documented below).\n* `terminate_blue_instances_on_deployment_success` - (Optional) Information about whether to terminate instances in the original fleet during a blue/green deployment (documented below).\n\n_Only one `blue_green_deployment_config` is allowed_.\n\nYou can configure how traffic is rerouted to instances in a replacement environment in a blue/green deployment. `deployment_ready_option` supports the following:\n\n* `action_on_timeout` - (Optional) When to reroute traffic from an original environment to a replacement environment in a blue/green deployment.\n    * `CONTINUE_DEPLOYMENT`: Register new instances with the load balancer immediately after the new application revision is installed on the instances in the replacement environment.\n    * `STOP_DEPLOYMENT`: Do not register new instances with load balancer unless traffic is rerouted manually. If traffic is not rerouted manually before the end of the specified wait period, the deployment status is changed to Stopped.\n* `wait_time_in_minutes` - (Optional) The number of minutes to wait before the status of a blue/green deployment changed to Stopped if rerouting is not started manually. Applies only to the `STOP_DEPLOYMENT` option for `action_on_timeout`.\n\nYou can configure how instances will be added to the replacement environment in a blue/green deployment. `green_fleet_provisioning_option` supports the following:\n\n* `action` - (Optional) The method used to add instances to a replacement environment.\n    * `DISCOVER_EXISTING`: Use instances that already exist or will be created manually.\n    * `COPY_AUTO_SCALING_GROUP`: Use settings from a specified **Auto Scaling** group to define and create instances in a new Auto Scaling group. _Exactly one Auto Scaling group must be specified_ when selecting `COPY_AUTO_SCALING_GROUP`. Use `autoscaling_groups` to specify the Auto Scaling group.\n\nYou can configure how instances in the original environment are terminated when a blue/green deployment is successful. `terminate_blue_instances_on_deployment_success` supports the following:\n\n* `action` - (Optional) The action to take on instances in the original environment after a successful blue/green deployment.\n    * `TERMINATE`: Instances are terminated after a specified wait time.\n    * `KEEP_ALIVE`: Instances are left running after they are deregistered from the load balancer and removed from the deployment group.\n* `termination_wait_time_in_minutes` - (Optional) The number of minutes to wait after a successful blue/green deployment before terminating instances from the original environment.\n\n### deployment_style Argument Reference\n\nYou can configure the type of deployment, either in-place or blue/green, you want to run and whether to route deployment traffic behind a load balancer. `deployment_style` supports the following:\n\n* `deployment_option` - (Optional) Indicates whether to route deployment traffic behind a load balancer. Valid Values are `WITH_TRAFFIC_CONTROL` or `WITHOUT_TRAFFIC_CONTROL`. Default is `WITHOUT_TRAFFIC_CONTROL`.\n* `deployment_type` - (Optional) Indicates whether to run an in-place deployment or a blue/green deployment. Valid Values are `IN_PLACE` or `BLUE_GREEN`. Default is `IN_PLACE`.\n\n_Only one `deployment_style` is allowed_.\n\n### ec2_tag_filter Argument Reference\n\nThe `ec2_tag_filter` configuration block supports the following:\n\n* `key` - (Optional) The key of the tag filter.\n* `type` - (Optional) The type of the tag filter, either `KEY_ONLY`, `VALUE_ONLY`, or `KEY_AND_VALUE`.\n* `value` - (Optional) The value of the tag filter.\n\nMultiple occurrences of `ec2_tag_filter` are allowed, where any instance that matches to at least one of the tag filters is selected.\n\n### ec2_tag_set Argument Reference\n\nYou can form a tag group by putting a set of tag filters into `ec2_tag_set`. If multiple tag groups are specified, any instance that matches to at least one tag filter of every tag group is selected.\n\n### ecs_service Argument Reference\n\nEach `ecs_service` configuration block supports the following:\n\n* `cluster_name` - (Required) The name of the ECS cluster.\n* `service_name` - (Required) The name of the ECS service.\n\n### load_balancer_info Argument Reference\n\nYou can configure the **Load Balancer** to use in a deployment. `load_balancer_info` supports the following:\n\n* `elb_info` - (Optional) The Classic Elastic Load Balancer to use in a deployment. Conflicts with `target_group_info` and `target_group_pair_info`.\n* `target_group_info` - (Optional) The (Application/Network Load Balancer) target group to use in a deployment. Conflicts with `elb_info` and `target_group_pair_info`.\n* `target_group_pair_info` - (Optional) The (Application/Network Load Balancer) target group pair to use in a deployment. Conflicts with `elb_info` and `target_group_info`.\n\n#### load_balancer_info elb_info Argument Reference\n\nThe `elb_info` configuration block supports the following:\n\n* `name` - (Optional) The name of the load balancer that will be used to route traffic from original instances to replacement instances in a blue/green deployment. For in-place deployments, the name of the load balancer that instances are deregistered from so they are not serving traffic during a deployment, and then re-registered with after the deployment completes.\n\n#### load_balancer_info target_group_info Argument Reference\n\nThe `target_group_info` configuration block supports the following:\n\n* `name` - (Optional) The name of the target group that instances in the original environment are deregistered from, and instances in the replacement environment registered with. For in-place deployments, the name of the target group that instances are deregistered from, so they are not serving traffic during a deployment, and then re-registered with after the deployment completes.\n\n#### load_balancer_info target_group_pair_info Argument Reference\n\nThe `target_group_pair_info` configuration block supports the following:\n\n* `prod_traffic_route` - (Required) Configuration block for the production traffic route (documented below).\n* `target_group` - (Required) Configuration blocks for a target group within a target group pair (documented below).\n* `test_traffic_route` - (Optional) Configuration block for the test traffic route (documented below).\n\n##### load_balancer_info target_group_pair_info prod_traffic_route Argument Reference\n\nThe `prod_traffic_route` configuration block supports the following:\n\n* `listener_arns` - (Required) List of Amazon Resource Names (ARNs) of the load balancer listeners.\n\n##### load_balancer_info target_group_pair_info target_group Argument Reference\n\nThe `target_group` configuration block supports the following:\n\n* `name` - (Required) Name of the target group.\n\n##### load_balancer_info target_group_pair_info test_traffic_route Argument Reference\n\nThe `test_traffic_route` configuration block supports the following:\n\n* `listener_arns` - (Required) List of Amazon Resource Names (ARNs) of the load balancer listeners.\n\n### on_premises_instance_tag_filter Argument Reference\n\nThe `on_premises_instance_tag_filter` configuration block supports the following:\n\n* `key` - (Optional) The key of the tag filter.\n* `type` - (Optional) The type of the tag filter, either `KEY_ONLY`, `VALUE_ONLY`, or `KEY_AND_VALUE`.\n* `value` - (Optional) The value of the tag filter.\n\n### trigger_configuration Argument Reference\n\nAdd triggers to a Deployment Group to receive notifications about events related to deployments or instances in the group. Notifications are sent to subscribers of the **SNS** topic associated with the trigger. _CodeDeploy must have permission to publish to the topic from this deployment group_. `trigger_configuration` supports the following:\n\n* `trigger_events` - (Required) The event type or types for which notifications are triggered. Some values that are supported: `DeploymentStart`, `DeploymentSuccess`, `DeploymentFailure`, `DeploymentStop`, `DeploymentRollback`, `InstanceStart`, `InstanceSuccess`, `InstanceFailure`.  See [the CodeDeploy documentation][1] for all possible values.\n* `trigger_name` - (Required) The name of the notification trigger.\n* `trigger_target_arn` - (Required) The ARN of the SNS topic through which notifications are sent.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the CodeDeploy deployment group.\n* `id` - Application name and deployment group name.\n* `compute_platform` - The destination platform type for the deployment.\n* `deployment_group_id` - The ID of the CodeDeploy deployment group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeDeploy Deployment Groups can be imported by their `app_name`, a colon, and `deployment_group_name`, e.g.,\n\n```\n$ terraform import aws_codedeploy_deployment_group.example my-application:my-deployment-group\n```\n\n[1]: http://docs.aws.amazon.com/codedeploy/latest/userguide/monitoring-sns-event-notifications-create-trigger.html\n",
    "basename": "codedeploy_deployment_group.html"
  },
  "codepipeline": {
    "subcategory": "CodePipeline",
    "layout": "aws",
    "page_title": "AWS: aws_codepipeline",
    "description": "Provides a CodePipeline",
    "preview": "# Resource: aws_codepipeline\n\nProvides a CodePipeline.\n\n## Example …",
    "content": "\n\n# Resource: aws_codepipeline\n\nProvides a CodePipeline.\n\n## Example Usage\n\n```terraform\nresource \"aws_codepipeline\" \"codepipeline\" {\n  name     = \"tf-test-pipeline\"\n  role_arn = aws_iam_role.codepipeline_role.arn\n\n  artifact_store {\n    location = aws_s3_bucket.codepipeline_bucket.bucket\n    type     = \"S3\"\n\n    encryption_key {\n      id   = data.aws_kms_alias.s3kmskey.arn\n      type = \"KMS\"\n    }\n  }\n\n  stage {\n    name = \"Source\"\n\n    action {\n      name             = \"Source\"\n      category         = \"Source\"\n      owner            = \"AWS\"\n      provider         = \"CodeStarSourceConnection\"\n      version          = \"1\"\n      output_artifacts = [\"source_output\"]\n\n      configuration = {\n        ConnectionArn    = aws_codestarconnections_connection.example.arn\n        FullRepositoryId = \"my-organization/example\"\n        BranchName       = \"main\"\n      }\n    }\n  }\n\n  stage {\n    name = \"Build\"\n\n    action {\n      name             = \"Build\"\n      category         = \"Build\"\n      owner            = \"AWS\"\n      provider         = \"CodeBuild\"\n      input_artifacts  = [\"source_output\"]\n      output_artifacts = [\"build_output\"]\n      version          = \"1\"\n\n      configuration = {\n        ProjectName = \"test\"\n      }\n    }\n  }\n\n  stage {\n    name = \"Deploy\"\n\n    action {\n      name            = \"Deploy\"\n      category        = \"Deploy\"\n      owner           = \"AWS\"\n      provider        = \"CloudFormation\"\n      input_artifacts = [\"build_output\"]\n      version         = \"1\"\n\n      configuration = {\n        ActionMode     = \"REPLACE_ON_FAILURE\"\n        Capabilities   = \"CAPABILITY_AUTO_EXPAND,CAPABILITY_IAM\"\n        OutputFileName = \"CreateStackOutput.json\"\n        StackName      = \"MyStack\"\n        TemplatePath   = \"build_output::sam-templated.yaml\"\n      }\n    }\n  }\n}\n\nresource \"aws_codestarconnections_connection\" \"example\" {\n  name          = \"example-connection\"\n  provider_type = \"GitHub\"\n}\n\nresource \"aws_s3_bucket\" \"codepipeline_bucket\" {\n  bucket = \"test-bucket\"\n  acl    = \"private\"\n}\n\nresource \"aws_iam_role\" \"codepipeline_role\" {\n  name = \"test-role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"codepipeline.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"codepipeline_policy\" {\n  name = \"codepipeline_policy\"\n  role = aws_iam_role.codepipeline_role.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\":\"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:GetObjectVersion\",\n        \"s3:GetBucketVersioning\",\n        \"s3:PutObjectAcl\",\n        \"s3:PutObject\"\n      ],\n      \"Resource\": [\n        \"${aws_s3_bucket.codepipeline_bucket.arn}\",\n        \"${aws_s3_bucket.codepipeline_bucket.arn}/*\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"codestar-connections:UseConnection\"\n      ],\n      \"Resource\": \"${aws_codestarconnections_connection.example.arn}\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"codebuild:BatchGetBuilds\",\n        \"codebuild:StartBuild\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n\ndata \"aws_kms_alias\" \"s3kmskey\" {\n  name = \"alias/myKmsKey\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the pipeline.\n* `role_arn` - (Required) A service role Amazon Resource Name (ARN) that grants AWS CodePipeline permission to make calls to AWS services on your behalf.\n* `artifact_store` (Required) One or more artifact_store blocks. Artifact stores are documented below.\n* `stage` (Minimum of at least two `stage` blocks is required) A stage block. Stages are documented below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\nAn `artifact_store` block supports the following arguments:\n\n* `location` - (Required) The location where AWS CodePipeline stores artifacts for a pipeline; currently only `S3` is supported.\n* `type` - (Required) The type of the artifact store, such as Amazon S3\n* `encryption_key` - (Optional) The encryption key block AWS CodePipeline uses to encrypt the data in the artifact store, such as an AWS Key Management Service (AWS KMS) key. If you don't specify a key, AWS CodePipeline uses the default key for Amazon Simple Storage Service (Amazon S3). An `encryption_key` block is documented below.\n* `region` - (Optional) The region where the artifact store is located. Required for a cross-region CodePipeline, do not provide for a single-region CodePipeline.\n\nAn `encryption_key` block supports the following arguments:\n\n* `id` - (Required) The KMS key ARN or ID\n* `type` - (Required) The type of key; currently only `KMS` is supported\n\nA `stage` block supports the following arguments:\n\n* `name` - (Required) The name of the stage.\n* `action` - (Required) The action(s) to include in the stage. Defined as an `action` block below\n\nAn `action` block supports the following arguments:\n\n* `category` - (Required) A category defines what kind of action can be taken in the stage, and constrains the provider type for the action. Possible values are `Approval`, `Build`, `Deploy`, `Invoke`, `Source` and `Test`.\n* `owner` - (Required) The creator of the action being called. Possible values are `AWS`, `Custom` and `ThirdParty`.\n* `name` - (Required) The action declaration's name.\n* `provider` - (Required) The provider of the service being called by the action. Valid providers are determined by the action category. Provider names are listed in the [Action Structure Reference](https://docs.aws.amazon.com/codepipeline/latest/userguide/action-reference.html) documentation.\n* `version` - (Required) A string that identifies the action type.\n* `configuration` - (Optional) A map of the action declaration's configuration. Configurations options for action types and providers can be found in the [Pipeline Structure Reference](http://docs.aws.amazon.com/codepipeline/latest/userguide/reference-pipeline-structure.html#action-requirements) and [Action Structure Reference](https://docs.aws.amazon.com/codepipeline/latest/userguide/action-reference.html) documentation.\n* `input_artifacts` - (Optional) A list of artifact names to be worked on.\n* `output_artifacts` - (Optional) A list of artifact names to output. Output artifact names must be unique within a pipeline.\n* `role_arn` - (Optional) The ARN of the IAM service role that will perform the declared action. This is assumed through the roleArn for the pipeline.\n* `run_order` - (Optional) The order in which actions are run.\n* `region` - (Optional) The region in which to run the action.\n* `namespace` - (Optional) The namespace all output variables will be accessed from.\n\n~> **Note:** The input artifact of an action must exactly match the output artifact declared in a preceding action, but the input artifact does not have to be the next action in strict sequence from the action that provided the output artifact. Actions in parallel can declare different output artifacts, which are in turn consumed by different following actions.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The codepipeline ID.\n* `arn` - The codepipeline ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodePipelines can be imported using the name, e.g.,\n\n```\n$ terraform import aws_codepipeline.foo example\n```\n",
    "basename": "codepipeline"
  },
  "codepipeline_webhook": {
    "subcategory": "CodePipeline",
    "layout": "aws",
    "page_title": "AWS: aws_codepipeline_webhook",
    "description": "Provides a CodePipeline Webhook",
    "preview": "# Resource: aws_codepipeline_webhook\n\nProvides a CodePipeline …",
    "content": "\n\n# Resource: aws_codepipeline_webhook\n\nProvides a CodePipeline Webhook.\n\n## Example Usage\n\n```terraform\nresource \"aws_codepipeline\" \"bar\" {\n  name     = \"tf-test-pipeline\"\n  role_arn = aws_iam_role.bar.arn\n\n  artifact_store {\n    location = aws_s3_bucket.bar.bucket\n    type     = \"S3\"\n\n    encryption_key {\n      id   = data.aws_kms_alias.s3kmskey.arn\n      type = \"KMS\"\n    }\n  }\n\n  stage {\n    name = \"Source\"\n\n    action {\n      name             = \"Source\"\n      category         = \"Source\"\n      owner            = \"ThirdParty\"\n      provider         = \"GitHub\"\n      version          = \"1\"\n      output_artifacts = [\"test\"]\n\n      configuration = {\n        Owner  = \"my-organization\"\n        Repo   = \"test\"\n        Branch = \"master\"\n      }\n    }\n  }\n\n  stage {\n    name = \"Build\"\n\n    action {\n      name            = \"Build\"\n      category        = \"Build\"\n      owner           = \"AWS\"\n      provider        = \"CodeBuild\"\n      input_artifacts = [\"test\"]\n      version         = \"1\"\n\n      configuration = {\n        ProjectName = \"test\"\n      }\n    }\n  }\n}\n\n# A shared secret between GitHub and AWS that allows AWS\n# CodePipeline to authenticate the request came from GitHub.\n# Would probably be better to pull this from the environment\n# or something like SSM Parameter Store.\nlocals {\n  webhook_secret = \"super-secret\"\n}\n\nresource \"aws_codepipeline_webhook\" \"bar\" {\n  name            = \"test-webhook-github-bar\"\n  authentication  = \"GITHUB_HMAC\"\n  target_action   = \"Source\"\n  target_pipeline = aws_codepipeline.bar.name\n\n  authentication_configuration {\n    secret_token = local.webhook_secret\n  }\n\n  filter {\n    json_path    = \"$.ref\"\n    match_equals = \"refs/heads/{Branch}\"\n  }\n}\n\n# Wire the CodePipeline webhook into a GitHub repository.\nresource \"github_repository_webhook\" \"bar\" {\n  repository = github_repository.repo.name\n\n  name = \"web\"\n\n  configuration {\n    url          = aws_codepipeline_webhook.bar.url\n    content_type = \"json\"\n    insecure_ssl = true\n    secret       = local.webhook_secret\n  }\n\n  events = [\"push\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the webhook.\n* `authentication` - (Required) The type of authentication  to use. One of `IP`, `GITHUB_HMAC`, or `UNAUTHENTICATED`.\n* `authentication_configuration` - (Optional) An `auth` block. Required for `IP` and `GITHUB_HMAC`. Auth blocks are documented below.\n* `filter` (Required) One or more `filter` blocks. Filter blocks are documented below.\n* `target_action` - (Required) The name of the action in a pipeline you want to connect to the webhook. The action must be from the source (first) stage of the pipeline.\n* `target_pipeline` - (Required) The name of the pipeline.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nAn `authentication_configuration` block supports the following arguments:\n\n* `secret_token` - (Optional) The shared secret for the GitHub repository webhook. Set this as `secret` in your `github_repository_webhook`'s `configuration` block. Required for `GITHUB_HMAC`.\n* `allowed_ip_range` - (Optional) A valid CIDR block for `IP` filtering. Required for `IP`.\n\nA `filter` block supports the following arguments:\n\n* `json_path` - (Required) The [JSON path](https://github.com/json-path/JsonPath) to filter on.\n* `match_equals` - (Required) The value to match on (e.g., `refs/heads/{Branch}`). See [AWS docs](https://docs.aws.amazon.com/codepipeline/latest/APIReference/API_WebhookFilterRule.html) for details.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The CodePipeline webhook's ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `url` - The CodePipeline webhook's URL. POST events to this endpoint to trigger the target.\n\n## Import\n\nCodePipeline Webhooks can be imported by their ARN, e.g.,\n\n```\n$ terraform import aws_codepipeline_webhook.example arn:aws:codepipeline:us-west-2:123456789012:webhook:example\n```\n",
    "basename": "codepipeline_webhook"
  },
  "codestarconnections_connection": {
    "subcategory": "CodeStar Connections",
    "layout": "aws",
    "page_title": "AWS: aws_codestarconnections_connection",
    "description": "Provides a CodeStar Connection",
    "preview": "# Resource: aws_codestarconnections_connection\n\nProvides a CodeStar …",
    "content": "\n\n# Resource: aws_codestarconnections_connection\n\nProvides a CodeStar Connection.\n\n~> **NOTE:** The `aws_codestarconnections_connection` resource is created in the state `PENDING`. Authentication with the connection provider must be completed in the AWS Console.\n\n## Example Usage\n\n```terraform\nresource \"aws_codestarconnections_connection\" \"example\" {\n  name          = \"example-connection\"\n  provider_type = \"Bitbucket\"\n}\n\nresource \"aws_codepipeline\" \"example\" {\n  name     = \"tf-test-pipeline\"\n  role_arn = aws_iam_role.codepipeline_role.arn\n\n  artifact_store {\n    # ...\n  }\n\n  stage {\n    name = \"Source\"\n    action {\n      name             = \"Source\"\n      category         = \"Source\"\n      owner            = \"AWS\"\n      provider         = \"CodeStarSourceConnection\"\n      version          = \"1\"\n      output_artifacts = [\"source_output\"]\n      configuration = {\n        ConnectionArn    = aws_codestarconnections_connection.example.arn\n        FullRepositoryId = \"my-organization/test\"\n        BranchName       = \"main\"\n      }\n    }\n  }\n\n  stage {\n    name = \"Build\"\n    action {\n      # ...\n    }\n  }\n\n  stage {\n    name = \"Deploy\"\n    action {\n      # ...\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the connection to be created. The name must be unique in the calling AWS account. Changing `name` will create a new resource.\n* `provider_type` - (Optional) The name of the external provider where your third-party code repository is configured. Valid values are `Bitbucket`, `GitHub` or `GitHubEnterpriseServer`. Changing `provider_type` will create a new resource. Conflicts with `host_arn`\n* `host_arn` - (Optional) The Amazon Resource Name (ARN) of the host associated with the connection. Conflicts with `provider_type`\n* `tags` - (Optional) Map of key-value resource tags to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The codestar connection ARN.\n* `arn` - The codestar connection ARN.\n* `connection_status` - The codestar connection status. Possible values are `PENDING`, `AVAILABLE` and `ERROR`.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeStar connections can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_codestarconnections_connection.test-connection arn:aws:codestar-connections:us-west-1:0123456789:connection/79d4d357-a2ee-41e4-b350-2fe39ae59448\n```\n",
    "basename": "codestarconnections_connection"
  },
  "codestarconnections_host": {
    "subcategory": "CodeStar Connections",
    "layout": "aws",
    "page_title": "AWS: aws_codestarconnections_host",
    "description": "Provides a CodeStar Host",
    "preview": "# Resource: aws_codestarconnections_host\n\nProvides a CodeStar Host.\n …",
    "content": "\n\n# Resource: aws_codestarconnections_host\n\nProvides a CodeStar Host.\n\n~> **NOTE:** The `aws_codestarconnections_host` resource is created in the state `PENDING`. Authentication with the host provider must be completed in the AWS Console. For more information visit [Set up a pending host](https://docs.aws.amazon.com/dtconsole/latest/userguide/connections-host-setup.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_codestarconnections_host\" \"example\" {\n  name              = \"example-host\"\n  provider_endpoint = \"https://example.com\"\n  provider_type     = \"GitHubEnterpriseServer\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the host to be created. The name must be unique in the calling AWS account.\n* `provider_endpoint` - (Required) The endpoint of the infrastructure to be represented by the host after it is created.\n* `provider_type` - (Required) The name of the external provider where your third-party code repository is configured.\n* `vpc_configuration` - (Optional) The VPC configuration to be provisioned for the host. A VPC must be configured, and the infrastructure to be represented by the host must already be connected to the VPC.\n\nA `vpc_configuration` block supports the following arguments:\n\n* `security_group_ids` - (Required) he ID of the security group or security groups associated with the Amazon VPC connected to the infrastructure where your provider type is installed.\n* `subnet_ids` - (Required) The ID of the subnet or subnets associated with the Amazon VPC connected to the infrastructure where your provider type is installed.\n* `tls_certificate` - (Optional) The value of the Transport Layer Security (TLS) certificate associated with the infrastructure where your provider type is installed.\n* `vpc_id` - (Required) The ID of the Amazon VPC connected to the infrastructure where your provider type is installed.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The CodeStar Host ARN.\n* `arn` - The CodeStar Host ARN.\n* `status` - The CodeStar Host status. Possible values are `PENDING`, `AVAILABLE`, `VPC_CONFIG_DELETING`, `VPC_CONFIG_INITIALIZING`, and `VPC_CONFIG_FAILED_INITIALIZATION`.\n\n## Import\n\nCodeStar Host can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_codestarconnections_host.example-host arn:aws:codestar-connections:us-west-1:0123456789:host/79d4d357-a2ee-41e4-b350-2fe39ae59448\n```\n",
    "basename": "codestarconnections_host"
  },
  "codestarnotifications_notification_rule": {
    "subcategory": "CodeStar Notifications",
    "layout": "aws",
    "page_title": "AWS: aws_codestarnotifications_notification_rule",
    "description": "Provides a CodeStar Notifications Rule",
    "preview": "# Resource: aws_codestarnotifications_notification_rule\n\nProvides a …",
    "content": "\n\n# Resource: aws_codestarnotifications_notification_rule\n\nProvides a CodeStar Notifications Rule.\n\n## Example Usage\n\n```terraform\nresource \"aws_codecommit_repository\" \"code\" {\n  repository_name = \"example-code-repo\"\n}\n\nresource \"aws_sns_topic\" \"notif\" {\n  name = \"notification\"\n}\n\ndata \"aws_iam_policy_document\" \"notif_access\" {\n  statement {\n    actions = [\"sns:Publish\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"codestar-notifications.amazonaws.com\"]\n    }\n\n    resources = [aws_sns_topic.notif.arn]\n  }\n}\n\nresource \"aws_sns_topic_policy\" \"default\" {\n  arn    = aws_sns_topic.notif.arn\n  policy = data.aws_iam_policy_document.notif_access.json\n}\n\nresource \"aws_codestarnotifications_notification_rule\" \"commits\" {\n  detail_type    = \"BASIC\"\n  event_type_ids = [\"codecommit-repository-comments-on-commits\"]\n\n  name     = \"example-code-repo-commits\"\n  resource = aws_codecommit_repository.code.arn\n\n  target {\n    address = aws_sns_topic.notif.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `detail_type` - (Required) The level of detail to include in the notifications for this resource. Possible values are `BASIC` and `FULL`.\n* `event_type_ids` - (Required) A list of event types associated with this notification rule.\n  For list of allowed events see [here](https://docs.aws.amazon.com/codestar-notifications/latest/userguide/concepts.html#concepts-api).\n* `name` - (Required) The name of notification rule.\n* `resource` - (Required) The ARN of the resource to associate with the notification rule.\n* `status` - (Optional) The status of the notification rule. Possible values are `ENABLED` and `DISABLED`, default is `ENABLED`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `target` - (Optional) Configuration blocks containing notification target information. Can be specified multiple times. At least one target must be specified on creation.\n\nAn `target` block supports the following arguments:\n\n* `address` - (Required) The ARN of notification rule target. For example, a SNS Topic ARN.\n* `type` - (Optional) The type of the notification target. Default value is `SNS`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The codestar notification rule ARN.\n* `arn` - The codestar notification rule ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCodeStar notification rule can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_codestarnotifications_notification_rule.foo arn:aws:codestar-notifications:us-west-1:0123456789:notificationrule/2cdc68a3-8f7c-4893-b6a5-45b362bd4f2b\n```\n",
    "basename": "codestarnotifications_notification_rule"
  },
  "cognito_identity_pool": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_identity_pool",
    "description": "Provides an AWS Cognito Identity Pool.",
    "preview": "# Resource: aws_cognito_identity_pool\n\nProvides an AWS Cognito …",
    "content": "\n\n# Resource: aws_cognito_identity_pool\n\nProvides an AWS Cognito Identity Pool.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_saml_provider\" \"default\" {\n  name                   = \"my-saml-provider\"\n  saml_metadata_document = file(\"saml-metadata.xml\")\n}\n\nresource \"aws_cognito_identity_pool\" \"main\" {\n  identity_pool_name               = \"identity pool\"\n  allow_unauthenticated_identities = false\n  allow_classic_flow               = false\n\n  cognito_identity_providers {\n    client_id               = \"6lhlkkfbfb4q5kpp90urffae\"\n    provider_name           = \"cognito-idp.us-east-1.amazonaws.com/us-east-1_Tv0493apJ\"\n    server_side_token_check = false\n  }\n\n  cognito_identity_providers {\n    client_id               = \"7kodkvfqfb4qfkp39eurffae\"\n    provider_name           = \"cognito-idp.us-east-1.amazonaws.com/eu-west-1_Zr231apJu\"\n    server_side_token_check = false\n  }\n\n  supported_login_providers = {\n    \"graph.facebook.com\"  = \"7346241598935552\"\n    \"accounts.google.com\" = \"123456789012.apps.googleusercontent.com\"\n  }\n\n  saml_provider_arns           = [aws_iam_saml_provider.default.arn]\n  openid_connect_provider_arns = [\"arn:aws:iam::123456789012:oidc-provider/id.example.com\"]\n}\n```\n\n## Argument Reference\n\nThe Cognito Identity Pool argument layout is a structure composed of several sub-resources - these resources are laid out below.\n\n* `identity_pool_name` (Required) - The Cognito Identity Pool name.\n* `allow_unauthenticated_identities` (Required) - Whether the identity pool supports unauthenticated logins or not.\n* `allow_classic_flow` (Optional) - Enables or disables the classic / basic authentication flow. Default is `false`.\n* `developer_provider_name` (Optional) - The \"domain\" by which Cognito will refer to your users. This name acts as a placeholder that allows your\nbackend and the Cognito service to communicate about the developer provider.\n* `cognito_identity_providers` (Optional) - An array of [Amazon Cognito Identity user pools](#cognito-identity-providers) and their client IDs.\n* `openid_connect_provider_arns` (Optional) - Set of OpendID Connect provider ARNs.\n* `saml_provider_arns` (Optional) - An array of Amazon Resource Names (ARNs) of the SAML provider for your identity.\n* `supported_login_providers` (Optional) - Key-Value pairs mapping provider names to provider app IDs.\n* `tags` - (Optional) A map of tags to assign to the Identity Pool. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n#### Cognito Identity Providers\n\n* `client_id` (Optional) - The client ID for the Amazon Cognito Identity User Pool.\n* `provider_name` (Optional) - The provider name for an Amazon Cognito Identity User Pool.\n* `server_side_token_check` (Optional) - Whether server-side token validation is enabled for the identity provider’s token or not.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - An identity pool ID in the format REGION:GUID.\n* `arn` - The ARN of the identity pool.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCognito Identity Pool can be imported using the name, e.g.,\n\n```\n$ terraform import aws_cognito_identity_pool.mypool <identity-pool-id>\n```\n",
    "basename": "cognito_identity_pool"
  },
  "cognito_identity_pool_roles_attachment": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_identity_pool_roles_attachment",
    "description": "Provides an AWS Cognito Identity Pool Roles Attachment.",
    "preview": "# Resource: aws_cognito_identity_pool_roles_attachment\n\nProvides an …",
    "content": "\n\n# Resource: aws_cognito_identity_pool_roles_attachment\n\nProvides an AWS Cognito Identity Pool Roles Attachment.\n\n## Example Usage\n\n```terraform\nresource \"aws_cognito_identity_pool\" \"main\" {\n  identity_pool_name               = \"identity pool\"\n  allow_unauthenticated_identities = false\n\n  supported_login_providers = {\n    \"graph.facebook.com\" = \"7346241598935555\"\n  }\n}\n\nresource \"aws_iam_role\" \"authenticated\" {\n  name = \"cognito_authenticated\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Federated\": \"cognito-identity.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"cognito-identity.amazonaws.com:aud\": \"${aws_cognito_identity_pool.main.id}\"\n        },\n        \"ForAnyValue:StringLike\": {\n          \"cognito-identity.amazonaws.com:amr\": \"authenticated\"\n        }\n      }\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"authenticated\" {\n  name = \"authenticated_policy\"\n  role = aws_iam_role.authenticated.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"mobileanalytics:PutEvents\",\n        \"cognito-sync:*\",\n        \"cognito-identity:*\"\n      ],\n      \"Resource\": [\n        \"*\"\n      ]\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_cognito_identity_pool_roles_attachment\" \"main\" {\n  identity_pool_id = aws_cognito_identity_pool.main.id\n\n  role_mapping {\n    identity_provider         = \"graph.facebook.com\"\n    ambiguous_role_resolution = \"AuthenticatedRole\"\n    type                      = \"Rules\"\n\n    mapping_rule {\n      claim      = \"isAdmin\"\n      match_type = \"Equals\"\n      role_arn   = aws_iam_role.authenticated.arn\n      value      = \"paid\"\n    }\n  }\n\n  roles = {\n    \"authenticated\" = aws_iam_role.authenticated.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe Cognito Identity Pool Roles Attachment argument layout is a structure composed of several sub-resources - these resources are laid out below.\n\n* `identity_pool_id` (Required) - An identity pool ID in the format REGION:GUID.\n* `role_mapping` (Optional) - A List of [Role Mapping](#role-mappings).\n* `roles` (Required) - The map of roles associated with this pool. For a given role, the key will be either \"authenticated\" or \"unauthenticated\" and the value will be the Role ARN.\n\n#### Role Mappings\n\n* `identity_provider` (Required) - A string identifying the identity provider, for example, \"graph.facebook.com\" or \"cognito-idp.us-east-1.amazonaws.com/us-east-1_abcdefghi:app_client_id\". Depends on `cognito_identity_providers` set on `aws_cognito_identity_pool` resource or a `aws_cognito_identity_provider` resource.\n* `ambiguous_role_resolution` (Optional) - Specifies the action to be taken if either no rules match the claim value for the Rules type, or there is no cognito:preferred_role claim and there are multiple cognito:roles matches for the Token type. `Required` if you specify Token or Rules as the Type.\n* `mapping_rule` (Optional) - The [Rules Configuration](#rules-configuration) to be used for mapping users to roles. You can specify up to 25 rules per identity provider. Rules are evaluated in order. The first one to match specifies the role.\n* `type` (Required) - The role mapping type.\n\n#### Rules Configuration\n\n* `claim` (Required) - The claim name that must be present in the token, for example, \"isAdmin\" or \"paid\".\n* `match_type` (Required) - The match condition that specifies how closely the claim value in the IdP token must match Value.\n* `role_arn` (Required) - The role ARN.\n* `value` (Required) - A brief string that the claim must match, for example, \"paid\" or \"yes\".\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identity pool ID.\n* `identity_pool_id` (Required) - An identity pool ID in the format REGION:GUID.\n* `role_mapping` (Optional) - The List of [Role Mapping](#role-mappings).\n* `roles` (Required) - The map of roles associated with this pool. For a given role, the key will be either \"authenticated\" or \"unauthenticated\" and the value will be the Role ARN.\n\n## Import\n\nCognito Identity Pool Roles Attachment can be imported using the Identity Pool id, e.g.,\n\n```\n$ terraform import aws_cognito_identity_pool_roles_attachment.example <identity-pool-id>\n```\n",
    "basename": "cognito_identity_pool_roles_attachment"
  },
  "cognito_identity_provider.html": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_identity_provider",
    "side_bar_current": "docs-aws-resource-cognito-identity-provider",
    "description": "Provides a Cognito User Identity Provider resource.",
    "preview": "# Resource: aws_cognito_identity_provider\n\nProvides a Cognito User …",
    "content": "\n\n# Resource: aws_cognito_identity_provider\n\nProvides a Cognito User Identity Provider resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cognito_user_pool\" \"example\" {\n  name                     = \"example-pool\"\n  auto_verified_attributes = [\"email\"]\n}\n\nresource \"aws_cognito_identity_provider\" \"example_provider\" {\n  user_pool_id  = aws_cognito_user_pool.example.id\n  provider_name = \"Google\"\n  provider_type = \"Google\"\n\n  provider_details = {\n    authorize_scopes = \"email\"\n    client_id        = \"your client_id\"\n    client_secret    = \"your client_secret\"\n  }\n\n  attribute_mapping = {\n    email    = \"email\"\n    username = \"sub\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `user_pool_id` (Required) - The user pool id\n* `provider_name` (Required) - The provider name\n* `provider_type` (Required) - The provider type.  [See AWS API for valid values](https://docs.aws.amazon.com/cognito-user-identity-pools/latest/APIReference/API_CreateIdentityProvider.html#CognitoUserPools-CreateIdentityProvider-request-ProviderType)\n* `attribute_mapping` (Optional) - The map of attribute mapping of user pool attributes. [AttributeMapping in AWS API documentation](https://docs.aws.amazon.com/cognito-user-identity-pools/latest/APIReference/API_CreateIdentityProvider.html#CognitoUserPools-CreateIdentityProvider-request-AttributeMapping)\n* `idp_identifiers` (Optional) - The list of identity providers.\n* `provider_details` (Optional) - The map of identity details, such as access token\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_cognito_identity_provider` resources can be imported using their User Pool ID and Provider Name, e.g.,\n\n```\n$ terraform import aws_cognito_identity_provider.example xxx_yyyyy:example\n```\n",
    "basename": "cognito_identity_provider.html"
  },
  "cognito_resource_server": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_resource_server",
    "side_bar_current": "docs-aws-resource-cognito-resource-server",
    "description": "Provides a Cognito Resource Server.",
    "preview": "# Resource: aws_cognito_resource_server\n\nProvides a Cognito Resource …",
    "content": "\n\n# Resource: aws_cognito_resource_server\n\nProvides a Cognito Resource Server.\n\n## Example Usage\n\n### Create a basic resource server\n\n```terraform\nresource \"aws_cognito_user_pool\" \"pool\" {\n  name = \"pool\"\n}\n\nresource \"aws_cognito_resource_server\" \"resource\" {\n  identifier = \"https://example.com\"\n  name       = \"example\"\n\n  user_pool_id = aws_cognito_user_pool.pool.id\n}\n```\n\n### Create a resource server with sample-scope\n\n```terraform\nresource \"aws_cognito_user_pool\" \"pool\" {\n  name = \"pool\"\n}\n\nresource \"aws_cognito_resource_server\" \"resource\" {\n  identifier = \"https://example.com\"\n  name       = \"example\"\n\n  scope {\n    scope_name        = \"sample-scope\"\n    scope_description = \"a Sample Scope Description\"\n  }\n\n  user_pool_id = aws_cognito_user_pool.pool.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `identifier` - (Required) An identifier for the resource server.\n* `name` - (Required) A name for the resource server.\n* `scope` - (Optional) A list of [Authorization Scope](#authorization_scope).\n\n### Authorization Scope\n\n* `scope_name` - (Required) The scope name.\n* `scope_description` - (Required) The scope description.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `scope_identifiers` - A list of all scopes configured for this resource server in the format identifier/scope_name.\n\n## Import\n\n`aws_cognito_resource_server` can be imported using their User Pool ID and Identifier, e.g.,\n\n```\n$ terraform import aws_cognito_resource_server.example xxx_yyyyy|https://example.com\n```\n",
    "basename": "cognito_resource_server"
  },
  "cognito_user_group.html": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_user_group",
    "description": "Provides a Cognito User Group resource.",
    "preview": "# Resource: aws_cognito_user_group\n\nProvides a Cognito User Group …",
    "content": "\n\n# Resource: aws_cognito_user_group\n\nProvides a Cognito User Group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cognito_user_pool\" \"main\" {\n  name = \"identity pool\"\n}\n\nresource \"aws_iam_role\" \"group_role\" {\n  name = \"user-group-role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Federated\": \"cognito-identity.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"cognito-identity.amazonaws.com:aud\": \"us-east-1:12345678-dead-beef-cafe-123456790ab\"\n        },\n        \"ForAnyValue:StringLike\": {\n          \"cognito-identity.amazonaws.com:amr\": \"authenticated\"\n        }\n      }\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_cognito_user_group\" \"main\" {\n  name         = \"user-group\"\n  user_pool_id = aws_cognito_user_pool.main.id\n  description  = \"Managed by Terraform\"\n  precedence   = 42\n  role_arn     = aws_iam_role.group_role.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the user group.\n* `user_pool_id` - (Required) The user pool ID.\n* `description` - (Optional) The description of the user group.\n* `precedence` - (Optional) The precedence of the user group.\n* `role_arn` - (Optional) The ARN of the IAM role to be associated with the user group.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nCognito User Groups can be imported using the `user_pool_id`/`name` attributes concatenated, e.g.,\n\n```\n$ terraform import aws_cognito_user_group.group us-east-1_vG78M4goG/user-group\n```\n",
    "basename": "cognito_user_group.html"
  },
  "cognito_user_pool": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_user_pool",
    "description": "Provides a Cognito User Pool resource.",
    "preview": "# Resource: aws_cognito_user_pool\n\nProvides a Cognito User Pool …",
    "content": "\n\n# Resource: aws_cognito_user_pool\n\nProvides a Cognito User Pool resource.\n\n## Example Usage\n\n### Basic configuration\n\n```terraform\nresource \"aws_cognito_user_pool\" \"pool\" {\n  name = \"mypool\"\n}\n```\n\n### Enabling SMS and Software Token Multi-Factor Authentication\n\n```terraform\nresource \"aws_cognito_user_pool\" \"example\" {\n  # ... other configuration ...\n\n  mfa_configuration          = \"ON\"\n  sms_authentication_message = \"Your code is {####}\"\n\n  sms_configuration {\n    external_id    = \"example\"\n    sns_caller_arn = aws_iam_role.example.arn\n  }\n\n  software_token_mfa_configuration {\n    enabled = true\n  }\n}\n```\n\n### Using Account Recovery Setting\n\n```terraform\nresource \"aws_cognito_user_pool\" \"test\" {\n  name = \"mypool\"\n\n  account_recovery_setting {\n    recovery_mechanism {\n      name     = \"verified_email\"\n      priority = 1\n    }\n\n    recovery_mechanism {\n      name     = \"verified_phone_number\"\n      priority = 2\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following argument is required:\n\n* `name` - (Required) Name of the user pool.\n\nThe following arguments are optional:\n\n* `account_recovery_setting` - (Optional) Configuration block to define which verified available method a user can use to recover their forgotten password. [Detailed below](#account_recovery_setting).\n* `admin_create_user_config` - (Optional) Configuration block for creating a new user profile. [Detailed below](#admin_create_user_config).\n* `alias_attributes` - (Optional) Attributes supported as an alias for this user pool. Valid values: `phone_number`, `email`, or `preferred_username`. Conflicts with `username_attributes`.\n* `auto_verified_attributes` - (Optional) Attributes to be auto-verified. Valid values: `email`, `phone_number`.\n* `device_configuration` - (Optional) Configuration block for the user pool's device tracking. [Detailed below](#device_configuration).\n* `email_configuration` - (Optional) Configuration block for configuring email. [Detailed below](#email_configuration).\n* `email_verification_message` - (Optional) String representing the email verification message. Conflicts with `verification_message_template` configuration block `email_message` argument.\n* `email_verification_subject` - (Optional) String representing the email verification subject. Conflicts with `verification_message_template` configuration block `email_subject` argument.\n* `lambda_config` - (Optional) Configuration block for the AWS Lambda triggers associated with the user pool. [Detailed below](#lambda_configuration).\n* `mfa_configuration` - (Optional) Multi-Factor Authentication (MFA) configuration for the User Pool. Defaults of `OFF`. Valid values are `OFF` (MFA Tokens are not required), `ON` (MFA is required for all users to sign in; requires at least one of `sms_configuration` or `software_token_mfa_configuration` to be configured), or `OPTIONAL` (MFA Will be required only for individual users who have MFA Enabled; requires at least one of `sms_configuration` or `software_token_mfa_configuration` to be configured).\n* `password_policy` - (Optional) Configuration blocked for information about the user pool password policy. [Detailed below](#password_policy).\n* `schema` - (Optional) Configuration block for the schema attributes of a user pool. [Detailed below](#schema). Schema attributes from the [standard attribute set](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html#cognito-user-pools-standard-attributes) only need to be specified if they are different from the default configuration. Attributes can be added, but not modified or removed. Maximum of 50 attributes.\n* `sms_authentication_message` - (Optional) String representing the SMS authentication message. The Message must contain the `{####}` placeholder, which will be replaced with the code.\n* `sms_configuration` - (Optional) Configuration block for Short Message Service (SMS) settings. [Detailed below](#sms_configuration). These settings apply to SMS user verification and SMS Multi-Factor Authentication (MFA). Due to Cognito API restrictions, the SMS configuration cannot be removed without recreating the Cognito User Pool. For user data safety, this resource will ignore the removal of this configuration by disabling drift detection. To force resource recreation after this configuration has been applied, see the [`taint` command](https://www.terraform.io/docs/commands/taint.html).\n* `sms_verification_message` - (Optional) String representing the SMS verification message. Conflicts with `verification_message_template` configuration block `sms_message` argument.\n* `software_token_mfa_configuration` - (Optional) Configuration block for software token Mult-Factor Authentication (MFA) settings. [Detailed below](#software_token_mfa_configuration).\n* `tags` - (Optional) Map of tags to assign to the User Pool. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `user_pool_add_ons` - (Optional) Configuration block for user pool add-ons to enable user pool advanced security mode features. [Detailed below](#user_pool_add_ons).\n* `username_attributes` - (Optional) Whether email addresses or phone numbers can be specified as usernames when a user signs up. Conflicts with `alias_attributes`.\n* `username_configuration` - (Optional) Configuration block for username configuration. [Detailed below](#username_configuration).\n* `verification_message_template` - (Optional) Configuration block for verification message templates. [Detailed below](#verification_message_template).\n\n### account_recovery_setting\n\n* `recovery_mechanism` - (Required) List of Account Recovery Options of the following structure:\n    * `name` - (Required) Recovery method for a user. Can be of the following: `verified_email`, `verified_phone_number`, and `admin_only`.\n    * `priority` - (Required) Positive integer specifying priority of a method with 1 being the highest priority.\n\n### admin_create_user_config\n\n* `allow_admin_create_user_only` - (Optional) Set to True if only the administrator is allowed to create user profiles. Set to False if users can sign themselves up via an app.\n* `invite_message_template` - (Optional) Invite message template structure. [Detailed below](#invite_message_template).\n\n#### invite_message_template\n\n* `email_message` - (Optional) Message template for email messages. Must contain `{username}` and `{####}` placeholders, for username and temporary password, respectively.\n* `email_subject` - (Optional) Subject line for email messages.\n* `sms_message` - (Optional) Message template for SMS messages. Must contain `{username}` and `{####}` placeholders, for username and temporary password, respectively.\n\n### device_configuration\n\n* `challenge_required_on_new_device` - (Optional) Whether a challenge is required on a new device. Only applicable to a new device.\n* `device_only_remembered_on_user_prompt` - (Optional) Whether a device is only remembered on user prompt. `false` equates to \"Always\" remember, `true` is \"User Opt In,\" and not using a `device_configuration` block is \"No.\"\n\n### email_configuration\n\n* `configuration_set` - (Optional) Email configuration set name from SES.\n* `email_sending_account` - (Optional) Email delivery method to use. `COGNITO_DEFAULT` for the default email functionality built into Cognito or `DEVELOPER` to use your Amazon SES configuration.\n* `from_email_address` - (Optional) Sender’s email address or sender’s display name with their email address (e.g., `john@example.com`, `John Smith <john@example.com>` or `\\\"John Smith Ph.D.\\\" <john@example.com>`). Escaped double quotes are required around display names that contain certain characters as specified in [RFC 5322](https://tools.ietf.org/html/rfc5322).\n* `reply_to_email_address` - (Optional) REPLY-TO email address.\n* `source_arn` - (Optional) ARN of the SES verified email identity to to use. Required if `email_sending_account` is set to `DEVELOPER`.\n\n### lambda_config\n\n* `create_auth_challenge` - (Optional) ARN of the lambda creating an authentication challenge.\n* `custom_message` - (Optional) Custom Message AWS Lambda trigger.\n* `define_auth_challenge` - (Optional) Defines the authentication challenge.\n* `post_authentication` - (Optional) Post-authentication AWS Lambda trigger.\n* `post_confirmation` - (Optional) Post-confirmation AWS Lambda trigger.\n* `pre_authentication` - (Optional) Pre-authentication AWS Lambda trigger.\n* `pre_sign_up` - (Optional) Pre-registration AWS Lambda trigger.\n* `pre_token_generation` - (Optional) Allow to customize identity token claims before token generation.\n* `user_migration` - (Optional) User migration Lambda config type.\n* `verify_auth_challenge_response` - (Optional) Verifies the authentication challenge response.\n* `kms_key_id` - (Optional) The Amazon Resource Name of Key Management Service Customer master keys. Amazon Cognito uses the key to encrypt codes and temporary passwords sent to CustomEmailSender and CustomSMSSender.\n* `custom_email_sender` - (Optional) A custom email sender AWS Lambda trigger. See [custom_email_sender](#custom_email_sender) Below.\n* `custom_sms_sender` - (Optional) A custom SMS sender AWS Lambda trigger. See [custom_sms_sender](#custom_sms_sender) Below.\n\n#### custom_email_sender\n\n* `lambda_arn` - (Required) The Lambda Amazon Resource Name of the Lambda function that Amazon Cognito triggers to send email notifications to users.\n* `lambda_version` - (Required) The Lambda version represents the signature of the \"request\" attribute in the \"event\" information Amazon Cognito passes to your custom email Lambda function. The only supported value is `V1_0`.\n\n#### custom_sms_sender\n\n* `lambda_arn` - (Required) The Lambda Amazon Resource Name of the Lambda function that Amazon Cognito triggers to send SMS notifications to users.\n* `lambda_version` - (Required) The Lambda version represents the signature of the \"request\" attribute in the \"event\" information Amazon Cognito passes to your custom SMS Lambda function. The only supported value is `V1_0`.\n\n### password_policy\n\n* `minimum_length` - (Optional) Minimum length of the password policy that you have set.\n* `require_lowercase` - (Optional) Whether you have required users to use at least one lowercase letter in their password.\n* `require_numbers` - (Optional) Whether you have required users to use at least one number in their password.\n* `require_symbols` - (Optional) Whether you have required users to use at least one symbol in their password.\n* `require_uppercase` - (Optional) Whether you have required users to use at least one uppercase letter in their password.\n* `temporary_password_validity_days` - (Optional) In the password policy you have set, refers to the number of days a temporary password is valid. If the user does not sign-in during this time, their password will need to be reset by an administrator.\n\n### schema\n\n~> **NOTE:** When defining an `attribute_data_type` of `String` or `Number`, the respective attribute constraints configuration block (e.g `string_attribute_constraints` or `number_attribute_constraints`) is **required** to prevent recreation of the Terraform resource. This requirement is true for both standard (e.g., name, email) and custom schema attributes.\n\n* `attribute_data_type` - (Required) Attribute data type. Must be one of `Boolean`, `Number`, `String`, `DateTime`.\n* `developer_only_attribute` - (Optional) Whether the attribute type is developer only.\n* `mutable` - (Optional) Whether the attribute can be changed once it has been created.\n* `name` - (Required) Name of the attribute.\n* `number_attribute_constraints` - (Required when `attribute_data_type` is `Number`) Configuration block for the constraints for an attribute of the number type. [Detailed below](#number_attribute_constraints).\n* `required` - (Optional) Whether a user pool attribute is required. If the attribute is required and the user does not provide a value, registration or sign-in will fail.\n* `string_attribute_constraints` - (Required when `attribute_data_type` is `String`) Constraints for an attribute of the string type. [Detailed below](#string_attribute_constraints).\n\n#### schema: Defaults for Standard Attributes\n\nThe [standard attributes](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html#cognito-user-pools-standard-attributes) have the following defaults. Note that attributes which match the default values are not stored in Terraform state when importing.\n\n```terraform\nresource \"aws_cognito_user_pool\" \"example\" {\n  # ... other configuration ...\n\n  schema {\n    name                     = \"<name>\"\n    attribute_data_type      = \"<appropriate type>\"\n    developer_only_attribute = false\n    mutable                  = true  # false for \"sub\"\n    required                 = false # true for \"sub\"\n    string_attribute_constraints {   # if it is a string\n      min_length = 0                 # 10 for \"birthdate\"\n      max_length = 2048              # 10 for \"birthdate\"\n    }\n  }\n}\n```\n\n#### number_attribute_constraints\n\n* `max_value` - (Optional) Maximum value of an attribute that is of the number data type.\n* `min_value` - (Optional) Minimum value of an attribute that is of the number data type.\n\n#### string_attribute_constraints\n\n* `max_length` - (Optional) Maximum length of an attribute value of the string type.\n* `min_length` - (Optional) Minimum length of an attribute value of the string type.\n\n### sms_configuration\n\n* `external_id` - (Required) External ID used in IAM role trust relationships. For more information about using external IDs, see [How to Use an External ID When Granting Access to Your AWS Resources to a Third Party](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html).\n* `sns_caller_arn` - (Required) ARN of the Amazon SNS caller. This is usually the IAM role that you've given Cognito permission to assume.\n\n### software_token_mfa_configuration\n\nThe following arguments are required in the `software_token_mfa_configuration` configuration block:\n\n* `enabled` - (Required) Boolean whether to enable software token Multi-Factor (MFA) tokens, such as Time-based One-Time Password (TOTP). To disable software token MFA When `sms_configuration` is not present, the `mfa_configuration` argument must be set to `OFF` and the `software_token_mfa_configuration` configuration block must be fully removed.\n\n### user_pool_add_ons\n\n* `advanced_security_mode` - (Required) Mode for advanced security, must be one of `OFF`, `AUDIT` or `ENFORCED`.\n\n### username_configuration\n\n* `case_sensitive` - (Required) Whether username case sensitivity will be applied for all users in the user pool through Cognito APIs.\n\n### verification_message_template\n\n* `default_email_option` - (Optional) Default email option. Must be either `CONFIRM_WITH_CODE` or `CONFIRM_WITH_LINK`. Defaults to `CONFIRM_WITH_CODE`.\n* `email_message` - (Optional) Email message template. Must contain the `{####}` placeholder. Conflicts with `email_verification_message` argument.\n* `email_message_by_link` - (Optional) Email message template for sending a confirmation link to the user, it must contain the `{##Click Here##}` placeholder.\n* `email_subject` - (Optional) Subject line for the email message template. Conflicts with `email_verification_subject` argument.\n* `email_subject_by_link` - (Optional) Subject line for the email message template for sending a confirmation link to the user.\n* `sms_message` - (Optional) SMS message template. Must contain the `{####}` placeholder. Conflicts with `sms_verification_message` argument.\n  \n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the user pool.\n* `creation_date` - Date the user pool was created.\n* `custom_domain` - A custom domain name that you provide to Amazon Cognito. This parameter applies only if you use a custom domain to host the sign-up and sign-in pages for your application. For example: `auth.example.com`.\n* `domain` - Holds the domain prefix if the user pool has a domain associated with it.\n* `endpoint` - Endpoint name of the user pool. Example format: `cognito-idp.REGION.amazonaws.com/xxxx_yyyyy`\n* `estimated_number_of_users` - A number estimating the size of the user pool.\n* `id` - ID of the user pool.\n* `last_modified_date` - Date the user pool was last modified.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCognito User Pools can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_cognito_user_pool.pool <id>\n```\n",
    "basename": "cognito_user_pool"
  },
  "cognito_user_pool_client": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_user_pool_client",
    "description": "Provides a Cognito User Pool Client resource.",
    "preview": "# Resource: aws_cognito_user_pool_client\n\nProvides a Cognito User …",
    "content": "\n\n# Resource: aws_cognito_user_pool_client\n\nProvides a Cognito User Pool Client resource.\n\n## Example Usage\n\n### Create a basic user pool client\n\n```terraform\nresource \"aws_cognito_user_pool\" \"pool\" {\n  name = \"pool\"\n}\n\nresource \"aws_cognito_user_pool_client\" \"client\" {\n  name = \"client\"\n\n  user_pool_id = aws_cognito_user_pool.pool.id\n}\n```\n\n### Create a user pool client with no SRP authentication\n\n```terraform\nresource \"aws_cognito_user_pool\" \"pool\" {\n  name = \"pool\"\n}\n\nresource \"aws_cognito_user_pool_client\" \"client\" {\n  name = \"client\"\n\n  user_pool_id = aws_cognito_user_pool.pool.id\n\n  generate_secret     = true\n  explicit_auth_flows = [\"ADMIN_NO_SRP_AUTH\"]\n}\n```\n\n### Create a user pool client with pinpoint analytics\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_cognito_user_pool\" \"test\" {\n  name = \"pool\"\n}\n\nresource \"aws_pinpoint_app\" \"test\" {\n  name = \"pinpoint\"\n}\n\nresource \"aws_iam_role\" \"test\" {\n  name = \"role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"cognito-idp.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"test\" {\n  name = \"role_policy\"\n  role = aws_iam_role.test.id\n\n  policy = <<-EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"mobiletargeting:UpdateEndpoint\",\n        \"mobiletargeting:PutItems\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"arn:aws:mobiletargeting:*:${data.aws_caller_identity.current.account_id}:apps/${aws_pinpoint_app.test.application_id}*\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_cognito_user_pool_client\" \"test\" {\n  name         = \"pool_client\"\n  user_pool_id = aws_cognito_user_pool.test.id\n\n  analytics_configuration {\n    application_id   = aws_pinpoint_app.test.application_id\n    external_id      = \"some_id\"\n    role_arn         = aws_iam_role.test.arn\n    user_data_shared = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the application client.\n* `user_pool_id` - (Required) User pool the client belongs to.\n\nThe following arguments are optional:\n\n* `access_token_validity` - (Optional) Time limit, between 5 minutes and 1 day, after which the access token is no longer valid and cannot be used. This value will be overridden if you have entered a value in `token_validity_units`.\n* `allowed_oauth_flows_user_pool_client` - (Optional) Whether the client is allowed to follow the OAuth protocol when interacting with Cognito user pools.\n* `allowed_oauth_flows` - (Optional) List of allowed OAuth flows (code, implicit, client_credentials).\n* `allowed_oauth_scopes` - (Optional) List of allowed OAuth scopes (phone, email, openid, profile, and aws.cognito.signin.user.admin).\n* `analytics_configuration` - (Optional) Configuration block for Amazon Pinpoint analytics for collecting metrics for this user pool. [Detailed below](#analytics_configuration).\n* `callback_urls` - (Optional) List of allowed callback URLs for the identity providers.\n* `default_redirect_uri` - (Optional) Default redirect URI. Must be in the list of callback URLs.\n* `enable_token_revocation` - (Optional) Enables or disables token revocation.\n* `explicit_auth_flows` - (Optional) List of authentication flows (ADMIN_NO_SRP_AUTH, CUSTOM_AUTH_FLOW_ONLY, USER_PASSWORD_AUTH, ALLOW_ADMIN_USER_PASSWORD_AUTH, ALLOW_CUSTOM_AUTH, ALLOW_USER_PASSWORD_AUTH, ALLOW_USER_SRP_AUTH, ALLOW_REFRESH_TOKEN_AUTH).\n* `generate_secret` - (Optional) Should an application secret be generated.\n* `id_token_validity` - (Optional) Time limit, between 5 minutes and 1 day, after which the ID token is no longer valid and cannot be used. This value will be overridden if you have entered a value in `token_validity_units`.\n* `logout_urls` - (Optional) List of allowed logout URLs for the identity providers.\n* `prevent_user_existence_errors` - (Optional) Choose which errors and responses are returned by Cognito APIs during authentication, account confirmation, and password recovery when the user does not exist in the user pool. When set to `ENABLED` and the user does not exist, authentication returns an error indicating either the username or password was incorrect, and account confirmation and password recovery return a response indicating a code was sent to a simulated destination. When set to `LEGACY`, those APIs will return a `UserNotFoundException` exception if the user does not exist in the user pool.\n* `read_attributes` - (Optional) List of user pool attributes the application client can read from.\n* `refresh_token_validity` - (Optional) Time limit in days refresh tokens are valid for.\n* `supported_identity_providers` - (Optional) List of provider names for the identity providers that are supported on this client. Uses the `provider_name` attribute of `aws_cognito_identity_provider` resource(s), or the equivalent string(s).\n* `token_validity_units` - (Optional) Configuration block for units in which the validity times are represented in. [Detailed below](#token_validity_units).\n* `write_attributes` - (Optional) List of user pool attributes the application client can write to.\n\n### analytics_configuration\n\nEither `application_arn` or `application_id` is required.\n\n* `application_arn` - (Optional) Application ARN for an Amazon Pinpoint application. Conflicts with `external_id` and `role_arn`.\n* `application_id` - (Optional) Application ID for an Amazon Pinpoint application.\n* `external_id` - (Optional) ID for the Analytics Configuration. Conflicts with `application_arn`.\n* `role_arn` - (Optional) ARN of an IAM role that authorizes Amazon Cognito to publish events to Amazon Pinpoint analytics. Conflicts with `application_arn`.\n* `user_data_shared` (Optional) If set to `true`, Amazon Cognito will include user data in the events it publishes to Amazon Pinpoint analytics.\n\n### token_validity_units\n\nValid values for the following arguments are: `seconds`, `minutes`, `hours` or `days`.\n\n* `access_token` - (Optional) Time unit in for the value in `access_token_validity`, defaults to `hours`.\n* `id_token` - (Optional) Time unit in for the value in `id_token_validity`, defaults to `hours`.\n* `refresh_token` - (Optional) Time unit in for the value in `refresh_token_validity`, defaults to `days`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `client_secret` - Client secret of the user pool client.\n* `id` - ID of the user pool client.\n\n## Import\n\nCognito User Pool Clients can be imported using the `id` of the Cognito User Pool, and the `id` of the Cognito User Pool Client, e.g.,\n\n```\n$ terraform import aws_cognito_user_pool_client.client <user_pool_id>/<user_pool_client_id>\n```\n",
    "basename": "cognito_user_pool_client"
  },
  "cognito_user_pool_domain": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_user_pool_domain",
    "description": "Provides a Cognito User Pool Domain resource.",
    "preview": "# Resource: aws_cognito_user_pool_domain\n\nProvides a Cognito User …",
    "content": "\n\n# Resource: aws_cognito_user_pool_domain\n\nProvides a Cognito User Pool Domain resource.\n\n## Example Usage\n\n### Amazon Cognito domain\n\n```terraform\nresource \"aws_cognito_user_pool_domain\" \"main\" {\n  domain       = \"example-domain\"\n  user_pool_id = aws_cognito_user_pool.example.id\n}\n\nresource \"aws_cognito_user_pool\" \"example\" {\n  name = \"example-pool\"\n}\n```\n\n### Custom Cognito domain\n\n```terraform\nresource \"aws_cognito_user_pool_domain\" \"main\" {\n  domain          = \"example-domain.example.com\"\n  certificate_arn = aws_acm_certificate.cert.arn\n  user_pool_id    = aws_cognito_user_pool.example.id\n}\n\nresource \"aws_cognito_user_pool\" \"example\" {\n  name = \"example-pool\"\n}\n\ndata \"aws_route53_zone\" \"example\" {\n  name = \"example.com\"\n}\n\nresource \"aws_route53_record\" \"auth-cognito-A\" {\n  name    = aws_cognito_user_pool_domain.main.domain\n  type    = \"A\"\n  zone_id = data.aws_route53_zone.example.zone_id\n  alias {\n    evaluate_target_health = false\n    name                   = aws_cognito_user_pool_domain.main.cloudfront_distribution_arn\n    # This zone_id is fixed\n    zone_id = \"Z2FDTNDATAQYW2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain` - (Required) The domain string.\n* `user_pool_id` - (Required) The user pool ID.\n* `certificate_arn` - (Optional) The ARN of an ISSUED ACM certificate in us-east-1 for a custom domain.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `aws_account_id` - The AWS account ID for the user pool owner.\n* `cloudfront_distribution_arn` - The URL of the CloudFront distribution. This is required to generate the ALIAS `aws_route53_record`\n* `s3_bucket` - The S3 bucket where the static files for this domain are stored.\n* `version` - The app version.\n\n## Import\n\nCognito User Pool Domains can be imported using the `domain`, e.g.,\n\n```\n$ terraform import aws_cognito_user_pool_domain.main <domain>\n```\n",
    "basename": "cognito_user_pool_domain"
  },
  "cognito_user_pool_ui_customization.html": {
    "subcategory": "Cognito",
    "layout": "aws",
    "page_title": "AWS: aws_cognito_user_pool_ui_customization",
    "description": "Provides a Cognito User Pool UI Customization resource.",
    "preview": "# Resource: aws_cognito_user_pool_ui_customization\n\nProvides a …",
    "content": "\n\n# Resource: aws_cognito_user_pool_ui_customization\n\nProvides a Cognito User Pool UI Customization resource.\n\n~> **Note:** To use this resource, the user pool must have a domain associated with it. For more information, see the Amazon Cognito Developer Guide on [Customizing the Built-in Sign-In and Sign-up Webpages](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-app-ui-customization.html).\n\n## Example Usage\n\n### UI customization settings for a single client\n\n```terraform\nresource \"aws_cognito_user_pool\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_cognito_user_pool_domain\" \"example\" {\n  domain       = \"example\"\n  user_pool_id = aws_cognito_user_pool.example.id\n}\n\nresource \"aws_cognito_user_pool_client\" \"example\" {\n  name         = \"example\"\n  user_pool_id = aws_cognito_user_pool.example.id\n}\n\nresource \"aws_cognito_user_pool_ui_customization\" \"example\" {\n  client_id = aws_cognito_user_pool_client.example.id\n\n  css        = \".label-customizable {font-weight: 400;}\"\n  image_file = filebase64(\"logo.png\")\n\n  # Refer to the aws_cognito_user_pool_domain resource's\n  # user_pool_id attribute to ensure it is in an 'Active' state\n  user_pool_id = aws_cognito_user_pool_domain.example.user_pool_id\n}\n```\n\n### UI customization settings for all clients\n\n```terraform\nresource \"aws_cognito_user_pool\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_cognito_user_pool_domain\" \"example\" {\n  domain       = \"example\"\n  user_pool_id = aws_cognito_user_pool.example.id\n}\n\nresource \"aws_cognito_user_pool_ui_customization\" \"example\" {\n  css        = \".label-customizable {font-weight: 400;}\"\n  image_file = filebase64(\"logo.png\")\n\n  # Refer to the aws_cognito_user_pool_domain resource's\n  # user_pool_id attribute to ensure it is in an 'Active' state\n  user_pool_id = aws_cognito_user_pool_domain.example.user_pool_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `client_id` (Optional) The client ID for the client app. Defaults to `ALL`. If `ALL` is specified, the `css` and/or `image_file` settings will be used for every client that has no UI customization set previously.\n* `css` (Optional) - The CSS values in the UI customization, provided as a String. At least one of `css` or `image_file` is required.\n* `image_file` (Optional) - The uploaded logo image for the UI customization, provided as a base64-encoded String. Drift detection is not possible for this argument. At least one of `css` or `image_file` is required.\n* `user_pool_id` (Required) - The user pool ID for the user pool.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `creation_date` - The creation date in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) for the UI customization.\n* `css_version` - The CSS version number.\n* `image_url` - The logo image URL for the UI customization.\n* `last_modified_date` - The last-modified date in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) for the UI customization.\n\n## Import\n\nCognito User Pool UI Customizations can be imported using the `user_pool_id` and `client_id` separated by `,`, e.g.,\n\n```\n$ terraform import aws_cognito_user_pool_ui_customization.example us-west-2_ZCTarbt5C,12bu4fuk3mlgqa2rtrujgp6egq\n```\n",
    "basename": "cognito_user_pool_ui_customization.html"
  },
  "config_aggregate_authorization": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_aggregate_authorization",
    "description": "Manages an AWS Config Aggregate Authorization.",
    "preview": "# Resource: aws_config_aggregate_authorization\n\nManages an AWS …",
    "content": "\n\n# Resource: aws_config_aggregate_authorization\n\nManages an AWS Config Aggregate Authorization\n\n## Example Usage\n\n```terraform\nresource \"aws_config_aggregate_authorization\" \"example\" {\n  account_id = \"123456789012\"\n  region     = \"eu-west-2\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Required) Account ID\n* `region` - (Required) Region\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the authorization\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nConfig aggregate authorizations can be imported using `account_id:region`, e.g.,\n\n```\n$ terraform import aws_config_aggregate_authorization.example 123456789012:us-east-1\n```\n",
    "basename": "config_aggregate_authorization"
  },
  "config_config_rule.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_config_rule",
    "description": "Provides an AWS Config Rule.",
    "preview": "# Resource: aws_config_config_rule\n\nProvides an AWS Config Rule.\n\n~> …",
    "content": "\n\n# Resource: aws_config_config_rule\n\nProvides an AWS Config Rule.\n\n~> **Note:** Config Rule requires an existing [Configuration Recorder](/docs/providers/aws/r/config_configuration_recorder.html) to be present. Use of `depends_on` is recommended (as shown below) to avoid race conditions.\n\n## Example Usage\n\n### AWS Managed Rules\n\nAWS managed rules can be used by setting the source owner to `AWS` and the source identifier to the name of the managed rule. More information about AWS managed rules can be found in the [AWS Config Developer Guide](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html).\n\n```terraform\nresource \"aws_config_config_rule\" \"r\" {\n  name = \"example\"\n\n  source {\n    owner             = \"AWS\"\n    source_identifier = \"S3_BUCKET_VERSIONING_ENABLED\"\n  }\n\n  depends_on = [aws_config_configuration_recorder.foo]\n}\n\nresource \"aws_config_configuration_recorder\" \"foo\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.r.arn\n}\n\nresource \"aws_iam_role\" \"r\" {\n  name = \"my-awsconfig-role\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"config.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy\" \"p\" {\n  name = \"my-awsconfig-policy\"\n  role = aws_iam_role.r.id\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n  \t{\n  \t\t\"Action\": \"config:Put*\",\n  \t\t\"Effect\": \"Allow\",\n  \t\t\"Resource\": \"*\"\n\n  \t}\n  ]\n}\nPOLICY\n}\n```\n\n### Custom Rules\n\nCustom rules can be used by setting the source owner to `CUSTOM_LAMBDA` and the source identifier to the Amazon Resource Name (ARN) of the Lambda Function. The AWS Config service must have permissions to invoke the Lambda Function, e.g., via the [`aws_lambda_permission` resource](/docs/providers/aws/r/lambda_permission.html). More information about custom rules can be found in the [AWS Config Developer Guide](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_develop-rules.html).\n\n```terraform\nresource \"aws_config_configuration_recorder\" \"example\" {\n  # ... other configuration ...\n}\n\nresource \"aws_lambda_function\" \"example\" {\n  # ... other configuration ...\n}\n\nresource \"aws_lambda_permission\" \"example\" {\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.example.arn\n  principal     = \"config.amazonaws.com\"\n  statement_id  = \"AllowExecutionFromConfig\"\n}\n\nresource \"aws_config_config_rule\" \"example\" {\n  # ... other configuration ...\n\n  source {\n    owner             = \"CUSTOM_LAMBDA\"\n    source_identifier = aws_lambda_function.example.arn\n  }\n\n  depends_on = [\n    aws_config_configuration_recorder.example,\n    aws_lambda_permission.example,\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the rule\n* `description` - (Optional) Description of the rule\n* `input_parameters` - (Optional) A string in JSON format that is passed to the AWS Config rule Lambda function.\n* `maximum_execution_frequency` - (Optional) The maximum frequency with which AWS Config runs evaluations for a rule.\n* `scope` - (Optional) Scope defines which resources can trigger an evaluation for the rule as documented below.\n* `source` - (Required) Source specifies the rule owner, the rule identifier, and the notifications that cause the function to evaluate your AWS resources as documented below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `scope`\n\nDefines which resources can trigger an evaluation for the rule.\nIf you do not specify a scope, evaluations are triggered when any resource in the recording group changes.\n\n* `compliance_resource_id` - (Optional) The IDs of the only AWS resource that you want to trigger an evaluation for the rule. If you specify a resource ID, you must specify one resource type for `compliance_resource_types`.\n* `compliance_resource_types` - (Optional) A list of resource types of only those AWS resources that you want to trigger an evaluation for the ruleE.g., `AWS::EC2::Instance`. You can only specify one type if you also specify a resource ID for `compliance_resource_id`. See [relevant part of AWS Docs](http://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType) for available types.\n* `tag_key` - (Optional, Required if `tag_value` is specified) The tag key that is applied to only those AWS resources that you want you want to trigger an evaluation for the rule.\n* `tag_value` - (Optional) The tag value applied to only those AWS resources that you want to trigger an evaluation for the rule.\n\n### `source`\n\nProvides the rule owner (AWS or customer), the rule identifier, and the notifications that cause the function to evaluate your AWS resources.\n\n* `owner` - (Required) Indicates whether AWS or the customer owns and manages the AWS Config rule. Valid values are `AWS` or `CUSTOM_LAMBDA`. For more information about managed rules, see the [AWS Config Managed Rules documentation](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html). For more information about custom rules, see the [AWS Config Custom Rules documentation](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_develop-rules.html). Custom Lambda Functions require permissions to allow the AWS Config service to invoke them, e.g., via the [`aws_lambda_permission` resource](/docs/providers/aws/r/lambda_permission.html).\n* `source_identifier` - (Required) For AWS Config managed rules, a predefined identifier, e.g `IAM_PASSWORD_POLICY`. For custom Lambda rules, the identifier is the ARN of the Lambda Function, such as `arn:aws:lambda:us-east-1:123456789012:function:custom_rule_name` or the [`arn` attribute of the `aws_lambda_function` resource](/docs/providers/aws/r/lambda_function.html#arn).\n* `source_detail` - (Optional) Provides the source and type of the event that causes AWS Config to evaluate your AWS resources. Only valid if `owner` is `CUSTOM_LAMBDA`.\n    * `event_source` - (Optional) The source of the event, such as an AWS service, that triggers AWS Config to evaluate your AWS resources. This defaults to `aws.config` and is the only valid value.\n    * `maximum_execution_frequency` - (Optional) The frequency that you want AWS Config to run evaluations for a rule that is triggered periodically. If specified, requires `message_type` to be `ScheduledNotification`.\n    * `message_type` - (Optional) The type of notification that triggers AWS Config to run an evaluation for a rule. You can specify the following notification types:\n        * `ConfigurationItemChangeNotification` - Triggers an evaluation when AWS Config delivers a configuration item as a result of a resource change.\n        * `OversizedConfigurationItemChangeNotification` - Triggers an evaluation when AWS Config delivers an oversized configuration item. AWS Config may generate this notification type when a resource changes and the notification exceeds the maximum size allowed by Amazon SNS.\n        * `ScheduledNotification` - Triggers a periodic evaluation at the frequency specified for `maximum_execution_frequency`.\n        * `ConfigurationSnapshotDeliveryCompleted` - Triggers a periodic evaluation when AWS Config delivers a configuration snapshot.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the config rule\n* `rule_id` - The ID of the config rule\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nConfig Rule can be imported using the name, e.g.,\n\n```\n$ terraform import aws_config_config_rule.foo example\n```\n",
    "basename": "config_config_rule.html"
  },
  "config_configuration_aggregator.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_configuration_aggregator",
    "description": "Manages an AWS Config Configuration Aggregator.",
    "preview": "# Resource: aws_config_configuration_aggregator\n\nManages an AWS …",
    "content": "\n\n# Resource: aws_config_configuration_aggregator\n\nManages an AWS Config Configuration Aggregator\n\n## Example Usage\n\n### Account Based Aggregation\n\n```terraform\nresource \"aws_config_configuration_aggregator\" \"account\" {\n  name = \"example\"\n\n  account_aggregation_source {\n    account_ids = [\"123456789012\"]\n    regions     = [\"us-west-2\"]\n  }\n}\n```\n\n### Organization Based Aggregation\n\n```terraform\nresource \"aws_config_configuration_aggregator\" \"organization\" {\n  depends_on = [aws_iam_role_policy_attachment.organization]\n\n  name = \"example\" # Required\n\n  organization_aggregation_source {\n    all_regions = true\n    role_arn    = aws_iam_role.organization.arn\n  }\n}\n\nresource \"aws_iam_role\" \"organization\" {\n  name = \"example\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"config.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"organization\" {\n  role       = aws_iam_role.organization.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSConfigRoleForOrganizations\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the configuration aggregator.\n* `account_aggregation_source` - (Optional) The account(s) to aggregate config data from as documented below.\n* `organization_aggregation_source` - (Optional) The organization to aggregate config data from as documented below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nEither `account_aggregation_source` or `organization_aggregation_source` must be specified.\n\n### `account_aggregation_source`\n\n* `account_ids` - (Required) List of 12-digit account IDs of the account(s) being aggregated.\n* `all_regions` - (Optional) If true, aggregate existing AWS Config regions and future regions.\n* `regions` - (Optional) List of source regions being aggregated.\n\nEither `regions` or `all_regions` (as true) must be specified.\n\n### `organization_aggregation_source`\n\n~> **Note:** If your source type is an organization, you must be signed in to the master account and all features must be enabled in your organization. AWS Config calls EnableAwsServiceAccess API to enable integration between AWS Config and AWS Organizations.\n\n* `all_regions` - (Optional) If true, aggregate existing AWS Config regions and future regions.\n* `regions` - (Optional) List of source regions being aggregated.\n* `role_arn` - (Required) ARN of the IAM role used to retrieve AWS Organization details associated with the aggregator account.\n\nEither `regions` or `all_regions` (as true) must be specified.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the aggregator\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nConfiguration Aggregators can be imported using the name, e.g.,\n\n```\n$ terraform import aws_config_configuration_aggregator.example foo\n```\n",
    "basename": "config_configuration_aggregator.html"
  },
  "config_configuration_recorder.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_configuration_recorder",
    "description": "Provides an AWS Config Configuration Recorder.",
    "preview": "# Resource: aws_config_configuration_recorder\n\nProvides an AWS …",
    "content": "\n\n# Resource: aws_config_configuration_recorder\n\nProvides an AWS Config Configuration Recorder. Please note that this resource **does not start** the created recorder automatically.\n\n~> **Note:** _Starting_ the Configuration Recorder requires a [delivery channel](/docs/providers/aws/r/config_delivery_channel.html) (while delivery channel creation requires Configuration Recorder). This is why [`aws_config_configuration_recorder_status`](/docs/providers/aws/r/config_configuration_recorder_status.html) is a separate resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_config_configuration_recorder\" \"foo\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.r.arn\n}\n\nresource \"aws_iam_role\" \"r\" {\n  name = \"awsconfig-example\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"config.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the recorder. Defaults to `default`. Changing it recreates the resource.\n* `role_arn` - (Required) Amazon Resource Name (ARN) of the IAM role. Used to make read or write requests to the delivery channel and to describe the AWS resources associated with the account. See [AWS Docs](http://docs.aws.amazon.com/config/latest/developerguide/iamrole-permissions.html) for more details.\n* `recording_group` - (Optional) Recording group - see below.\n\n### `recording_group`\n\n* `all_supported` - (Optional) Specifies whether AWS Config records configuration changes for every supported type of regional resource (which includes any new type that will become supported in the future). Conflicts with `resource_types`. Defaults to `true`.\n* `include_global_resource_types` - (Optional) Specifies whether AWS Config includes all supported types of *global resources* with the resources that it records. Requires `all_supported = true`. Conflicts with `resource_types`.\n* `resource_types` - (Optional) A list that specifies the types of AWS resources for which AWS Config records configuration changes (for example, `AWS::EC2::Instance` or `AWS::CloudTrail::Trail`). See [relevant part of AWS Docs](http://docs.aws.amazon.com/config/latest/APIReference/API_ResourceIdentifier.html#config-Type-ResourceIdentifier-resourceType) for available types. In order to use this attribute, `all_supported` must be set to false.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Name of the recorder\n\n## Import\n\nConfiguration Recorder can be imported using the name, e.g.,\n\n```\n$ terraform import aws_config_configuration_recorder.foo example\n```\n",
    "basename": "config_configuration_recorder.html"
  },
  "config_configuration_recorder_status.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_configuration_recorder_status",
    "description": "Manages status of an AWS Config Configuration Recorder.",
    "preview": "# Resource: aws_config_configuration_recorder_status\n\nManages status …",
    "content": "\n\n# Resource: aws_config_configuration_recorder_status\n\nManages status (recording / stopped) of an AWS Config Configuration Recorder.\n\n~> **Note:** Starting Configuration Recorder requires a [Delivery Channel](/docs/providers/aws/r/config_delivery_channel.html) to be present. Use of `depends_on` (as shown below) is recommended to avoid race conditions.\n\n## Example Usage\n\n```terraform\nresource \"aws_config_configuration_recorder_status\" \"foo\" {\n  name       = aws_config_configuration_recorder.foo.name\n  is_enabled = true\n  depends_on = [aws_config_delivery_channel.foo]\n}\n\nresource \"aws_iam_role_policy_attachment\" \"a\" {\n  role       = aws_iam_role.r.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSConfigRole\"\n}\n\nresource \"aws_s3_bucket\" \"b\" {\n  bucket = \"awsconfig-example\"\n}\n\nresource \"aws_config_delivery_channel\" \"foo\" {\n  name           = \"example\"\n  s3_bucket_name = aws_s3_bucket.b.bucket\n}\n\nresource \"aws_config_configuration_recorder\" \"foo\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.r.arn\n}\n\nresource \"aws_iam_role\" \"r\" {\n  name = \"example-awsconfig\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"config.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy\" \"p\" {\n  name = \"awsconfig-example\"\n  role = aws_iam_role.r.id\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"s3:*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"${aws_s3_bucket.b.arn}\",\n        \"${aws_s3_bucket.b.arn}/*\"\n      ]\n    }\n  ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the recorder\n* `is_enabled` - (Required) Whether the configuration recorder should be enabled or disabled.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nConfiguration Recorder Status can be imported using the name of the Configuration Recorder, e.g.,\n\n```\n$ terraform import aws_config_configuration_recorder_status.foo example\n```\n",
    "basename": "config_configuration_recorder_status.html"
  },
  "config_conformance_pack.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_conformance_pack",
    "description": "Manages a Config Conformance Pack",
    "preview": "# Resource: aws_config_conformance_pack\n\nManages a Config …",
    "content": "\n\n# Resource: aws_config_conformance_pack\n\nManages a Config Conformance Pack. More information about this collection of Config rules and remediation actions can be found in the\n[Conformance Packs](https://docs.aws.amazon.com/config/latest/developerguide/conformance-packs.html) documentation.\nSample Conformance Pack templates may be found in the\n[AWS Config Rules Repository](https://github.com/awslabs/aws-config-rules/tree/master/aws-config-conformance-packs).\n\n~> **NOTE:** The account must have a Configuration Recorder with proper IAM permissions before the Conformance Pack will\nsuccessfully create or update. See also the\n[`aws_config_configuration_recorder` resource](/docs/providers/aws/r/config_configuration_recorder.html).\n\n## Example Usage\n\n### Template Body\n\n```terraform\nresource \"aws_config_conformance_pack\" \"example\" {\n  name = \"example\"\n\n  input_parameter {\n    parameter_name  = \"AccessKeysRotatedParameterMaxAccessKeyAge\"\n    parameter_value = \"90\"\n  }\n\n  template_body = <<EOT\nParameters:\n  AccessKeysRotatedParameterMaxAccessKeyAge:\n    Type: String\nResources:\n  IAMPasswordPolicy:\n    Properties:\n      ConfigRuleName: IAMPasswordPolicy\n      Source:\n        Owner: AWS\n        SourceIdentifier: IAM_PASSWORD_POLICY\n    Type: AWS::Config::ConfigRule\nEOT\n\n  depends_on = [aws_config_configuration_recorder.example]\n}\n```\n\n### Template S3 URI\n\n```terraform\nresource \"aws_config_conformance_pack\" \"example\" {\n  name            = \"example\"\n  template_s3_uri = \"s3://${aws_s3_bucket.example.bucket}/${aws_s3_bucket_object.example.key}\"\n\n  depends_on = [aws_config_configuration_recorder.example]\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_bucket_object\" \"example\" {\n  bucket  = aws_s3_bucket.example.id\n  key     = \"example-key\"\n  content = <<EOT\nResources:\n  IAMPasswordPolicy:\n    Properties:\n      ConfigRuleName: IAMPasswordPolicy\n      Source:\n        Owner: AWS\n        SourceIdentifier: IAM_PASSWORD_POLICY\n    Type: AWS::Config::ConfigRule\nEOT\n}\n```\n\n## Argument Reference\n\n~> **Note:** If both `template_body` and `template_s3_uri` are specified, AWS Config uses the `template_s3_uri` and ignores the `template_body`.\n\nThe following arguments are supported:\n\n* `name` - (Required, Forces new resource) The name of the conformance pack. Must begin with a letter and contain from 1 to 256 alphanumeric characters and hyphens.\n* `delivery_s3_bucket` - (Optional) Amazon S3 bucket where AWS Config stores conformance pack templates. Maximum length of 63.\n* `delivery_s3_key_prefix` - (Optional) The prefix for the Amazon S3 bucket. Maximum length of 1024.\n* `input_parameter` - (Optional) Set of configuration blocks describing input parameters passed to the conformance pack template. Documented below. When configured, the parameters must also be included in the `template_body` or in the template stored in Amazon S3 if using `template_s3_uri`.\n* `template_body` - (Optional, required if `template_s3_uri` is not provided) A string containing full conformance pack template body. Maximum length of 51200. Drift detection is not possible with this argument.\n* `template_s3_uri` - (Optional, required if `template_body` is not provided) Location of file, e.g., `s3://bucketname/prefix`, containing the template body. The uri must point to the conformance pack template that is located in an Amazon S3 bucket in the same region as the conformance pack. Maximum length of 1024. Drift detection is not possible with this argument.\n\n### input_parameter Argument Reference\n\nThe `input_parameter` configuration block supports the following arguments:\n\n* `parameter_name` - (Required) The input key.\n* `parameter_value` - (Required) The input value.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the conformance pack.\n\n## Import\n\nConfig Conformance Packs can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_config_conformance_pack.example example\n```\n",
    "basename": "config_conformance_pack.html"
  },
  "config_delivery_channel.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_delivery_channel",
    "description": "Provides an AWS Config Delivery Channel.",
    "preview": "# Resource: aws_config_delivery_channel\n\nProvides an AWS Config …",
    "content": "\n\n# Resource: aws_config_delivery_channel\n\nProvides an AWS Config Delivery Channel.\n\n~> **Note:** Delivery Channel requires a [Configuration Recorder](/docs/providers/aws/r/config_configuration_recorder.html) to be present. Use of `depends_on` (as shown below) is recommended to avoid race conditions.\n\n## Example Usage\n\n```terraform\nresource \"aws_config_delivery_channel\" \"foo\" {\n  name           = \"example\"\n  s3_bucket_name = aws_s3_bucket.b.bucket\n  depends_on     = [aws_config_configuration_recorder.foo]\n}\n\nresource \"aws_s3_bucket\" \"b\" {\n  bucket        = \"example-awsconfig\"\n  force_destroy = true\n}\n\nresource \"aws_config_configuration_recorder\" \"foo\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.r.arn\n}\n\nresource \"aws_iam_role\" \"r\" {\n  name = \"awsconfig-example\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"config.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy\" \"p\" {\n  name = \"awsconfig-example\"\n  role = aws_iam_role.r.id\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"s3:*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"${aws_s3_bucket.b.arn}\",\n        \"${aws_s3_bucket.b.arn}/*\"\n      ]\n    }\n  ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the delivery channel. Defaults to `default`. Changing it recreates the resource.\n* `s3_bucket_name` - (Required) The name of the S3 bucket used to store the configuration history.\n* `s3_key_prefix` - (Optional) The prefix for the specified S3 bucket.\n* `s3_kms_key_arn` - (Optional) The ARN of the AWS KMS key used to encrypt objects delivered by AWS Config. Must belong to the same Region as the destination S3 bucket.\n* `sns_topic_arn` - (Optional) The ARN of the SNS topic that AWS Config delivers notifications to.\n* `snapshot_delivery_properties` - (Optional) Options for how AWS Config delivers configuration snapshots. See below\n\n### `snapshot_delivery_properties`\n\n* `delivery_frequency` - (Optional) - The frequency with which AWS Config recurringly delivers configuration snapshotsE.g., `One_Hour` or `Three_Hours`. Valid values are listed [here](https://docs.aws.amazon.com/config/latest/APIReference/API_ConfigSnapshotDeliveryProperties.html#API_ConfigSnapshotDeliveryProperties_Contents).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the delivery channel.\n\n## Import\n\nDelivery Channel can be imported using the name, e.g.,\n\n```\n$ terraform import aws_config_delivery_channel.foo example\n```\n",
    "basename": "config_delivery_channel.html"
  },
  "config_organization_conformance_pack.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_organization_conformance_pack",
    "description": "Manages a Config Organization Conformance Pack",
    "preview": "# Resource: aws_config_organization_conformance_pack\n\nManages a …",
    "content": "\n\n# Resource: aws_config_organization_conformance_pack\n\nManages a Config Organization Conformance Pack. More information can be found in the [Managing Conformance Packs Across all Accounts in Your Organization](https://docs.aws.amazon.com/config/latest/developerguide/conformance-pack-organization-apis.html) and [AWS Config Managed Rules](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html) documentation. Example conformance pack templates may be found in the [AWS Config Rules Repository](https://github.com/awslabs/aws-config-rules/tree/master/aws-config-conformance-packs).\n\n~> **NOTE:** This resource must be created in the Organization master account or a delegated administrator account, and the Organization must have all features enabled. Every Organization account except those configured in the `excluded_accounts` argument must have a Configuration Recorder with proper IAM permissions before the Organization Conformance Pack will successfully create or update. See also the [`aws_config_configuration_recorder` resource](/docs/providers/aws/r/config_configuration_recorder.html).\n\n## Example Usage\n\n### Using Template Body\n\n```hcl\nresource \"aws_config_organization_conformance_pack\" \"example\" {\n  name = \"example\"\n\n  input_parameter {\n    parameter_name  = \"AccessKeysRotatedParameterMaxAccessKeyAge\"\n    parameter_value = \"90\"\n  }\n\n  template_body = <<EOT\nParameters:\n  AccessKeysRotatedParameterMaxAccessKeyAge:\n    Type: String\nResources:\n  IAMPasswordPolicy:\n    Properties:\n      ConfigRuleName: IAMPasswordPolicy\n      Source:\n        Owner: AWS\n        SourceIdentifier: IAM_PASSWORD_POLICY\n    Type: AWS::Config::ConfigRule\nEOT\n\n  depends_on = [aws_config_configuration_recorder.example, aws_organizations_organization.example]\n}\n\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"config-multiaccountsetup.amazonaws.com\"]\n  feature_set                   = \"ALL\"\n}\n```\n\n### Using Template S3 URI\n\n```hcl\nresource \"aws_config_organization_conformance_pack\" \"example\" {\n  name            = \"example\"\n  template_s3_uri = \"s3://${aws_s3_bucket.example.bucket}/${aws_s3_bucket_object.example.key}\"\n\n  depends_on = [aws_config_configuration_recorder.example, aws_organizations_organization.example]\n}\n\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"config-multiaccountsetup.amazonaws.com\"]\n  feature_set                   = \"ALL\"\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_bucket_object\" \"example\" {\n  bucket  = aws_s3_bucket.example.id\n  key     = \"example-key\"\n  content = <<EOT\nResources:\n  IAMPasswordPolicy:\n    Properties:\n      ConfigRuleName: IAMPasswordPolicy\n      Source:\n        Owner: AWS\n        SourceIdentifier: IAM_PASSWORD_POLICY\n    Type: AWS::Config::ConfigRule\nEOT\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required, Forces new resource) The name of the organization conformance pack. Must begin with a letter and contain from 1 to 128 alphanumeric characters and hyphens.\n* `delivery_s3_bucket` - (Optional) Amazon S3 bucket where AWS Config stores conformance pack templates. Delivery bucket must begin with `awsconfigconforms` prefix. Maximum length of 63.\n* `delivery_s3_key_prefix` - (Optional) The prefix for the Amazon S3 bucket. Maximum length of 1024.\n* `excluded_accounts` - (Optional) Set of AWS accounts to be excluded from an organization conformance pack while deploying a conformance pack. Maximum of 1000 accounts.\n* `input_parameter` - (Optional) Set of configuration blocks describing input parameters passed to the conformance pack template. Documented below. When configured, the parameters must also be included in the `template_body` or in the template stored in Amazon S3 if using `template_s3_uri`.\n* `template_body` - (Optional, Conflicts with `template_s3_uri`) A string containing full conformance pack template body. Maximum length of 51200. Drift detection is not possible with this argument.\n* `template_s3_uri` - (Optional, Conflicts with `template_body`) Location of file, e.g., `s3://bucketname/prefix`, containing the template body. The uri must point to the conformance pack template that is located in an Amazon S3 bucket in the same region as the conformance pack. Maximum length of 1024. Drift detection is not possible with this argument.\n\n### input_parameter Argument Reference\n\nThe `input_parameter` configuration block supports the following arguments:\n\n* `parameter_name` - (Required) The input key.\n* `parameter_value` - (Required) The input value.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the organization conformance pack.\n* `id` - The name of the organization conformance pack.\n\n## Timeouts\n\n`aws_config_organization_conformance_pack` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating conformance pack\n- `update` - (Default `10 minutes`) Used for conformance pack modifications\n- `delete` - (Default `20 minutes`) Used for destroying conformance pack\n\n## Import\n\nConfig Organization Conformance Packs can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_config_organization_conformance_pack.example example\n```\n",
    "basename": "config_organization_conformance_pack.html"
  },
  "config_organization_custom_rule.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_organization_custom_rule",
    "description": "Manages a Config Organization Custom Rule",
    "preview": "# Resource: aws_config_organization_custom_rule\n\nManages a Config …",
    "content": "\n\n# Resource: aws_config_organization_custom_rule\n\nManages a Config Organization Custom Rule. More information about these rules can be found in the [Enabling AWS Config Rules Across all Accounts in Your Organization](https://docs.aws.amazon.com/config/latest/developerguide/config-rule-multi-account-deployment.html) and [AWS Config Managed Rules](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html) documentation. For working with Organization Managed Rules (those invoking an AWS managed rule), see the [`aws_config_organization_managed__rule` resource](/docs/providers/aws/r/config_organization_managed_rule.html).\n\n~> **NOTE:** This resource must be created in the Organization master account and rules will include the master account unless its ID is added to the `excluded_accounts` argument.\n\n~> **NOTE:** The proper Lambda permission to allow the AWS Config service invoke the Lambda Function must be in place before the rule will successfully create or update. See also the [`aws_lambda_permission` resource](/docs/providers/aws/r/lambda_permission.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_lambda_permission\" \"example\" {\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.example.arn\n  principal     = \"config.amazonaws.com\"\n  statement_id  = \"AllowExecutionFromConfig\"\n}\n\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"config-multiaccountsetup.amazonaws.com\"]\n  feature_set                   = \"ALL\"\n}\n\nresource \"aws_config_organization_custom_rule\" \"example\" {\n  depends_on = [\n    aws_lambda_permission.example,\n    aws_organizations_organization.example,\n  ]\n\n  lambda_function_arn = aws_lambda_function.example.arn\n  name                = \"example\"\n  trigger_types       = [\"ConfigurationItemChangeNotification\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `lambda_function_arn` - (Required) Amazon Resource Name (ARN) of the rule Lambda Function\n* `name` - (Required) The name of the rule\n* `trigger_types` - (Required) List of notification types that trigger AWS Config to run an evaluation for the rule. Valid values: `ConfigurationItemChangeNotification`, `OversizedConfigurationItemChangeNotification`, and `ScheduledNotification`\n* `description` - (Optional) Description of the rule\n* `excluded_accounts` - (Optional) List of AWS account identifiers to exclude from the rule\n* `input_parameters` - (Optional) A string in JSON format that is passed to the AWS Config Rule Lambda Function\n* `maximum_execution_frequency` - (Optional) The maximum frequency with which AWS Config runs evaluations for a rule, if the rule is triggered at a periodic frequency. Defaults to `TwentyFour_Hours` for periodic frequency triggered rules. Valid values: `One_Hour`, `Three_Hours`, `Six_Hours`, `Twelve_Hours`, or `TwentyFour_Hours`.\n* `resource_id_scope` - (Optional) Identifier of the AWS resource to evaluate\n* `resource_types_scope` - (Optional) List of types of AWS resources to evaluate\n* `tag_key_scope` - (Optional, Required if `tag_value_scope` is configured) Tag key of AWS resources to evaluate\n* `tag_value_scope` - (Optional) Tag value of AWS resources to evaluate\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the rule\n\n## Timeouts\n\n`aws_config_organization_custom_rule` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `5m`) How long to wait for the rule to be created.\n* `delete` - (Default `5m`) How long to wait for the rule to be deleted.\n* `update` - (Default `5m`) How long to wait for the rule to be updated.\n\n## Import\n\nConfig Organization Custom Rules can be imported using the name, e.g.,\n\n```\n$ terraform import aws_config_organization_custom_rule.example example\n```\n",
    "basename": "config_organization_custom_rule.html"
  },
  "config_organization_managed_rule.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_organization_managed_rule",
    "description": "Manages a Config Organization Managed Rule",
    "preview": "# Resource: aws_config_organization_managed_rule\n\nManages a Config …",
    "content": "\n\n# Resource: aws_config_organization_managed_rule\n\nManages a Config Organization Managed Rule. More information about these rules can be found in the [Enabling AWS Config Rules Across all Accounts in Your Organization](https://docs.aws.amazon.com/config/latest/developerguide/config-rule-multi-account-deployment.html) and [AWS Config Managed Rules](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html) documentation. For working with Organization Custom Rules (those invoking a custom Lambda Function), see the [`aws_config_organization_custom_rule` resource](/docs/providers/aws/r/config_organization_custom_rule.html).\n\n~> **NOTE:** This resource must be created in the Organization master account and rules will include the master account unless its ID is added to the `excluded_accounts` argument.\n\n~> **NOTE:** Every Organization account except those configured in the `excluded_accounts` argument must have a Configuration Recorder with proper IAM permissions before the rule will successfully create or update. See also the [`aws_config_configuration_recorder` resource](/docs/providers/aws/r/config_configuration_recorder.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"config-multiaccountsetup.amazonaws.com\"]\n  feature_set                   = \"ALL\"\n}\n\nresource \"aws_config_organization_managed_rule\" \"example\" {\n  depends_on = [aws_organizations_organization.example]\n\n  name            = \"example\"\n  rule_identifier = \"IAM_PASSWORD_POLICY\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the rule\n* `rule_identifier` - (Required) Identifier of an available AWS Config Managed Rule to call. For available values, see the [List of AWS Config Managed Rules](https://docs.aws.amazon.com/config/latest/developerguide/managed-rules-by-aws-config.html) documentation\n* `description` - (Optional) Description of the rule\n* `excluded_accounts` - (Optional) List of AWS account identifiers to exclude from the rule\n* `input_parameters` - (Optional) A string in JSON format that is passed to the AWS Config Rule Lambda Function\n* `maximum_execution_frequency` - (Optional) The maximum frequency with which AWS Config runs evaluations for a rule, if the rule is triggered at a periodic frequency. Defaults to `TwentyFour_Hours` for periodic frequency triggered rules. Valid values: `One_Hour`, `Three_Hours`, `Six_Hours`, `Twelve_Hours`, or `TwentyFour_Hours`.\n* `resource_id_scope` - (Optional) Identifier of the AWS resource to evaluate\n* `resource_types_scope` - (Optional) List of types of AWS resources to evaluate\n* `tag_key_scope` - (Optional, Required if `tag_value_scope` is configured) Tag key of AWS resources to evaluate\n* `tag_value_scope` - (Optional) Tag value of AWS resources to evaluate\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the rule\n\n## Timeouts\n\n`aws_config_organization_managed_rule` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `5m`) How long to wait for the rule to be created.\n* `delete` - (Default `5m`) How long to wait for the rule to be deleted.\n* `update` - (Default `5m`) How long to wait for the rule to be updated.\n\n## Import\n\nConfig Organization Managed Rules can be imported using the name, e.g.,\n\n```\n$ terraform import aws_config_organization_managed_rule.example example\n```\n",
    "basename": "config_organization_managed_rule.html"
  },
  "config_remediation_configuration.html": {
    "subcategory": "Config",
    "layout": "aws",
    "page_title": "AWS: aws_config_remediation_configuration",
    "description": "Provides an AWS Config Remediation Configuration.",
    "preview": "# Resource: aws_config_remediation_configuration\n\nProvides an AWS …",
    "content": "\n\n# Resource: aws_config_remediation_configuration\n\nProvides an AWS Config Remediation Configuration.\n\n~> **Note:** Config Remediation Configuration requires an existing [Config Rule](/docs/providers/aws/r/config_config_rule.html) to be present.\n\n## Example Usage\n\nAWS managed rules can be used by setting the source owner to `AWS` and the source identifier to the name of the managed rule. More information about AWS managed rules can be found in the [AWS Config Developer Guide](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html).\n\n```terraform\nresource \"aws_config_config_rule\" \"this\" {\n  name = \"example\"\n\n  source {\n    owner             = \"AWS\"\n    source_identifier = \"S3_BUCKET_VERSIONING_ENABLED\"\n  }\n}\n\nresource \"aws_config_remediation_configuration\" \"this\" {\n  config_rule_name = aws_config_config_rule.this.name\n  resource_type    = \"AWS::S3::Bucket\"\n  target_type      = \"SSM_DOCUMENT\"\n  target_id        = \"AWS-EnableS3BucketEncryption\"\n  target_version   = \"1\"\n\n  parameter {\n    name         = \"AutomationAssumeRole\"\n    static_value = \"arn:aws:iam::875924563244:role/security_config\"\n  }\n  parameter {\n    name           = \"BucketName\"\n    resource_value = \"RESOURCE_ID\"\n  }\n  parameter {\n    name         = \"SSEAlgorithm\"\n    static_value = \"AES256\"\n  }\n\n  automatic                  = true\n  maximum_automatic_attempts = 10\n  retry_attempt_seconds      = 600\n\n  execution_controls {\n    ssm_controls {\n      concurrent_execution_rate_percentage = 25\n      error_percentage                     = 20\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `config_rule_name` - (Required) Name of the AWS Config rule.\n* `target_id` - (Required) Target ID is the name of the public document.\n* `target_type` - (Required) Type of the target. Target executes remediation. For example, SSM document.\n\nThe following arguments are optional:\n\n* `automatic` - (Optional) Remediation is triggered automatically if `true`.\n* `execution_controls` - (Optional) Configuration block for execution controls. See below.\n* `maximum_automatic_attempts` - (Optional) Maximum number of failed attempts for auto-remediation. If you do not select a number, the default is 5.\n* `parameter` - (Optional) Can be specified multiple times for each parameter. Each parameter block supports arguments below.\n* `resource_type` - (Optional) Type of resource.\n* `retry_attempt_seconds` - (Optional) Maximum time in seconds that AWS Config runs auto-remediation. If you do not select a number, the default is 60 seconds.\n* `target_version` - (Optional) Version of the target. For example, version of the SSM document\n\n### `execution_controls`\n\n* `ssm_controls` - (Required) Configuration block for SSM controls. See below.\n\n#### `ssm_controls`\n\nOne or both of these values are required.\n\n* `concurrent_execution_rate_percentage` - (Optional) Maximum percentage of remediation actions allowed to run in parallel on the non-compliant resources for that specific rule. The default value is 10%.\n* `error_percentage` - (Optional) Percentage of errors that are allowed before SSM stops running automations on non-compliant resources for that specific rule. The default is 50%.\n\n### `parameter`\n\nThe value is either a dynamic (resource) value or a static value. You must select either a dynamic value or a static value.\n\n* `name` - (Required) Name of the attribute.\n* `resource_value` - (Optional) Value is dynamic and changes at run-time.\n* `static_value` - (Optional) Value is static and does not change at run-time.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the Config Remediation Configuration.\n\n## Import\n\nRemediation Configurations can be imported using the name config_rule_name, e.g.,\n\n```\n$ terraform import aws_config_remediation_configuration.this example\n```\n",
    "basename": "config_remediation_configuration.html"
  },
  "connect_bot_association": {
    "subcategory": "Connect",
    "layout": "aws",
    "page_title": "AWS: aws_connect_bot_association",
    "description": "Associates an Amazon Connect instance to an Amazon Lex (V1) bot",
    "preview": "# Resource: aws_connect_bot_association\n\nAllows the specified Amazon …",
    "content": "\n\n# Resource: aws_connect_bot_association\n\nAllows the specified Amazon Connect instance to access the specified Amazon Lex (V1) bot. For more information see\n[Amazon Connect: Getting Started](https://docs.aws.amazon.com/connect/latest/adminguide/amazon-connect-get-started.html) and [Add an Amazon Lex bot](https://docs.aws.amazon.com/connect/latest/adminguide/amazon-lex.html).\n\n~> **NOTE:** This resource only currently supports Amazon Lex (V1) Associations.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_connect_bot_association\" \"example\" {\n  instance_id = aws_connect_instance.example.id\n  lex_bot {\n    lex_region = \"us-west-2\"\n    name       = \"Test\"\n\n  }\n}\n```\n\n### Including a sample Lex bot\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_lex_intent\" \"example\" {\n  create_version = true\n  name           = \"connect_lex_intent\"\n  fulfillment_activity {\n    type = \"ReturnIntent\"\n  }\n  sample_utterances = [\n    \"I would like to pick up flowers.\",\n  ]\n}\n\nresource \"aws_lex_bot\" \"example\" {\n  abort_statement {\n    message {\n      content      = \"Sorry, I am not able to assist at this time.\"\n      content_type = \"PlainText\"\n    }\n  }\n  clarification_prompt {\n    max_attempts = 2\n    message {\n      content      = \"I didn't understand you, what would you like to do?\"\n      content_type = \"PlainText\"\n    }\n  }\n  intent {\n    intent_name    = aws_lex_intent.example.name\n    intent_version = \"1\"\n  }\n\n  child_directed   = false\n  name             = \"connect_lex_bot\"\n  process_behavior = \"BUILD\"\n}\n\nresource \"aws_connect_bot_association\" \"example\" {\n  instance_id = aws_connect_instance.example.id\n  lex_bot {\n    lex_region = data.aws_region.current.name\n    name       = aws_lex_bot.example.name\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `instance_id` - (Required) The identifier of the Amazon Connect instance. You can find the instanceId in the ARN of the instance.\n* `lex_bot` - (Required) Configuration information of an Amazon Lex (V1) bot. Detailed below.\n\n### lex_bot\n\nThe `lex_bot` configuration block supports the following:\n\n* `name` - (Required) The name of the Amazon Lex (V1) bot.\n* `lex_region` - (Optional) The Region that the Amazon Lex (V1) bot was created in. Defaults to current region.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Connect instance ID, Lex (V1) bot name, and Lex (V1) bot region separated by colons (`:`).\n\n## Import\n\n`aws_connect_bot_association` can be imported by using the Amazon Connect instance ID, Lex (V1) bot name, and Lex (V1) bot region separated by colons (`:`), e.g.\n\n```\n$ terraform import aws_connect_bot_association.example aaaaaaaa-bbbb-cccc-dddd-111111111111:Example:us-west-2\n```\n",
    "basename": "connect_bot_association"
  },
  "connect_contact_flow.html": {
    "subcategory": "Connect",
    "layout": "aws",
    "page_title": "AWS: aws_connect_contact_flow",
    "description": "Provides details about a specific Amazon Connect Contact Flow.",
    "preview": "# Resource: aws_connect_contact_flow\n\nProvides an Amazon Connect …",
    "content": "\n\n# Resource: aws_connect_contact_flow\n\nProvides an Amazon Connect Contact Flow resource. For more information see\n[Amazon Connect: Getting Started](https://docs.aws.amazon.com/connect/latest/adminguide/amazon-connect-get-started.html)\n\nThis resource embeds or references Contact Flows specified in Amazon Connect Contact Flow Language. For more information see\n[Amazon Connect Flow language](https://docs.aws.amazon.com/connect/latest/adminguide/flow-language.html)\n\n!> **WARN:** Contact Flows exported from the Console [Contact Flow import/export](https://docs.aws.amazon.com/connect/latest/adminguide/contact-flow-import-export.html) are not in the Amazon Connect Contact Flow Language and can not be used with this resource. Instead, the recommendation is to use the AWS CLI [`describe-contact-flow`](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/connect/describe-contact-flow.html).\nSee [example](#with-external-content) below which uses `jq` to extract the `Content` attribute and saves it to a local file.\n\n~> **NOTE:** Due to The behaviour of Amazon Connect you cannot delete contact flows. The [recommendation](https://docs.aws.amazon.com/connect/latest/adminguide/create-contact-flow.html#before-create-contact-flow) is to prefix the Contact Flow with `zzTrash_` to get obsolete contact flows out of the way.\n\n## Example Usage\n\n### Basic\n\n```hcl\nresource \"aws_connect_contact_flow\" \"test\" {\n  instance_id = \"aaaaaaaa-bbbb-cccc-dddd-111111111111\"\n  name        = \"Test\"\n  description = \"Test Contact Flow Description\"\n  type        = \"CONTACT_FLOW\"\n  content     = <<JSON\n\t{\n\t\t\"Version\": \"2019-10-30\",\n\t\t\"StartAction\": \"12345678-1234-1234-1234-123456789012\",\n\t\t\"Actions\": [\n\t\t\t{\n\t\t\t\t\"Identifier\": \"12345678-1234-1234-1234-123456789012\",\n\t\t\t\t\"Type\": \"MessageParticipant\",\n\t\t\t\t\"Transitions\": {\n\t\t\t\t\t\"NextAction\": \"abcdef-abcd-abcd-abcd-abcdefghijkl\",\n\t\t\t\t\t\"Errors\": [],\n\t\t\t\t\t\"Conditions\": []\n\t\t\t\t},\n\t\t\t\t\"Parameters\": {\n\t\t\t\t\t\"Text\": \"Thanks for calling the sample flow!\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"Identifier\": \"abcdef-abcd-abcd-abcd-abcdefghijkl\",\n\t\t\t\t\"Type\": \"DisconnectParticipant\",\n\t\t\t\t\"Transitions\": {},\n\t\t\t\t\"Parameters\": {}\n\t\t\t}\n\t\t]\n\t}\n\tJSON\n  tags = {\n    \"Name\"        = \"Test Contact Flow\",\n    \"Application\" = \"Terraform\",\n    \"Method\"      = \"Create\"\n  }\n}\n```\n\n### With External Content\n\nUse the AWS CLI to extract Contact Flow Content:\n\n```shell\n$ aws connect describe-contact-flow --instance-id 1b3c5d8-1b3c-1b3c-1b3c-1b3c5d81b3c5 --contact-flow-id c1d4e5f6-1b3c-1b3c-1b3c-c1d4e5f6c1d4e5 --region us-west-2 | jq '.ContactFlow.Content | fromjson' > contact_flow.json\n```\n\nUse the generated file as input:\n\n```hcl\nresource \"aws_connect_contact_flow\" \"test\" {\n  instance_id  = \"aaaaaaaa-bbbb-cccc-dddd-111111111111\"\n  name         = \"Test\"\n  description  = \"Test Contact Flow Description\"\n  type         = \"CONTACT_FLOW\"\n  filename     = \"contact_flow.json\"\n  content_hash = filebase64sha256(\"contact_flow.json\")\n  tags = {\n    \"Name\"        = \"Test Contact Flow\",\n    \"Application\" = \"Terraform\",\n    \"Method\"      = \"Create\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `content` - (Optional) Specifies the content of the Contact Flow, provided as a JSON string, written in Amazon Connect Contact Flow Language. If defined, the `filename` argument cannot be used.\n* `content_hash` - (Optional) Used to trigger updates. Must be set to a base64-encoded SHA256 hash of the Contact Flow source specified with `filename`. The usual way to set this is filebase64sha256(\"mycontact_flow.json\") (Terraform 0.11.12 and later) or base64sha256(file(\"mycontact_flow.json\")) (Terraform 0.11.11 and earlier), where \"mycontact_flow.json\" is the local filename of the Contact Flow source.\n* `description` - (Optional) Specifies the description of the Contact Flow.\n* `filename` - (Optional) The path to the Contact Flow source within the local filesystem. Conflicts with `content`.\n* `instance_id` - (Required) Specifies the identifier of the hosting Amazon Connect Instance.\n* `name` - (Required) Specifies the name of the Contact Flow.\n* `tags` - (Optional) Tags to apply to the Contact Flow. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `type` - (Optional) Specifies the type of the Contact Flow. Defaults to `CONTACT_FLOW`. Allowed Values are: `CONTACT_FLOW`, `CUSTOMER_QUEUE`, `CUSTOMER_HOLD`, `CUSTOMER_WHISPER`, `AGENT_HOLD`, `AGENT_WHISPER`, `OUTBOUND_WHISPER`, `AGENT_TRANSFER`, `QUEUE_TRANSFER`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Contact Flow.\n* `id` - The identifier of the hosting Amazon Connect Instance and identifier of the Contact Flow separated by a colon (`:`).\n* `contact_flow_id` - The identifier of the Contact Flow.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/resources.html#timeouts) for certain actions:\n\n* `create` - (Defaults to 5 min) Used when creating the Contact Flow.\n* `update` - (Defaults to 5 min) Used when updating the Contact Flow.\n\n## Import\n\nAmazon Connect Contact Flows can be imported using the `instance_id` and `contact_flow_id` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_connect_contact_flow.example f1288a1f-6193-445a-b47e-af739b2:c1d4e5f6-1b3c-1b3c-1b3c-c1d4e5f6c1d4e5\n```\n",
    "basename": "connect_contact_flow.html"
  },
  "connect_hours_of_operation.html": {
    "subcategory": "Connect",
    "layout": "aws",
    "page_title": "AWS: aws_connect_hours_of_operation",
    "description": "Provides details about a specific Amazon Connect Hours of Operation.",
    "preview": "# Resource: aws_connect_hours_of_operation\n\nProvides an Amazon …",
    "content": "\n\n# Resource: aws_connect_hours_of_operation\n\nProvides an Amazon Connect Hours of Operation resource. For more information see\n[Amazon Connect: Getting Started](https://docs.aws.amazon.com/connect/latest/adminguide/amazon-connect-get-started.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_connect_hours_of_operation\" \"test\" {\n  instance_id = \"aaaaaaaa-bbbb-cccc-dddd-111111111111\"\n  name        = \"Office Hours\"\n  description = \"Monday office hours\"\n  time_zone   = \"EST\"\n\n  config {\n    day = \"MONDAY\"\n\n    end_time {\n      hours   = 23\n      minutes = 8\n    }\n\n    start_time {\n      hours   = 8\n      minutes = 0\n    }\n  }\n\n  config {\n    day = \"TUESDAY\"\n\n    end_time {\n      hours   = 21\n      minutes = 0\n    }\n\n    start_time {\n      hours   = 9\n      minutes = 0\n    }\n  }\n\n  tags = {\n    \"Name\" = \"Example Hours of Operation\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `config` - (Required) One or more config blocks which define the configuration information for the hours of operation: day, start time, and end time . Config blocks are documented below.\n* `description` - (Optional) Specifies the description of the Hours of Operation.\n* `instance_id` - (Required) Specifies the identifier of the hosting Amazon Connect Instance.\n* `name` - (Required) Specifies the name of the Hours of Operation.\n* `tags` - (Optional) Tags to apply to the Hours of Operation. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `time_zone` - (Required) Specifies the time zone of the Hours of Operation.\n\nA `config` blog supports the following arguments:\n\n* `day` - (Required) Specifies the day that the hours of operation applies to.\n* `end_time` - (Required) A end time block specifies the time that your contact center closes. The `end_time` is documented below.\n* `start_time` - (Required) A start time block specifies the time that your contact center opens. The `start_time` is documented below.\n\nA `end_time` blocks supports the following arguments:\n\n* `hours` - (Required) Specifies the hour of closing.\n* `minutes` - (Required) Specifies the minute of closing.\n\nA `start_time` blocks supports the following arguments:\n\n* `hours` - (Required) Specifies the hour of opening.\n* `minutes` - (Required) Specifies the minute of opening.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `hours_of_operation_arn` - The Amazon Resource Name (ARN) of the Hours of Operation.\n* `hours_of_operation_id` - The identifier for the hours of operation.\n* `id` - The identifier of the hosting Amazon Connect Instance and identifier of the Hours of Operation separated by a colon (`:`).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/resources.html#timeouts) for certain actions:\n\n* `create` - (Defaults to 5 min) Used when creating the Hours of Operation.\n* `update` - (Defaults to 5 min) Used when updating the Hours of Operation.\n\n## Import\n\nAmazon Connect Hours of Operations can be imported using the `instance_id` and `hours_of_operation_id` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_connect_hours_of_operation.example f1288a1f-6193-445a-b47e-af739b2:c1d4e5f6-1b3c-1b3c-1b3c-c1d4e5f6c1d4e5\n```\n",
    "basename": "connect_hours_of_operation.html"
  },
  "connect_instance.html": {
    "subcategory": "Connect",
    "layout": "aws",
    "page_title": "AWS: aws_connect_instance",
    "description": "Provides details about a specific Connect Instance.",
    "preview": "# Resource: aws_connect_instance\n\nProvides an Amazon Connect …",
    "content": "\n\n# Resource: aws_connect_instance\n\nProvides an Amazon Connect instance resource. For more information see\n[Amazon Connect: Getting Started](https://docs.aws.amazon.com/connect/latest/adminguide/amazon-connect-get-started.html)\n\n!> **WARN:** There are limits to the number of Connect Instances that can be created in a specific AWS account, and those limits span the life of the account, not just active Instances. Minimize the number of times you create/delete an instance.\n\n## Example Usage\n\n```terraform\nresource \"aws_connect_instance\" \"test\" {\n  identity_management_type = \"CONNECT_MANAGED\"\n  inbound_calls_enabled    = true\n  instance_alias           = \"friendly-name-connect\"\n  outbound_calls_enabled   = true\n}\n```\n\n## Example Usage with Existing Active Directory\n\n```terraform\nresource \"aws_connect_instance\" \"test\" {\n  directory_id             = aws_directory_service_directory.test.id\n  identity_management_type = \"EXISTING_DIRECTORY\"\n  inbound_calls_enabled    = true\n  instance_alias           = \"friendly-name-connect\"\n  outbound_calls_enabled   = true\n}\n```\n\n## Example Usage with SAML\n\n```terraform\nresource \"aws_connect_instance\" \"test\" {\n  identity_management_type = \"SAML\"\n  inbound_calls_enabled    = true\n  instance_alias           = \"friendly-name-connect\"\n  outbound_calls_enabled   = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `auto_resolve_best_voices_enabled` - (Optional) Specifies whether auto resolve best voices is enabled. Defaults to `true`.\n* `contact_flow_logs_enabled` - (Optional) Specifies whether contact flow logs are enabled. Defaults to `false`.\n* `contact_lens_enabled` - (Optional) Specifies whether contact lens is enabled. Defaults to `true`.\n* `directory_id` - (Optional) The identifier for the directory if identity_management_type is `EXISTING_DIRECTORY`.\n* `early_media_enabled` - (Optional) Specifies whether early media for outbound calls is enabled . Defaults to `true` if outbound calls is enabled.\n* `identity_management_type` - (Required) Specifies the identity management type attached to the instance. Allowed Values are: `SAML`, `CONNECT_MANAGED`, `EXISTING_DIRECTORY`.\n* `inbound_calls_enabled` - (Required) Specifies whether inbound calls are enabled.\n* `instance_alias` - (Optional) Specifies the name of the instance. Required if `directory_id` not specified.\n* `outbound_calls_enabled` - (Required) Specifies whether outbound calls are enabled.\n<!-- * `use_custom_tts_voices` - (Optional) Specifies Whether use custom tts voices is enabled. Defaults to `false` -->\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identifier of the instance.\n* `arn` - Amazon Resource Name (ARN) of the instance.\n* `created_time` - Specifies when the instance was created.\n* `service_role` - The service role of the instance.\n* `status` - The state of the instance.\n\n### Timeouts\n\n`aws_connect_instance` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Defaults to 5 mins) Used when creating the instance.\n* `delete` - (Defaults to 5 mins) Used when deleting the instance.\n\n## Import\n\nConnect instances can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_connect_instance.example f1288a1f-6193-445a-b47e-af739b2\n```\n",
    "basename": "connect_instance.html"
  },
  "connect_lambda_function_association": {
    "subcategory": "Connect",
    "layout": "aws",
    "page_title": "AWS: aws_connect_lambda_function_association",
    "description": "Provides details about a specific Connect Lambda Function Association.",
    "preview": "# Resource: aws_connect_lambda_function_association\n\nProvides an …",
    "content": "\n\n# Resource: aws_connect_lambda_function_association\n\nProvides an Amazon Connect Lambda Function Association. For more information see\n[Amazon Connect: Getting Started](https://docs.aws.amazon.com/connect/latest/adminguide/amazon-connect-get-started.html) and [Invoke AWS Lambda functions](https://docs.aws.amazon.com/connect/latest/adminguide/connect-lambda-functions.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_connect_lambda_function_association\" \"example\" {\n  function_arn = aws_lambda_function.example.arn\n  instance_id  = aws_connect_instance.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `function_arn` - (Required) Amazon Resource Name (ARN) of the Lambda Function, omitting any version or alias qualifier.\n* `instance_id` - (Required) The identifier of the Amazon Connect instance. You can find the instanceId in the ARN of the instance.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Connect instance ID and Lambda Function ARN separated by a comma (`,`).\n\n## Import\n\n`aws_connect_lambda_function_association` can be imported using the `instance_id` and `function_arn` separated by a comma (`,`) e.g.,\n\n```\n$ terraform import aws_connect_lambda_function_association.example aaaaaaaa-bbbb-cccc-dddd-111111111111,arn:aws:lambda:us-west-2:123456789123:function:example\n```\n",
    "basename": "connect_lambda_function_association"
  },
  "cur_report_definition.html": {
    "subcategory": "Cost and Usage Report",
    "layout": "aws",
    "page_title": "AWS: aws_cur_report_definition",
    "description": "Provides a Cost and Usage Report Definition.",
    "preview": "# Resource: aws_cur_report_definition\n\nManages Cost and Usage Report …",
    "content": "\n\n# Resource: aws_cur_report_definition\n\nManages Cost and Usage Report Definitions.\n\n~> *NOTE:* The AWS Cost and Usage Report service is only available in `us-east-1` currently.\n\n~> *NOTE:* If AWS Organizations is enabled, only the master account can use this resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_cur_report_definition\" \"example_cur_report_definition\" {\n  report_name                = \"example-cur-report-definition\"\n  time_unit                  = \"HOURLY\"\n  format                     = \"textORcsv\"\n  compression                = \"GZIP\"\n  additional_schema_elements = [\"RESOURCES\"]\n  s3_bucket                  = \"example-bucket-name\"\n  s3_region                  = \"us-east-1\"\n  additional_artifacts       = [\"REDSHIFT\", \"QUICKSIGHT\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `report_name` - (Required) Unique name for the report. Must start with a number/letter and is case sensitive. Limited to 256 characters.\n* `time_unit` - (Required) The frequency on which report data are measured and displayed.  Valid values are: `HOURLY`, `DAILY`.\n* `format` - (Required) Format for report. Valid values are: `textORcsv`, `Parquet`. If `Parquet` is used, then Compression must also be `Parquet`.\n* `compression` - (Required) Compression format for report. Valid values are: `GZIP`, `ZIP`, `Parquet`. If `Parquet` is used, then format must also be `Parquet`.\n* `additional_schema_elements` - (Required) A list of schema elements. Valid values are: `RESOURCES`.\n* `s3_bucket` - (Required) Name of the existing S3 bucket to hold generated reports.\n* `s3_prefix` - (Optional) Report path prefix. Limited to 256 characters.\n* `s3_region` - (Required) Region of the existing S3 bucket to hold generated reports.\n* `additional_artifacts` - (Required) A list of additional artifacts. Valid values are: `REDSHIFT`, `QUICKSIGHT`, `ATHENA`. When ATHENA exists within additional_artifacts, no other artifact type can be declared and report_versioning must be `OVERWRITE_REPORT`.\n* `refresh_closed_reports` - (Optional) Set to true to update your reports after they have been finalized if AWS detects charges related to previous months.\n* `report_versioning` - (Optional) Overwrite the previous version of each report or to deliver the report in addition to the previous versions. Valid values are: `CREATE_NEW_REPORT` and `OVERWRITE_REPORT`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) specifying the cur report.\n\n## Import\n\nReport Definitions can be imported using the `report_name`, e.g.,\n\n```\n$ terraform import aws_cur_report_definition.example_cur_report_definition example-cur-report-definition\n```\n",
    "basename": "cur_report_definition.html"
  },
  "customer_gateway.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_customer_gateway",
    "description": "Provides a customer gateway inside a VPC. These objects can be\nconnected to VPN gateways via VPN connections, and allow you to\nestablish tunnels between your network and the VPC.",
    "preview": "# Resource: aws_customer_gateway\n\nProvides a customer gateway inside …",
    "content": "\n\n# Resource: aws_customer_gateway\n\nProvides a customer gateway inside a VPC. These objects can be connected to VPN gateways via VPN connections, and allow you to establish tunnels between your network and the VPC.\n\n## Example Usage\n\n```terraform\nresource \"aws_customer_gateway\" \"main\" {\n  bgp_asn    = 65000\n  ip_address = \"172.83.124.10\"\n  type       = \"ipsec.1\"\n\n  tags = {\n    Name = \"main-customer-gateway\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bgp_asn` - (Required) The gateway's Border Gateway Protocol (BGP) Autonomous System Number (ASN).\n* `device_name` - (Optional) A name for the customer gateway device.\n* `ip_address` - (Required) The IP address of the gateway's Internet-routable external interface.\n* `type` - (Required) The type of customer gateway. The only type AWS\n  supports at this time is \"ipsec.1\".\n* `tags` - (Optional) Tags to apply to the gateway. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The amazon-assigned ID of the gateway.\n* `arn` - The ARN of the customer gateway.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCustomer Gateways can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_customer_gateway.main cgw-b4dc3961\n```\n",
    "basename": "customer_gateway.html"
  },
  "datapipeline_pipeline.html": {
    "subcategory": "DataPipeline",
    "layout": "aws",
    "page_title": "AWS: aws_datapipeline_pipeline",
    "description": "Provides a AWS DataPipeline Pipeline.",
    "preview": "# Resource: aws_datapipeline_pipeline\n\nProvides a Data Pipeline …",
    "content": "\n\n# Resource: aws_datapipeline_pipeline\n\nProvides a Data Pipeline resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_datapipeline_pipeline\" \"default\" {\n  name = \"tf-pipeline-default\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of Pipeline.\n* `description` - (Optional) The description of Pipeline.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identifier of the client certificate.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_datapipeline_pipeline` can be imported by using the id (Pipeline ID), e.g.,\n\n```\n$ terraform import aws_datapipeline_pipeline.default df-1234567890\n```\n",
    "basename": "datapipeline_pipeline.html"
  },
  "datasync_agent.html": {
    "subcategory": "DataSync",
    "layout": "aws",
    "page_title": "AWS: aws_datasync_agent",
    "description": "Manages an AWS DataSync Agent in the provider region",
    "preview": "# Resource: aws_datasync_agent\n\nManages an AWS DataSync Agent …",
    "content": "\n\n# Resource: aws_datasync_agent\n\nManages an AWS DataSync Agent deployed on premises.\n\n~> **NOTE:** One of `activation_key` or `ip_address` must be provided for resource creation (agent activation). Neither is required for resource import. If using `ip_address`, Terraform must be able to make an HTTP (port 80) GET request to the specified IP address from where it is running. The agent will turn off that HTTP server after activation.\n\n## Example Usage\n\n```terraform\nresource \"aws_datasync_agent\" \"example\" {\n  ip_address = \"1.2.3.4\"\n  name       = \"example\"\n}\n```\n\n## Example Usage with VPC Endpoints\n\n```hcl\nresource \"aws_datasync_agent\" \"example\" {\n  ip_address            = \"1.2.3.4\"\n  security_group_arns   = [aws_security_group.example.arn]\n  subnet_arns           = [aws_subnet.example.arn]\n  vpc_endpoint_id       = aws_vpc_endpoint.example.id\n  private_link_endpoint = data.aws_network_interface.example.private_ip\n  name                  = \"example\"\n}\n\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_endpoint\" \"example\" {\n  service_name       = \"com.amazonaws.${data.aws_region.current.name}.datasync\"\n  vpc_id             = aws_vpc.example.id\n  security_group_ids = [aws_security_group.example.id]\n  subnet_ids         = [aws_subnet.example.id]\n  vpc_endpoint_type  = \"Interface\"\n}\n\ndata \"aws_network_interface\" \"example\" {\n  id = tolist(aws_vpc_endpoint.example.network_interface_ids)[0]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the DataSync Agent.\n* `activation_key` - (Optional) DataSync Agent activation key during resource creation. Conflicts with `ip_address`. If an `ip_address` is provided instead, Terraform will retrieve the `activation_key` as part of the resource creation.\n* `ip_address` - (Optional) DataSync Agent IP address to retrieve activation key during resource creation. Conflicts with `activation_key`. DataSync Agent must be accessible on port 80 from where Terraform is running.\n* `private_link_endpoint` - (Optional) The IP address of the VPC endpoint the agent should connect to when retrieving an activation key during resource creation. Conflicts with `activation_key`.\n* `security_group_arns` - (Optional) The ARNs of the security groups used to protect your data transfer task subnets.\n* `subnet_arns` - (Optional) The Amazon Resource Names (ARNs) of the subnets in which DataSync will create elastic network interfaces for each data transfer task.\n* `tags` - (Optional) Key-value pairs of resource tags to assign to the DataSync Agent. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_endpoint_id` - (Optional) The ID of the VPC (virtual private cloud) endpoint that the agent has access to.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the DataSync Agent.\n* `arn` - Amazon Resource Name (ARN) of the DataSync Agent.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_datasync_agent` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `10m`) How long to wait for agent activation and connection to DataSync.\n\n## Import\n\n`aws_datasync_agent` can be imported by using the DataSync Agent Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_datasync_agent.example arn:aws:datasync:us-east-1:123456789012:agent/agent-12345678901234567\n```\n",
    "basename": "datasync_agent.html"
  },
  "datasync_location_efs.html": {
    "subcategory": "DataSync",
    "layout": "aws",
    "page_title": "AWS: aws_datasync_location_efs",
    "description": "Manages an EFS Location within AWS DataSync.",
    "preview": "# Resource: aws_datasync_location_efs\n\nManages an AWS DataSync EFS …",
    "content": "\n\n# Resource: aws_datasync_location_efs\n\nManages an AWS DataSync EFS Location.\n\n~> **NOTE:** The EFS File System must have a mounted EFS Mount Target before creating this resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_datasync_location_efs\" \"example\" {\n  # The below example uses aws_efs_mount_target as a reference to ensure a mount target already exists when resource creation occurs.\n  # You can accomplish the same behavior with depends_on or an aws_efs_mount_target data source reference.\n  efs_file_system_arn = aws_efs_mount_target.example.file_system_arn\n\n  ec2_config {\n    security_group_arns = [aws_security_group.example.arn]\n    subnet_arn          = aws_subnet.example.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `ec2_config` - (Required) Configuration block containing EC2 configurations for connecting to the EFS File System.\n* `efs_file_system_arn` - (Required) Amazon Resource Name (ARN) of EFS File System.\n* `subdirectory` - (Optional) Subdirectory to perform actions as source or destination. Default `/`.\n* `tags` - (Optional) Key-value pairs of resource tags to assign to the DataSync Location. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### ec2_config Argument Reference\n\nThe following arguments are supported inside the `ec2_config` configuration block:\n\n* `security_group_arns` - (Required) List of Amazon Resource Names (ARNs) of the EC2 Security Groups that are associated with the EFS Mount Target.\n* `subnet_arn` - (Required) Amazon Resource Name (ARN) of the EC2 Subnet that is associated with the EFS Mount Target.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the DataSync Location.\n* `arn` - Amazon Resource Name (ARN) of the DataSync Location.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_datasync_location_efs` can be imported by using the DataSync Task Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_datasync_location_efs.example arn:aws:datasync:us-east-1:123456789012:location/loc-12345678901234567\n```\n",
    "basename": "datasync_location_efs.html"
  },
  "datasync_location_fsx_windows_file_system.html": {
    "subcategory": "DataSync",
    "layout": "aws",
    "page_title": "AWS: aws_datasync_location_fsx_windows_file_system",
    "description": "Manages an FSx Windows Location within AWS DataSync.",
    "preview": "# Resource: aws_datasync_location_fsx_windows_file_system\n\nManages …",
    "content": "\n\n# Resource: aws_datasync_location_fsx_windows_file_system\n\nManages an AWS DataSync FSx Windows Location.\n\n## Example Usage\n\n```terraform\nresource \"aws_datasync_location_fsx_windows_file_system\" \"example\" {\n  fsx_filesystem_arn  = aws_fsx_windows_file_system.example.arn\n  user                = \"SomeUser\"\n  password            = \"SuperSecretPassw0rd\"\n  security_group_arns = [aws_security_group.example.arn]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `fsx_filesystem_arn` - (Required) The Amazon Resource Name (ARN) for the FSx for Windows file system.\n* `password` - (Required) The password of the user who has the permissions to access files and folders in the FSx for Windows file system.\n* `user` - (Required) The user who has the permissions to access files and folders in the FSx for Windows file system.\n* `domain` - (Optional) The name of the Windows domain that the FSx for Windows server belongs to.\n* `security_group_arns` - (Optional) The Amazon Resource Names (ARNs) of the security groups that are to use to configure the FSx for Windows file system.\n* `subdirectory` - (Optional) Subdirectory to perform actions as source or destination.\n* `tags` - (Optional) Key-value pairs of resource tags to assign to the DataSync Location. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the DataSync Location.\n* `arn` - Amazon Resource Name (ARN) of the DataSync Location.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `uri` - The URL of the FSx for Windows location that was described.\n* `creation_time` - The time that the FSx for Windows location was created.\n\n## Import\n\n`aws_datasync_location_fsx_windows_file_system` can be imported by using the `DataSync-ARN#FSx-Windows-ARN`, e.g.,\n\n```\n$ terraform import aws_datasync_location_fsx_windows_file_system.example arn:aws:datasync:us-west-2:123456789012:location/loc-12345678901234567#arn:aws:fsx:us-west-2:476956259333:file-system/fs-08e04cd442c1bb94a\n```\n",
    "basename": "datasync_location_fsx_windows_file_system.html"
  },
  "datasync_location_nfs.html": {
    "subcategory": "DataSync",
    "layout": "aws",
    "page_title": "AWS: aws_datasync_location_nfs",
    "description": "Manages an AWS DataSync NFS Location",
    "preview": "# Resource: aws_datasync_location_nfs\n\nManages an NFS Location …",
    "content": "\n\n# Resource: aws_datasync_location_nfs\n\nManages an NFS Location within AWS DataSync.\n\n~> **NOTE:** The DataSync Agents must be available before creating this resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_datasync_location_nfs\" \"example\" {\n  server_hostname = \"nfs.example.com\"\n  subdirectory    = \"/exported/path\"\n\n  on_prem_config {\n    agent_arns = [aws_datasync_agent.example.arn]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `mount_options` - (Optional) Configuration block containing mount options used by DataSync to access the NFS Server.\n* `on_prem_config` - (Required) Configuration block containing information for connecting to the NFS File System.\n* `server_hostname` - (Required) Specifies the IP address or DNS name of the NFS server. The DataSync Agent(s) use this to mount the NFS server.\n* `subdirectory` - (Required) Subdirectory to perform actions as source or destination. Should be exported by the NFS server.\n* `tags` - (Optional) Key-value pairs of resource tags to assign to the DataSync Location. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### mount_options Argument Reference\n\nThe following arguments are supported inside the `mount_options` configuration block:\n\n* `version` - (Optional) The specific NFS version that you want DataSync to use for mounting your NFS share. Valid values: `AUTOMATIC`, `NFS3`, `NFS4_0` and `NFS4_1`. Default: `AUTOMATIC`\n\n### on_prem_config Argument Reference\n\nThe following arguments are supported inside the `on_prem_config` configuration block:\n\n* `agent_arns` - (Required) List of Amazon Resource Names (ARNs) of the DataSync Agents used to connect to the NFS server.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the DataSync Location.\n* `arn` - Amazon Resource Name (ARN) of the DataSync Location.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_datasync_location_nfs` can be imported by using the DataSync Task Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_datasync_location_nfs.example arn:aws:datasync:us-east-1:123456789012:location/loc-12345678901234567\n```\n",
    "basename": "datasync_location_nfs.html"
  },
  "datasync_location_s3.html": {
    "subcategory": "DataSync",
    "layout": "aws",
    "page_title": "AWS: aws_datasync_location_s3",
    "description": "Manages an AWS DataSync S3 Location",
    "preview": "# Resource: aws_datasync_location_s3\n\nManages an S3 Location within …",
    "content": "\n\n# Resource: aws_datasync_location_s3\n\nManages an S3 Location within AWS DataSync.\n\n## Example Usage\n\n```terraform\nresource \"aws_datasync_location_s3\" \"example\" {\n  s3_bucket_arn = aws_s3_bucket.example.arn\n  subdirectory  = \"/example/prefix\"\n\n  s3_config {\n    bucket_access_role_arn = aws_iam_role.example.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `agent_arns` - (Optional) A list of DataSync Agent ARNs with which this location will be associated.\n* `s3_bucket_arn` - (Required) Amazon Resource Name (ARN) of the S3 Bucket.\n* `s3_config` - (Required) Configuration block containing information for connecting to S3.\n* `s3_storage_class` - (Optional) The Amazon S3 storage class that you want to store your files in when this location is used as a task destination. [Valid values](https://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html#using-storage-classes)  \n* `subdirectory` - (Required) Prefix to perform actions as source or destination.\n* `tags` - (Optional) Key-value pairs of resource tags to assign to the DataSync Location. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### s3_config Argument Reference\n\nThe following arguments are supported inside the `s3_config` configuration block:\n\n* `bucket_access_role_arn` - (Required) Amazon Resource Names (ARN) of the IAM Role used to connect to the S3 Bucket.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the DataSync Location.\n* `arn` - Amazon Resource Name (ARN) of the DataSync Location.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_datasync_location_s3` can be imported by using the DataSync Task Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_datasync_location_s3.example arn:aws:datasync:us-east-1:123456789012:location/loc-12345678901234567\n```\n",
    "basename": "datasync_location_s3.html"
  },
  "datasync_location_smb.html": {
    "subcategory": "DataSync",
    "layout": "aws",
    "page_title": "AWS: aws_datasync_location_smb",
    "description": "Manages an AWS DataSync SMB Location",
    "preview": "# Resource: aws_datasync_location_smb\n\nManages a SMB Location within …",
    "content": "\n\n# Resource: aws_datasync_location_smb\n\nManages a SMB Location within AWS DataSync.\n\n~> **NOTE:** The DataSync Agents must be available before creating this resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_datasync_location_smb\" \"example\" {\n  server_hostname = \"smb.example.com\"\n  subdirectory    = \"/exported/path\"\n\n  user     = \"Guest\"\n  password = \"ANotGreatPassword\"\n\n  agent_arns = [aws_datasync_agent.example.arn]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `agent_arns` - (Required) A list of DataSync Agent ARNs with which this location will be associated.\n* `domain` - (Optional) The name of the Windows domain the SMB server belongs to.\n* `mount_options` - (Optional) Configuration block containing mount options used by DataSync to access the SMB Server. Can be `AUTOMATIC`, `SMB2`, or `SMB3`.\n* `password` - (Required) The password of the user who can mount the share and has file permissions in the SMB.\n* `server_hostname` - (Required) Specifies the IP address or DNS name of the SMB server. The DataSync Agent(s) use this to mount the SMB share.\n* `subdirectory` - (Required) Subdirectory to perform actions as source or destination. Should be exported by the NFS server.\n* `tags` - (Optional) Key-value pairs of resource tags to assign to the DataSync Location. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `user` - (Required) The user who can mount the share and has file and folder permissions in the SMB share.\n\n### mount_options Argument Reference\n\nThe following arguments are supported inside the `mount_options` configuration block:\n\n* `version` - (Optional) The specific SMB version that you want DataSync to use for mounting your SMB share. Valid values: `AUTOMATIC`, `SMB2`, and `SMB3`. Default: `AUTOMATIC`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the DataSync Location.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_datasync_location_smb` can be imported by using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_datasync_location_smb.example arn:aws:datasync:us-east-1:123456789012:location/loc-12345678901234567\n```\n",
    "basename": "datasync_location_smb.html"
  },
  "datasync_task.html": {
    "subcategory": "DataSync",
    "layout": "aws",
    "page_title": "AWS: aws_datasync_task",
    "description": "Manages an AWS DataSync Task",
    "preview": "# Resource: aws_datasync_task\n\nManages an AWS DataSync Task, which …",
    "content": "\n\n# Resource: aws_datasync_task\n\nManages an AWS DataSync Task, which represents a configuration for synchronization. Starting an execution of these DataSync Tasks (actually synchronizing files) is performed outside of this Terraform resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_datasync_task\" \"example\" {\n  destination_location_arn = aws_datasync_location_s3.destination.arn\n  name                     = \"example\"\n  source_location_arn      = aws_datasync_location_nfs.source.arn\n\n  options {\n    bytes_per_second = -1\n  }\n}\n```\n\n## Example Usage with Scheduling\n\n```terraform\nresource \"aws_datasync_task\" \"example\" {\n  destination_location_arn = aws_datasync_location_s3.destination.arn\n  name                     = \"example\"\n  source_location_arn      = aws_datasync_location_nfs.source.arn\n\n  schedule {\n    schedule_expression = \"cron(0 12 ? * SUN,WED *)\"\n  }\n}\n```\n\n## Example Usage with Filtering\n\n```hcl\nresource \"aws_datasync_task\" \"example\" {\n  destination_location_arn = aws_datasync_location_s3.destination.arn\n  name                     = \"example\"\n  source_location_arn      = aws_datasync_location_nfs.source.arn\n\n  excludes {\n    filter_type = \"SIMPLE_PATTERN\"\n    value       = \"/folder1|/folder2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `destination_location_arn` - (Required) Amazon Resource Name (ARN) of destination DataSync Location.\n* `source_location_arn` - (Required) Amazon Resource Name (ARN) of source DataSync Location.\n* `cloudwatch_log_group_arn` - (Optional) Amazon Resource Name (ARN) of the CloudWatch Log Group that is used to monitor and log events in the sync task.\n* `excludes` - (Optional) Filter rules that determines which files to exclude from a task.\n* `name` - (Optional) Name of the DataSync Task.\n* `options` - (Optional) Configuration block containing option that controls the default behavior when you start an execution of this DataSync Task. For each individual task execution, you can override these options by specifying an overriding configuration in those executions.\n* `schedule` - (Optional) Specifies a schedule used to periodically transfer files from a source to a destination location.\n* `tags` - (Optional) Key-value pairs of resource tags to assign to the DataSync Task. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### options Argument Reference\n\n~> **NOTE:** If `atime` is set to `BEST_EFFORT`, `mtime` must be set to `PRESERVE`. If `atime` is set to `NONE`, `mtime` must be set to `NONE`.\n\nThe following arguments are supported inside the `options` configuration block:\n\n* `atime` - (Optional) A file metadata that shows the last time a file was accessed (that is when the file was read or written to). If set to `BEST_EFFORT`, the DataSync Task attempts to preserve the original (that is, the version before sync `PREPARING` phase) `atime` attribute on all source files. Valid values: `BEST_EFFORT`, `NONE`. Default: `BEST_EFFORT`.\n* `bytes_per_second` - (Optional) Limits the bandwidth utilized. For example, to set a maximum of 1 MB, set this value to `1048576`. Value values: `-1` or greater. Default: `-1` (unlimited).\n* `gid` - (Optional) Group identifier of the file's owners. Valid values: `BOTH`, `INT_VALUE`, `NAME`, `NONE`. Default: `INT_VALUE` (preserve integer value of the ID).\n* `log_level` - (Optional) Determines the type of logs that DataSync publishes to a log stream in the Amazon CloudWatch log group that you provide. Valid values: `OFF`, `BASIC`, `TRANSFER`. Default: `OFF`.\n* `mtime` - (Optional) A file metadata that indicates the last time a file was modified (written to) before the sync `PREPARING` phase. Value values: `NONE`, `PRESERVE`. Default: `PRESERVE`.\n* `overwrite_mode` - (Optional) Determines whether files at the destination should be overwritten or preserved when copying files. Valid values: `ALWAYS`, `NEVER`. Default: `ALWAYS`.\n* `posix_permissions` - (Optional) Determines which users or groups can access a file for a specific purpose such as reading, writing, or execution of the file. Valid values: `NONE`, `PRESERVE`. Default: `PRESERVE`.\n* `preserve_deleted_files` - (Optional) Whether files deleted in the source should be removed or preserved in the destination file system. Valid values: `PRESERVE`, `REMOVE`. Default: `PRESERVE`.\n* `preserve_devices` - (Optional) Whether the DataSync Task should preserve the metadata of block and character devices in the source files system, and recreate the files with that device name and metadata on the destination. The DataSync Task can’t sync the actual contents of such devices, because many of the devices are non-terminal and don’t return an end of file (EOF) marker. Valid values: `NONE`, `PRESERVE`. Default: `NONE` (ignore special devices).\n* `task_queueing` - (Optional) Determines whether tasks should be queued before executing the tasks. Valid values: `ENABLED`, `DISABLED`. Default `ENABLED`.\n* `transfer_mode` - (Optional) Determines whether DataSync transfers only the data and metadata that differ between the source and the destination location, or whether DataSync transfers all the content from the source, without comparing to the destination location. Valid values: `CHANGED`, `ALL`. Default: `CHANGED`\n* `uid` - (Optional) User identifier of the file's owners. Valid values: `BOTH`, `INT_VALUE`, `NAME`, `NONE`. Default: `INT_VALUE` (preserve integer value of the ID).\n* `verify_mode` - (Optional) Whether a data integrity verification should be performed at the end of a task execution after all data and metadata have been transferred. Valid values: `NONE`, `POINT_IN_TIME_CONSISTENT`, `ONLY_FILES_TRANSFERRED`. Default: `POINT_IN_TIME_CONSISTENT`.\n\n### Schedule\n\n* `schedule_expression` - (Required) Specifies the schedule you want your task to use for repeated executions. For more information, see [Schedule Expressions for Rules](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html).\n\n### excludes Argument Reference\n\n* `filter_type` - (Optional) The type of filter rule to apply. Valid values: `SIMPLE_PATTERN`.\n* `value` - (Optional) A single filter string that consists of the patterns to include or exclude. The patterns are delimited by \"|\" (that is, a pipe), for example: `/folder1|/folder2`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the DataSync Task.\n* `arn` - Amazon Resource Name (ARN) of the DataSync Task.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_datasync_task` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `5m`) How long to wait for DataSync Task availability.\n\n## Import\n\n`aws_datasync_task` can be imported by using the DataSync Task Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_datasync_task.example arn:aws:datasync:us-east-1:123456789012:task/task-12345678901234567\n```\n",
    "basename": "datasync_task.html"
  },
  "dax_cluster.html": {
    "subcategory": "DynamoDB Accelerator (DAX)",
    "layout": "aws",
    "page_title": "AWS: aws_dax_cluster",
    "description": "Provides an DAX Cluster resource.",
    "preview": "# Resource: aws_dax_cluster\n\nProvides a DAX Cluster resource.\n\n## …",
    "content": "\n\n# Resource: aws_dax_cluster\n\nProvides a DAX Cluster resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dax_cluster\" \"bar\" {\n  cluster_name       = \"cluster-example\"\n  iam_role_arn       = data.aws_iam_role.example.arn\n  node_type          = \"dax.r4.large\"\n  replication_factor = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_name` – (Required) Group identifier. DAX converts this name to\nlowercase\n\n* `iam_role_arn` - (Required) A valid Amazon Resource Name (ARN) that identifies\nan IAM role. At runtime, DAX will assume this role and use the role's\npermissions to access DynamoDB on your behalf\n\n* `node_type` – (Required) The compute and memory capacity of the nodes. See\n[Nodes][1] for supported node types\n\n* `replication_factor` – (Required) The number of nodes in the DAX cluster. A\nreplication factor of 1 will create a single-node cluster, without any read\nreplicas\n\n* `availability_zones` - (Optional) List of Availability Zones in which the\nnodes will be created\n\n* `description` – (Optional) Description for the cluster\n\n* `notification_topic_arn` – (Optional) An Amazon Resource Name (ARN) of an\nSNS topic to send DAX notifications to. Example:\n`arn:aws:sns:us-east-1:012345678999:my_sns_topic`\n\n* `parameter_group_name` – (Optional) Name of the parameter group to associate\nwith this DAX cluster\n\n* `maintenance_window` – (Optional) Specifies the weekly time range for when\nmaintenance on the cluster is performed. The format is `ddd:hh24:mi-ddd:hh24:mi`\n(24H Clock UTC). The minimum maintenance window is a 60 minute period. Example:\n`sun:05:00-sun:09:00`\n\n* `security_group_ids` – (Optional) One or more VPC security groups associated\nwith the cluster\n\n* `server_side_encryption` - (Optional) Encrypt at rest options\n\n* `subnet_group_name` – (Optional) Name of the subnet group to be used for the\ncluster\n\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `server_side_encryption` object supports the following:\n\n* `enabled` - (Optional) Whether to enable encryption at rest. Defaults to `false`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the DAX cluster\n\n* `nodes` - List of node objects including `id`, `address`, `port` and\n`availability_zone`. Referenceable e.g., as\n`${aws_dax_cluster.test.nodes.0.address}`\n\n* `configuration_endpoint` - The configuration endpoint for this DAX cluster,\nconsisting of a DNS name and a port number\n\n* `cluster_address` - The DNS name of the DAX cluster without the port appended\n\n* `port` - The port used by the configuration endpoint\n\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dax_cluster` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `45 minutes`) Used for creating a DAX cluster\n- `update` - (Default `45 minutes`) Used for cluster modifications\n- `delete` - (Default `90 minutes`) Used for destroying a DAX cluster\n\n## Import\n\nDAX Clusters can be imported using the `cluster_name`, e.g.,\n\n```\n$ terraform import aws_dax_cluster.my_cluster my_cluster\n```\n\n[1]: http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.concepts.cluster.html#DAX.concepts.nodes\n",
    "basename": "dax_cluster.html"
  },
  "dax_parameter_group.html": {
    "subcategory": "DynamoDB Accelerator (DAX)",
    "layout": "aws",
    "page_title": "AWS: aws_dax_parameter_group",
    "description": "Provides an DAX Parameter Group resource.",
    "preview": "# Resource: aws_dax_parameter_group\n\nProvides a DAX Parameter Group …",
    "content": "\n\n# Resource: aws_dax_parameter_group\n\nProvides a DAX Parameter Group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dax_parameter_group\" \"example\" {\n  name = \"example\"\n\n  parameters {\n    name  = \"query-ttl-millis\"\n    value = \"100000\"\n  }\n\n  parameters {\n    name  = \"record-ttl-millis\"\n    value = \"100000\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` – (Required) The name of the parameter group.\n\n* `description` - (Optional, ForceNew) A description of the parameter group.\n\n* `parameters` – (Optional) The parameters of the parameter group.\n\n## parameters\n\n`parameters` supports the following:\n\n* `name` - (Required) The name of the parameter.\n* `value` - (Required) The value for the parameter.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the parameter group.\n\n## Import\n\nDAX Parameter Group can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_dax_parameter_group.example my_dax_pg\n```\n",
    "basename": "dax_parameter_group.html"
  },
  "dax_subnet_group.html": {
    "subcategory": "DynamoDB Accelerator (DAX)",
    "layout": "aws",
    "page_title": "AWS: aws_dax_subnet_group",
    "description": "Provides an DAX Subnet Group resource.",
    "preview": "# Resource: aws_dax_subnet_group\n\nProvides a DAX Subnet Group …",
    "content": "\n\n# Resource: aws_dax_subnet_group\n\nProvides a DAX Subnet Group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dax_subnet_group\" \"example\" {\n  name       = \"example\"\n  subnet_ids = [aws_subnet.example1.id, aws_subnet.example2.id]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` – (Required) The name of the subnet group.\n* `description` - (Optional) A description of the subnet group.\n* `subnet_ids` – (Required) A list of VPC subnet IDs for the subnet group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the subnet group.\n* `vpc_id` – VPC ID of the subnet group.\n\n## Import\n\nDAX Subnet Group can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_dax_subnet_group.example my_dax_sg\n```\n",
    "basename": "dax_subnet_group.html"
  },
  "db_cluster_snapshot.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_cluster_snapshot",
    "description": "Manages an RDS database cluster snapshot.",
    "preview": "# Resource: aws_db_cluster_snapshot\n\nManages an RDS database cluster …",
    "content": "\n\n# Resource: aws_db_cluster_snapshot\n\nManages an RDS database cluster snapshot for Aurora clusters. For managing RDS database instance snapshots, see the [`aws_db_snapshot` resource](/docs/providers/aws/r/db_snapshot.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_db_cluster_snapshot\" \"example\" {\n  db_cluster_identifier          = aws_rds_cluster.example.id\n  db_cluster_snapshot_identifier = \"resourcetestsnapshot1234\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_cluster_identifier` - (Required) The DB Cluster Identifier from which to take the snapshot.\n* `db_cluster_snapshot_identifier` - (Required) The Identifier for the snapshot.\n* `tags` - (Optional) A map of tags to assign to the DB cluster. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `allocated_storage` - Specifies the allocated storage size in gigabytes (GB).\n* `availability_zones` - List of EC2 Availability Zones that instances in the DB cluster snapshot can be restored in.\n* `db_cluster_snapshot_arn` - The Amazon Resource Name (ARN) for the DB Cluster Snapshot.\n* `engine` - Specifies the name of the database engine.\n* `engine_version` - Version of the database engine for this DB cluster snapshot.\n* `kms_key_id` - If storage_encrypted is true, the AWS KMS key identifier for the encrypted DB cluster snapshot.\n* `license_model` - License model information for the restored DB cluster.\n* `port` - Port that the DB cluster was listening on at the time of the snapshot.\n* `source_db_cluster_snapshot_identifier` - The DB Cluster Snapshot Arn that the DB Cluster Snapshot was copied from. It only has value in case of cross customer or cross region copy.\n* `storage_encrypted` - Specifies whether the DB cluster snapshot is encrypted.\n* `status` - The status of this DB Cluster Snapshot.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` - The VPC ID associated with the DB cluster snapshot.\n\n## Timeouts\n\n`aws_db_cluster_snapshot` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `20m`) How long to wait for the snapshot to be available.\n\n## Import\n\n`aws_db_cluster_snapshot` can be imported by using the cluster snapshot identifier, e.g.,\n\n```\n$ terraform import aws_db_cluster_snapshot.example my-cluster-snapshot\n```\n",
    "basename": "db_cluster_snapshot.html"
  },
  "db_event_subscription.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_event_subscription",
    "description": "Provides a DB event subscription resource.",
    "preview": "# Resource: aws_db_event_subscription\n\nProvides a DB event …",
    "content": "\n\n# Resource: aws_db_event_subscription\n\nProvides a DB event subscription resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_db_instance\" \"default\" {\n  allocated_storage    = 10\n  engine               = \"mysql\"\n  engine_version       = \"5.6.17\"\n  instance_class       = \"db.t2.micro\"\n  name                 = \"mydb\"\n  username             = \"foo\"\n  password             = \"bar\"\n  db_subnet_group_name = \"my_database_subnet_group\"\n  parameter_group_name = \"default.mysql5.6\"\n}\n\nresource \"aws_sns_topic\" \"default\" {\n  name = \"rds-events\"\n}\n\nresource \"aws_db_event_subscription\" \"default\" {\n  name      = \"rds-event-sub\"\n  sns_topic = aws_sns_topic.default.arn\n\n  source_type = \"db-instance\"\n  source_ids  = [aws_db_instance.default.id]\n\n  event_categories = [\n    \"availability\",\n    \"deletion\",\n    \"failover\",\n    \"failure\",\n    \"low storage\",\n    \"maintenance\",\n    \"notification\",\n    \"read replica\",\n    \"recovery\",\n    \"restoration\",\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the DB event subscription. By default generated by Terraform.\n* `name_prefix` - (Optional) The name of the DB event subscription. Conflicts with `name`.\n* `sns_topic` - (Required) The SNS topic to send events to.\n* `source_ids` - (Optional) A list of identifiers of the event sources for which events will be returned. If not specified, then all sources are included in the response. If specified, a source_type must also be specified.\n* `source_type` - (Optional) The type of source that will be generating the events. Valid options are `db-instance`, `db-security-group`, `db-parameter-group`, `db-snapshot`, `db-cluster` or `db-cluster-snapshot`. If not set, all sources will be subscribed to.\n* `event_categories` - (Optional) A list of event categories for a SourceType that you want to subscribe to. See http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html or run `aws rds describe-event-categories`.\n* `enabled` - (Optional) A boolean flag to enable/disable the subscription. Defaults to true.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the RDS event notification subscription\n* `arn` - The Amazon Resource Name of the RDS event notification subscription\n* `customer_aws_id` - The AWS customer account associated with the RDS event notification subscription\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_db_event_subscription` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `40m`) How long to wait for an RDS event notification subscription to be ready.\n- `delete` - (Default `40m`) How long to wait for an RDS event notification subscription to be deleted.\n- `update` - (Default `40m`) How long to wait for an RDS event notification subscription to be updated.\n\n## Import\n\nDB Event Subscriptions can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_db_event_subscription.default rds-event-sub\n```\n",
    "basename": "db_event_subscription.html"
  },
  "db_instance.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_instance",
    "description": "Provides an RDS instance resource.",
    "preview": "# Resource: aws_db_instance\n\nProvides an RDS instance resource.  A …",
    "content": "\n\n# Resource: aws_db_instance\n\nProvides an RDS instance resource.  A DB instance is an isolated database\nenvironment in the cloud.  A DB instance can contain multiple user-created\ndatabases.\n\nChanges to a DB instance can occur when you manually change a parameter, such as\n`allocated_storage`, and are reflected in the next maintenance window. Because\nof this, Terraform may report a difference in its planning phase because a\nmodification has not yet taken place. You can use the `apply_immediately` flag\nto instruct the service to apply the change immediately (see documentation\nbelow).\n\nWhen upgrading the major version of an engine, `allow_major_version_upgrade`\nmust be set to `true`.\n\n~> **Note:** using `apply_immediately` can result in a brief downtime as the\nserver reboots. See the AWS Docs on [RDS Maintenance][2] for more information.\n\n~> **Note:** All arguments including the username and password will be stored in\nthe raw state as plain-text. [Read more about sensitive data in\nstate](https://www.terraform.io/docs/state/sensitive-data.html).\n\n> **Hands-on:** Try the [Manage AWS RDS Instances](https://learn.hashicorp.com/tutorials/terraform/aws-rds?in=terraform/modules&utm_source=WEBSITE&utm_medium=WEB_IO&utm_offer=ARTICLE_PAGE&utm_content=DOCS) tutorial on HashiCorp Learn.\n\n## RDS Instance Class Types\nAmazon RDS supports three types of instance classes: Standard, Memory Optimized,\nand Burstable Performance. For more information please read the AWS RDS documentation\nabout [DB Instance Class Types](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html)\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_db_instance\" \"default\" {\n  allocated_storage    = 10\n  engine               = \"mysql\"\n  engine_version       = \"5.7\"\n  instance_class       = \"db.t3.micro\"\n  name                 = \"mydb\"\n  username             = \"foo\"\n  password             = \"foobarbaz\"\n  parameter_group_name = \"default.mysql5.7\"\n  skip_final_snapshot  = true\n}\n```\n\n### Storage Autoscaling\n\nTo enable Storage Autoscaling with instances that support the feature, define the `max_allocated_storage` argument higher than the `allocated_storage` argument. Terraform will automatically hide differences with the `allocated_storage` argument value if autoscaling occurs.\n\n```terraform\nresource \"aws_db_instance\" \"example\" {\n  # ... other configuration ...\n\n  allocated_storage     = 50\n  max_allocated_storage = 100\n}\n```\n\n## Argument Reference\n\nFor more detailed documentation about each argument, refer to the [AWS official\ndocumentation](http://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBInstance.html).\n\nThe following arguments are supported:\n\n* `allocated_storage` - (Required unless a `snapshot_identifier` or `replicate_source_db` is provided) The allocated storage in gibibytes. If `max_allocated_storage` is configured, this argument represents the initial storage allocation and differences from the configuration will be ignored automatically when Storage Autoscaling occurs. If `replicate_source_db` is set, the value is ignored during the creation of the instance.\n* `allow_major_version_upgrade` - (Optional) Indicates that major version\nupgrades are allowed. Changing this parameter does not result in an outage and\nthe change is asynchronously applied as soon as possible.\n* `apply_immediately` - (Optional) Specifies whether any database modifications\nare applied immediately, or during the next maintenance window. Default is\n`false`. See [Amazon RDS Documentation for more\ninformation.](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html)\n* `auto_minor_version_upgrade` - (Optional) Indicates that minor engine upgrades\nwill be applied automatically to the DB instance during the maintenance window.\nDefaults to true.\n* `availability_zone` - (Optional) The AZ for the RDS instance.\n* `backup_retention_period` - (Optional) The days to retain backups for. Must be\nbetween `0` and `35`. Must be greater than `0` if the database is used as a source for a Read Replica. [See Read Replica][1].\n* `backup_window` - (Optional) The daily time range (in UTC) during which\nautomated backups are created if they are enabled. Example: \"09:46-10:16\". Must\nnot overlap with `maintenance_window`.\n* `ca_cert_identifier` - (Optional) The identifier of the CA certificate for the DB instance.\n* `character_set_name` - (Optional) The character set name to use for DB\nencoding in Oracle and Microsoft SQL instances (collation). This can't be changed. See [Oracle Character Sets\nSupported in Amazon RDS](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.OracleCharacterSets.html)\nor [Server-Level Collation for Microsoft SQL Server](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.SQLServer.CommonDBATasks.Collation.html) for more information.\n* `copy_tags_to_snapshot` – (Optional, boolean) Copy all Instance `tags` to snapshots. Default is `false`.\n* `db_subnet_group_name` - (Optional) Name of [DB subnet group](/docs/providers/aws/r/db_subnet_group.html). DB instance will\nbe created in the VPC associated with the DB subnet group. If unspecified, will\nbe created in the `default` VPC, or in EC2 Classic, if available. When working\nwith read replicas, it should be specified only if the source database\nspecifies an instance in another AWS Region. See [DBSubnetGroupName in API\naction CreateDBInstanceReadReplica](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBInstanceReadReplica.html)\nfor additional read replica contraints.\n* `delete_automated_backups` - (Optional) Specifies whether to remove automated backups immediately after the DB instance is deleted. Default is `true`.\n* `deletion_protection` - (Optional) If the DB instance should have deletion protection enabled. The database can't be deleted when this value is set to `true`. The default is `false`.\n* `domain` - (Optional) The ID of the Directory Service Active Directory domain to create the instance in.\n* `domain_iam_role_name` - (Optional, but required if domain is provided) The name of the IAM role to be used when making API calls to the Directory Service.\n* `enabled_cloudwatch_logs_exports` - (Optional) Set of log types to enable for exporting to CloudWatch logs. If omitted, no logs will be exported. Valid values (depending on `engine`). MySQL and MariaDB: `audit`, `error`, `general`, `slowquery`. PostgreSQL: `postgresql`, `upgrade`. MSSQL: `agent` , `error`. Oracle: `alert`, `audit`, `listener`, `trace`.\n* `engine` - (Required unless a `snapshot_identifier` or `replicate_source_db`\nis provided) The database engine to use.  For supported values, see the Engine parameter in [API action CreateDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBInstance.html).\nNote that for Amazon Aurora instances the engine must match the [DB cluster](/docs/providers/aws/r/rds_cluster.html)'s engine'.\nFor information on the difference between the available Aurora MySQL engines\nsee [Comparison between Aurora MySQL 1 and Aurora MySQL 2](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.Updates.20180206.html)\nin the Amazon RDS User Guide.\n* `engine_version` - (Optional) The engine version to use. If `auto_minor_version_upgrade`\nis enabled, you can provide a prefix of the version such as `5.7` (for `5.7.10`).\nThe actual engine version used is returned in the attribute `engine_version_actual`, [defined below](#engine_version_actual).\nFor supported values, see the EngineVersion parameter in [API action CreateDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBInstance.html).\nNote that for Amazon Aurora instances the engine version must match the [DB cluster](/docs/providers/aws/r/rds_cluster.html)'s engine version'.\n* `final_snapshot_identifier` - (Optional) The name of your final DB snapshot\nwhen this DB instance is deleted. Must be provided if `skip_final_snapshot` is\nset to `false`. The value must begin with a letter, only contain alphanumeric characters and hyphens, and not end with a hyphen or contain two consecutive hyphens. Must not be provided when deleting a read replica.\n* `iam_database_authentication_enabled` - (Optional) Specifies whether or\nmappings of AWS Identity and Access Management (IAM) accounts to database\naccounts is enabled.\n* `identifier` - (Optional, Forces new resource) The name of the RDS instance,\nif omitted, Terraform will assign a random, unique identifier. Required if `restore_to_point_in_time` is specified.\n* `identifier_prefix` - (Optional, Forces new resource) Creates a unique\nidentifier beginning with the specified prefix. Conflicts with `identifier`.\n* `instance_class` - (Required) The instance type of the RDS instance.\n* `iops` - (Optional) The amount of provisioned IOPS. Setting this implies a\nstorage_type of \"io1\".\n* `kms_key_id` - (Optional) The ARN for the KMS encryption key. If creating an\nencrypted replica, set this to the destination KMS ARN.\n* `license_model` - (Optional, but required for some DB engines, i.e., Oracle\nSE1) License model information for this DB instance.\n* `maintenance_window` - (Optional) The window to perform maintenance in.\nSyntax: \"ddd:hh24:mi-ddd:hh24:mi\". Eg: \"Mon:00:00-Mon:03:00\". See [RDS\nMaintenance Window\ndocs](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html#AdjustingTheMaintenanceWindow)\nfor more information.\n* `max_allocated_storage` - (Optional) When configured, the upper limit to which Amazon RDS can automatically scale the storage of the DB instance. Configuring this will automatically ignore differences to `allocated_storage`. Must be greater than or equal to `allocated_storage` or `0` to disable Storage Autoscaling.\n* `monitoring_interval` - (Optional) The interval, in seconds, between points\nwhen Enhanced Monitoring metrics are collected for the DB instance. To disable\ncollecting Enhanced Monitoring metrics, specify 0. The default is 0. Valid\nValues: 0, 1, 5, 10, 15, 30, 60.\n* `monitoring_role_arn` - (Optional) The ARN for the IAM role that permits RDS\nto send enhanced monitoring metrics to CloudWatch Logs. You can find more\ninformation on the [AWS\nDocumentation](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html)\nwhat IAM permissions are needed to allow Enhanced Monitoring for RDS Instances.\n* `multi_az` - (Optional) Specifies if the RDS instance is multi-AZ\n* `name` - (Optional) The name of the database to create when the DB instance is created. If this parameter is not specified, no database is created in the DB instance. Note that this does not apply for Oracle or SQL Server engines. See the [AWS documentation](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/rds/create-db-instance.html) for more details on what applies for those engines. If you are providing an Oracle db name, it needs to be in all upper case.\n* `nchar_character_set_name` - (Optional, Forces new resource) The national character set is used in the NCHAR, NVARCHAR2, and NCLOB data types for Oracle instances. This can't be changed. See [Oracle Character Sets\nSupported in Amazon RDS](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.OracleCharacterSets.html).\n* `option_group_name` - (Optional) Name of the DB option group to associate.\n* `parameter_group_name` - (Optional) Name of the DB parameter group to\nassociate.\n* `password` - (Required unless a `snapshot_identifier` or `replicate_source_db`\nis provided) Password for the master DB user. Note that this may show up in\nlogs, and it will be stored in the state file.\n* `performance_insights_enabled` - (Optional) Specifies whether Performance Insights are enabled. Defaults to false.\n* `performance_insights_kms_key_id` - (Optional) The ARN for the KMS key to encrypt Performance Insights data. When specifying `performance_insights_kms_key_id`, `performance_insights_enabled` needs to be set to true. Once KMS key is set, it can never be changed.\n* `performance_insights_retention_period` - (Optional) The amount of time in days to retain Performance Insights data. Either 7 (7 days) or 731 (2 years). When specifying `performance_insights_retention_period`, `performance_insights_enabled` needs to be set to true. Defaults to '7'.\n* `port` - (Optional) The port on which the DB accepts connections.\n* `publicly_accessible` - (Optional) Bool to control if instance is publicly\naccessible. Default is `false`.\n* `replica_mode` - (Optional) Specifies whether the replica is in either `mounted` or `open-read-only` mode. This attribute\nis only supported by Oracle instances. Oracle replicas operate in `open-read-only` mode unless otherwise specified. See [Working with Oracle Read Replicas](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-read-replicas.html) for more information.\n* `replicate_source_db` - (Optional) Specifies that this resource is a Replicate\ndatabase, and to use this value as the source database. This correlates to the\n`identifier` of another Amazon RDS Database to replicate (if replicating within\na single region) or ARN of the Amazon RDS Database to replicate (if replicating\ncross-region). Note that if you are\ncreating a cross-region replica of an encrypted database you will also need to\nspecify a `kms_key_id`. See [DB Instance Replication][1] and [Working with\nPostgreSQL and MySQL Read Replicas](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html)\nfor more information on using Replication.\n* `restore_to_point_in_time` - (Optional, Forces new resource) A configuration block for restoring a DB instance to an arbitrary point in time. Requires the `identifier` argument to be set with the name of the new DB instance to be created. See [Restore To Point In Time](#restore-to-point-in-time) below for details.\n* `s3_import` - (Optional) Restore from a Percona Xtrabackup in S3.  See [Importing Data into an Amazon RDS MySQL DB Instance](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.Procedural.Importing.html)\n* `security_group_names` - (Optional/Deprecated) List of DB Security Groups to\nassociate. Only used for [DB Instances on the _EC2-Classic_\nPlatform](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.html#USER_VPC.FindDefaultVPC).\n* `skip_final_snapshot` - (Optional) Determines whether a final DB snapshot is\ncreated before the DB instance is deleted. If true is specified, no DBSnapshot\nis created. If false is specified, a DB snapshot is created before the DB\ninstance is deleted, using the value from `final_snapshot_identifier`. Default\nis `false`.\n* `snapshot_identifier` - (Optional) Specifies whether or not to create this\ndatabase from a snapshot. This correlates to the snapshot ID you'd find in the\nRDS console, e.g: rds:production-2015-06-26-06-05.\n* `storage_encrypted` - (Optional) Specifies whether the DB instance is\nencrypted. Note that if you are creating a cross-region read replica this field\nis ignored and you should instead declare `kms_key_id` with a valid ARN. The\ndefault is `false` if not specified.\n* `storage_type` - (Optional) One of \"standard\" (magnetic), \"gp2\" (general\npurpose SSD), or \"io1\" (provisioned IOPS SSD). The default is \"io1\" if `iops` is\nspecified, \"gp2\" if not.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `timezone` - (Optional) Time zone of the DB instance. `timezone` is currently\nonly supported by Microsoft SQL Server. The `timezone` can only be set on\ncreation. See [MSSQL User\nGuide](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_SQLServer.html#SQLServer.Concepts.General.TimeZone)\nfor more information.\n* `username` - (Required unless a `snapshot_identifier` or `replicate_source_db`\nis provided) Username for the master DB user.\n* `vpc_security_group_ids` - (Optional) List of VPC security groups to\nassociate.\n* `customer_owned_ip_enabled` - (Optional) Indicates whether to enable a customer-owned IP address (CoIP) for an RDS on Outposts DB instance. See [CoIP for RDS on Outposts](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html#rds-on-outposts.coip) for more information.\n\n~> **NOTE:** Removing the `replicate_source_db` attribute from an existing RDS\nReplicate database managed by Terraform will promote the database to a fully\nstandalone database.\n\n### Restore To Point In Time\n\n-> **Note:** You can restore to any point in time before the source DB instance's `latest_restorable_time` or a point up to the number of days specified in the source DB instance's `backup_retention_period`.\nFor more information, please refer to the [Developer Guide](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIT.html).\nThis setting does not apply to `aurora-mysql` or `aurora-postgresql` DB engines. For Aurora, refer to the [`aws_rds_cluster` resource documentation](/docs/providers/aws/r/rds_cluster.html#restore_in_time).\n\nThe `restore_to_point_in_time` block supports the following arguments:\n\n* `restore_time` - (Optional) The date and time to restore from. Value must be a time in Universal Coordinated Time (UTC) format and must be before the latest restorable time for the DB instance. Cannot be specified with `use_latest_restorable_time`.\n* `source_db_instance_identifier` - (Optional) The identifier of the source DB instance from which to restore. Must match the identifier of an existing DB instance. Required if `source_dbi_resource_id` is not specified.\n* `source_dbi_resource_id` - (Optional) The resource ID of the source DB instance from which to restore. Required if `source_db_instance_identifier` is not specified.\n* `use_latest_restorable_time` - (Optional) A boolean value that indicates whether the DB instance is restored from the latest backup time. Defaults to `false`. Cannot be specified with `restore_time`.\n\n### S3 Import Options\n\nFull details on the core parameters and impacts are in the API Docs: [RestoreDBInstanceFromS3](http://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_RestoreDBInstanceFromS3.html).  Sample\n\n```terraform\nresource \"aws_db_instance\" \"db\" {\n  s3_import {\n    source_engine         = \"mysql\"\n    source_engine_version = \"5.6\"\n    bucket_name           = \"mybucket\"\n    bucket_prefix         = \"backups\"\n    ingestion_role        = \"arn:aws:iam::1234567890:role/role-xtrabackup-rds-restore\"\n  }\n}\n```\n\n* `bucket_name` - (Required) The bucket name where your backup is stored\n* `bucket_prefix` - (Optional) Can be blank, but is the path to your backup\n* `ingestion_role` - (Required) Role applied to load the data.\n* `source_engine` - (Required, as of Feb 2018 only 'mysql' supported) Source engine for the backup\n* `source_engine_version` - (Required, as of Feb 2018 only '5.6' supported) Version of the source engine used to make the backup\n\nThis will not recreate the resource if the S3 object changes in some way.  It's only used to initialize the database\n\n### Timeouts\n\n`aws_db_instance` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `40 minutes`) Used for Creating Instances, Replicas, and\nrestoring from Snapshots.\n- `update` - (Default `80 minutes`) Used for Database modifications.\n- `delete` - (Default `60 minutes`) Used for destroying databases. This includes\nthe time required to take snapshots.\n\n[1]:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Replication.html\n[2]:\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `address` - The hostname of the RDS instance. See also `endpoint` and `port`.\n* `arn` - The ARN of the RDS instance.\n* `allocated_storage` - The amount of allocated storage.\n* `availability_zone` - The availability zone of the instance.\n* `backup_retention_period` - The backup retention period.\n* `backup_window` - The backup window.\n* `ca_cert_identifier` - Specifies the identifier of the CA certificate for the\nDB instance.\n* `domain` - The ID of the Directory Service Active Directory domain the instance is joined to\n* `domain_iam_role_name` - The name of the IAM role to be used when making API calls to the Directory Service.\n* `endpoint` - The connection endpoint in `address:port` format.\n* `engine` - The database engine.\n* `engine_version_actual` - The running version of the database.\n* `hosted_zone_id` - The canonical hosted zone ID of the DB instance (to be used\nin a Route 53 Alias record).\n* `id` - The RDS instance ID.\n* `instance_class`- The RDS instance class.\n* `latest_restorable_time` - The latest time, in UTC [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8), to which a database can be restored with point-in-time restore.\n* `maintenance_window` - The instance maintenance window.\n* `multi_az` - If the RDS instance is multi AZ enabled.\n* `name` - The database name.\n* `port` - The database port.\n* `resource_id` - The RDS Resource ID of this instance.\n* `status` - The RDS instance status.\n* `storage_encrypted` - Specifies whether the DB instance is encrypted.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `username` - The master username for the database.\n\nOn Oracle and Microsoft SQL instances the following is exported additionally:\n\n* `character_set_name` - The character set (collation) used on Oracle and Microsoft SQL instances.\n\n## Import\n\nDB Instances can be imported using the `identifier`, e.g.,\n\n```\n$ terraform import aws_db_instance.default mydb-rds-instance\n```\n",
    "basename": "db_instance.html"
  },
  "db_instance_role_association.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_instance_role_association",
    "description": "Manages an RDS DB Instance association with an IAM Role.",
    "preview": "# Resource: aws_db_instance_role_association\n\nManages an RDS DB …",
    "content": "\n\n# Resource: aws_db_instance_role_association\n\nManages an RDS DB Instance association with an IAM Role. Example use cases:\n\n* [Amazon RDS Oracle integration with Amazon S3](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-s3-integration.html)\n* [Importing Amazon S3 Data into an RDS PostgreSQL DB Instance](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PostgreSQL.S3Import.html)\n\n-> To manage the RDS DB Instance IAM Role for [Enhanced Monitoring](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html), see the `aws_db_instance` resource `monitoring_role_arn` argument instead.\n\n## Example Usage\n\n```terraform\nresource \"aws_db_instance_role_association\" \"example\" {\n  db_instance_identifier = aws_db_instance.example.id\n  feature_name           = \"S3_INTEGRATION\"\n  role_arn               = aws_iam_role.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_instance_identifier` - (Required) DB Instance Identifier to associate with the IAM Role.\n* `feature_name` - (Required) Name of the feature for association. This can be found in the AWS documentation relevant to the integration or a full list is available in the `SupportedFeatureNames` list returned by [AWS CLI rds describe-db-engine-versions](https://docs.aws.amazon.com/cli/latest/reference/rds/describe-db-engine-versions.html).\n* `role_arn` - (Required) Amazon Resource Name (ARN) of the IAM Role to associate with the DB Instance.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - DB Instance Identifier and IAM Role ARN separated by a comma (`,`)\n\n## Import\n\n`aws_db_instance_role_association` can be imported using the DB Instance Identifier and IAM Role ARN separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_db_instance_role_association.example my-db-instance,arn:aws:iam::123456789012:role/my-role\n```\n",
    "basename": "db_instance_role_association.html"
  },
  "db_option_group.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_option_group",
    "description": "Provides an RDS DB option group resource.",
    "preview": "# Resource: aws_db_option_group\n\nProvides an RDS DB option group …",
    "content": "\n\n# Resource: aws_db_option_group\n\nProvides an RDS DB option group resource. Documentation of the available options for various RDS engines can be found at:\n\n* [MariaDB Options](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.MariaDB.Options.html)\n* [Microsoft SQL Server Options](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.SQLServer.Options.html)\n* [MySQL Options](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.MySQL.Options.html)\n* [Oracle Options](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.Oracle.Options.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_db_option_group\" \"example\" {\n  name                     = \"option-group-test-terraform\"\n  option_group_description = \"Terraform Option Group\"\n  engine_name              = \"sqlserver-ee\"\n  major_engine_version     = \"11.00\"\n\n  option {\n    option_name = \"Timezone\"\n\n    option_settings {\n      name  = \"TIME_ZONE\"\n      value = \"UTC\"\n    }\n  }\n\n  option {\n    option_name = \"SQLSERVER_BACKUP_RESTORE\"\n\n    option_settings {\n      name  = \"IAM_ROLE_ARN\"\n      value = aws_iam_role.example.arn\n    }\n  }\n\n  option {\n    option_name = \"TDE\"\n  }\n}\n```\n\n~> **Note**: Any modifications to the `aws_db_option_group` are set to happen immediately as we default to applying immediately.\n\n~> **WARNING:** You can perform a destroy on a `aws_db_option_group`, as long as it is not associated with any Amazon RDS resource. An option group can be associated with a DB instance, a manual DB snapshot, or an automated DB snapshot.\n\nIf you try to delete an option group that is associated with an Amazon RDS resource, an error similar to the following is returned:\n\n> An error occurred (InvalidOptionGroupStateFault) when calling the DeleteOptionGroup operation: The option group 'optionGroupName' cannot be deleted because it is in use.\n\nMore information about this can be found [here](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithOptionGroups.html#USER_WorkingWithOptionGroups.Delete).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the option group. If omitted, Terraform will assign a random, unique name. Must be lowercase, to match as it is stored in AWS.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`. Must be lowercase, to match as it is stored in AWS.\n* `option_group_description` - (Optional) The description of the option group. Defaults to \"Managed by Terraform\".\n* `engine_name` - (Required) Specifies the name of the engine that this option group should be associated with.\n* `major_engine_version` - (Required) Specifies the major version of the engine that this option group should be associated with.\n* `option` - (Optional) A list of Options to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nOption blocks support the following:\n\n* `option_name` - (Required) The Name of the Option (e.g., MEMCACHED).\n* `option_settings` - (Optional) A list of option settings to apply.\n* `port` - (Optional) The Port number when connecting to the Option (e.g., 11211).\n* `version` - (Optional) The version of the option (e.g., 13.1.0.0).\n* `db_security_group_memberships` - (Optional) A list of DB Security Groups for which the option is enabled.\n* `vpc_security_group_memberships` - (Optional) A list of VPC Security Groups for which the option is enabled.\n\nOption Settings blocks support the following:\n\n* `name` - (Optional) The Name of the setting.\n* `value` - (Optional) The Value of the setting.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The db option group name.\n* `arn` - The ARN of the db option group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_db_option_group` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `delete` - (Default `15 minutes`)\n\n## Import\n\nDB Option groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_db_option_group.example mysql-option-group\n```\n",
    "basename": "db_option_group.html"
  },
  "db_parameter_group.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_parameter_group",
    "description": "Provides an RDS DB parameter group resource.",
    "preview": "# Resource: aws_db_parameter_group\n\nProvides an RDS DB parameter …",
    "content": "\n\n# Resource: aws_db_parameter_group\n\nProvides an RDS DB parameter group resource .Documentation of the available parameters for various RDS engines can be found at:\n\n* [Aurora MySQL Parameters](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.Reference.html)\n* [Aurora PostgreSQL Parameters](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraPostgreSQL.Reference.html)\n* [MariaDB Parameters](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.MariaDB.Parameters.html)\n* [Oracle Parameters](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ModifyInstance.Oracle.html#USER_ModifyInstance.Oracle.sqlnet)\n* [PostgreSQL Parameters](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.html#Appendix.PostgreSQL.CommonDBATasks.Parameters)\n\n> **Hands-on:** For an example of the `aws_db_parameter_group` in use, follow the [Manage AWS RDS Instances](https://learn.hashicorp.com/tutorials/terraform/aws-rds?in=terraform/aws&utm_source=WEBSITE&utm_medium=WEB_IO&utm_offer=ARTICLE_PAGE&utm_content=DOCS) tutorial on HashiCorp Learn.\n\n## Example Usage\n\n```terraform\nresource \"aws_db_parameter_group\" \"default\" {\n  name   = \"rds-pg\"\n  family = \"mysql5.6\"\n\n  parameter {\n    name  = \"character_set_server\"\n    value = \"utf8\"\n  }\n\n  parameter {\n    name  = \"character_set_client\"\n    value = \"utf8\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the DB parameter group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `family` - (Required, Forces new resource) The family of the DB parameter group.\n* `description` - (Optional, Forces new resource) The description of the DB parameter group. Defaults to \"Managed by Terraform\".\n* `parameter` - (Optional) A list of DB parameters to apply. Note that parameters may differ from a family to an other. Full list of all parameters can be discovered via [`aws rds describe-db-parameters`](https://docs.aws.amazon.com/cli/latest/reference/rds/describe-db-parameters.html) after initial creation of the group.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nParameter blocks support the following:\n\n* `name` - (Required) The name of the DB parameter.\n* `value` - (Required) The value of the DB parameter.\n* `apply_method` - (Optional) \"immediate\" (default), or \"pending-reboot\". Some\n    engines can't apply some parameters without a reboot, and you will need to\n    specify \"pending-reboot\" here.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The db parameter group name.\n* `arn` - The ARN of the db parameter group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDB Parameter groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_db_parameter_group.rds_pg rds-pg\n```\n",
    "basename": "db_parameter_group.html"
  },
  "db_proxy.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_proxy",
    "description": "Provides an RDS DB proxy resource.",
    "preview": "# Resource: aws_db_proxy\n\nProvides an RDS DB proxy resource. For …",
    "content": "\n\n# Resource: aws_db_proxy\n\nProvides an RDS DB proxy resource. For additional information, see the [RDS User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_db_proxy\" \"example\" {\n  name                   = \"example\"\n  debug_logging          = false\n  engine_family          = \"MYSQL\"\n  idle_client_timeout    = 1800\n  require_tls            = true\n  role_arn               = aws_iam_role.example.arn\n  vpc_security_group_ids = [aws_security_group.example.id]\n  vpc_subnet_ids         = [aws_subnet.example.id]\n\n  auth {\n    auth_scheme = \"SECRETS\"\n    description = \"example\"\n    iam_auth    = \"DISABLED\"\n    secret_arn  = aws_secretsmanager_secret.example.arn\n  }\n\n  tags = {\n    Name = \"example\"\n    Key  = \"value\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The identifier for the proxy. This name must be unique for all proxies owned by your AWS account in the specified AWS Region. An identifier must begin with a letter and must contain only ASCII letters, digits, and hyphens; it can't end with a hyphen or contain two consecutive hyphens.\n* `auth` - (Required) Configuration block(s) with authorization mechanisms to connect to the associated instances or clusters. Described below.\n* `debug_logging` - (Optional) Whether the proxy includes detailed information about SQL statements in its logs. This information helps you to debug issues involving SQL behavior or the performance and scalability of the proxy connections. The debug information includes the text of SQL statements that you submit through the proxy. Thus, only enable this setting when needed for debugging, and only when you have security measures in place to safeguard any sensitive information that appears in the logs.\n* `engine_family` - (Required, Forces new resource) The kinds of databases that the proxy can connect to. This value determines which database network protocol the proxy recognizes when it interprets network traffic to and from the database. The engine family applies to MySQL and PostgreSQL for both RDS and Aurora. Valid values are `MYSQL` and `POSTGRESQL`.\n* `idle_client_timeout` - (Optional) The number of seconds that a connection to the proxy can be inactive before the proxy disconnects it. You can set this value higher or lower than the connection timeout limit for the associated database.\n* `require_tls` - (Optional) A Boolean parameter that specifies whether Transport Layer Security (TLS) encryption is required for connections to the proxy. By enabling this setting, you can enforce encrypted TLS connections to the proxy.\n* `role_arn` - (Required) The Amazon Resource Name (ARN) of the IAM role that the proxy uses to access secrets in AWS Secrets Manager.\n* `vpc_security_group_ids` - (Optional) One or more VPC security group IDs to associate with the new proxy.\n* `vpc_subnet_ids` - (Required) One or more VPC subnet IDs to associate with the new proxy.\n* `tags` - (Optional) A mapping of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n`auth` blocks support the following:\n\n* `auth_scheme` - (Optional) The type of authentication that the proxy uses for connections from the proxy to the underlying database. One of `SECRETS`.\n* `description` - (Optional) A user-specified description about the authentication used by a proxy to log in as a specific database user.\n* `iam_auth` - (Optional) Whether to require or disallow AWS Identity and Access Management (IAM) authentication for connections to the proxy. One of `DISABLED`, `REQUIRED`.\n* `secret_arn` - (Optional) The Amazon Resource Name (ARN) representing the secret that the proxy uses to authenticate to the RDS DB instance or Aurora DB cluster. These secrets are stored within Amazon Secrets Manager.\n* `username` - (Optional) The name of the database user to which the proxy connects.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) for the proxy.\n* `arn` - The Amazon Resource Name (ARN) for the proxy.\n* `endpoint` - The endpoint that you can use to connect to the proxy. You include the endpoint value in the connection string for a database client application.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n### Timeouts\n\n`aws_db_proxy` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `30 minutes`) Used for creating DB proxies.\n- `update` - (Default `30 minutes`) Used for modifying DB proxies.\n- `delete` - (Default `60 minutes`) Used for destroying DB proxies.\n\n## Import\n\nDB proxies can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_db_proxy.example example\n```\n",
    "basename": "db_proxy.html"
  },
  "db_proxy_default_target_group.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_proxy_default_target_group",
    "description": "Manage an RDS DB proxy default target group resource.",
    "preview": "# Resource: aws_db_proxy_default_target_group\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_db_proxy_default_target_group\n\nProvides a resource to manage an RDS DB proxy default target group resource.\n\nThe `aws_db_proxy_default_target_group` behaves differently from normal resources, in that Terraform does not _create_ or _destroy_ this resource, since it implicitly exists as part of an RDS DB Proxy. On Terraform resource creation it is automatically imported and on resource destruction, Terraform performs no actions in RDS.\n\n## Example Usage\n\n```terraform\nresource \"aws_db_proxy\" \"example\" {\n  name                   = \"example\"\n  debug_logging          = false\n  engine_family          = \"MYSQL\"\n  idle_client_timeout    = 1800\n  require_tls            = true\n  role_arn               = aws_iam_role.example.arn\n  vpc_security_group_ids = [aws_security_group.example.id]\n  vpc_subnet_ids         = [aws_subnet.example.id]\n\n  auth {\n    auth_scheme = \"SECRETS\"\n    description = \"example\"\n    iam_auth    = \"DISABLED\"\n    secret_arn  = aws_secretsmanager_secret.example.arn\n  }\n\n  tags = {\n    Name = \"example\"\n    Key  = \"value\"\n  }\n}\n\nresource \"aws_db_proxy_default_target_group\" \"example\" {\n  db_proxy_name = aws_db_proxy.example.name\n\n  connection_pool_config {\n    connection_borrow_timeout    = 120\n    init_query                   = \"SET x=1, y=2\"\n    max_connections_percent      = 100\n    max_idle_connections_percent = 50\n    session_pinning_filters      = [\"EXCLUDE_VARIABLE_SETS\"]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_proxy_name` - (Required) Name of the RDS DB Proxy.\n* `connection_pool_config` - (Optional) The settings that determine the size and behavior of the connection pool for the target group.\n\n`connection_pool_config` blocks support the following:\n\n* `connection_borrow_timeout` - (Optional) The number of seconds for a proxy to wait for a connection to become available in the connection pool. Only applies when the proxy has opened its maximum number of connections and all connections are busy with client sessions.\n* `init_query` - (Optional) One or more SQL statements for the proxy to run when opening each new database connection. Typically used with `SET` statements to make sure that each connection has identical settings such as time zone and character set. This setting is empty by default. For multiple statements, use semicolons as the separator. You can also include multiple variables in a single `SET` statement, such as `SET x=1, y=2`.\n* `max_connections_percent` - (Optional) The maximum size of the connection pool for each target in a target group. For Aurora MySQL, it is expressed as a percentage of the max_connections setting for the RDS DB instance or Aurora DB cluster used by the target group.\n* `max_idle_connections_percent` - (Optional) Controls how actively the proxy closes idle database connections in the connection pool. A high value enables the proxy to leave a high percentage of idle connections open. A low value causes the proxy to close idle client connections and return the underlying database connections to the connection pool. For Aurora MySQL, it is expressed as a percentage of the max_connections setting for the RDS DB instance or Aurora DB cluster used by the target group.\n* `session_pinning_filters` - (Optional) Each item in the list represents a class of SQL operations that normally cause all later statements in a session using a proxy to be pinned to the same underlying database connection. Including an item in the list exempts that class of SQL operations from the pinning behavior. Currently, the only allowed value is `EXCLUDE_VARIABLE_SETS`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Name of the RDS DB Proxy.\n* `arn` - The Amazon Resource Name (ARN) representing the target group.\n* `name` - The name of the default target group.\n\n### Timeouts\n\n`aws_db_proxy_default_target_group` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `30 minutes`) Timeout for modifying DB proxy target group on creation.\n- `update` - (Default `30 minutes`) Timeout for modifying DB proxy target group on update.\n\n## Import\n\nDB proxy default target groups can be imported using the `db_proxy_name`, e.g.,\n\n```\n$ terraform import aws_db_proxy_default_target_group.example example\n```\n",
    "basename": "db_proxy_default_target_group.html"
  },
  "db_proxy_endpoint.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_proxy_endpoint",
    "description": "Provides an RDS DB proxy endpoint resource.",
    "preview": "# Resource: aws_db_proxy_endpoint\n\nProvides an RDS DB proxy endpoint …",
    "content": "\n\n# Resource: aws_db_proxy_endpoint\n\nProvides an RDS DB proxy endpoint resource. For additional information, see the [RDS User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html#rds-proxy-endpoints).\n\n## Example Usage\n\n```terraform\nresource \"aws_db_proxy_endpoint\" \"example\" {\n  db_proxy_name          = aws_db_proxy.test.name\n  db_proxy_endpoint_name = \"example\"\n  vpc_subnet_ids         = aws_subnet.test.*.id\n  target_role            = \"READ_ONLY\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_proxy_endpoint_name` - (Required) The identifier for the proxy endpoint. An identifier must begin with a letter and must contain only ASCII letters, digits, and hyphens; it can't end with a hyphen or contain two consecutive hyphens.\n* `db_proxy_name` - (Required) The name of the DB proxy associated with the DB proxy endpoint that you create.\n* `vpc_subnet_ids` - (Required) One or more VPC subnet IDs to associate with the new proxy.\n* `vpc_security_group_ids` - (Optional) One or more VPC security group IDs to associate with the new proxy.\n* `target_role` - (Optional) Indicates whether the DB proxy endpoint can be used for read/write or read-only operations. The default is `READ_WRITE`. Valid values are `READ_WRITE` and `READ_ONLY`.\n* `tags` - (Optional) A mapping of tags to assign to the resource.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the proxy and proxy endpoint separated by `/`, `DB-PROXY-NAME/DB-PROXY-ENDPOINT-NAME`.\n* `arn` - The Amazon Resource Name (ARN) for the proxy endpoint.\n* `endpoint` - The endpoint that you can use to connect to the proxy. You include the endpoint value in the connection string for a database client application.\n* `is_default` - Indicates whether this endpoint is the default endpoint for the associated DB proxy.\n* `vpc_id` - The VPC ID of the DB proxy endpoint.\n\n### Timeouts\n\n`aws_db_proxy_endpoint` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `30 minutes`) Used for creating DB proxy endpoint.\n- `update` - (Default `30 minutes`) Used for modifying DB proxy endpoint.\n- `delete` - (Default `60 minutes`) Used for destroying DB proxy endpoint.\n\n## Import\n\nDB proxy endpoints can be imported using the `DB-PROXY-NAME/DB-PROXY-ENDPOINT-NAME`, e.g.,\n\n```\n$ terraform import aws_db_proxy_endpoint.example example/example\n```\n",
    "basename": "db_proxy_endpoint.html"
  },
  "db_proxy_target.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_proxy_target",
    "description": "Provides an RDS DB proxy target resource.",
    "preview": "# Resource: aws_db_proxy_target\n\nProvides an RDS DB proxy target …",
    "content": "\n\n# Resource: aws_db_proxy_target\n\nProvides an RDS DB proxy target resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_db_proxy\" \"example\" {\n  name                   = \"example\"\n  debug_logging          = false\n  engine_family          = \"MYSQL\"\n  idle_client_timeout    = 1800\n  require_tls            = true\n  role_arn               = aws_iam_role.example.arn\n  vpc_security_group_ids = [aws_security_group.example.id]\n  vpc_subnet_ids         = [aws_subnet.example.id]\n\n  auth {\n    auth_scheme = \"SECRETS\"\n    description = \"example\"\n    iam_auth    = \"DISABLED\"\n    secret_arn  = aws_secretsmanager_secret.example.arn\n  }\n\n  tags = {\n    Name = \"example\"\n    Key  = \"value\"\n  }\n}\n\nresource \"aws_db_proxy_default_target_group\" \"example\" {\n  db_proxy_name = aws_db_proxy.example.name\n\n  connection_pool_config {\n    connection_borrow_timeout    = 120\n    init_query                   = \"SET x=1, y=2\"\n    max_connections_percent      = 100\n    max_idle_connections_percent = 50\n    session_pinning_filters      = [\"EXCLUDE_VARIABLE_SETS\"]\n  }\n}\n\nresource \"aws_db_proxy_target\" \"example\" {\n  db_instance_identifier = aws_db_instance.example.id\n  db_proxy_name          = aws_db_proxy.example.name\n  target_group_name      = aws_db_proxy_default_target_group.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_proxy_name` - (Required, Forces new resource) The name of the DB proxy.\n* `target_group_name` - (Required, Forces new resource) The name of the target group.\n* `db_instance_identifier` - (Optional, Forces new resource) DB instance identifier.\n* `db_cluster_identifier` - (Optional, Forces new resource) DB cluster identifier.\n\n**NOTE:** Either `db_instance_identifier` or `db_cluster_identifier` should be specified and both should not be specified together\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `endpoint` - Hostname for the target RDS DB Instance. Only returned for `RDS_INSTANCE` type.\n* `id` - Identifier of  `db_proxy_name`, `target_group_name`, target type (e.g., `RDS_INSTANCE` or `TRACKED_CLUSTER`), and resource identifier separated by forward slashes (`/`).\n* `port` - Port for the target RDS DB Instance or Aurora DB Cluster.\n* `rds_resource_id` - Identifier representing the DB Instance or DB Cluster target.\n* `target_arn` - Amazon Resource Name (ARN) for the DB instance or DB cluster. Currently not returned by the RDS API.\n* `tracked_cluster_id` - DB Cluster identifier for the DB Instance target. Not returned unless manually importing an `RDS_INSTANCE` target that is part of a DB Cluster.\n* `type` - Type of targetE.g., `RDS_INSTANCE` or `TRACKED_CLUSTER`\n\n## Import\n\nRDS DB Proxy Targets can be imported using the `db_proxy_name`, `target_group_name`, target type (e.g., `RDS_INSTANCE` or `TRACKED_CLUSTER`), and resource identifier separated by forward slashes (`/`), e.g.,\n\nInstances:\n\n```\n$ terraform import aws_db_proxy_target.example example-proxy/default/RDS_INSTANCE/example-instance\n```\n\nProvisioned Clusters:\n\n```\n$ terraform import aws_db_proxy_target.example example-proxy/default/TRACKED_CLUSTER/example-cluster\n```\n",
    "basename": "db_proxy_target.html"
  },
  "db_security_group.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_security_group",
    "description": "Provides an RDS security group resource.",
    "preview": "# Resource: aws_db_security_group\n\nProvides an RDS security group …",
    "content": "\n\n# Resource: aws_db_security_group\n\nProvides an RDS security group resource. This is only for DB instances in the\nEC2-Classic Platform. For instances inside a VPC, use the\n[`aws_db_instance.vpc_security_group_ids`](/docs/providers/aws/r/db_instance.html#vpc_security_group_ids)\nattribute instead.\n\n## Example Usage\n\n```terraform\nresource \"aws_db_security_group\" \"default\" {\n  name = \"rds_sg\"\n\n  ingress {\n    cidr = \"10.0.0.0/24\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the DB security group.\n* `description` - (Optional) The description of the DB security group. Defaults to \"Managed by Terraform\".\n* `ingress` - (Required) A list of ingress rules.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nIngress blocks support the following:\n\n* `cidr` - The CIDR block to accept\n* `security_group_name` - The name of the security group to authorize\n* `security_group_id` - The ID of the security group to authorize\n* `security_group_owner_id` - The owner Id of the security group provided\n  by `security_group_name`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The db security group ID.\n* `arn` - The arn of the DB security group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDB Security groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_db_security_group.default aws_rds_sg-1\n```\n",
    "basename": "db_security_group.html"
  },
  "db_snapshot.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_snapshot",
    "description": "Manages an RDS database instance snapshot.",
    "preview": "# Resource: aws_db_snapshot\n\nManages an RDS database instance …",
    "content": "\n\n# Resource: aws_db_snapshot\n\nManages an RDS database instance snapshot. For managing RDS database cluster snapshots, see the [`aws_db_cluster_snapshot` resource](/docs/providers/aws/r/db_cluster_snapshot.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_db_instance\" \"bar\" {\n  allocated_storage = 10\n  engine            = \"mysql\"\n  engine_version    = \"5.6.21\"\n  instance_class    = \"db.t2.micro\"\n  name              = \"baz\"\n  password          = \"barbarbarbar\"\n  username          = \"foo\"\n\n  maintenance_window      = \"Fri:09:00-Fri:09:30\"\n  backup_retention_period = 0\n  parameter_group_name    = \"default.mysql5.6\"\n}\n\nresource \"aws_db_snapshot\" \"test\" {\n  db_instance_identifier = aws_db_instance.bar.id\n  db_snapshot_identifier = \"testsnapshot1234\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_instance_identifier` - (Required) The DB Instance Identifier from which to take the snapshot.\n* `db_snapshot_identifier` - (Required) The Identifier for the snapshot.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `allocated_storage` - Specifies the allocated storage size in gigabytes (GB).\n* `availability_zone` - Specifies the name of the Availability Zone the DB instance was located in at the time of the DB snapshot.\n* `db_snapshot_arn` - The Amazon Resource Name (ARN) for the DB snapshot.\n* `encrypted` - Specifies whether the DB snapshot is encrypted.\n* `engine` - Specifies the name of the database engine.\n* `engine_version` - Specifies the version of the database engine.\n* `iops` - Specifies the Provisioned IOPS (I/O operations per second) value of the DB instance at the time of the snapshot.\n* `kms_key_id` - The ARN for the KMS encryption key.\n* `license_model` - License model information for the restored DB instance.\n* `option_group_name` - Provides the option group name for the DB snapshot.\n* `source_db_snapshot_identifier` - The DB snapshot Arn that the DB snapshot was copied from. It only has value in case of cross customer or cross region copy.\n* `source_region` - The region that the DB snapshot was created in or copied from.\n* `status` - Specifies the status of this DB snapshot.\n* `storage_type` - Specifies the storage type associated with DB snapshot.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` - Provides the VPC ID associated with the DB snapshot.\n\n## Timeouts\n\n`aws_db_snapshot` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `read` - (Default `20 minutes`)  Length of time to wait for the snapshot to become available\n\n## Import\n\n`aws_db_snapshot` can be imported by using the snapshot identifier, e.g.,\n\n```\n$ terraform import aws_db_snapshot.example my-snapshot\n```\n",
    "basename": "db_snapshot.html"
  },
  "db_subnet_group.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_db_subnet_group",
    "description": "Provides an RDS DB subnet group resource.",
    "preview": "# Resource: aws_db_subnet_group\n\nProvides an RDS DB subnet group …",
    "content": "\n\n# Resource: aws_db_subnet_group\n\nProvides an RDS DB subnet group resource.\n\n> **Hands-on:** For an example of the `aws_db_subnet_group` in use, follow the [Manage AWS RDS Instances](https://learn.hashicorp.com/tutorials/terraform/aws-rds?in=terraform/aws&utm_source=WEBSITE&utm_medium=WEB_IO&utm_offer=ARTICLE_PAGE&utm_content=DOCS) tutorial on HashiCorp Learn.\n\n## Example Usage\n\n```terraform\nresource \"aws_db_subnet_group\" \"default\" {\n  name       = \"main\"\n  subnet_ids = [aws_subnet.frontend.id, aws_subnet.backend.id]\n\n  tags = {\n    Name = \"My DB subnet group\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the DB subnet group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` - (Optional) The description of the DB subnet group. Defaults to \"Managed by Terraform\".\n* `subnet_ids` - (Required) A list of VPC subnet IDs.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The db subnet group name.\n* `arn` - The ARN of the db subnet group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDB Subnet groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_db_subnet_group.default production-subnet-group\n```\n",
    "basename": "db_subnet_group.html"
  },
  "default_network_acl.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_default_network_acl",
    "description": "Manage a default network ACL.",
    "preview": "# Resource: aws_default_network_acl\n\nProvides a resource to manage a …",
    "content": "\n\n# Resource: aws_default_network_acl\n\nProvides a resource to manage a VPC's default network ACL. This resource can manage the default network ACL of the default or a non-default VPC.\n\n~> **NOTE:** This is an advanced resource with special caveats. Please read this document in its entirety before using this resource. The `aws_default_network_acl` behaves differently from normal resources. Terraform does not _create_ this resource but instead attempts to \"adopt\" it into management.\n\nEvery VPC has a default network ACL that can be managed but not destroyed. When Terraform first adopts the Default Network ACL, it **immediately removes all rules in the ACL**. It then proceeds to create any rules specified in the configuration. This step is required so that only the rules specified in the configuration are created.\n\nThis resource treats its inline rules as absolute; only the rules defined inline are created, and any additions/removals external to this resource will result in diffs being shown. For these reasons, this resource is incompatible with the `aws_network_acl_rule` resource.\n\nFor more information about Network ACLs, see the AWS Documentation on [Network ACLs][aws-network-acls].\n\n## Example Usage\n\n### Basic Example\n\nThe following config gives the Default Network ACL the same rules that AWS includes but pulls the resource under management by Terraform. This means that any ACL rules added or changed will be detected as drift.\n\n```terraform\nresource \"aws_vpc\" \"mainvpc\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_default_network_acl\" \"default\" {\n  default_network_acl_id = aws_vpc.mainvpc.default_network_acl_id\n\n  ingress {\n    protocol   = -1\n    rule_no    = 100\n    action     = \"allow\"\n    cidr_block = aws_vpc.mainvpc.cidr_block\n    from_port  = 0\n    to_port    = 0\n  }\n\n  egress {\n    protocol   = -1\n    rule_no    = 100\n    action     = \"allow\"\n    cidr_block = \"0.0.0.0/0\"\n    from_port  = 0\n    to_port    = 0\n  }\n}\n```\n\n### Example: Deny All Egress Traffic, Allow Ingress\n\nThe following denies all Egress traffic by omitting any `egress` rules, while including the default `ingress` rule to allow all traffic.\n\n```terraform\nresource \"aws_vpc\" \"mainvpc\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_default_network_acl\" \"default\" {\n  default_network_acl_id = aws_vpc.mainvpc.default_network_acl_id\n\n  ingress {\n    protocol   = -1\n    rule_no    = 100\n    action     = \"allow\"\n    cidr_block = aws_default_vpc.mainvpc.cidr_block\n    from_port  = 0\n    to_port    = 0\n  }\n}\n```\n\n### Example: Deny All Traffic To Any Subnet In The Default Network ACL\n\nThis config denies all traffic in the Default ACL. This can be useful if you want to lock down the VPC to force all resources to assign a non-default ACL.\n\n```terraform\nresource \"aws_vpc\" \"mainvpc\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_default_network_acl\" \"default\" {\n  default_network_acl_id = aws_vpc.mainvpc.default_network_acl_id\n\n  # no rules defined, deny all traffic in this ACL\n}\n```\n\n### Managing Subnets In A Default Network ACL\n\nWithin a VPC, all Subnets must be associated with a Network ACL. In order to \"delete\" the association between a Subnet and a non-default Network ACL, the association is destroyed by replacing it with an association between the Subnet and the Default ACL instead.\n\nWhen managing the Default Network ACL, you cannot \"remove\" Subnets. Instead, they must be reassigned to another Network ACL, or the Subnet itself must be destroyed. Because of these requirements, removing the `subnet_ids` attribute from the configuration of a `aws_default_network_acl` resource may result in a reoccurring plan, until the Subnets are reassigned to another Network ACL or are destroyed.\n\nBecause Subnets are by default associated with the Default Network ACL, any non-explicit association will show up as a plan to remove the Subnet. For example: if you have a custom `aws_network_acl` with two subnets attached, and you remove the `aws_network_acl` resource, after successfully destroying this resource future plans will show a diff on the managed `aws_default_network_acl`, as those two Subnets have been orphaned by the now destroyed network acl and thus adopted by the Default Network ACL. In order to avoid a reoccurring plan, they will need to be reassigned, destroyed, or added to the `subnet_ids` attribute of the `aws_default_network_acl` entry.\n\nAs an alternative to the above, you can also specify the following lifecycle configuration in your `aws_default_network_acl` resource:\n\n```terraform\nresource \"aws_default_network_acl\" \"default\" {\n  # ... other configuration ...\n\n  lifecycle {\n    ignore_changes = [subnet_ids]\n  }\n}\n```\n\n### Removing `aws_default_network_acl` From Your Configuration\n\nEach AWS VPC comes with a Default Network ACL that cannot be deleted. The `aws_default_network_acl` allows you to manage this Network ACL, but Terraform cannot destroy it. Removing this resource from your configuration will remove it from your statefile and management, **but will not destroy the Network ACL.** All Subnets associations and ingress or egress rules will be left as they are at the time of removal. You can resume managing them via the AWS Console.\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `default_network_acl_id` - (Required) Network ACL ID to manage. This attribute is exported from `aws_vpc`, or manually found via the AWS Console.\n\nThe following arguments are optional:\n\n* `egress` - (Optional) Configuration block for an egress rule. Detailed below.\n* `ingress` - (Optional) Configuration block for an ingress rule. Detailed below.\n* `subnet_ids` - (Optional) List of Subnet IDs to apply the ACL to. See the notes below on managing Subnets in the Default Network ACL\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### egress and ingress\n\nBoth the `egress` and `ingress` configuration blocks have the same arguments.\n\nThe following arguments are required:\n\n* `action` - (Required) The action to take.\n* `from_port` - (Required) The from port to match.\n* `protocol` - (Required) The protocol to match. If using the -1 'all' protocol, you must specify a from and to port of 0.\n* `rule_no` - (Required) The rule number. Used for ordering.\n* `to_port` - (Required) The to port to match.\n\nThe following arguments are optional:\n\n* `cidr_block` - (Optional) The CIDR block to match. This must be a valid network mask.\n* `icmp_code` - (Optional) The ICMP type code to be used. Default 0.\n* `icmp_type` - (Optional) The ICMP type to be used. Default 0.\n* `ipv6_cidr_block` - (Optional) The IPv6 CIDR block.\n\n-> For more information on ICMP types and codes, see [Internet Control Message Protocol (ICMP) Parameters](https://www.iana.org/assignments/icmp-parameters/icmp-parameters.xhtml).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the Default Network ACL\n* `id` - ID of the Default Network ACL\n* `owner_id` - ID of the AWS account that owns the Default Network ACL\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` -  ID of the associated VPC\n\n[aws-network-acls]: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html\n\n## Import\n\nDefault Network ACLs can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_default_network_acl.sample acl-7aaabd18\n```\n",
    "basename": "default_network_acl.html"
  },
  "default_route_table.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_default_route_table",
    "description": "Provides a resource to manage a default route table of a VPC.",
    "preview": "# Resource: aws_default_route_table\n\nProvides a resource to manage a …",
    "content": "\n\n# Resource: aws_default_route_table\n\nProvides a resource to manage a default route table of a VPC. This resource can manage the default route table of the default or a non-default VPC.\n\n~> **NOTE:** This is an advanced resource with special caveats. Please read this document in its entirety before using this resource. The `aws_default_route_table` resource behaves differently from normal resources. Terraform does not _create_ this resource but instead attempts to \"adopt\" it into management. **Do not** use both `aws_default_route_table` to manage a default route table **and** `aws_main_route_table_association` with the same VPC due to possible route conflicts. See [aws_main_route_table_association][tf-main-route-table-association] documentation for more details.\n\nEvery VPC has a default route table that can be managed but not destroyed. When Terraform first adopts a default route table, it **immediately removes all defined routes**. It then proceeds to create any routes specified in the configuration. This step is required so that only the routes specified in the configuration exist in the default route table.\n\nFor more information, see the Amazon VPC User Guide on [Route Tables](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html). For information about managing normal route tables in Terraform, see [`aws_route_table`](/docs/providers/aws/r/route_table.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_default_route_table\" \"example\" {\n  default_route_table_id = aws_vpc.example.default_route_table_id\n\n  route {\n    cidr_block = \"10.0.1.0/24\"\n    gateway_id = aws_internet_gateway.example.id\n  }\n\n  route {\n    ipv6_cidr_block        = \"::/0\"\n    egress_only_gateway_id = aws_egress_only_internet_gateway.example.id\n  }\n\n  tags = {\n    Name = \"example\"\n  }\n}\n```\n\nTo subsequently remove all managed routes:\n\n```terraform\nresource \"aws_default_route_table\" \"example\" {\n  default_route_table_id = aws_vpc.example.default_route_table_id\n\n  route = []\n\n  tags = {\n    Name = \"example\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `default_route_table_id` - (Required) ID of the default route table.\n\nThe following arguments are optional:\n\n* `propagating_vgws` - (Optional) List of virtual gateways for propagation.\n* `route` - (Optional) Configuration block of routes. Detailed below. This argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html). This means that omitting this argument is interpreted as ignoring any existing routes. To remove all managed routes an empty list should be specified. See the example above.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### route\n\nThis argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\nOne of the following destination arguments must be supplied:\n\n* `cidr_block` - (Required) The CIDR block of the route.\n* `ipv6_cidr_block` - (Optional) The Ipv6 CIDR block of the route\n* `destination_prefix_list_id` - (Optional) The ID of a [managed prefix list](ec2_managed_prefix_list.html) destination of the route.\n\nOne of the following target arguments must be supplied:\n\n* `egress_only_gateway_id` - (Optional) Identifier of a VPC Egress Only Internet Gateway.\n* `gateway_id` - (Optional) Identifier of a VPC internet gateway or a virtual private gateway.\n* `instance_id` - (Optional) Identifier of an EC2 instance.\n* `nat_gateway_id` - (Optional) Identifier of a VPC NAT gateway.\n* `network_interface_id` - (Optional) Identifier of an EC2 network interface.\n* `transit_gateway_id` - (Optional) Identifier of an EC2 Transit Gateway.\n* `vpc_endpoint_id` - (Optional) Identifier of a VPC Endpoint. This route must be removed prior to VPC Endpoint deletion.\n* `vpc_peering_connection_id` - (Optional) Identifier of a VPC peering connection.\n\nNote that the default route, mapping the VPC's CIDR block to \"local\", is created implicitly and cannot be specified.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ID of the route table.\n* `arn` - The ARN of the route table.\n* `owner_id` - ID of the AWS account that owns the route table.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` - ID of the VPC.\n\n## Timeouts\n\n`aws_default_route_table` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `2 minutes`) Used for route creation\n- `update` - (Default `2 minutes`) Used for route creation\n\n## Import\n\nDefault VPC route tables can be imported using the `vpc_id`, e.g.,\n\n```\n$ terraform import aws_default_route_table.example vpc-33cc44dd\n```\n\n[aws-route-tables]: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#Route_Replacing_Main_Table\n[tf-route-tables]: /docs/providers/aws/r/route_table.html\n[tf-main-route-table-association]: /docs/providers/aws/r/main_route_table_association.html\n",
    "basename": "default_route_table.html"
  },
  "default_security_group.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_default_security_group",
    "description": "Manage a default security group resource.",
    "preview": "# Resource: aws_default_security_group\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_default_security_group\n\nProvides a resource to manage a default security group. This resource can manage the default security group of the default or a non-default VPC.\n\n~> **NOTE:** This is an advanced resource with special caveats. Please read this document in its entirety before using this resource. The `aws_default_security_group` resource behaves differently from normal resources. Terraform does not _create_ this resource but instead attempts to \"adopt\" it into management.\n\nFor EC2 Classic accounts, each region comes with a default security group. Additionally, each VPC created in AWS comes with a default security group that can be managed but not destroyed.\n\nWhen Terraform first adopts the default security group, it **immediately removes all ingress and egress rules in the Security Group**. It then creates any rules specified in the configuration. This way only the rules specified in the configuration are created.\n\nThis resource treats its inline rules as absolute; only the rules defined inline are created, and any additions/removals external to this resource will result in diff shown. For these reasons, this resource is incompatible with the `aws_security_group_rule` resource.\n\nFor more information about default security groups, see the AWS documentation on [Default Security Groups][aws-default-security-groups]. To manage normal security groups, see the [`aws_security_group`](/docs/providers/aws/r/security_group.html) resource.\n\n## Example Usage\n\nThe following config gives the default security group the same rules that AWS provides by default but under management by Terraform. This means that any ingress or egress rules added or changed will be detected as drift.\n\n```terraform\nresource \"aws_vpc\" \"mainvpc\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_default_security_group\" \"default\" {\n  vpc_id = aws_vpc.mainvpc.id\n\n  ingress {\n    protocol  = -1\n    self      = true\n    from_port = 0\n    to_port   = 0\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n```\n\n### Example Config To Deny All Egress Traffic, Allowing Ingress\n\nThe following denies all Egress traffic by omitting any `egress` rules, while including the default `ingress` rule to allow all traffic.\n\n```terraform\nresource \"aws_vpc\" \"mainvpc\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_default_security_group\" \"default\" {\n  vpc_id = aws_vpc.mainvpc.id\n\n  ingress {\n    protocol  = -1\n    self      = true\n    from_port = 0\n    to_port   = 0\n  }\n}\n```\n\n### Removing `aws_default_security_group` From Your Configuration\n\nRemoving this resource from your configuration will remove it from your statefile and management, but will not destroy the Security Group. All ingress or egress rules will be left as they are at the time of removal. You can resume managing them via the AWS Console.\n\n## Argument Reference\n\nThe following arguments are optional:\n\n* `egress` - (Optional, VPC only) Configuration block. Detailed below.\n* `ingress` - (Optional) Configuration block. Detailed below.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_id` - (Optional, Forces new resource) VPC ID. **Note that changing the `vpc_id` will _not_ restore any default security group rules that were modified, added, or removed.** It will be left in its current state.\n\n### egress and ingress\n\nBoth arguments are processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\nBoth `egress` and `ingress` objects have the same arguments.\n\n* `cidr_blocks` - (Optional) List of CIDR blocks.\n* `description` - (Optional) Description of this rule.\n* `from_port` - (Required) Start port (or ICMP type number if protocol is `icmp`)\n* `ipv6_cidr_blocks` - (Optional) List of IPv6 CIDR blocks.\n* `prefix_list_ids` - (Optional) List of prefix list IDs (for allowing access to VPC endpoints)\n* `protocol` - (Required) Protocol. If you select a protocol of \"-1\" (semantically equivalent to `all`, which is not a valid value here), you must specify a `from_port` and `to_port` equal to `0`. If not `icmp`, `tcp`, `udp`, or `-1` use the [protocol number](https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml).\n* `security_groups` - (Optional) List of security group Group Names if using EC2-Classic, or Group IDs if using a VPC.\n* `self` - (Optional) Whether the security group itself will be added as a source to this egress rule.\n* `to_port` - (Required) End range port (or ICMP code if protocol is `icmp`).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the security group.\n* `description` - Description of the security group.\n* `id` - ID of the security group.\n* `name` - Name of the security group.\n* `owner_id` - Owner ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[aws-default-security-groups]: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html#default-security-group\n\n## Import\n\nSecurity Groups can be imported using the `security group id`, e.g.,\n\n```\n$ terraform import aws_default_security_group.default_sg sg-903004f8\n```\n",
    "basename": "default_security_group.html"
  },
  "default_subnet.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_default_subnet",
    "description": "Manage a default VPC subnet resource.",
    "preview": "# Resource: aws_default_subnet\n\nProvides a resource to manage a …",
    "content": "\n\n# Resource: aws_default_subnet\n\nProvides a resource to manage a [default AWS VPC subnet](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/default-vpc.html#default-vpc-basics) in the current region.\n\nThe `aws_default_subnet` behaves differently from normal resources, in that Terraform does not _create_ this resource but instead \"adopts\" it into management.\n\nThe `aws_default_subnet` resource allows you to manage a region's default VPC subnet but Terraform cannot destroy it. Removing this resource from your configuration will remove it from your statefile and Terraform management.\n\n## Example Usage\n\n```terraform\nresource \"aws_default_subnet\" \"default_az1\" {\n  availability_zone = \"us-west-2a\"\n\n  tags = {\n    Name = \"Default subnet for us-west-2a\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following argument is required:\n\n* `availability_zone`- (Required) AZ for the subnet.\n\nThe following arguments are optional:\n\n* `map_public_ip_on_launch` - (Optional) Whether instances launched into the subnet should be assigned a public IP address.\n* `tags` - (Optional) Map of tags to assign to the resource.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN for the subnet.\n* `assign_ipv6_address_on_creation` - Whether IPv6 addresses are assigned on creation.\n* `availability_zone_id`- AZ ID of the subnet.\n* `cidr_block` - CIDR block for the subnet.\n* `id` - ID of the subnet\n* `ipv6_association_id` - Association ID for the IPv6 CIDR block.\n* `ipv6_cidr_block` - IPv6 CIDR block.\n* `owner_id` - ID of the AWS account that owns the subnet.\n* `vpc_id` - VPC ID.\n\n## Import\n\nSubnets can be imported using the `subnet id`, e.g.,\n\n```\n$ terraform import aws_default_subnet.public_subnet subnet-9d4a7b6c\n```",
    "basename": "default_subnet.html"
  },
  "default_vpc.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_default_vpc",
    "description": "Manage the default VPC resource.",
    "preview": "# Resource: aws_default_vpc\n\nProvides a resource to manage the …",
    "content": "\n\n# Resource: aws_default_vpc\n\nProvides a resource to manage the [default AWS VPC](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/default-vpc.html)\nin the current region.\n\nFor AWS accounts created after 2013-12-04, each region comes with a Default VPC.\n**This is an advanced resource**, and has special caveats to be aware of when\nusing it. Please read this document in its entirety before using this resource.\n\nThe `aws_default_vpc` behaves differently from normal resources, in that\nTerraform does not _create_ this resource, but instead \"adopts\" it\ninto management.\n\n## Example Usage\n\nBasic usage with tags:\n\n```terraform\nresource \"aws_default_vpc\" \"default\" {\n  tags = {\n    Name = \"Default VPC\"\n  }\n}\n```\n\n## Argument Reference\n\nThe arguments of an `aws_default_vpc` differ slightly from `aws_vpc`\nresources. Namely, the `cidr_block`, `instance_tenancy` and `assign_generated_ipv6_cidr_block`\narguments are computed. The following arguments are still supported:\n\n* `enable_dns_support` - (Optional) A boolean flag to enable/disable DNS support in the VPC. Defaults true.\n* `enable_dns_hostnames` - (Optional) A boolean flag to enable/disable DNS hostnames in the VPC. Defaults false.\n* `enable_classiclink` - (Optional) A boolean flag to enable/disable ClassicLink\n  for the VPC. Only valid in regions and accounts that support EC2 Classic.\n  See the [ClassicLink documentation][1] for more information. Defaults false.\n* `tags` - (Optional) A map of tags to assign to the resource.\n\n### Removing `aws_default_vpc` from your configuration\n\nThe `aws_default_vpc` resource allows you to manage a region's default VPC,\nbut Terraform cannot destroy it. Removing this resource from your configuration\nwill remove it from your statefile and management, but will not destroy the VPC.\nYou can resume managing the VPC via the AWS Console.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of VPC\n* `id` - The ID of the VPC\n* `cidr_block` - The CIDR block of the VPC\n* `instance_tenancy` - Tenancy of instances spin up within VPC.\n* `enable_dns_support` - Whether or not the VPC has DNS support\n* `enable_dns_hostnames` - Whether or not the VPC has DNS hostname support\n* `enable_classiclink` - Whether or not the VPC has Classiclink enabled\n* `assign_generated_ipv6_cidr_block` - Whether or not an Amazon-provided IPv6 CIDR\nblock with a /56 prefix length for the VPC was assigned\n* `main_route_table_id` - The ID of the main route table associated with\n     this VPC. Note that you can change a VPC's main route table by using an\n     [`aws_main_route_table_association`](/docs/providers/aws/r/main_route_table_association.html)\n* `default_network_acl_id` - The ID of the network ACL created by default on VPC creation\n* `default_security_group_id` - The ID of the security group created by default on VPC creation\n* `default_route_table_id` - The ID of the route table created by default on VPC creation\n* `ipv6_association_id` - The association ID for the IPv6 CIDR block of the VPC\n* `ipv6_cidr_block` - The IPv6 CIDR block of the VPC\n* `owner_id` - The ID of the AWS account that owns the VPC.\n\n\n[1]: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html\n\n## Import\n\nDefault VPCs can be imported using the `vpc id`, e.g.,\n\n```\n$ terraform import aws_default_vpc.default vpc-a01106c2\n```\n",
    "basename": "default_vpc.html"
  },
  "default_vpc_dhcp_options.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_default_vpc_dhcp_options",
    "description": "Manage the default VPC DHCP Options resource.",
    "preview": "# Resource: aws_default_vpc_dhcp_options\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_default_vpc_dhcp_options\n\nProvides a resource to manage the [default AWS DHCP Options Set](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_DHCP_Options.html#AmazonDNS)\nin the current region.\n\nEach AWS region comes with a default set of DHCP options.\n**This is an advanced resource**, and has special caveats to be aware of when\nusing it. Please read this document in its entirety before using this resource.\n\nThe `aws_default_vpc_dhcp_options` behaves differently from normal resources, in that\nTerraform does not _create_ this resource, but instead \"adopts\" it\ninto management.\n\n## Example Usage\n\nBasic usage with tags:\n\n```terraform\nresource \"aws_default_vpc_dhcp_options\" \"default\" {\n  tags = {\n    Name = \"Default DHCP Option Set\"\n  }\n}\n```\n\n## Argument Reference\n\nThe arguments of an `aws_default_vpc_dhcp_options` differ slightly from `aws_vpc_dhcp_options`  resources.\nNamely, the `domain_name`, `domain_name_servers` and `ntp_servers` arguments are computed.\nThe following arguments are still supported:\n\n* `netbios_name_servers` - (Optional) List of NETBIOS name servers.\n* `netbios_node_type` - (Optional) The NetBIOS node type (1, 2, 4, or 8). AWS recommends to specify 2 since broadcast and multicast are not supported in their network. For more information about these node types, see [RFC 2132](http://www.ietf.org/rfc/rfc2132.txt).\n* `owner_id` - The ID of the AWS account that owns the DHCP options set.\n* `tags` - (Optional) A map of tags to assign to the resource.\n\n### Removing `aws_default_vpc_dhcp_options` from your configuration\n\nThe `aws_default_vpc_dhcp_options` resource allows you to manage a region's default DHCP Options Set,\nbut Terraform cannot destroy it. Removing this resource from your configuration\nwill remove it from your statefile and management, but will not destroy the DHCP Options Set.\nYou can resume managing the DHCP Options Set via the AWS Console.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the DHCP Options Set.\n* `arn` - The ARN of the DHCP Options Set.\n\n## Import\n\nVPC DHCP Options can be imported using the `dhcp options id`, e.g.,\n\n```\n$ terraform import aws_default_vpc_dhcp_options.default_options dopt-d9070ebb\n```\n",
    "basename": "default_vpc_dhcp_options.html"
  },
  "detective_graph.html": {
    "subcategory": "Detective",
    "layout": "aws",
    "page_title": "AWS: aws_detective_graph",
    "description": "Provides a resource to manage Amazon Detective on a Graph.",
    "preview": "# Resource: aws_detective_graph\n\nProvides a resource to manage an …",
    "content": "\n\n# Resource: aws_detective_graph\n\nProvides a resource to manage an [AWS Detective Graph](https://docs.aws.amazon.com/detective/latest/APIReference/API_CreateGraph.html). As an AWS account may own only one Detective graph per region, provisioning multiple Detective graphs requires a separate provider configuration for each graph.\n\n## Example Usage\n\n```terraform\nresource \"aws_detective_graph\" \"example\" {\n  tags = {\n    Name = \"example-detective-graph\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are optional:\n\n* `tags` -  (Optional) A map of tags to assign to the instance. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ARN of the Detective Graph.\n* `graph_arn` - ARN of the Detective Graph.\n* `created_time` - Date and time, in UTC and extended RFC 3339 format, when the Amazon Detective Graph was created.\n\n## Import\n\n`aws_detective_graph` can be imported using the arn, e.g.\n\n```\n$ terraform import aws_detective_graph.example arn:aws:detective:us-east-1:123456789101:graph:231684d34gh74g4bae1dbc7bd807d02d\n```\n",
    "basename": "detective_graph.html"
  },
  "devicefarm_project.html": {
    "subcategory": "Device Farm",
    "layout": "aws",
    "page_title": "AWS: aws_devicefarm_project",
    "description": "Provides a Devicefarm project",
    "preview": "# Resource: aws_devicefarm_project\n\nProvides a resource to manage …",
    "content": "\n\n# Resource: aws_devicefarm_project\n\nProvides a resource to manage AWS Device Farm Projects.\n\nFor more information about Device Farm Projects, see the AWS Documentation on\n[Device Farm Projects][aws-get-project].\n\n~> **NOTE:** AWS currently has limited regional support for Device Farm (e.g., `us-west-2`). See [AWS Device Farm endpoints and quotas](https://docs.aws.amazon.com/general/latest/gr/devicefarm.html) for information on supported regions.\n\n## Example Usage\n\n\n```terraform\nresource \"aws_devicefarm_project\" \"awesome_devices\" {\n  name = \"my-device-farm\"\n}\n```\n\n## Argument Reference\n\n* `name` - (Required) The name of the project\n* `default_job_timeout_minutes` - (Optional) Sets the execution timeout value (in minutes) for a project. All test runs in this project use the specified execution timeout value unless overridden when scheduling a run.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name of this project\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[aws-get-project]: http://docs.aws.amazon.com/devicefarm/latest/APIReference/API_GetProject.html\n\n## Import\n\nDeviceFarm Projects can be imported by their arn:\n\n```\n$ terraform import aws_devicefarm_project.example arn:aws:devicefarm:us-west-2:123456789012:project:4fa784c7-ccb4-4dbf-ba4f-02198320daa1\n```\n",
    "basename": "devicefarm_project.html"
  },
  "directory_service_conditional_forwarder.html": {
    "subcategory": "Directory Service",
    "layout": "aws",
    "page_title": "AWS: aws_directory_service_conditional_forwarder",
    "description": "Provides a conditional forwarder for managed Microsoft AD in AWS Directory Service.",
    "preview": "# Resource: aws_directory_service_conditional_forwarder\n\nProvides a …",
    "content": "\n\n# Resource: aws_directory_service_conditional_forwarder\n\nProvides a conditional forwarder for managed Microsoft AD in AWS Directory Service.\n\n## Example Usage\n\n```terraform\nresource \"aws_directory_service_conditional_forwarder\" \"example\" {\n  directory_id       = aws_directory_service_directory.ad.id\n  remote_domain_name = \"example.com\"\n\n  dns_ips = [\n    \"8.8.8.8\",\n    \"8.8.4.4\",\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `directory_id` - (Required) The id of directory.\n* `dns_ips` - (Required) A list of forwarder IP addresses.\n* `remote_domain_name` - (Required) The fully qualified domain name of the remote domain for which forwarders will be used.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nConditional forwarders can be imported using the directory id and remote_domain_name, e.g.,\n\n```\n$ terraform import aws_directory_service_conditional_forwarder.example d-1234567890:example.com\n```\n",
    "basename": "directory_service_conditional_forwarder.html"
  },
  "directory_service_directory.html": {
    "subcategory": "Directory Service",
    "layout": "aws",
    "page_title": "AWS: aws_directory_service_directory",
    "description": "Provides a directory in AWS Directory Service.",
    "preview": "# Resource: aws_directory_service_directory\n\nProvides a Simple or …",
    "content": "\n\n# Resource: aws_directory_service_directory\n\nProvides a Simple or Managed Microsoft directory in AWS Directory Service.\n\n~> **Note:** All arguments including the password and customer username will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n### SimpleAD\n\n```terraform\nresource \"aws_directory_service_directory\" \"bar\" {\n  name     = \"corp.notexample.com\"\n  password = \"SuperSecretPassw0rd\"\n  size     = \"Small\"\n\n  vpc_settings {\n    vpc_id     = aws_vpc.main.id\n    subnet_ids = [aws_subnet.foo.id, aws_subnet.bar.id]\n  }\n\n  tags = {\n    Project = \"foo\"\n  }\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"foo\" {\n  vpc_id            = aws_vpc.main.id\n  availability_zone = \"us-west-2a\"\n  cidr_block        = \"10.0.1.0/24\"\n}\n\nresource \"aws_subnet\" \"bar\" {\n  vpc_id            = aws_vpc.main.id\n  availability_zone = \"us-west-2b\"\n  cidr_block        = \"10.0.2.0/24\"\n}\n```\n\n### Microsoft Active Directory (MicrosoftAD)\n\n```terraform\nresource \"aws_directory_service_directory\" \"bar\" {\n  name     = \"corp.notexample.com\"\n  password = \"SuperSecretPassw0rd\"\n  edition  = \"Standard\"\n  type     = \"MicrosoftAD\"\n\n  vpc_settings {\n    vpc_id     = aws_vpc.main.id\n    subnet_ids = [aws_subnet.foo.id, aws_subnet.bar.id]\n  }\n\n  tags = {\n    Project = \"foo\"\n  }\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"foo\" {\n  vpc_id            = aws_vpc.main.id\n  availability_zone = \"us-west-2a\"\n  cidr_block        = \"10.0.1.0/24\"\n}\n\nresource \"aws_subnet\" \"bar\" {\n  vpc_id            = aws_vpc.main.id\n  availability_zone = \"us-west-2b\"\n  cidr_block        = \"10.0.2.0/24\"\n}\n```\n\n### Microsoft Active Directory Connector (ADConnector)\n\n```terraform\nresource \"aws_directory_service_directory\" \"connector\" {\n  name     = \"corp.notexample.com\"\n  password = \"SuperSecretPassw0rd\"\n  size     = \"Small\"\n  type     = \"ADConnector\"\n\n  connect_settings {\n    customer_dns_ips  = [\"A.B.C.D\"]\n    customer_username = \"Admin\"\n    subnet_ids        = [aws_subnet.foo.id, aws_subnet.bar.id]\n    vpc_id            = aws_vpc.main.id\n  }\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"foo\" {\n  vpc_id            = aws_vpc.main.id\n  availability_zone = \"us-west-2a\"\n  cidr_block        = \"10.0.1.0/24\"\n}\n\nresource \"aws_subnet\" \"bar\" {\n  vpc_id            = aws_vpc.main.id\n  availability_zone = \"us-west-2b\"\n  cidr_block        = \"10.0.2.0/24\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The fully qualified name for the directory, such as `corp.example.com`\n* `password` - (Required) The password for the directory administrator or connector user.\n* `size` - (Required for `SimpleAD` and `ADConnector`) The size of the directory (`Small` or `Large` are accepted values).\n* `vpc_settings` - (Required for `SimpleAD` and `MicrosoftAD`) VPC related information about the directory. Fields documented below.\n* `connect_settings` - (Required for `ADConnector`) Connector related information about the directory. Fields documented below.\n* `alias` - (Optional) The alias for the directory (must be unique amongst all aliases in AWS). Required for `enable_sso`.\n* `description` - (Optional) A textual description for the directory.\n* `short_name` - (Optional) The short name of the directory, such as `CORP`.\n* `enable_sso` - (Optional) Whether to enable single-sign on for the directory. Requires `alias`. Defaults to `false`.\n* `type` (Optional) - The directory type (`SimpleAD`, `ADConnector` or `MicrosoftAD` are accepted values). Defaults to `SimpleAD`.\n* `edition` - (Optional) The MicrosoftAD edition (`Standard` or `Enterprise`). Defaults to `Enterprise` (applies to MicrosoftAD type only).\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n**vpc_settings** supports the following:\n\n* `subnet_ids` - (Required) The identifiers of the subnets for the directory servers (2 subnets in 2 different AZs).\n* `vpc_id` - (Required) The identifier of the VPC that the directory is in.\n\n**connect_settings** supports the following:\n\n* `customer_username` - (Required) The username corresponding to the password provided.\n* `customer_dns_ips` - (Required) The DNS IP addresses of the domain to connect to.\n* `subnet_ids` - (Required) The identifiers of the subnets for the directory servers (2 subnets in 2 different AZs).\n* `vpc_id` - (Required) The identifier of the VPC that the directory is in.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The directory identifier.\n* `access_url` - The access URL for the directory, such as `http://alias.awsapps.com`.\n* `dns_ip_addresses` - A list of IP addresses of the DNS servers for the directory or connector.\n* `security_group_id` - The ID of the security group created by the directory.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n`connect_settings` (for `ADConnector`) is also exported with the following attributes:\n\n* `connect_ips` - The IP addresses of the AD Connector servers.\n\n## Import\n\nDirectoryService directories can be imported using the directory `id`, e.g.,\n\n```\n$ terraform import aws_directory_service_directory.sample d-926724cf57\n```\n",
    "basename": "directory_service_directory.html"
  },
  "directory_service_log_subscription.html": {
    "subcategory": "Directory Service",
    "layout": "aws",
    "page_title": "AWS: aws_directory_service_log_subscription",
    "description": "Provides a Log subscription for AWS Directory Service that pushes logs to cloudwatch.",
    "preview": "# Resource: aws_directory_service_log_subscription\n\nProvides a Log …",
    "content": "\n\n# Resource: aws_directory_service_log_subscription\n\nProvides a Log subscription for AWS Directory Service that pushes logs to cloudwatch.\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name              = \"/aws/directoryservice/${aws_directory_service_directory.example.id}\"\n  retention_in_days = 14\n}\n\ndata \"aws_iam_policy_document\" \"ad-log-policy\" {\n  statement {\n    actions = [\n      \"logs:CreateLogStream\",\n      \"logs:PutLogEvents\",\n    ]\n\n    principals {\n      identifiers = [\"ds.amazonaws.com\"]\n      type        = \"Service\"\n    }\n\n    resources = [\"${aws_cloudwatch_log_group.example.arn}:*\"]\n\n    effect = \"Allow\"\n  }\n}\n\nresource \"aws_cloudwatch_log_resource_policy\" \"ad-log-policy\" {\n  policy_document = data.aws_iam_policy_document.ad-log-policy.json\n  policy_name     = \"ad-log-policy\"\n}\n\nresource \"aws_directory_service_log_subscription\" \"example\" {\n  directory_id   = aws_directory_service_directory.example.id\n  log_group_name = aws_cloudwatch_log_group.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `directory_id` - (Required) The id of directory.\n* `log_group_name` - (Required) Name of the cloudwatch log group to which the logs should be published. The log group should be already created and the directory service principal should be provided with required permission to create stream and publish logs. Changing this value would delete the current subscription and create a new one. A directory can only have one log subscription at a time.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nDirectory Service Log Subscriptions can be imported using the directory id, e.g.,\n\n```\n$ terraform import aws_directory_service_log_subscription.msad d-1234567890\n```\n",
    "basename": "directory_service_log_subscription.html"
  },
  "dlm_lifecycle_policy": {
    "subcategory": "Data Lifecycle Manager (DLM)",
    "layout": "aws",
    "page_title": "AWS: aws_dlm_lifecycle_policy",
    "description": "Provides a Data Lifecycle Manager (DLM) lifecycle policy for managing snapshots.",
    "preview": "# Resource: aws_dlm_lifecycle_policy\n\nProvides a [Data Lifecycle …",
    "content": "\n\n# Resource: aws_dlm_lifecycle_policy\n\nProvides a [Data Lifecycle Manager (DLM) lifecycle policy](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html) for managing snapshots.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_iam_role\" \"dlm_lifecycle_role\" {\n  name = \"dlm-lifecycle-role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"dlm.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"dlm_lifecycle\" {\n  name = \"dlm-lifecycle-policy\"\n  role = aws_iam_role.dlm_lifecycle_role.id\n\n  policy = <<EOF\n{\n   \"Version\": \"2012-10-17\",\n   \"Statement\": [\n      {\n         \"Effect\": \"Allow\",\n         \"Action\": [\n            \"ec2:CreateSnapshot\",\n            \"ec2:CreateSnapshots\",\n            \"ec2:DeleteSnapshot\",\n            \"ec2:DescribeInstances\",\n            \"ec2:DescribeVolumes\",\n            \"ec2:DescribeSnapshots\"\n         ],\n         \"Resource\": \"*\"\n      },\n      {\n         \"Effect\": \"Allow\",\n         \"Action\": [\n            \"ec2:CreateTags\"\n         ],\n         \"Resource\": \"arn:aws:ec2:*::snapshot/*\"\n      }\n   ]\n}\nEOF\n}\n\nresource \"aws_dlm_lifecycle_policy\" \"example\" {\n  description        = \"example DLM lifecycle policy\"\n  execution_role_arn = aws_iam_role.dlm_lifecycle_role.arn\n  state              = \"ENABLED\"\n\n  policy_details {\n    resource_types = [\"VOLUME\"]\n\n    schedule {\n      name = \"2 weeks of daily snapshots\"\n\n      create_rule {\n        interval      = 24\n        interval_unit = \"HOURS\"\n        times         = [\"23:45\"]\n      }\n\n      retain_rule {\n        count = 14\n      }\n\n      tags_to_add = {\n        SnapshotCreator = \"DLM\"\n      }\n\n      copy_tags = false\n    }\n\n    target_tags = {\n      Snapshot = \"true\"\n    }\n  }\n}\n```\n\n### Example Cross-Region Snapshot Copy Usage\n\n```terraform\n# ...other configuration...\nresource \"aws_kms_key\" \"dlm_cross_region_copy_cmk\" {\n  provider = aws.alternate\n\n  description = \"Example Alternate Region KMS Key\"\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Id\": \"dlm-cross-region-copy-cmk\",\n  \"Statement\": [\n    {\n      \"Sid\": \"Enable IAM User Permissions\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"\n      },\n      \"Action\": \"kms:*\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_dlm_lifecycle_policy\" \"example\" {\n  description        = \"example DLM lifecycle policy\"\n  execution_role_arn = aws_iam_role.dlm_lifecycle_role.arn\n  state              = \"ENABLED\"\n\n  policy_details {\n    resource_types = [\"VOLUME\"]\n\n    schedule {\n      name = \"2 weeks of daily snapshots\"\n\n      create_rule {\n        interval      = 24\n        interval_unit = \"HOURS\"\n        times         = [\"23:45\"]\n      }\n\n      retain_rule {\n        count = 14\n      }\n\n      tags_to_add = {\n        SnapshotCreator = \"DLM\"\n      }\n\n      copy_tags = false\n\n      cross_region_copy_rule {\n        target    = \"us-west-2\"\n        encrypted = true\n        cmk_arn   = aws_kms_key.dlm_cross_region_copy_cmk.arn\n        copy_tags = true\n        retain_rule {\n          interval      = 30\n          interval_unit = \"DAYS\"\n        }\n      }\n    }\n\n    target_tags = {\n      Snapshot = \"true\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Required) A description for the DLM lifecycle policy.\n* `execution_role_arn` - (Required) The ARN of an IAM role that is able to be assumed by the DLM service.\n* `policy_details` - (Required) See the [`policy_details` configuration](#policy-details-arguments) block. Max of 1.\n* `state` - (Optional) Whether the lifecycle policy should be enabled or disabled. `ENABLED` or `DISABLED` are valid values. Defaults to `ENABLED`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n#### Policy Details arguments\n\n* `resource_types` - (Required) A list of resource types that should be targeted by the lifecycle policy. `VOLUME` is currently the only allowed value.\n* `schedule` - (Required) See the [`schedule` configuration](#schedule-arguments) block.\n* `target_tags` (Required) A map of tag keys and their values. Any resources that match the `resource_types` and are tagged with _any_ of these tags will be targeted.\n\n~> Note: You cannot have overlapping lifecycle policies that share the same `target_tags`. Terraform is unable to detect this at plan time but it will fail during apply.\n\n#### Schedule arguments\n\n* `copy_tags` - (Optional) Copy all user-defined tags on a source volume to snapshots of the volume created by this policy.\n* `create_rule` - (Required) See the [`create_rule`](#create-rule-arguments) block. Max of 1 per schedule.\n* `cross_region_copy_rule` (Optional) - See the [`cross_region_copy_rule`](#cross-region-copy-rule-arguments) block. Max of 3 per schedule.\n* `name` - (Required) A name for the schedule.\n* `retain_rule` - (Required) See the [`retain_rule`](#retain-rule-arguments) block. Max of 1 per schedule.\n* `tags_to_add` - (Optional) A map of tag keys and their values. DLM lifecycle policies will already tag the snapshot with the tags on the volume. This configuration adds extra tags on top of these.\n\n#### Create Rule arguments\n\n* `interval` - (Required) How often this lifecycle policy should be evaluated. `1`, `2`,`3`,`4`,`6`,`8`,`12` or `24` are valid values.\n* `interval_unit` - (Optional) The unit for how often the lifecycle policy should be evaluated. `HOURS` is currently the only allowed value and also the default value.\n* `times` - (Optional) A list of times in 24 hour clock format that sets when the lifecycle policy should be evaluated. Max of 1.\n\n#### Retain Rule arguments\n\n* `count` - (Required) How many snapshots to keep. Must be an integer between 1 and 1000.\n\n#### Cross Region Copy Rule arguments\n\n* `cmk_arn` - (Optional) The Amazon Resource Name (ARN) of the AWS KMS customer master key (CMK) to use for EBS encryption. If this argument is not specified, the default KMS key for the account is used.\n* `copy_tags` - (Optional) Whether to copy all user-defined tags from the source snapshot to the cross-region snapshot copy.\n* `deprecate_rule` - (Optional) The AMI deprecation rule for cross-Region AMI copies created by the rule. See the [`deprecate_rule`](#cross-region-copy-rule-deprecate-rule-arguments) block.\n* `encrypted` - (Required) To encrypt a copy of an unencrypted snapshot if encryption by default is not enabled, enable encryption using this parameter. Copies of encrypted snapshots are encrypted, even if this parameter is false or if encryption by default is not enabled.\n* `retain_rule` - (Required) The retention rule that indicates how long snapshot copies are to be retained in the destination Region. See the [`retain_rule`](#cross-region-copy-rule-retain-rule-arguments) block. Max of 1 per schedule.\n* `target` - (Required) The target Region or the Amazon Resource Name (ARN) of the target Outpost for the snapshot copies.\n\n#### Cross Region Copy Rule Deprecate Rule arguments\n\n* `interval` - (Required) The period after which to deprecate the cross-Region AMI copies. The period must be less than or equal to the cross-Region AMI copy retention period, and it can't be greater than 10 years. This is equivalent to 120 months, 520 weeks, or 3650 days.\n* `interval_unit` - (Required) The unit of time in which to measure the `interval`. Valid values: `DAYS`, `WEEKS`, `MONTHS`, or `YEARS`.\n\n#### Cross Region Copy Rule Retain Rule arguments\n\n* `interval` - (Required) The amount of time to retain each snapshot. The maximum is 100 years. This is equivalent to 1200 months, 5200 weeks, or 36500 days.\n* `interval_unit` - (Required) The unit of time for time-based retention. Valid values: `DAYS`, `WEEKS`, `MONTHS`, or `YEARS`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the DLM Lifecycle Policy.\n* `id` - Identifier of the DLM Lifecycle Policy.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDLM lifecycle policies can be imported by their policy ID:\n\n```\n$ terraform import aws_dlm_lifecycle_policy.example policy-abcdef12345678901\n```\n",
    "basename": "dlm_lifecycle_policy"
  },
  "dms_certificate.html": {
    "subcategory": "Database Migration Service (DMS)",
    "layout": "aws",
    "page_title": "AWS: aws_dms_certificate",
    "description": "Provides a DMS (Data Migration Service) certificate resource.",
    "preview": "# Resource: aws_dms_certificate\n\nProvides a DMS (Data Migration …",
    "content": "\n\n# Resource: aws_dms_certificate\n\nProvides a DMS (Data Migration Service) certificate resource. DMS certificates can be created, deleted, and imported.\n\n~> **Note:** All arguments including the PEM encoded certificate will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\n# Create a new certificate\nresource \"aws_dms_certificate\" \"test\" {\n  certificate_id  = \"test-dms-certificate-tf\"\n  certificate_pem = \"...\"\n\n  tags = {\n    Name = \"test\"\n  }\n\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `certificate_id` - (Required) The certificate identifier.\n\n    - Must contain from 1 to 255 alphanumeric characters and hyphens.\n\n* `certificate_pem` - (Optional) The contents of the .pem X.509 certificate file for the certificate. Either `certificate_pem` or `certificate_wallet` must be set.\n* `certificate_wallet` - (Optional) The contents of the Oracle Wallet certificate for use with SSL, provided as a base64-encoded String. Either `certificate_pem` or `certificate_wallet` must be set.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `certificate_arn` - The Amazon Resource Name (ARN) for the certificate.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nCertificates can be imported using the `certificate_id`, e.g.,\n\n```\n$ terraform import aws_dms_certificate.test test-dms-certificate-tf\n```\n",
    "basename": "dms_certificate.html"
  },
  "dms_endpoint.html": {
    "subcategory": "Database Migration Service (DMS)",
    "layout": "aws",
    "page_title": "AWS: aws_dms_endpoint",
    "description": "Provides a DMS (Data Migration Service) endpoint resource.",
    "preview": "# Resource: aws_dms_endpoint\n\nProvides a DMS (Data Migration …",
    "content": "\n\n# Resource: aws_dms_endpoint\n\nProvides a DMS (Data Migration Service) endpoint resource. DMS endpoints can be created, updated, deleted, and imported.\n\n~> **Note:** All arguments including the password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\n# Create a new endpoint\nresource \"aws_dms_endpoint\" \"test\" {\n  certificate_arn             = \"arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012\"\n  database_name               = \"test\"\n  endpoint_id                 = \"test-dms-endpoint-tf\"\n  endpoint_type               = \"source\"\n  engine_name                 = \"aurora\"\n  extra_connection_attributes = \"\"\n  kms_key_arn                 = \"arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012\"\n  password                    = \"test\"\n  port                        = 3306\n  server_name                 = \"test\"\n  ssl_mode                    = \"none\"\n\n  tags = {\n    Name = \"test\"\n  }\n\n  username = \"test\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `certificate_arn` - (Optional, Default: empty string) The Amazon Resource Name (ARN) for the certificate.\n* `database_name` - (Optional) The name of the endpoint database.\n* `elasticsearch_settings` - (Optional) Configuration block with Elasticsearch settings. Detailed below.\n* `endpoint_id` - (Required) The database endpoint identifier.\n\n    - Must contain from 1 to 255 alphanumeric characters or hyphens.\n    - Must begin with a letter\n    - Must contain only ASCII letters, digits, and hyphens\n    - Must not end with a hyphen\n    - Must not contain two consecutive hyphens\n\n* `endpoint_type` - (Required) The type of endpoint. Can be one of `source | target`.\n* `engine_name` - (Required) The type of engine for the endpoint. Can be one of `aurora | aurora-postgresql| azuredb | db2 | docdb | dynamodb | elasticsearch | kafka | kinesis | mariadb | mongodb | mysql | oracle | postgres | redshift | s3 | sqlserver | sybase`.\n* `extra_connection_attributes` - (Optional) Additional attributes associated with the connection. For available attributes see [Using Extra Connection Attributes with AWS Database Migration Service](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.ConnectionAttrib).\n* `kafka_settings` - (Optional) Configuration block with Kafka settings. Detailed below.\n* `kinesis_settings` - (Optional) Configuration block with Kinesis settings. Detailed below.\n* `kms_key_arn` - (Required when `engine_name` is `mongodb`, optional otherwise) The Amazon Resource Name (ARN) for the KMS key that will be used to encrypt the connection parameters. If you do not specify a value for `kms_key_arn`, then AWS DMS will use your default encryption key. AWS KMS creates the default encryption key for your AWS account. Your AWS account has a different default encryption key for each AWS region.\n* `mongodb_settings` - (Optional) Configuration block with MongoDB settings. Detailed below.\n* `password` - (Optional) The password to be used to login to the endpoint database.\n* `port` - (Optional) The port used by the endpoint database.\n* `s3_settings` - (Optional) Configuration block with S3 settings. Detailed below.\n* `server_name` - (Optional) The host name of the server.\n* `service_access_role` - (Optional) The Amazon Resource Name (ARN) used by the service access IAM role for dynamodb endpoints.\n* `ssl_mode` - (Optional, Default: none) The SSL mode to use for the connection. Can be one of `none | require | verify-ca | verify-full`\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `username` - (Optional) The user name to be used to login to the endpoint database.\n\n### elasticsearch_settings Arguments\n\n-> Additional information can be found in the [Using Amazon Elasticsearch Service as a Target for AWS Database Migration Service documentation](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Elasticsearch.html).\n\nThe `elasticsearch_settings` configuration block supports the following arguments:\n\n* `endpoint_uri` - (Required) Endpoint for the Elasticsearch cluster.\n* `error_retry_duration` - (Optional) Maximum number of seconds for which DMS retries failed API requests to the Elasticsearch cluster. Defaults to `300`.\n* `full_load_error_percentage` - (Optional) Maximum percentage of records that can fail to be written before a full load operation stops. Defaults to `10`.\n* `service_access_role_arn` - (Required) Amazon Resource Name (ARN) of the IAM Role with permissions to write to the Elasticsearch cluster.\n\n### kafka_settings Arguments\n\n-> Additional information can be found in the [Using Apache Kafka as a Target for AWS Database Migration Service documentation](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Kafka.html).\n\nThe `kafka_settings` configuration block supports the following arguments:\n\n* `broker` - (Required) Kafka broker location. Specify in the form broker-hostname-or-ip:port.\n* `include_control_details` - (Optional) Shows detailed control information for table definition, column definition, and table and column changes in the Kafka message output. The default is `false`.\n* `include_null_and_empty` - (Optional) Include NULL and empty columns for records migrated to the endpoint. The default is `false`.\n* `include_partition_value` - (Optional) Shows the partition value within the Kafka message output unless the partition type is `schema-table-type`. The default is `false`.\n* `include_table_alter_operations` - (Optional) Includes any data definition language (DDL) operations that change the table in the control data, such as `rename-table`, `drop-table`, `add-column`, `drop-column`, and `rename-column`. The default is `false`.\n* `include_transaction_details` - (Optional) Provides detailed transaction information from the source database. This information includes a commit timestamp, a log position, and values for `transaction_id`, previous `transaction_id`, and `transaction_record_id` (the record offset within a transaction). The default is `false`.\n* `message_format` - (Optional) The output format for the records created on the endpoint. The message format is `JSON` (default) or `JSON_UNFORMATTED` (a single line with no tab).\n* `message_max_bytes` - (Optional) The maximum size in bytes for records created on the endpoint The default is `1,000,000`.\n* `no_hex_prefix` - (Optional) Set this optional parameter to true to avoid adding a '0x' prefix to raw data in hexadecimal format. For example, by default, AWS DMS adds a '0x' prefix to the LOB column type in hexadecimal format moving from an Oracle source to a Kafka target. Use the `no_hex_prefix` endpoint setting to enable migration of RAW data type columns without adding the `'0x'` prefix.\n* `partition_include_schema_table` - (Optional) Prefixes schema and table names to partition values, when the partition type is `primary-key-type`. Doing this increases data distribution among Kafka partitions. For example, suppose that a SysBench schema has thousands of tables and each table has only limited range for a primary key. In this case, the same primary key is sent from thousands of tables to the same partition, which causes throttling. The default is `false`.\n* `sasl_password` - (Optional) The secure password you created when you first set up your MSK cluster to validate a client identity and make an encrypted connection between server and client using SASL-SSL authentication.\n* `sasl_username` - (Optional) The secure user name you created when you first set up your MSK cluster to validate a client identity and make an encrypted connection between server and client using SASL-SSL authentication.\n* `security_protocol` - (Optional) Set secure connection to a Kafka target endpoint using Transport Layer Security (TLS). Options include `ssl-encryption`, `ssl-authentication`, and `sasl-ssl`. `sasl-ssl` requires `sasl_username` and `sasl_password`.\n* `ssl_ca_certificate_arn` - (Optional) The Amazon Resource Name (ARN) for the private certificate authority (CA) cert that AWS DMS uses to securely connect to your Kafka target endpoint.\n* `ssl_client_certificate_arn` - (Optional) The Amazon Resource Name (ARN) of the client certificate used to securely connect to a Kafka target endpoint.\n* `ssl_client_key_arn` - (Optional) The Amazon Resource Name (ARN) for the client private key used to securely connect to a Kafka target endpoint.\n* `ssl_client_key_password` - (Optional) The password for the client private key used to securely connect to a Kafka target endpoint.\n* `topic` - (Optional) Kafka topic for migration. Defaults to `kafka-default-topic`.\n\n### kinesis_settings Arguments\n\n-> Additional information can be found in the [Using Amazon Kinesis Data Streams as a Target for AWS Database Migration Service documentation](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Kinesis.html).\n\nThe `kinesis_settings` configuration block supports the following arguments:\n\n* `include_control_details` - (Optional) Shows detailed control information for table definition, column definition, and table and column changes in the Kinesis message output. The default is `false`.\n* `include_null_and_empty` - (Optional) Include NULL and empty columns in the target. The default is `false`.\n* `include_partition_value` - (Optional) Shows the partition value within the Kinesis message output, unless the partition type is schema-table-type. The default is `false`.\n* `include_table_alter_operations` - (Optional) Includes any data definition language (DDL) operations that change the table in the control data. The default is `false`.\n* `include_transaction_details` - (Optional) Provides detailed transaction information from the source database. The default is `false`.\n* `message_format` - (Optional) Output format for the records created. Defaults to `json`. Valid values are `json` and `json_unformatted` (a single line with no tab).\n* `partition_include_schema_table` - (Optional) Prefixes schema and table names to partition values, when the partition type is primary-key-type. The default is `false`.\n* `service_access_role_arn` - (Optional) Amazon Resource Name (ARN) of the IAM Role with permissions to write to the Kinesis data stream.\n* `stream_arn` - (Optional) Amazon Resource Name (ARN) of the Kinesis data stream.\n\n### mongodb_settings Arguments\n\n-> Additional information can be found in the [Using MongoDB as a Source for AWS DMS documentation](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.MongoDB.html).\n\nThe `mongodb_settings` configuration block supports the following arguments:\n\n* `auth_mechanism` - (Optional) Authentication mechanism to access the MongoDB source endpoint. Defaults to `default`.\n* `auth_source` - (Optional) Authentication database name. Not used when `auth_type` is `no`. Defaults to `admin`.\n* `auth_type` - (Optional) Authentication type to access the MongoDB source endpoint. Defaults to `password`.\n* `docs_to_investigate` - (Optional) Number of documents to preview to determine the document organization. Use this setting when `nesting_level` is set to `one`. Defaults to `1000`.\n* `extract_doc_id` - (Optional) Document ID. Use this setting when `nesting_level` is set to `none`. Defaults to `false`.\n* `nesting_level` - (Optional) Specifies either document or table mode. Defaults to `none`. Valid values are `one` (table mode) and `none` (document mode).\n\n### s3_settings Arguments\n\n-> Additional information can be found in the [Using Amazon S3 as a Source for AWS Database Migration Service documentation](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.S3.html) and [Using Amazon S3 as a Target for AWS Database Migration Service documentation](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html).\n\nThe `s3_settings` configuration block supports the following arguments:\n\n* `bucket_folder` - (Optional) S3 Bucket Object prefix.\n* `bucket_name` - (Optional) S3 Bucket name.\n* `compression_type` - (Optional) Set to compress target files. Defaults to `NONE`. Valid values are `GZIP` and `NONE`.\n* `csv_delimiter` - (Optional) Delimiter used to separate columns in the source files. Defaults to `,`.\n* `csv_row_delimiter` - (Optional) Delimiter used to separate rows in the source files. Defaults to `\\n`.\n* `data_format` - (Optional) The output format for the files that AWS DMS uses to create S3 objects. Defaults to `csv`. Valid values are `csv` and `parquet`.\n* `date_partition_enabled` - (Optional) Partition S3 bucket folders based on transaction commit dates. Defaults to `false`.\n* `encryption_mode` - (Optional) The server-side encryption mode that you want to encrypt your .csv or .parquet object files copied to S3. Defaults to `SSE_S3`. Valid values are `SSE_S3` and `SSE_KMS`.\n* `external_table_definition` - (Optional) JSON document that describes how AWS DMS should interpret the data.\n* `parquet_timestamp_in_millisecond` - (Optional) - Specifies the precision of any TIMESTAMP column values written to an S3 object file in .parquet format. Defaults to `false`.\n* `parquet_version` - (Optional) The version of the .parquet file format. Defaults to `parquet-1-0`. Valid values are `parquet-1-0` and `parquet-2-0`.\n* `server_side_encryption_kms_key_id` - (Optional) If you set encryptionMode to `SSE_KMS`, set this parameter to the Amazon Resource Name (ARN) for the AWS KMS key.\n* `service_access_role_arn` - (Optional) Amazon Resource Name (ARN) of the IAM Role with permissions to read from or write to the S3 Bucket.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `endpoint_arn` - The Amazon Resource Name (ARN) for the endpoint.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEndpoints can be imported using the `endpoint_id`, e.g.,\n\n```\n$ terraform import aws_dms_endpoint.test test-dms-endpoint-tf\n```\n",
    "basename": "dms_endpoint.html"
  },
  "dms_event_subscription.html": {
    "subcategory": "Database Migration Service (DMS)",
    "layout": "aws",
    "page_title": "AWS: aws_dms_event_subscription",
    "description": "Provides a DMS (Data Migration Service) event subscription resource.",
    "preview": "# Resource: aws_dms_event_subscription\n\nProvides a DMS (Data …",
    "content": "\n\n# Resource: aws_dms_event_subscription\n\nProvides a DMS (Data Migration Service) event subscription resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dms_event_subscription\" \"example\" {\n  enabled          = true\n  event_categories = [\"creation\", \"failure\"]\n  name             = \"my-favorite-event-subscription\"\n  sns_topic_arn    = aws_sns_topic.example.arn\n  source_ids       = [aws_dms_replication_task.example.replication_task_id]\n  source_type      = \"replication-task\"\n\n  tags = {\n    Name = \"example\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of event subscription.\n* `enabled` - (Optional, Default: true) Whether the event subscription should be enabled.\n* `event_categories` - (Optional) List of event categories to listen for, see `DescribeEventCategories` for a canonical list.\n* `source_type` - (Optional, Default: all events) Type of source for events. Valid values: `replication-instance` or `replication-task`\n* `source_ids` - (Required) Ids of sources to listen to.\n* `sns_topic_arn` - (Required) SNS topic arn to send events on.\n* `tags` - (Optional) Map of resource tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the DMS Event Subscription.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dms_event_subscription` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10m`) Used for creating event subscriptions.\n- `update` - (Default `10m`) Used for event subscription modifications.\n- `delete` - (Default `10m`) Used for destroying event descriptions.\n\n## Import\n\nEvent subscriptions can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_dms_event_subscription.test my-awesome-event-subscription\n```\n",
    "basename": "dms_event_subscription.html"
  },
  "dms_replication_instance.html": {
    "subcategory": "Database Migration Service (DMS)",
    "layout": "aws",
    "page_title": "AWS: aws_dms_replication_instance",
    "description": "Provides a DMS (Data Migration Service) replication instance resource.",
    "preview": "# Resource: aws_dms_replication_instance\n\nProvides a DMS (Data …",
    "content": "\n\n# Resource: aws_dms_replication_instance\n\nProvides a DMS (Data Migration Service) replication instance resource. DMS replication instances can be created, updated, deleted, and imported.\n\n## Example Usage\nCreate required roles and then create a DMS instance, setting the depends_on to the required role policy attachments.\n\n```terraform\n# Database Migration Service requires the below IAM Roles to be created before\n# replication instances can be created. See the DMS Documentation for\n# additional information: https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Security.html#CHAP_Security.APIRole\n#  * dms-vpc-role\n#  * dms-cloudwatch-logs-role\n#  * dms-access-for-endpoint\n\ndata \"aws_iam_policy_document\" \"dms_assume_role\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      identifiers = [\"dms.amazonaws.com\"]\n      type        = \"Service\"\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"dms-access-for-endpoint\" {\n  assume_role_policy = data.aws_iam_policy_document.dms_assume_role.json\n  name               = \"dms-access-for-endpoint\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"dms-access-for-endpoint-AmazonDMSRedshiftS3Role\" {\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonDMSRedshiftS3Role\"\n  role       = aws_iam_role.dms-access-for-endpoint.name\n}\n\nresource \"aws_iam_role\" \"dms-cloudwatch-logs-role\" {\n  assume_role_policy = data.aws_iam_policy_document.dms_assume_role.json\n  name               = \"dms-cloudwatch-logs-role\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"dms-cloudwatch-logs-role-AmazonDMSCloudWatchLogsRole\" {\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonDMSCloudWatchLogsRole\"\n  role       = aws_iam_role.dms-cloudwatch-logs-role.name\n}\n\nresource \"aws_iam_role\" \"dms-vpc-role\" {\n  assume_role_policy = data.aws_iam_policy_document.dms_assume_role.json\n  name               = \"dms-vpc-role\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"dms-vpc-role-AmazonDMSVPCManagementRole\" {\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonDMSVPCManagementRole\"\n  role       = aws_iam_role.dms-vpc-role.name\n}\n\n# Create a new replication instance\nresource \"aws_dms_replication_instance\" \"test\" {\n  allocated_storage            = 20\n  apply_immediately            = true\n  auto_minor_version_upgrade   = true\n  availability_zone            = \"us-west-2c\"\n  engine_version               = \"3.1.4\"\n  kms_key_arn                  = \"arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012\"\n  multi_az                     = false\n  preferred_maintenance_window = \"sun:10:30-sun:14:30\"\n  publicly_accessible          = true\n  replication_instance_class   = \"dms.t2.micro\"\n  replication_instance_id      = \"test-dms-replication-instance-tf\"\n  replication_subnet_group_id  = aws_dms_replication_subnet_group.test-dms-replication-subnet-group-tf.id\n\n  tags = {\n    Name = \"test\"\n  }\n\n  vpc_security_group_ids = [\n    \"sg-12345678\",\n  ]\n\n  depends_on = [\n    aws_iam_role_policy_attachment.dms-access-for-endpoint-AmazonDMSRedshiftS3Role,\n    aws_iam_role_policy_attachment.dms-cloudwatch-logs-role-AmazonDMSCloudWatchLogsRole,\n    aws_iam_role_policy_attachment.dms-vpc-role-AmazonDMSVPCManagementRole\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `allocated_storage` - (Optional, Default: 50, Min: 5, Max: 6144) The amount of storage (in gigabytes) to be initially allocated for the replication instance.\n* `allow_major_version_upgrade` - (Optional, Default: false) Indicates that major version upgrades are allowed.\n* `apply_immediately` - (Optional, Default: false) Indicates whether the changes should be applied immediately or during the next maintenance window. Only used when updating an existing resource.\n* `auto_minor_version_upgrade` - (Optional, Default: false) Indicates that minor engine upgrades will be applied automatically to the replication instance during the maintenance window.\n* `availability_zone` - (Optional) The EC2 Availability Zone that the replication instance will be created in.\n* `engine_version` - (Optional) The engine version number of the replication instance.\n* `kms_key_arn` - (Optional) The Amazon Resource Name (ARN) for the KMS key that will be used to encrypt the connection parameters. If you do not specify a value for `kms_key_arn`, then AWS DMS will use your default encryption key. AWS KMS creates the default encryption key for your AWS account. Your AWS account has a different default encryption key for each AWS region.\n* `multi_az` - (Optional) Specifies if the replication instance is a multi-az deployment. You cannot set the `availability_zone` parameter if the `multi_az` parameter is set to `true`.\n* `preferred_maintenance_window` - (Optional) The weekly time range during which system maintenance can occur, in Universal Coordinated Time (UTC).\n\n    - Default: A 30-minute window selected at random from an 8-hour block of time per region, occurring on a random day of the week.\n    - Format: `ddd:hh24:mi-ddd:hh24:mi`\n    - Valid Days: `mon, tue, wed, thu, fri, sat, sun`\n    - Constraints: Minimum 30-minute window.\n\n* `publicly_accessible` - (Optional, Default: false) Specifies the accessibility options for the replication instance. A value of true represents an instance with a public IP address. A value of false represents an instance with a private IP address.\n* `replication_instance_class` - (Required) The compute and memory capacity of the replication instance as specified by the replication instance class. Can be one of `dms.t2.micro | dms.t2.small | dms.t2.medium | dms.t2.large | dms.c4.large | dms.c4.xlarge | dms.c4.2xlarge | dms.c4.4xlarge`\n* `replication_instance_id` - (Required) The replication instance identifier. This parameter is stored as a lowercase string.\n\n    - Must contain from 1 to 63 alphanumeric characters or hyphens.\n    - First character must be a letter.\n    - Cannot end with a hyphen\n    - Cannot contain two consecutive hyphens.\n\n* `replication_subnet_group_id` - (Optional) A subnet group to associate with the replication instance.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_security_group_ids` - (Optional) A list of VPC security group IDs to be used with the replication instance. The VPC security groups must work with the VPC containing the replication instance.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `replication_instance_arn` - The Amazon Resource Name (ARN) of the replication instance.\n* `replication_instance_private_ips` -  A list of the private IP addresses of the replication instance.\n* `replication_instance_public_ips` - A list of the public IP addresses of the replication instance.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dms_replication_instance` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `30 minutes`) Used for Creating Instances\n- `update` - (Default `30 minutes`) Used for Database modifications\n- `delete` - (Default `30 minutes`) Used for destroying databases.\n\n## Import\n\nReplication instances can be imported using the `replication_instance_id`, e.g.,\n\n```\n$ terraform import aws_dms_replication_instance.test test-dms-replication-instance-tf\n```\n",
    "basename": "dms_replication_instance.html"
  },
  "dms_replication_subnet_group.html": {
    "subcategory": "Database Migration Service (DMS)",
    "layout": "aws",
    "page_title": "AWS: aws_dms_replication_subnet_group",
    "description": "Provides a DMS (Data Migration Service) subnet group resource.",
    "preview": "# Resource: aws_dms_replication_subnet_group\n\nProvides a DMS (Data …",
    "content": "\n\n# Resource: aws_dms_replication_subnet_group\n\nProvides a DMS (Data Migration Service) replication subnet group resource. DMS replication subnet groups can be created, updated, deleted, and imported.\n\n## Example Usage\n\n```terraform\n# Create a new replication subnet group\nresource \"aws_dms_replication_subnet_group\" \"test\" {\n  replication_subnet_group_description = \"Test replication subnet group\"\n  replication_subnet_group_id          = \"test-dms-replication-subnet-group-tf\"\n\n  subnet_ids = [\n    \"subnet-12345678\",\n  ]\n\n  tags = {\n    Name = \"test\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `replication_subnet_group_description` - (Required) The description for the subnet group.\n* `replication_subnet_group_id` - (Required) The name for the replication subnet group. This value is stored as a lowercase string.\n\n    - Must contain no more than 255 alphanumeric characters, periods, spaces, underscores, or hyphens.\n    - Must not be \"default\".\n\n* `subnet_ids` - (Required) A list of the EC2 subnet IDs for the subnet group.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` - The ID of the VPC the subnet group is in.\n\n## Import\n\nReplication subnet groups can be imported using the `replication_subnet_group_id`, e.g.,\n\n```\n$ terraform import aws_dms_replication_subnet_group.test test-dms-replication-subnet-group-tf\n```\n",
    "basename": "dms_replication_subnet_group.html"
  },
  "dms_replication_task.html": {
    "subcategory": "Database Migration Service (DMS)",
    "layout": "aws",
    "page_title": "AWS: aws_dms_replication_task",
    "description": "Provides a DMS (Data Migration Service) replication task resource.",
    "preview": "# Resource: aws_dms_replication_task\n\nProvides a DMS (Data Migration …",
    "content": "\n\n# Resource: aws_dms_replication_task\n\nProvides a DMS (Data Migration Service) replication task resource. DMS replication tasks can be created, updated, deleted, and imported.\n\n## Example Usage\n\n```terraform\n# Create a new replication task\nresource \"aws_dms_replication_task\" \"test\" {\n  cdc_start_time            = 1484346880\n  migration_type            = \"full-load\"\n  replication_instance_arn  = aws_dms_replication_instance.test-dms-replication-instance-tf.replication_instance_arn\n  replication_task_id       = \"test-dms-replication-task-tf\"\n  replication_task_settings = \"...\"\n  source_endpoint_arn       = aws_dms_endpoint.test-dms-source-endpoint-tf.endpoint_arn\n  table_mappings            = \"{\\\"rules\\\":[{\\\"rule-type\\\":\\\"selection\\\",\\\"rule-id\\\":\\\"1\\\",\\\"rule-name\\\":\\\"1\\\",\\\"object-locator\\\":{\\\"schema-name\\\":\\\"%\\\",\\\"table-name\\\":\\\"%\\\"},\\\"rule-action\\\":\\\"include\\\"}]}\"\n\n  tags = {\n    Name = \"test\"\n  }\n\n  target_endpoint_arn = aws_dms_endpoint.test-dms-target-endpoint-tf.endpoint_arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cdc_start_position` - (Optional, Conflicts with `cdc_start_time`) Indicates when you want a change data capture (CDC) operation to start. The value can be in date, checkpoint, or LSN/SCN format depending on the source engine. For more information, see [Determining a CDC native start point](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Task.CDC.html#CHAP_Task.CDC.StartPoint.Native).\n* `cdc_start_time` - (Optional, Conflicts with `cdc_start_position`) The Unix timestamp integer for the start of the Change Data Capture (CDC) operation.\n* `migration_type` - (Required) The migration type. Can be one of `full-load | cdc | full-load-and-cdc`.\n* `replication_instance_arn` - (Required) The Amazon Resource Name (ARN) of the replication instance.\n* `replication_task_id` - (Required) The replication task identifier.\n\n    - Must contain from 1 to 255 alphanumeric characters or hyphens.\n    - First character must be a letter.\n    - Cannot end with a hyphen.\n    - Cannot contain two consecutive hyphens.\n\n* `replication_task_settings` - (Optional) An escaped JSON string that contains the task settings. For a complete list of task settings, see [Task Settings for AWS Database Migration Service Tasks](http://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.CustomizingTasks.TaskSettings.html).\n* `source_endpoint_arn` - (Required) The Amazon Resource Name (ARN) string that uniquely identifies the source endpoint.\n* `table_mappings` - (Required) An escaped JSON string that contains the table mappings. For information on table mapping see [Using Table Mapping with an AWS Database Migration Service Task to Select and Filter Data](http://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.CustomizingTasks.TableMapping.html)\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `target_endpoint_arn` - (Required) The Amazon Resource Name (ARN) string that uniquely identifies the target endpoint.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `replication_task_arn` - The Amazon Resource Name (ARN) for the replication task.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nReplication tasks can be imported using the `replication_task_id`, e.g.,\n\n```\n$ terraform import aws_dms_replication_task.test test-dms-replication-task-tf\n```\n",
    "basename": "dms_replication_task.html"
  },
  "docdb_cluster.html": {
    "subcategory": "DocumentDB",
    "layout": "aws",
    "page_title": "AWS: aws_docdb",
    "description": "Manages a DocDB Aurora Cluster",
    "preview": "# Resource: aws_docdb_cluster\n\nManages a DocDB Cluster.\n\nChanges to …",
    "content": "\n\n# Resource: aws_docdb_cluster\n\nManages a DocDB Cluster.\n\nChanges to a DocDB Cluster can occur when you manually change a\nparameter, such as `port`, and are reflected in the next maintenance\nwindow. Because of this, Terraform may report a difference in its planning\nphase because a modification has not yet taken place. You can use the\n`apply_immediately` flag to instruct the service to apply the change immediately\n(see documentation below).\n\n~> **Note:** using `apply_immediately` can result in a brief downtime as the server reboots.\n~> **Note:** All arguments including the username and password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_docdb_cluster\" \"docdb\" {\n  cluster_identifier      = \"my-docdb-cluster\"\n  engine                  = \"docdb\"\n  master_username         = \"foo\"\n  master_password         = \"mustbeeightchars\"\n  backup_retention_period = 5\n  preferred_backup_window = \"07:00-09:00\"\n  skip_final_snapshot     = true\n}\n```\n\n## Argument Reference\n\nFor more detailed documentation about each argument, refer to\nthe [AWS official documentation](https://docs.aws.amazon.com/cli/latest/reference/docdb/create-db-cluster.html).\n\nThe following arguments are supported:\n\n* `apply_immediately` - (Optional) Specifies whether any cluster modifications\n     are applied immediately, or during the next maintenance window. Default is\n     `false`.\n* `availability_zones` - (Optional) A list of EC2 Availability Zones that\n  instances in the DB cluster can be created in.\n* `backup_retention_period` - (Optional) The days to retain backups for. Default `1`\n* `cluster_identifier_prefix` - (Optional, Forces new resource) Creates a unique cluster identifier beginning with the specified prefix. Conflicts with `cluster_identifier`.\n* `cluster_identifier` - (Optional, Forces new resources) The cluster identifier. If omitted, Terraform will assign a random, unique identifier.\n* `db_subnet_group_name` - (Optional) A DB subnet group to associate with this DB instance.\n* `db_cluster_parameter_group_name` - (Optional) A cluster parameter group to associate with the cluster.\n* `deletion_protection` - (Optional) A value that indicates whether the DB cluster has deletion protection enabled. The database can't be deleted when deletion protection is enabled. By default, deletion protection is disabled.\n* `enabled_cloudwatch_logs_exports` - (Optional) List of log types to export to cloudwatch. If omitted, no logs will be exported.\n   The following log types are supported: `audit`, `profiler`.\n* `engine_version` - (Optional) The database engine version. Updating this argument results in an outage.\n* `engine` - (Optional) The name of the database engine to be used for this DB cluster. Defaults to `docdb`. Valid Values: `docdb`\n* `final_snapshot_identifier` - (Optional) The name of your final DB snapshot\n    when this DB cluster is deleted. If omitted, no final snapshot will be\n    made.\n* `global_cluster_identifier` - (Optional) The global cluster identifier specified on [`aws_docdb_global_cluster`](/docs/providers/aws/r/docdb_global_cluster.html).\n* `kms_key_id` - (Optional) The ARN for the KMS encryption key. When specifying `kms_key_id`, `storage_encrypted` needs to be set to true.\n* `master_password` - (Required unless a `snapshot_identifier` or unless a `global_cluster_identifier` is provided when the cluster is the \"secondary\" cluster of a global database) Password for the master DB user. Note that this may\n    show up in logs, and it will be stored in the state file. Please refer to the DocDB Naming Constraints.\n* `master_username` - (Required unless a `snapshot_identifier` or unless a `global_cluster_identifier` is provided when the cluster is the \"secondary\" cluster of a global database) Username for the master DB user.\n* `port` - (Optional) The port on which the DB accepts connections\n* `preferred_backup_window` - (Optional) The daily time range during which automated backups are created if automated backups are enabled using the BackupRetentionPeriod parameter.Time in UTC\nDefault: A 30-minute window selected at random from an 8-hour block of time per regionE.g., 04:00-09:00\n* `preferred_maintenance_window` - (Optional) The weekly time range during which system maintenance can occur, in (UTC) e.g., wed:04:00-wed:04:30\n* `skip_final_snapshot` - (Optional) Determines whether a final DB snapshot is created before the DB cluster is deleted. If true is specified, no DB snapshot is created. If false is specified, a DB snapshot is created before the DB cluster is deleted, using the value from `final_snapshot_identifier`. Default is `false`.\n* `snapshot_identifier` - (Optional) Specifies whether or not to create this cluster from a snapshot. You can use either the name or ARN when specifying a DB cluster snapshot, or the ARN when specifying a DB snapshot.\n* `storage_encrypted` - (Optional) Specifies whether the DB cluster is encrypted. The default is `false`.\n* `tags` - (Optional) A map of tags to assign to the DB cluster. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_security_group_ids` - (Optional) List of VPC security groups to associate\n  with the Cluster\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of cluster\n* `cluster_members` – List of DocDB Instances that are a part of this cluster\n* `cluster_resource_id` - The DocDB Cluster Resource ID\n* `endpoint` - The DNS address of the DocDB instance\n* `hosted_zone_id` - The Route53 Hosted Zone ID of the endpoint\n* `id` - The DocDB Cluster Identifier\n* `reader_endpoint` - A read-only endpoint for the DocDB cluster, automatically load-balanced across replicas\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_docdb_cluster` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `120 minutes`) Used for Cluster creation\n- `update` - (Default `120 minutes`) Used for Cluster modifications\n- `delete` - (Default `120 minutes`) Used for destroying cluster. This includes\nany cleanup task during the destroying process.\n\n## Import\n\nDocDB Clusters can be imported using the `cluster_identifier`, e.g.,\n\n```\n$ terraform import aws_docdb_cluster.docdb_cluster docdb-prod-cluster\n```\n",
    "basename": "docdb_cluster.html"
  },
  "docdb_cluster_instance.html": {
    "subcategory": "DocumentDB",
    "layout": "aws",
    "page_title": "AWS: aws_docdb_cluster_instance",
    "description": "Provides an DocDB Cluster Resource Instance",
    "preview": "# Resource: aws_docdb_cluster_instance\n\nProvides an DocDB Cluster …",
    "content": "\n\n# Resource: aws_docdb_cluster_instance\n\nProvides an DocDB Cluster Resource Instance. A Cluster Instance Resource defines\nattributes that are specific to a single instance in a [DocDB Cluster][1].\n\nYou do not designate a primary and subsequent replicas. Instead, you simply add DocDB\nInstances and DocDB manages the replication. You can use the [count][3]\nmeta-parameter to make multiple instances and join them all to the same DocDB\nCluster, or you may specify different Cluster Instance resources with various\n`instance_class` sizes.\n\n## Example Usage\n\n```terraform\nresource \"aws_docdb_cluster_instance\" \"cluster_instances\" {\n  count              = 2\n  identifier         = \"docdb-cluster-demo-${count.index}\"\n  cluster_identifier = aws_docdb_cluster.default.id\n  instance_class     = \"db.r5.large\"\n}\n\nresource \"aws_docdb_cluster\" \"default\" {\n  cluster_identifier = \"docdb-cluster-demo\"\n  availability_zones = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n  master_username    = \"foo\"\n  master_password    = \"barbut8chars\"\n}\n```\n\n## Argument Reference\n\nFor more detailed documentation about each argument, refer to\nthe [AWS official documentation](https://docs.aws.amazon.com/cli/latest/reference/docdb/create-db-instance.html).\n\nThe following arguments are supported:\n\n* `apply_immediately` - (Optional) Specifies whether any database modifications\n     are applied immediately, or during the next maintenance window. Default is`false`.\n* `auto_minor_version_upgrade` - (Optional) Indicates that minor engine upgrades will be applied automatically to the DB instance during the maintenance window. Default `true`.\n* `availability_zone` - (Optional, Computed) The EC2 Availability Zone that the DB instance is created in. See [docs](https://docs.aws.amazon.com/documentdb/latest/developerguide/API_CreateDBInstance.html) about the details.\n* `cluster_identifier` - (Required) The identifier of the [`aws_docdb_cluster`](/docs/providers/aws/r/docdb_cluster.html) in which to launch this instance.\n* `engine` - (Optional) The name of the database engine to be used for the DocDB instance. Defaults to `docdb`. Valid Values: `docdb`.\n* `identifier` - (Optional, Forces new resource) The identifier for the DocDB instance, if omitted, Terraform will assign a random, unique identifier.\n* `identifier_prefix` - (Optional, Forces new resource) Creates a unique identifier beginning with the specified prefix. Conflicts with `identifier`.\n* `instance_class` - (Required) The instance class to use. For details on CPU and memory, see [Scaling for DocDB Instances][2]. DocDB currently\n  supports the below instance classes. Please see [AWS Documentation][4] for complete details.\n    - db.r5.large\n    - db.r5.xlarge\n    - db.r5.2xlarge\n    - db.r5.4xlarge\n    - db.r5.12xlarge\n    - db.r5.24xlarge\n    - db.r4.large\n    - db.r4.xlarge\n    - db.r4.2xlarge\n    - db.r4.4xlarge\n    - db.r4.8xlarge\n    - db.r4.16xlarge\n    - db.t3.medium\n* `preferred_maintenance_window` - (Optional) The window to perform maintenance in.\n  Syntax: \"ddd:hh24:mi-ddd:hh24:mi\". Eg: \"Mon:00:00-Mon:03:00\".\n* `promotion_tier` - (Optional) Default 0. Failover Priority setting on instance level. The reader who has lower tier has higher priority to get promoter to writer.\n* `tags` - (Optional) A map of tags to assign to the instance. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of cluster instance\n* `db_subnet_group_name` - The DB subnet group to associate with this DB instance.\n* `dbi_resource_id` - The region-unique, immutable identifier for the DB instance.\n* `endpoint` - The DNS address for this instance. May not be writable\n* `engine_version` - The database engine version\n* `kms_key_id` - The ARN for the KMS encryption key if one is set to the cluster.\n* `port` - The database port\n* `preferred_backup_window` - The daily time range during which automated backups are created if automated backups are enabled.\n* `storage_encrypted` - Specifies whether the DB cluster is encrypted.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `writer` – Boolean indicating if this instance is writable. `False` indicates this instance is a read replica.\n* `ca_cert_identifier` - (Optional) The identifier of the CA certificate for the DB instance.\n\n[1]: /docs/providers/aws/r/docdb_cluster.html\n[2]: https://docs.aws.amazon.com/documentdb/latest/developerguide/db-cluster-manage-performance.html#db-cluster-manage-scaling-instance\n[3]: https://www.terraform.io/docs/configuration/meta-arguments/count.html\n[4]: https://docs.aws.amazon.com/documentdb/latest/developerguide/db-instance-classes.html#db-instance-class-specs\n\n## Timeouts\n\n`aws_docdb_cluster_instance` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `90 minutes`) Used for Creating Instances, Replicas, and\nrestoring from Snapshots\n- `update` - (Default `90 minutes`) Used for Database modifications\n- `delete` - (Default `90 minutes`) Used for destroying databases. This includes\nthe time required to take snapshots\n\n## Import\n\nDocDB Cluster Instances can be imported using the `identifier`, e.g.,\n\n```\n$ terraform import aws_docdb_cluster_instance.prod_instance_1 aurora-cluster-instance-1\n```\n",
    "basename": "docdb_cluster_instance.html"
  },
  "docdb_cluster_parameter_group.html": {
    "subcategory": "DocumentDB",
    "layout": "aws",
    "page_title": "AWS: aws_docdb_cluster_parameter_group",
    "description": "Manages a DocumentDB Cluster Parameter Group",
    "preview": "# Resource: aws_docdb_cluster_parameter_group\n\nManages a DocumentDB …",
    "content": "\n\n# Resource: aws_docdb_cluster_parameter_group\n\nManages a DocumentDB Cluster Parameter Group\n\n## Example Usage\n\n```terraform\nresource \"aws_docdb_cluster_parameter_group\" \"example\" {\n  family      = \"docdb3.6\"\n  name        = \"example\"\n  description = \"docdb cluster parameter group\"\n\n  parameter {\n    name  = \"tls\"\n    value = \"enabled\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the documentDB cluster parameter group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `family` - (Required, Forces new resource) The family of the documentDB cluster parameter group.\n* `description` - (Optional, Forces new resource) The description of the documentDB cluster parameter group. Defaults to \"Managed by Terraform\".\n* `parameter` - (Optional) A list of documentDB parameters to apply. Setting parameters to system default values may show a difference on imported resources.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nParameter blocks support the following:\n\n~> **NOTE:** These arguments take a `string` representation of their values.\n\n* `name` - (Required) The name of the documentDB parameter.\n* `value` - (Required) The value of the documentDB parameter.\n* `apply_method` - (Optional) Valid values are `immediate` and `pending-reboot`. Defaults to `pending-reboot`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The documentDB cluster parameter group name.\n* `arn` - The ARN of the documentDB cluster parameter group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDocumentDB Cluster Parameter Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_docdb_cluster_parameter_group.cluster_pg production-pg-1\n```\n",
    "basename": "docdb_cluster_parameter_group.html"
  },
  "docdb_cluster_snapshot.html": {
    "subcategory": "DocumentDB",
    "layout": "aws",
    "page_title": "AWS: aws_docdb_cluster_snapshot",
    "description": "Manages a DocDB database cluster snapshot.",
    "preview": "# Resource: aws_docdb_cluster_snapshot\n\nManages a DocDB database …",
    "content": "\n\n# Resource: aws_docdb_cluster_snapshot\n\nManages a DocDB database cluster snapshot for DocDB clusters.\n\n## Example Usage\n\n```terraform\nresource \"aws_docdb_cluster_snapshot\" \"example\" {\n  db_cluster_identifier          = aws_docdb_cluster.example.id\n  db_cluster_snapshot_identifier = \"resourcetestsnapshot1234\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_cluster_identifier` - (Required) The DocDB Cluster Identifier from which to take the snapshot.\n* `db_cluster_snapshot_identifier` - (Required) The Identifier for the snapshot.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `availability_zones` - List of EC2 Availability Zones that instances in the DocDB cluster snapshot can be restored in.\n* `db_cluster_snapshot_arn` - The Amazon Resource Name (ARN) for the DocDB Cluster Snapshot.\n* `engine` - Specifies the name of the database engine.\n* `engine_version` - Version of the database engine for this DocDB cluster snapshot.\n* `kms_key_id` - If storage_encrypted is true, the AWS KMS key identifier for the encrypted DocDB cluster snapshot.\n* `port` - Port that the DocDB cluster was listening on at the time of the snapshot.\n* `source_db_cluster_snapshot_identifier` - The DocDB Cluster Snapshot Arn that the DocDB Cluster Snapshot was copied from. It only has value in case of cross customer or cross region copy.\n* `storage_encrypted` - Specifies whether the DocDB cluster snapshot is encrypted.\n* `status` - The status of this DocDB Cluster Snapshot.\n* `vpc_id` - The VPC ID associated with the DocDB cluster snapshot.\n\n## Timeouts\n\n`aws_docdb_cluster_snapshot` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `20m`) How long to wait for the snapshot to be available.\n\n## Import\n\n`aws_docdb_cluster_snapshot` can be imported by using the cluster snapshot identifier, e.g.,\n\n```\n$ terraform import aws_docdb_cluster_snapshot.example my-cluster-snapshot\n```\n",
    "basename": "docdb_cluster_snapshot.html"
  },
  "docdb_global_cluster.html": {
    "subcategory": "DocumentDB",
    "layout": "aws",
    "page_title": "AWS: aws_docdb",
    "description": "Manages a DocDB Global Cluster",
    "preview": "# Resource: aws_docdb_global_cluster\n\nManages an DocumentDB Global …",
    "content": "\n\n# Resource: aws_docdb_global_cluster\n\nManages an DocumentDB Global Cluster. A global cluster consists of one primary region and up to five read-only secondary regions. You issue write operations directly to the primary cluster in the primary region and Amazon DocumentDB automatically replicates the data to the secondary regions using dedicated infrastructure.\n\nMore information about DocumentDB Global Clusters can be found in the [DocumentDB Developer Guide](https://docs.aws.amazon.com/documentdb/latest/developerguide/global-clusters.html).\n\n## Example Usage\n\n### New DocumentDB Global Cluster\n\n```terraform\nprovider \"aws\" {\n  alias  = \"primary\"\n  region = \"us-east-2\"\n}\n\nprovider \"aws\" {\n  alias  = \"secondary\"\n  region = \"us-east-1\"\n}\n\nresource \"aws_docdb_global_cluster\" \"example\" {\n  global_cluster_identifier = \"global-test\"\n  engine                    = \"docdb\"\n  engine_version            = \"4.0.0\"\n}\n\nresource \"aws_docdb_cluster\" \"primary\" {\n  provider                  = aws.primary\n  engine                    = aws_docdb_global_cluster.example.engine\n  engine_version            = aws_docdb_global_cluster.example.engine_version\n  cluster_identifier        = \"test-primary-cluster\"\n  master_username           = \"username\"\n  master_password           = \"somepass123\"\n  global_cluster_identifier = aws_docdb_global_cluster.example.id\n  db_subnet_group_name      = \"default\"\n}\n\nresource \"aws_docdb_cluster_instance\" \"primary\" {\n  provider             = aws.primary\n  engine               = aws_docdb_global_cluster.example.engine\n  engine_version       = aws_docdb_global_cluster.example.engine_version\n  identifier           = \"test-primary-cluster-instance\"\n  cluster_identifier   = aws_docdb_cluster.primary.id\n  instance_class       = \"db.r5.large\"\n  db_subnet_group_name = \"default\"\n}\n\nresource \"aws_docdb_cluster\" \"secondary\" {\n  provider                  = aws.secondary\n  engine                    = aws_docdb_global_cluster.example.engine\n  engine_version            = aws_docdb_global_cluster.example.engine_version\n  cluster_identifier        = \"test-secondary-cluster\"\n  global_cluster_identifier = aws_docdb_global_cluster.example.id\n  db_subnet_group_name      = \"default\"\n}\n\nresource \"aws_docdb_cluster_instance\" \"secondary\" {\n  provider             = aws.secondary\n  engine               = aws_docdb_global_cluster.example.engine\n  engine_version       = aws_docdb_global_cluster.example.engine_version\n  identifier           = \"test-secondary-cluster-instance\"\n  cluster_identifier   = aws_docdb_cluster.secondary.id\n  instance_class       = \"db.r5.large\"\n  db_subnet_group_name = \"default\"\n\n  depends_on = [\n    aws_docdb_cluster_instance.primary\n  ]\n}\n```\n\n### New Global Cluster From Existing DB Cluster\n\n```terraform\nresource \"aws_docdb_cluster\" \"example\" {\n  # ... other configuration ...\n\n  # NOTE: Using this DB Cluster to create a Global Cluster, the\n  # global_cluster_identifier attribute will become populated and\n  # Terraform will begin showing it as a difference. Do not configure:\n  # global_cluster_identifier = aws_docdb_global_cluster.example.id\n  # as it creates a circular reference. Use ignore_changes instead.\n  lifecycle {\n    ignore_changes = [global_cluster_identifier]\n  }\n}\n\nresource \"aws_docdb_global_cluster\" \"example\" {\n  global_cluster_identifier    = \"example\"\n  source_db_cluster_identifier = aws_docdb_cluster.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `global_cluster_identifier` - (Required, Forces new resources) The global cluster identifier.\n* `database_name` - (Optional, Forces new resources) Name for an automatically created database on cluster creation.\n* `deletion_protection` - (Optional) If the Global Cluster should have deletion protection enabled. The database can't be deleted when this value is set to `true`. The default is `false`.\n* `engine` - (Optional, Forces new resources) Name of the database engine to be used for this DB cluster. Terraform will only perform drift detection if a configuration value is provided. Current Valid values: `docdb`. Defaults to `docdb`. Conflicts with `source_db_cluster_identifier`.\n* `engine_version` - (Optional) Engine version of the global database. Upgrading the engine version will result in all cluster members being immediately updated and will.\n    * **NOTE:** Upgrading major versions is not supported.\n* `source_db_cluster_identifier` - (Optional) Amazon Resource Name (ARN) to use as the primary DB Cluster of the Global Cluster on creation. Terraform cannot perform drift detection of this value.\n* `storage_encrypted` - (Optional, Forces new resources) Specifies whether the DB cluster is encrypted. The default is `false` unless `source_db_cluster_identifier` is specified and encrypted. Terraform will only perform drift detection if a configuration value is provided.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 5 mins) Used when creating the Global Cluster\n* `update` - (Defaults to 5 mins) Used when updating the Global Cluster members (time is per member)\n* `delete` - (Defaults to 5 mins) Used when deleting the Global Cluster members (time is per member)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Global Cluster Amazon Resource Name (ARN)\n* `global_cluster_members` - Set of objects containing Global Cluster members.\n    * `db_cluster_arn` - Amazon Resource Name (ARN) of member DB Cluster.\n    * `is_writer` - Whether the member is the primary DB Cluster.\n* `global_cluster_resource_id` - AWS Region-unique, immutable identifier for the global database cluster. This identifier is found in AWS CloudTrail log entries whenever the AWS KMS key for the DB cluster is accessed.\n* `id` - DocDB Global Cluster.\n\n## Import\n\n`aws_docdb_global_cluster` can be imported by using the Global Cluster identifier, e.g.\n\n```\n$ terraform import aws_docdb_global_cluster.example example\n```\n\nCertain resource arguments, like `source_db_cluster_identifier`, do not have an API method for reading the information after creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.\n\n```terraform\nresource \"aws_docdb_global_cluster\" \"example\" {\n  # ... other configuration ...\n\n  # There is no API for reading source_db_cluster_identifier\n  lifecycle {\n    ignore_changes = [source_db_cluster_identifier]\n  }\n}\n```\n",
    "basename": "docdb_global_cluster.html"
  },
  "docdb_subnet_group.html": {
    "subcategory": "DocumentDB",
    "layout": "aws",
    "page_title": "AWS: aws_docdb_subnet_group",
    "description": "Provides an DocumentDB subnet group resource.",
    "preview": "# Resource: aws_docdb_subnet_group\n\nProvides an DocumentDB subnet …",
    "content": "\n\n# Resource: aws_docdb_subnet_group\n\nProvides an DocumentDB subnet group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_docdb_subnet_group\" \"default\" {\n  name       = \"main\"\n  subnet_ids = [aws_subnet.frontend.id, aws_subnet.backend.id]\n\n  tags = {\n    Name = \"My docdb subnet group\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the docDB subnet group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` - (Optional) The description of the docDB subnet group. Defaults to \"Managed by Terraform\".\n* `subnet_ids` - (Required) A list of VPC subnet IDs.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The docDB subnet group name.\n* `arn` - The ARN of the docDB subnet group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDocumentDB Subnet groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_docdb_subnet_group.default production-subnet-group\n```\n",
    "basename": "docdb_subnet_group.html"
  },
  "dx_bgp_peer.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_bgp_peer",
    "description": "Provides a Direct Connect BGP peer resource.",
    "preview": "# Resource: aws_dx_bgp_peer\n\nProvides a Direct Connect BGP peer …",
    "content": "\n\n# Resource: aws_dx_bgp_peer\n\nProvides a Direct Connect BGP peer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_bgp_peer\" \"peer\" {\n  virtual_interface_id = aws_dx_private_virtual_interface.foo.id\n  address_family       = \"ipv6\"\n  bgp_asn              = 65351\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required) The address family for the BGP peer. `ipv4 ` or `ipv6`.\n* `bgp_asn` - (Required) The autonomous system (AS) number for Border Gateway Protocol (BGP) configuration.\n* `virtual_interface_id` - (Required) The ID of the Direct Connect virtual interface on which to create the BGP peer.\n* `amazon_address` - (Optional) The IPv4 CIDR address to use to send traffic to Amazon.\nRequired for IPv4 BGP peers on public virtual interfaces.\n* `bgp_auth_key` - (Optional) The authentication key for BGP configuration.\n* `customer_address` - (Optional) The IPv4 CIDR destination address to which Amazon should send traffic.\nRequired for IPv4 BGP peers on public virtual interfaces.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the BGP peer resource.\n* `bgp_status` - The Up/Down state of the BGP peer.\n* `bgp_peer_id` - The ID of the BGP peer.\n* `aws_device` - The Direct Connect endpoint on which the BGP peer terminates.\n\n## Timeouts\n\n`aws_dx_bgp_peer` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating BGP peer\n- `delete` - (Default `10 minutes`) Used for destroying BGP peer\n",
    "basename": "dx_bgp_peer.html"
  },
  "dx_connection.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_connection",
    "description": "Provides a Connection of Direct Connect.",
    "preview": "# Resource: aws_dx_connection\n\nProvides a Connection of Direct …",
    "content": "\n\n# Resource: aws_dx_connection\n\nProvides a Connection of Direct Connect.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_connection\" \"hoge\" {\n  name      = \"tf-dx-connection\"\n  bandwidth = \"1Gbps\"\n  location  = \"EqDC2\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bandwidth` - (Required) The bandwidth of the connection. Valid values for dedicated connections: 1Gbps, 10Gbps. Valid values for hosted connections: 50Mbps, 100Mbps, 200Mbps, 300Mbps, 400Mbps, 500Mbps, 1Gbps, 2Gbps, 5Gbps, 10Gbps and 100Gbps. Case sensitive.\n* `location` - (Required) The AWS Direct Connect location where the connection is located. See [DescribeLocations](https://docs.aws.amazon.com/directconnect/latest/APIReference/API_DescribeLocations.html) for the list of AWS Direct Connect locations. Use `locationCode`.\n* `name` - (Required) The name of the connection.\n* `provider_name` - (Optional) The name of the service provider associated with the connection.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the connection.\n* `aws_device` - The Direct Connect endpoint on which the physical connection terminates.\n* `has_logical_redundancy` - Indicates whether the connection supports a secondary BGP peer in the same address family (IPv4/IPv6).\n* `id` - The ID of the connection.\n* `jumbo_frame_capable` - Boolean value representing if jumbo frames have been enabled for this connection.\n* `owner_account_id` - The ID of the AWS account that owns the connection.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDirect Connect connections can be imported using the `connection id`, e.g.,\n\n```\n$ terraform import aws_dx_connection.test_connection dxcon-ffre0ec3\n```\n",
    "basename": "dx_connection.html"
  },
  "dx_connection_association.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_connection_association",
    "description": "Associates a Direct Connect Connection with a LAG.",
    "preview": "# Resource: aws_dx_connection_association\n\nAssociates a Direct …",
    "content": "\n\n# Resource: aws_dx_connection_association\n\nAssociates a Direct Connect Connection with a LAG.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_connection\" \"example\" {\n  name      = \"example\"\n  bandwidth = \"1Gbps\"\n  location  = \"EqSe2-EQ\"\n}\n\nresource \"aws_dx_lag\" \"example\" {\n  name                  = \"example\"\n  connections_bandwidth = \"1Gbps\"\n  location              = \"EqSe2-EQ\"\n}\n\nresource \"aws_dx_connection_association\" \"example\" {\n  connection_id = aws_dx_connection.example.id\n  lag_id        = aws_dx_lag.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `connection_id` - (Required) The ID of the connection.\n* `lag_id` - (Required) The ID of the LAG with which to associate the connection.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "dx_connection_association.html"
  },
  "dx_connection_confirmation.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_connection_confirmation",
    "description": "Provides a confirmation of the creation of the specified hosted connection on an interconnect.",
    "preview": "# Resource: aws_dx_connection_confirmation\n\nProvides a confirmation …",
    "content": "\n\n# Resource: aws_dx_connection_confirmation\n\nProvides a confirmation of the creation of the specified hosted connection on an interconnect.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_connection_confirmation\" \"confirmation\" {\n  connection_id = \"dxcon-ffabc123\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `connection_id` - (Required) The ID of the hosted connection.\n\n### Removing `aws_dx_connection_confirmation` from your configuration\n\nRemoving an `aws_dx_connection_confirmation` resource from your configuration will remove it\nfrom your statefile and management, **but will not destroy the Hosted Connection.**\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the connection.\n",
    "basename": "dx_connection_confirmation.html"
  },
  "dx_gateway.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_gateway",
    "description": "Provides a Direct Connect Gateway.",
    "preview": "# Resource: aws_dx_gateway\n\nProvides a Direct Connect Gateway.\n\n## …",
    "content": "\n\n# Resource: aws_dx_gateway\n\nProvides a Direct Connect Gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_gateway\" \"example\" {\n  name            = \"tf-dxg-example\"\n  amazon_side_asn = \"64512\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the connection.\n* `amazon_side_asn` - (Required) The ASN to be configured on the Amazon side of the connection. The ASN must be in the private range of 64,512 to 65,534 or 4,200,000,000 to 4,294,967,294.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the gateway.\n* `owner_account_id` - AWS Account ID of the gateway.\n\n## Timeouts\n\n`aws_dx_gateway` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating the gateway\n- `delete` - (Default `10 minutes`) Used for destroying the gateway\n\n## Import\n\nDirect Connect Gateways can be imported using the `gateway id`, e.g.,\n\n```\n$ terraform import aws_dx_gateway.test abcd1234-dcba-5678-be23-cdef9876ab45\n```\n",
    "basename": "dx_gateway.html"
  },
  "dx_gateway_association.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_gateway_association",
    "description": "Associates a Direct Connect Gateway with a VGW or transit gateway.",
    "preview": "# Resource: aws_dx_gateway_association\n\nAssociates a Direct Connect …",
    "content": "\n\n# Resource: aws_dx_gateway_association\n\nAssociates a Direct Connect Gateway with a VGW or transit gateway.\n\nTo create a cross-account association, create an [`aws_dx_gateway_association_proposal` resource](/docs/providers/aws/r/dx_gateway_association_proposal.html)\nin the AWS account that owns the VGW or transit gateway and then accept the proposal in the AWS account that owns the Direct Connect Gateway\nby creating an `aws_dx_gateway_association` resource with the `proposal_id` and `associated_gateway_owner_account_id` attributes set.\n\n## Example Usage\n\n### VPN Gateway Association\n\n```terraform\nresource \"aws_dx_gateway\" \"example\" {\n  name            = \"example\"\n  amazon_side_asn = \"64512\"\n}\n\nresource \"aws_vpc\" \"example\" {\n  cidr_block = \"10.255.255.0/28\"\n}\n\nresource \"aws_vpn_gateway\" \"example\" {\n  vpc_id = aws_vpc.example.id\n}\n\nresource \"aws_dx_gateway_association\" \"example\" {\n  dx_gateway_id         = aws_dx_gateway.example.id\n  associated_gateway_id = aws_vpn_gateway.example.id\n}\n```\n\n### Transit Gateway Association\n\n```terraform\nresource \"aws_dx_gateway\" \"example\" {\n  name            = \"example\"\n  amazon_side_asn = \"64512\"\n}\n\nresource \"aws_ec2_transit_gateway\" \"example\" {\n}\n\nresource \"aws_dx_gateway_association\" \"example\" {\n  dx_gateway_id         = aws_dx_gateway.example.id\n  associated_gateway_id = aws_ec2_transit_gateway.example.id\n\n  allowed_prefixes = [\n    \"10.255.255.0/30\",\n    \"10.255.255.8/30\",\n  ]\n}\n```\n\n### Allowed Prefixes\n\n```terraform\nresource \"aws_dx_gateway\" \"example\" {\n  name            = \"example\"\n  amazon_side_asn = \"64512\"\n}\n\nresource \"aws_vpc\" \"example\" {\n  cidr_block = \"10.255.255.0/28\"\n}\n\nresource \"aws_vpn_gateway\" \"example\" {\n  vpc_id = aws_vpc.example.id\n}\n\nresource \"aws_dx_gateway_association\" \"example\" {\n  dx_gateway_id         = aws_dx_gateway.example.id\n  associated_gateway_id = aws_vpn_gateway.example.id\n\n  allowed_prefixes = [\n    \"210.52.109.0/24\",\n    \"175.45.176.0/22\",\n  ]\n}\n```\n\nA full example of how to create a VPN Gateway in one AWS account, create a Direct Connect Gateway in a second AWS account, and associate the VPN Gateway with the Direct Connect Gateway via the `aws_dx_gateway_association_proposal` and `aws_dx_gateway_association` resources can be found in [the `./examples/dx-gateway-cross-account-vgw-association` directory within the Github Repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/dx-gateway-cross-account-vgw-association).\n\n## Argument Reference\n\n~> **NOTE:** `dx_gateway_id` and `associated_gateway_id` must be specified for single account Direct Connect gateway associations.\n\nThe following arguments are supported:\n\n* `dx_gateway_id` - (Required) The ID of the Direct Connect gateway.\n* `associated_gateway_id` - (Optional) The ID of the VGW or transit gateway with which to associate the Direct Connect gateway.\nUsed for single account Direct Connect gateway associations.\n* `associated_gateway_owner_account_id` - (Optional) The ID of the AWS account that owns the VGW or transit gateway with which to associate the Direct Connect gateway.\nUsed for cross-account Direct Connect gateway associations.\n* `proposal_id` - (Optional) The ID of the Direct Connect gateway association proposal.\nUsed for cross-account Direct Connect gateway associations.\n* `allowed_prefixes` - (Optional) VPC prefixes (CIDRs) to advertise to the Direct Connect gateway. Defaults to the CIDR block of the VPC associated with the Virtual Gateway. To enable drift detection, must be configured.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Direct Connect gateway association resource.\n* `associated_gateway_type` - The type of the associated gateway, `transitGateway` or `virtualPrivateGateway`.\n* `dx_gateway_association_id` - The ID of the Direct Connect gateway association.\n* `dx_gateway_owner_account_id` - The ID of the AWS account that owns the Direct Connect gateway.\n\n## Timeouts\n\n`aws_dx_gateway_association` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `30 minutes`) Used for creating the association\n- `update` - (Default `30 minutes`) Used for updating the association\n- `delete` - (Default `30 minutes`) Used for destroying the association\n\n## Import\n\nDirect Connect gateway associations can be imported using `dx_gateway_id` together with `associated_gateway_id`,\ne.g.,\n\n```\n$ terraform import aws_dx_gateway_association.example 345508c3-7215-4aef-9832-07c125d5bd0f/vgw-98765432\n```\n",
    "basename": "dx_gateway_association.html"
  },
  "dx_gateway_association_proposal.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_gateway_association_proposal",
    "description": "Manages a Direct Connect Gateway Association Proposal.",
    "preview": "# Resource: aws_dx_gateway_association_proposal\n\nManages a Direct …",
    "content": "\n\n# Resource: aws_dx_gateway_association_proposal\n\nManages a Direct Connect Gateway Association Proposal, typically for enabling cross-account associations. For single account associations, see the [`aws_dx_gateway_association` resource](/docs/providers/aws/r/dx_gateway_association.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_gateway_association_proposal\" \"example\" {\n  dx_gateway_id               = aws_dx_gateway.example.id\n  dx_gateway_owner_account_id = aws_dx_gateway.example.owner_account_id\n  associated_gateway_id       = aws_vpn_gateway.example.id\n}\n```\n\nA full example of how to create a VPN Gateway in one AWS account, create a Direct Connect Gateway in a second AWS account, and associate the VPN Gateway with the Direct Connect Gateway via the `aws_dx_gateway_association_proposal` and `aws_dx_gateway_association` resources can be found in [the `./examples/dx-gateway-cross-account-vgw-association` directory within the Github Repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/dx-gateway-cross-account-vgw-association).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `associated_gateway_id` - (Required) The ID of the VGW or transit gateway with which to associate the Direct Connect gateway.\n* `dx_gateway_id` - (Required) Direct Connect Gateway identifier.\n* `dx_gateway_owner_account_id` - (Required) AWS Account identifier of the Direct Connect Gateway's owner.\n* `allowed_prefixes` - (Optional) VPC prefixes (CIDRs) to advertise to the Direct Connect gateway. Defaults to the CIDR block of the VPC associated with the Virtual Gateway. To enable drift detection, must be configured.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Direct Connect Gateway Association Proposal identifier.\n* `associated_gateway_owner_account_id` - The ID of the AWS account that owns the VGW or transit gateway with which to associate the Direct Connect gateway.\n* `associated_gateway_type` - The type of the associated gateway, `transitGateway` or `virtualPrivateGateway`.\n\n## Import\n\nDirect Connect Gateway Association Proposals can be imported using either a proposal ID or proposal ID, Direct Connect Gateway ID and associated gateway ID separated by `/`, e.g.,\n\n```\n$ terraform import aws_dx_gateway_association_proposal.example ac90e981-b718-4364-872d-65478c84fafe\n```\n\nor\n\n```\n$ terraform import aws_dx_gateway_association_proposal.example ac90e981-b718-4364-872d-65478c84fafe/abcd1234-dcba-5678-be23-cdef9876ab45/vgw-12345678\n```\n\nThe latter case is useful when a previous proposal has been accepted and deleted by AWS.\nThe `aws_dx_gateway_association_proposal` resource will then represent a pseudo-proposal for the same Direct Connect Gateway and associated gateway.\nIf no previous proposal is available, use a tool like [`uuidgen`](http://manpages.ubuntu.com/manpages/bionic/man1/uuidgen.1.html) to generate a new random pseudo-proposal ID.\n",
    "basename": "dx_gateway_association_proposal.html"
  },
  "dx_hosted_connection.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_hosted_connection",
    "description": "Provides a hosted connection on the specified interconnect or a link aggregation group (LAG) of interconnects. Intended for use by AWS Direct Connect Partners only.",
    "preview": "# Resource: aws_dx_hosted_connection\n\nProvides a hosted connection …",
    "content": "\n\n# Resource: aws_dx_hosted_connection\n\nProvides a hosted connection on the specified interconnect or a link aggregation group (LAG) of interconnects. Intended for use by AWS Direct Connect Partners only.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_hosted_connection\" \"hosted\" {\n  connection_id    = \"dxcon-ffabc123\"\n  bandwidth        = \"100Mbps\"\n  name             = \"tf-dx-hosted-connection\"\n  owner_account_id = \"123456789012\"\n  vlan             = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the connection.\n* `bandwidth` - (Required) The bandwidth of the connection. Valid values for dedicated connections: 1Gbps, 10Gbps. Valid values for hosted connections: 50Mbps, 100Mbps, 200Mbps, 300Mbps, 400Mbps, 500Mbps, 1Gbps, 2Gbps, 5Gbps and 10Gbps. Case sensitive.\n* `connection_id` - (Required) The ID of the interconnect or LAG.\n* `owner_account_id` - (Required) The ID of the AWS account of the customer for the connection.\n* `vlan` - (Required) The dedicated VLAN provisioned to the hosted connection.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the connection.\n* `jumbo_frame_capable` - Boolean value representing if jumbo frames have been enabled for this connection.\n* `has_logical_redundancy` - Indicates whether the connection supports a secondary BGP peer in the same address family (IPv4/IPv6).\n* `aws_device` - The Direct Connect endpoint on which the physical connection terminates.\n* `state` - The state of the connection. Possible values include: ordering, requested, pending, available, down, deleting, deleted, rejected, unknown. See [AllocateHostedConnection](https://docs.aws.amazon.com/directconnect/latest/APIReference/API_AllocateHostedConnection.html) for a description of each connection state.\n* `lag_id` - The ID of the LAG.\n* `loa_issue_time` - The time of the most recent call to [DescribeLoa](https://docs.aws.amazon.com/directconnect/latest/APIReference/API_DescribeLoa.html) for this connection.\n* `location` - The location of the connection.\n* `partner_name` - The name of the AWS Direct Connect service provider associated with the connection.\n* `provider_name` - The name of the service provider associated with the connection.\n* `region` - The AWS Region where the connection is located.\n",
    "basename": "dx_hosted_connection.html"
  },
  "dx_hosted_private_virtual_interface.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_hosted_private_virtual_interface",
    "description": "Provides a Direct Connect hosted private virtual interface resource.",
    "preview": "# Resource: aws_dx_hosted_private_virtual_interface\n\nProvides a …",
    "content": "\n\n# Resource: aws_dx_hosted_private_virtual_interface\n\nProvides a Direct Connect hosted private virtual interface resource. This resource represents the allocator's side of the hosted virtual interface.\nA hosted virtual interface is a virtual interface that is owned by another AWS account.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_hosted_private_virtual_interface\" \"foo\" {\n  connection_id = \"dxcon-zzzzzzzz\"\n\n  name           = \"vif-foo\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required) The address family for the BGP peer. `ipv4 ` or `ipv6`.\n* `bgp_asn` - (Required) The autonomous system (AS) number for Border Gateway Protocol (BGP) configuration.\n* `connection_id` - (Required) The ID of the Direct Connect connection (or LAG) on which to create the virtual interface.\n* `name` - (Required) The name for the virtual interface.\n* `owner_account_id` - (Required) The AWS account that will own the new virtual interface.\n* `vlan` - (Required) The VLAN ID.\n* `amazon_address` - (Optional) The IPv4 CIDR address to use to send traffic to Amazon. Required for IPv4 BGP peers.\n* `mtu` - (Optional) The maximum transmission unit (MTU) is the size, in bytes, of the largest permissible packet that can be passed over the connection. The MTU of a virtual private interface can be either `1500` or `9001` (jumbo frames). Default is `1500`.\n* `bgp_auth_key` - (Optional) The authentication key for BGP configuration.\n* `customer_address` - (Optional) The IPv4 CIDR destination address to which Amazon should send traffic. Required for IPv4 BGP peers.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `jumbo_frame_capable` - Indicates whether jumbo frames (9001 MTU) are supported.\n* `aws_device` - The Direct Connect endpoint on which the virtual interface terminates.\n\n## Timeouts\n\n`aws_dx_hosted_private_virtual_interface` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `update` - (Default `10 minutes`) Used for virtual interface modifications\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect hosted private virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_hosted_private_virtual_interface.test dxvif-33cc44dd\n```\n",
    "basename": "dx_hosted_private_virtual_interface.html"
  },
  "dx_hosted_private_virtual_interface_accepter.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_hosted_private_virtual_interface_accepter",
    "description": "Provides a resource to manage the accepter's side of a Direct Connect hosted private virtual interface.",
    "preview": "# Resource: aws_dx_hosted_private_virtual_interface_accepter\n …",
    "content": "\n\n# Resource: aws_dx_hosted_private_virtual_interface_accepter\n\nProvides a resource to manage the accepter's side of a Direct Connect hosted private virtual interface.\nThis resource accepts ownership of a private virtual interface created by another AWS account.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  # Creator's credentials.\n}\n\nprovider \"aws\" {\n  alias = \"accepter\"\n\n  # Accepter's credentials.\n}\n\ndata \"aws_caller_identity\" \"accepter\" {\n  provider = aws.accepter\n}\n\n# Creator's side of the VIF\nresource \"aws_dx_hosted_private_virtual_interface\" \"creator\" {\n  connection_id    = \"dxcon-zzzzzzzz\"\n  owner_account_id = data.aws_caller_identity.accepter.account_id\n\n  name           = \"vif-foo\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n\n  # The aws_dx_hosted_private_virtual_interface\n  # must be destroyed before the aws_vpn_gateway.\n  depends_on = [aws_vpn_gateway.vpn_gw]\n}\n\n# Accepter's side of the VIF.\nresource \"aws_vpn_gateway\" \"vpn_gw\" {\n  provider = aws.accepter\n}\n\nresource \"aws_dx_hosted_private_virtual_interface_accepter\" \"accepter\" {\n  provider             = aws.accepter\n  virtual_interface_id = aws_dx_hosted_private_virtual_interface.creator.id\n  vpn_gateway_id       = aws_vpn_gateway.vpn_gw.id\n\n  tags = {\n    Side = \"Accepter\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `virtual_interface_id` - (Required) The ID of the Direct Connect virtual interface to accept.\n* `dx_gateway_id` - (Optional) The ID of the Direct Connect gateway to which to connect the virtual interface.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpn_gateway_id` - (Optional) The ID of the [virtual private gateway](vpn_gateway.html) to which to connect the virtual interface.\n\n### Removing `aws_dx_hosted_private_virtual_interface_accepter` from your configuration\n\nAWS allows a Direct Connect hosted private virtual interface to be deleted from either the allocator's or accepter's side.\nHowever, Terraform only allows the Direct Connect hosted private virtual interface to be deleted from the allocator's side\nby removing the corresponding `aws_dx_hosted_private_virtual_interface` resource from your configuration.\nRemoving a `aws_dx_hosted_private_virtual_interface_accepter` resource from your configuration will remove it\nfrom your statefile and management, **but will not delete the Direct Connect virtual interface.**\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dx_hosted_private_virtual_interface_accepter` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect hosted private virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_hosted_private_virtual_interface_accepter.test dxvif-33cc44dd\n```\n",
    "basename": "dx_hosted_private_virtual_interface_accepter.html"
  },
  "dx_hosted_public_virtual_interface.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_hosted_public_virtual_interface",
    "description": "Provides a Direct Connect hosted public virtual interface resource.",
    "preview": "# Resource: aws_dx_hosted_public_virtual_interface\n\nProvides a …",
    "content": "\n\n# Resource: aws_dx_hosted_public_virtual_interface\n\nProvides a Direct Connect hosted public virtual interface resource. This resource represents the allocator's side of the hosted virtual interface.\nA hosted virtual interface is a virtual interface that is owned by another AWS account.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_hosted_public_virtual_interface\" \"foo\" {\n  connection_id = \"dxcon-zzzzzzzz\"\n\n  name           = \"vif-foo\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n\n  customer_address = \"175.45.176.1/30\"\n  amazon_address   = \"175.45.176.2/30\"\n\n  route_filter_prefixes = [\n    \"210.52.109.0/24\",\n    \"175.45.176.0/22\",\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required) The address family for the BGP peer. `ipv4 ` or `ipv6`.\n* `bgp_asn` - (Required) The autonomous system (AS) number for Border Gateway Protocol (BGP) configuration.\n* `connection_id` - (Required) The ID of the Direct Connect connection (or LAG) on which to create the virtual interface.\n* `name` - (Required) The name for the virtual interface.\n* `owner_account_id` - (Required) The AWS account that will own the new virtual interface.\n* `route_filter_prefixes` - (Required) A list of routes to be advertised to the AWS network in this region.\n* `vlan` - (Required) The VLAN ID.\n* `amazon_address` - (Optional) The IPv4 CIDR address to use to send traffic to Amazon. Required for IPv4 BGP peers.\n* `bgp_auth_key` - (Optional) The authentication key for BGP configuration.\n* `customer_address` - (Optional) The IPv4 CIDR destination address to which Amazon should send traffic. Required for IPv4 BGP peers.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `aws_device` - The Direct Connect endpoint on which the virtual interface terminates.\n\n## Timeouts\n\n`aws_dx_hosted_public_virtual_interface` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect hosted public virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_hosted_public_virtual_interface.test dxvif-33cc44dd\n```\n",
    "basename": "dx_hosted_public_virtual_interface.html"
  },
  "dx_hosted_public_virtual_interface_accepter.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_hosted_public_virtual_interface_accepter",
    "description": "Provides a resource to manage the accepter's side of a Direct Connect hosted public virtual interface.",
    "preview": "# Resource: aws_dx_hosted_public_virtual_interface_accepter\n …",
    "content": "\n\n# Resource: aws_dx_hosted_public_virtual_interface_accepter\n\nProvides a resource to manage the accepter's side of a Direct Connect hosted public virtual interface.\nThis resource accepts ownership of a public virtual interface created by another AWS account.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  # Creator's credentials.\n}\n\nprovider \"aws\" {\n  alias = \"accepter\"\n\n  # Accepter's credentials.\n}\n\ndata \"aws_caller_identity\" \"accepter\" {\n  provider = aws.accepter\n}\n\n# Creator's side of the VIF\nresource \"aws_dx_hosted_public_virtual_interface\" \"creator\" {\n  connection_id    = \"dxcon-zzzzzzzz\"\n  owner_account_id = data.aws_caller_identity.accepter.account_id\n\n  name           = \"vif-foo\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n\n  customer_address = \"175.45.176.1/30\"\n  amazon_address   = \"175.45.176.2/30\"\n\n  route_filter_prefixes = [\n    \"210.52.109.0/24\",\n    \"175.45.176.0/22\",\n  ]\n}\n\n# Accepter's side of the VIF.\nresource \"aws_dx_hosted_public_virtual_interface_accepter\" \"accepter\" {\n  provider             = aws.accepter\n  virtual_interface_id = aws_dx_hosted_public_virtual_interface.creator.id\n\n  tags = {\n    Side = \"Accepter\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `virtual_interface_id` - (Required) The ID of the Direct Connect virtual interface to accept.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Removing `aws_dx_hosted_public_virtual_interface_accepter` from your configuration\n\nAWS allows a Direct Connect hosted public virtual interface to be deleted from either the allocator's or accepter's side.\nHowever, Terraform only allows the Direct Connect hosted public virtual interface to be deleted from the allocator's side\nby removing the corresponding `aws_dx_hosted_public_virtual_interface` resource from your configuration.\nRemoving a `aws_dx_hosted_public_virtual_interface_accepter` resource from your configuration will remove it\nfrom your statefile and management, **but will not delete the Direct Connect virtual interface.**\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dx_hosted_public_virtual_interface_accepter` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect hosted public virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_hosted_public_virtual_interface_accepter.test dxvif-33cc44dd\n```\n",
    "basename": "dx_hosted_public_virtual_interface_accepter.html"
  },
  "dx_hosted_transit_virtual_interface.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_hosted_transit_virtual_interface",
    "description": "Provides a Direct Connect hosted transit virtual interface resource.",
    "preview": "# Resource: aws_dx_hosted_transit_virtual_interface\n\nProvides a …",
    "content": "\n\n# Resource: aws_dx_hosted_transit_virtual_interface\n\nProvides a Direct Connect hosted transit virtual interface resource.\nThis resource represents the allocator's side of the hosted virtual interface.\nA hosted virtual interface is a virtual interface that is owned by another AWS account.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_hosted_transit_virtual_interface\" \"example\" {\n  connection_id = aws_dx_connection.example.id\n\n  name           = \"tf-transit-vif-example\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required) The address family for the BGP peer. `ipv4 ` or `ipv6`.\n* `bgp_asn` - (Required) The autonomous system (AS) number for Border Gateway Protocol (BGP) configuration.\n* `connection_id` - (Required) The ID of the Direct Connect connection (or LAG) on which to create the virtual interface.\n* `name` - (Required) The name for the virtual interface.\n* `owner_account_id` - (Required) The AWS account that will own the new virtual interface.\n* `vlan` - (Required) The VLAN ID.\n* `amazon_address` - (Optional) The IPv4 CIDR address to use to send traffic to Amazon. Required for IPv4 BGP peers.\n* `bgp_auth_key` - (Optional) The authentication key for BGP configuration.\n* `customer_address` - (Optional) The IPv4 CIDR destination address to which Amazon should send traffic. Required for IPv4 BGP peers.\n* `mtu` - (Optional) The maximum transmission unit (MTU) is the size, in bytes, of the largest permissible packet that can be passed over the connection. The MTU of a virtual transit interface can be either `1500` or `8500` (jumbo frames). Default is `1500`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `aws_device` - The Direct Connect endpoint on which the virtual interface terminates.\n* `jumbo_frame_capable` - Indicates whether jumbo frames (8500 MTU) are supported.\n\n## Timeouts\n\n`aws_dx_hosted_transit_virtual_interface` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `update` - (Default `10 minutes`) Used for virtual interface modifications\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect hosted transit virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_hosted_transit_virtual_interface.test dxvif-33cc44dd\n```\n",
    "basename": "dx_hosted_transit_virtual_interface.html"
  },
  "dx_hosted_transit_virtual_interface_accepter.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_hosted_transit_virtual_interface_accepter",
    "description": "Provides a resource to manage the accepter's side of a Direct Connect hosted transit virtual interface.",
    "preview": "# Resource: aws_dx_hosted_transit_virtual_interface_accepter\n …",
    "content": "\n\n# Resource: aws_dx_hosted_transit_virtual_interface_accepter\n\nProvides a resource to manage the accepter's side of a Direct Connect hosted transit virtual interface.\nThis resource accepts ownership of a transit virtual interface created by another AWS account.\n\n-> **NOTE:** AWS allows a Direct Connect hosted transit virtual interface to be deleted from either the allocator's or accepter's side. However, Terraform only allows the Direct Connect hosted transit virtual interface to be deleted from the allocator's side by removing the corresponding `aws_dx_hosted_transit_virtual_interface` resource from your configuration. Removing a `aws_dx_hosted_transit_virtual_interface_accepter` resource from your configuration will remove it from your statefile and management, **but will not delete the Direct Connect virtual interface.**\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  # Creator's credentials.\n}\n\nprovider \"aws\" {\n  alias = \"accepter\"\n\n  # Accepter's credentials.\n}\n\ndata \"aws_caller_identity\" \"accepter\" {\n  provider = aws.accepter\n}\n\n# Creator's side of the VIF\nresource \"aws_dx_hosted_transit_virtual_interface\" \"creator\" {\n  connection_id    = \"dxcon-zzzzzzzz\"\n  owner_account_id = data.aws_caller_identity.accepter.account_id\n\n  name           = \"tf-transit-vif-example\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n\n  # The aws_dx_hosted_transit_virtual_interface\n  # must be destroyed before the aws_dx_gateway.\n  depends_on = [aws_dx_gateway.example]\n}\n\n# Accepter's side of the VIF.\nresource \"aws_dx_gateway\" \"example\" {\n  provider = aws.accepter\n\n  name            = \"tf-dxg-example\"\n  amazon_side_asn = 64512\n}\n\nresource \"aws_dx_hosted_transit_virtual_interface_accepter\" \"accepter\" {\n  provider             = aws.accepter\n  virtual_interface_id = aws_dx_hosted_transit_virtual_interface.creator.id\n  dx_gateway_id        = aws_dx_gateway.example.id\n\n  tags = {\n    Side = \"Accepter\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `dx_gateway_id` - (Required) The ID of the [Direct Connect gateway](dx_gateway.html) to which to connect the virtual interface.\n* `virtual_interface_id` - (Required) The ID of the Direct Connect virtual interface to accept.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dx_hosted_transit_virtual_interface_accepter` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect hosted transit virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_hosted_transit_virtual_interface_accepter.test dxvif-33cc44dd\n```\n",
    "basename": "dx_hosted_transit_virtual_interface_accepter.html"
  },
  "dx_lag.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_lag",
    "description": "Provides a Direct Connect LAG.",
    "preview": "# Resource: aws_dx_lag\n\nProvides a Direct Connect LAG. Connections …",
    "content": "\n\n# Resource: aws_dx_lag\n\nProvides a Direct Connect LAG. Connections can be added to the LAG via the [`aws_dx_connection`](/docs/providers/aws/r/dx_connection.html) and [`aws_dx_connection_association`](/docs/providers/aws/r/dx_connection_association.html) resources.\n\n~> *NOTE:* When creating a LAG, if no existing connection is specified, Direct Connect will create a connection and Terraform will remove this unmanaged connection during resource creation.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_lag\" \"hoge\" {\n  name                  = \"tf-dx-lag\"\n  connections_bandwidth = \"1Gbps\"\n  location              = \"EqDC2\"\n  force_destroy         = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the LAG.\n* `connections_bandwidth` - (Required) The bandwidth of the individual physical connections bundled by the LAG. Valid values: 50Mbps, 100Mbps, 200Mbps, 300Mbps, 400Mbps, 500Mbps, 1Gbps, 2Gbps, 5Gbps, 10Gbps and 100Gbps. Case sensitive.\n* `location` - (Required) The AWS Direct Connect location in which the LAG should be allocated. See [DescribeLocations](https://docs.aws.amazon.com/directconnect/latest/APIReference/API_DescribeLocations.html) for the list of AWS Direct Connect locations. Use `locationCode`.\n* `connection_id` - (Optional) The ID of an existing dedicated connection to migrate to the LAG.\n* `force_destroy` - (Optional, Default:false) A boolean that indicates all connections associated with the LAG should be deleted so that the LAG can be destroyed without error. These objects are *not* recoverable.\n* `provider_name` - (Optional) The name of the service provider associated with the LAG.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the LAG.\n* `has_logical_redundancy` - Indicates whether the LAG supports a secondary BGP peer in the same address family (IPv4/IPv6).\n* `id` - The ID of the LAG.\n* `jumbo_frame_capable` -Indicates whether jumbo frames (9001 MTU) are supported.\n* `owner_account_id` - The ID of the AWS account that owns the LAG.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDirect Connect LAGs can be imported using the `lag id`, e.g.,\n\n```\n$ terraform import aws_dx_lag.test_lag dxlag-fgnsp5rq\n```\n",
    "basename": "dx_lag.html"
  },
  "dx_private_virtual_interface.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_private_virtual_interface",
    "description": "Provides a Direct Connect private virtual interface resource.",
    "preview": "# Resource: aws_dx_private_virtual_interface\n\nProvides a Direct …",
    "content": "\n\n# Resource: aws_dx_private_virtual_interface\n\nProvides a Direct Connect private virtual interface resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_private_virtual_interface\" \"foo\" {\n  connection_id = \"dxcon-zzzzzzzz\"\n\n  name           = \"vif-foo\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required) The address family for the BGP peer. `ipv4 ` or `ipv6`.\n* `bgp_asn` - (Required) The autonomous system (AS) number for Border Gateway Protocol (BGP) configuration.\n* `connection_id` - (Required) The ID of the Direct Connect connection (or LAG) on which to create the virtual interface.\n* `name` - (Required) The name for the virtual interface.\n* `vlan` - (Required) The VLAN ID.\n* `amazon_address` - (Optional) The IPv4 CIDR address to use to send traffic to Amazon. Required for IPv4 BGP peers.\n* `mtu` - (Optional) The maximum transmission unit (MTU) is the size, in bytes, of the largest permissible packet that can be passed over the connection.\nThe MTU of a virtual private interface can be either `1500` or `9001` (jumbo frames). Default is `1500`.\n* `bgp_auth_key` - (Optional) The authentication key for BGP configuration.\n* `customer_address` - (Optional) The IPv4 CIDR destination address to which Amazon should send traffic. Required for IPv4 BGP peers.\n* `dx_gateway_id` - (Optional) The ID of the Direct Connect gateway to which to connect the virtual interface.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpn_gateway_id` - (Optional) The ID of the [virtual private gateway](vpn_gateway.html) to which to connect the virtual interface.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `jumbo_frame_capable` - Indicates whether jumbo frames (9001 MTU) are supported.\n* `aws_device` - The Direct Connect endpoint on which the virtual interface terminates.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dx_private_virtual_interface` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `update` - (Default `10 minutes`) Used for virtual interface modifications\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect private virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_private_virtual_interface.test dxvif-33cc44dd\n```\n",
    "basename": "dx_private_virtual_interface.html"
  },
  "dx_public_virtual_interface.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_public_virtual_interface",
    "description": "Provides a Direct Connect public virtual interface resource.",
    "preview": "# Resource: aws_dx_public_virtual_interface\n\nProvides a Direct …",
    "content": "\n\n# Resource: aws_dx_public_virtual_interface\n\nProvides a Direct Connect public virtual interface resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_public_virtual_interface\" \"foo\" {\n  connection_id = \"dxcon-zzzzzzzz\"\n\n  name           = \"vif-foo\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n\n  customer_address = \"175.45.176.1/30\"\n  amazon_address   = \"175.45.176.2/30\"\n\n  route_filter_prefixes = [\n    \"210.52.109.0/24\",\n    \"175.45.176.0/22\",\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required) The address family for the BGP peer. `ipv4 ` or `ipv6`.\n* `bgp_asn` - (Required) The autonomous system (AS) number for Border Gateway Protocol (BGP) configuration.\n* `connection_id` - (Required) The ID of the Direct Connect connection (or LAG) on which to create the virtual interface.\n* `name` - (Required) The name for the virtual interface.\n* `vlan` - (Required) The VLAN ID.\n* `amazon_address` - (Optional) The IPv4 CIDR address to use to send traffic to Amazon. Required for IPv4 BGP peers.\n* `bgp_auth_key` - (Optional) The authentication key for BGP configuration.\n* `customer_address` - (Optional) The IPv4 CIDR destination address to which Amazon should send traffic. Required for IPv4 BGP peers.\n* `route_filter_prefixes` - (Required) A list of routes to be advertised to the AWS network in this region.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `aws_device` - The Direct Connect endpoint on which the virtual interface terminates.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dx_public_virtual_interface` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect public virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_public_virtual_interface.test dxvif-33cc44dd\n```\n",
    "basename": "dx_public_virtual_interface.html"
  },
  "dx_transit_virtual_interface.html": {
    "subcategory": "Direct Connect",
    "layout": "aws",
    "page_title": "AWS: aws_dx_transit_virtual_interface",
    "description": "Provides a Direct Connect transit virtual interface resource.",
    "preview": "# Resource: aws_dx_transit_virtual_interface\n\nProvides a Direct …",
    "content": "\n\n# Resource: aws_dx_transit_virtual_interface\n\nProvides a Direct Connect transit virtual interface resource.\nA transit virtual interface is a VLAN that transports traffic from a [Direct Connect gateway](dx_gateway.html) to one or more [transit gateways](ec2_transit_gateway.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_dx_gateway\" \"example\" {\n  name            = \"tf-dxg-example\"\n  amazon_side_asn = 64512\n}\n\nresource \"aws_dx_transit_virtual_interface\" \"example\" {\n  connection_id = aws_dx_connection.example.id\n\n  dx_gateway_id  = aws_dx_gateway.example.id\n  name           = \"tf-transit-vif-example\"\n  vlan           = 4094\n  address_family = \"ipv4\"\n  bgp_asn        = 65352\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required) The address family for the BGP peer. `ipv4 ` or `ipv6`.\n* `bgp_asn` - (Required) The autonomous system (AS) number for Border Gateway Protocol (BGP) configuration.\n* `connection_id` - (Required) The ID of the Direct Connect connection (or LAG) on which to create the virtual interface.\n* `dx_gateway_id` - (Required) The ID of the Direct Connect gateway to which to connect the virtual interface.\n* `name` - (Required) The name for the virtual interface.\n* `vlan` - (Required) The VLAN ID.\n* `amazon_address` - (Optional) The IPv4 CIDR address to use to send traffic to Amazon. Required for IPv4 BGP peers.\n* `bgp_auth_key` - (Optional) The authentication key for BGP configuration.\n* `customer_address` - (Optional) The IPv4 CIDR destination address to which Amazon should send traffic. Required for IPv4 BGP peers.\n* `mtu` - (Optional) The maximum transmission unit (MTU) is the size, in bytes, of the largest permissible packet that can be passed over the connection.\nThe MTU of a virtual transit interface can be either `1500` or `8500` (jumbo frames). Default is `1500`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the virtual interface.\n* `arn` - The ARN of the virtual interface.\n* `aws_device` - The Direct Connect endpoint on which the virtual interface terminates.\n* `jumbo_frame_capable` - Indicates whether jumbo frames (8500 MTU) are supported.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_dx_transit_virtual_interface` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating virtual interface\n- `update` - (Default `10 minutes`) Used for virtual interface modifications\n- `delete` - (Default `10 minutes`) Used for destroying virtual interface\n\n## Import\n\nDirect Connect transit virtual interfaces can be imported using the `vif id`, e.g.,\n\n```\n$ terraform import aws_dx_transit_virtual_interface.test dxvif-33cc44dd\n```\n",
    "basename": "dx_transit_virtual_interface.html"
  },
  "dynamodb_global_table.html": {
    "subcategory": "DynamoDB",
    "layout": "aws",
    "page_title": "AWS: aws_dynamodb_global_table",
    "description": "Manages DynamoDB Global Tables V1 (version 2017.11.29)",
    "preview": "# Resource: aws_dynamodb_global_table\n\nManages [DynamoDB Global …",
    "content": "\n\n# Resource: aws_dynamodb_global_table\n\nManages [DynamoDB Global Tables V1 (version 2017.11.29)](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/globaltables.V1.html). These are layered on top of existing DynamoDB Tables.\n\n~> **NOTE:** To instead manage [DynamoDB Global Tables V2 (version 2019.11.21)](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/globaltables.V2.html), use the [`aws_dynamodb_table` resource](/docs/providers/aws/r/dynamodb_table.html) `replica` configuration block.\n\n~> Note: There are many restrictions before you can properly create DynamoDB Global Tables in multiple regions. See the [AWS DynamoDB Global Table Requirements](http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/globaltables_reqs_bestpractices.html) for more information.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  alias  = \"us-east-1\"\n  region = \"us-east-1\"\n}\n\nprovider \"aws\" {\n  alias  = \"us-west-2\"\n  region = \"us-west-2\"\n}\n\nresource \"aws_dynamodb_table\" \"us-east-1\" {\n  provider = aws.us-east-1\n\n  hash_key         = \"myAttribute\"\n  name             = \"myTable\"\n  stream_enabled   = true\n  stream_view_type = \"NEW_AND_OLD_IMAGES\"\n  read_capacity    = 1\n  write_capacity   = 1\n\n  attribute {\n    name = \"myAttribute\"\n    type = \"S\"\n  }\n}\n\nresource \"aws_dynamodb_table\" \"us-west-2\" {\n  provider = aws.us-west-2\n\n  hash_key         = \"myAttribute\"\n  name             = \"myTable\"\n  stream_enabled   = true\n  stream_view_type = \"NEW_AND_OLD_IMAGES\"\n  read_capacity    = 1\n  write_capacity   = 1\n\n  attribute {\n    name = \"myAttribute\"\n    type = \"S\"\n  }\n}\n\nresource \"aws_dynamodb_global_table\" \"myTable\" {\n  depends_on = [\n    aws_dynamodb_table.us-east-1,\n    aws_dynamodb_table.us-west-2,\n  ]\n  provider = aws.us-east-1\n\n  name = \"myTable\"\n\n  replica {\n    region_name = \"us-east-1\"\n  }\n\n  replica {\n    region_name = \"us-west-2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the global table. Must match underlying DynamoDB Table names in all regions.\n* `replica` - (Required) Underlying DynamoDB Table. At least 1 replica must be defined. See below.\n\n### Nested Fields\n\n#### `replica`\n\n* `region_name` - (Required) AWS region name of replica DynamoDB TableE.g., `us-east-1`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the DynamoDB Global Table\n* `arn` - The ARN of the DynamoDB Global Table\n\n## Import\n\nDynamoDB Global Tables can be imported using the global table name, e.g.,\n\n```\n$ terraform import aws_dynamodb_global_table.MyTable MyTable\n```\n",
    "basename": "dynamodb_global_table.html"
  },
  "dynamodb_kinesis_streaming_destination.html": {
    "subcategory": "DynamoDB",
    "layout": "aws",
    "page_title": "AWS: aws_dynamodb_kinesis_streaming_destination",
    "description": "Enables a Kinesis streaming destination for a DynamoDB table",
    "preview": "# Resource: aws_dynamodb_kinesis_streaming_destination\n\nEnables a …",
    "content": "\n\n# Resource: aws_dynamodb_kinesis_streaming_destination\n\nEnables a [Kinesis streaming destination](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/kds.html) for data replication of a DynamoDB table.\n\n## Example Usage\n\n```terraform\nresource \"aws_dynamodb_table\" \"example\" {\n  name     = \"orders\"\n  hash_key = \"id\"\n\n  attribute {\n    name = \"id\"\n    type = \"S\"\n  }\n}\n\nresource \"aws_kinesis_stream\" \"example\" {\n  name        = \"order_item_changes\"\n  shard_count = 1\n}\n\nresource \"aws_dynamodb_kinesis_streaming_destination\" \"example\" {\n  stream_arn = aws_kinesis_stream.example.arn\n  table_name = aws_dynamodb_table.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stream_arn` - (Required) The ARN for a Kinesis data stream. This must exist in the same account and region as the DynamoDB table.\n  \n* `table_name` - (Required) The name of the DynamoDB table. There\n  can only be one Kinesis streaming destination for a given DynamoDB table.\n  \n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The `table_name` and `stream_arn` separated by a comma (`,`).\n\n## Import\n\nDynamoDB Kinesis Streaming Destinations can be imported using the `table_name` and `stream_arn` separated by `,`, e.g.,\n\n```\n$ terraform import aws_dynamodb_kinesis_streaming_destination.example example,arn:aws:kinesis:us-east-1:111122223333:exampleStreamName\n```\n",
    "basename": "dynamodb_kinesis_streaming_destination.html"
  },
  "dynamodb_table.html": {
    "subcategory": "DynamoDB",
    "layout": "aws",
    "page_title": "AWS: aws_dynamodb_table",
    "description": "Provides a DynamoDB table resource",
    "preview": "# Resource: aws_dynamodb_table\n\nProvides a DynamoDB table resource\n …",
    "content": "\n\n# Resource: aws_dynamodb_table\n\nProvides a DynamoDB table resource\n\n~> **Note:** It is recommended to use `lifecycle` [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) for `read_capacity` and/or `write_capacity` if there's [autoscaling policy](/docs/providers/aws/r/appautoscaling_policy.html) attached to the table.\n\n## Example Usage\n\nThe following dynamodb table description models the table and GSI shown\nin the [AWS SDK example documentation](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html)\n\n```terraform\nresource \"aws_dynamodb_table\" \"basic-dynamodb-table\" {\n  name           = \"GameScores\"\n  billing_mode   = \"PROVISIONED\"\n  read_capacity  = 20\n  write_capacity = 20\n  hash_key       = \"UserId\"\n  range_key      = \"GameTitle\"\n\n  attribute {\n    name = \"UserId\"\n    type = \"S\"\n  }\n\n  attribute {\n    name = \"GameTitle\"\n    type = \"S\"\n  }\n\n  attribute {\n    name = \"TopScore\"\n    type = \"N\"\n  }\n\n  ttl {\n    attribute_name = \"TimeToExist\"\n    enabled        = false\n  }\n\n  global_secondary_index {\n    name               = \"GameTitleIndex\"\n    hash_key           = \"GameTitle\"\n    range_key          = \"TopScore\"\n    write_capacity     = 10\n    read_capacity      = 10\n    projection_type    = \"INCLUDE\"\n    non_key_attributes = [\"UserId\"]\n  }\n\n  tags = {\n    Name        = \"dynamodb-table-1\"\n    Environment = \"production\"\n  }\n}\n```\n\n### Global Tables\n\nThis resource implements support for [DynamoDB Global Tables V2 (version 2019.11.21)](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/globaltables.V2.html) via `replica` configuration blocks. For working with [DynamoDB Global Tables V1 (version 2017.11.29)](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/globaltables.V1.html), see the [`aws_dynamodb_global_table` resource](/docs/providers/aws/r/dynamodb_global_table.html).\n\n```terraform\nresource \"aws_dynamodb_table\" \"example\" {\n  name             = \"example\"\n  hash_key         = \"TestTableHashKey\"\n  billing_mode     = \"PAY_PER_REQUEST\"\n  stream_enabled   = true\n  stream_view_type = \"NEW_AND_OLD_IMAGES\"\n\n  attribute {\n    name = \"TestTableHashKey\"\n    type = \"S\"\n  }\n\n  replica {\n    region_name = \"us-east-2\"\n  }\n\n  replica {\n    region_name = \"us-west-2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the table, this needs to be unique\n  within a region.\n* `billing_mode` - (Optional) Controls how you are charged for read and write throughput and how you manage capacity. The valid values are `PROVISIONED` and `PAY_PER_REQUEST`. Defaults to `PROVISIONED`.\n* `hash_key` - (Required, Forces new resource) The attribute to use as the hash (partition) key. Must also be defined as an `attribute`, see below.\n* `range_key` - (Optional, Forces new resource) The attribute to use as the range (sort) key. Must also be defined as an `attribute`, see below.\n* `write_capacity` - (Optional) The number of write units for this table. If the `billing_mode` is `PROVISIONED`, this field is required.\n* `read_capacity` - (Optional) The number of read units for this table. If the `billing_mode` is `PROVISIONED`, this field is required.\n* `attribute` - (Required) List of nested attribute definitions. Only required for `hash_key` and `range_key` attributes. Each attribute has two properties:\n    * `name` - (Required) The name of the attribute\n    * `type` - (Required) Attribute type, which must be a scalar type: `S`, `N`, or `B` for (S)tring, (N)umber or (B)inary data\n* `ttl` - (Optional) Defines ttl, has two properties, and can only be specified once:\n    * `enabled` - (Required) Indicates whether ttl is enabled (true) or disabled (false).\n    * `attribute_name` - (Required) The name of the table attribute to store the TTL timestamp in.\n* `local_secondary_index` - (Optional, Forces new resource) Describe an LSI on the table;\n  these can only be allocated *at creation* so you cannot change this\ndefinition after you have created the resource.\n* `global_secondary_index` - (Optional) Describe a GSI for the table;\n  subject to the normal limits on the number of GSIs, projected\nattributes, etc.\n* `replica` - (Optional) Configuration block(s) with [DynamoDB Global Tables V2 (version 2019.11.21)](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/globaltables.V2.html) replication configurations. Detailed below.\n* `stream_enabled` - (Optional) Indicates whether Streams are to be enabled (true) or disabled (false).\n* `stream_view_type` - (Optional) When an item in the table is modified, StreamViewType determines what information is written to the table's stream. Valid values are `KEYS_ONLY`, `NEW_IMAGE`, `OLD_IMAGE`, `NEW_AND_OLD_IMAGES`.\n* `server_side_encryption` - (Optional) Encryption at rest options. AWS DynamoDB tables are automatically encrypted at rest with an AWS owned Customer Master Key if this argument isn't specified.\n* `tags` - (Optional) A map of tags to populate on the created table. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `point_in_time_recovery` - (Optional) Point-in-time recovery options.\n* `table_class` - (Optional) The storage class of the table. Valid values are `STANDARD` and `STANDARD_INFREQUENT_ACCESS`.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 10 mins) Used when creating the table\n* `update` - (Defaults to 60 mins) Used when updating the table configuration and reset for each individual Global Secondary Index and Replica update\n* `delete` - (Defaults to 10 mins) Used when deleting the table\n\n### Nested fields\n\n#### `local_secondary_index`\n\n* `name` - (Required) The name of the index\n* `range_key` - (Required) The name of the range key; must be defined\n* `projection_type` - (Required) One of `ALL`, `INCLUDE` or `KEYS_ONLY`\n   where `ALL` projects every attribute into the index, `KEYS_ONLY`\n    projects just the hash and range key into the index, and `INCLUDE`\n    projects only the keys specified in the _non_key_attributes_\n    parameter.\n* `non_key_attributes` - (Optional) Only required with `INCLUDE` as a\n  projection type; a list of attributes to project into the index. These\n  do not need to be defined as attributes on the table.\n\n#### `global_secondary_index`\n\n* `name` - (Required) The name of the index\n* `write_capacity` - (Optional) The number of write units for this index. Must be set if billing_mode is set to PROVISIONED.\n* `read_capacity` - (Optional) The number of read units for this index. Must be set if billing_mode is set to PROVISIONED.\n* `hash_key` - (Required) The name of the hash key in the index; must be\n  defined as an attribute in the resource.\n* `range_key` - (Optional) The name of the range key; must be defined\n* `projection_type` - (Required) One of `ALL`, `INCLUDE` or `KEYS_ONLY`\n   where `ALL` projects every attribute into the index, `KEYS_ONLY`\n    projects just the hash and range key into the index, and `INCLUDE`\n    projects only the keys specified in the _non_key_attributes_\n    parameter.\n* `non_key_attributes` - (Optional) Only required with `INCLUDE` as a\n  projection type; a list of attributes to project into the index. These\n  do not need to be defined as attributes on the table.\n\n#### `replica`\n\nThe `replica` configuration block supports the following arguments:\n\n* `region_name` - (Required) Region name of the replica.\n* `kms_key_arn` - (Optional) The ARN of the CMK that should be used for the AWS KMS encryption.\n\n#### `server_side_encryption`\n\n* `enabled` - (Required) Whether or not to enable encryption at rest using an AWS managed KMS customer master key (CMK).\n* `kms_key_arn` - (Optional) The ARN of the CMK that should be used for the AWS KMS encryption.\nThis attribute should only be specified if the key is different from the default DynamoDB CMK, `alias/aws/dynamodb`.\n\nIf `enabled` is `false` then server-side encryption is set to AWS owned CMK (shown as `DEFAULT` in the AWS console).\nIf `enabled` is `true` and no `kms_key_arn` is specified then server-side encryption is set to AWS managed CMK (shown as `KMS` in the AWS console).\nThe [AWS KMS documentation](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html) explains the difference between AWS owned and AWS managed CMKs.\n\n#### `point_in_time_recovery`\n\n* `enabled` - (Required) Whether to enable point-in-time recovery - note that it can take up to 10 minutes to enable for new tables. If the `point_in_time_recovery` block is not provided then this defaults to `false`.\n\n### A note about attributes\n\nOnly define attributes on the table object that are going to be used as:\n\n* Table hash key or range key\n* LSI or GSI hash key or range key\n\nThe DynamoDB API expects attribute structure (name and type) to be\npassed along when creating or updating GSI/LSIs or creating the initial\ntable. In these cases it expects the Hash / Range keys to be provided;\nbecause these get re-used in numerous places (i.e the table's range key\ncould be a part of one or more GSIs), they are stored on the table\nobject to prevent duplication and increase consistency. If you add\nattributes here that are not used in these scenarios it can cause an\ninfinite loop in planning.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The arn of the table\n* `id` - The name of the table\n* `stream_arn` - The ARN of the Table Stream. Only available when `stream_enabled = true`\n* `stream_label` - A timestamp, in ISO 8601 format, for this stream. Note that this timestamp is not\n  a unique identifier for the stream on its own. However, the combination of AWS customer ID,\n  table name and this field is guaranteed to be unique.\n  It can be used for creating CloudWatch Alarms. Only available when `stream_enabled = true`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nDynamoDB tables can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_dynamodb_table.basic-dynamodb-table GameScores\n```\n",
    "basename": "dynamodb_table.html"
  },
  "dynamodb_table_item.html": {
    "subcategory": "DynamoDB",
    "layout": "aws",
    "page_title": "AWS: aws_dynamodb_table_item",
    "description": "Provides a DynamoDB table item resource",
    "preview": "# Resource: aws_dynamodb_table_item\n\nProvides a DynamoDB table item …",
    "content": "\n\n# Resource: aws_dynamodb_table_item\n\nProvides a DynamoDB table item resource\n\n-> **Note:** This resource is not meant to be used for managing large amounts of data in your table, it is not designed to scale.\n  You should perform **regular backups** of all data in the table, see [AWS docs for more](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/BackupRestore.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_dynamodb_table_item\" \"example\" {\n  table_name = aws_dynamodb_table.example.name\n  hash_key   = aws_dynamodb_table.example.hash_key\n\n  item = <<ITEM\n{\n  \"exampleHashKey\": {\"S\": \"something\"},\n  \"one\": {\"N\": \"11111\"},\n  \"two\": {\"N\": \"22222\"},\n  \"three\": {\"N\": \"33333\"},\n  \"four\": {\"N\": \"44444\"}\n}\nITEM\n}\n\nresource \"aws_dynamodb_table\" \"example\" {\n  name           = \"example-name\"\n  read_capacity  = 10\n  write_capacity = 10\n  hash_key       = \"exampleHashKey\"\n\n  attribute {\n    name = \"exampleHashKey\"\n    type = \"S\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `table_name` - (Required) The name of the table to contain the item.\n* `hash_key` - (Required) Hash key to use for lookups and identification of the item\n* `range_key` - (Optional) Range key to use for lookups and identification of the item. Required if there is range key defined in the table.\n* `item` - (Required) JSON representation of a map of attribute name/value pairs, one for each attribute.\n  Only the primary key attributes are required; you can optionally provide other attribute name-value pairs for the item.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n## Import\n\nDynamoDB table items cannot be imported.\n",
    "basename": "dynamodb_table_item.html"
  },
  "dynamodb_tag.html": {
    "subcategory": "DynamoDB",
    "layout": "aws",
    "page_title": "AWS: aws_dynamodb_tag",
    "description": "Manages an individual DynamoDB resource tag",
    "preview": "# Resource: aws_dynamodb_tag\n\nManages an individual DynamoDB …",
    "content": "\n\n# Resource: aws_dynamodb_tag\n\nManages an individual DynamoDB resource tag. This resource should only be used in cases where DynamoDB resources are created outside Terraform (e.g., Table replicas in other regions).\n\n~> **NOTE:** This tagging resource should not be combined with the Terraform resource for managing the parent resource. For example, using `aws_dynamodb_table` and `aws_dynamodb_tag` to manage tags of the same DynamoDB Table in the same region will cause a perpetual difference where the `aws_dynamodb_cluster` resource will try to remove the tag being added by the `aws_dynamodb_tag` resource.\n\n~> **NOTE:** This tagging resource does not use the [provider `ignore_tags` configuration](/docs/providers/aws/index.html#ignore_tags).\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  region = \"us-west-2\"\n}\n\nprovider \"aws\" {\n  alias  = \"replica\"\n  region = \"us-east-1\"\n}\n\ndata \"aws_region\" \"replica\" {\n  provider = \"aws.replica\"\n}\n\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_dynamodb_table\" \"example\" {\n  # ... other configuration ...\n\n  replica {\n    region_name = data.aws_region.replica.name\n  }\n}\n\nresource \"aws_dynamodb_tag\" \"test\" {\n  provider = \"aws.replica\"\n\n  resource_arn = replace(aws_dynamodb_table.test.arn, data.aws_region.current.name, data.aws_region.replica.name)\n  key          = \"testkey\"\n  value        = \"testvalue\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resource_arn` - (Required) Amazon Resource Name (ARN) of the DynamoDB resource to tag.\n* `key` - (Required) Tag name.\n* `value` - (Required) Tag value.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - DynamoDB resource identifier and key, separated by a comma (`,`)\n\n## Import\n\n`aws_dynamodb_tag` can be imported by using the DynamoDB resource identifier and key, separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_dynamodb_tag.example arn:aws:dynamodb:us-east-1:123456789012:table/example,Name\n```\n",
    "basename": "dynamodb_tag.html"
  },
  "ebs_default_kms_key.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ebs_default_kms_key",
    "description": "Manages the default customer master key (CMK) that your AWS account uses to encrypt EBS volumes.",
    "preview": "# Resource: aws_ebs_default_kms_key\n\nProvides a resource to manage …",
    "content": "\n\n# Resource: aws_ebs_default_kms_key\n\nProvides a resource to manage the default customer master key (CMK) that your AWS account uses to encrypt EBS volumes.\n\nYour AWS account has an AWS-managed default CMK that is used for encrypting an EBS volume when no CMK is specified in the API call that creates the volume.\nBy using the `aws_ebs_default_kms_key` resource, you can specify a customer-managed CMK to use in place of the AWS-managed default CMK.\n\n~> **NOTE:** Creating an `aws_ebs_default_kms_key` resource does not enable default EBS encryption. Use the [`aws_ebs_encryption_by_default`](ebs_encryption_by_default.html) to enable default EBS encryption.\n\n~> **NOTE:** Destroying this resource will reset the default CMK to the account's AWS-managed default CMK for EBS.\n\n## Example Usage\n\n```terraform\nresource \"aws_ebs_default_kms_key\" \"example\" {\n  key_arn = aws_kms_key.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `key_arn` - (Required, ForceNew) The ARN of the AWS Key Management Service (AWS KMS) customer master key (CMK) to use to encrypt the EBS volume.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nThe EBS default KMS CMK can be imported with the KMS key ARN, e.g.,\n\n```console\n$ terraform import aws_ebs_default_kms_key.example arn:aws:kms:us-east-1:123456789012:key/abcd-1234\n```\n",
    "basename": "ebs_default_kms_key.html"
  },
  "ebs_encryption_by_default.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ebs_encryption_by_default",
    "description": "Manages whether default EBS encryption is enabled for your AWS account in the current AWS region.",
    "preview": "# Resource: aws_ebs_encryption_by_default\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_ebs_encryption_by_default\n\nProvides a resource to manage whether default EBS encryption is enabled for your AWS account in the current AWS region. To manage the default KMS key for the region, see the [`aws_ebs_default_kms_key` resource](/docs/providers/aws/r/ebs_default_kms_key.html).\n\n~> **NOTE:** Removing this Terraform resource disables default EBS encryption.\n\n## Example Usage\n\n```terraform\nresource \"aws_ebs_encryption_by_default\" \"example\" {\n  enabled = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `enabled` - (Optional) Whether or not default EBS encryption is enabled. Valid values are `true` or `false`. Defaults to `true`.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nDefault EBS encryption state can be imported, e.g.,\n\n```\n$ terraform import aws_ebs_encryption_by_default.example default\n```",
    "basename": "ebs_encryption_by_default.html"
  },
  "ebs_snapshot.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ebs_snapshot",
    "description": "Provides an elastic block storage snapshot resource.",
    "preview": "# Resource: aws_ebs_snapshot\n\nCreates a Snapshot of an EBS Volume.\n …",
    "content": "\n\n# Resource: aws_ebs_snapshot\n\nCreates a Snapshot of an EBS Volume.\n\n## Example Usage\n\n```terraform\nresource \"aws_ebs_volume\" \"example\" {\n  availability_zone = \"us-west-2a\"\n  size              = 40\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n\nresource \"aws_ebs_snapshot\" \"example_snapshot\" {\n  volume_id = aws_ebs_volume.example.id\n\n  tags = {\n    Name = \"HelloWorld_snap\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `volume_id` - (Required) The Volume ID of which to make a snapshot.\n* `description` - (Optional) A description of what the snapshot is.\n* `tags` - (Optional) A map of tags to assign to the snapshot. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Timeouts\n\n`aws_ebs_snapshot` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating the ebs snapshot\n- `delete` - (Default `10 minutes`) Used for deleting the ebs snapshot\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the EBS Snapshot.\n* `id` - The snapshot ID (e.g., snap-59fcb34e).\n* `owner_id` - The AWS account ID of the EBS snapshot owner.\n* `owner_alias` - Value from an Amazon-maintained list (`amazon`, `aws-marketplace`, `microsoft`) of snapshot owners.\n* `encrypted` - Whether the snapshot is encrypted.\n* `volume_size` - The size of the drive in GiBs.\n* `kms_key_id` - The ARN for the KMS encryption key.\n* `data_encryption_key_id` - The data encryption key identifier for the snapshot.\n* `tags` - A map of tags for the snapshot.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEBS Snapshot can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ebs_snapshot.id snap-049df61146c4d7901\n```\n",
    "basename": "ebs_snapshot.html"
  },
  "ebs_snapshot_copy.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ebs_snapshot_copy",
    "description": "Duplicates an existing Amazon snapshot",
    "preview": "# Resource: aws_ebs_snapshot_copy\n\nCreates a Snapshot of a snapshot. …",
    "content": "\n\n# Resource: aws_ebs_snapshot_copy\n\nCreates a Snapshot of a snapshot.\n\n## Example Usage\n\n```terraform\nresource \"aws_ebs_volume\" \"example\" {\n  availability_zone = \"us-west-2a\"\n  size              = 40\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n\nresource \"aws_ebs_snapshot\" \"example_snapshot\" {\n  volume_id = aws_ebs_volume.example.id\n\n  tags = {\n    Name = \"HelloWorld_snap\"\n  }\n}\n\nresource \"aws_ebs_snapshot_copy\" \"example_copy\" {\n  source_snapshot_id = aws_ebs_snapshot.example_snapshot.id\n  source_region      = \"us-west-2\"\n\n  tags = {\n    Name = \"HelloWorld_copy_snap\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) A description of what the snapshot is.\n* `encrypted` - Whether the snapshot is encrypted.\n* `kms_key_id` - The ARN for the KMS encryption key.\n* `source_snapshot_id` The ARN for the snapshot to be copied.\n* `source_region` The region of the source snapshot.\n* `tags` - A map of tags for the snapshot. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the EBS Snapshot.\n* `id` - The snapshot ID (e.g., snap-59fcb34e).\n* `owner_id` - The AWS account ID of the snapshot owner.\n* `owner_alias` - Value from an Amazon-maintained list (`amazon`, `aws-marketplace`, `microsoft`) of snapshot owners.\n* `encrypted` - Whether the snapshot is encrypted.\n* `volume_size` - The size of the drive in GiBs.\n* `kms_key_id` - The ARN for the KMS encryption key.\n* `data_encryption_key_id` - The data encryption key identifier for the snapshot.\n* `source_snapshot_id` The ARN of the copied snapshot.\n* `source_region` The region of the source snapshot.\n* `tags` - A map of tags for the snapshot.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "ebs_snapshot_copy.html"
  },
  "ebs_snapshot_import.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ebs_snapshot_import",
    "description": "Provides an elastic block storage snapshot import resource.",
    "preview": "# Resource: aws_ebs_snapshot_import\n\nImports a disk image from S3 as …",
    "content": "\n\n# Resource: aws_ebs_snapshot_import\n\nImports a disk image from S3 as a Snapshot.\n\n## Example Usage\n\n```terraform\nresource \"aws_ebs_snapshot_import\" \"example\" {\n  disk_container {\n    format = \"VHD\"\n    user_bucket {\n      s3_bucket = \"disk-images\"\n      s3_key    = \"source.vhd\"\n    }\n  }\n\n  role_name = \"disk-image-import\"\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n```\n\n## Argument Reference\n\n\nThe following arguments are supported:\n\n* `client_data` - (Optional) The client-specific data. Detailed below.\n* `description` - (Optional) The description string for the import snapshot task.\n* `disk_container` - (Required) Information about the disk container. Detailed below.\n* `encrypted` - (Optional) Specifies whether the destination snapshot of the imported image should be encrypted. The default KMS key for EBS is used unless you specify a non-default KMS key using KmsKeyId.\n* `kms_key_id` - (Optional) An identifier for the symmetric KMS key to use when creating the encrypted snapshot. This parameter is only required if you want to use a non-default KMS key; if this parameter is not specified, the default KMS key for EBS is used. If a KmsKeyId is specified, the Encrypted flag must also be set.\n* `role_name` - (Optional) The name of the IAM Role the VM Import/Export service will assume. This role needs certain permissions. See https://docs.aws.amazon.com/vm-import/latest/userguide/vmie_prereqs.html#vmimport-role. Default: `vmimport`\n* `tags` - (Optional) A map of tags to assign to the snapshot.\n\n### client_data Configuration Block\n\n* `comment` - (Optional) A user-defined comment about the disk upload.\n* `upload_start` - (Optional) The time that the disk upload starts.\n* `upload_end` - (Optional) The time that the disk upload ends.\n* `upload_size` - (Optional) The size of the uploaded disk image, in GiB.\n\n### disk_container Configuration Block\n\n* `description` - (Optional) The description of the disk image being imported.\n* `format` - (Required) The format of the disk image being imported. One of `VHD` or `VMDK`.\n* `url` - (Optional) The URL to the Amazon S3-based disk image being imported. It can either be a https URL (https://..) or an Amazon S3 URL (s3://..). One of `url` or `user_bucket` must be set.\n* `user_bucket` - (Optional) The Amazon S3 bucket for the disk image. One of `url` or `user_bucket` must be set. Detailed below.\n\n### user_bucket Configuration Block\n\n* `s3_bucket` - The name of the Amazon S3 bucket where the disk image is located.\n* `s3_key` - The file name of the disk image.\n\n### Timeouts\n\n`aws_ebs_snapshot_import` provides the following\n[Timeouts](/docs/configuration/resources.html#timeouts) configuration options:\n\n- `create` - (Default `60 minutes`) Used for importing the EBS snapshot\n- `delete` - (Default `10 minutes`) Used for deleting the EBS snapshot\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the EBS Snapshot.\n* `id` - The snapshot ID (e.g., snap-59fcb34e).\n* `owner_id` - The AWS account ID of the EBS snapshot owner.\n* `owner_alias` - Value from an Amazon-maintained list (`amazon`, `aws-marketplace`, `microsoft`) of snapshot owners.\n* `volume_size` - The size of the drive in GiBs.\n* `data_encryption_key_id` - The data encryption key identifier for the snapshot.\n* `tags` - A map of tags for the snapshot.\n\n",
    "basename": "ebs_snapshot_import.html"
  },
  "ebs_volume.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ebs_volume",
    "description": "Provides an elastic block storage resource.",
    "preview": "# Resource: aws_ebs_volume\n\nManages a single EBS volume.\n\n## Example …",
    "content": "\n\n# Resource: aws_ebs_volume\n\nManages a single EBS volume.\n\n## Example Usage\n\n```terraform\nresource \"aws_ebs_volume\" \"example\" {\n  availability_zone = \"us-west-2a\"\n  size              = 40\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n```\n\n~> **NOTE**: At least one of `size` or `snapshot_id` is required when specifying an EBS volume\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `availability_zone` - (Required) The AZ where the EBS volume will exist.\n* `encrypted` - (Optional) If true, the disk will be encrypted.\n* `iops` - (Optional) The amount of IOPS to provision for the disk. Only valid for `type` of `io1`, `io2` or `gp3`.\n* `multi_attach_enabled` - (Optional) Specifies whether to enable Amazon EBS Multi-Attach. Multi-Attach is supported exclusively on `io1` volumes.\n* `size` - (Optional) The size of the drive in GiBs.\n* `snapshot_id` (Optional) A snapshot to base the EBS volume off of.\n* `outpost_arn` - (Optional) The Amazon Resource Name (ARN) of the Outpost.\n* `type` - (Optional) The type of EBS volume. Can be `standard`, `gp2`, `gp3`, `io1`, `io2`, `sc1` or `st1` (Default: `gp2`).\n* `kms_key_id` - (Optional) The ARN for the KMS encryption key. When specifying `kms_key_id`, `encrypted` needs to be set to true. Note: Terraform must be running with credentials which have the `GenerateDataKeyWithoutPlaintext` permission on the specified KMS key as required by the [EBS KMS CMK volume provisioning process](https://docs.aws.amazon.com/kms/latest/developerguide/services-ebs.html#ebs-cmk) to prevent a volume from being created and almost immediately deleted.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `throughput` - (Optional) The throughput that the volume supports, in MiB/s. Only valid for `type` of `gp3`.\n\n~> **NOTE**: When changing the `size`, `iops` or `type` of an instance, there are [considerations](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/considerations.html) to be aware of.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The volume ID (e.g., vol-59fcb34e).\n* `arn` - The volume ARN (e.g., arn:aws:ec2:us-east-1:0123456789012:volume/vol-59fcb34e).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEBS Volumes can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ebs_volume.id vol-049df61146c4d7901\n```\n",
    "basename": "ebs_volume.html"
  },
  "ec2_availability_zone_group.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_availability_zone_group",
    "description": "Manages an EC2 Availability Zone Group.",
    "preview": "# Resource: aws_ec2_availability_zone_group\n\nManages an EC2 …",
    "content": "\n\n# Resource: aws_ec2_availability_zone_group\n\nManages an EC2 Availability Zone Group, such as updating its opt-in status.\n\n~> **NOTE:** This is an advanced Terraform resource. Terraform will automatically assume management of the EC2 Availability Zone Group without import and perform no actions on removal from configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_availability_zone_group\" \"example\" {\n  group_name    = \"us-west-2-lax-1\"\n  opt_in_status = \"opted-in\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `group_name` - (Required) Name of the Availability Zone Group.\n* `opt_in_status` - (Required) Indicates whether to enable or disable Availability Zone Group. Valid values: `opted-in` or `not-opted-in`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Name of the Availability Zone Group.\n\n## Import\n\nEC2 Availability Zone Groups can be imported using the group name, e.g.,\n\n```\n$ terraform import aws_ec2_availability_zone_group.example us-west-2-lax-1\n```\n",
    "basename": "ec2_availability_zone_group.html"
  },
  "ec2_capacity_reservation.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_capacity_reservation",
    "description": "Provides an EC2 Capacity Reservation. This allows you to reserve capacity for your Amazon EC2 instances in a specific Availability Zone for any duration.",
    "preview": "# Resource: aws_ec2_capacity_reservation\n\nProvides an EC2 Capacity …",
    "content": "\n\n# Resource: aws_ec2_capacity_reservation\n\nProvides an EC2 Capacity Reservation. This allows you to reserve capacity for your Amazon EC2 instances in a specific Availability Zone for any duration.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_capacity_reservation\" \"default\" {\n  instance_type     = \"t2.micro\"\n  instance_platform = \"Linux/UNIX\"\n  availability_zone = \"eu-west-1a\"\n  instance_count    = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `availability_zone` - (Required) The Availability Zone in which to create the Capacity Reservation.\n* `ebs_optimized` - (Optional) Indicates whether the Capacity Reservation supports EBS-optimized instances.\n* `end_date` - (Optional) The date and time at which the Capacity Reservation expires. When a Capacity Reservation expires, the reserved capacity is released and you can no longer launch instances into it. Valid values: [RFC3339 time string](https://tools.ietf.org/html/rfc3339#section-5.8) (`YYYY-MM-DDTHH:MM:SSZ`)\n* `end_date_type` - (Optional) Indicates the way in which the Capacity Reservation ends. Specify either `unlimited` or `limited`.\n* `ephemeral_storage` - (Optional) Indicates whether the Capacity Reservation supports instances with temporary, block-level storage.\n* `instance_count` - (Required) The number of instances for which to reserve capacity.\n* `instance_match_criteria` - (Optional) Indicates the type of instance launches that the Capacity Reservation accepts. Specify either `open` or `targeted`.\n* `instance_platform` - (Required) The type of operating system for which to reserve capacity. Valid options are `Linux/UNIX`, `Red Hat Enterprise Linux`, `SUSE Linux`, `Windows`, `Windows with SQL Server`, `Windows with SQL Server Enterprise`, `Windows with SQL Server Standard` or `Windows with SQL Server Web`.\n* `instance_type` - (Required) The instance type for which to reserve capacity.\n* `outpost_arn` - (Optional) The Amazon Resource Name (ARN) of the Outpost on which to create the Capacity Reservation.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `tenancy` - (Optional) Indicates the tenancy of the Capacity Reservation. Specify either `default` or `dedicated`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Capacity Reservation ID.\n* `owner_id` - The ID of the AWS account that owns the Capacity Reservation.\n* `arn` - The ARN of the Capacity Reservation.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block)\n\n## Import\n\nCapacity Reservations can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ec2_capacity_reservation.web cr-0123456789abcdef0\n```\n",
    "basename": "ec2_capacity_reservation.html"
  },
  "ec2_carrier_gateway.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_carrier_gateway",
    "description": "Manages an EC2 Carrier Gateway.",
    "preview": "# Resource: aws_ec2_carrier_gateway\n\nManages an EC2 Carrier Gateway. …",
    "content": "\n\n# Resource: aws_ec2_carrier_gateway\n\nManages an EC2 Carrier Gateway. See the AWS [documentation](https://docs.aws.amazon.com/vpc/latest/userguide/Carrier_Gateway.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_carrier_gateway\" \"example\" {\n  vpc_id = aws_vpc.example.id\n\n  tags = {\n    Name = \"example-carrier-gateway\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_id` - (Required) The ID of the VPC to associate with the carrier gateway.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the carrier gateway.\n* `id` - The ID of the carrier gateway.\n* `owner_id` - The AWS account ID of the owner of the carrier gateway.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_ec2_carrier_gateway` can be imported using the carrier gateway's ID,\ne.g.,\n\n```\n$ terraform import aws_ec2_carrier_gateway.example cgw-12345\n```\n",
    "basename": "ec2_carrier_gateway.html"
  },
  "ec2_client_vpn_authorization_rule.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_client_vpn_authorization_rule",
    "description": "Provides authorization rules for AWS Client VPN endpoints.",
    "preview": "# Resource: aws_ec2_client_vpn_authorization_rule\n\nProvides …",
    "content": "\n\n# Resource: aws_ec2_client_vpn_authorization_rule\n\nProvides authorization rules for AWS Client VPN endpoints. For more information on usage, please see the\n[AWS Client VPN Administrator's Guide](https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/what-is.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_client_vpn_authorization_rule\" \"example\" {\n  client_vpn_endpoint_id = aws_ec2_client_vpn_endpoint.example.id\n  target_network_cidr    = aws_subnet.example.cidr_block\n  authorize_all_groups   = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `client_vpn_endpoint_id` - (Required) The ID of the Client VPN endpoint.\n* `target_network_cidr` - (Required) The IPv4 address range, in CIDR notation, of the network to which the authorization rule applies.\n* `access_group_id` - (Optional) The ID of the group to which the authorization rule grants access. One of `access_group_id` or `authorize_all_groups` must be set.\n* `authorize_all_groups` - (Optional) Indicates whether the authorization rule grants access to all clients. One of `access_group_id` or `authorize_all_groups` must be set.\n* `description` - (Optional) A brief description of the authorization rule.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nAWS Client VPN authorization rules can be imported using the endpoint ID and target network CIDR. If there is a specific group name that is included as well. All values are separated by a `,`.\n\n```\n$ terraform import aws_ec2_client_vpn_authorization_rule.example cvpn-endpoint-0ac3a1abbccddd666,10.1.0.0/24\n```\n\n```\n$ terraform import aws_ec2_client_vpn_authorization_rule.example cvpn-endpoint-0ac3a1abbccddd666,10.1.0.0/24,team-a\n```\n",
    "basename": "ec2_client_vpn_authorization_rule.html"
  },
  "ec2_client_vpn_endpoint.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_client_vpn_endpoint",
    "description": "Provides an AWS Client VPN endpoint for OpenVPN clients.",
    "preview": "# Resource: aws_ec2_client_vpn_endpoint\n\nProvides an AWS Client VPN …",
    "content": "\n\n# Resource: aws_ec2_client_vpn_endpoint\n\nProvides an AWS Client VPN endpoint for OpenVPN clients. For more information on usage, please see the\n[AWS Client VPN Administrator's Guide](https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/what-is.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_client_vpn_endpoint\" \"example\" {\n  description            = \"terraform-clientvpn-example\"\n  server_certificate_arn = aws_acm_certificate.cert.arn\n  client_cidr_block      = \"10.0.0.0/16\"\n\n  authentication_options {\n    type                       = \"certificate-authentication\"\n    root_certificate_chain_arn = aws_acm_certificate.root_cert.arn\n  }\n\n  connection_log_options {\n    enabled               = true\n    cloudwatch_log_group  = aws_cloudwatch_log_group.lg.name\n    cloudwatch_log_stream = aws_cloudwatch_log_stream.ls.name\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `authentication_options` - (Required) Information about the authentication method to be used to authenticate clients.\n* `client_cidr_block` - (Required) The IPv4 address range, in CIDR notation, from which to assign client IP addresses. The address range cannot overlap with the local CIDR of the VPC in which the associated subnet is located, or the routes that you add manually. The address range cannot be changed after the Client VPN endpoint has been created. The CIDR block should be /22 or greater.\n* `connection_log_options` - (Required) Information about the client connection logging options.\n* `description` - (Optional) A brief description of the Client VPN endpoint.\n* `dns_servers` - (Optional) Information about the DNS servers to be used for DNS resolution. A Client VPN endpoint can have up to two DNS servers. If no DNS server is specified, the DNS address of the VPC that is to be associated with Client VPN endpoint is used as the DNS server.\n* `server_certificate_arn` - (Required) The ARN of the ACM server certificate.\n* `split_tunnel` - (Optional) Indicates whether split-tunnel is enabled on VPN endpoint. Default value is `false`.\n* `self_service_portal` - (Optional) Specify whether to enable the self-service portal for the Client VPN endpoint. Values can be `enabled` or `disabled`. Default value is `disabled`.\n* `tags` - (Optional) A mapping of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `transport_protocol` - (Optional) The transport protocol to be used by the VPN session. Default value is `udp`.\n\n### `authentication_options` Argument Reference\n\nOne of the following arguments must be supplied:\n\n* `active_directory_id` - (Optional) The ID of the Active Directory to be used for authentication if type is `directory-service-authentication`.\n* `root_certificate_chain_arn` - (Optional) The ARN of the client certificate. The certificate must be signed by a certificate authority (CA) and it must be provisioned in AWS Certificate Manager (ACM). Only necessary when type is set to `certificate-authentication`.\n* `saml_provider_arn` - (Optional) The ARN of the IAM SAML identity provider if type is `federated-authentication`.\n* `self_service_saml_provider_arn` - (Optional) The ARN of the IAM SAML identity provider for the self service portal if type is `federated-authentication`.\n* `type` - (Required) The type of client authentication to be used. Specify `certificate-authentication` to use certificate-based authentication, `directory-service-authentication` to use Active Directory authentication, or `federated-authentication` to use Federated Authentication via SAML 2.0.\n\n### `connection_log_options` Argument Reference\n\nOne of the following arguments must be supplied:\n\n* `cloudwatch_log_group` - (Optional) The name of the CloudWatch Logs log group.\n* `cloudwatch_log_stream` - (Optional) The name of the CloudWatch Logs log stream to which the connection data is published.\n* `enabled` - (Required) Indicates whether connection logging is enabled.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the Client VPN endpoint.\n* `dns_name` - The DNS name to be used by clients when establishing their VPN session.\n* `id` - The ID of the Client VPN endpoint.\n* `status` - The current state of the Client VPN endpoint.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAWS Client VPN endpoints can be imported using the `id` value found via `aws ec2 describe-client-vpn-endpoints`, e.g.,\n\n```\n$ terraform import aws_ec2_client_vpn_endpoint.example cvpn-endpoint-0ac3a1abbccddd666\n```\n",
    "basename": "ec2_client_vpn_endpoint.html"
  },
  "ec2_client_vpn_network_association.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_client_vpn_network_association",
    "description": "Provides network associations for AWS Client VPN endpoints.",
    "preview": "# Resource: aws_ec2_client_vpn_network_association\n\nProvides network …",
    "content": "\n\n# Resource: aws_ec2_client_vpn_network_association\n\nProvides network associations for AWS Client VPN endpoints. For more information on usage, please see the\n[AWS Client VPN Administrator's Guide](https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/what-is.html).\n\n## Example Usage\n\n### Using default security group\n\n```terraform\nresource \"aws_ec2_client_vpn_network_association\" \"example\" {\n  client_vpn_endpoint_id = aws_ec2_client_vpn_endpoint.example.id\n  subnet_id              = aws_subnet.example.id\n}\n```\n\n### Using custom security groups\n\n```terraform\nresource \"aws_ec2_client_vpn_network_association\" \"example\" {\n  client_vpn_endpoint_id = aws_ec2_client_vpn_endpoint.example.id\n  subnet_id              = aws_subnet.example.id\n  security_groups        = [aws_security_group.example1.id, aws_security_group.example2.id]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `client_vpn_endpoint_id` - (Required) The ID of the Client VPN endpoint.\n* `subnet_id` - (Required) The ID of the subnet to associate with the Client VPN endpoint.\n* `security_groups` - (Optional) A list of up to five custom security groups to apply to the target network. If not specified, the VPC's default security group is assigned.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique ID of the target network association.\n* `association_id` - The unique ID of the target network association.\n* `security_groups` - The IDs of the security groups applied to the target network association.\n* `status` - The current state of the target network association.\n* `vpc_id` - The ID of the VPC in which the target subnet is located.\n\n## Import\n\nAWS Client VPN network associations can be imported using the endpoint ID and the association ID. Values are separated by a `,`.\n\n```\n$ terraform import aws_ec2_client_vpn_network_association.example cvpn-endpoint-0ac3a1abbccddd666,vpn-assoc-0b8db902465d069ad\n```\n",
    "basename": "ec2_client_vpn_network_association.html"
  },
  "ec2_client_vpn_route.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_client_vpn_route",
    "description": "Provides additional routes for AWS Client VPN endpoints.",
    "preview": "# Resource: aws_ec2_client_vpn_route\n\nProvides additional routes for …",
    "content": "\n\n# Resource: aws_ec2_client_vpn_route\n\nProvides additional routes for AWS Client VPN endpoints. For more information on usage, please see the\n[AWS Client VPN Administrator's Guide](https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/what-is.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_client_vpn_route\" \"example\" {\n  client_vpn_endpoint_id = aws_ec2_client_vpn_endpoint.example.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  target_vpc_subnet_id   = aws_ec2_client_vpn_network_association.example.subnet_id\n}\n\nresource \"aws_ec2_client_vpn_network_association\" \"example\" {\n  client_vpn_endpoint_id = aws_ec2_client_vpn_endpoint.example.id\n  subnet_id              = aws_subnet.example.id\n}\n\nresource \"aws_ec2_client_vpn_endpoint\" \"example\" {\n  description            = \"Example Client VPN endpoint\"\n  server_certificate_arn = aws_acm_certificate.example.arn\n  client_cidr_block      = \"10.0.0.0/16\"\n\n  authentication_options {\n    type                       = \"certificate-authentication\"\n    root_certificate_chain_arn = aws_acm_certificate.example.arn\n  }\n\n  connection_log_options {\n    enabled = false\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `client_vpn_endpoint_id` - (Required) The ID of the Client VPN endpoint.\n* `destination_cidr_block` - (Required) The IPv4 address range, in CIDR notation, of the route destination.\n* `description` - (Optional) A brief description of the authorization rule.\n* `target_vpc_subnet_id` - (Required) The ID of the Subnet to route the traffic through. It must already be attached to the Client VPN.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Client VPN endpoint.\n* `origin` - Indicates how the Client VPN route was added. Will be `add-route` for routes created by this resource.\n* `type` - The type of the route.\n\n## Import\n\nAWS Client VPN routes can be imported using the endpoint ID, target subnet ID, and destination CIDR block. All values are separated by a `,`.\n\n```\n$ terraform import aws_ec2_client_vpn_route.example cvpn-endpoint-1234567890abcdef,subnet-9876543210fedcba,10.1.0.0/24\n```\n",
    "basename": "ec2_client_vpn_route.html"
  },
  "ec2_fleet.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_fleet",
    "description": "Provides a resource to manage EC2 Fleets",
    "preview": "# Resource: aws_ec2_fleet\n\nProvides a resource to manage EC2 Fleets. …",
    "content": "\n\n# Resource: aws_ec2_fleet\n\nProvides a resource to manage EC2 Fleets.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_fleet\" \"example\" {\n  launch_template_config {\n    launch_template_specification {\n      launch_template_id = aws_launch_template.example.id\n      version            = aws_launch_template.example.latest_version\n    }\n  }\n\n  target_capacity_specification {\n    default_target_capacity_type = \"spot\"\n    total_target_capacity        = 5\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `launch_template_config` - (Required) Nested argument containing EC2 Launch Template configurations. Defined below.\n* `target_capacity_specification` - (Required) Nested argument containing target capacity configurations. Defined below.\n* `excess_capacity_termination_policy` - (Optional) Whether running instances should be terminated if the total target capacity of the EC2 Fleet is decreased below the current size of the EC2. Valid values: `no-termination`, `termination`. Defaults to `termination`.\n* `on_demand_options` - (Optional) Nested argument containing On-Demand configurations. Defined below.\n* `replace_unhealthy_instances` - (Optional) Whether EC2 Fleet should replace unhealthy instances. Defaults to `false`.\n* `spot_options` - (Optional) Nested argument containing Spot configurations. Defined below.\n* `tags` - (Optional) Map of Fleet tags. To tag instances at launch, specify the tags in the Launch Template. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `terminate_instances` - (Optional) Whether to terminate instances for an EC2 Fleet if it is deleted successfully. Defaults to `false`.\n* `terminate_instances_with_expiration` - (Optional) Whether running instances should be terminated when the EC2 Fleet expires. Defaults to `false`.\n* `type` - (Optional) The type of request. Indicates whether the EC2 Fleet only requests the target capacity, or also attempts to maintain it. Valid values: `maintain`, `request`. Defaults to `maintain`.\n\n### launch_template_config\n\n* `launch_template_specification` - (Required) Nested argument containing EC2 Launch Template to use. Defined below.\n* `override` - (Optional) Nested argument(s) containing parameters to override the same parameters in the Launch Template. Defined below.\n\n#### launch_template_specification\n\n~> *NOTE:* Either `launch_template_id` or `launch_template_name` must be specified.\n\n* `version` - (Required) Version number of the launch template.\n* `launch_template_id` - (Optional) ID of the launch template.\n* `launch_template_name` - (Optional) Name of the launch template.\n\n#### override\n\nExample:\n\n```terraform\nresource \"aws_ec2_fleet\" \"example\" {\n  # ... other configuration ...\n\n  launch_template_config {\n    # ... other configuration ...\n\n    override {\n      instance_type     = \"m4.xlarge\"\n      weighted_capacity = 1\n    }\n\n    override {\n      instance_type     = \"m4.2xlarge\"\n      weighted_capacity = 2\n    }\n  }\n}\n```\n\n* `availability_zone` - (Optional) Availability Zone in which to launch the instances.\n* `instance_type` - (Optional) Instance type.\n* `max_price` - (Optional) Maximum price per unit hour that you are willing to pay for a Spot Instance.\n* `priority` - (Optional) Priority for the launch template override. If `on_demand_options` `allocation_strategy` is set to `prioritized`, EC2 Fleet uses priority to determine which launch template override to use first in fulfilling On-Demand capacity. The highest priority is launched first. The lower the number, the higher the priority. If no number is set, the launch template override has the lowest priority. Valid values are whole numbers starting at 0.\n* `subnet_id` - (Optional) ID of the subnet in which to launch the instances.\n* `weighted_capacity` - (Optional) Number of units provided by the specified instance type.\n\n### on_demand_options\n\n* `allocation_strategy` - (Optional) The order of the launch template overrides to use in fulfilling On-Demand capacity. Valid values: `lowestPrice`, `prioritized`. Default: `lowestPrice`.\n\n### spot_options\n\n* `allocation_strategy` - (Optional) How to allocate the target capacity across the Spot pools. Valid values: `diversified`, `lowestPrice`. Default: `lowestPrice`.\n* `instance_interruption_behavior` - (Optional) Behavior when a Spot Instance is interrupted. Valid values: `hibernate`, `stop`, `terminate`. Default: `terminate`.\n* `instance_pools_to_use_count` - (Optional) Number of Spot pools across which to allocate your target Spot capacity. Valid only when Spot `allocation_strategy` is set to `lowestPrice`. Default: `1`.\n* `maintenance_strategies` - (Optional) Nested argument containing maintenance strategies for managing your Spot Instances that are at an elevated risk of being interrupted. Defined below.\n\n\n### maintenance_strategies\n\n* `capacity_rebalance` - (Optional) Nested argument containing the capacity rebalance for your fleet request. Defined below.\n\n### capacity_rebalance\n\n* `replacement_strategy` - (Optional) The replacement strategy to use. Only available for fleets of `type` set to `maintain`. Valid values: `launch`.\n\n\n\n### target_capacity_specification\n\n* `default_target_capacity_type` - (Required) Default target capacity type. Valid values: `on-demand`, `spot`.\n* `total_target_capacity` - (Required) The number of units to request, filled using `default_target_capacity_type`.\n* `on_demand_target_capacity` - (Optional) The number of On-Demand units to request.\n* `spot_target_capacity` - (Optional) The number of Spot units to request.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Fleet identifier\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_ec2_fleet` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `10m`) How long to wait for a fleet to be active.\n* `update` - (Default `10m`) How long to wait for a fleet to be modified.\n* `delete` - (Default `10m`) How long to wait for a fleet to be deleted. If `terminate_instances` is `true`, how long to wait for instances to terminate.\n\n## Import\n\n`aws_ec2_fleet` can be imported by using the Fleet identifier, e.g.,\n\n```\n$ terraform import aws_ec2_fleet.example fleet-b9b55d27-c5fc-41ac-a6f3-48fcc91f080c\n```\n",
    "basename": "ec2_fleet.html"
  },
  "ec2_host.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_host",
    "description": "Provides an EC2 Host resource. This allows Dedicated Hosts to be allocated, modified, and released.",
    "preview": "# Resource: aws_ec2_host\n\nProvides an EC2 Host resource. This allows …",
    "content": "\n\n# Resource: aws_ec2_host\n\nProvides an EC2 Host resource. This allows Dedicated Hosts to be allocated, modified, and released.\n\n## Example Usage\n\n```terraform\n# Create a new host with instance type of c5.18xlarge with Auto Placement\n# and Host Recovery enabled.\nresource \"aws_ec2_host\" \"test\" {\n  instance_type     = \"c5.18xlarge\"\n  availability_zone = \"us-west-2a\"\n  host_recovery     = \"on\"\n  auto_placement    = \"on\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `auto_placement` - (Optional) Indicates whether the host accepts any untargeted instance launches that match its instance type configuration, or if it only accepts Host tenancy instance launches that specify its unique host ID. Valid values: `on`, `off`. Default: `on`.\n* `availability_zone` - (Required) The Availability Zone in which to allocate the Dedicated Host.\n* `host_recovery` - (Optional) Indicates whether to enable or disable host recovery for the Dedicated Host. Valid values: `on`, `off`. Default: `off`.\n* `instance_family` - (Optional) Specifies the instance family to be supported by the Dedicated Hosts. If you specify an instance family, the Dedicated Hosts support multiple instance types within that instance family. Exactly one of `instance_family` or `instance_type` must be specified.\n* `instance_type` - (Optional) Specifies the instance type to be supported by the Dedicated Hosts. If you specify an instance type, the Dedicated Hosts support instances of the specified instance type only.  Exactly one of `instance_family` or `instance_type` must be specified.\n* `tags` - (Optional) Map of tags to assign to this resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the allocated Dedicated Host. This is used to launch an instance onto a specific host.\n* `arn` - The ARN of the Dedicated Host.\n* `owner_id` - The ID of the AWS account that owns the Dedicated Host.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nHosts can be imported using the host `id`, e.g.,\n\n```\n$ terraform import aws_ec2_host.example h-0385a99d0e4b20cbb\n```\n",
    "basename": "ec2_host.html"
  },
  "ec2_local_gateway_route.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_local_gateway_route",
    "description": "Manages an EC2 Local Gateway Route",
    "preview": "# Resource: aws_ec2_local_gateway_route\n\nManages an EC2 Local …",
    "content": "\n\n# Resource: aws_ec2_local_gateway_route\n\nManages an EC2 Local Gateway Route. More information can be found in the [Outposts User Guide](https://docs.aws.amazon.com/outposts/latest/userguide/outposts-networking-components.html#routing).\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_local_gateway_route\" \"example\" {\n  destination_cidr_block                   = \"172.16.0.0/16\"\n  local_gateway_route_table_id             = data.aws_ec2_local_gateway_route_table.example.id\n  local_gateway_virtual_interface_group_id = data.aws_ec2_local_gateway_virtual_interface_group.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `destination_cidr_block` - (Required) IPv4 CIDR range used for destination matches. Routing decisions are based on the most specific match.\n* `local_gateway_route_table_id` - (Required) Identifier of EC2 Local Gateway Route Table.\n* `local_gateway_virtual_interface_group_id` - (Required) Identifier of EC2 Local Gateway Virtual Interface Group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Local Gateway Route Table identifier and destination CIDR block separated by underscores (`_`)\n\n## Import\n\n`aws_ec2_local_gateway_route` can be imported by using the EC2 Local Gateway Route Table identifier and destination CIDR block separated by underscores (`_`), e.g.,\n\n```\n$ terraform import aws_ec2_local_gateway_route.example lgw-rtb-12345678_172.16.0.0/16\n```\n",
    "basename": "ec2_local_gateway_route.html"
  },
  "ec2_local_gateway_route_table_vpc_association.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_local_gateway_route_table_vpc_association",
    "description": "Manages an EC2 Local Gateway Route Table VPC Association",
    "preview": "# Resource: aws_ec2_local_gateway_route_table_vpc_association\n …",
    "content": "\n\n# Resource: aws_ec2_local_gateway_route_table_vpc_association\n\nManages an EC2 Local Gateway Route Table VPC Association. More information can be found in the [Outposts User Guide](https://docs.aws.amazon.com/outposts/latest/userguide/outposts-local-gateways.html#vpc-associations).\n\n## Example Usage\n\n```terraform\ndata \"aws_ec2_local_gateway_route_table\" \"example\" {\n  outpost_arn = \"arn:aws:outposts:us-west-2:123456789012:outpost/op-1234567890abcdef\"\n}\n\nresource \"aws_vpc\" \"example\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_ec2_local_gateway_route_table_vpc_association\" \"example\" {\n  local_gateway_route_table_id = data.aws_ec2_local_gateway_route_table.example.id\n  vpc_id                       = aws_vpc.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `local_gateway_route_table_id` - (Required) Identifier of EC2 Local Gateway Route Table.\n* `vpc_id` - (Required) Identifier of EC2 VPC.\n\nThe following arguments are optional:\n\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier of EC2 Local Gateway Route Table VPC Association.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_ec2_local_gateway_route_table_vpc_association` can be imported by using the Local Gateway Route Table VPC Association identifier, e.g.,\n\n```\n$ terraform import aws_ec2_local_gateway_route_table_vpc_association.example lgw-vpc-assoc-1234567890abcdef\n```\n",
    "basename": "ec2_local_gateway_route_table_vpc_association.html"
  },
  "ec2_managed_prefix_list.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_managed_prefix_list",
    "description": "Provides a managed prefix list resource.",
    "preview": "# Resource: aws_ec2_managed_prefix_list\n\nProvides a managed prefix …",
    "content": "\n\n# Resource: aws_ec2_managed_prefix_list\n\nProvides a managed prefix list resource.\n\n~> **NOTE on Managed Prefix Lists and Managed Prefix List Entries:** Terraform\ncurrently provides both a standalone [Managed Prefix List Entry resource](ec2_managed_prefix_list_entry.html) (a single entry),\nand a Managed Prefix List resource with entries defined in-line. At this time you\ncannot use a Managed Prefix List with in-line rules in conjunction with any Managed\nPrefix List Entry resources. Doing so will cause a conflict of entries and will overwrite entries.\n\n~> **NOTE on `max_entries`:** When you reference a Prefix List in a resource,\nthe maximum number of entries for the prefix lists counts as the same number of rules\nor entries for the resource. For example, if you create a prefix list with a maximum\nof 20 entries and you reference that prefix list in a security group rule, this counts\nas 20 rules for the security group.\n\n## Example Usage\n\nBasic usage\n\n```terraform\nresource \"aws_ec2_managed_prefix_list\" \"example\" {\n  name           = \"All VPC CIDR-s\"\n  address_family = \"IPv4\"\n  max_entries    = 5\n\n  entry {\n    cidr        = aws_vpc.example.cidr_block\n    description = \"Primary\"\n  }\n\n  entry {\n    cidr        = aws_vpc_ipv4_cidr_block_association.example.cidr_block\n    description = \"Secondary\"\n  }\n\n  tags = {\n    Env = \"live\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Required, Forces new resource) Address family (`IPv4` or `IPv6`) of this prefix list.\n* `entry` - (Optional) Configuration block for prefix list entry. Detailed below. Different entries may have overlapping CIDR blocks, but a particular CIDR should not be duplicated.\n* `max_entries` - (Required) Maximum number of entries that this prefix list can contain.\n* `name` - (Required) Name of this resource. The name must not start with `com.amazonaws`.\n* `tags` - (Optional) Map of tags to assign to this resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `entry`\n\n* `cidr` - (Required) CIDR block of this entry.\n* `description` - (Optional) Description of this entry. Due to API limitations, updating only the description of an existing entry requires temporarily removing and re-adding the entry.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the prefix list.\n* `id` - ID of the prefix list.\n* `owner_id` - ID of the AWS account that owns this prefix list.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version` - Latest version of this prefix list.\n\n## Import\n\nPrefix Lists can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ec2_managed_prefix_list.default pl-0570a1d2d725c16be\n```\n",
    "basename": "ec2_managed_prefix_list.html"
  },
  "ec2_managed_prefix_list_entry.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_managed_prefix_list_entry",
    "description": "Provides a managed prefix list entry resource.",
    "preview": "# Resource: aws_ec2_managed_prefix_list_entry\n\nProvides a managed …",
    "content": "\n\n# Resource: aws_ec2_managed_prefix_list_entry\n\nProvides a managed prefix list entry resource.\n\n~> **NOTE on Managed Prefix Lists and Managed Prefix List Entries:** Terraform\ncurrently provides both a standalone Managed Prefix List Entry resource (a single entry),\nand a [Managed Prefix List resource](ec2_managed_prefix_list.html) with entries defined\nin-line. At this time you cannot use a Managed Prefix List with in-line rules in\nconjunction with any Managed Prefix List Entry resources. Doing so will cause a conflict\nof entries and will overwrite entries.\n\n## Example Usage\n\nBasic usage\n\n```terraform\nresource \"aws_ec2_managed_prefix_list\" \"example\" {\n  name           = \"All VPC CIDR-s\"\n  address_family = \"IPv4\"\n  max_entries    = 5\n\n  tags = {\n    Env = \"live\"\n  }\n}\n\nresource \"aws_ec2_managed_prefix_list_entry\" \"entry_1\" {\n  cidr           = aws_vpc.example.cidr_block\n  description    = \"Primary\"\n  prefix_list_id = aws_ec2_managed_prefix_list.entry.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cidr` - (Required) CIDR block of this entry.\n* `description` - (Optional) Description of this entry. Due to API limitations, updating only the description of an entry requires recreating the entry.\n* `prefix_list_id` - (Required) CIDR block of this entry.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ID of the managed prefix list entry.\n\n## Import\n\nPrefix List Entries can be imported using the `prefix_list_id` and `cidr` separated by a `,`, e.g.,\n\n```\n$ terraform import aws_ec2_managed_prefix_list_entry.default pl-0570a1d2d725c16be,10.0.3.0/24\n```\n",
    "basename": "ec2_managed_prefix_list_entry.html"
  },
  "ec2_subnet_cidr_reservation.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_subnet_cidr_reservation",
    "description": "Provides a subnet CIDR reservation resource.",
    "preview": "# Resource: aws_ec2_subnet_cidr_reservation\n\nProvides a subnet CIDR …",
    "content": "\n\n# Resource: aws_ec2_subnet_cidr_reservation\n\nProvides a subnet CIDR reservation resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_subnet_cidr_reservation\" \"example\" {\n  cidr_block       = \"10.0.0.16/28\"\n  reservation_type = \"prefix\"\n  subnet_id        = aws_subnet.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cidr_block` - (Required) The CIDR block for the reservation.\n* `reservation_type` - (Required) The type of reservation to create. Valid values: `explicit`, `prefix`\n* `subnet_id` - (Required) The ID of the subnet to create the reservation for.\n* `description` - (Optional) A brief description of the reservation.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ID of the CIDR reservation.\n* `owner_id` - ID of the AWS account that owns this CIDR reservation.\n\n## Import\n\nExisting CIDR reservations can be imported using `SUBNET_ID:RESERVATION_ID`, e.g.,\n\n```\n$ terraform import aws_ec2_subnet_cidr_reservation.example subnet-01llsxvsxabqiymcz:scr-4mnvz6wb7otksjcs9\n```",
    "basename": "ec2_subnet_cidr_reservation.html"
  },
  "ec2_tag.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_tag",
    "description": "Manages an individual EC2 resource tag",
    "preview": "# Resource: aws_ec2_tag\n\nManages an individual EC2 resource tag. …",
    "content": "\n\n# Resource: aws_ec2_tag\n\nManages an individual EC2 resource tag. This resource should only be used in cases where EC2 resources are created outside Terraform (e.g., AMIs), being shared via Resource Access Manager (RAM), or implicitly created by other means (e.g., Transit Gateway VPN Attachments).\n\n~> **NOTE:** This tagging resource should not be combined with the Terraform resource for managing the parent resource. For example, using `aws_vpc` and `aws_ec2_tag` to manage tags of the same VPC will cause a perpetual difference where the `aws_vpc` resource will try to remove the tag being added by the `aws_ec2_tag` resource.\n\n~> **NOTE:** This tagging resource does not use the [provider `ignore_tags` configuration](/docs/providers/aws/index.html#ignore_tags).\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway\" \"example\" {}\n\nresource \"aws_customer_gateway\" \"example\" {\n  bgp_asn    = 65000\n  ip_address = \"172.0.0.1\"\n  type       = \"ipsec.1\"\n}\n\nresource \"aws_vpn_connection\" \"example\" {\n  customer_gateway_id = aws_customer_gateway.example.id\n  transit_gateway_id  = aws_ec2_transit_gateway.example.id\n  type                = aws_customer_gateway.example.type\n}\n\nresource \"aws_ec2_tag\" \"example\" {\n  resource_id = aws_vpn_connection.example.transit_gateway_attachment_id\n  key         = \"Name\"\n  value       = \"Hello World\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resource_id` - (Required) The ID of the EC2 resource to manage the tag for.\n* `key` - (Required) The tag name.\n* `value` - (Required) The value of the tag.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 resource identifier and key, separated by a comma (`,`)\n\n## Import\n\n`aws_ec2_tag` can be imported by using the EC2 resource identifier and key, separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_ec2_tag.example tgw-attach-1234567890abcdef,Name\n```\n",
    "basename": "ec2_tag.html"
  },
  "ec2_traffic_mirror_filter.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_traffic_mirror_filter",
    "description": "Provides an Traffic mirror filter",
    "preview": "# Resource: aws_ec2_traffic_mirror_filter\n\nProvides an Traffic …",
    "content": "\n\n# Resource: aws_ec2_traffic_mirror_filter\n\nProvides an Traffic mirror filter.  \nRead [limits and considerations](https://docs.aws.amazon.com/vpc/latest/mirroring/traffic-mirroring-considerations.html) for traffic mirroring\n\n## Example Usage\n\nTo create a basic traffic mirror filter\n\n```terraform\nresource \"aws_ec2_traffic_mirror_filter\" \"foo\" {\n  description      = \"traffic mirror filter - terraform example\"\n  network_services = [\"amazon-dns\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional, Forces new resource) A description of the filter.\n* `network_services` - (Optional) List of amazon network services that should be mirrored. Valid values: `amazon-dns`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the traffic mirror filter.\n* `id` - The name of the filter.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nTraffic mirror filter can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ec2_traffic_mirror_filter.foo tmf-0fbb93ddf38198f64\n```\n",
    "basename": "ec2_traffic_mirror_filter.html"
  },
  "ec2_traffic_mirror_filter_rule.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_traffic_mirror_filter_rule",
    "description": "Provides an Traffic mirror filter rule",
    "preview": "# Resource: aws_ec2_traffic_mirror_filter_rule\n\nProvides an Traffic …",
    "content": "\n\n# Resource: aws_ec2_traffic_mirror_filter_rule\n\nProvides an Traffic mirror filter rule.  \nRead [limits and considerations](https://docs.aws.amazon.com/vpc/latest/mirroring/traffic-mirroring-considerations.html) for traffic mirroring\n\n## Example Usage\n\nTo create a basic traffic mirror session\n\n```terraform\nresource \"aws_ec2_traffic_mirror_filter\" \"filter\" {\n  description      = \"traffic mirror filter - terraform example\"\n  network_services = [\"amazon-dns\"]\n}\n\nresource \"aws_ec2_traffic_mirror_filter_rule\" \"ruleout\" {\n  description              = \"test rule\"\n  traffic_mirror_filter_id = aws_ec2_traffic_mirror_filter.filter.id\n  destination_cidr_block   = \"10.0.0.0/8\"\n  source_cidr_block        = \"10.0.0.0/8\"\n  rule_number              = 1\n  rule_action              = \"accept\"\n  traffic_direction        = \"egress\"\n}\n\nresource \"aws_ec2_traffic_mirror_filter_rule\" \"rulein\" {\n  description              = \"test rule\"\n  traffic_mirror_filter_id = aws_ec2_traffic_mirror_filter.filter.id\n  destination_cidr_block   = \"10.0.0.0/8\"\n  source_cidr_block        = \"10.0.0.0/8\"\n  rule_number              = 1\n  rule_action              = \"accept\"\n  traffic_direction        = \"ingress\"\n  protocol                 = 6\n\n  destination_port_range {\n    from_port = 22\n    to_port   = 53\n  }\n\n  source_port_range {\n    from_port = 0\n    to_port   = 10\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) Description of the traffic mirror filter rule.\n* `traffic_mirror_filter_id`  - (Required) ID of the traffic mirror filter to which this rule should be added\n* `destination_cidr_block` - (Required) Destination CIDR block to assign to the Traffic Mirror rule.\n* `destination_port_range` - (Optional) Destination port range. Supported only when the protocol is set to TCP(6) or UDP(17). See Traffic mirror port range documented below\n* `protocol` - (Optional) Protocol number, for example 17 (UDP), to assign to the Traffic Mirror rule. For information about the protocol value, see [Protocol Numbers](https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml) on the Internet Assigned Numbers Authority (IANA) website.\n* `rule_action` - (Required) Action to take (accept | reject) on the filtered traffic. Valid values are `accept` and `reject`\n* `rule_number` - (Required) Number of the Traffic Mirror rule. This number must be unique for each Traffic Mirror rule in a given direction. The rules are processed in ascending order by rule number.\n* `source_cidr_block` - (Required) Source CIDR block to assign to the Traffic Mirror rule.\n* `source_port_range` - (Optional) Source port range. Supported only when the protocol is set to TCP(6) or UDP(17). See Traffic mirror port range documented below\n* `traffic_direction` - (Required) Direction of traffic to be captured. Valid values are `ingress` and `egress`\n\nTraffic mirror port range support following attributes:\n\n* `from_port` - (Optional) Starting port of the range\n* `to_port` - (Optional) Ending port of the range\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the traffic mirror filter rule.\n* `id` - Name of the traffic mirror filter rule.\n\n## Import\n\nTraffic mirror rules can be imported using the `traffic_mirror_filter_id` and `id` separated by `:` e.g.,\n\n```\n$ terraform import aws_ec2_traffic_mirror_filter_rule.rule tmf-0fbb93ddf38198f64:tmfr-05a458f06445d0aee\n```\n",
    "basename": "ec2_traffic_mirror_filter_rule.html"
  },
  "ec2_traffic_mirror_session.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_traffic_mirror_session",
    "description": "Provides a Traffic mirror session",
    "preview": "# Resource: aws_ec2_traffic_mirror_session\n\nProvides an Traffic …",
    "content": "\n\n# Resource: aws_ec2_traffic_mirror_session\n\nProvides an Traffic mirror session.  \nRead [limits and considerations](https://docs.aws.amazon.com/vpc/latest/mirroring/traffic-mirroring-considerations.html) for traffic mirroring\n\n## Example Usage\n\nTo create a basic traffic mirror session\n\n```terraform\nresource \"aws_ec2_traffic_mirror_filter\" \"filter\" {\n  description      = \"traffic mirror filter - terraform example\"\n  network_services = [\"amazon-dns\"]\n}\n\nresource \"aws_ec2_traffic_mirror_target\" \"target\" {\n  network_load_balancer_arn = aws_lb.lb.arn\n}\n\nresource \"aws_ec2_traffic_mirror_session\" \"session\" {\n  description              = \"traffic mirror session - terraform example\"\n  network_interface_id     = aws_instance.test.primary_network_interface_id\n  session_number           = 1\n  traffic_mirror_filter_id = aws_ec2_traffic_mirror_filter.filter.id\n  traffic_mirror_target_id = aws_ec2_traffic_mirror_target.target.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) A description of the traffic mirror session.\n* `network_interface_id` - (Required, Forces new) ID of the source network interface. Not all network interfaces are eligible as mirror sources. On EC2 instances only nitro based instances support mirroring.\n* `traffic_mirror_filter_id`  - (Required) ID of the traffic mirror filter to be used\n* `traffic_mirror_target_id` - (Required) ID of the traffic mirror target to be used\n* `packet_length` - (Optional) The number of bytes in each packet to mirror. These are bytes after the VXLAN header. Do not specify this parameter when you want to mirror the entire packet. To mirror a subset of the packet, set this to the length (in bytes) that you want to mirror.\n* `session_number` - (Required) - The session number determines the order in which sessions are evaluated when an interface is used by multiple sessions. The first session with a matching filter is the one that mirrors the packets.\n* `virtual_network_id` - (Optional) - The VXLAN ID for the Traffic Mirror session. For more information about the VXLAN protocol, see RFC 7348. If you do not specify a VirtualNetworkId, an account-wide unique id is chosen at random.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the traffic mirror session.\n* `id` - The name of the session.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `owner_id` - The AWS account ID of the session owner.\n\n## Import\n\nTraffic mirror sessions can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ec2_traffic_mirror_session.session tms-0d8aa3ca35897b82e\n```\n",
    "basename": "ec2_traffic_mirror_session.html"
  },
  "ec2_traffic_mirror_target.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_traffic_mirror_target",
    "description": "Provides a Traffic mirror target",
    "preview": "# Resource: aws_ec2_traffic_mirror_target\n\nProvides a Traffic mirror …",
    "content": "\n\n# Resource: aws_ec2_traffic_mirror_target\n\nProvides a Traffic mirror target.  \nRead [limits and considerations](https://docs.aws.amazon.com/vpc/latest/mirroring/traffic-mirroring-considerations.html) for traffic mirroring\n\n## Example Usage\n\nTo create a basic traffic mirror session\n\n```terraform\nresource \"aws_ec2_traffic_mirror_target\" \"nlb\" {\n  description               = \"NLB target\"\n  network_load_balancer_arn = aws_lb.lb.arn\n}\n\nresource \"aws_ec2_traffic_mirror_target\" \"eni\" {\n  description          = \"ENI target\"\n  network_interface_id = aws_instance.test.primary_network_interface_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional, Forces new) A description of the traffic mirror session.\n* `network_interface_id` - (Optional, Forces new) The network interface ID that is associated with the target.\n* `network_load_balancer_arn` - (Optional, Forces new) The Amazon Resource Name (ARN) of the Network Load Balancer that is associated with the target.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n**NOTE:** Either `network_interface_id` or `network_load_balancer_arn` should be specified and both should not be specified together\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Traffic Mirror target.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `arn` - The ARN of the traffic mirror target.\n* `owner_id` - The ID of the AWS account that owns the traffic mirror target.\n\n## Import\n\nTraffic mirror targets can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ec2_traffic_mirror_target.target tmt-0c13a005422b86606\n```\n",
    "basename": "ec2_traffic_mirror_target.html"
  },
  "ec2_transit_gateway.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway",
    "description": "Manages an EC2 Transit Gateway",
    "preview": "# Resource: aws_ec2_transit_gateway\n\nManages an EC2 Transit Gateway. …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway\n\nManages an EC2 Transit Gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway\" \"example\" {\n  description = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `amazon_side_asn` - (Optional) Private Autonomous System Number (ASN) for the Amazon side of a BGP session. The range is `64512` to `65534` for 16-bit ASNs and `4200000000` to `4294967294` for 32-bit ASNs. Default value: `64512`.\n* `auto_accept_shared_attachments` - (Optional) Whether resource attachment requests are automatically accepted. Valid values: `disable`, `enable`. Default value: `disable`.\n* `default_route_table_association` - (Optional) Whether resource attachments are automatically associated with the default association route table. Valid values: `disable`, `enable`. Default value: `enable`.\n* `default_route_table_propagation` - (Optional) Whether resource attachments automatically propagate routes to the default propagation route table. Valid values: `disable`, `enable`. Default value: `enable`.\n* `description` - (Optional) Description of the EC2 Transit Gateway.\n* `dns_support` - (Optional) Whether DNS support is enabled. Valid values: `disable`, `enable`. Default value: `enable`.\n* `tags` - (Optional) Key-value tags for the EC2 Transit Gateway. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpn_ecmp_support` - (Optional) Whether VPN Equal Cost Multipath Protocol support is enabled. Valid values: `disable`, `enable`. Default value: `enable`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - EC2 Transit Gateway Amazon Resource Name (ARN)\n* `association_default_route_table_id` - Identifier of the default association route table\n* `id` - EC2 Transit Gateway identifier\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `owner_id` - Identifier of the AWS account that owns the EC2 Transit Gateway\n* `propagation_default_route_table_id` - Identifier of the default propagation route table\n\n## Import\n\n`aws_ec2_transit_gateway` can be imported by using the EC2 Transit Gateway identifier, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway.example tgw-12345678\n```\n",
    "basename": "ec2_transit_gateway.html"
  },
  "ec2_transit_gateway_peering_attachment.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_peering_attachment",
    "description": "Manages an EC2 Transit Gateway Peering Attachment",
    "preview": "# Resource: aws_ec2_transit_gateway_peering_attachment\n\nManages an …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_peering_attachment\n\nManages an EC2 Transit Gateway Peering Attachment.\nFor examples of custom route table association and propagation, see the [EC2 Transit Gateway Networking Examples Guide](https://docs.aws.amazon.com/vpc/latest/tgw/TGW_Scenarios.html).\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  alias  = \"local\"\n  region = \"us-east-1\"\n}\n\nprovider \"aws\" {\n  alias  = \"peer\"\n  region = \"us-west-2\"\n}\n\ndata \"aws_region\" \"peer\" {\n  provider = aws.peer\n}\n\nresource \"aws_ec2_transit_gateway\" \"local\" {\n  provider = aws.local\n\n  tags = {\n    Name = \"Local TGW\"\n  }\n}\n\nresource \"aws_ec2_transit_gateway\" \"peer\" {\n  provider = aws.peer\n\n  tags = {\n    Name = \"Peer TGW\"\n  }\n}\n\nresource \"aws_ec2_transit_gateway_peering_attachment\" \"example\" {\n  peer_account_id         = aws_ec2_transit_gateway.peer.owner_id\n  peer_region             = data.aws_region.peer.name\n  peer_transit_gateway_id = aws_ec2_transit_gateway.peer.id\n  transit_gateway_id      = aws_ec2_transit_gateway.local.id\n\n  tags = {\n    Name = \"TGW Peering Requestor\"\n  }\n}\n```\n\nA full example of how to create a Transit Gateway in one AWS account, share it with a second AWS account, and attach a to a Transit Gateway in the second account via the `aws_ec2_transit_gateway_peering_attachment` resource can be found in [the `./examples/transit-gateway-cross-account-peering-attachment` directory within the Github Repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/transit-gateway-cross-account-peering-attachment).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `peer_account_id` - (Optional) Account ID of EC2 Transit Gateway to peer with. Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `peer_region` - (Required) Region of EC2 Transit Gateway to peer with.\n* `peer_transit_gateway_id` - (Required) Identifier of EC2 Transit Gateway to peer with.\n* `tags` - (Optional) Key-value tags for the EC2 Transit Gateway Peering Attachment. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `transit_gateway_id` - (Required) Identifier of EC2 Transit Gateway.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Attachment identifier\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_ec2_transit_gateway_peering_attachment` can be imported by using the EC2 Transit Gateway Attachment identifier, e.g.,\n\n```sh\nterraform import aws_ec2_transit_gateway_peering_attachment.example tgw-attach-12345678\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "ec2_transit_gateway_peering_attachment.html"
  },
  "ec2_transit_gateway_peering_attachment_accepter.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_peering_attachment_accepter",
    "description": "Manages the accepter's side of an EC2 Transit Gateway peering Attachment",
    "preview": "# Resource: aws_ec2_transit_gateway_peering_attachment_accepter\n …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_peering_attachment_accepter\n\nManages the accepter's side of an EC2 Transit Gateway Peering Attachment.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway_peering_attachment_accepter\" \"example\" {\n  transit_gateway_attachment_id = aws_ec2_transit_gateway_peering_attachment.example.id\n\n  tags = {\n    Name = \"Example cross-account attachment\"\n  }\n}\n```\n\nA full example of how to create a Transit Gateway in one AWS account, share it with a second AWS account, and attach a to a Transit Gateway in the second account via the `aws_ec2_transit_gateway_peering_attachment` resource can be found in [the `./examples/transit-gateway-cross-account-peering-attachment` directory within the Github Repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/transit-gateway-cross-account-peering-attachment).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `transit_gateway_attachment_id` - (Required) The ID of the EC2 Transit Gateway Peering Attachment to manage.\n* `tags` - (Optional) Key-value tags for the EC2 Transit Gateway Peering Attachment. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Attachment identifier\n* `transit_gateway_id` - Identifier of EC2 Transit Gateway.\n* `peer_transit_gateway_id` - Identifier of EC2 Transit Gateway to peer with.\n* `peer_account_id` - Identifier of the AWS account that owns the EC2 TGW peering.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_ec2_transit_gateway_peering_attachment_accepter` can be imported by using the EC2 Transit Gateway Attachment identifier, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway_peering_attachment_accepter.example tgw-attach-12345678\n```\n",
    "basename": "ec2_transit_gateway_peering_attachment_accepter.html"
  },
  "ec2_transit_gateway_prefix_list_reference.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_prefix_list_reference",
    "description": "Manages an EC2 Transit Gateway Prefix List Reference",
    "preview": "# Resource: aws_ec2_transit_gateway_prefix_list_reference\n\nManages …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_prefix_list_reference\n\nManages an EC2 Transit Gateway Prefix List Reference.\n\n## Example Usage\n\n### Attachment Routing\n\n```terraform\nresource \"aws_ec2_transit_gateway_prefix_list_reference\" \"example\" {\n  prefix_list_id                 = aws_ec2_managed_prefix_list.example.id\n  transit_gateway_attachment_id  = aws_ec2_transit_gateway_vpc_attachment.example.id\n  transit_gateway_route_table_id = aws_ec2_transit_gateway.example.association_default_route_table_id\n}\n```\n\n### Blackhole Routing\n\n```terraform\nresource \"aws_ec2_transit_gateway_prefix_list_reference\" \"example\" {\n  blackhole                      = true\n  prefix_list_id                 = aws_ec2_managed_prefix_list.example.id\n  transit_gateway_route_table_id = aws_ec2_transit_gateway.example.association_default_route_table_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `prefix_list_id` - (Required) Identifier of EC2 Prefix List.\n* `transit_gateway_route_table_id` - (Required) Identifier of EC2 Transit Gateway Route Table.\n\nThe following arguments are optional:\n\n* `blackhole` - (Optional) Indicates whether to drop traffic that matches the Prefix List. Defaults to `false`.\n* `transit_gateway_attachment_id` - (Optional) Identifier of EC2 Transit Gateway Attachment.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Route Table identifier and EC2 Prefix List identifier, separated by an underscore (`_`)\n\n## Import\n\n`aws_ec2_transit_gateway_prefix_list_reference` can be imported by using the EC2 Transit Gateway Route Table identifier and EC2 Prefix List identifier, separated by an underscore (`_`), e.g.,\n\n```console\n$ terraform import aws_ec2_transit_gateway_prefix_list_reference.example tgw-rtb-12345678_pl-12345678\n```\n",
    "basename": "ec2_transit_gateway_prefix_list_reference.html"
  },
  "ec2_transit_gateway_route.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_route",
    "description": "Manages an EC2 Transit Gateway Route",
    "preview": "# Resource: aws_ec2_transit_gateway_route\n\nManages an EC2 Transit …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_route\n\nManages an EC2 Transit Gateway Route.\n\n## Example Usage\n\n### Standard usage\n\n```terraform\nresource \"aws_ec2_transit_gateway_route\" \"example\" {\n  destination_cidr_block         = \"0.0.0.0/0\"\n  transit_gateway_attachment_id  = aws_ec2_transit_gateway_vpc_attachment.example.id\n  transit_gateway_route_table_id = aws_ec2_transit_gateway.example.association_default_route_table_id\n}\n```\n\n### Blackhole route\n\n```terraform\nresource \"aws_ec2_transit_gateway_route\" \"example\" {\n  destination_cidr_block         = \"0.0.0.0/0\"\n  blackhole                      = true\n  transit_gateway_route_table_id = aws_ec2_transit_gateway.example.association_default_route_table_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `destination_cidr_block` - (Required) IPv4 or IPv6 RFC1924 CIDR used for destination matches. Routing decisions are based on the most specific match.\n* `transit_gateway_attachment_id` - (Optional) Identifier of EC2 Transit Gateway Attachment (required if `blackhole` is set to false).\n* `blackhole` - (Optional) Indicates whether to drop traffic that matches this route (default to `false`).\n* `transit_gateway_route_table_id` - (Required) Identifier of EC2 Transit Gateway Route Table.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Route Table identifier combined with destination\n\n## Import\n\n`aws_ec2_transit_gateway_route` can be imported by using the EC2 Transit Gateway Route Table, an underscore, and the destination, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway_route.example tgw-rtb-12345678_0.0.0.0/0\n```\n",
    "basename": "ec2_transit_gateway_route.html"
  },
  "ec2_transit_gateway_route_table.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_route_table",
    "description": "Manages an EC2 Transit Gateway Route Table",
    "preview": "# Resource: aws_ec2_transit_gateway_route_table\n\nManages an EC2 …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_route_table\n\nManages an EC2 Transit Gateway Route Table.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway_route_table\" \"example\" {\n  transit_gateway_id = aws_ec2_transit_gateway.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `transit_gateway_id` - (Required) Identifier of EC2 Transit Gateway.\n* `tags` - (Optional) Key-value tags for the EC2 Transit Gateway Route Table. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - EC2 Transit Gateway Route Table Amazon Resource Name (ARN).\n* `default_association_route_table` - Boolean whether this is the default association route table for the EC2 Transit Gateway.\n* `default_propagation_route_table` - Boolean whether this is the default propagation route table for the EC2 Transit Gateway.\n* `id` - EC2 Transit Gateway Route Table identifier\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_ec2_transit_gateway_route_table` can be imported by using the EC2 Transit Gateway Route Table identifier, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway_route_table.example tgw-rtb-12345678\n```\n",
    "basename": "ec2_transit_gateway_route_table.html"
  },
  "ec2_transit_gateway_route_table_association.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_route_table_association_table_association",
    "description": "Manages an EC2 Transit Gateway Route Table association",
    "preview": "# Resource: aws_ec2_transit_gateway_route_table_association\n\nManages …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_route_table_association\n\nManages an EC2 Transit Gateway Route Table association.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway_route_table_association\" \"example\" {\n  transit_gateway_attachment_id  = aws_ec2_transit_gateway_vpc_attachment.example.id\n  transit_gateway_route_table_id = aws_ec2_transit_gateway_route_table.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `transit_gateway_attachment_id` - (Required) Identifier of EC2 Transit Gateway Attachment.\n* `transit_gateway_route_table_id` - (Required) Identifier of EC2 Transit Gateway Route Table.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Route Table identifier combined with EC2 Transit Gateway Attachment identifier\n* `resource_id` - Identifier of the resource\n* `resource_type` - Type of the resource\n\n## Import\n\n`aws_ec2_transit_gateway_route_table_association` can be imported by using the EC2 Transit Gateway Route Table identifier, an underscore, and the EC2 Transit Gateway Attachment identifier, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway_route_table_association.example tgw-rtb-12345678_tgw-attach-87654321\n```\n",
    "basename": "ec2_transit_gateway_route_table_association.html"
  },
  "ec2_transit_gateway_route_table_propagation.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_route_table_propagation_table_propagation",
    "description": "Manages an EC2 Transit Gateway Route Table propagation",
    "preview": "# Resource: aws_ec2_transit_gateway_route_table_propagation\n\nManages …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_route_table_propagation\n\nManages an EC2 Transit Gateway Route Table propagation.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway_route_table_propagation\" \"example\" {\n  transit_gateway_attachment_id  = aws_ec2_transit_gateway_vpc_attachment.example.id\n  transit_gateway_route_table_id = aws_ec2_transit_gateway_route_table.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `transit_gateway_attachment_id` - (Required) Identifier of EC2 Transit Gateway Attachment.\n* `transit_gateway_route_table_id` - (Required) Identifier of EC2 Transit Gateway Route Table.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Route Table identifier combined with EC2 Transit Gateway Attachment identifier\n* `resource_id` - Identifier of the resource\n* `resource_type` - Type of the resource\n\n## Import\n\n`aws_ec2_transit_gateway_route_table_propagation` can be imported by using the EC2 Transit Gateway Route Table identifier, an underscore, and the EC2 Transit Gateway Attachment identifier, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway_route_table_propagation.example tgw-rtb-12345678_tgw-attach-87654321\n```\n",
    "basename": "ec2_transit_gateway_route_table_propagation.html"
  },
  "ec2_transit_gateway_vpc_attachment.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_vpc_attachment",
    "description": "Manages an EC2 Transit Gateway VPC Attachment",
    "preview": "# Resource: aws_ec2_transit_gateway_vpc_attachment\n\nManages an EC2 …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_vpc_attachment\n\nManages an EC2 Transit Gateway VPC Attachment. For examples of custom route table association and propagation, see the EC2 Transit Gateway Networking Examples Guide.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway_vpc_attachment\" \"example\" {\n  subnet_ids         = [aws_subnet.example.id]\n  transit_gateway_id = aws_ec2_transit_gateway.example.id\n  vpc_id             = aws_vpc.example.id\n}\n```\n\nA full example of how to create a Transit Gateway in one AWS account, share it with a second AWS account, and attach a VPC in the second account to the Transit Gateway via the `aws_ec2_transit_gateway_vpc_attachment` and `aws_ec2_transit_gateway_vpc_attachment_accepter` resources can be found in [the `./examples/transit-gateway-cross-account-vpc-attachment` directory within the Github Repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/transit-gateway-cross-account-vpc-attachment).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `subnet_ids` - (Required) Identifiers of EC2 Subnets.\n* `transit_gateway_id` - (Required) Identifier of EC2 Transit Gateway.\n* `vpc_id` - (Required) Identifier of EC2 VPC.\n* `appliance_mode_support` - (Optional) Whether Appliance Mode support is enabled. If enabled, a traffic flow between a source and destination uses the same Availability Zone for the VPC attachment for the lifetime of that flow. Valid values: `disable`, `enable`. Default value: `disable`.\n* `dns_support` - (Optional) Whether DNS support is enabled. Valid values: `disable`, `enable`. Default value: `enable`.\n* `ipv6_support` - (Optional) Whether IPv6 support is enabled. Valid values: `disable`, `enable`. Default value: `disable`.\n* `tags` - (Optional) Key-value tags for the EC2 Transit Gateway VPC Attachment. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `transit_gateway_default_route_table_association` - (Optional) Boolean whether the VPC Attachment should be associated with the EC2 Transit Gateway association default route table. This cannot be configured or perform drift detection with Resource Access Manager shared EC2 Transit Gateways. Default value: `true`.\n* `transit_gateway_default_route_table_propagation` - (Optional) Boolean whether the VPC Attachment should propagate routes with the EC2 Transit Gateway propagation default route table. This cannot be configured or perform drift detection with Resource Access Manager shared EC2 Transit Gateways. Default value: `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Attachment identifier\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_owner_id` - Identifier of the AWS account that owns the EC2 VPC.\n\n## Import\n\n`aws_ec2_transit_gateway_vpc_attachment` can be imported by using the EC2 Transit Gateway Attachment identifier, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway_vpc_attachment.example tgw-attach-12345678\n```\n",
    "basename": "ec2_transit_gateway_vpc_attachment.html"
  },
  "ec2_transit_gateway_vpc_attachment_accepter.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_ec2_transit_gateway_vpc_attachment_accepter",
    "description": "Manages the accepter's side of an EC2 Transit Gateway VPC Attachment",
    "preview": "# Resource: aws_ec2_transit_gateway_vpc_attachment_accepter\n\nManages …",
    "content": "\n\n# Resource: aws_ec2_transit_gateway_vpc_attachment_accepter\n\nManages the accepter's side of an EC2 Transit Gateway VPC Attachment.\n\nWhen a cross-account (requester's AWS account differs from the accepter's AWS account) EC2 Transit Gateway VPC Attachment\nis created, an EC2 Transit Gateway VPC Attachment resource is automatically created in the accepter's account.\nThe requester can use the `aws_ec2_transit_gateway_vpc_attachment` resource to manage its side of the connection\nand the accepter can use the `aws_ec2_transit_gateway_vpc_attachment_accepter` resource to \"adopt\" its side of the\nconnection into management.\n\n## Example Usage\n\n```terraform\nresource \"aws_ec2_transit_gateway_vpc_attachment_accepter\" \"example\" {\n  transit_gateway_attachment_id = aws_ec2_transit_gateway_vpc_attachment.example.id\n\n  tags = {\n    Name = \"Example cross-account attachment\"\n  }\n}\n```\n\nA full example of how to create a Transit Gateway in one AWS account, share it with a second AWS account, and attach a VPC in the second account to the Transit Gateway via the `aws_ec2_transit_gateway_vpc_attachment` and `aws_ec2_transit_gateway_vpc_attachment_accepter` resources can be found in [the `./examples/transit-gateway-cross-account-vpc-attachment` directory within the Github Repository](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/transit-gateway-cross-account-vpc-attachment).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `transit_gateway_attachment_id` - (Required) The ID of the EC2 Transit Gateway Attachment to manage.\n* `transit_gateway_default_route_table_association` - (Optional) Boolean whether the VPC Attachment should be associated with the EC2 Transit Gateway association default route table. Default value: `true`.\n* `transit_gateway_default_route_table_propagation` - (Optional) Boolean whether the VPC Attachment should propagate routes with the EC2 Transit Gateway propagation default route table. Default value: `true`.\n* `tags` - (Optional) Key-value tags for the EC2 Transit Gateway VPC Attachment. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - EC2 Transit Gateway Attachment identifier\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `appliance_mode_support` - Whether Appliance Mode support is enabled. Valid values: `disable`, `enable`.\n* `dns_support` - Whether DNS support is enabled. Valid values: `disable`, `enable`.\n* `ipv6_support` - Whether IPv6 support is enabled. Valid values: `disable`, `enable`.\n* `subnet_ids` - Identifiers of EC2 Subnets.\n* `transit_gateway_id` - Identifier of EC2 Transit Gateway.\n* `vpc_id` - Identifier of EC2 VPC.\n* `vpc_owner_id` - Identifier of the AWS account that owns the EC2 VPC.\n\n## Import\n\n`aws_ec2_transit_gateway_vpc_attachment_accepter` can be imported by using the EC2 Transit Gateway Attachment identifier, e.g.,\n\n```\n$ terraform import aws_ec2_transit_gateway_vpc_attachment_accepter.example tgw-attach-12345678\n```\n",
    "basename": "ec2_transit_gateway_vpc_attachment_accepter.html"
  },
  "ecr_lifecycle_policy.html": {
    "subcategory": "ECR",
    "layout": "aws",
    "page_title": "AWS: aws_ecr_lifecycle_policy",
    "description": "Manages an ECR repository lifecycle policy.",
    "preview": "# Resource: aws_ecr_lifecycle_policy\n\nManages an ECR repository …",
    "content": "\n\n# Resource: aws_ecr_lifecycle_policy\n\nManages an ECR repository lifecycle policy.\n\n~> **NOTE:** Only one `aws_ecr_lifecycle_policy` resource can be used with the same ECR repository. To apply multiple rules, they must be combined in the `policy` JSON.\n\n~> **NOTE:** The AWS ECR API seems to reorder rules based on `rulePriority`. If you define multiple rules that are not sorted in ascending `rulePriority` order in the Terraform code, the resource will be flagged for recreation every `terraform plan`.\n\n## Example Usage\n\n### Policy on untagged image\n\n```terraform\nresource \"aws_ecr_repository\" \"foo\" {\n  name = \"bar\"\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"foopolicy\" {\n  repository = aws_ecr_repository.foo.name\n\n  policy = <<EOF\n{\n    \"rules\": [\n        {\n            \"rulePriority\": 1,\n            \"description\": \"Expire images older than 14 days\",\n            \"selection\": {\n                \"tagStatus\": \"untagged\",\n                \"countType\": \"sinceImagePushed\",\n                \"countUnit\": \"days\",\n                \"countNumber\": 14\n            },\n            \"action\": {\n                \"type\": \"expire\"\n            }\n        }\n    ]\n}\nEOF\n}\n```\n\n### Policy on tagged image\n\n```terraform\nresource \"aws_ecr_repository\" \"foo\" {\n  name = \"bar\"\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"foopolicy\" {\n  repository = aws_ecr_repository.foo.name\n\n  policy = <<EOF\n{\n    \"rules\": [\n        {\n            \"rulePriority\": 1,\n            \"description\": \"Keep last 30 images\",\n            \"selection\": {\n                \"tagStatus\": \"tagged\",\n                \"tagPrefixList\": [\"v\"],\n                \"countType\": \"imageCountMoreThan\",\n                \"countNumber\": 30\n            },\n            \"action\": {\n                \"type\": \"expire\"\n            }\n        }\n    ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `repository` - (Required) Name of the repository to apply the policy.\n* `policy` - (Required) The policy document. This is a JSON formatted string. See more details about [Policy Parameters](http://docs.aws.amazon.com/AmazonECR/latest/userguide/LifecyclePolicies.html#lifecycle_policy_parameters) in the official AWS docs.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `repository` - The name of the repository.\n* `registry_id` - The registry ID where the repository was created.\n\n## Import\n\nECR Lifecycle Policy can be imported using the name of the repository, e.g.,\n\n```\n$ terraform import aws_ecr_lifecycle_policy.example tf-example\n```\n",
    "basename": "ecr_lifecycle_policy.html"
  },
  "ecr_registry_policy.html": {
    "subcategory": "ECR",
    "layout": "aws",
    "page_title": "AWS: aws_ecr_registry_policy",
    "description": "Provides an Elastic Container Registry Policy.",
    "preview": "# Resource: aws_ecr_registry_policy\n\nProvides an Elastic Container …",
    "content": "\n\n# Resource: aws_ecr_registry_policy\n\nProvides an Elastic Container Registry Policy.\n\n## Example Usage\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_region\" \"current\" {}\n\ndata \"aws_partition\" \"current\" {}\n\nresource \"aws_ecr_registry_policy\" \"example\" {\n  policy = jsonencode({\n    Version = \"2012-10-17\",\n    Statement = [\n      {\n        Sid    = \"testpolicy\",\n        Effect = \"Allow\",\n        Principal = {\n          \"AWS\" : \"arn:${data.aws_partition.current.partition}:iam::${data.aws_caller_identity.current.account_id}:root\"\n        },\n        Action = [\n          \"ecr:ReplicateImage\"\n        ],\n        Resource = [\n          \"arn:${data.aws_partition.current.partition}:ecr:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:repository/*\"\n        ]\n      }\n    ]\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy` - (Required) The policy document. This is a JSON formatted string. For more information about building IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `registry_id` - The registry ID where the registry was created.\n\n## Import\n\nECR Registry Policy can be imported using the registry id, e.g.,\n\n```\n$ terraform import aws_ecr_registry_policy.example 123456789012\n```\n",
    "basename": "ecr_registry_policy.html"
  },
  "ecr_replication_configuration.html": {
    "subcategory": "ECR",
    "layout": "aws",
    "page_title": "AWS: aws_ecr_replication_configuration",
    "description": "Provides an Elastic Container Registry Replication Configuration.",
    "preview": "# Resource: aws_ecr_replication_configuration\n\nProvides an Elastic …",
    "content": "\n\n# Resource: aws_ecr_replication_configuration\n\nProvides an Elastic Container Registry Replication Configuration.\n\n## Example Usage\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_regions\" \"example\" {}\n\nresource \"aws_ecr_replication_configuration\" \"example\" {\n  replication_configuration {\n    rule {\n      destination {\n        region      = data.aws_regions.example.names[0]\n        registry_id = data.aws_caller_identity.current.account_id\n      }\n    }\n  }\n}\n```\n\n## Multiple Region Usage\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_regions\" \"example\" {}\n\nresource \"aws_ecr_replication_configuration\" \"example\" {\n  replication_configuration {\n    rule {\n      destination {\n        region      = data.aws_regions.example.names[0]\n        registry_id = data.aws_caller_identity.current.account_id\n      }\n\n      destination {\n        region      = data.aws_regions.example.names[1]\n        registry_id = data.aws_caller_identity.current.account_id\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `replication_configuration` - (Required) Replication configuration for a registry. See [Replication Configuration](#replication-configuration).\n\n### Replication Configuration\n\n* `rule` - (Required) The replication rules for a replication configuration. See [Rule](#rule).\n\n### Rule\n\n* `destination` - (Required) the details of a replication destination. See [Destination](#destination).\n\n### Destination\n\n* `region` - (Required) A Region to replicate to.\n* `registry_id` - (Required) The account ID of the destination registry to replicate to.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `registry_id` - The registry ID where the replication configuration was created.\n\n## Import\n\nECR Replication Configuration can be imported using the `registry_id`, e.g.,\n\n```\n$ terraform import aws_ecr_replication_configuration.service 012345678912\n```\n",
    "basename": "ecr_replication_configuration.html"
  },
  "ecr_repository.html": {
    "subcategory": "ECR",
    "layout": "aws",
    "page_title": "AWS: aws_ecr_repository",
    "description": "Provides an Elastic Container Registry Repository.",
    "preview": "# Resource: aws_ecr_repository\n\nProvides an Elastic Container …",
    "content": "\n\n# Resource: aws_ecr_repository\n\nProvides an Elastic Container Registry Repository.\n\n## Example Usage\n\n```terraform\nresource \"aws_ecr_repository\" \"foo\" {\n  name                 = \"bar\"\n  image_tag_mutability = \"MUTABLE\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the repository.\n* `encryption_configuration` - (Optional) Encryption configuration for the repository. See [below for schema](#encryption_configuration).\n* `image_tag_mutability` - (Optional) The tag mutability setting for the repository. Must be one of: `MUTABLE` or `IMMUTABLE`. Defaults to `MUTABLE`.\n* `image_scanning_configuration` - (Optional) Configuration block that defines image scanning configuration for the repository. By default, image scanning must be manually triggered. See the [ECR User Guide](https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html) for more information about image scanning.\n    * `scan_on_push` - (Required) Indicates whether images are scanned after being pushed to the repository (true) or not scanned (false).\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### encryption_configuration\n\n* `encryption_type` - (Optional) The encryption type to use for the repository. Valid values are `AES256` or `KMS`. Defaults to `AES256`.\n* `kms_key` - (Optional) The ARN of the KMS key to use when `encryption_type` is `KMS`. If not specified, uses the default AWS managed key for ECR.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Full ARN of the repository.\n* `registry_id` - The registry ID where the repository was created.\n* `repository_url` - The URL of the repository (in the form `aws_account_id.dkr.ecr.region.amazonaws.com/repositoryName`).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_ecr_repository` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `delete` - (Default `20 minutes`) How long to wait for a repository to be deleted.\n\n## Import\n\nECR Repositories can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_ecr_repository.service test-service\n```\n",
    "basename": "ecr_repository.html"
  },
  "ecr_repository_policy.html": {
    "subcategory": "ECR",
    "layout": "aws",
    "page_title": "AWS: aws_ecr_repository_policy",
    "description": "Provides an Elastic Container Registry Repository Policy.",
    "preview": "# Resource: aws_ecr_repository_policy\n\nProvides an Elastic Container …",
    "content": "\n\n# Resource: aws_ecr_repository_policy\n\nProvides an Elastic Container Registry Repository Policy.\n\nNote that currently only one policy may be applied to a repository.\n\n## Example Usage\n\n```terraform\nresource \"aws_ecr_repository\" \"foo\" {\n  name = \"bar\"\n}\n\nresource \"aws_ecr_repository_policy\" \"foopolicy\" {\n  repository = aws_ecr_repository.foo.name\n\n  policy = <<EOF\n{\n    \"Version\": \"2008-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"new policy\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": [\n                \"ecr:GetDownloadUrlForLayer\",\n                \"ecr:BatchGetImage\",\n                \"ecr:BatchCheckLayerAvailability\",\n                \"ecr:PutImage\",\n                \"ecr:InitiateLayerUpload\",\n                \"ecr:UploadLayerPart\",\n                \"ecr:CompleteLayerUpload\",\n                \"ecr:DescribeRepositories\",\n                \"ecr:GetRepositoryPolicy\",\n                \"ecr:ListImages\",\n                \"ecr:DeleteRepository\",\n                \"ecr:BatchDeleteImage\",\n                \"ecr:SetRepositoryPolicy\",\n                \"ecr:DeleteRepositoryPolicy\"\n            ]\n        }\n    ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `repository` - (Required) Name of the repository to apply the policy.\n* `policy` - (Required) The policy document. This is a JSON formatted string. For more information about building IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `repository` - The name of the repository.\n* `registry_id` - The registry ID where the repository was created.\n\n## Import\n\nECR Repository Policy can be imported using the repository name, e.g.,\n\n```\n$ terraform import aws_ecr_repository_policy.example example\n```\n",
    "basename": "ecr_repository_policy.html"
  },
  "ecrpublic_repository.html": {
    "subcategory": "ECR",
    "layout": "aws",
    "page_title": "AWS: aws_ecrpublic_repository",
    "description": "Provides a Public Elastic Container Registry Repository.",
    "preview": "# Resource: aws_ecrpublic_repository\n\nProvides a Public Elastic …",
    "content": "\n\n# Resource: aws_ecrpublic_repository\n\nProvides a Public Elastic Container Registry Repository.\n\n~> **NOTE:** This resource can only be used with `us-east-1` region.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  alias  = \"us_east_1\"\n  region = \"us-east-1\"\n}\n\nresource \"aws_ecrpublic_repository\" \"foo\" {\n  provider = aws.us_east_1\n\n  repository_name = \"bar\"\n\n  catalog_data {\n    about_text        = \"About Text\"\n    architectures     = [\"ARM\"]\n    description       = \"Description\"\n    logo_image_blob   = filebase64(image.png)\n    operating_systems = [\"Linux\"]\n    usage_text        = \"Usage Text\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `repository_name` - (Required) Name of the repository.\n* `catalog_data` - (Optional) Catalog data configuration for the repository. See [below for schema](#catalog_data).\n\n\n### catalog_data\n\n* `about_text` - (Optional) A detailed description of the contents of the repository. It is publicly visible in the Amazon ECR Public Gallery. The text must be in markdown format.\n* `architectures` - (Optional) The system architecture that the images in the repository are compatible with. On the Amazon ECR Public Gallery, the following supported architectures will appear as badges on the repository and are used as search filters: `ARM`, `ARM 64`, `x86`, `x86-64`\n* `description` - (Optional) A short description of the contents of the repository. This text appears in both the image details and also when searching for repositories on the Amazon ECR Public Gallery.\n* `logo_image_blob` - (Optional) The base64-encoded repository logo payload. (Only visible for verified accounts) Note that drift detection is disabled for this attribute.\n* `operating_systems` -  (Optional) The operating systems that the images in the repository are compatible with. On the Amazon ECR Public Gallery, the following supported operating systems will appear as badges on the repository and are used as search filters: `Linux`, `Windows`\n* `usage_text` -  (Optional) Detailed information on how to use the contents of the repository. It is publicly visible in the Amazon ECR Public Gallery. The usage text provides context, support information, and additional usage details for users of the repository. The text must be in markdown format.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Full ARN of the repository.\n* `id` - The repository name.\n* `registry_id` - The registry ID where the repository was created.\n* `repository_uri` - The URI of the repository.\n\n## Timeouts\n\n`aws_ecrpublic_repository` provides the following [Timeouts](/docs/configuration/resources.html#timeouts)\nconfiguration options:\n\n- `delete` - (Default `20 minutes`) How long to wait for a repository to be deleted.\n\n## Import\n\nECR Public Repositories can be imported using the `repository_name`, e.g.,\n\n```\n$ terraform import aws_ecrpublic_repository.example example\n```\n",
    "basename": "ecrpublic_repository.html"
  },
  "ecs_account_setting_default.html": {
    "subcategory": "ECS",
    "layout": "aws",
    "page_title": "AWS: aws_ecs_account_setting_default",
    "description": "Provides an ECS Default account setting.",
    "preview": "# Resource: aws_ecs_account_setting_default\n\nProvides an ECS default …",
    "content": "\n\n# Resource: aws_ecs_account_setting_default\n\nProvides an ECS default account setting for a specific ECS Resource name within a specific region. More information can be found on the [ECS Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-account-settings.html).\n\n~> **NOTE:** The AWS API does not delete this resource. When you run `destroy`, the provider will attempt to disable the setting.\n\n~> **NOTE:** Your AWS account may not support disabling `containerInstanceLongArnFormat`, `serviceLongArnFormat`, and `taskLongArnFormat`. If your account does not support disabling these, \"destroying\" this resource will not disable the setting nor cause a Terraform error. However, the AWS Provider will log an AWS error: `InvalidParameterException: You can no longer disable Long Arn settings`.\n\n## Example Usage\n\n```terraform\nresource \"aws_ecs_account_setting_default\" \"test\" {\n  name  = \"taskLongArnFormat\"\n  value = \"enabled\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the account setting to set. Valid values are `serviceLongArnFormat`, `taskLongArnFormat`, `containerInstanceLongArnFormat`, `awsvpcTrunking` and `containerInsights`.\n* `value` - (Required) State of the setting. Valid values are `enabled` and `disabled`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ARN that identifies the account setting.\n* `prinicpal_arn` - ARN that identifies the account setting.\n\n## Import\n\nECS Account Setting defaults can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_ecs_account_setting_default.example taskLongArnFormat\n```\n",
    "basename": "ecs_account_setting_default.html"
  },
  "ecs_capacity_provider.html": {
    "subcategory": "ECS",
    "layout": "aws",
    "page_title": "AWS: aws_ecs_capacity_provider",
    "description": "Provides an ECS cluster capacity provider.",
    "preview": "# Resource: aws_ecs_capacity_provider\n\nProvides an ECS cluster …",
    "content": "\n\n# Resource: aws_ecs_capacity_provider\n\nProvides an ECS cluster capacity provider. More information can be found on the [ECS Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-capacity-providers.html).\n\n~> **NOTE:** Associating an ECS Capacity Provider to an Auto Scaling Group will automatically add the `AmazonECSManaged` tag to the Auto Scaling Group. This tag should be included in the `aws_autoscaling_group` resource configuration to prevent Terraform from removing it in subsequent executions as well as ensuring the `AmazonECSManaged` tag is propagated to all EC2 Instances in the Auto Scaling Group if `min_size` is above 0 on creation. Any EC2 Instances in the Auto Scaling Group without this tag must be manually be updated, otherwise they may cause unexpected scaling behavior and metrics.\n\n## Example Usage\n\n```terraform\nresource \"aws_autoscaling_group\" \"test\" {\n  # ... other configuration, including potentially other tags ...\n\n  tag {\n    key                 = \"AmazonECSManaged\"\n    value               = true\n    propagate_at_launch = true\n  }\n}\n\nresource \"aws_ecs_capacity_provider\" \"test\" {\n  name = \"test\"\n\n  auto_scaling_group_provider {\n    auto_scaling_group_arn         = aws_autoscaling_group.test.arn\n    managed_termination_protection = \"ENABLED\"\n\n    managed_scaling {\n      maximum_scaling_step_size = 1000\n      minimum_scaling_step_size = 1\n      status                    = \"ENABLED\"\n      target_capacity           = 10\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `auto_scaling_group_provider` - (Required) Configuration block for the provider for the ECS auto scaling group. Detailed below.\n* `name` - (Required) Name of the capacity provider.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `auto_scaling_group_provider`\n\n* `auto_scaling_group_arn` - (Required) - ARN of the associated auto scaling group.\n* `managed_scaling` - (Optional) - Configuration block defining the parameters of the auto scaling. Detailed below.\n* `managed_termination_protection` - (Optional) - Enables or disables container-aware termination of instances in the auto scaling group when scale-in happens. Valid values are `ENABLED` and `DISABLED`.\n\n### `managed_scaling`\n\n* `instance_warmup_period` - (Optional) Period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of 300 seconds is used.\n* `maximum_scaling_step_size` - (Optional) Maximum step adjustment size. A number between 1 and 10,000.\n* `minimum_scaling_step_size` - (Optional) Minimum step adjustment size. A number between 1 and 10,000.\n* `status` - (Optional) Whether auto scaling is managed by ECS. Valid values are `ENABLED` and `DISABLED`.\n* `target_capacity` - (Optional) Target utilization for the capacity provider. A number between 1 and 100.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN that identifies the capacity provider.\n* `id` - ARN that identifies the capacity provider.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nECS Capacity Providers can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_ecs_capacity_provider.example example\n```\n",
    "basename": "ecs_capacity_provider.html"
  },
  "ecs_cluster.html": {
    "subcategory": "ECS",
    "layout": "aws",
    "page_title": "AWS: aws_ecs_cluster",
    "description": "Provides an ECS cluster.",
    "preview": "# Resource: aws_ecs_cluster\n\nProvides an ECS cluster.\n\n## Example …",
    "content": "\n\n# Resource: aws_ecs_cluster\n\nProvides an ECS cluster.\n\n## Example Usage\n\n```terraform\nresource \"aws_ecs_cluster\" \"foo\" {\n  name = \"white-hart\"\n\n  setting {\n    name  = \"containerInsights\"\n    value = \"enabled\"\n  }\n}\n```\n\n## Example W/Log Configuration\n\n```terraform\nresource \"aws_kms_key\" \"example\" {\n  description             = \"example\"\n  deletion_window_in_days = 7\n}\n\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_ecs_cluster\" \"test\" {\n  name = \"example\"\n\n  configuration {\n    execute_command_configuration {\n      kms_key_id = aws_kms_key.example.arn\n      logging    = \"OVERRIDE\"\n\n      log_configuration {\n        cloud_watch_encryption_enabled = true\n        cloud_watch_log_group_name     = aws_cloudwatch_log_group.example.name\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `capacity_providers` - (Optional) List of short names of one or more capacity providers to associate with the cluster. Valid values also include `FARGATE` and `FARGATE_SPOT`.\n* `configuration` - (Optional) The execute command configuration for the cluster. Detailed below.\n* `default_capacity_provider_strategy` - (Optional) Configuration block for capacity provider strategy to use by default for the cluster. Can be one or more. Detailed below.\n* `name` - (Required) Name of the cluster (up to 255 letters, numbers, hyphens, and underscores)\n* `setting` - (Optional) Configuration block(s) with cluster settings. For example, this can be used to enable CloudWatch Container Insights for a cluster. Detailed below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `configuration`\n\n* `execute_command_configuration` - (Optional) The details of the execute command configuration. Detailed below.\n\n#### `execute_command_configuration`\n\n* `kms_key_id` - (Optional) The AWS Key Management Service key ID to encrypt the data between the local client and the container.\n* `log_configuration` - (Optional) The log configuration for the results of the execute command actions Required when `logging` is `OVERRIDE`. Detailed below.\n* `logging` - (Optional) The log setting to use for redirecting logs for your execute command results. Valid values are `NONE`, `DEFAULT`, and `OVERRIDE`.\n\n##### `log_configuration`\n\n* `cloud_watch_encryption_enabled` - (Optional) Whether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n* `cloud_watch_log_group_name` - (Optional) The name of the CloudWatch log group to send logs to.\n* `s3_bucket_name` - (Optional) The name of the S3 bucket to send logs to.\n* `s3_bucket_encryption_enabled` - (Optional) Whether or not to enable encryption on the logs sent to S3. If not specified, encryption will be disabled.\n* `s3_key_prefix` - (Optional) An optional folder in the S3 bucket to place logs in.\n\n### `default_capacity_provider_strategy`\n\n* `capacity_provider` - (Required) The short name of the capacity provider.\n* `weight` - (Optional) The relative percentage of the total number of launched tasks that should use the specified capacity provider.\n* `base` - (Optional) The number of tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined.\n\n### `setting`\n\n* `name` - (Required) Name of the setting to manage. Valid values: `containerInsights`.\n* `value` -  (Required) The value to assign to the setting. Value values are `enabled` and `disabled`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN that identifies the cluster.\n* `id` - ARN that identifies the cluster.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nECS clusters can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_ecs_cluster.stateless stateless-app\n```\n",
    "basename": "ecs_cluster.html"
  },
  "ecs_service.html": {
    "subcategory": "ECS",
    "layout": "aws",
    "page_title": "AWS: aws_ecs_service",
    "description": "Provides an ECS service.",
    "preview": "# Resource: aws_ecs_service\n\n-> **Note:** To prevent a race …",
    "content": "\n\n# Resource: aws_ecs_service\n\n-> **Note:** To prevent a race condition during service deletion, make sure to set `depends_on` to the related `aws_iam_role_policy`; otherwise, the policy may be destroyed too soon and the ECS service will then get stuck in the `DRAINING` state.\n\nProvides an ECS service - effectively a task that is expected to run until an error occurs or a user terminates it (typically a webserver or a database).\n\nSee [ECS Services section in AWS developer guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ecs_service\" \"mongo\" {\n  name            = \"mongodb\"\n  cluster         = aws_ecs_cluster.foo.id\n  task_definition = aws_ecs_task_definition.mongo.arn\n  desired_count   = 3\n  iam_role        = aws_iam_role.foo.arn\n  depends_on      = [aws_iam_role_policy.foo]\n\n  ordered_placement_strategy {\n    type  = \"binpack\"\n    field = \"cpu\"\n  }\n\n  load_balancer {\n    target_group_arn = aws_lb_target_group.foo.arn\n    container_name   = \"mongo\"\n    container_port   = 8080\n  }\n\n  placement_constraints {\n    type       = \"memberOf\"\n    expression = \"attribute:ecs.availability-zone in [us-west-2a, us-west-2b]\"\n  }\n}\n```\n\n### Ignoring Changes to Desired Count\n\nYou can utilize the generic Terraform resource [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` to create an ECS service with an initial count of running instances, then ignore any changes to that count caused externally (e.g., Application Autoscaling).\n\n```terraform\nresource \"aws_ecs_service\" \"example\" {\n  # ... other configurations ...\n\n  # Example: Create service with 2 instances to start\n  desired_count = 2\n\n  # Optional: Allow external changes without Terraform plan difference\n  lifecycle {\n    ignore_changes = [desired_count]\n  }\n}\n```\n\n### Daemon Scheduling Strategy\n\n```terraform\nresource \"aws_ecs_service\" \"bar\" {\n  name                = \"bar\"\n  cluster             = aws_ecs_cluster.foo.id\n  task_definition     = aws_ecs_task_definition.bar.arn\n  scheduling_strategy = \"DAEMON\"\n}\n```\n\n### External Deployment Controller\n\n```terraform\nresource \"aws_ecs_service\" \"example\" {\n  name    = \"example\"\n  cluster = aws_ecs_cluster.example.id\n\n  deployment_controller {\n    type = \"EXTERNAL\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the service (up to 255 letters, numbers, hyphens, and underscores)\n\nThe following arguments are optional:\n\n* `capacity_provider_strategy` - (Optional) Capacity provider strategies to use for the service. Can be one or more. These can be updated without destroying and recreating the service only if `force_new_deployment = true` and not changing from 0 `capacity_provider_strategy` blocks to greater than 0, or vice versa. See below.\n* `cluster` - (Optional) ARN of an ECS cluster.\n* `deployment_circuit_breaker` - (Optional) Configuration block for deployment circuit breaker. See below.\n* `deployment_controller` - (Optional) Configuration block for deployment controller configuration. See below.\n* `deployment_maximum_percent` - (Optional) Upper limit (as a percentage of the service's desiredCount) of the number of running tasks that can be running in a service during a deployment. Not valid when using the `DAEMON` scheduling strategy.\n* `deployment_minimum_healthy_percent` - (Optional) Lower limit (as a percentage of the service's desiredCount) of the number of running tasks that must remain running and healthy in a service during a deployment.\n* `desired_count` - (Optional) Number of instances of the task definition to place and keep running. Defaults to 0. Do not specify if using the `DAEMON` scheduling strategy.\n* `enable_ecs_managed_tags` - (Optional) Specifies whether to enable Amazon ECS managed tags for the tasks within the service.\n* `enable_execute_command` - (Optional) Specifies whether to enable Amazon ECS Exec for the tasks within the service.\n* `force_new_deployment` - (Optional) Enable to force a new task deployment of the service. This can be used to update tasks to use a newer Docker image with same image/tag combination (e.g., `myimage:latest`), roll Fargate tasks onto a newer platform version, or immediately deploy `ordered_placement_strategy` and `placement_constraints` updates.\n* `health_check_grace_period_seconds` - (Optional) Seconds to ignore failing load balancer health checks on newly instantiated tasks to prevent premature shutdown, up to 2147483647. Only valid for services configured to use load balancers.\n* `iam_role` - (Optional) ARN of the IAM role that allows Amazon ECS to make calls to your load balancer on your behalf. This parameter is required if you are using a load balancer with your service, but only if your task definition does not use the `awsvpc` network mode. If using `awsvpc` network mode, do not specify this role. If your account has already created the Amazon ECS service-linked role, that role is used by default for your service unless you specify a role here.\n* `launch_type` - (Optional) Launch type on which to run your service. The valid values are `EC2`, `FARGATE`, and `EXTERNAL`. Defaults to `EC2`.\n* `load_balancer` - (Optional) Configuration block for load balancers. See below.\n* `network_configuration` - (Optional) Network configuration for the service. This parameter is required for task definitions that use the `awsvpc` network mode to receive their own Elastic Network Interface, and it is not supported for other network modes. See below.\n* `ordered_placement_strategy` - (Optional) Service level strategy rules that are taken into consideration during task placement. List from top to bottom in order of precedence. Updates to this configuration will take effect next task deployment unless `force_new_deployment` is enabled. The maximum number of `ordered_placement_strategy` blocks is `5`. See below.\n* `placement_constraints` - (Optional) Rules that are taken into consideration during task placement. Updates to this configuration will take effect next task deployment unless `force_new_deployment` is enabled. Maximum number of `placement_constraints` is `10`. See below.\n* `platform_version` - (Optional) Platform version on which to run your service. Only applicable for `launch_type` set to `FARGATE`. Defaults to `LATEST`. More information about Fargate platform versions can be found in the [AWS ECS User Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html).\n* `propagate_tags` - (Optional) Specifies whether to propagate the tags from the task definition or the service to the tasks. The valid values are `SERVICE` and `TASK_DEFINITION`.\n* `scheduling_strategy` - (Optional) Scheduling strategy to use for the service. The valid values are `REPLICA` and `DAEMON`. Defaults to `REPLICA`. Note that [*Tasks using the Fargate launch type or the `CODE_DEPLOY` or `EXTERNAL` deployment controller types don't support the `DAEMON` scheduling strategy*](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html).\n* `service_registries` - (Optional) Service discovery registries for the service. The maximum number of `service_registries` blocks is `1`. See below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `task_definition` - (Optional) Family and revision (`family:revision`) or full ARN of the task definition that you want to run in your service. Required unless using the `EXTERNAL` deployment controller. If a revision is not specified, the latest `ACTIVE` revision is used.\n* `wait_for_steady_state` - (Optional) If `true`, Terraform will wait for the service to reach a steady state (like [`aws ecs wait services-stable`](https://docs.aws.amazon.com/cli/latest/reference/ecs/wait/services-stable.html)) before continuing. Default `false`.\n\n### capacity_provider_strategy\n\nThe `capacity_provider_strategy` configuration block supports the following:\n\n* `base` - (Optional) Number of tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined.\n* `capacity_provider` - (Required) Short name of the capacity provider.\n* `weight` - (Required) Relative percentage of the total number of launched tasks that should use the specified capacity provider.\n\n### deployment_circuit_breaker\n\nThe `deployment_circuit_breaker` configuration block supports the following:\n\n* `enable` - (Required) Whether to enable the deployment circuit breaker logic for the service.\n* `rollback` - (Required) Whether to enable Amazon ECS to roll back the service if a service deployment fails. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\n### deployment_controller\n\nThe `deployment_controller` configuration block supports the following:\n\n* `type` - (Optional) Type of deployment controller. Valid values: `CODE_DEPLOY`, `ECS`, `EXTERNAL`. Default: `ECS`.\n\n### load_balancer\n\n`load_balancer` supports the following:\n\n* `elb_name` - (Required for ELB Classic) Name of the ELB (Classic) to associate with the service.\n* `target_group_arn` - (Required for ALB/NLB) ARN of the Load Balancer target group to associate with the service.\n* `container_name` - (Required) Name of the container to associate with the load balancer (as it appears in a container definition).\n* `container_port` - (Required) Port on the container to associate with the load balancer.\n\n-> **Version note:** Multiple `load_balancer` configuration block support was added in Terraform AWS Provider version 2.22.0. This allows configuration of [ECS service support for multiple target groups](https://aws.amazon.com/about-aws/whats-new/2019/07/amazon-ecs-services-now-support-multiple-load-balancer-target-groups/).\n\n### network_configuration\n\n`network_configuration` support the following:\n\n* `subnets` - (Required) Subnets associated with the task or service.\n* `security_groups` - (Optional) Security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used.\n* `assign_public_ip` - (Optional) Assign a public IP address to the ENI (Fargate launch type only). Valid values are `true` or `false`. Default `false`.\n\nFor more information, see [Task Networking](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-networking.html)\n\n### ordered_placement_strategy\n\n`ordered_placement_strategy` supports the following:\n\n* `type` - (Required) Type of placement strategy. Must be one of: `binpack`, `random`, or `spread`\n* `field` - (Optional) For the `spread` placement strategy, valid values are `instanceId` (or `host`,\n which has the same effect), or any platform or custom attribute that is applied to a container instance.\n For the `binpack` type, valid values are `memory` and `cpu`. For the `random` type, this attribute is not\n needed. For more information, see [Placement Strategy](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PlacementStrategy.html).\n\n-> **Note:** for `spread`, `host` and `instanceId` will be normalized, by AWS, to be `instanceId`. This means the statefile will show `instanceId` but your config will differ if you use `host`.\n\n### placement_constraints\n\n`placement_constraints` support the following:\n\n* `type` - (Required) Type of constraint. The only valid values at this time are `memberOf` and `distinctInstance`.\n* `expression` -  (Optional) Cluster Query Language expression to apply to the constraint. Does not need to be specified for the `distinctInstance` type. For more information, see [Cluster Query Language in the Amazon EC2 Container Service Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html).\n\n### service_registries\n\n`service_registries` support the following:\n\n* `registry_arn` - (Required) ARN of the Service Registry. The currently supported service registry is Amazon Route 53 Auto Naming Service(`aws_service_discovery_service`). For more information, see [Service](https://docs.aws.amazon.com/Route53/latest/APIReference/API_autonaming_Service.html)\n* `port` - (Optional) Port value used if your Service Discovery service specified an SRV record.\n* `container_port` - (Optional) Port value, already specified in the task definition, to be used for your service discovery service.\n* `container_name` - (Optional) Container name value, already specified in the task definition, to be used for your service discovery service.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `cluster` - Amazon Resource Name (ARN) of cluster which the service runs on.\n* `desired_count` - Number of instances of the task definition.\n* `iam_role` - ARN of IAM role used for ELB.\n* `id` - ARN that identifies the service.\n* `name` - Name of the service.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_ecs_service` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `delete` - (Default `20 minutes`)\n\n## Import\n\nECS services can be imported using the `name` together with ecs cluster `name`, e.g.,\n\n```\n$ terraform import aws_ecs_service.imported cluster-name/service-name\n```\n",
    "basename": "ecs_service.html"
  },
  "ecs_tag.html": {
    "subcategory": "ECS",
    "layout": "aws",
    "page_title": "AWS: aws_ecs_tag",
    "description": "Manages an individual ECS resource tag",
    "preview": "# Resource: aws_ecs_tag\n\nManages an individual ECS resource tag. …",
    "content": "\n\n# Resource: aws_ecs_tag\n\nManages an individual ECS resource tag. This resource should only be used in cases where ECS resources are created outside Terraform (e.g., ECS Clusters implicitly created by Batch Compute Environments).\n\n~> **NOTE:** This tagging resource should not be combined with the Terraform resource for managing the parent resource. For example, using `aws_ecs_cluster` and `aws_ecs_tag` to manage tags of the same ECS Cluster will cause a perpetual difference where the `aws_ecs_cluster` resource will try to remove the tag being added by the `aws_ecs_tag` resource.\n\n~> **NOTE:** This tagging resource does not use the [provider `ignore_tags` configuration](/docs/providers/aws/index.html#ignore_tags).\n\n## Example Usage\n\n```terraform\nresource \"aws_batch_compute_environment\" \"example\" {\n  compute_environment_name = \"example\"\n  service_role             = aws_iam_role.example.arn\n  type                     = \"UNMANAGED\"\n}\n\nresource \"aws_ecs_tag\" \"example\" {\n  resource_arn = aws_batch_compute_environment.example.ecs_cluster_arn\n  key          = \"Name\"\n  value        = \"Hello World\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resource_arn` - (Required) Amazon Resource Name (ARN) of the ECS resource to tag.\n* `key` - (Required) Tag name.\n* `value` - (Required) Tag value.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ECS resource identifier and key, separated by a comma (`,`)\n\n## Import\n\n`aws_ecs_tag` can be imported by using the ECS resource identifier and key, separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_ecs_tag.example arn:aws:ecs:us-east-1:123456789012:cluster/example,Name\n```\n",
    "basename": "ecs_tag.html"
  },
  "ecs_task_definition.html": {
    "subcategory": "ECS",
    "layout": "aws",
    "page_title": "AWS: aws_ecs_task_definition",
    "description": "Manages a revision of an ECS task definition.",
    "preview": "# Resource: aws_ecs_task_definition\n\nManages a revision of an ECS …",
    "content": "\n\n# Resource: aws_ecs_task_definition\n\nManages a revision of an ECS task definition to be used in `aws_ecs_service`.\n\n## Example Usage\n\n### Basic Example\n\n```terraform\nresource \"aws_ecs_task_definition\" \"service\" {\n  family = \"service\"\n  container_definitions = jsonencode([\n    {\n      name      = \"first\"\n      image     = \"service-first\"\n      cpu       = 10\n      memory    = 512\n      essential = true\n      portMappings = [\n        {\n          containerPort = 80\n          hostPort      = 80\n        }\n      ]\n    },\n    {\n      name      = \"second\"\n      image     = \"service-second\"\n      cpu       = 10\n      memory    = 256\n      essential = true\n      portMappings = [\n        {\n          containerPort = 443\n          hostPort      = 443\n        }\n      ]\n    }\n  ])\n\n  volume {\n    name      = \"service-storage\"\n    host_path = \"/ecs/service-storage\"\n  }\n\n  placement_constraints {\n    type       = \"memberOf\"\n    expression = \"attribute:ecs.availability-zone in [us-west-2a, us-west-2b]\"\n  }\n}\n```\n\n### With AppMesh Proxy\n\n```terraform\nresource \"aws_ecs_task_definition\" \"service\" {\n  family                = \"service\"\n  container_definitions = file(\"task-definitions/service.json\")\n\n  proxy_configuration {\n    type           = \"APPMESH\"\n    container_name = \"applicationContainerName\"\n    properties = {\n      AppPorts         = \"8080\"\n      EgressIgnoredIPs = \"169.254.170.2,169.254.169.254\"\n      IgnoredUID       = \"1337\"\n      ProxyEgressPort  = 15001\n      ProxyIngressPort = 15000\n    }\n  }\n}\n```\n\n### Example Using `docker_volume_configuration`\n\n```terraform\nresource \"aws_ecs_task_definition\" \"service\" {\n  family                = \"service\"\n  container_definitions = file(\"task-definitions/service.json\")\n\n  volume {\n    name = \"service-storage\"\n\n    docker_volume_configuration {\n      scope         = \"shared\"\n      autoprovision = true\n      driver        = \"local\"\n\n      driver_opts = {\n        \"type\"   = \"nfs\"\n        \"device\" = \"${aws_efs_file_system.fs.dns_name}:/\"\n        \"o\"      = \"addr=${aws_efs_file_system.fs.dns_name},rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport\"\n      }\n    }\n  }\n}\n```\n\n### Example Using `efs_volume_configuration`\n\n```terraform\nresource \"aws_ecs_task_definition\" \"service\" {\n  family                = \"service\"\n  container_definitions = file(\"task-definitions/service.json\")\n\n  volume {\n    name = \"service-storage\"\n\n    efs_volume_configuration {\n      file_system_id          = aws_efs_file_system.fs.id\n      root_directory          = \"/opt/data\"\n      transit_encryption      = \"ENABLED\"\n      transit_encryption_port = 2999\n      authorization_config {\n        access_point_id = aws_efs_access_point.test.id\n        iam             = \"ENABLED\"\n      }\n    }\n  }\n}\n```\n\n### Example Using `fsx_windows_file_server_volume_configuration`\n\n```terraform\nresource \"aws_ecs_task_definition\" \"service\" {\n  family                = \"service\"\n  container_definitions = file(\"task-definitions/service.json\")\n\n  volume {\n    name = \"service-storage\"\n\n    fsx_windows_file_server_volume_configuration {\n      file_system_id = aws_fsx_windows_file_system.test.id\n      root_directory = \"\\\\data\"\n\n      authorization_config {\n        credentials_parameter = aws_secretsmanager_secret_version.test.arn\n        domain                = aws_directory_service_directory.test.name\n      }\n    }\n  }\n}\n\nresource \"aws_secretsmanager_secret_version\" \"test\" {\n  secret_id     = aws_secretsmanager_secret.test.id\n  secret_string = jsonencode({ username : \"admin\", password : aws_directory_service_directory.test.password })\n}\n```\n\n### Example Using `container_definitions` and `inference_accelerator`\n\n```terraform\nresource \"aws_ecs_task_definition\" \"test\" {\n  family                = \"test\"\n  container_definitions = <<TASK_DEFINITION\n[\n  {\n    \"cpu\": 10,\n    \"command\": [\"sleep\", \"10\"],\n    \"entryPoint\": [\"/\"],\n    \"environment\": [\n      {\"name\": \"VARNAME\", \"value\": \"VARVAL\"}\n    ],\n    \"essential\": true,\n    \"image\": \"jenkins\",\n    \"memory\": 128,\n    \"name\": \"jenkins\",\n    \"portMappings\": [\n      {\n        \"containerPort\": 80,\n        \"hostPort\": 8080\n      }\n    ],\n        \"resourceRequirements\":[\n            {\n                \"type\":\"InferenceAccelerator\",\n                \"value\":\"device_1\"\n            }\n        ]\n  }\n]\nTASK_DEFINITION\n\n  inference_accelerator {\n    device_name = \"device_1\"\n    device_type = \"eia1.medium\"\n  }\n}\n```\n\n### Example Using `runtime_platform` and `fargate`\n\n```terraform\nresource \"aws_ecs_task_definition\" \"test\" {\n  family                   = \"test\"\n  requires_compatibilities = [\"FARGATE\"]\n  network_mode             = \"awsvpc\"\n  cpu                      = 1024\n  memory                   = 2048\n  container_definitions    = <<TASK_DEFINITION\n[\n  {\n    \"name\": \"iis\",\n    \"image\": \"mcr.microsoft.com/windows/servercore/iis\",\n    \"cpu\": 1024,\n    \"memory\": 2048,\n    \"essential\": true\n  }\n]\nTASK_DEFINITION\n\n  runtime_platform {\n    operating_system_family = \"WINDOWS_SERVER_2019_CORE\"\n    cpu_architecture        = \"X86_64\"\n  }\n}\n```\n\n## Argument Reference\n\n~> **NOTE**: Proper escaping is required for JSON field values containing quotes (`\"`) such as `environment` values. If directly setting the JSON, they should be escaped as `\\\"` in the JSON,  e.g., `\"value\": \"I \\\"love\\\" escaped quotes\"`. If using a Terraform variable value, they should be escaped as `\\\\\\\"` in the variable, e.g., `value = \"I \\\\\\\"love\\\\\\\" escaped quotes\"` in the variable and `\"value\": \"${var.myvariable}\"` in the JSON.\n\nThe following arguments are required:\n\n* `container_definitions` - (Required) A list of valid [container definitions](http://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_ContainerDefinition.html) provided as a single valid JSON document. Please note that you should only provide values that are part of the container definition document. For a detailed description of what parameters are available, see the [Task Definition Parameters](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html) section from the official [Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide).\n* `family` - (Required) A unique name for your task definition.\n\nThe following arguments are optional:\n\n* `cpu` - (Optional) Number of cpu units used by the task. If the `requires_compatibilities` is `FARGATE` this field is required.\n* `execution_role_arn` - (Optional) ARN of the task execution role that the Amazon ECS container agent and the Docker daemon can assume.\n* `inference_accelerator` - (Optional) Configuration block(s) with Inference Accelerators settings. [Detailed below.](#inference_accelerator)\n* `ipc_mode` - (Optional) IPC resource namespace to be used for the containers in the task The valid values are `host`, `task`, and `none`.\n* `memory` - (Optional) Amount (in MiB) of memory used by the task. If the `requires_compatibilities` is `FARGATE` this field is required.\n* `network_mode` - (Optional) Docker networking mode to use for the containers in the task. Valid values are `none`, `bridge`, `awsvpc`, and `host`.\n* `runtime_platform` - (Optional) Configuration block for [runtime_platform](#runtime_platform) that containers in your task may use.\n* `pid_mode` - (Optional) Process namespace to use for the containers in the task. The valid values are `host` and `task`.\n* `placement_constraints` - (Optional) Configuration block for rules that are taken into consideration during task placement. Maximum number of `placement_constraints` is `10`. [Detailed below](#placement_constraints).\n* `proxy_configuration` - (Optional) Configuration block for the App Mesh proxy. [Detailed below.](#proxy_configuration)\n* `ephemeral_storage` - (Optional)  The amount of ephemeral storage to allocate for the task. This parameter is used to expand the total amount of ephemeral storage available, beyond the default amount, for tasks hosted on AWS Fargate. See [Ephemeral Storage](#ephemeral_storage).\n* `requires_compatibilities` - (Optional) Set of launch types required by the task. The valid values are `EC2` and `FARGATE`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `task_role_arn` - (Optional) ARN of IAM role that allows your Amazon ECS container task to make calls to other AWS services.\n* `volume` - (Optional) Configuration block for [volumes](#volume) that containers in your task may use. Detailed below.\n\n### volume\n\n* `docker_volume_configuration` - (Optional) Configuration block to configure a [docker volume](#docker_volume_configuration). Detailed below.\n* `efs_volume_configuration` - (Optional) Configuration block for an [EFS volume](#efs_volume_configuration). Detailed below.\n* `fsx_windows_file_server_volume_configuration` - (Optional) Configuration block for an [FSX Windows File Server volume](#fsx_windows_file_server_volume_configuration). Detailed below.\n* `host_path` - (Optional) Path on the host container instance that is presented to the container. If not set, ECS will create a nonpersistent data volume that starts empty and is deleted after the task has finished.\n* `name` - (Required) Name of the volume. This name is referenced in the `sourceVolume`\nparameter of container definition in the `mountPoints` section.\n\n### docker_volume_configuration\n\nFor more information, see [Specifying a Docker volume in your Task Definition Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-volumes.html#specify-volume-config)\n\n* `autoprovision` - (Optional) If this value is `true`, the Docker volume is created if it does not already exist. *Note*: This field is only used if the scope is `shared`.\n* `driver_opts` - (Optional) Map of Docker driver specific options.\n* `driver` - (Optional) Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement.\n* `labels` - (Optional) Map of custom metadata to add to your Docker volume.\n* `scope` - (Optional) Scope for the Docker volume, which determines its lifecycle, either `task` or `shared`.  Docker volumes that are scoped to a `task` are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as `shared` persist after the task stops.\n\n### efs_volume_configuration\n\nFor more information, see [Specifying an EFS volume in your Task Definition Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html#specify-efs-config)\n\n* `file_system_id` - (Required) ID of the EFS File System.\n* `root_directory` - (Optional) Directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying / will have the same effect as omitting this parameter. This argument is ignored when using `authorization_config`.\n* `transit_encryption` - (Optional) Whether or not to enable encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be enabled if Amazon EFS IAM authorization is used. Valid values: `ENABLED`, `DISABLED`. If this parameter is omitted, the default value of `DISABLED` is used.\n* `transit_encryption_port` - (Optional) Port to use for transit encryption. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses.\n* `authorization_config` - (Optional) Configuration block for [authorization](#authorization_config) for the Amazon EFS file system. Detailed below.\n\n### runtime_platform\n\n* `operating_system_family` - (Optional) If the `requires_compatibilities` is `FARGATE` this field is required; must be set to a valid option from the [operating system family in the runtime platform](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#runtime-platform) setting\n* `cpu_architecture` - (Optional) Must be set to either `X86_64` or `ARM64`; see [cpu architecture](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#runtime-platform)\n\n#### authorization_config\n\n* `access_point_id` - (Optional) Access point ID to use. If an access point is specified, the root directory value will be relative to the directory set for the access point. If specified, transit encryption must be enabled in the EFSVolumeConfiguration.\n* `iam` - (Optional) Whether or not to use the Amazon ECS task IAM role defined in a task definition when mounting the Amazon EFS file system. If enabled, transit encryption must be enabled in the EFSVolumeConfiguration. Valid values: `ENABLED`, `DISABLED`. If this parameter is omitted, the default value of `DISABLED` is used.\n\n### fsx_windows_file_server_volume_configuration\n\nFor more information, see [Specifying an FSX Windows File Server volume in your Task Definition Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/tutorial-wfsx-volumes.html)\n\n* `file_system_id` - (Required) The Amazon FSx for Windows File Server file system ID to use.\n* `root_directory` - (Required) The directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.\n* `authorization_config` - (Required) Configuration block for [authorization](#authorization_config) for the Amazon FSx for Windows File Server file system detailed below.\n\n#### authorization_config\n\n* `credentials_parameter` - (Required) The authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an AWS Secrets Manager secret or AWS Systems Manager Parameter Store parameter. The ARNs refer to the stored credentials.\n* `domain` - (Required) A fully qualified domain name hosted by an AWS Directory Service Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.\n\n### placement_constraints\n\n* `expression` -  (Optional) Cluster Query Language expression to apply to the constraint. For more information, see [Cluster Query Language in the Amazon EC2 Container Service Developer Guide](http://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html).\n* `type` - (Required) Type of constraint. Use `memberOf` to restrict selection to a group of valid candidates. Note that `distinctInstance` is not supported in task definitions.\n\n### proxy_configuration\n\n* `container_name` - (Required) Name of the container that will serve as the App Mesh proxy.\n* `properties` - (Required) Set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified a key-value mapping.\n* `type` - (Optional) Proxy type. The default value is `APPMESH`. The only supported value is `APPMESH`.\n\n### ephemeral_storage\n\n* `size_in_gib` - (Required) The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is `21` GiB and the maximum supported value is `200` GiB.\n\n### inference_accelerator\n\n* `device_name` - (Required) Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement.\n* `device_type` - (Required) Elastic Inference accelerator type to use.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Full ARN of the Task Definition (including both `family` and `revision`).\n* `revision` - Revision of the task in a particular family.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nECS Task Definitions can be imported via their Amazon Resource Name (ARN):\n\n```\n$ terraform import aws_ecs_task_definition.example arn:aws:ecs:us-east-1:012345678910:task-definition/mytaskfamily:123\n```\n",
    "basename": "ecs_task_definition.html"
  },
  "ecs_task_set.html": {
    "subcategory": "ECS",
    "layout": "aws",
    "page_title": "AWS: aws_ecs_task_set",
    "description": "Provides an ECS task set.",
    "preview": "# Resource: aws_ecs_task_set\n\nProvides an ECS task set - effectively …",
    "content": "\n\n# Resource: aws_ecs_task_set\n\nProvides an ECS task set - effectively a task that is expected to run until an error occurs or a user terminates it (typically a webserver or a database).\n\nSee [ECS Task Set section in AWS developer guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-external.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ecs_task_set\" \"example\" {\n  service         = aws_ecs_service.example.id\n  cluster         = aws_ecs_cluster.example.id\n  task_definition = aws_ecs_task_definition.example.arn\n\n  load_balancer {\n    target_group_arn = aws_lb_target_group.example.arn\n    container_name   = \"mongo\"\n    container_port   = 8080\n  }\n}\n```\n\n### Ignoring Changes to Scale\n\nYou can utilize the generic Terraform resource [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` to create an ECS service with an initial count of running instances, then ignore any changes to that count caused externally (e.g. Application Autoscaling).\n\n```terraform\nresource \"aws_ecs_task_set\" \"example\" {\n  # ... other configurations ...\n\n  # Example: Run 50% of the servcie's desired count\n  scale {\n    value = 50.0\n  }\n\n  # Optional: Allow external changes without Terraform plan difference\n  lifecycle {\n    ignore_changes = [\"scale\"]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `service` - (Required) The short name or ARN of the ECS service.\n* `cluster` - (Required) The short name or ARN of the cluster that hosts the service to create the task set in.\n* `task_definition` - (Required) The family and revision (`family:revision`) or full ARN of the task definition that you want to run in your service.\n\nThe following arguments are optional:\n\n* `capacity_provider_strategy` - (Optional) The capacity provider strategy to use for the service. Can be one or more.  [Defined below](#capacity_provider_strategy).\n* `external_id` - (Optional) The external ID associated with the task set.\n* `force_delete` - (Optional) Whether to allow deleting the task set without waiting for scaling down to 0. You can force a task set to delete even if it's in the process of scaling a resource. Normally, Terraform drains all the tasks before deleting the task set. This bypasses that behavior and potentially leaves resources dangling.\n* `launch_type` - (Optional) The launch type on which to run your service. The valid values are `EC2`, `FARGATE`, and `EXTERNAL`. Defaults to `EC2`.\n* `load_balancer` - (Optional) Details on load balancers that are used with a task set. [Detailed below](#load_balancer).\n* `platform_version` - (Optional) The platform version on which to run your service. Only applicable for `launch_type` set to `FARGATE`. Defaults to `LATEST`. More information about Fargate platform versions can be found in the [AWS ECS User Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html).\n* `network_configuration` - (Optional) The network configuration for the service. This parameter is required for task definitions that use the `awsvpc` network mode to receive their own Elastic Network Interface, and it is not supported for other network modes. [Detailed below](#network_configuration).\n* `scale` - (Optional) A floating-point percentage of the desired number of tasks to place and keep running in the task set. [Detailed below](#scale).\n* `service_registries` - (Optional) The service discovery registries for the service. The maximum number of `service_registries` blocks is `1`. [Detailed below](#service_registries).\n* `tags` - (Optional) A map of tags to assign to the file system. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level. If you have set `copy_tags_to_backups` to true, and you specify one or more tags, no existing file system tags are copied from the file system to the backup.\n* `wait_until_stable` - (Optional) Whether `terraform` should wait until the task set has reached `STEADY_STATE`.\n* `wait_until_stable_timeout` - (Optional) Wait timeout for task set to reach `STEADY_STATE`. Valid time units include `ns`, `us` (or `µs`), `ms`, `s`, `m`, and `h`. Default `10m`.\n\n## capacity_provider_strategy\n\nThe `capacity_provider_strategy` configuration block supports the following:\n\n* `capacity_provider` - (Required) The short name or full Amazon Resource Name (ARN) of the capacity provider.\n* `weight` - (Required) The relative percentage of the total number of launched tasks that should use the specified capacity provider.\n* `base` - (Optional) The number of tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined.\n\n## load_balancer\n\nThe `load_balancer` configuration block supports the following:\n\n* `container_name` - (Required) The name of the container to associate with the load balancer (as it appears in a container definition).\n* `load_balancer_name` - (Optional, Required for ELB Classic) The name of the ELB (Classic) to associate with the service.\n* `target_group_arn` - (Optional, Required for ALB/NLB) The ARN of the Load Balancer target group to associate with the service.\n* `container_port` - (Optional) The port on the container to associate with the load balancer. Defaults to `0` if not specified.\n\n~> **Note:** Specifying multiple `load_balancer` configurations is still not supported by AWS for ECS task set.\n\n## network_configuration\n\nThe `network_configuration` configuration block supports the following:\n\n* `subnets` - (Required) The subnets associated with the task or service. Maximum of 16.\n* `security_groups` - (Optional) The security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. Maximum of 5.\n* `assign_public_ip` - (Optional) Whether to assign a public IP address to the ENI (`FARGATE` launch type only). Valid values are `true` or `false`. Default `false`.\n\nFor more information, see [Task Networking](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-networking.html).\n\n## scale\n\nThe `scale` configuration block supports the following:\n\n* `unit` - (Optional) The unit of measure for the scale value. Default: `PERCENT`.\n* `value` - (Optional) The value, specified as a percent total of a service's `desiredCount`, to scale the task set. Defaults to `0` if not specified. Accepted values are numbers between 0.0 and 100.0.\n\n## service_registries\n\n`service_registries` support the following:\n\n* `registry_arn` - (Required) The ARN of the Service Registry. The currently supported service registry is Amazon Route 53 Auto Naming Service([`aws_service_discovery_service` resource](/docs/providers/aws/r/service_discovery_service.html)). For more information, see [Service](https://docs.aws.amazon.com/Route53/latest/APIReference/API_autonaming_Service.html).\n* `port` - (Optional) The port value used if your Service Discovery service specified an SRV record.\n* `container_port` - (Optional) The port value, already specified in the task definition, to be used for your service discovery service.\n* `container_name` - (Optional) The container name value, already specified in the task definition, to be used for your service discovery service.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The `task_set_id`, `service` and `cluster` separated by commas (`,`).\n* `arn` - The Amazon Resource Name (ARN) that identifies the task set.\n* `stability_status` - The stability status. This indicates whether the task set has reached a steady state.\n* `status` - The status of the task set.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `task_set_id` - The ID of the task set.\n\n## Import\n\nECS Task Sets can be imported via the `task_set_id`, `service`, and `cluster` separated by commas (`,`) e.g.\n\n```\n$ terraform import aws_ecs_task_set.example ecs-svc/7177320696926227436,arn:aws:ecs:us-west-2:123456789101:service/example/example-1234567890,arn:aws:ecs:us-west-2:123456789101:cluster/example\n```\n",
    "basename": "ecs_task_set.html"
  },
  "efs_access_point.html": {
    "subcategory": "EFS",
    "layout": "aws",
    "page_title": "AWS: aws_efs_access_point",
    "description": "Provides an Elastic File System (EFS) access point.",
    "preview": "# Resource: aws_efs_access_point\n\nProvides an Elastic File System …",
    "content": "\n\n# Resource: aws_efs_access_point\n\nProvides an Elastic File System (EFS) access point.\n\n## Example Usage\n\n```terraform\nresource \"aws_efs_access_point\" \"test\" {\n  file_system_id = aws_efs_file_system.foo.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `file_system_id` - (Required) ID of the file system for which the access point is intended.\n* `posix_user` - (Optional) Operating system user and group applied to all file system requests made using the access point. [Detailed](#posix_user) below.\n* `root_directory`- (Optional) Directory on the Amazon EFS file system that the access point provides access to. [Detailed](#root_directory) below.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### posix_user\n\n* `gid` - (Required) POSIX group ID used for all file system operations using this access point.\n* `secondary_gids` - (Optional) Secondary POSIX group IDs used for all file system operations using this access point.\n* `uid` - (Required) POSIX user ID used for all file system operations using this access point.\n\n### root_directory\n\nThe access point exposes the specified file system path as the root directory of your file system to applications using the access point. NFS clients using the access point can only access data in the access point's RootDirectory and it's subdirectories.\n\n* `creation_info` - (Optional) POSIX IDs and permissions to apply to the access point's Root Directory. See [Creation Info](#creation_info) below.\n* `path` - (Optional) Path on the EFS file system to expose as the root directory to NFS clients using the access point to access the EFS file system. A path can have up to four subdirectories. If the specified path does not exist, you are required to provide `creation_info`.\n\n### creation_info\n\nIf the `path` specified does not exist, EFS creates the root directory using the `creation_info` settings when a client connects to an access point.\n\n* `owner_gid` - (Required) POSIX group ID to apply to the `root_directory`.\n* `owner_uid` - (Required) POSIX user ID to apply to the `root_directory`.\n* `permissions` - (Required) POSIX permissions to apply to the RootDirectory, in the format of an octal number representing the file's mode bits.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the access point.\n* `file_system_arn` - ARN of the file system.\n* `id` - ID of the access point.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nThe EFS access points can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_efs_access_point.test fsap-52a643fb\n```\n",
    "basename": "efs_access_point.html"
  },
  "efs_backup_policy.html": {
    "subcategory": "EFS",
    "layout": "aws",
    "page_title": "AWS: aws_efs_backup_policy",
    "description": "Provides an Elastic File System (EFS) Backup Policy resource.",
    "preview": "# Resource: aws_efs_backup_policy\n\nProvides an Elastic File System …",
    "content": "\n\n# Resource: aws_efs_backup_policy\n\nProvides an Elastic File System (EFS) Backup Policy resource.\nBackup policies turn automatic backups on or off for an existing file system.\n\n## Example Usage\n\n```terraform\nresource \"aws_efs_file_system\" \"fs\" {\n  creation_token = \"my-product\"\n}\n\nresource \"aws_efs_backup_policy\" \"policy\" {\n  file_system_id = aws_efs_file_system.fs.id\n\n  backup_policy {\n    status = \"ENABLED\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `file_system_id` - (Required) The ID of the EFS file system.\n* `backup_policy` - (Required) A backup_policy object (documented below).\n\n### Backup Policy Arguments\nFor **backup_policy** the following attributes are supported:\n\n* `status` - (Required) A status of the backup policy. Valid values: `ENABLED`, `DISABLED`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID that identifies the file system (e.g., fs-ccfc0d65).\n\n## Import\n\nThe EFS backup policies can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_efs_backup_policy.example fs-6fa144c6\n```\n",
    "basename": "efs_backup_policy.html"
  },
  "efs_file_system.html": {
    "subcategory": "EFS",
    "layout": "aws",
    "page_title": "AWS: aws_efs_file_system",
    "description": "Provides an Elastic File System (EFS) File System resource.",
    "preview": "# Resource: aws_efs_file_system\n\nProvides an Elastic File System …",
    "content": "\n\n# Resource: aws_efs_file_system\n\nProvides an Elastic File System (EFS) File System resource.\n\n## Example Usage\n\n### EFS File System w/ tags\n\n```terraform\nresource \"aws_efs_file_system\" \"foo\" {\n  creation_token = \"my-product\"\n\n  tags = {\n    Name = \"MyProduct\"\n  }\n}\n```\n\n### Using lifecycle policy\n\n```terraform\nresource \"aws_efs_file_system\" \"foo_with_lifecyle_policy\" {\n  creation_token = \"my-product\"\n\n  lifecycle_policy {\n    transition_to_ia = \"AFTER_30_DAYS\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `availability_zone_name` - (Optional) the AWS Availability Zone in which to create the file system. Used to create a file system that uses One Zone storage classes. See [user guide](https://docs.aws.amazon.com/efs/latest/ug/storage-classes.html) for more information.\n* `creation_token` - (Optional) A unique name (a maximum of 64 characters are allowed)\nused as reference when creating the Elastic File System to ensure idempotent file\nsystem creation. By default generated by Terraform. See [Elastic File System](http://docs.aws.amazon.com/efs/latest/ug/)\nuser guide for more information.\n* `encrypted` - (Optional) If true, the disk will be encrypted.\n* `kms_key_id` - (Optional) The ARN for the KMS encryption key. When specifying kms_key_id, encrypted needs to be set to true.\n* `lifecycle_policy` - (Optional) A file system [lifecycle policy](https://docs.aws.amazon.com/efs/latest/ug/API_LifecyclePolicy.html) object (documented below).\n* `performance_mode` - (Optional) The file system performance mode. Can be either `\"generalPurpose\"` or `\"maxIO\"` (Default: `\"generalPurpose\"`).\n* `provisioned_throughput_in_mibps` - (Optional) The throughput, measured in MiB/s, that you want to provision for the file system. Only applicable with `throughput_mode` set to `provisioned`.\n* `tags` - (Optional) A map of tags to assign to the file system. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `throughput_mode` - (Optional) Throughput mode for the file system. Defaults to `bursting`. Valid values: `bursting`, `provisioned`. When using `provisioned`, also set `provisioned_throughput_in_mibps`.\n\n### Lifecycle Policy Arguments\nFor **lifecycle_policy** the following attributes are supported:\n\n* `transition_to_ia` - (Optional) Indicates how long it takes to transition files to the IA storage class. Valid values: `AFTER_7_DAYS`, `AFTER_14_DAYS`, `AFTER_30_DAYS`, `AFTER_60_DAYS`, or `AFTER_90_DAYS`.\n* `transition_to_primary_storage_class` - (Optional) Describes the policy used to transition a file from infequent access storage to primary storage. Valid values: `AFTER_1_ACCESS`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name of the file system.\n* `availability_zone_id` - The identifier of the Availability Zone in which the file system's One Zone storage classes exist.\n* `id` - The ID that identifies the file system (e.g., fs-ccfc0d65).\n* `dns_name` - The DNS name for the filesystem per [documented convention](http://docs.aws.amazon.com/efs/latest/ug/mounting-fs-mount-cmd-dns-name.html).\n* `owner_id` - The AWS account that created the file system. If the file system was createdby an IAM user, the parent account to which the user belongs is the owner.\n* `number_of_mount_targets` - The current number of mount targets that the file system has.\n* `size_in_bytes` - The latest known metered size (in bytes) of data stored in the file system, the value is not the exact size that the file system was at any point in time. See [Size In Bytes](#size-in-bytes).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n### Size In Bytes\n\n* `value` - The latest known metered size (in bytes) of data stored in the file system.\n* `value_in_ia` - The latest known metered size (in bytes) of data stored in the Infrequent Access storage class.\n* `value_in_standard` - The latest known metered size (in bytes) of data stored in the Standard storage class.\n\n## Import\n\nThe EFS file systems can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_efs_file_system.foo fs-6fa144c6\n```\n",
    "basename": "efs_file_system.html"
  },
  "efs_file_system_policy.html": {
    "subcategory": "EFS",
    "layout": "aws",
    "page_title": "AWS: aws_efs_file_system_policy",
    "description": "Provides an Elastic File System (EFS) File System Policy resource.",
    "preview": "# Resource: aws_efs_file_system_policy\n\nProvides an Elastic File …",
    "content": "\n\n# Resource: aws_efs_file_system_policy\n\nProvides an Elastic File System (EFS) File System Policy resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_efs_file_system\" \"fs\" {\n  creation_token = \"my-product\"\n}\n\nresource \"aws_efs_file_system_policy\" \"policy\" {\n  file_system_id = aws_efs_file_system.fs.id\n\n  bypass_policy_lockout_safety_check = true\n\n  policy = <<POLICY\n{\n    \"Version\": \"2012-10-17\",\n    \"Id\": \"ExamplePolicy01\",\n    \"Statement\": [\n        {\n            \"Sid\": \"ExampleStatement01\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"*\"\n            },\n            \"Resource\": \"${aws_efs_file_system.test.arn}\",\n            \"Action\": [\n                \"elasticfilesystem:ClientMount\",\n                \"elasticfilesystem:ClientWrite\"\n            ],\n            \"Condition\": {\n                \"Bool\": {\n                    \"aws:SecureTransport\": \"true\"\n                }\n            }\n        }\n    ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `file_system_id` - (Required) The ID of the EFS file system.\n* `bypass_policy_lockout_safety_check` - (Optional) A flag to indicate whether to bypass the `aws_efs_file_system_policy` lockout safety check. The policy lockout safety check determines whether the policy in the request will prevent the principal making the request will be locked out from making future `PutFileSystemPolicy` requests on the file system. Set `bypass_policy_lockout_safety_check` to `true` only when you intend to prevent the principal that is making the request from making a subsequent `PutFileSystemPolicy` request on the file system. The default value is `false`.\n* `policy` - (Required) The JSON formatted file system policy for the EFS file system. see [Docs](https://docs.aws.amazon.com/efs/latest/ug/access-control-overview.html#access-control-manage-access-intro-resource-policies) for more info.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID that identifies the file system (e.g., fs-ccfc0d65).\n\n## Import\n\nThe EFS file system policies can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_efs_file_system_policy.foo fs-6fa144c6\n```\n",
    "basename": "efs_file_system_policy.html"
  },
  "efs_mount_target.html": {
    "subcategory": "EFS",
    "layout": "aws",
    "page_title": "AWS: aws_efs_mount_target",
    "description": "Provides an Elastic File System (EFS) mount target.",
    "preview": "# Resource: aws_efs_mount_target\n\nProvides an Elastic File System …",
    "content": "\n\n# Resource: aws_efs_mount_target\n\nProvides an Elastic File System (EFS) mount target.\n\n## Example Usage\n\n```terraform\nresource \"aws_efs_mount_target\" \"alpha\" {\n  file_system_id = aws_efs_file_system.foo.id\n  subnet_id      = aws_subnet.alpha.id\n}\n\nresource \"aws_vpc\" \"foo\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"alpha\" {\n  vpc_id            = aws_vpc.foo.id\n  availability_zone = \"us-west-2a\"\n  cidr_block        = \"10.0.1.0/24\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `file_system_id` - (Required) The ID of the file system for which the mount target is intended.\n* `subnet_id` - (Required) The ID of the subnet to add the mount target in.\n* `ip_address` - (Optional) The address (within the address range of the specified subnet) at\nwhich the file system may be mounted via the mount target.\n* `security_groups` - (Optional) A list of up to 5 VPC security group IDs (that must\nbe for the same VPC as subnet specified) in effect for the mount target.\n\n## Attributes Reference\n\n~> **Note:** The `dns_name` and `mount_target_dns_name` attributes are only useful if the mount target is in a VPC that has\nsupport for DNS hostnames enabled. See [Using DNS with Your VPC](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-dns.html)\nand [VPC resource](/docs/providers/aws/r/vpc.html#enable_dns_hostnames) in Terraform for more information.\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the mount target.\n* `dns_name` - The DNS name for the EFS file system.\n* `mount_target_dns_name` - The DNS name for the given subnet/AZ per [documented convention](http://docs.aws.amazon.com/efs/latest/ug/mounting-fs-mount-cmd-dns-name.html).\n* `file_system_arn` - Amazon Resource Name of the file system.\n* `network_interface_id` - The ID of the network interface that Amazon EFS created when it created the mount target.\n* `availability_zone_name` - The name of the Availability Zone (AZ) that the mount target resides in.\n* `availability_zone_id` - The unique and consistent identifier of the Availability Zone (AZ) that the mount target resides in.\n* `owner_id` - AWS account ID that owns the resource.\n\n## Import\n\nThe EFS mount targets can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_efs_mount_target.alpha fsmt-52a643fb\n```\n",
    "basename": "efs_mount_target.html"
  },
  "egress_only_internet_gateway.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_egress_only_internet_gateway",
    "description": "Provides a resource to create an egress-only Internet gateway.",
    "preview": "# Resource: aws_egress_only_internet_gateway\n\n[IPv6 only] Creates an …",
    "content": "\n\n# Resource: aws_egress_only_internet_gateway\n\n[IPv6 only] Creates an egress-only Internet gateway for your VPC.\nAn egress-only Internet gateway is used to enable outbound communication\nover IPv6 from instances in your VPC to the Internet, and prevents hosts\noutside of your VPC from initiating an IPv6 connection with your instance.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"example\" {\n  cidr_block                       = \"10.1.0.0/16\"\n  assign_generated_ipv6_cidr_block = true\n}\n\nresource \"aws_egress_only_internet_gateway\" \"example\" {\n  vpc_id = aws_vpc.example.id\n\n  tags = {\n    Name = \"main\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Required) The VPC ID to create in.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the egress-only Internet gateway.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEgress-only Internet gateways can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_egress_only_internet_gateway.example eigw-015e0e244e24dfe8a\n```\n",
    "basename": "egress_only_internet_gateway.html"
  },
  "eip.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_eip",
    "description": "Provides an Elastic IP resource.",
    "preview": "# Resource: aws_eip\n\nProvides an Elastic IP resource.\n\n~> **Note:** …",
    "content": "\n\n# Resource: aws_eip\n\nProvides an Elastic IP resource.\n\n~> **Note:** EIP may require IGW to exist prior to association. Use `depends_on` to set an explicit dependency on the IGW.\n\n~> **Note:** Do not use `network_interface` to associate the EIP to `aws_lb` or `aws_nat_gateway` resources. Instead use the `allocation_id` available in those resources to allow AWS to manage the association, otherwise you will see `AuthFailure` errors.\n\n## Example Usage\n\n### Single EIP associated with an instance\n\n```terraform\nresource \"aws_eip\" \"lb\" {\n  instance = aws_instance.web.id\n  vpc      = true\n}\n```\n\n### Multiple EIPs associated with a single network interface\n\n```terraform\nresource \"aws_network_interface\" \"multi-ip\" {\n  subnet_id   = aws_subnet.main.id\n  private_ips = [\"10.0.0.10\", \"10.0.0.11\"]\n}\n\nresource \"aws_eip\" \"one\" {\n  vpc                       = true\n  network_interface         = aws_network_interface.multi-ip.id\n  associate_with_private_ip = \"10.0.0.10\"\n}\n\nresource \"aws_eip\" \"two\" {\n  vpc                       = true\n  network_interface         = aws_network_interface.multi-ip.id\n  associate_with_private_ip = \"10.0.0.11\"\n}\n```\n\n### Attaching an EIP to an Instance with a pre-assigned private ip (VPC Only)\n\n```terraform\nresource \"aws_vpc\" \"default\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n}\n\nresource \"aws_internet_gateway\" \"gw\" {\n  vpc_id = aws_vpc.default.id\n}\n\nresource \"aws_subnet\" \"tf_test_subnet\" {\n  vpc_id                  = aws_vpc.default.id\n  cidr_block              = \"10.0.0.0/24\"\n  map_public_ip_on_launch = true\n\n  depends_on = [aws_internet_gateway.gw]\n}\n\nresource \"aws_instance\" \"foo\" {\n  # us-west-2\n  ami           = \"ami-5189a661\"\n  instance_type = \"t2.micro\"\n\n  private_ip = \"10.0.0.12\"\n  subnet_id  = aws_subnet.tf_test_subnet.id\n}\n\nresource \"aws_eip\" \"bar\" {\n  vpc = true\n\n  instance                  = aws_instance.foo.id\n  associate_with_private_ip = \"10.0.0.12\"\n  depends_on                = [aws_internet_gateway.gw]\n}\n```\n\n### Allocating EIP from the BYOIP pool\n\n```terraform\nresource \"aws_eip\" \"byoip-ip\" {\n  vpc              = true\n  public_ipv4_pool = \"ipv4pool-ec2-012345\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address` - (Optional) IP address from an EC2 BYOIP pool. This option is only available for VPC EIPs.\n* `associate_with_private_ip` - (Optional) User-specified primary or secondary private IP address to associate with the Elastic IP address. If no private IP address is specified, the Elastic IP address is associated with the primary private IP address.\n* `customer_owned_ipv4_pool` - (Optional) ID  of a customer-owned address pool. For more on customer owned IP addressed check out [Customer-owned IP addresses guide](https://docs.aws.amazon.com/outposts/latest/userguide/outposts-networking-components.html#ip-addressing).\n* `instance` - (Optional) EC2 instance ID.\n* `network_border_group` - (Optional) Location from which the IP address is advertised. Use this parameter to limit the address to this location.\n* `network_interface` - (Optional) Network interface ID to associate with.\n* `public_ipv4_pool` - (Optional) EC2 IPv4 address pool identifier or `amazon`. This option is only available for VPC EIPs.\n* `tags` - (Optional) Map of tags to assign to the resource. Tags can only be applied to EIPs in a VPC. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc` - (Optional) Boolean if the EIP is in a VPC or not.\n\n~> **NOTE:** You can specify either the `instance` ID or the `network_interface` ID, but not both. Including both will **not** return an error from the AWS API, but will have undefined behavior. See the relevant [AssociateAddress API Call][1] for more information.\n\n~> **NOTE:** Specifying both `public_ipv4_pool` and `address` won't cause an error but `address` will be used in the\ncase both options are defined as the api only requires one or the other.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `allocation_id` - ID that AWS assigns to represent the allocation of the Elastic IP address for use with instances in a VPC.\n* `association_id` - ID representing the association of the address with an instance in a VPC.\n* `carrier_ip` - Carrier IP address.\n* `customer_owned_ip` - Customer owned IP.\n* `domain` - Indicates if this EIP is for use in VPC (`vpc`) or EC2 Classic (`standard`).\n* `id` - Contains the EIP allocation ID.\n* `private_dns` - The Private DNS associated with the Elastic IP address (if in VPC).\n* `private_ip` - Contains the private IP address (if in VPC).\n* `public_dns` - Public DNS associated with the Elastic IP address.\n* `public_ip` - Contains the public IP address.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n~> **Note:** The resource computes the `public_dns` and `private_dns` attributes according to the [VPC DNS Guide](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html#vpc-dns-hostnames) as they are not available with the EC2 API.\n\n## Timeouts\n\n`aws_eip` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `read` - (Default `15 minutes`) How long to wait querying for information about EIPs.\n- `update` - (Default `5 minutes`) How long to wait for an EIP to be updated.\n- `delete` - (Default `3 minutes`) How long to wait for an EIP to be deleted.\n\n## Import\n\nEIPs in a VPC can be imported using their Allocation ID, e.g.,\n\n```\n$ terraform import aws_eip.bar eipalloc-00a10e96\n```\n\nEIPs in EC2 Classic can be imported using their Public IP, e.g.,\n\n```\n$ terraform import aws_eip.bar 52.0.0.0\n```\n\n[1]: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_AssociateAddress.html\n",
    "basename": "eip.html"
  },
  "eip_association.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_eip_association",
    "description": "Provides an AWS EIP Association",
    "preview": "# Resource: aws_eip_association\n\nProvides an AWS EIP Association as …",
    "content": "\n\n# Resource: aws_eip_association\n\nProvides an AWS EIP Association as a top level resource, to associate and\ndisassociate Elastic IPs from AWS Instances and Network Interfaces.\n\n~> **NOTE:** Do not use this resource to associate an EIP to `aws_lb` or `aws_nat_gateway` resources. Instead use the `allocation_id` available in those resources to allow AWS to manage the association, otherwise you will see `AuthFailure` errors.\n\n~> **NOTE:** `aws_eip_association` is useful in scenarios where EIPs are either\npre-existing or distributed to customers or users and therefore cannot be changed.\n\n## Example Usage\n\n```terraform\nresource \"aws_eip_association\" \"eip_assoc\" {\n  instance_id   = aws_instance.web.id\n  allocation_id = aws_eip.example.id\n}\n\nresource \"aws_instance\" \"web\" {\n  ami               = \"ami-21f78e11\"\n  availability_zone = \"us-west-2a\"\n  instance_type     = \"t2.micro\"\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n\nresource \"aws_eip\" \"example\" {\n  vpc = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `allocation_id` - (Optional) The allocation ID. This is required for EC2-VPC.\n* `allow_reassociation` - (Optional, Boolean) Whether to allow an Elastic IP to\nbe re-associated. Defaults to `true` in VPC.\n* `instance_id` - (Optional) The ID of the instance. This is required for\nEC2-Classic. For EC2-VPC, you can specify either the instance ID or the\nnetwork interface ID, but not both. The operation fails if you specify an\ninstance ID unless exactly one network interface is attached.\n* `network_interface_id` - (Optional) The ID of the network interface. If the\ninstance has more than one network interface, you must specify a network\ninterface ID.\n* `private_ip_address` - (Optional) The primary or secondary private IP address\nto associate with the Elastic IP address. If no private IP address is\nspecified, the Elastic IP address is associated with the primary private IP\naddress.\n* `public_ip` - (Optional) The Elastic IP address. This is required for EC2-Classic.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `association_id` - The ID that represents the association of the Elastic IP\naddress with an instance.\n* `allocation_id` - As above\n* `instance_id` - As above\n* `network_interface_id` - As above\n* `private_ip_address` - As above\n* `public_ip` - As above\n\n## Import\n\nEIP Assocations can be imported using their association ID.\n\n```\n$ terraform import aws_eip_association.test eipassoc-ab12c345\n```\n",
    "basename": "eip_association.html"
  },
  "eks_addon.html": {
    "subcategory": "EKS",
    "layout": "aws",
    "page_title": "AWS: aws_eks_addon",
    "description": "Manages an EKS add-on",
    "preview": "# Resource: aws_eks_addon\n\nManages an EKS add-on.\n\n~> **Note:** …",
    "content": "\n\n# Resource: aws_eks_addon\n\nManages an EKS add-on.\n\n~> **Note:** Amazon EKS add-on can only be used with Amazon EKS Clusters\nrunning version 1.18 with platform version eks.3 or later\nbecause add-ons rely on the Server-side Apply Kubernetes feature,\nwhich is only available in Kubernetes 1.18 and later.\n\n## Example Usage\n\n```terraform\nresource \"aws_eks_addon\" \"example\" {\n  cluster_name = aws_eks_cluster.example.name\n  addon_name   = \"vpc-cni\"\n}\n```\n\n### Example IAM Role for EKS Addon \"vpc-cni\" with AWS managed policy\n\n```terraform\nresource \"aws_eks_cluster\" \"example\" {\n  # ... other configuration ...\n}\n\ndata \"tls_certificate\" \"example\" {\n  url = aws_eks_cluster.example.identity[0].oidc[0].issuer\n}\n\nresource \"aws_iam_openid_connect_provider\" \"example\" {\n  client_id_list  = [\"sts.amazonaws.com\"]\n  thumbprint_list = [data.tls_certificate.example.certificates[0].sha1_fingerprint]\n  url             = aws_eks_cluster.example.identity[0].oidc[0].issuer\n}\n\ndata \"aws_iam_policy_document\" \"example_assume_role_policy\" {\n  statement {\n    actions = [\"sts:AssumeRoleWithWebIdentity\"]\n    effect  = \"Allow\"\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${replace(aws_iam_openid_connect_provider.example.url, \"https://\", \"\")}:sub\"\n      values   = [\"system:serviceaccount:kube-system:aws-node\"]\n    }\n\n    principals {\n      identifiers = [aws_iam_openid_connect_provider.example.arn]\n      type        = \"Federated\"\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"example\" {\n  assume_role_policy = data.aws_iam_policy_document.example_assume_role_policy.json\n  name               = \"example-vpc-cni-role\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\"\n  role       = aws_iam_role.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `addon_name` – (Required) Name of the EKS add-on. The name must match one of\n  the names returned by [list-addon](https://docs.aws.amazon.com/cli/latest/reference/eks/list-addons.html).\n* `cluster_name` – (Required) Name of the EKS Cluster. Must be between 1-100 characters in length. Must begin with an alphanumeric character, and must only contain alphanumeric characters, dashes and underscores (`^[0-9A-Za-z][A-Za-z0-9\\-_]+$`).\n\nThe following arguments are optional:\n\n* `addon_version` – (Optional) The version of the EKS add-on. The version must\n  match one of the versions returned by [describe-addon-versions](https://docs.aws.amazon.com/cli/latest/reference/eks/describe-addon-versions.html).\n* `resolve_conflicts` - (Optional) Define how to resolve parameter value conflicts\n  when migrating an existing add-on to an Amazon EKS add-on or when applying\n  version updates to the add-on. Valid values are `NONE` and `OVERWRITE`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `service_account_role_arn` - (Optional) The Amazon Resource Name (ARN) of an\n  existing IAM role to bind to the add-on's service account. The role must be\n  assigned the IAM permissions required by the add-on. If you don't specify\n  an existing IAM role, then the add-on uses the permissions assigned to the node\n  IAM role. For more information, see [Amazon EKS node IAM role](https://docs.aws.amazon.com/eks/latest/userguide/create-node-role.html)\n  in the Amazon EKS User Guide.\n  \n  ~> **Note:** To specify an existing IAM role, you must have an IAM OpenID Connect (OIDC)\n  provider created for your cluster. For more information, [see Enabling IAM roles\n  for service accounts on your cluster](https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html)\n  in the Amazon EKS User Guide.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the EKS add-on.\n* `id` - EKS Cluster name and EKS Addon name separated by a colon (`:`).\n* `status` - Status of the EKS add-on.\n* `created_at` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) that the EKS add-on was created.\n* `modified_at` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) that the EKS add-on was updated.\n* `tags_all` - (Optional) Key-value map of resource tags, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEKS add-on can be imported using the `cluster_name` and `addon_name` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_eks_addon.my_eks_addon my_cluster_name:my_addon_name\n```\n",
    "basename": "eks_addon.html"
  },
  "eks_cluster.html": {
    "subcategory": "EKS",
    "layout": "aws",
    "page_title": "AWS: aws_eks_cluster",
    "description": "Manages an EKS Cluster",
    "preview": "# Resource: aws_eks_cluster\n\nManages an EKS Cluster.\n\n> …",
    "content": "\n\n# Resource: aws_eks_cluster\n\nManages an EKS Cluster.\n\n> **Hands-on:** For an example of `aws_eks_cluster` in use, follow the [Provision an EKS Cluster](https://learn.hashicorp.com/tutorials/terraform/eks) tutorial on HashiCorp Learn.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_eks_cluster\" \"example\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.example.arn\n\n  vpc_config {\n    subnet_ids = [aws_subnet.example1.id, aws_subnet.example2.id]\n  }\n\n  # Ensure that IAM Role permissions are created before and deleted after EKS Cluster handling.\n  # Otherwise, EKS will not be able to properly delete EKS managed EC2 infrastructure such as Security Groups.\n  depends_on = [\n    aws_iam_role_policy_attachment.example-AmazonEKSClusterPolicy,\n    aws_iam_role_policy_attachment.example-AmazonEKSVPCResourceController,\n  ]\n}\n\noutput \"endpoint\" {\n  value = aws_eks_cluster.example.endpoint\n}\n\noutput \"kubeconfig-certificate-authority-data\" {\n  value = aws_eks_cluster.example.certificate_authority[0].data\n}\n```\n\n### Example IAM Role for EKS Cluster\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name = \"eks-cluster-example\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example-AmazonEKSClusterPolicy\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\"\n  role       = aws_iam_role.example.name\n}\n\n# Optionally, enable Security Groups for Pods\n# Reference: https://docs.aws.amazon.com/eks/latest/userguide/security-groups-for-pods.html\nresource \"aws_iam_role_policy_attachment\" \"example-AmazonEKSVPCResourceController\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSVPCResourceController\"\n  role       = aws_iam_role.example.name\n}\n```\n\n### Enabling Control Plane Logging\n\n[EKS Control Plane Logging](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html) can be enabled via the `enabled_cluster_log_types` argument. To manage the CloudWatch Log Group retention period, the [`aws_cloudwatch_log_group` resource](/docs/providers/aws/r/cloudwatch_log_group.html) can be used.\n\n-> The below configuration uses [`depends_on`](https://www.terraform.io/docs/configuration/meta-arguments/depends_on.html) to prevent ordering issues with EKS automatically creating the log group first and a variable for naming consistency. Other ordering and naming methodologies may be more appropriate for your environment.\n\n```terraform\nvariable \"cluster_name\" {\n  default = \"example\"\n  type    = string\n}\n\nresource \"aws_eks_cluster\" \"example\" {\n  depends_on = [aws_cloudwatch_log_group.example]\n\n  enabled_cluster_log_types = [\"api\", \"audit\"]\n  name                      = var.cluster_name\n\n  # ... other configuration ...\n}\n\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  # The log group name format is /aws/eks/<cluster-name>/cluster\n  # Reference: https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html\n  name              = \"/aws/eks/${var.cluster_name}/cluster\"\n  retention_in_days = 7\n\n  # ... potentially other configuration ...\n}\n```\n\n### Enabling IAM Roles for Service Accounts\n\nOnly available on Kubernetes version 1.13 and 1.14 clusters created or upgraded on or after September 3, 2019. For more information about this feature, see the [EKS User Guide](https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html).\n\n```terraform\nresource \"aws_eks_cluster\" \"example\" {\n  # ... other configuration ...\n}\n\ndata \"tls_certificate\" \"example\" {\n  url = aws_eks_cluster.example.identity[0].oidc[0].issuer\n}\n\nresource \"aws_iam_openid_connect_provider\" \"example\" {\n  client_id_list  = [\"sts.amazonaws.com\"]\n  thumbprint_list = [data.tls_certificate.example.certificates[0].sha1_fingerprint]\n  url             = aws_eks_cluster.example.identity[0].oidc[0].issuer\n}\n\ndata \"aws_iam_policy_document\" \"example_assume_role_policy\" {\n  statement {\n    actions = [\"sts:AssumeRoleWithWebIdentity\"]\n    effect  = \"Allow\"\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"${replace(aws_iam_openid_connect_provider.example.url, \"https://\", \"\")}:sub\"\n      values   = [\"system:serviceaccount:kube-system:aws-node\"]\n    }\n\n    principals {\n      identifiers = [aws_iam_openid_connect_provider.example.arn]\n      type        = \"Federated\"\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"example\" {\n  assume_role_policy = data.aws_iam_policy_document.example_assume_role_policy.json\n  name               = \"example\"\n}\n```\n\nAfter adding inline IAM Policies (e.g., [`aws_iam_role_policy` resource](/docs/providers/aws/r/iam_role_policy.html)) or attaching IAM Policies (e.g., [`aws_iam_policy` resource](/docs/providers/aws/r/iam_policy.html) and [`aws_iam_role_policy_attachment` resource](/docs/providers/aws/r/iam_role_policy_attachment.html)) with the desired permissions to the IAM Role, annotate the Kubernetes service account (e.g., [`kubernetes_service_account` resource](https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/resources/service_account)) and recreate any pods.\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` – (Required) Name of the cluster. Must be between 1-100 characters in length. Must begin with an alphanumeric character, and must only contain alphanumeric characters, dashes and underscores (`^[0-9A-Za-z][A-Za-z0-9\\-_]+$`).\n* `role_arn` - (Required) ARN of the IAM role that provides permissions for the Kubernetes control plane to make calls to AWS API operations on your behalf. Ensure the resource configuration includes explicit dependencies on the IAM Role permissions by adding [`depends_on`](https://www.terraform.io/docs/configuration/meta-arguments/depends_on.html) if using the [`aws_iam_role_policy` resource](/docs/providers/aws/r/iam_role_policy.html) or [`aws_iam_role_policy_attachment` resource](/docs/providers/aws/r/iam_role_policy_attachment.html), otherwise EKS cannot delete EKS managed EC2 infrastructure such as Security Groups on EKS Cluster deletion.\n* `vpc_config` - (Required) Configuration block for the VPC associated with your cluster. Amazon EKS VPC resources have specific requirements to work properly with Kubernetes. For more information, see [Cluster VPC Considerations](https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html) and [Cluster Security Group Considerations](https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html) in the Amazon EKS User Guide. Detailed below. Also contains attributes detailed in the Attributes section.\n\nThe following arguments are optional:\n\n* `enabled_cluster_log_types` - (Optional) List of the desired control plane logging to enable. For more information, see [Amazon EKS Control Plane Logging](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html).\n* `encryption_config` - (Optional) Configuration block with encryption configuration for the cluster. Only available on Kubernetes 1.13 and above clusters created after March 6, 2020. Detailed below.\n* `kubernetes_network_config` - (Optional) Configuration block with kubernetes network configuration for the cluster. Detailed below. If removed, Terraform will only perform drift detection if a configuration value is provided.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `version` – (Optional) Desired Kubernetes master version. If you do not specify a value, the latest available version at resource creation is used and no upgrades will occur except those automatically triggered by EKS. The value must be configured and increased to upgrade the version when desired. Downgrades are not supported by EKS.\n\n### encryption_config\n\nThe following arguments are supported in the `encryption_config` configuration block:\n\n* `provider` - (Required) Configuration block with provider for encryption. Detailed below.\n* `resources` - (Required) List of strings with resources to be encrypted. Valid values: `secrets`.\n\n#### provider\n\nThe following arguments are supported in the `provider` configuration block:\n\n* `key_arn` - (Required) ARN of the Key Management Service (KMS) customer master key (CMK). The CMK must be symmetric, created in the same region as the cluster, and if the CMK was created in a different account, the user must have access to the CMK. For more information, see [Allowing Users in Other Accounts to Use a CMK in the AWS Key Management Service Developer Guide](https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying-external-accounts.html).\n\n### vpc_config Arguments\n\n* `endpoint_private_access` - (Optional) Whether the Amazon EKS private API server endpoint is enabled. Default is `false`.\n* `endpoint_public_access` - (Optional) Whether the Amazon EKS public API server endpoint is enabled. Default is `true`.\n* `public_access_cidrs` - (Optional) List of CIDR blocks. Indicates which CIDR blocks can access the Amazon EKS public API server endpoint when enabled. EKS defaults this to a list with `0.0.0.0/0`. Terraform will only perform drift detection of its value when present in a configuration.\n* `security_group_ids` – (Optional) List of security group IDs for the cross-account elastic network interfaces that Amazon EKS creates to use to allow communication between your worker nodes and the Kubernetes control plane.\n* `subnet_ids` – (Required) List of subnet IDs. Must be in at least two different availability zones. Amazon EKS creates cross-account elastic network interfaces in these subnets to allow communication between your worker nodes and the Kubernetes control plane.\n\n### kubernetes_network_config\n\nThe following arguments are supported in the `kubernetes_network_config` configuration block:\n\n* `service_ipv4_cidr` - (Optional) The CIDR block to assign Kubernetes service IP addresses from. If you don't specify a block, Kubernetes assigns addresses from either the 10.100.0.0/16 or 172.20.0.0/16 CIDR blocks. We recommend that you specify a block that does not overlap with resources in other networks that are peered or connected to your VPC. You can only specify a custom CIDR block when you create a cluster, changing this value will force a new cluster to be created. The block must meet the following requirements:\n\n    * Within one of the following private IP address blocks: 10.0.0.0/8, 172.16.0.0/12, or 192.168.0.0/16.\n\n    * Doesn't overlap with any CIDR block assigned to the VPC that you selected for VPC.\n\n    * Between /24 and /12.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the cluster.\n* `certificate_authority` - Attribute block containing `certificate-authority-data` for your cluster. Detailed below.\n* `created_at` - Unix epoch timestamp in seconds for when the cluster was created.\n* `endpoint` - Endpoint for your Kubernetes API server.\n* `id` - Name of the cluster.\n* `identity` - Attribute block containing identity provider information for your cluster. Only available on Kubernetes version 1.13 and 1.14 clusters created or upgraded on or after September 3, 2019. Detailed below.\n* `platform_version` - Platform version for the cluster.\n* `status` - Status of the EKS cluster. One of `CREATING`, `ACTIVE`, `DELETING`, `FAILED`.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_config` - Configuration block _argument_ that also includes attributes for the VPC associated with your cluster. Detailed below.\n\n### certificate_authority\n\n* `data` - Base64 encoded certificate data required to communicate with your cluster. Add this to the `certificate-authority-data` section of the `kubeconfig` file for your cluster.\n\n### identity\n\n* `oidc` - Nested block containing [OpenID Connect](https://openid.net/connect/) identity provider information for the cluster. Detailed below.\n\n### oidc\n\n* `issuer` - Issuer URL for the OpenID Connect identity provider.\n\n### vpc_config Attributes\n\n* `cluster_security_group_id` - Cluster security group that was created by Amazon EKS for the cluster. Managed node groups use this security group for control-plane-to-data-plane communication.\n* `vpc_id` - ID of the VPC associated with your cluster.\n\n## Timeouts\n\n`aws_eks_cluster` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `30 minutes`) How long to wait for the EKS Cluster to be created.\n* `update` - (Default `60 minutes`) How long to wait for the EKS Cluster to be updated.\nNote that the `update` timeout is used separately for both `version` and `vpc_config` update timeouts.\n* `delete` - (Default `15 minutes`) How long to wait for the EKS Cluster to be deleted.\n\n## Import\n\nEKS Clusters can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_eks_cluster.my_cluster my_cluster\n```\n",
    "basename": "eks_cluster.html"
  },
  "eks_fargate_profile.html": {
    "subcategory": "EKS",
    "layout": "aws",
    "page_title": "AWS: aws_eks_fargate_profile",
    "description": "Manages an EKS Fargate Profile",
    "preview": "# Resource: aws_eks_fargate_profile\n\nManages an EKS Fargate Profile. …",
    "content": "\n\n# Resource: aws_eks_fargate_profile\n\nManages an EKS Fargate Profile.\n\n## Example Usage\n\n```terraform\nresource \"aws_eks_fargate_profile\" \"example\" {\n  cluster_name           = aws_eks_cluster.example.name\n  fargate_profile_name   = \"example\"\n  pod_execution_role_arn = aws_iam_role.example.arn\n  subnet_ids             = aws_subnet.example[*].id\n\n  selector {\n    namespace = \"example\"\n  }\n}\n```\n\n### Example IAM Role for EKS Fargate Profile\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name = \"eks-fargate-profile-example\"\n\n  assume_role_policy = jsonencode({\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"eks-fargate-pods.amazonaws.com\"\n      }\n    }]\n    Version = \"2012-10-17\"\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example-AmazonEKSFargatePodExecutionRolePolicy\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSFargatePodExecutionRolePolicy\"\n  role       = aws_iam_role.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `cluster_name` – (Required) Name of the EKS Cluster. Must be between 1-100 characters in length. Must begin with an alphanumeric character, and must only contain alphanumeric characters, dashes and underscores (`^[0-9A-Za-z][A-Za-z0-9\\-_]+$`).\n* `fargate_profile_name` – (Required) Name of the EKS Fargate Profile.\n* `pod_execution_role_arn` – (Required) Amazon Resource Name (ARN) of the IAM Role that provides permissions for the EKS Fargate Profile.\n* `selector` - (Required) Configuration block(s) for selecting Kubernetes Pods to execute with this EKS Fargate Profile. Detailed below.\n* `subnet_ids` – (Required) Identifiers of private EC2 Subnets to associate with the EKS Fargate Profile. These subnets must have the following resource tag: `kubernetes.io/cluster/CLUSTER_NAME` (where `CLUSTER_NAME` is replaced with the name of the EKS Cluster).\n\nThe following arguments are optional:\n\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### selector Configuration Block\n\nThe following arguments are required:\n\n* `namespace` - (Required) Kubernetes namespace for selection.\n\nThe following arguments are optional:\n\n* `labels` - (Optional) Key-value map of Kubernetes labels for selection.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the EKS Fargate Profile.\n* `id` - EKS Cluster name and EKS Fargate Profile name separated by a colon (`:`).\n* `status` - Status of the EKS Fargate Profile.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_eks_fargate_profile` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `10 minutes`) How long to wait for the EKS Fargate Profile to be created.\n* `delete` - (Default `10 minutes`) How long to wait for the EKS Fargate Profile to be deleted.\n\n## Import\n\nEKS Fargate Profiles can be imported using the `cluster_name` and `fargate_profile_name` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_eks_fargate_profile.my_fargate_profile my_cluster:my_fargate_profile\n```\n",
    "basename": "eks_fargate_profile.html"
  },
  "eks_identity_provider_config.html": {
    "subcategory": "EKS",
    "layout": "aws",
    "page_title": "AWS: aws_eks_identity_provider_config",
    "description": "Manages an EKS Identity Provider Configuration.",
    "preview": "# Resource: aws_eks_identity_provider_config\n\nManages an EKS …",
    "content": "\n\n# Resource: aws_eks_identity_provider_config\n\nManages an EKS Identity Provider Configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_eks_identity_provider_config\" \"example\" {\n  cluster_name = aws_eks_cluster.example.name\n\n  oidc {\n    client_id                     = \"your client_id\"\n    identity_provider_config_name = \"example\"\n    issuer_url                    = \"your issuer_url\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_name` – (Required) Name of the EKS Cluster.\n* `oidc` - (Required) Nested attribute containing [OpenID Connect](https://openid.net/connect/) identity provider information for the cluster. Detailed below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### oidc Configuration Block\n\n* `client_id` – (Required) Client ID for the OpenID Connect identity provider.\n* `groups_claim` - (Optional) The JWT claim that the provider will use to return groups.\n* `groups_prefix` - (Optional) A prefix that is prepended to group claims e.g., `oidc:`.\n* `identity_provider_config_name` – (Required) The name of the identity provider config.\n* `issuer_url` - (Required) Issuer URL for the OpenID Connect identity provider.\n* `required_claims` - (Optional) The key value pairs that describe required claims in the identity token.\n* `username_claim` - (Optional) The JWT claim that the provider will use as the username.\n* `username_prefix` - (Optional) A prefix that is prepended to username claims.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the EKS Identity Provider Configuration.\n* `id` - EKS Cluster name and EKS Identity Provider Configuration name separated by a colon (`:`).\n* `status` - Status of the EKS Identity Provider Configuration.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_eks_identity_provider_config` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `40 minutes`) How long to wait for the EKS Identity Provider Configuration to be associated.\n* `delete` - (Default `40 minutes`) How long to wait for the EKS Identity Provider Configuration to be disassociated.\n\n## Import\n\nEKS Identity Provider Configurations can be imported using the `cluster_name` and `identity_provider_config_name` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_eks_identity_provider_config.my_identity_provider_config my_cluster:my_identity_provider_config\n```\n",
    "basename": "eks_identity_provider_config.html"
  },
  "eks_node_group.html": {
    "subcategory": "EKS",
    "layout": "aws",
    "page_title": "AWS: aws_eks_node_group",
    "description": "Manages an EKS Node Group",
    "preview": "# Resource: aws_eks_node_group\n\nManages an EKS Node Group, which can …",
    "content": "\n\n# Resource: aws_eks_node_group\n\nManages an EKS Node Group, which can provision and optionally update an Auto Scaling Group of Kubernetes worker nodes compatible with EKS. Additional documentation about this functionality can be found in the [EKS User Guide](https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_eks_node_group\" \"example\" {\n  cluster_name    = aws_eks_cluster.example.name\n  node_group_name = \"example\"\n  node_role_arn   = aws_iam_role.example.arn\n  subnet_ids      = aws_subnet.example[*].id\n\n  scaling_config {\n    desired_size = 1\n    max_size     = 1\n    min_size     = 1\n  }\n\n  update_config {\n    max_unavailable = 2\n  }\n\n  # Ensure that IAM Role permissions are created before and deleted after EKS Node Group handling.\n  # Otherwise, EKS will not be able to properly delete EC2 Instances and Elastic Network Interfaces.\n  depends_on = [\n    aws_iam_role_policy_attachment.example-AmazonEKSWorkerNodePolicy,\n    aws_iam_role_policy_attachment.example-AmazonEKS_CNI_Policy,\n    aws_iam_role_policy_attachment.example-AmazonEC2ContainerRegistryReadOnly,\n  ]\n}\n```\n\n### Ignoring Changes to Desired Size\n\nYou can utilize the generic Terraform resource [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` to create an EKS Node Group with an initial size of running instances, then ignore any changes to that count caused externally (e.g., Application Autoscaling).\n\n```terraform\nresource \"aws_eks_node_group\" \"example\" {\n  # ... other configurations ...\n\n  scaling_config {\n    # Example: Create EKS Node Group with 2 instances to start\n    desired_size = 2\n\n    # ... other configurations ...\n  }\n\n  # Optional: Allow external changes without Terraform plan difference\n  lifecycle {\n    ignore_changes = [scaling_config[0].desired_size]\n  }\n}\n```\n\n### Example IAM Role for EKS Node Group\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name = \"eks-node-group-example\"\n\n  assume_role_policy = jsonencode({\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"ec2.amazonaws.com\"\n      }\n    }]\n    Version = \"2012-10-17\"\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example-AmazonEKSWorkerNodePolicy\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\"\n  role       = aws_iam_role.example.name\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example-AmazonEKS_CNI_Policy\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\"\n  role       = aws_iam_role.example.name\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example-AmazonEC2ContainerRegistryReadOnly\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\"\n  role       = aws_iam_role.example.name\n}\n```\n\n### Example Subnets for EKS Node Group\n\n```terraform\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\nresource \"aws_subnet\" \"example\" {\n  count = 2\n\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  cidr_block        = cidrsubnet(aws_vpc.example.cidr_block, 8, count.index)\n  vpc_id            = aws_vpc.example.id\n\n  tags = {\n    \"kubernetes.io/cluster/${aws_eks_cluster.example.name}\" = \"shared\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `cluster_name` – (Required) Name of the EKS Cluster. Must be between 1-100 characters in length. Must begin with an alphanumeric character, and must only contain alphanumeric characters, dashes and underscores (`^[0-9A-Za-z][A-Za-z0-9\\-_]+$`).\n* `node_role_arn` – (Required) Amazon Resource Name (ARN) of the IAM Role that provides permissions for the EKS Node Group.\n* `scaling_config` - (Required) Configuration block with scaling settings. Detailed below.\n* `subnet_ids` – (Required) Identifiers of EC2 Subnets to associate with the EKS Node Group. These subnets must have the following resource tag: `kubernetes.io/cluster/CLUSTER_NAME` (where `CLUSTER_NAME` is replaced with the name of the EKS Cluster).\n\nThe following arguments are optional:\n\n* `ami_type` - (Optional) Type of Amazon Machine Image (AMI) associated with the EKS Node Group. See the [AWS documentation](https://docs.aws.amazon.com/eks/latest/APIReference/API_Nodegroup.html#AmazonEKS-Type-Nodegroup-amiType) for valid values. Terraform will only perform drift detection if a configuration value is provided.\n* `capacity_type` - (Optional) Type of capacity associated with the EKS Node Group. Valid values: `ON_DEMAND`, `SPOT`. Terraform will only perform drift detection if a configuration value is provided.\n* `disk_size` - (Optional) Disk size in GiB for worker nodes. Defaults to `20`. Terraform will only perform drift detection if a configuration value is provided.\n* `force_update_version` - (Optional) Force version update if existing pods are unable to be drained due to a pod disruption budget issue.\n* `instance_types` - (Optional) List of instance types associated with the EKS Node Group. Defaults to `[\"t3.medium\"]`. Terraform will only perform drift detection if a configuration value is provided.\n* `labels` - (Optional) Key-value map of Kubernetes labels. Only labels that are applied with the EKS API are managed by this argument. Other Kubernetes labels applied to the EKS Node Group will not be managed.\n* `launch_template` - (Optional) Configuration block with Launch Template settings. Detailed below.\n* `node_group_name` – (Optional) Name of the EKS Node Group. If omitted, Terraform will assign a random, unique name. Conflicts with `node_group_name_prefix`.\n* `node_group_name_prefix` – (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `node_group_name`.\n* `release_version` – (Optional) AMI version of the EKS Node Group. Defaults to latest version for Kubernetes version.\n* `remote_access` - (Optional) Configuration block with remote access settings. Detailed below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `taint` - (Optional) The Kubernetes taints to be applied to the nodes in the node group. Maximum of 50 taints per node group. Detailed below.\n* `version` – (Optional) Kubernetes version. Defaults to EKS Cluster Kubernetes version. Terraform will only perform drift detection if a configuration value is provided.\n\n### launch_template Configuration Block\n\n~> **NOTE:** Either `id` or `name` must be specified.\n\n* `id` - (Optional) Identifier of the EC2 Launch Template. Conflicts with `name`.\n* `name` - (Optional) Name of the EC2 Launch Template. Conflicts with `id`.\n* `version` - (Required) EC2 Launch Template version number. While the API accepts values like `$Default` and `$Latest`, the API will convert the value to the associated version number (e.g., `1`) on read and Terraform will show a difference on next plan. Using the `default_version` or `latest_version` attribute of the `aws_launch_template` resource or data source is recommended for this argument.\n\n### remote_access Configuration Block\n\n* `ec2_ssh_key` - (Optional) EC2 Key Pair name that provides access for SSH communication with the worker nodes in the EKS Node Group. If you specify this configuration, but do not specify `source_security_group_ids` when you create an EKS Node Group, port 22 on the worker nodes is opened to the Internet (0.0.0.0/0).\n* `source_security_group_ids` - (Optional) Set of EC2 Security Group IDs to allow SSH access (port 22) from on the worker nodes. If you specify `ec2_ssh_key`, but do not specify this configuration when you create an EKS Node Group, port 22 on the worker nodes is opened to the Internet (0.0.0.0/0).\n\n### scaling_config Configuration Block\n\n* `desired_size` - (Required) Desired number of worker nodes.\n* `max_size` - (Required) Maximum number of worker nodes.\n* `min_size` - (Required) Minimum number of worker nodes.\n\n### taint Configuration Block\n\n* `key` - (Required) The key of the taint. Maximum length of 63.\n* `value` - (Optional) The value of the taint. Maximum length of 63.\n* `effect` - (Required) The effect of the taint. Valid values: `NO_SCHEDULE`, `NO_EXECUTE`, `PREFER_NO_SCHEDULE`.\n\n### update_config Configuration Block\n\nThe following arguments are mutually exclusive.\n\n* `max_unavailable` - (Optional) Desired max number of unavailable worker nodes during node group update.\n* `max_unavailable_percentage` - (Optional) Desired max percentage of unavailable worker nodes during node group update.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the EKS Node Group.\n* `id` - EKS Cluster name and EKS Node Group name separated by a colon (`:`).\n* `resources` - List of objects containing information about underlying resources.\n    * `autoscaling_groups` - List of objects containing information about AutoScaling Groups.\n        * `name` - Name of the AutoScaling Group.\n    * `remote_access_security_group_id` - Identifier of the remote access EC2 Security Group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `status` - Status of the EKS Node Group.\n\n## Timeouts\n\n`aws_eks_node_group` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `60 minutes`) How long to wait for the EKS Node Group to be created.\n* `update` - (Default `60 minutes`) How long to wait for the EKS Node Group to be updated. Note that the `update` timeout is used separately for both configuration and version update operations.\n* `delete` - (Default `60 minutes`) How long to wait for the EKS Node Group to be deleted.\n\n## Import\n\nEKS Node Groups can be imported using the `cluster_name` and `node_group_name` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_eks_node_group.my_node_group my_cluster:my_node_group\n```\n",
    "basename": "eks_node_group.html"
  },
  "elastic_beanstalk_application.html": {
    "subcategory": "Elastic Beanstalk",
    "layout": "aws",
    "page_title": "AWS: aws_elastic_beanstalk_application",
    "description": "Provides an Elastic Beanstalk Application Resource",
    "preview": "# Resource: aws_elastic_beanstalk_application\n\nProvides an Elastic …",
    "content": "\n\n# Resource: aws_elastic_beanstalk_application\n\nProvides an Elastic Beanstalk Application Resource. Elastic Beanstalk allows\nyou to deploy and manage applications in the AWS cloud without worrying about\nthe infrastructure that runs those applications.\n\nThis resource creates an application that has one configuration template named\n`default`, and no application versions\n\n## Example Usage\n\n```terraform\nresource \"aws_elastic_beanstalk_application\" \"tftest\" {\n  name        = \"tf-test-name\"\n  description = \"tf-test-desc\"\n\n  appversion_lifecycle {\n    service_role          = aws_iam_role.beanstalk_service.arn\n    max_count             = 128\n    delete_source_from_s3 = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the application, must be unique within your account\n* `description` - (Optional) Short description of the application\n* `tags` - (Optional) Key-value map of tags for the Elastic Beanstalk Application. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nApplication version lifecycle (`appversion_lifecycle`) supports the following settings.  Only one of either `max_count` or `max_age_in_days` can be provided:\n\n* `service_role` - (Required) The ARN of an IAM service role under which the application version is deleted.  Elastic Beanstalk must have permission to assume this role.\n* `max_count` - (Optional) The maximum number of application versions to retain ('max_age_in_days' and 'max_count' cannot be enabled simultaneously.).\n* `max_age_in_days` - (Optional) The number of days to retain an application version ('max_age_in_days' and 'max_count' cannot be enabled simultaneously.).\n* `delete_source_from_s3` - (Optional) Set to `true` to delete a version's source bundle from S3 when the application version is deleted.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS for this Elastic Beanstalk Application.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nElastic Beanstalk Applications can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_elastic_beanstalk_application.tf_test tf-test-name\n```\n",
    "basename": "elastic_beanstalk_application.html"
  },
  "elastic_beanstalk_application_version.html": {
    "subcategory": "Elastic Beanstalk",
    "layout": "aws",
    "page_title": "AWS: aws_elastic_beanstalk_application_version",
    "description": "Provides an Elastic Beanstalk Application Version Resource",
    "preview": "# Resource: aws_elastic_beanstalk_application_version\n\nProvides an …",
    "content": "\n\n# Resource: aws_elastic_beanstalk_application_version\n\nProvides an Elastic Beanstalk Application Version Resource. Elastic Beanstalk allows\nyou to deploy and manage applications in the AWS cloud without worrying about\nthe infrastructure that runs those applications.\n\nThis resource creates a Beanstalk Application Version that can be deployed to a Beanstalk\nEnvironment.\n\n~> **NOTE on Application Version Resource:**  When using the Application Version resource with multiple\n[Elastic Beanstalk Environments](elastic_beanstalk_environment.html) it is possible that an error may be returned\nwhen attempting to delete an Application Version while it is still in use by a different environment.\nTo work around this you can either create each environment in a separate AWS account or create your `aws_elastic_beanstalk_application_version` resources with a unique names in your Elastic Beanstalk Application. For example &lt;revision&gt;-&lt;environment&gt;.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"default\" {\n  bucket = \"tftest.applicationversion.bucket\"\n}\n\nresource \"aws_s3_bucket_object\" \"default\" {\n  bucket = aws_s3_bucket.default.id\n  key    = \"beanstalk/go-v1.zip\"\n  source = \"go-v1.zip\"\n}\n\nresource \"aws_elastic_beanstalk_application\" \"default\" {\n  name        = \"tf-test-name\"\n  description = \"tf-test-desc\"\n}\n\nresource \"aws_elastic_beanstalk_application_version\" \"default\" {\n  name        = \"tf-test-version-label\"\n  application = \"tf-test-name\"\n  description = \"application version created by terraform\"\n  bucket      = aws_s3_bucket.default.id\n  key         = aws_s3_bucket_object.default.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `application` - (Required) Name of the Beanstalk Application the version is associated with.\n* `bucket` - (Required) S3 bucket that contains the Application Version source bundle.\n* `key` - (Required) S3 object that is the Application Version source bundle.\n* `name` - (Required) Unique name for the this Application Version.\n\nThe following arguments are optional:\n\n* `description` - (Optional) Short description of the Application Version.\n* `force_delete` - (Optional) On delete, force an Application Version to be deleted when it may be in use by multiple Elastic Beanstalk Environments.\n* `tags` - (Optional) Key-value map of tags for the Elastic Beanstalk Application Version. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN assigned by AWS for this Elastic Beanstalk Application.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "elastic_beanstalk_application_version.html"
  },
  "elastic_beanstalk_configuration_template.html": {
    "subcategory": "Elastic Beanstalk",
    "layout": "aws",
    "page_title": "AWS: aws_elastic_beanstalk_configuration_template",
    "description": "Provides an Elastic Beanstalk Configuration Template",
    "preview": "# Resource: aws_elastic_beanstalk_configuration_template\n\nProvides …",
    "content": "\n\n# Resource: aws_elastic_beanstalk_configuration_template\n\nProvides an Elastic Beanstalk Configuration Template, which are associated with\na specific application and are used to deploy different versions of the\napplication with the same configuration settings.\n\n## Example Usage\n\n```terraform\nresource \"aws_elastic_beanstalk_application\" \"tftest\" {\n  name        = \"tf-test-name\"\n  description = \"tf-test-desc\"\n}\n\nresource \"aws_elastic_beanstalk_configuration_template\" \"tf_template\" {\n  name                = \"tf-test-template-config\"\n  application         = aws_elastic_beanstalk_application.tftest.name\n  solution_stack_name = \"64bit Amazon Linux 2015.09 v2.0.8 running Go 1.4\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A unique name for this Template.\n* `application` – (Required) name of the application to associate with this configuration template\n* `description` - (Optional) Short description of the Template\n* `environment_id` – (Optional) The ID of the environment used with this configuration template\n* `setting` – (Optional) Option settings to configure the new Environment. These\n  override specific values that are set as defaults. The format is detailed\n  below in [Option Settings](#option-settings)\n* `solution_stack_name` – (Optional) A solution stack to base your Template\noff of. Example stacks can be found in the [Amazon API documentation][1]\n\n\n## Option Settings\n\nThe `setting` field supports the following format:\n\n* `namespace` - unique namespace identifying the option's associated AWS resource\n* `name` - name of the configuration option\n* `value` - value for the configuration option\n* `resource` - (Optional) resource name for [scheduled action](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/command-options-general.html#command-options-general-autoscalingscheduledaction)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `name`\n* `application`\n* `description`\n* `environment_id`\n* `option_settings`\n* `solution_stack_name`\n\n[1]: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html\n",
    "basename": "elastic_beanstalk_configuration_template.html"
  },
  "elastic_beanstalk_environment.html": {
    "subcategory": "Elastic Beanstalk",
    "layout": "aws",
    "page_title": "AWS: aws_elastic_beanstalk_environment",
    "description": "Provides an Elastic Beanstalk Environment Resource",
    "preview": "# Resource: aws_elastic_beanstalk_environment\n\nProvides an Elastic …",
    "content": "\n\n# Resource: aws_elastic_beanstalk_environment\n\nProvides an Elastic Beanstalk Environment Resource. Elastic Beanstalk allows\nyou to deploy and manage applications in the AWS cloud without worrying about\nthe infrastructure that runs those applications.\n\nEnvironments are often things such as `development`, `integration`, or\n`production`.\n\n## Example Usage\n\n```terraform\nresource \"aws_elastic_beanstalk_application\" \"tftest\" {\n  name        = \"tf-test-name\"\n  description = \"tf-test-desc\"\n}\n\nresource \"aws_elastic_beanstalk_environment\" \"tfenvtest\" {\n  name                = \"tf-test-name\"\n  application         = aws_elastic_beanstalk_application.tftest.name\n  solution_stack_name = \"64bit Amazon Linux 2015.03 v2.0.3 running Go 1.4\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A unique name for this Environment. This name is used\n  in the application URL\n* `application` – (Required) Name of the application that contains the version\n  to be deployed\n* `cname_prefix` - (Optional) Prefix to use for the fully qualified DNS name of\n  the Environment.\n* `description` - (Optional) Short description of the Environment\n* `tier` - (Optional) Elastic Beanstalk Environment tier. Valid values are `Worker`\n  or `WebServer`. If tier is left blank `WebServer` will be used.\n* `setting` – (Optional) Option settings to configure the new Environment. These\n  override specific values that are set as defaults. The format is detailed\n  below in [Option Settings](#option-settings)\n* `solution_stack_name` – (Optional) A solution stack to base your environment\noff of. Example stacks can be found in the [Amazon API documentation][1]\n* `template_name` – (Optional) The name of the Elastic Beanstalk Configuration\n  template to use in deployment\n* `platform_arn` – (Optional) The [ARN][2] of the Elastic Beanstalk [Platform][3]\n  to use in deployment\n* `wait_for_ready_timeout` - (Default: `20m`) The maximum\n  [duration](https://golang.org/pkg/time/#ParseDuration) that Terraform should\n  wait for an Elastic Beanstalk Environment to be in a ready state before timing\n  out.\n* `poll_interval` – The time between polling the AWS API to\ncheck if changes have been applied. Use this to adjust the rate of API calls\nfor any `create` or `update` action. Minimum `10s`, maximum `180s`. Omit this to\nuse the default behavior, which is an exponential backoff\n* `version_label` - (Optional) The name of the Elastic Beanstalk Application Version\nto use in deployment.\n* `tags` - (Optional) A set of tags to apply to the Environment. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\n## Option Settings\n\nSome options can be stack-specific, check [AWS Docs](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/command-options-general.html)\nfor supported options and examples.\n\nThe `setting` and `all_settings` mappings support the following format:\n\n* `namespace` - unique namespace identifying the option's associated AWS resource\n* `name` - name of the configuration option\n* `value` - value for the configuration option\n* `resource` - (Optional) resource name for [scheduled action](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/command-options-general.html#command-options-general-autoscalingscheduledaction)\n\n### Example With Options\n\n```terraform\nresource \"aws_elastic_beanstalk_application\" \"tftest\" {\n  name        = \"tf-test-name\"\n  description = \"tf-test-desc\"\n}\n\nresource \"aws_elastic_beanstalk_environment\" \"tfenvtest\" {\n  name                = \"tf-test-name\"\n  application         = aws_elastic_beanstalk_application.tftest.name\n  solution_stack_name = \"64bit Amazon Linux 2015.03 v2.0.3 running Go 1.4\"\n\n  setting {\n    namespace = \"aws:ec2:vpc\"\n    name      = \"VPCId\"\n    value     = \"vpc-xxxxxxxx\"\n  }\n\n  setting {\n    namespace = \"aws:ec2:vpc\"\n    name      = \"Subnets\"\n    value     = \"subnet-xxxxxxxx\"\n  }\n}\n```\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ID of the Elastic Beanstalk Environment.\n* `name` - Name of the Elastic Beanstalk Environment.\n* `description` - Description of the Elastic Beanstalk Environment.\n* `tier` - The environment tier specified.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `application` – The Elastic Beanstalk Application specified for this environment.\n* `setting` – Settings specifically set for this Environment.\n* `all_settings` – List of all option settings configured in this Environment. These\n  are a combination of default settings and their overrides from `setting` in\n  the configuration.\n* `cname` - Fully qualified DNS name for this Environment.\n* `autoscaling_groups` - The autoscaling groups used by this Environment.\n* `instances` - Instances used by this Environment.\n* `launch_configurations` - Launch configurations in use by this Environment.\n* `load_balancers` - Elastic load balancers in use by this Environment.\n* `queues` - SQS queues in use by this Environment.\n* `triggers` - Autoscaling triggers in use by this Environment.\n* `endpoint_url` - The URL to the Load Balancer for this Environment\n\n\n\n[1]: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html\n[2]: https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\n[3]: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-beanstalk-environment.html#cfn-beanstalk-environment-platformarn\n\n## Import\n\nElastic Beanstalk Environments can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_elastic_beanstalk_environment.prodenv e-rpqsewtp2j\n```\n",
    "basename": "elastic_beanstalk_environment.html"
  },
  "elasticache_cluster.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_cluster",
    "description": "Provides an ElastiCache Cluster resource.",
    "preview": "# Resource: aws_elasticache_cluster\n\nProvides an ElastiCache Cluster …",
    "content": "\n\n# Resource: aws_elasticache_cluster\n\nProvides an ElastiCache Cluster resource, which manages either a\n[Memcached cluster](https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/WhatIs.html), a\n[single-node Redis instance](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.html), or a\n[read replica in a Redis (Cluster Mode Enabled) replication group].\n\nFor working with Redis (Cluster Mode Enabled) replication groups, see the\n[`aws_elasticache_replication_group` resource](/docs/providers/aws/r/elasticache_replication_group.html).\n\n~> **Note:** When you change an attribute, such as `num_cache_nodes`, by default\nit is applied in the next maintenance window. Because of this, Terraform may report\na difference in its planning phase because the actual modification has not yet taken\nplace. You can use the `apply_immediately` flag to instruct the service to apply the\nchange immediately. Using `apply_immediately` can result in a brief downtime as the server reboots.\nSee the AWS Documentation on Modifying an ElastiCache Cache Cluster for\n[ElastiCache for Memcached](https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Clusters.Modify.html) or\n[ElastiCache for Redis](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Clusters.Modify.html)\nfor more information.\n\n~> **Note:** Any attribute changes that re-create the resource will be applied immediately, regardless of the value of `apply_immediately`.\n\n## Example Usage\n\n### Memcached Cluster\n\n```terraform\nresource \"aws_elasticache_cluster\" \"example\" {\n  cluster_id           = \"cluster-example\"\n  engine               = \"memcached\"\n  node_type            = \"cache.m4.large\"\n  num_cache_nodes      = 2\n  parameter_group_name = \"default.memcached1.4\"\n  port                 = 11211\n}\n```\n\n### Redis Instance\n\n```terraform\nresource \"aws_elasticache_cluster\" \"example\" {\n  cluster_id           = \"cluster-example\"\n  engine               = \"redis\"\n  node_type            = \"cache.m4.large\"\n  num_cache_nodes      = 1\n  parameter_group_name = \"default.redis3.2\"\n  engine_version       = \"3.2.10\"\n  port                 = 6379\n}\n```\n\n### Redis Cluster Mode Disabled Read Replica Instance\n\nThese inherit their settings from the replication group.\n\n```terraform\nresource \"aws_elasticache_cluster\" \"replica\" {\n  cluster_id           = \"cluster-example\"\n  replication_group_id = aws_elasticache_replication_group.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `cluster_id` – (Required) Group identifier. ElastiCache converts this name to lowercase. Changing this value will re-create the resource.\n* `engine` – (Required unless `replication_group_id` is provided) Name of the cache engine to be used for this cache cluster. Valid values are `memcached` or `redis`.\n* `node_type` – (Required unless `replication_group_id` is provided) The instance class used. See AWS documentation for information on [supported node types for Redis](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheNodes.SupportedTypes.html) and [guidance on selecting node types for Redis](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/nodes-select-size.html). See AWS documentation for information on [supported node types for Memcached](https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/CacheNodes.SupportedTypes.html) and [guidance on selecting node types for Memcached](https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/nodes-select-size.html). For Memcached, changing this value will re-create the resource.\n* `num_cache_nodes` – (Required unless `replication_group_id` is provided) The initial number of cache nodes that the cache cluster will have. For Redis, this value must be 1. For Memcached, this value must be between 1 and 40. If this number is reduced on subsequent runs, the highest numbered nodes will be removed.\n* `parameter_group_name` – (Required unless `replication_group_id` is provided) The name of the parameter group to associate with this cache cluster.\n\nThe following arguments are optional:\n\n* `apply_immediately` - (Optional) Whether any database modifications are applied immediately, or during the next maintenance window. Default is `false`. See [Amazon ElastiCache Documentation for more information.](https://docs.aws.amazon.com/AmazonElastiCache/latest/APIReference/API_ModifyCacheCluster.html).\n* `availability_zone` - (Optional) Availability Zone for the cache cluster. If you want to create cache nodes in multi-az, use `preferred_availability_zones` instead. Default: System chosen Availability Zone. Changing this value will re-create the resource.\n* `az_mode` - (Optional, Memcached only) Whether the nodes in this Memcached node group are created in a single Availability Zone or created across multiple Availability Zones in the cluster's region. Valid values for this parameter are `single-az` or `cross-az`, default is `single-az`. If you want to choose `cross-az`, `num_cache_nodes` must be greater than `1`.\n* `engine_version` – (Optional) Version number of the cache engine to be used.\nSee [Describe Cache Engine Versions](https://docs.aws.amazon.com/cli/latest/reference/elasticache/describe-cache-engine-versions.html)\nin the AWS Documentation for supported versions. When `engine` is `redis` and the version is 6 or higher, only the major version can be set, e.g., `6.x`, otherwise, specify the full version desired, e.g., `5.0.6`. The actual engine version used is returned in the attribute `engine_version_actual`, [defined below](#engine_version_actual).\n* `final_snapshot_identifier` - (Optional, Redis only) Name of your final cluster snapshot. If omitted, no final snapshot will be made.\n* `maintenance_window` – (Optional) Specifies the weekly time range for when maintenance\non the cache cluster is performed. The format is `ddd:hh24:mi-ddd:hh24:mi` (24H Clock UTC).\nThe minimum maintenance window is a 60 minute period. Example: `sun:05:00-sun:09:00`.\n* `notification_topic_arn` – (Optional) ARN of an SNS topic to send ElastiCache notifications to. Example: `arn:aws:sns:us-east-1:012345678999:my_sns_topic`.\n* `port` – (Optional) The port number on which each of the cache nodes will accept connections. For Memcached the default is 11211, and for Redis the default port is 6379. Cannot be provided with `replication_group_id`. Changing this value will re-create the resource.\n* `preferred_availability_zones` - (Optional, Memcached only) List of the Availability Zones in which cache nodes are created. If you are creating your cluster in an Amazon VPC you can only locate nodes in Availability Zones that are associated with the subnets in the selected subnet group. The number of Availability Zones listed must equal the value of `num_cache_nodes`. If you want all the nodes in the same Availability Zone, use `availability_zone` instead, or repeat the Availability Zone multiple times in the list. Default: System chosen Availability Zones. Detecting drift of existing node availability zone is not currently supported. Updating this argument by itself to migrate existing node availability zones is not currently supported and will show a perpetual difference.\n* `replication_group_id` - (Optional) ID of the replication group to which this cluster should belong. If this parameter is specified, the cluster is added to the specified replication group as a read replica; otherwise, the cluster is a standalone primary that is not part of any replication group.\n* `security_group_ids` – (Optional, VPC only) One or more VPC security groups associated with the cache cluster\n* `security_group_names` – (Optional, EC2 Classic only) List of security group names to associate with this cache cluster. Changing this value will re-create the resource.\n* `snapshot_arns` – (Optional, Redis only) Single-element string list containing an Amazon Resource Name (ARN) of a Redis RDB snapshot file stored in Amazon S3. The object name cannot contain any commas. Changing `snapshot_arns` forces a new resource.\n* `snapshot_name` - (Optional, Redis only) Name of a snapshot from which to restore data into the new node group. Changing `snapshot_name` forces a new resource.\n* `snapshot_retention_limit` - (Optional, Redis only) Number of days for which ElastiCache will retain automatic cache cluster snapshots before deleting them. For example, if you set SnapshotRetentionLimit to 5, then a snapshot that was taken today will be retained for 5 days before being deleted. If the value of SnapshotRetentionLimit is set to zero (0), backups are turned off. Please note that setting a `snapshot_retention_limit` is not supported on cache.t1.micro cache nodes\n* `snapshot_window` - (Optional, Redis only) Daily time range (in UTC) during which ElastiCache will begin taking a daily snapshot of your cache cluster. Example: 05:00-09:00\n* `subnet_group_name` – (Optional, VPC only) Name of the subnet group to be used for the cache cluster. Changing this value will re-create the resource.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the created ElastiCache Cluster.\n* `engine_version_actual` - The running version of the cache engine.\n* `cache_nodes` - List of node objects including `id`, `address`, `port` and `availability_zone`.\n* `cluster_address` - (Memcached only) DNS name of the cache cluster without the port appended.\n* `configuration_endpoint` - (Memcached only) Configuration endpoint to allow host discovery.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nElastiCache Clusters can be imported using the `cluster_id`, e.g.,\n\n```\n$ terraform import aws_elasticache_cluster.my_cluster my_cluster\n```\n",
    "basename": "elasticache_cluster.html"
  },
  "elasticache_global_replication_group.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_global_replication_group",
    "description": "Provides an ElastiCache Global Replication Group resource.",
    "preview": "# Resource: aws_elasticache_global_replication_group\n\nProvides an …",
    "content": "\n\n# Resource: aws_elasticache_global_replication_group\n\nProvides an ElastiCache Global Replication Group resource, which manages replication between two or more Replication Groups in different regions. For more information, see the [ElastiCache User Guide](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Redis-Global-Datastore.html).\n\n## Example Usage\n\n### Global replication group with one secondary replication group\n\nThe global replication group depends on the primary group existing. Secondary replication groups depend on the global replication group. Terraform dependency management will handle this transparently using resource value references.\n\n```terraform\nresource \"aws_elasticache_global_replication_group\" \"example\" {\n  global_replication_group_id_suffix = \"example\"\n  primary_replication_group_id       = aws_elasticache_replication_group.primary.id\n}\n\nresource \"aws_elasticache_replication_group\" \"primary\" {\n  replication_group_id          = \"example-primary\"\n  replication_group_description = \"primary replication group\"\n\n  engine         = \"redis\"\n  engine_version = \"5.0.6\"\n  node_type      = \"cache.m5.large\"\n\n  number_cache_clusters = 1\n}\n\nresource \"aws_elasticache_replication_group\" \"secondary\" {\n  provider = aws.other_region\n\n  replication_group_id          = \"example-secondary\"\n  replication_group_description = \"secondary replication group\"\n  global_replication_group_id   = aws_elasticache_global_replication_group.example.global_replication_group_id\n\n  number_cache_clusters = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `global_replication_group_id_suffix` – (Required) The suffix name of a Global Datastore. If `global_replication_group_id_suffix` is changed, creates a new resource.\n* `primary_replication_group_id` – (Required) The ID of the primary cluster that accepts writes and will replicate updates to the secondary cluster. If `primary_replication_group_id` is changed, creates a new resource.\n* `global_replication_group_description` – (Optional) A user-created description for the global replication group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the ElastiCache Global Replication Group.\n* `arn` - The ARN of the ElastiCache Global Replication Group.\n* `actual_engine_version` - (**DEPRECATED** use `engine_version_actual` instead) The full version number of the cache engine running on the members of this global replication group.\n* `engine_version_actual` - The full version number of the cache engine running on the members of this global replication group.\n* `at_rest_encryption_enabled` - A flag that indicate whether the encryption at rest is enabled.\n* `auth_token_enabled` - A flag that indicate whether AuthToken (password) is enabled.\n* `cache_node_type` - The instance class used. See AWS documentation for information on [supported node types](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheNodes.SupportedTypes.html) and [guidance on selecting node types](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/nodes-select-size.html).\n* `cluster_enabled` - Indicates whether the Global Datastore is cluster enabled.\n* `engine` - The name of the cache engine to be used for the clusters in this global replication group.\n* `global_replication_group_id` - The full ID of the global replication group.\n* `transit_encryption_enabled` - A flag that indicates whether the encryption in transit is enabled.\n\n## Import\n\nElastiCache Global Replication Groups can be imported using the `global_replication_group_id`, e.g.,\n\n```\n$ terraform import aws_elasticache_global_replication_group.my_global_replication_group okuqm-global-replication-group-1\n```\n",
    "basename": "elasticache_global_replication_group.html"
  },
  "elasticache_parameter_group.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_parameter_group",
    "description": "Provides an ElastiCache parameter group resource.",
    "preview": "# Resource: aws_elasticache_parameter_group\n\nProvides an ElastiCache …",
    "content": "\n\n# Resource: aws_elasticache_parameter_group\n\nProvides an ElastiCache parameter group resource.\n\n~> **NOTE:** Attempting to remove the `reserved-memory` parameter when `family` is set to `redis2.6` or `redis2.8` may show a perpetual difference in Terraform due to an Elasticache API limitation. Leave that parameter configured with any value to workaround the issue.\n\n## Example Usage\n\n```terraform\nresource \"aws_elasticache_parameter_group\" \"default\" {\n  name   = \"cache-params\"\n  family = \"redis2.8\"\n\n  parameter {\n    name  = \"activerehashing\"\n    value = \"yes\"\n  }\n\n  parameter {\n    name  = \"min-slaves-to-write\"\n    value = \"2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the ElastiCache parameter group.\n* `family` - (Required) The family of the ElastiCache parameter group.\n* `description` - (Optional) The description of the ElastiCache parameter group. Defaults to \"Managed by Terraform\".\n* `parameter` - (Optional) A list of ElastiCache parameters to apply.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nParameter blocks support the following:\n\n* `name` - (Required) The name of the ElastiCache parameter.\n* `value` - (Required) The value of the ElastiCache parameter.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ElastiCache parameter group name.\n* `arn` - The AWS ARN associated with the parameter group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nElastiCache Parameter Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_elasticache_parameter_group.default redis-params\n```\n",
    "basename": "elasticache_parameter_group.html"
  },
  "elasticache_replication_group.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_replication_group",
    "description": "Provides an ElastiCache Replication Group resource.",
    "preview": "# Resource: aws_elasticache_replication_group\n\nProvides an …",
    "content": "\n\n# Resource: aws_elasticache_replication_group\n\nProvides an ElastiCache Replication Group resource.\n\nFor working with a [Memcached cluster](https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/WhatIs.html) or a\n[single-node Redis instance (Cluster Mode Disabled)](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.html),\nsee the [`aws_elasticache_cluster` resource](/docs/providers/aws/r/elasticache_cluster.html).\n\n~> **Note:** When you change an attribute, such as `engine_version`, by\ndefault the ElastiCache API applies it in the next maintenance window. Because\nof this, Terraform may report a difference in its planning phase because the\nactual modification has not yet taken place. You can use the\n`apply_immediately` flag to instruct the service to apply the change\nimmediately. Using `apply_immediately` can result in a brief downtime as\nservers reboots.\nSee the AWS Documentation on\n[Modifying an ElastiCache Cache Cluster](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Clusters.Modify.html)\nfor more information.\n\n~> **Note:** Any attribute changes that re-create the resource will be applied immediately, regardless of the value of `apply_immediately`.\n\n~> **Note:** Be aware of the terminology collision around \"cluster\" for `aws_elasticache_replication_group`. For example, it is possible to create a [\"Cluster Mode Disabled [Redis] Cluster\"](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Clusters.Create.CON.Redis.html). With \"Cluster Mode Enabled\", the data will be stored in shards (called \"node groups\"). See [Redis Cluster Configuration](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/cluster-create-determine-requirements.html#redis-cluster-configuration) for a diagram of the differences. To enable cluster mode, use a parameter group that has cluster mode enabled. The default parameter groups provided by AWS end with \".cluster.on\", for example `default.redis6.x.cluster.on`.\n\n## Example Usage\n\n### Redis Cluster Mode Disabled\n\nTo create a single shard primary with single read replica:\n\n```terraform\nresource \"aws_elasticache_replication_group\" \"example\" {\n  automatic_failover_enabled    = true\n  availability_zones            = [\"us-west-2a\", \"us-west-2b\"]\n  replication_group_id          = \"tf-rep-group-1\"\n  replication_group_description = \"test description\"\n  node_type                     = \"cache.m4.large\"\n  number_cache_clusters         = 2\n  parameter_group_name          = \"default.redis3.2\"\n  port                          = 6379\n}\n```\n\nYou have two options for adjusting the number of replicas:\n\n* Adjusting `number_cache_clusters` directly. This will attempt to automatically add or remove replicas, but provides no granular control (e.g., preferred availability zone, cache cluster ID) for the added or removed replicas. This also currently expects cache cluster IDs in the form of `replication_group_id-00#`.\n* Otherwise for fine grained control of the underlying cache clusters, they can be added or removed with the [`aws_elasticache_cluster` resource](/docs/providers/aws/r/elasticache_cluster.html) and its `replication_group_id` attribute. In this situation, you will need to utilize the [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` to prevent perpetual differences during Terraform plan with the `number_cache_cluster` attribute.\n\n```terraform\nresource \"aws_elasticache_replication_group\" \"example\" {\n  automatic_failover_enabled    = true\n  availability_zones            = [\"us-west-2a\", \"us-west-2b\"]\n  replication_group_id          = \"tf-rep-group-1\"\n  replication_group_description = \"test description\"\n  node_type                     = \"cache.m4.large\"\n  number_cache_clusters         = 2\n  parameter_group_name          = \"default.redis3.2\"\n  port                          = 6379\n\n  lifecycle {\n    ignore_changes = [number_cache_clusters]\n  }\n}\n\nresource \"aws_elasticache_cluster\" \"replica\" {\n  count = 1\n\n  cluster_id           = \"tf-rep-group-1-${count.index}\"\n  replication_group_id = aws_elasticache_replication_group.example.id\n}\n```\n\n### Redis Cluster Mode Enabled\n\nTo create two shards with a primary and a single read replica each:\n\n```terraform\nresource \"aws_elasticache_replication_group\" \"baz\" {\n  replication_group_id          = \"tf-redis-cluster\"\n  replication_group_description = \"test description\"\n  node_type                     = \"cache.t2.small\"\n  port                          = 6379\n  parameter_group_name          = \"default.redis3.2.cluster.on\"\n  automatic_failover_enabled    = true\n\n  cluster_mode {\n    replicas_per_node_group = 1\n    num_node_groups         = 2\n  }\n}\n```\n\n~> **Note:** We currently do not support passing a `primary_cluster_id` in order to create the Replication Group.\n\n~> **Note:** Automatic Failover is unavailable for Redis versions earlier than 2.8.6,\nand unavailable on T1 node types. For T2 node types, it is only available on Redis version 3.2.4 or later with cluster mode enabled. See the [High Availability Using Replication Groups](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.html) guide\nfor full details on using Replication Groups.\n\n### Creating a secondary replication group for a global replication group\n\nA Global Replication Group can have one one two secondary Replication Groups in different regions. These are added to an existing Global Replication Group.\n\n```terraform\nresource \"aws_elasticache_replication_group\" \"secondary\" {\n  replication_group_id          = \"example-secondary\"\n  replication_group_description = \"secondary replication group\"\n  global_replication_group_id   = aws_elasticache_global_replication_group.example.global_replication_group_id\n\n  number_cache_clusters = 1\n}\n\nresource \"aws_elasticache_global_replication_group\" \"example\" {\n  provider = aws.other_region\n\n  global_replication_group_id_suffix = \"example\"\n  primary_replication_group_id       = aws_elasticache_replication_group.primary.id\n}\n\nresource \"aws_elasticache_replication_group\" \"primary\" {\n  provider = aws.other_region\n\n  replication_group_id          = \"example-primary\"\n  replication_group_description = \"primary replication group\"\n\n  engine         = \"redis\"\n  engine_version = \"5.0.6\"\n  node_type      = \"cache.m5.large\"\n\n  number_cache_clusters = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `replication_group_description` – (Required) A user-created description for the replication group.\n* `replication_group_id` – (Required) The replication group identifier. This parameter is stored as a lowercase string.\n\nThe following arguments are optional:\n\n* `apply_immediately` - (Optional) Specifies whether any modifications are applied immediately, or during the next maintenance window. Default is `false`.\n* `at_rest_encryption_enabled` - (Optional) Whether to enable encryption at rest.\n* `auth_token` - (Optional) The password used to access a password protected server. Can be specified only if `transit_encryption_enabled = true`.\n* `auto_minor_version_upgrade` - (Optional) Specifies whether a minor engine upgrades will be applied automatically to the underlying Cache Cluster instances during the maintenance window. This parameter is currently not supported by the AWS API. Defaults to `true`.\n* `automatic_failover_enabled` - (Optional) Specifies whether a read-only replica will be automatically promoted to read/write primary if the existing primary fails. If enabled, `number_cache_clusters` must be greater than 1. Must be enabled for Redis (cluster mode enabled) replication groups. Defaults to `false`.\n* `availability_zones` - (Optional) A list of EC2 availability zones in which the replication group's cache clusters will be created. The order of the availability zones in the list is not important.\n* `cluster_mode` - (Optional) Create a native Redis cluster. `automatic_failover_enabled` must be set to true. Cluster Mode documented below. Only 1 `cluster_mode` block is allowed. Note that configuring this block does not enable cluster mode, i.e., data sharding, this requires using a parameter group that has the parameter `cluster-enabled` set to true.\n* `data_tiering_enabled` - (Optional) Enables data tiering. Data tiering is only supported for replication groups using the r6gd node type. This parameter must be set to `true` when using r6gd nodes.\n* `engine` - (Optional) The name of the cache engine to be used for the clusters in this replication group. The only valid value is `redis`.\n* `engine_version` - (Optional) The version number of the cache engine to be used for the cache clusters in this replication group. If the version is 6 or higher, only the major version can be set, e.g., `6.x`, otherwise, specify the full version desired, e.g., `5.0.6`. The actual engine version used is returned in the attribute `engine_version_actual`, [defined below](#engine_version_actual).\n* `final_snapshot_identifier` - (Optional) The name of your final node group (shard) snapshot. ElastiCache creates the snapshot from the primary node in the cluster. If omitted, no final snapshot will be made.\n* `global_replication_group_id` - (Optional) The ID of the global replication group to which this replication group should belong. If this parameter is specified, the replication group is added to the specified global replication group as a secondary replication group; otherwise, the replication group is not part of any global replication group. If `global_replication_group_id` is set, the `num_node_groups` parameter of the `cluster_mode` block cannot be set.\n* `kms_key_id` - (Optional) The ARN of the key that you wish to use if encrypting at rest. If not supplied, uses service managed encryption. Can be specified only if `at_rest_encryption_enabled = true`.\n* `maintenance_window` – (Optional) Specifies the weekly time range for when maintenance on the cache cluster is performed. The format is `ddd:hh24:mi-ddd:hh24:mi` (24H Clock UTC). The minimum maintenance window is a 60 minute period. Example: `sun:05:00-sun:09:00`\n* `multi_az_enabled` - (Optional) Specifies whether to enable Multi-AZ Support for the replication group. If `true`, `automatic_failover_enabled` must also be enabled. Defaults to `false`.\n* `node_type` - (Optional) The instance class to be used. See AWS documentation for information on [supported node types](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheNodes.SupportedTypes.html) and [guidance on selecting node types](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/nodes-select-size.html). Required unless `global_replication_group_id` is set. Cannot be set if `global_replication_group_id` is set.\n* `notification_topic_arn` – (Optional) An Amazon Resource Name (ARN) of an SNS topic to send ElastiCache notifications to. Example: `arn:aws:sns:us-east-1:012345678999:my_sns_topic`\n* `number_cache_clusters` - (Optional) The number of cache clusters (primary and replicas) this replication group will have. If Multi-AZ is enabled, the value of this parameter must be at least 2. Updates will occur before other modifications. One of `number_cache_clusters` or `cluster_mode` is required.\n* `parameter_group_name` - (Optional) The name of the parameter group to associate with this replication group. If this argument is omitted, the default cache parameter group for the specified engine is used. To enable \"cluster mode\", i.e., data sharding, use a parameter group that has the parameter `cluster-enabled` set to true.\n* `port` – (Optional) The port number on which each of the cache nodes will accept connections. For Memcache the default is 11211, and for Redis the default port is 6379.\n* `security_group_ids` - (Optional) One or more Amazon VPC security groups associated with this replication group. Use this parameter only when you are creating a replication group in an Amazon Virtual Private Cloud\n* `security_group_names` - (Optional) A list of cache security group names to associate with this replication group.\n* `snapshot_arns` – (Optional) A list of Amazon Resource Names (ARNs) that identify Redis RDB snapshot files stored in Amazon S3. The names object names cannot contain any commas.\n* `snapshot_name` - (Optional) The name of a snapshot from which to restore data into the new node group. Changing the `snapshot_name` forces a new resource.\n* `snapshot_retention_limit` - (Optional, Redis only) The number of days for which ElastiCache will retain automatic cache cluster snapshots before deleting them. For example, if you set SnapshotRetentionLimit to 5, then a snapshot that was taken today will be retained for 5 days before being deleted. If the value of SnapshotRetentionLimit is set to zero (0), backups are turned off. Please note that setting a `snapshot_retention_limit` is not supported on cache.t1.micro cache nodes\n* `snapshot_window` - (Optional, Redis only) The daily time range (in UTC) during which ElastiCache will begin taking a daily snapshot of your cache cluster. The minimum snapshot window is a 60 minute period. Example: `05:00-09:00`\n* `subnet_group_name` - (Optional) The name of the cache subnet group to be used for the replication group.\n* `tags` - (Optional) A map of tags to assign to the resource. Adding tags to this resource will add or overwrite any existing tags on the clusters in the replication group and not to the group itself. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `transit_encryption_enabled` - (Optional) Whether to enable encryption in transit.\n\n### cluster_mode\n\n* `num_node_groups` - (Optional) Number of node groups (shards) for this Redis replication group. Changing this number will trigger an online resizing operation before other settings modifications. Required unless `global_replication_group_id` is set.\n* `replicas_per_node_group` - (Required) Number of replica nodes in each node group. Valid values are 0 to 5. Changing this number will trigger an online resizing operation before other settings modifications.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the created ElastiCache Replication Group.\n* `engine_version_actual` - The running version of the cache engine.\n* `cluster_enabled` - Indicates if cluster mode is enabled.\n* `configuration_endpoint_address` - The address of the replication group configuration endpoint when cluster mode is enabled.\n* `id` - The ID of the ElastiCache Replication Group.\n* `member_clusters` - The identifiers of all the nodes that are part of this replication group.\n* `primary_endpoint_address` - (Redis only) The address of the endpoint for the primary node in the replication group, if the cluster mode is disabled.\n* `reader_endpoint_address` - (Redis only) The address of the endpoint for the reader node in the replication group, if the cluster mode is disabled.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_elasticache_replication_group` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `60m`) How long to wait for a replication group to be created.\n* `delete` - (Default `40m`) How long to wait for a replication group to be deleted.\n* `update` - (Default `40m`) How long to wait for replication group settings to be updated. This is also separately used for adding/removing replicas and online resize operation completion, if necessary.\n\n## Import\n\nElastiCache Replication Groups can be imported using the `replication_group_id`, e.g.,\n\n```\n$ terraform import aws_elasticache_replication_group.my_replication_group replication-group-1\n```\n",
    "basename": "elasticache_replication_group.html"
  },
  "elasticache_security_group.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_security_group",
    "description": "Provides an ElastiCache Security Group to control access to one or more cache clusters.",
    "preview": "# Resource: aws_elasticache_security_group\n\nProvides an ElastiCache …",
    "content": "\n\n# Resource: aws_elasticache_security_group\n\nProvides an ElastiCache Security Group to control access to one or more cache\nclusters.\n\n~> **NOTE:** ElastiCache Security Groups are for use only when working with an\nElastiCache cluster **outside** of a VPC. If you are using a VPC, see the\n[ElastiCache Subnet Group resource](elasticache_subnet_group.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_security_group\" \"bar\" {\n  name = \"security-group\"\n}\n\nresource \"aws_elasticache_security_group\" \"bar\" {\n  name                 = \"elasticache-security-group\"\n  security_group_names = [aws_security_group.bar.name]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` – (Required) Name for the cache security group. This value is stored as a lowercase string.\n* `description` – (Optional) description for the cache security group. Defaults to \"Managed by Terraform\".\n* `security_group_names` – (Required) List of EC2 security group names to be\nauthorized for ingress to the cache security group\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `description`\n* `name`\n* `security_group_names`\n\n## Import\n\nElastiCache Security Groups can be imported by name, e.g.,\n\n```\n$ terraform import aws_elasticache_security_group.my_ec_security_group ec-security-group-1\n```\n",
    "basename": "elasticache_security_group.html"
  },
  "elasticache_subnet_group.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_subnet_group",
    "description": "Provides an ElastiCache Subnet Group resource.",
    "preview": "# Resource: aws_elasticache_subnet_group\n\nProvides an ElastiCache …",
    "content": "\n\n# Resource: aws_elasticache_subnet_group\n\nProvides an ElastiCache Subnet Group resource.\n\n~> **NOTE:** ElastiCache Subnet Groups are only for use when working with an\nElastiCache cluster **inside** of a VPC. If you are on EC2 Classic, see the\n[ElastiCache Security Group resource](elasticache_security_group.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"foo\" {\n  cidr_block = \"10.0.0.0/16\"\n\n  tags = {\n    Name = \"tf-test\"\n  }\n}\n\nresource \"aws_subnet\" \"foo\" {\n  vpc_id            = aws_vpc.foo.id\n  cidr_block        = \"10.0.0.0/24\"\n  availability_zone = \"us-west-2a\"\n\n  tags = {\n    Name = \"tf-test\"\n  }\n}\n\nresource \"aws_elasticache_subnet_group\" \"bar\" {\n  name       = \"tf-test-cache-subnet\"\n  subnet_ids = [aws_subnet.foo.id]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` – (Required) Name for the cache subnet group. Elasticache converts this name to lowercase.\n* `description` – (Optional) Description for the cache subnet group. Defaults to \"Managed by Terraform\".\n* `subnet_ids` – (Required) List of VPC Subnet IDs for the cache subnet group\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `description` - The Description of the ElastiCache Subnet Group.\n* `name` - The Name of the ElastiCache Subnet Group.\n* `subnet_ids` - The Subnet IDs of the ElastiCache Subnet Group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nElastiCache Subnet Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_elasticache_subnet_group.bar tf-test-cache-subnet\n```\n",
    "basename": "elasticache_subnet_group.html"
  },
  "elasticache_user.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_user",
    "description": "Provides an ElastiCache user.",
    "preview": "# Resource: aws_elasticache_user\n\nProvides an ElastiCache user …",
    "content": "\n\n# Resource: aws_elasticache_user\n\nProvides an ElastiCache user resource.\n\n~> **Note:** All arguments including the username and passwords will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_elasticache_user\" \"test\" {\n  user_id       = \"testUserId\"\n  user_name     = \"testUserName\"\n  access_string = \"on ~app::* -@all +@read +@hash +@bitmap +@geo -setbit -bitfield -hset -hsetnx -hmset -hincrby -hincrbyfloat -hdel -bitop -geoadd -georadius -georadiusbymember\"\n  engine        = \"REDIS\"\n  passwords     = [\"password123456789\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `access_string` - (Required) Access permissions string used for this user. See [Specifying Permissions Using an Access String](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Clusters.RBAC.html#Access-string) for more details.\n* `engine` - (Required) The current supported value is `REDIS`.\n* `user_id` - (Required) The ID of the user.\n* `user_name` - (Required) The username of the user.\n\nThe following arguments are optional:\n\n* `no_password_required` - (Optional) Indicates a password is not required for this user.\n* `passwords` - (Optional) Passwords used for this user. You can create up to two passwords for each user.\n* `tags` - (Optional) A list of tags to be added to this resource. A tag is a key-value pair.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the created ElastiCache User.\n\n## Import\n\nElastiCache users can be imported using the `user_id`, e.g.,\n\n```\n$ terraform import aws_elasticache_user.my_user userId1\n```\n",
    "basename": "elasticache_user.html"
  },
  "elasticache_user_group.html": {
    "subcategory": "ElastiCache",
    "layout": "aws",
    "page_title": "AWS: aws_elasticache_user_group",
    "description": "Provides an ElastiCache user group.",
    "preview": "# Resource: aws_elasticache_user_group\n\nProvides an ElastiCache user …",
    "content": "\n\n# Resource: aws_elasticache_user_group\n\nProvides an ElastiCache user group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_elasticache_user\" \"test\" {\n  user_id       = \"testUserId\"\n  user_name     = \"default\"\n  access_string = \"on ~app::* -@all +@read +@hash +@bitmap +@geo -setbit -bitfield -hset -hsetnx -hmset -hincrby -hincrbyfloat -hdel -bitop -geoadd -georadius -georadiusbymember\"\n  engine        = \"REDIS\"\n  passwords     = [\"password123456789\"]\n}\n\nresource \"aws_elasticache_user_group\" \"test\" {\n  engine        = \"REDIS\"\n  user_group_id = \"userGroupId\"\n  user_ids      = [aws_elasticache_user.test.user_id]\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `engine` - (Required) The current supported value is `REDIS`.\n* `user_group_id` - (Required) The ID of the user group.\n\nThe following arguments are optional:\n\n* `user_ids` - (Optional) The list of user IDs that belong to the user group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The user group identifier.\n\n## Import\n\nElastiCache user groups can be imported using the `user_group_id`, e.g.,\n\n```\n$ terraform import aws_elasticache_user_group.my_user_group userGoupId1\n```\n",
    "basename": "elasticache_user_group.html"
  },
  "elasticsearch_domain.html": {
    "subcategory": "Elasticsearch",
    "layout": "aws",
    "page_title": "AWS: aws_elasticsearch_domain",
    "description": "Terraform resource for managing an AWS Elasticsearch Domain.",
    "preview": "# Resource: aws_elasticsearch_domain\n\nManages an AWS Elasticsearch …",
    "content": "\n\n# Resource: aws_elasticsearch_domain\n\nManages an AWS Elasticsearch Domain.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_elasticsearch_domain\" \"example\" {\n  domain_name           = \"example\"\n  elasticsearch_version = \"7.10\"\n\n  cluster_config {\n    instance_type = \"r4.large.elasticsearch\"\n  }\n\n  tags = {\n    Domain = \"TestDomain\"\n  }\n}\n```\n\n### Access Policy\n\n-> See also: [`aws_elasticsearch_domain_policy` resource](/docs/providers/aws/r/elasticsearch_domain_policy.html)\n\n```terraform\nvariable \"domain\" {\n  default = \"tf-test\"\n}\n\ndata \"aws_region\" \"current\" {}\n\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_elasticsearch_domain\" \"example\" {\n  domain_name = var.domain\n\n  # ... other configuration ...\n\n  access_policies = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"es:*\",\n      \"Principal\": \"*\",\n      \"Effect\": \"Allow\",\n      \"Resource\": \"arn:aws:es:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:domain/${var.domain}/*\",\n      \"Condition\": {\n        \"IpAddress\": {\"aws:SourceIp\": [\"66.193.100.22/32\"]}\n      }\n    }\n  ]\n}\nPOLICY\n}\n```\n\n### Log Publishing to CloudWatch Logs\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_cloudwatch_log_resource_policy\" \"example\" {\n  policy_name = \"example\"\n\n  policy_document = <<CONFIG\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"es.amazonaws.com\"\n      },\n      \"Action\": [\n        \"logs:PutLogEvents\",\n        \"logs:PutLogEventsBatch\",\n        \"logs:CreateLogStream\"\n      ],\n      \"Resource\": \"arn:aws:logs:*\"\n    }\n  ]\n}\nCONFIG\n}\n\nresource \"aws_elasticsearch_domain\" \"example\" {\n  # .. other configuration ...\n\n  log_publishing_options {\n    cloudwatch_log_group_arn = aws_cloudwatch_log_group.example.arn\n    log_type                 = \"INDEX_SLOW_LOGS\"\n  }\n}\n```\n\n### VPC based ES\n\n```terraform\nvariable \"vpc\" {}\n\nvariable \"domain\" {\n  default = \"tf-test\"\n}\n\ndata \"aws_vpc\" \"selected\" {\n  tags = {\n    Name = var.vpc\n  }\n}\n\ndata \"aws_subnet_ids\" \"selected\" {\n  vpc_id = data.aws_vpc.selected.id\n\n  tags = {\n    Tier = \"private\"\n  }\n}\n\ndata \"aws_region\" \"current\" {}\n\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_security_group\" \"es\" {\n  name        = \"${var.vpc}-elasticsearch-${var.domain}\"\n  description = \"Managed by Terraform\"\n  vpc_id      = data.aws_vpc.selected.id\n\n  ingress {\n    from_port = 443\n    to_port   = 443\n    protocol  = \"tcp\"\n\n    cidr_blocks = [\n      data.aws_vpc.selected.cidr_block,\n    ]\n  }\n}\n\nresource \"aws_iam_service_linked_role\" \"es\" {\n  aws_service_name = \"es.amazonaws.com\"\n}\n\nresource \"aws_elasticsearch_domain\" \"es\" {\n  domain_name           = var.domain\n  elasticsearch_version = \"6.3\"\n\n  cluster_config {\n    instance_type          = \"m4.large.elasticsearch\"\n    zone_awareness_enabled = true\n  }\n\n  vpc_options {\n    subnet_ids = [\n      data.aws_subnet_ids.selected.ids[0],\n      data.aws_subnet_ids.selected.ids[1],\n    ]\n\n    security_group_ids = [aws_security_group.es.id]\n  }\n\n  advanced_options = {\n    \"rest.action.multi.allow_explicit_index\" = \"true\"\n  }\n\n  access_policies = <<CONFIG\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\t\"Action\": \"es:*\",\n\t\t\t\"Principal\": \"*\",\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Resource\": \"arn:aws:es:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:domain/${var.domain}/*\"\n\t\t}\n\t]\n}\nCONFIG\n\n  tags = {\n    Domain = \"TestDomain\"\n  }\n\n  depends_on = [aws_iam_service_linked_role.es]\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `domain_name` - (Required) Name of the domain.\n\nThe following arguments are optional:\n\n* `access_policies` - (Optional) IAM policy document specifying the access policies for the domain.\n* `advanced_options` - (Optional) Key-value string pairs to specify advanced configuration options. Note that the values for these configuration options must be strings (wrapped in quotes) or they may be wrong and cause a perpetual diff, causing Terraform to want to recreate your Elasticsearch domain on every apply.\n* `advanced_security_options` - (Optional) Configuration block for [fine-grained access control](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/fgac.html). Detailed below.\n* `auto_tune_options` - (Optional) Configuration block for the Auto-Tune options of the domain. Detailed below.\n* `cluster_config` - (Optional) Configuration block for the cluster of the domain. Detailed below.\n* `cognito_options` - (Optional) Configuration block for authenticating Kibana with Cognito. Detailed below.\n* `domain_endpoint_options` - (Optional) Configuration block for domain endpoint HTTP(S) related options. Detailed below.\n* `ebs_options` - (Optional) Configuration block for EBS related options, may be required based on chosen [instance size](https://aws.amazon.com/elasticsearch-service/pricing/). Detailed below.\n* `elasticsearch_version` - (Optional) Version of Elasticsearch to deploy. Defaults to `1.5`.\n* `encrypt_at_rest` - (Optional) Configuration block for encrypt at rest options. Only available for [certain instance types](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-supported-instance-types.html). Detailed below.\n* `log_publishing_options` - (Optional) Configuration block for publishing slow and application logs to CloudWatch Logs. This block can be declared multiple times, for each log_type, within the same resource. Detailed below.\n* `node_to_node_encryption` - (Optional) Configuration block for node-to-node encryption options. Detailed below.\n* `snapshot_options` - (Optional) Configuration block for snapshot related options. Detailed below. DEPRECATED. For domains running Elasticsearch 5.3 and later, Amazon ES takes hourly automated snapshots, making this setting irrelevant. For domains running earlier versions of Elasticsearch, Amazon ES takes daily automated snapshots.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_options` - (Optional) Configuration block for VPC related options. Adding or removing this configuration forces a new resource ([documentation](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-vpc.html#es-vpc-limitations)). Detailed below.\n\n### advanced_security_options\n\n* `enabled` - (Required, Forces new resource) Whether advanced security is enabled.\n* `internal_user_database_enabled` - (Optional, Default: false) Whether the internal user database is enabled. If not set, defaults to `false` by the AWS API.\n* `master_user_options` - (Optional) Configuration block for the main user. Detailed below.\n\n#### master_user_options\n\n* `master_user_arn` - (Optional) ARN for the main user. Only specify if `internal_user_database_enabled` is not set or set to `false`.\n* `master_user_name` - (Optional) Main user's username, which is stored in the Amazon Elasticsearch Service domain's internal database. Only specify if `internal_user_database_enabled` is set to `true`.\n* `master_user_password` - (Optional) Main user's password, which is stored in the Amazon Elasticsearch Service domain's internal database. Only specify if `internal_user_database_enabled` is set to `true`.\n\n### auto_tune_options\n\n* `desired_state` - (Required) The Auto-Tune desired state for the domain. Valid values: `ENABLED` or `DISABLED`.\n* `maintenance_schedule` - (Required if `rollback_on_disable` is set to `DEFAULT_ROLLBACK`) Configuration block for Auto-Tune maintenance windows. Can be specified multiple times for each maintenance window. Detailed below.\n* `rollback_on_disable` - (Optional) Whether to roll back to default Auto-Tune settings when disabling Auto-Tune. Valid values: `DEFAULT_ROLLBACK` or `NO_ROLLBACK`.\n\n#### maintenance_schedule\n\n* `start_at` - (Required) Date and time at which to start the Auto-Tune maintenance schedule in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `duration` - (Required) Configuration block for the duration of the Auto-Tune maintenance window. Detailed below.\n* `cron_expression_for_recurrence` - (Required) A cron expression specifying the recurrence pattern for an Auto-Tune maintenance schedule.\n\n##### duration\n\n* `value` - (Required) An integer specifying the value of the duration of an Auto-Tune maintenance window.\n* `unit` - (Required) The unit of time specifying the duration of an Auto-Tune maintenance window. Valid values: `HOURS`.\n\n### cluster_config\n\n* `dedicated_master_count` - (Optional) Number of dedicated main nodes in the cluster.\n* `dedicated_master_enabled` - (Optional) Whether dedicated main nodes are enabled for the cluster.\n* `dedicated_master_type` - (Optional) Instance type of the dedicated main nodes in the cluster.\n* `instance_count` - (Optional) Number of instances in the cluster.\n* `instance_type` - (Optional) Instance type of data nodes in the cluster.\n* `warm_count` - (Optional) Number of warm nodes in the cluster. Valid values are between `2` and `150`. `warm_count` can be only and must be set when `warm_enabled` is set to `true`.\n* `warm_enabled` - (Optional) Whether to enable warm storage.\n* `warm_type` - (Optional) Instance type for the Elasticsearch cluster's warm nodes. Valid values are `ultrawarm1.medium.elasticsearch`, `ultrawarm1.large.elasticsearch` and `ultrawarm1.xlarge.elasticsearch`. `warm_type` can be only and must be set when `warm_enabled` is set to `true`.\n* `zone_awareness_config` - (Optional) Configuration block containing zone awareness settings. Detailed below.\n* `zone_awareness_enabled` - (Optional) Whether zone awareness is enabled, set to `true` for multi-az deployment. To enable awareness with three Availability Zones, the `availability_zone_count` within the `zone_awareness_config` must be set to `3`.\n\n#### zone_awareness_config\n\n* `availability_zone_count` - (Optional) Number of Availability Zones for the domain to use with `zone_awareness_enabled`. Defaults to `2`. Valid values: `2` or `3`.\n\n### cognito_options\n\nAWS documentation: [Amazon Cognito Authentication for Kibana](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-cognito-auth.html)\n\n* `enabled` - (Optional, Default: false) Whether Amazon Cognito authentication with Kibana is enabled or not.\n* `identity_pool_id` - (Required) ID of the Cognito Identity Pool to use.\n* `role_arn` - (Required) ARN of the IAM role that has the AmazonESCognitoAccess policy attached.\n* `user_pool_id` - (Required) ID of the Cognito User Pool to use.\n\n### domain_endpoint_options\n\n* `custom_endpoint_certificate_arn` - (Optional) ACM certificate ARN for your custom endpoint.\n* `custom_endpoint_enabled` - (Optional) Whether to enable custom endpoint for the Elasticsearch domain.\n* `custom_endpoint` - (Optional) Fully qualified domain for your custom endpoint.\n* `enforce_https` - (Optional) Whether or not to require HTTPS. Defaults to `true`.\n* `tls_security_policy` - (Optional) Name of the TLS security policy that needs to be applied to the HTTPS endpoint. Valid values:  `Policy-Min-TLS-1-0-2019-07` and `Policy-Min-TLS-1-2-2019-07`. Terraform will only perform drift detection if a configuration value is provided.\n\n### ebs_options\n\n* `ebs_enabled` - (Required) Whether EBS volumes are attached to data nodes in the domain.\n* `iops` - (Optional) Baseline input/output (I/O) performance of EBS volumes attached to data nodes. Applicable only for the Provisioned IOPS EBS volume type.\n* `volume_size` - (Required if `ebs_enabled` is set to `true`.) Size of EBS volumes attached to data nodes (in GiB).\n* `volume_type` - (Optional) Type of EBS volumes attached to data nodes.\n\n### encrypt_at_rest\n\n* `enabled` - (Required) Whether to enable encryption at rest. If the `encrypt_at_rest` block is not provided then this defaults to `false`.\n* `kms_key_id` - (Optional) KMS key id to encrypt the Elasticsearch domain with. If not specified then it defaults to using the `aws/es` service KMS key.\n\n### log_publishing_options\n\n* `cloudwatch_log_group_arn` - (Required) ARN of the Cloudwatch log group to which log needs to be published.\n* `enabled` - (Optional, Default: true) Whether given log publishing option is enabled or not.\n* `log_type` - (Required) Type of Elasticsearch log. Valid values: `INDEX_SLOW_LOGS`, `SEARCH_SLOW_LOGS`, `ES_APPLICATION_LOGS`, `AUDIT_LOGS`.\n\n### node_to_node_encryption\n\n* `enabled` - (Required) Whether to enable node-to-node encryption. If the `node_to_node_encryption` block is not provided then this defaults to `false`.\n\n### snapshot_options\n\n* `automated_snapshot_start_hour` - (Required) Hour during which the service takes an automated daily snapshot of the indices in the domain.\n\n### vpc_options\n\nAWS documentation: [VPC Support for Amazon Elasticsearch Service Domains](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-vpc.html)\n\n~> **Note:** You must have created the service linked role for the Elasticsearch service to use `vpc_options`. If you need to create the service linked role at the same time as the Elasticsearch domain then you must use `depends_on` to make sure that the role is created before the Elasticsearch domain. See the [VPC based ES domain example](#vpc-based-es) above.\n\n-> Security Groups and Subnets referenced in these attributes must all be within the same VPC. This determines what VPC the endpoints are created in.\n\n* `security_group_ids` - (Optional) List of VPC Security Group IDs to be applied to the Elasticsearch domain endpoints. If omitted, the default Security Group for the VPC will be used.\n* `subnet_ids` - (Required) List of VPC Subnet IDs for the Elasticsearch domain endpoints to be created in.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the domain.\n* `domain_id` - Unique identifier for the domain.\n* `domain_name` - Name of the Elasticsearch domain.\n* `endpoint` - Domain-specific endpoint used to submit index, search, and data upload requests.\n* `kibana_endpoint` - Domain-specific endpoint for kibana without https scheme.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_options.0.availability_zones` - If the domain was created inside a VPC, the names of the availability zones the configured `subnet_ids` were created inside.\n* `vpc_options.0.vpc_id` - If the domain was created inside a VPC, the ID of the VPC.\n\n## Timeouts\n\n`aws_elasticsearch_domain` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `update` - (Optional, Default: `60m`) How long to wait for updates.\n\n## Import\n\nElasticsearch domains can be imported using the `domain_name`, e.g.,\n\n```\n$ terraform import aws_elasticsearch_domain.example domain_name\n```\n",
    "basename": "elasticsearch_domain.html"
  },
  "elasticsearch_domain_policy.html": {
    "subcategory": "Elasticsearch",
    "layout": "aws",
    "page_title": "AWS: aws_elasticsearch_domain",
    "description": "Provides an Elasticsearch Domain Policy.",
    "preview": "# Resource: aws_elasticsearch_domain_policy\n\nAllows setting policy …",
    "content": "\n\n# Resource: aws_elasticsearch_domain_policy\n\nAllows setting policy to an Elasticsearch domain while referencing domain attributes (e.g., ARN)\n\n## Example Usage\n\n```terraform\nresource \"aws_elasticsearch_domain\" \"example\" {\n  domain_name           = \"tf-test\"\n  elasticsearch_version = \"2.3\"\n}\n\nresource \"aws_elasticsearch_domain_policy\" \"main\" {\n  domain_name = aws_elasticsearch_domain.example.domain_name\n\n  access_policies = <<POLICIES\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"es:*\",\n            \"Principal\": \"*\",\n            \"Effect\": \"Allow\",\n            \"Condition\": {\n                \"IpAddress\": {\"aws:SourceIp\": \"127.0.0.1/32\"}\n            },\n            \"Resource\": \"${aws_elasticsearch_domain.example.arn}/*\"\n        }\n    ]\n}\nPOLICIES\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Required) Name of the domain.\n* `access_policies` - (Optional) IAM policy document specifying the access policies for the domain\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "elasticsearch_domain_policy.html"
  },
  "elasticsearch_domain_saml_options.html": {
    "subcategory": "Elasticsearch",
    "layout": "aws",
    "page_title": "AWS: aws_elasticsearch_domain_saml_options",
    "description": "Terraform resource for managing SAML authentication options for an AWS Elasticsearch Domain.",
    "preview": "# Resource: aws_elasticsearch_domain_saml_options\n\nManages SAML …",
    "content": "\n\n# Resource: aws_elasticsearch_domain_saml_options\n\nManages SAML authentication options for an AWS Elasticsearch Domain.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_elasticsearch_domain\" \"example\" {\n  domain_name           = \"example\"\n  elasticsearch_version = \"1.5\"\n\n  cluster_config {\n    instance_type = \"r4.large.elasticsearch\"\n  }\n\n  snapshot_options {\n    automated_snapshot_start_hour = 23\n  }\n\n  tags = {\n    Domain = \"TestDomain\"\n  }\n}\n\nresource \"aws_elasticsearch_domain_saml_options\" \"example\" {\n  domain_name = aws_elasticsearch_domain.example.domain_name\n  saml_options {\n    enabled = true\n    idp {\n      entity_id        = \"https://example.com\"\n      metadata_content = file(\"./saml-metadata.xml\")\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `domain_name` - (Required) Name of the domain.\n\nThe following arguments are optional:\n\n* `saml_options` - (Optional) The SAML authentication options for an AWS Elasticsearch Domain.\n\n### saml_options\n\n* `enabled` - (Required) Whether SAML authentication is enabled.\n* `idp` - (Optional) Information from your identity provider.\n* `master_backend_role` - (Optional) This backend role from the SAML IdP receives full permissions to the cluster, equivalent to a new master user.\n* `master_user_name` - (Optional) This username from the SAML IdP receives full permissions to the cluster, equivalent to a new master user.\n* `roles_key` - (Optional) Element of the SAML assertion to use for backend roles. Default is roles.\n* `session_timeout_minutes` - (Optional) Duration of a session in minutes after a user logs in. Default is 60. Maximum value is 1,440.\n* `subject_key` - (Optional) Element of the SAML assertion to use for username. Default is NameID.\n\n\n#### idp\n\n* `entity_id` - (Required) The unique Entity ID of the application in SAML Identity Provider.\n* `metadata_content` - (Required) The Metadata of the SAML application in xml format.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the domain the SAML options are associated with.\n\n## Import\n\nElasticsearch domains can be imported using the `domain_name`, e.g.,\n\n```\n$ terraform import aws_elasticsearch_domain_saml_options.example domain_name\n```\n",
    "basename": "elasticsearch_domain_saml_options.html"
  },
  "elastictranscoder_pipeline.html": {
    "subcategory": "Elastic Transcoder",
    "layout": "aws",
    "page_title": "AWS: aws_elastictranscoder_pipeline",
    "description": "Provides an Elastic Transcoder pipeline resource.",
    "preview": "# Resource: aws_elastictranscoder_pipeline\n\nProvides an Elastic …",
    "content": "\n\n# Resource: aws_elastictranscoder_pipeline\n\nProvides an Elastic Transcoder pipeline resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_elastictranscoder_pipeline\" \"bar\" {\n  input_bucket = aws_s3_bucket.input_bucket.bucket\n  name         = \"aws_elastictranscoder_pipeline_tf_test_\"\n  role         = aws_iam_role.test_role.arn\n\n  content_config {\n    bucket        = aws_s3_bucket.content_bucket.bucket\n    storage_class = \"Standard\"\n  }\n\n  thumbnail_config {\n    bucket        = aws_s3_bucket.thumb_bucket.bucket\n    storage_class = \"Standard\"\n  }\n}\n```\n\n## Argument Reference\n\nSee [\"Create Pipeline\"](http://docs.aws.amazon.com/elastictranscoder/latest/developerguide/create-pipeline.html) in the AWS docs for reference.\n\nThe following arguments are supported:\n\n* `aws_kms_key_arn` - (Optional) The AWS Key Management Service (AWS KMS) key that you want to use with this pipeline.\n* `content_config` - (Optional) The ContentConfig object specifies information about the Amazon S3 bucket in which you want Elastic Transcoder to save transcoded files and playlists. (documented below)\n* `content_config_permissions` - (Optional) The permissions for the `content_config` object. (documented below)\n* `input_bucket` - (Required) The Amazon S3 bucket in which you saved the media files that you want to transcode and the graphics that you want to use as watermarks.\n* `name` - (Optional, Forces new resource) The name of the pipeline. Maximum 40 characters\n* `notifications` - (Optional) The Amazon Simple Notification Service (Amazon SNS) topic that you want to notify to report job status. (documented below)\n* `output_bucket` - (Optional) The Amazon S3 bucket in which you want Elastic Transcoder to save the transcoded files.\n* `role` - (Required) The IAM Amazon Resource Name (ARN) for the role that you want Elastic Transcoder to use to transcode jobs for this pipeline.\n* `thumbnail_config` - (Optional) The ThumbnailConfig object specifies information about the Amazon S3 bucket in which you want Elastic Transcoder to save thumbnail files. (documented below)\n* `thumbnail_config_permissions` - (Optional) The permissions for the `thumbnail_config` object. (documented below)\n\nThe `content_config` object specifies information about the Amazon S3 bucket in\nwhich you want Elastic Transcoder to save transcoded files and playlists: which\nbucket to use, and the storage class that you want to assign to the files. If\nyou specify values for `content_config`, you must also specify values for\n`thumbnail_config`. If you specify values for `content_config` and\n`thumbnail_config`, omit the `output_bucket` object.\n\nThe `content_config` object supports the following:\n\n* `bucket` - The Amazon S3 bucket in which you want Elastic Transcoder to save transcoded files and playlists.\n* `storage_class` - The Amazon S3 storage class, `Standard` or `ReducedRedundancy`, that you want Elastic Transcoder to assign to the files and playlists that it stores in your Amazon S3 bucket.\n\nThe `content_config_permissions` object supports the following:\n\n* `access` - The permission that you want to give to the AWS user that you specified in `content_config_permissions.grantee`. Valid values are `Read`, `ReadAcp`, `WriteAcp` or `FullControl`.\n* `grantee` - The AWS user or group that you want to have access to transcoded files and playlists.\n* `grantee_type` - Specify the type of value that appears in the `content_config_permissions.grantee` object. Valid values are `Canonical`, `Email` or `Group`.\n\n\nThe `notifications` object supports the following:\n\n* `completed` - The topic ARN for the Amazon SNS topic that you want to notify when Elastic Transcoder has finished processing a job in this pipeline.\n* `error` - The topic ARN for the Amazon SNS topic that you want to notify when Elastic Transcoder encounters an error condition while processing a job in this pipeline.\n* `progressing` - The topic ARN for the Amazon Simple Notification Service (Amazon SNS) topic that you want to notify when Elastic Transcoder has started to process a job in this pipeline.\n* `warning` - The topic ARN for the Amazon SNS topic that you want to notify when Elastic Transcoder encounters a warning condition while processing a job in this pipeline.\n\nThe `thumbnail_config` object specifies information about the Amazon S3 bucket in\nwhich you want Elastic Transcoder to save thumbnail files: which bucket to use,\nwhich users you want to have access to the files, the type of access you want\nusers to have, and the storage class that you want to assign to the files. If\nyou specify values for `content_config`, you must also specify values for\n`thumbnail_config` even if you don't want to create thumbnails. (You control\nwhether to create thumbnails when you create a job. For more information, see\nThumbnailPattern in the topic Create Job.) If you specify values for\n`content_config` and `thumbnail_config`, omit the OutputBucket object.\n\nThe `thumbnail_config` object supports the following:\n\n* `bucket` - The Amazon S3 bucket in which you want Elastic Transcoder to save thumbnail files.\n* `storage_class` - The Amazon S3 storage class, Standard or ReducedRedundancy, that you want Elastic Transcoder to assign to the thumbnails that it stores in your Amazon S3 bucket.\n\nThe `thumbnail_config_permissions` object supports the following:\n\n* `access` - The permission that you want to give to the AWS user that you specified in `thumbnail_config_permissions.grantee`. Valid values are `Read`, `ReadAcp`, `WriteAcp` or `FullControl`.\n* `grantee` - The AWS user or group that you want to have access to thumbnail files.\n* `grantee_type` - Specify the type of value that appears in the `thumbnail_config_permissions.grantee` object. Valid values are `Canonical`, `Email` or `Group`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Elastictranscoder pipeline.\n* `arn` - The ARN of the Elastictranscoder pipeline.\n\n## Import\n\nElastic Transcoder pipelines can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_elastictranscoder_pipeline.basic_pipeline 1407981661351-cttk8b\n```\n",
    "basename": "elastictranscoder_pipeline.html"
  },
  "elastictranscoder_preset.html": {
    "subcategory": "Elastic Transcoder",
    "layout": "aws",
    "page_title": "AWS: aws_elastictranscoder_preset",
    "description": "Provides an Elastic Transcoder preset resource.",
    "preview": "# Resource: aws_elastictranscoder_preset\n\nProvides an Elastic …",
    "content": "\n\n# Resource: aws_elastictranscoder_preset\n\nProvides an Elastic Transcoder preset resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_elastictranscoder_preset\" \"bar\" {\n  container   = \"mp4\"\n  description = \"Sample Preset\"\n  name        = \"sample_preset\"\n\n  audio {\n    audio_packing_mode = \"SingleTrack\"\n    bit_rate           = 96\n    channels           = 2\n    codec              = \"AAC\"\n    sample_rate        = 44100\n  }\n\n  audio_codec_options {\n    profile = \"AAC-LC\"\n  }\n\n  video {\n    bit_rate             = \"1600\"\n    codec                = \"H.264\"\n    display_aspect_ratio = \"16:9\"\n    fixed_gop            = \"false\"\n    frame_rate           = \"auto\"\n    max_frame_rate       = \"60\"\n    keyframes_max_dist   = 240\n    max_height           = \"auto\"\n    max_width            = \"auto\"\n    padding_policy       = \"Pad\"\n    sizing_policy        = \"Fit\"\n  }\n\n  video_codec_options = {\n    Profile                  = \"main\"\n    Level                    = \"2.2\"\n    MaxReferenceFrames       = 3\n    InterlacedMode           = \"Progressive\"\n    ColorSpaceConversionMode = \"None\"\n  }\n\n  video_watermarks {\n    id                = \"Terraform Test\"\n    max_width         = \"20%\"\n    max_height        = \"20%\"\n    sizing_policy     = \"ShrinkToFit\"\n    horizontal_align  = \"Right\"\n    horizontal_offset = \"10px\"\n    vertical_align    = \"Bottom\"\n    vertical_offset   = \"10px\"\n    opacity           = \"55.5\"\n    target            = \"Content\"\n  }\n\n  thumbnails {\n    format         = \"png\"\n    interval       = 120\n    max_width      = \"auto\"\n    max_height     = \"auto\"\n    padding_policy = \"Pad\"\n    sizing_policy  = \"Fit\"\n  }\n}\n```\n\n## Argument Reference\n\nSee [\"Create Preset\"](http://docs.aws.amazon.com/elastictranscoder/latest/developerguide/create-preset.html) in the AWS docs for reference.\n\nThe following arguments are supported:\n\n* `audio` - (Optional, Forces new resource) Audio parameters object (documented below).\n* `audio_codec_options` - (Optional, Forces new resource) Codec options for the audio parameters (documented below)\n* `container` - (Required, Forces new resource) The container type for the output file. Valid values are `flac`, `flv`, `fmp4`, `gif`, `mp3`, `mp4`, `mpg`, `mxf`, `oga`, `ogg`, `ts`, and `webm`.\n* `description` - (Optional, Forces new resource) A description of the preset (maximum 255 characters)\n* `name` - (Optional, Forces new resource) The name of the preset. (maximum 40 characters)\n* `thumbnails` - (Optional, Forces new resource) Thumbnail parameters object (documented below)\n* `video` - (Optional, Forces new resource) Video parameters object (documented below)\n* `video_watermarks` - (Optional, Forces new resource) Watermark parameters for the video parameters (documented below)\n* `video_codec_options` (Optional, Forces new resource) Codec options for the video parameters\n\nThe `audio` object supports the following:\n\n* `audio_packing_mode` - The method of organizing audio channels and tracks. Use Audio:Channels to specify the number of channels in your output, and Audio:AudioPackingMode to specify the number of tracks and their relation to the channels. If you do not specify an Audio:AudioPackingMode, Elastic Transcoder uses SingleTrack.\n* `bit_rate` - The bit rate of the audio stream in the output file, in kilobits/second. Enter an integer between 64 and 320, inclusive.\n* `channels` - The number of audio channels in the output file\n* `codec` - The audio codec for the output file. Valid values are `AAC`, `flac`, `mp2`, `mp3`, `pcm`, and `vorbis`.\n* `sample_rate` - The sample rate of the audio stream in the output file, in hertz. Valid values are: `auto`, `22050`, `32000`, `44100`, `48000`, `96000`\n\nThe `audio_codec_options` object supports the following:\n\n* `bit_depth` - The bit depth of a sample is how many bits of information are included in the audio samples. Valid values are `16` and `24`. (FLAC/PCM Only)\n* `bit_order` - The order the bits of a PCM sample are stored in. The supported value is LittleEndian. (PCM Only)\n* `profile` - If you specified AAC for Audio:Codec, choose the AAC profile for the output file.\n* `signed` - Whether audio samples are represented with negative and positive numbers (signed) or only positive numbers (unsigned). The supported value is Signed. (PCM Only)\n\nThe `thumbnails` object supports the following:\n\n* `aspect_ratio` - The aspect ratio of thumbnails. The following values are valid: auto, 1:1, 4:3, 3:2, 16:9\n* `format` - The format of thumbnails, if any. Valid formats are jpg and png.\n* `interval` - The approximate number of seconds between thumbnails. The value must be an integer. The actual interval can vary by several seconds from one thumbnail to the next.\n* `max_height` - The maximum height of thumbnails, in pixels. If you specify auto, Elastic Transcoder uses 1080 (Full HD) as the default value. If you specify a numeric value, enter an even integer between 32 and 3072, inclusive.\n* `max_width` - The maximum width of thumbnails, in pixels. If you specify auto, Elastic Transcoder uses 1920 (Full HD) as the default value. If you specify a numeric value, enter an even integer between 32 and 4096, inclusive.\n* `padding_policy` - When you set PaddingPolicy to Pad, Elastic Transcoder might add black bars to the top and bottom and/or left and right sides of thumbnails to make the total size of the thumbnails match the values that you specified for thumbnail MaxWidth and MaxHeight settings.\n* `resolution` - The width and height of thumbnail files in pixels, in the format WidthxHeight, where both values are even integers. The values cannot exceed the width and height that you specified in the Video:Resolution object. (To better control resolution and aspect ratio of thumbnails, we recommend that you use the thumbnail values `max_width`, `max_height`, `sizing_policy`, and `padding_policy` instead of `resolution` and `aspect_ratio`. The two groups of settings are mutually exclusive. Do not use them together)\n* `sizing_policy` - A value that controls scaling of thumbnails. Valid values are: `Fit`, `Fill`, `Stretch`, `Keep`, `ShrinkToFit`, and `ShrinkToFill`.\n\nThe `video` object supports the following:\n\n* `aspect_ratio` - The display aspect ratio of the video in the output file. Valid values are: `auto`, `1:1`, `4:3`, `3:2`, `16:9`. (Note; to better control resolution and aspect ratio of output videos, we recommend that you use the values `max_width`, `max_height`, `sizing_policy`, `padding_policy`, and `display_aspect_ratio` instead of `resolution` and `aspect_ratio`.)\n* `bit_rate` - The bit rate of the video stream in the output file, in kilobits/second. You can configure variable bit rate or constant bit rate encoding.\n* `codec` - The video codec for the output file. Valid values are `gif`, `H.264`, `mpeg2`, `vp8`, and `vp9`.\n* `display_aspect_ratio` - The value that Elastic Transcoder adds to the metadata in the output file. If you set DisplayAspectRatio to auto, Elastic Transcoder chooses an aspect ratio that ensures square pixels. If you specify another option, Elastic Transcoder sets that value in the output file.\n* `fixed_gop` - Whether to use a fixed value for Video:FixedGOP. Not applicable for containers of type gif. Valid values are true and false. Also known as, Fixed Number of Frames Between Keyframes.\n* `frame_rate` - The frames per second for the video stream in the output file. The following values are valid: `auto`, `10`, `15`, `23.97`, `24`, `25`, `29.97`, `30`, `50`, `60`.\n* `keyframes_max_dist` - The maximum number of frames between key frames. Not applicable for containers of type gif.\n* `max_frame_rate` - If you specify auto for FrameRate, Elastic Transcoder uses the frame rate of the input video for the frame rate of the output video, up to the maximum frame rate. If you do not specify a MaxFrameRate, Elastic Transcoder will use a default of 30.\n* `max_height` - The maximum height of the output video in pixels. If you specify auto, Elastic Transcoder uses 1080 (Full HD) as the default value. If you specify a numeric value, enter an even integer between 96 and 3072, inclusive.\n* `max_width` - The maximum width of the output video in pixels. If you specify auto, Elastic Transcoder uses 1920 (Full HD) as the default value. If you specify a numeric value, enter an even integer between 128 and 4096, inclusive.\n* `padding_policy` - When you set PaddingPolicy to Pad, Elastic Transcoder might add black bars to the top and bottom and/or left and right sides of the output video to make the total size of the output video match the values that you specified for `max_width` and `max_height`.\n* `resolution` - The width and height of the video in the output file, in pixels. Valid values are `auto` and `widthxheight`. (see note for `aspect_ratio`)\n* `sizing_policy` - A value that controls scaling of the output video. Valid values are: `Fit`, `Fill`, `Stretch`, `Keep`, `ShrinkToFit`, `ShrinkToFill`.\n\nThe `video_watermarks` object supports the following:\n\n* `horizontal_align` - The horizontal position of the watermark unless you specify a nonzero value for `horzontal_offset`.\n* `horizontal_offset` - The amount by which you want the horizontal position of the watermark to be offset from the position specified by `horizontal_align`.\n* `id` - A unique identifier for the settings for one watermark. The value of Id can be up to 40 characters long. You can specify settings for up to four watermarks.\n* `max_height` - The maximum height of the watermark.\n* `max_width` - The maximum width of the watermark.\n* `opacity` - A percentage that indicates how much you want a watermark to obscure the video in the location where it appears.\n* `sizing_policy` - A value that controls scaling of the watermark. Valid values are: `Fit`, `Stretch`, `ShrinkToFit`\n* `target` - A value that determines how Elastic Transcoder interprets values that you specified for `video_watermarks.horizontal_offset`, `video_watermarks.vertical_offset`, `video_watermarks.max_width`, and `video_watermarks.max_height`. Valid values are `Content` and `Frame`.\n* `vertical_align` - The vertical position of the watermark unless you specify a nonzero value for `vertical_align`. Valid values are `Top`, `Bottom`, `Center`.\n* `vertical_offset` - The amount by which you want the vertical position of the watermark to be offset from the position specified by `vertical_align`\n\nThe `video_codec_options` map supports the following:\n\n* `Profile` - The codec profile that you want to use for the output file. (H.264/VP8 Only)\n* `Level` - The H.264 level that you want to use for the output file. Elastic Transcoder supports the following levels: `1`, `1b`, `1.1`, `1.2`, `1.3`, `2`, `2.1`, `2.2`, `3`, `3.1`, `3.2`, `4`, `4.1` (H.264 only)\n* `MaxReferenceFrames` - The maximum number of previously decoded frames to use as a reference for decoding future frames. Valid values are integers 0 through 16. (H.264 only)\n* `MaxBitRate` - The maximum number of kilobits per second in the output video. Specify a value between 16 and 62,500 inclusive, or `auto`. (Optional, H.264/MPEG2/VP8/VP9 only)\n* `BufferSize` - The maximum number of kilobits in any x seconds of the output video. This window is commonly 10 seconds, the standard segment duration when you're using ts for the container type of the output video. Specify an integer greater than 0. If you specify MaxBitRate and omit BufferSize, Elastic Transcoder sets BufferSize to 10 times the value of MaxBitRate. (Optional, H.264/MPEG2/VP8/VP9 only)\n* `InterlacedMode` -  The interlace mode for the output video. (Optional, H.264/MPEG2 Only)\n* `ColorSpaceConversion` - The color space conversion Elastic Transcoder applies to the output video. Valid values are `None`, `Bt709toBt601`, `Bt601toBt709`, and `Auto`. (Optional, H.264/MPEG2 Only)\n* `ChromaSubsampling` - The sampling pattern for the chroma (color) channels of the output video. Valid values are `yuv420p` and `yuv422p`.\n* `LoopCount` - The number of times you want the output gif to loop (Gif only)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the Elastic Transcoder Preset.\n\n## Import\n\nElastic Transcoder presets can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_elastictranscoder_preset.basic_preset 1407981661351-cttk8b\n```\n",
    "basename": "elastictranscoder_preset.html"
  },
  "elb.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_elb",
    "description": "Provides an Elastic Load Balancer resource.",
    "preview": "# Resource: aws_elb\n\nProvides an Elastic Load Balancer resource, …",
    "content": "\n\n# Resource: aws_elb\n\nProvides an Elastic Load Balancer resource, also known as a \"Classic\nLoad Balancer\" after the release of\n[Application/Network Load Balancers](/docs/providers/aws/r/lb.html).\n\n~> **NOTE on ELB Instances and ELB Attachments:** Terraform currently\nprovides both a standalone [ELB Attachment resource](elb_attachment.html)\n(describing an instance attached to an ELB), and an ELB resource with\n`instances` defined in-line. At this time you cannot use an ELB with in-line\ninstances in conjunction with a ELB Attachment resources. Doing so will cause a\nconflict and will overwrite attachments.\n\n## Example Usage\n\n```terraform\n# Create a new load balancer\nresource \"aws_elb\" \"bar\" {\n  name               = \"foobar-terraform-elb\"\n  availability_zones = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n\n  access_logs {\n    bucket        = \"foo\"\n    bucket_prefix = \"bar\"\n    interval      = 60\n  }\n\n  listener {\n    instance_port     = 8000\n    instance_protocol = \"http\"\n    lb_port           = 80\n    lb_protocol       = \"http\"\n  }\n\n  listener {\n    instance_port      = 8000\n    instance_protocol  = \"http\"\n    lb_port            = 443\n    lb_protocol        = \"https\"\n    ssl_certificate_id = \"arn:aws:iam::123456789012:server-certificate/certName\"\n  }\n\n  health_check {\n    healthy_threshold   = 2\n    unhealthy_threshold = 2\n    timeout             = 3\n    target              = \"HTTP:8000/\"\n    interval            = 30\n  }\n\n  instances                   = [aws_instance.foo.id]\n  cross_zone_load_balancing   = true\n  idle_timeout                = 400\n  connection_draining         = true\n  connection_draining_timeout = 400\n\n  tags = {\n    Name = \"foobar-terraform-elb\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the ELB. By default generated by Terraform.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified\n  prefix. Conflicts with `name`.\n* `access_logs` - (Optional) An Access Logs block. Access Logs documented below.\n* `availability_zones` - (Required for an EC2-classic ELB) The AZ's to serve traffic in.\n* `security_groups` - (Optional) A list of security group IDs to assign to the ELB.\n  Only valid if creating an ELB within a VPC\n* `subnets` - (Required for a VPC ELB) A list of subnet IDs to attach to the ELB.\n* `instances` - (Optional) A list of instance ids to place in the ELB pool.\n* `internal` - (Optional) If true, ELB will be an internal ELB.\n* `listener` - (Required) A list of listener blocks. Listeners documented below.\n* `health_check` - (Optional) A health_check block. Health Check documented below.\n* `cross_zone_load_balancing` - (Optional) Enable cross-zone load balancing. Default: `true`\n* `idle_timeout` - (Optional) The time in seconds that the connection is allowed to be idle. Default: `60`\n* `connection_draining` - (Optional) Boolean to enable connection draining. Default: `false`\n* `connection_draining_timeout` - (Optional) The time in seconds to allow for connections to drain. Default: `300`\n* `desync_mitigation_mode` - (Optional) Determines how the load balancer handles requests that might pose a security risk to an application due to HTTP desync. Valid values are `monitor`, `defensive` (default), `strictest`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nExactly one of `availability_zones` or `subnets` must be specified: this\ndetermines if the ELB exists in a VPC or in EC2-classic.\n\nAccess Logs (`access_logs`) support the following:\n\n* `bucket` - (Required) The S3 bucket name to store the logs in.\n* `bucket_prefix` - (Optional) The S3 bucket prefix. Logs are stored in the root if not configured.\n* `interval` - (Optional) The publishing interval in minutes. Default: 60 minutes.\n* `enabled` - (Optional) Boolean to enable / disable `access_logs`. Default is `true`\n\nListeners (`listener`) support the following:\n\n* `instance_port` - (Required) The port on the instance to route to\n* `instance_protocol` - (Required) The protocol to use to the instance. Valid\n  values are `HTTP`, `HTTPS`, `TCP`, or `SSL`\n* `lb_port` - (Required) The port to listen on for the load balancer\n* `lb_protocol` - (Required) The protocol to listen on. Valid values are `HTTP`,\n  `HTTPS`, `TCP`, or `SSL`\n* `ssl_certificate_id` - (Optional) The ARN of an SSL certificate you have\nuploaded to AWS IAM. **Note ECDSA-specific restrictions below.  Only valid when `lb_protocol` is either HTTPS or SSL**\n\nHealth Check (`health_check`) supports the following:\n\n* `healthy_threshold` - (Required) The number of checks before the instance is declared healthy.\n* `unhealthy_threshold` - (Required) The number of checks before the instance is declared unhealthy.\n* `target` - (Required) The target of the check. Valid pattern is \"${PROTOCOL}:${PORT}${PATH}\", where PROTOCOL\n  values are:\n    * `HTTP`, `HTTPS` - PORT and PATH are required\n    * `TCP`, `SSL` - PORT is required, PATH is not supported\n* `interval` - (Required) The interval between checks.\n* `timeout` - (Required) The length of time before the check times out.\n\n## Note on ECDSA Key Algorithm\n\nIf the ARN of the `ssl_certificate_id` that is pointed to references a\ncertificate that was signed by an ECDSA key, note that ELB only supports the\nP256 and P384 curves.  Using a certificate signed by a key using a different\ncurve could produce the error `ERR_SSL_VERSION_OR_CIPHER_MISMATCH` in your\nbrowser.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the ELB\n* `arn` - The ARN of the ELB\n* `name` - The name of the ELB\n* `dns_name` - The DNS name of the ELB\n* `instances` - The list of instances in the ELB\n* `source_security_group` - The name of the security group that you can use as\n  part of your inbound rules for your load balancer's back-end application\n  instances. Use this for Classic or Default VPC only.\n* `source_security_group_id` - The ID of the security group that you can use as\n  part of your inbound rules for your load balancer's back-end application\n  instances. Only available on ELBs launched in a VPC.\n* `zone_id` - The canonical hosted zone ID of the ELB (to be used in a Route 53 Alias record)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nELBs can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_elb.bar elb-production-12345\n```\n",
    "basename": "elb.html"
  },
  "elb_attachment.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_elb_attachment",
    "description": "Provides an Elastic Load Balancer Attachment resource.",
    "preview": "# Resource: aws_elb_attachment\n\nAttaches an EC2 instance to an …",
    "content": "\n\n# Resource: aws_elb_attachment\n\nAttaches an EC2 instance to an Elastic Load Balancer (ELB). For attaching resources with Application Load Balancer (ALB) or Network Load Balancer (NLB), see the [`aws_lb_target_group_attachment` resource](/docs/providers/aws/r/lb_target_group_attachment.html).\n\n~> **NOTE on ELB Instances and ELB Attachments:** Terraform currently provides\nboth a standalone ELB Attachment resource (describing an instance attached to\nan ELB), and an [Elastic Load Balancer resource](elb.html) with\n`instances` defined in-line. At this time you cannot use an ELB with in-line\ninstances in conjunction with an ELB Attachment resource. Doing so will cause a\nconflict and will overwrite attachments.\n\n## Example Usage\n\n```terraform\n# Create a new load balancer attachment\nresource \"aws_elb_attachment\" \"baz\" {\n  elb      = aws_elb.bar.id\n  instance = aws_instance.foo.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `elb` - (Required) The name of the ELB.\n* `instance` - (Required) Instance ID to place in the ELB pool.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "elb_attachment.html"
  },
  "emr_cluster.html": {
    "subcategory": "Elastic Map Reduce (EMR)",
    "layout": "aws",
    "page_title": "AWS: aws_emr_cluster",
    "description": "Provides an Elastic MapReduce Cluster",
    "preview": "# Resource: aws_emr_cluster\n\nProvides an Elastic MapReduce Cluster, …",
    "content": "\n\n# Resource: aws_emr_cluster\n\nProvides an Elastic MapReduce Cluster, a web service that makes it easy to process large amounts of data efficiently. See [Amazon Elastic MapReduce Documentation](https://aws.amazon.com/documentation/elastic-mapreduce/) for more information.\n\nTo configure [Instance Groups](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-group-configuration.html#emr-plan-instance-groups) for [task nodes](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html#emr-plan-task), see the [`aws_emr_instance_group` resource](/docs/providers/aws/r/emr_instance_group.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_emr_cluster\" \"cluster\" {\n  name          = \"emr-test-arn\"\n  release_label = \"emr-4.6.0\"\n  applications  = [\"Spark\"]\n\n  additional_info = <<EOF\n{\n  \"instanceAwsClientConfiguration\": {\n    \"proxyPort\": 8099,\n    \"proxyHost\": \"myproxy.example.com\"\n  }\n}\nEOF\n\n  termination_protection            = false\n  keep_job_flow_alive_when_no_steps = true\n\n  ec2_attributes {\n    subnet_id                         = aws_subnet.main.id\n    emr_managed_master_security_group = aws_security_group.sg.id\n    emr_managed_slave_security_group  = aws_security_group.sg.id\n    instance_profile                  = aws_iam_instance_profile.emr_profile.arn\n  }\n\n  master_instance_group {\n    instance_type = \"m4.large\"\n  }\n\n  core_instance_group {\n    instance_type  = \"c4.large\"\n    instance_count = 1\n\n    ebs_config {\n      size                 = \"40\"\n      type                 = \"gp2\"\n      volumes_per_instance = 1\n    }\n\n    bid_price = \"0.30\"\n\n    autoscaling_policy = <<EOF\n{\n\"Constraints\": {\n  \"MinCapacity\": 1,\n  \"MaxCapacity\": 2\n},\n\"Rules\": [\n  {\n    \"Name\": \"ScaleOutMemoryPercentage\",\n    \"Description\": \"Scale out if YARNMemoryAvailablePercentage is less than 15\",\n    \"Action\": {\n      \"SimpleScalingPolicyConfiguration\": {\n        \"AdjustmentType\": \"CHANGE_IN_CAPACITY\",\n        \"ScalingAdjustment\": 1,\n        \"CoolDown\": 300\n      }\n    },\n    \"Trigger\": {\n      \"CloudWatchAlarmDefinition\": {\n        \"ComparisonOperator\": \"LESS_THAN\",\n        \"EvaluationPeriods\": 1,\n        \"MetricName\": \"YARNMemoryAvailablePercentage\",\n        \"Namespace\": \"AWS/ElasticMapReduce\",\n        \"Period\": 300,\n        \"Statistic\": \"AVERAGE\",\n        \"Threshold\": 15.0,\n        \"Unit\": \"PERCENT\"\n      }\n    }\n  }\n]\n}\nEOF\n  }\n\n  ebs_root_volume_size = 100\n\n  tags = {\n    role = \"rolename\"\n    env  = \"env\"\n  }\n\n  bootstrap_action {\n    path = \"s3://elasticmapreduce/bootstrap-actions/run-if\"\n    name = \"runif\"\n    args = [\"instance.isMaster=true\", \"echo running on master node\"]\n  }\n\n  configurations_json = <<EOF\n  [\n    {\n      \"Classification\": \"hadoop-env\",\n      \"Configurations\": [\n        {\n          \"Classification\": \"export\",\n          \"Properties\": {\n            \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n          }\n        }\n      ],\n      \"Properties\": {}\n    },\n    {\n      \"Classification\": \"spark-env\",\n      \"Configurations\": [\n        {\n          \"Classification\": \"export\",\n          \"Properties\": {\n            \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n          }\n        }\n      ],\n      \"Properties\": {}\n    }\n  ]\nEOF\n\n  service_role = aws_iam_role.iam_emr_service_role.arn\n}\n```\n\nThe `aws_emr_cluster` resource typically requires two IAM roles, one for the EMR Cluster to use as a service, and another to place on your Cluster Instances to interact with AWS from those instances. The suggested role policy template for the EMR service is `AmazonElasticMapReduceRole`, and `AmazonElasticMapReduceforEC2Role` for the EC2 profile. See the [Getting Started](https://docs.aws.amazon.com/ElasticMapReduce/latest/ManagementGuide/emr-gs-launch-sample-cluster.html) guide for more information on these IAM roles. There is also a fully-bootable example Terraform configuration at the bottom of this page.\n\n### Instance Fleet\n\n```terraform\nresource \"aws_emr_cluster\" \"example\" {\n  # ... other configuration ...\n  master_instance_fleet {\n    instance_type_configs {\n      instance_type = \"m4.xlarge\"\n    }\n    target_on_demand_capacity = 1\n  }\n  core_instance_fleet {\n    instance_type_configs {\n      bid_price_as_percentage_of_on_demand_price = 80\n      ebs_config {\n        size                 = 100\n        type                 = \"gp2\"\n        volumes_per_instance = 1\n      }\n      instance_type     = \"m3.xlarge\"\n      weighted_capacity = 1\n    }\n    instance_type_configs {\n      bid_price_as_percentage_of_on_demand_price = 100\n      ebs_config {\n        size                 = 100\n        type                 = \"gp2\"\n        volumes_per_instance = 1\n      }\n      instance_type     = \"m4.xlarge\"\n      weighted_capacity = 1\n    }\n    instance_type_configs {\n      bid_price_as_percentage_of_on_demand_price = 100\n      ebs_config {\n        size                 = 100\n        type                 = \"gp2\"\n        volumes_per_instance = 1\n      }\n      instance_type     = \"m4.2xlarge\"\n      weighted_capacity = 2\n    }\n    launch_specifications {\n      spot_specification {\n        allocation_strategy      = \"capacity-optimized\"\n        block_duration_minutes   = 0\n        timeout_action           = \"SWITCH_TO_ON_DEMAND\"\n        timeout_duration_minutes = 10\n      }\n    }\n    name                      = \"core fleet\"\n    target_on_demand_capacity = 2\n    target_spot_capacity      = 2\n  }\n}\n\nresource \"aws_emr_instance_fleet\" \"task\" {\n  cluster_id = aws_emr_cluster.example.id\n  instance_type_configs {\n    bid_price_as_percentage_of_on_demand_price = 100\n    ebs_config {\n      size                 = 100\n      type                 = \"gp2\"\n      volumes_per_instance = 1\n    }\n    instance_type     = \"m4.xlarge\"\n    weighted_capacity = 1\n  }\n  instance_type_configs {\n    bid_price_as_percentage_of_on_demand_price = 100\n    ebs_config {\n      size                 = 100\n      type                 = \"gp2\"\n      volumes_per_instance = 1\n    }\n    instance_type     = \"m4.2xlarge\"\n    weighted_capacity = 2\n  }\n  launch_specifications {\n    spot_specification {\n      allocation_strategy      = \"capacity-optimized\"\n      block_duration_minutes   = 0\n      timeout_action           = \"TERMINATE_CLUSTER\"\n      timeout_duration_minutes = 10\n    }\n  }\n  name                      = \"task fleet\"\n  target_on_demand_capacity = 1\n  target_spot_capacity      = 1\n}\n```\n\n### Enable Debug Logging\n\n[Debug logging in EMR](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-debugging.html) is implemented as a step. It is highly recommended that you utilize the [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` if other steps are being managed outside of Terraform.\n\n```terraform\nresource \"aws_emr_cluster\" \"example\" {\n  # ... other configuration ...\n\n  step {\n    action_on_failure = \"TERMINATE_CLUSTER\"\n    name              = \"Setup Hadoop Debugging\"\n\n    hadoop_jar_step {\n      jar  = \"command-runner.jar\"\n      args = [\"state-pusher-script\"]\n    }\n  }\n\n  # Optional: ignore outside changes to running cluster steps\n  lifecycle {\n    ignore_changes = [step]\n  }\n}\n```\n\n### Multiple Node Master Instance Group\n\nAvailable in EMR version 5.23.0 and later, an EMR Cluster can be launched with three master nodes for high availability. Additional information about this functionality and its requirements can be found in the [EMR Management Guide](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-ha.html).\n\n```terraform\n# This configuration is for illustrative purposes and highlights\n# only relevant configurations for working with this functionality.\n\n# Map public IP on launch must be enabled for public (Internet accessible) subnets\nresource \"aws_subnet\" \"example\" {\n  # ... other configuration ...\n\n  map_public_ip_on_launch = true\n}\n\nresource \"aws_emr_cluster\" \"example\" {\n  # ... other configuration ...\n\n  # EMR version must be 5.23.0 or later\n  release_label = \"emr-5.24.1\"\n\n  # Termination protection is automatically enabled for multiple masters\n  # To destroy the cluster, this must be configured to false and applied first\n  termination_protection = true\n\n  ec2_attributes {\n    # ... other configuration ...\n\n    subnet_id = aws_subnet.example.id\n  }\n\n  master_instance_group {\n    # ... other configuration ...\n\n    # Master instance count must be set to 3\n    instance_count = 3\n  }\n\n  # core_instance_group must be configured\n  core_instance_group {\n    # ... other configuration ...\n  }\n}\n```\n\n### Bootable Cluster\n\n**NOTE:** This configuration demonstrates a minimal configuration needed to boot an example EMR Cluster. It is not meant to display best practices. As with all examples, use at your own risk.\n\n```terraform\nresource \"aws_emr_cluster\" \"cluster\" {\n  name          = \"emr-test-arn\"\n  release_label = \"emr-4.6.0\"\n  applications  = [\"Spark\"]\n\n  ec2_attributes {\n    subnet_id                         = aws_subnet.main.id\n    emr_managed_master_security_group = aws_security_group.allow_all.id\n    emr_managed_slave_security_group  = aws_security_group.allow_all.id\n    instance_profile                  = aws_iam_instance_profile.emr_profile.arn\n  }\n\n  master_instance_group {\n    instance_type = \"m5.xlarge\"\n  }\n\n  core_instance_group {\n    instance_count = 1\n    instance_type  = \"m5.xlarge\"\n  }\n\n  tags = {\n    role     = \"rolename\"\n    dns_zone = \"env_zone\"\n    env      = \"env\"\n    name     = \"name-env\"\n  }\n\n  bootstrap_action {\n    path = \"s3://elasticmapreduce/bootstrap-actions/run-if\"\n    name = \"runif\"\n    args = [\"instance.isMaster=true\", \"echo running on master node\"]\n  }\n\n  configurations_json = <<EOF\n  [\n    {\n      \"Classification\": \"hadoop-env\",\n      \"Configurations\": [\n        {\n          \"Classification\": \"export\",\n          \"Properties\": {\n            \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n          }\n        }\n      ],\n      \"Properties\": {}\n    },\n    {\n      \"Classification\": \"spark-env\",\n      \"Configurations\": [\n        {\n          \"Classification\": \"export\",\n          \"Properties\": {\n            \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n          }\n        }\n      ],\n      \"Properties\": {}\n    }\n  ]\nEOF\n\n  service_role = aws_iam_role.iam_emr_service_role.arn\n}\n\nresource \"aws_security_group\" \"allow_access\" {\n  name        = \"allow_access\"\n  description = \"Allow inbound traffic\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = aws_vpc.main.cidr_block\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  depends_on = [aws_subnet.main]\n\n  lifecycle {\n    ignore_changes = [\n      ingress,\n      egress,\n    ]\n  }\n\n  tags = {\n    name = \"emr_test\"\n  }\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = \"168.31.0.0/16\"\n  enable_dns_hostnames = true\n\n  tags = {\n    name = \"emr_test\"\n  }\n}\n\nresource \"aws_subnet\" \"main\" {\n  vpc_id     = aws_vpc.main.id\n  cidr_block = \"168.31.0.0/20\"\n\n  tags = {\n    name = \"emr_test\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"gw\" {\n  vpc_id = aws_vpc.main.id\n}\n\nresource \"aws_route_table\" \"r\" {\n  vpc_id = aws_vpc.main.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.gw.id\n  }\n}\n\nresource \"aws_main_route_table_association\" \"a\" {\n  vpc_id         = aws_vpc.main.id\n  route_table_id = aws_route_table.r.id\n}\n\n###\n\n# IAM Role setups\n\n###\n\n# IAM role for EMR Service\nresource \"aws_iam_role\" \"iam_emr_service_role\" {\n  name = \"iam_emr_service_role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2008-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"elasticmapreduce.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"iam_emr_service_policy\" {\n  name = \"iam_emr_service_policy\"\n  role = aws_iam_role.iam_emr_service_role.id\n\n  policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Resource\": \"*\",\n        \"Action\": [\n            \"ec2:AuthorizeSecurityGroupEgress\",\n            \"ec2:AuthorizeSecurityGroupIngress\",\n            \"ec2:CancelSpotInstanceRequests\",\n            \"ec2:CreateNetworkInterface\",\n            \"ec2:CreateSecurityGroup\",\n            \"ec2:CreateTags\",\n            \"ec2:DeleteNetworkInterface\",\n            \"ec2:DeleteSecurityGroup\",\n            \"ec2:DeleteTags\",\n            \"ec2:DescribeAvailabilityZones\",\n            \"ec2:DescribeAccountAttributes\",\n            \"ec2:DescribeDhcpOptions\",\n            \"ec2:DescribeInstanceStatus\",\n            \"ec2:DescribeInstances\",\n            \"ec2:DescribeKeyPairs\",\n            \"ec2:DescribeNetworkAcls\",\n            \"ec2:DescribeNetworkInterfaces\",\n            \"ec2:DescribePrefixLists\",\n            \"ec2:DescribeRouteTables\",\n            \"ec2:DescribeSecurityGroups\",\n            \"ec2:DescribeSpotInstanceRequests\",\n            \"ec2:DescribeSpotPriceHistory\",\n            \"ec2:DescribeSubnets\",\n            \"ec2:DescribeVpcAttribute\",\n            \"ec2:DescribeVpcEndpoints\",\n            \"ec2:DescribeVpcEndpointServices\",\n            \"ec2:DescribeVpcs\",\n            \"ec2:DetachNetworkInterface\",\n            \"ec2:ModifyImageAttribute\",\n            \"ec2:ModifyInstanceAttribute\",\n            \"ec2:RequestSpotInstances\",\n            \"ec2:RevokeSecurityGroupEgress\",\n            \"ec2:RunInstances\",\n            \"ec2:TerminateInstances\",\n            \"ec2:DeleteVolume\",\n            \"ec2:DescribeVolumeStatus\",\n            \"ec2:DescribeVolumes\",\n            \"ec2:DetachVolume\",\n            \"iam:GetRole\",\n            \"iam:GetRolePolicy\",\n            \"iam:ListInstanceProfiles\",\n            \"iam:ListRolePolicies\",\n            \"iam:PassRole\",\n            \"s3:CreateBucket\",\n            \"s3:Get*\",\n            \"s3:List*\",\n            \"sdb:BatchPutAttributes\",\n            \"sdb:Select\",\n            \"sqs:CreateQueue\",\n            \"sqs:Delete*\",\n            \"sqs:GetQueue*\",\n            \"sqs:PurgeQueue\",\n            \"sqs:ReceiveMessage\"\n        ]\n    }]\n}\nEOF\n}\n\n# IAM Role for EC2 Instance Profile\nresource \"aws_iam_role\" \"iam_emr_profile_role\" {\n  name = \"iam_emr_profile_role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2008-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_instance_profile\" \"emr_profile\" {\n  name = \"emr_profile\"\n  role = aws_iam_role.iam_emr_profile_role.name\n}\n\nresource \"aws_iam_role_policy\" \"iam_emr_profile_policy\" {\n  name = \"iam_emr_profile_policy\"\n  role = aws_iam_role.iam_emr_profile_role.id\n\n  policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Resource\": \"*\",\n        \"Action\": [\n            \"cloudwatch:*\",\n            \"dynamodb:*\",\n            \"ec2:Describe*\",\n            \"elasticmapreduce:Describe*\",\n            \"elasticmapreduce:ListBootstrapActions\",\n            \"elasticmapreduce:ListClusters\",\n            \"elasticmapreduce:ListInstanceGroups\",\n            \"elasticmapreduce:ListInstances\",\n            \"elasticmapreduce:ListSteps\",\n            \"kinesis:CreateStream\",\n            \"kinesis:DeleteStream\",\n            \"kinesis:DescribeStream\",\n            \"kinesis:GetRecords\",\n            \"kinesis:GetShardIterator\",\n            \"kinesis:MergeShards\",\n            \"kinesis:PutRecord\",\n            \"kinesis:SplitShard\",\n            \"rds:Describe*\",\n            \"s3:*\",\n            \"sdb:*\",\n            \"sns:*\",\n            \"sqs:*\"\n        ]\n    }]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the job flow.\n* `release_label` - (Required) Release label for the Amazon EMR release.\n* `service_role` - (Required) IAM role that will be assumed by the Amazon EMR service to access AWS resources.\n\nThe following arguments are optional:\n\n* `additional_info` - (Optional) JSON string for selecting additional features such as adding proxy information. Note: Currently there is no API to retrieve the value of this argument after EMR cluster creation from provider, therefore Terraform cannot detect drift from the actual EMR cluster if its value is changed outside Terraform.\n* `applications` - (Optional) List of applications for the cluster. Valid values are: `Flink`, `Hadoop`, `Hive`, `Mahout`, `Pig`, `Spark`, and `JupyterHub` (as of EMR 5.14.0). Case insensitive.\n* `autoscaling_role` - (Optional) IAM role for automatic scaling policies. The IAM role provides permissions that the automatic scaling feature requires to launch and terminate EC2 instances in an instance group.\n* `auto_termination_policy` - (Optional) An auto-termination policy for an Amazon EMR cluster. An auto-termination policy defines the amount of idle time in seconds after which a cluster automatically terminates. See [Auto Termination Policy](#auto_termination_policy) Below.\n* `bootstrap_action` - (Optional) Ordered list of bootstrap actions that will be run before Hadoop is started on the cluster nodes. See below.\n* `configurations` - (Optional) List of configurations supplied for the EMR cluster you are creating. Supply a configuration object for applications to override their default configuration. See [AWS Documentation](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-configure-apps.html) for more information.\n* `configurations_json` - (Optional) JSON string for supplying list of configurations for the EMR cluster.\n\n~> **NOTE on `configurations_json`:** If the `Configurations` value is empty then you should skip the `Configurations` field instead of providing an empty list as a value, `\"Configurations\": []`.\n\n```terraform\nresource \"aws_emr_cluster\" \"cluster\" {\n  # ... other configuration ...\n\n  configurations_json = <<EOF\n  [\n    {\n      \"Classification\": \"hadoop-env\",\n      \"Configurations\": [\n        {\n          \"Classification\": \"export\",\n          \"Properties\": {\n            \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n          }\n        }\n      ],\n      \"Properties\": {}\n    }\n  ]\nEOF\n}\n```\n\n* `core_instance_fleet` - (Optional) Configuration block to use an [Instance Fleet](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-fleet.html) for the core node type. Cannot be specified if any `core_instance_group` configuration blocks are set. Detailed below.\n* `core_instance_group` - (Optional) Configuration block to use an [Instance Group](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-group-configuration.html#emr-plan-instance-groups) for the [core node type](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html#emr-plan-core).\n* `custom_ami_id` - (Optional) Custom Amazon Linux AMI for the cluster (instead of an EMR-owned AMI). Available in Amazon EMR version 5.7.0 and later.\n* `ebs_root_volume_size` - (Optional) Size in GiB of the EBS root device volume of the Linux AMI that is used for each EC2 instance. Available in Amazon EMR version 4.x and later.\n* `ec2_attributes` - (Optional) Attributes for the EC2 instances running the job flow. See below.\n* `keep_job_flow_alive_when_no_steps` - (Optional) Switch on/off run cluster with no steps or when all steps are complete (default is on)\n* `kerberos_attributes` - (Optional) Kerberos configuration for the cluster. See below.\n* `log_encryption_kms_key_id` - (Optional) AWS KMS customer master key (CMK) key ID or arn used for encrypting log files. This attribute is only available with EMR version 5.30.0 and later, excluding EMR 6.0.0.  \n* `log_uri` - (Optional) S3 bucket to write the log files of the job flow. If a value is not provided, logs are not created.\n* `master_instance_fleet` - (Optional) Configuration block to use an [Instance Fleet](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-fleet.html) for the master node type. Cannot be specified if any `master_instance_group` configuration blocks are set. Detailed below.\n* `master_instance_group` - (Optional) Configuration block to use an [Instance Group](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-group-configuration.html#emr-plan-instance-groups) for the [master node type](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html#emr-plan-master).\n* `scale_down_behavior` - (Optional) Way that individual Amazon EC2 instances terminate when an automatic scale-in activity occurs or an `instance group` is resized.\n* `security_configuration` - (Optional) Security configuration name to attach to the EMR cluster. Only valid for EMR clusters with `release_label` 4.8.0 or greater.\n* `step` - (Optional) List of steps to run when creating the cluster. See below. It is highly recommended to utilize the [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` if other steps are being managed outside of Terraform. This argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n* `step_concurrency_level` - (Optional) Number of steps that can be executed concurrently. You can specify a maximum of 256 steps. Only valid for EMR clusters with `release_label` 5.28.0 or greater (default is 1).\n* `tags` - (Optional) list of tags to apply to the EMR Cluster. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `termination_protection` - (Optional) Switch on/off termination protection (default is `false`, except when using multiple master nodes). Before attempting to destroy the resource when termination protection is enabled, this configuration must be applied with its value set to `false`.\n* `visible_to_all_users` - (Optional) Whether the job flow is visible to all IAM users of the AWS account associated with the job flow. Default value is `true`.\n\n### auto_termination_policy\n\n* `args` - (Optional) List of command line arguments to pass to the bootstrap action script.\n* `name` - (Required) Name of the bootstrap action.\n* `path` - (Required) Location of the script to run during a bootstrap action. Can be either a location in Amazon S3 or on a local file system.\n\n### bootstrap_action\n\n* `idle_timeout` - (Optional) Specifies the amount of idle time in seconds after which the cluster automatically terminates. You can specify a minimum of `60` seconds and a maximum of `604800` seconds (seven days).\n\n### configurations\n\nA configuration classification that applies when provisioning cluster instances, which can include configurations for applications and software that run on the cluster. See [Configuring Applications](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-configure-apps.html).\n\n* `classification` - (Optional) Classification within a configuration.\n* `properties` - (Optional) Map of properties specified within a configuration classification.\n\n### core_instance_fleet\n\n* `instance_type_configs` - (Optional) Configuration block for instance fleet.\n* `launch_specifications` - (Optional) Configuration block for launch specification.\n* `name` - (Optional) Friendly name given to the instance fleet.\n* `target_on_demand_capacity` - (Optional)  The target capacity of On-Demand units for the instance fleet, which determines how many On-Demand instances to provision.\n* `target_spot_capacity` - (Optional) Target capacity of Spot units for the instance fleet, which determines how many Spot instances to provision.\n\n#### instance_type_configs\n\n* `bid_price` - (Optional) Bid price for each EC2 Spot instance type as defined by `instance_type`. Expressed in USD. If neither `bid_price` nor `bid_price_as_percentage_of_on_demand_price` is provided, `bid_price_as_percentage_of_on_demand_price` defaults to 100%.\n* `bid_price_as_percentage_of_on_demand_price` - (Optional) Bid price, as a percentage of On-Demand price, for each EC2 Spot instance as defined by `instance_type`. Expressed as a number (for example, 20 specifies 20%). If neither `bid_price` nor `bid_price_as_percentage_of_on_demand_price` is provided, `bid_price_as_percentage_of_on_demand_price` defaults to 100%.\n* `configurations` - (Optional) Configuration classification that applies when provisioning cluster instances, which can include configurations for applications and software that run on the cluster. List of `configuration` blocks.\n* `ebs_config` - (Optional) Configuration block(s) for EBS volumes attached to each instance in the instance group. Detailed below.\n* `instance_type` - (Required) EC2 instance type, such as m4.xlarge.\n* `weighted_capacity` - (Optional) Number of units that a provisioned instance of this type provides toward fulfilling the target capacities defined in `aws_emr_instance_fleet`.\n\n#### launch_specifications\n\n* `on_demand_specification` - (Optional) Configuration block for on demand instances launch specifications.\n* `spot_specification` - (Optional) Configuration block for spot instances launch specifications.\n\n##### on_demand_specification\n\nThe launch specification for On-Demand instances in the instance fleet, which determines the allocation strategy.\nThe instance fleet configuration is available only in Amazon EMR versions 4.8.0 and later, excluding 5.0.x versions. On-Demand instances allocation strategy is available in Amazon EMR version 5.12.1 and later.\n\n* `allocation_strategy` - (Required) Specifies the strategy to use in launching On-Demand instance fleets. Currently, the only option is `lowest-price` (the default), which launches the lowest price first.\n\n##### spot_specification\n\nThe launch specification for Spot instances in the fleet, which determines the defined duration, provisioning timeout behavior, and allocation strategy.\n\n* `allocation_strategy` - (Required) Specifies the strategy to use in launching Spot instance fleets. Currently, the only option is `capacity-optimized` (the default), which launches instances from Spot instance pools with optimal capacity for the number of instances that are launching.\n* `block_duration_minutes` - (Optional) Defined duration for Spot instances (also known as Spot blocks) in minutes. When specified, the Spot instance does not terminate before the defined duration expires, and defined duration pricing for Spot instances applies. Valid values are 60, 120, 180, 240, 300, or 360. The duration period starts as soon as a Spot instance receives its instance ID. At the end of the duration, Amazon EC2 marks the Spot instance for termination and provides a Spot instance termination notice, which gives the instance a two-minute warning before it terminates.\n* `timeout_action` - (Required) Action to take when TargetSpotCapacity has not been fulfilled when the TimeoutDurationMinutes has expired; that is, when all Spot instances could not be provisioned within the Spot provisioning timeout. Valid values are `TERMINATE_CLUSTER` and `SWITCH_TO_ON_DEMAND`. SWITCH_TO_ON_DEMAND specifies that if no Spot instances are available, On-Demand Instances should be provisioned to fulfill any remaining Spot capacity.\n* `timeout_duration_minutes` - (Required) Spot provisioning timeout period in minutes. If Spot instances are not provisioned within this time period, the TimeOutAction is taken. Minimum value is 5 and maximum value is 1440. The timeout applies only during initial provisioning, when the cluster is first created.\n\n### core_instance_group\n\n* `autoscaling_policy` - (Optional) String containing the [EMR Auto Scaling Policy](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-automatic-scaling.html) JSON.\n* `bid_price` - (Optional) Bid price for each EC2 instance in the instance group, expressed in USD. By setting this attribute, the instance group is being declared as a Spot Instance, and will implicitly create a Spot request. Leave this blank to use On-Demand Instances.\n* `ebs_config` - (Optional) Configuration block(s) for EBS volumes attached to each instance in the instance group. Detailed below.\n* `instance_count` - (Optional) Target number of instances for the instance group. Must be at least 1. Defaults to 1.\n* `instance_type` - (Required) EC2 instance type for all instances in the instance group.\n* `name` - (Optional) Friendly name given to the instance group.\n\n#### ebs_config\n\n* `iops` - (Optional) Number of I/O operations per second (IOPS) that the volume supports.\n* `size` - (Required) Volume size, in gibibytes (GiB).\n* `type` - (Required) Volume type. Valid options are `gp2`, `io1`, `standard` and `st1`. See [EBS Volume Types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html).\n* `volumes_per_instance` - (Optional) Number of EBS volumes with this configuration to attach to each EC2 instance in the instance group (default is 1).\n\n### ec2_attributes\n\nAttributes for the Amazon EC2 instances running the job flow:\n\n* `additional_master_security_groups` - (Optional) String containing a comma separated list of additional Amazon EC2 security group IDs for the master node.\n* `additional_slave_security_groups` - (Optional) String containing a comma separated list of additional Amazon EC2 security group IDs for the slave nodes as a comma separated string.\n* `emr_managed_master_security_group` - (Optional) Identifier of the Amazon EC2 EMR-Managed security group for the master node.\n* `emr_managed_slave_security_group` - (Optional) Identifier of the Amazon EC2 EMR-Managed security group for the slave nodes.\n* `instance_profile` - (Required) Instance Profile for EC2 instances of the cluster assume this role.\n* `key_name` - (Optional) Amazon EC2 key pair that can be used to ssh to the master node as the user called `hadoop`.\n* `service_access_security_group` - (Optional) Identifier of the Amazon EC2 service-access security group - required when the cluster runs on a private subnet.\n* `subnet_id` - (Optional) VPC subnet id where you want the job flow to launch. Cannot specify the `cc1.4xlarge` instance type for nodes of a job flow launched in an Amazon VPC.\n* `subnet_ids` - (Optional) List of VPC subnet id-s where you want the job flow to launch.  Amazon EMR identifies the best Availability Zone to launch instances according to your fleet specifications.\n\n~> **NOTE on EMR-Managed security groups:** These security groups will have any missing inbound or outbound access rules added and maintained by AWS, to ensure proper communication between instances in a cluster. The EMR service will maintain these rules for groups provided in `emr_managed_master_security_group` and `emr_managed_slave_security_group`; attempts to remove the required rules may succeed, only for the EMR service to re-add them in a matter of minutes. This may cause Terraform to fail to destroy an environment that contains an EMR cluster, because the EMR service does not revoke rules added on deletion, leaving a cyclic dependency between the security groups that prevents their deletion. To avoid this, use the `revoke_rules_on_delete` optional attribute for any Security Group used in `emr_managed_master_security_group` and `emr_managed_slave_security_group`. See [Amazon EMR-Managed Security Groups](http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-man-sec-groups.html) for more information about the EMR-managed security group rules.\n\n### kerberos_attributes\n\n* `ad_domain_join_password` - (Optional) Active Directory password for `ad_domain_join_user`. Terraform cannot perform drift detection of this configuration.\n* `ad_domain_join_user` - (Optional) Required only when establishing a cross-realm trust with an Active Directory domain. A user with sufficient privileges to join resources to the domain. Terraform cannot perform drift detection of this configuration.\n* `cross_realm_trust_principal_password` - (Optional) Required only when establishing a cross-realm trust with a KDC in a different realm. The cross-realm principal password, which must be identical across realms. Terraform cannot perform drift detection of this configuration.\n* `kdc_admin_password` - (Required) Password used within the cluster for the kadmin service on the cluster-dedicated KDC, which maintains Kerberos principals, password policies, and keytabs for the cluster. Terraform cannot perform drift detection of this configuration.\n* `realm` - (Required) Name of the Kerberos realm to which all nodes in a cluster belong. For example, `EC2.INTERNAL`\n\n### master_instance_fleet\n\n* `instance_type_configs` - (Optional) Configuration block for instance fleet.\n* `launch_specifications` - (Optional) Configuration block for launch specification.\n* `name` - (Optional) Friendly name given to the instance fleet.\n* `target_on_demand_capacity` - (Optional) Target capacity of On-Demand units for the instance fleet, which determines how many On-Demand instances to provision.\n* `target_spot_capacity` - (Optional) Target capacity of Spot units for the instance fleet, which determines how many Spot instances to provision.\n\n#### instance_type_configs\n\nSee `instance_type_configs` above, under `core_instance_fleet`.\n\n#### launch_specifications\n\nSee `launch_specifications` above, under `core_instance_fleet`.\n\n### master_instance_group\n\nSupported nested arguments for the `master_instance_group` configuration block:\n\n* `bid_price` - (Optional) Bid price for each EC2 instance in the instance group, expressed in USD. By setting this attribute, the instance group is being declared as a Spot Instance, and will implicitly create a Spot request. Leave this blank to use On-Demand Instances.\n* `ebs_config` - (Optional) Configuration block(s) for EBS volumes attached to each instance in the instance group. Detailed below.\n* `instance_count` - (Optional) Target number of instances for the instance group. Must be 1 or 3. Defaults to 1. Launching with multiple master nodes is only supported in EMR version 5.23.0+, and requires this resource's `core_instance_group` to be configured. Public (Internet accessible) instances must be created in VPC subnets that have [map public IP on launch](/docs/providers/aws/r/subnet.html#map_public_ip_on_launch) enabled. Termination protection is automatically enabled when launched with multiple master nodes and Terraform must have the `termination_protection = false` configuration applied before destroying this resource.\n* `instance_type` - (Required) EC2 instance type for all instances in the instance group.\n* `name` - (Optional) Friendly name given to the instance group.\n\n#### ebs_config\n\nSee `ebs_config` under `core_instance_group` above.\n\n### step\n\nThis argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\n* `action_on_failure` - (Required) Action to take if the step fails. Valid values: `TERMINATE_JOB_FLOW`, `TERMINATE_CLUSTER`, `CANCEL_AND_WAIT`, and `CONTINUE`\n* `hadoop_jar_step` - (Required) JAR file used for the step. See below.\n* `name` - (Required) Name of the step.\n\n#### hadoop_jar_step\n\nThis argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\n* `args` - (Optional) List of command line arguments passed to the JAR file's main function when executed.\n* `jar` - (Required) Path to a JAR file run during the step.\n* `main_class` - (Optional) Name of the main class in the specified Java file. If not specified, the JAR file should specify a Main-Class in its manifest file.\n* `properties` - (Optional) Key-Value map of Java properties that are set when the step runs. You can use these properties to pass key value pairs to your main function.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `applications` - Applications installed on this cluster.\n* `arn`- ARN of the cluster.\n* `bootstrap_action` - List of bootstrap actions that will be run before Hadoop is started on the cluster nodes.\n* `configurations` - List of Configurations supplied to the EMR cluster.\n* `core_instance_group.0.id` - Core node type Instance Group ID, if using Instance Group for this node type.\n* `ec2_attributes` - Provides information about the EC2 instances in a cluster grouped by category: key name, subnet ID, IAM instance profile, and so on.\n* `id` - ID of the cluster.\n* `log_uri` - Path to the Amazon S3 location where logs for this cluster are stored.\n* `master_instance_group.0.id` - Master node type Instance Group ID, if using Instance Group for this node type.\n* `master_public_dns` - Public DNS name of the master EC2 instance.\n* `name` - Name of the cluster.\n* `release_label` - Release label for the Amazon EMR release.\n* `service_role` - IAM role that will be assumed by the Amazon EMR service to access AWS resources on your behalf.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `visible_to_all_users` - Indicates whether the job flow is visible to all IAM users of the AWS account associated with the job flow.\n\n## Import\n\nEMR clusters can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_emr_cluster.cluster j-123456ABCDEF\n```\n\nSince the API does not return the actual values for Kerberos configurations, environments with those Terraform configurations will need to use the [`lifecycle` configuration block `ignore_changes` argument](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) available to all Terraform resources to prevent perpetual differences, e.g.,\n\n```terraform\nresource \"aws_emr_cluster\" \"example\" {\n  # ... other configuration ...\n\n  lifecycle {\n    ignore_changes = [kerberos_attributes]\n  }\n}\n```\n",
    "basename": "emr_cluster.html"
  },
  "emr_instance_fleet.html": {
    "subcategory": "Elastic Map Reduce (EMR)",
    "layout": "aws",
    "page_title": "AWS: aws_emr_instance_fleet",
    "description": "Provides an Elastic MapReduce Cluster Instance Fleet",
    "preview": "# Resource: aws_emr_instance_fleet\n\nProvides an Elastic MapReduce …",
    "content": "\n\n# Resource: aws_emr_instance_fleet\n\nProvides an Elastic MapReduce Cluster Instance Fleet configuration.\nSee [Amazon Elastic MapReduce Documentation](https://aws.amazon.com/documentation/emr/) for more information.\n\n~> **NOTE:** At this time, Instance Fleets cannot be destroyed through the API nor\nweb interface. Instance Fleets are destroyed when the EMR Cluster is destroyed.\nTerraform will resize any Instance Fleet to zero when destroying the resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_emr_instance_fleet\" \"task\" {\n  cluster_id = aws_emr_cluster.cluster.id\n  instance_type_configs {\n    bid_price_as_percentage_of_on_demand_price = 100\n    ebs_config {\n      size                 = 100\n      type                 = \"gp2\"\n      volumes_per_instance = 1\n    }\n    instance_type     = \"m4.xlarge\"\n    weighted_capacity = 1\n  }\n  instance_type_configs {\n    bid_price_as_percentage_of_on_demand_price = 100\n    ebs_config {\n      size                 = 100\n      type                 = \"gp2\"\n      volumes_per_instance = 1\n    }\n    instance_type     = \"m4.2xlarge\"\n    weighted_capacity = 2\n  }\n  launch_specifications {\n    spot_specification {\n      allocation_strategy      = \"capacity-optimized\"\n      block_duration_minutes   = 0\n      timeout_action           = \"TERMINATE_CLUSTER\"\n      timeout_duration_minutes = 10\n    }\n  }\n  name                      = \"task fleet\"\n  target_on_demand_capacity = 1\n  target_spot_capacity      = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_id` - (Required) ID of the EMR Cluster to attach to. Changing this forces a new resource to be created.\n* `instance_type_configs` - (Optional) Configuration block for instance fleet\n* `launch_specifications` - (Optional) Configuration block for launch specification\n* `target_on_demand_capacity` - (Optional)  The target capacity of On-Demand units for the instance fleet, which determines how many On-Demand instances to provision.\n* `target_spot_capacity` - (Optional) The target capacity of Spot units for the instance fleet, which determines how many Spot instances to provision.\n* `name` - (Optional) Friendly name given to the instance fleet.\n\n## instance_type_configs Configuration Block\n\n* `bid_price` - (Optional) The bid price for each EC2 Spot instance type as defined by `instance_type`. Expressed in USD. If neither `bid_price` nor `bid_price_as_percentage_of_on_demand_price` is provided, `bid_price_as_percentage_of_on_demand_price` defaults to 100%.\n* `bid_price_as_percentage_of_on_demand_price` - (Optional) The bid price, as a percentage of On-Demand price, for each EC2 Spot instance as defined by `instance_type`. Expressed as a number (for example, 20 specifies 20%). If neither `bid_price` nor `bid_price_as_percentage_of_on_demand_price` is provided, `bid_price_as_percentage_of_on_demand_price` defaults to 100%.\n* `configurations` - (Optional) A configuration classification that applies when provisioning cluster instances, which can include configurations for applications and software that run on the cluster. List of `configuration` blocks.\n* `ebs_config` - (Optional) Configuration block(s) for EBS volumes attached to each instance in the instance group. Detailed below.\n* `instance_type` - (Required) An EC2 instance type, such as m4.xlarge.\n* `weighted_capacity` - (Optional) The number of units that a provisioned instance of this type provides toward fulfilling the target capacities defined in `aws_emr_instance_fleet`.\n\n## configurations Configuration Block\n\nA configuration classification that applies when provisioning cluster instances, which can include configurations for applications and software that run on the cluster. See [Configuring Applications](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-configure-apps.html).\n\n* `classification` - (Optional) The classification within a configuration.\n* `properties` - (Optional) A map of properties specified within a configuration classification\n\n## ebs_config\n\nAttributes for the EBS volumes attached to each EC2 instance in the `master_instance_group` and `core_instance_group` configuration blocks:\n\n* `size` - (Required) The volume size, in gibibytes (GiB).\n* `type` - (Required) The volume type. Valid options are `gp2`, `io1`, `standard` and `st1`. See [EBS Volume Types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html).\n* `iops` - (Optional) The number of I/O operations per second (IOPS) that the volume supports\n* `volumes_per_instance` - (Optional) The number of EBS volumes with this configuration to attach to each EC2 instance in the instance group (default is 1)\n\n## launch_specifications Configuration Block\n\n* `on_demand_specification` - (Optional) Configuration block for on demand instances launch specifications\n* `spot_specification` - (Optional) Configuration block for spot instances launch specifications\n\n## on_demand_specification  Configuration Block\n\nThe launch specification for On-Demand instances in the instance fleet, which determines the allocation strategy.\nThe instance fleet configuration is available only in Amazon EMR versions 4.8.0 and later, excluding 5.0.x versions. On-Demand instances allocation strategy is available in Amazon EMR version 5.12.1 and later.\n\n* `allocation_strategy` - (Required) Specifies the strategy to use in launching On-Demand instance fleets. Currently, the only option is `lowest-price` (the default), which launches the lowest price first.\n\n## spot_specification  Configuration Block\n\nThe launch specification for Spot instances in the fleet, which determines the defined duration, provisioning timeout behavior, and allocation strategy.\n\n* `allocation_strategy` - (Required) Specifies the strategy to use in launching Spot instance fleets. Currently, the only option is `capacity-optimized` (the default), which launches instances from Spot instance pools with optimal capacity for the number of instances that are launching.\n* `block_duration_minutes` - (Optional) The defined duration for Spot instances (also known as Spot blocks) in minutes. When specified, the Spot instance does not terminate before the defined duration expires, and defined duration pricing for Spot instances applies. Valid values are 60, 120, 180, 240, 300, or 360. The duration period starts as soon as a Spot instance receives its instance ID. At the end of the duration, Amazon EC2 marks the Spot instance for termination and provides a Spot instance termination notice, which gives the instance a two-minute warning before it terminates.\n* `timeout_action` - (Required) The action to take when TargetSpotCapacity has not been fulfilled when the TimeoutDurationMinutes has expired; that is, when all Spot instances could not be provisioned within the Spot provisioning timeout. Valid values are `TERMINATE_CLUSTER` and `SWITCH_TO_ON_DEMAND`. SWITCH_TO_ON_DEMAND specifies that if no Spot instances are available, On-Demand Instances should be provisioned to fulfill any remaining Spot capacity.\n* `timeout_duration_minutes` - (Required) The spot provisioning timeout period in minutes. If Spot instances are not provisioned within this time period, the TimeOutAction is taken. Minimum value is 5 and maximum value is 1440. The timeout applies only during initial provisioning, when the cluster is first created.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier of the instance fleet.\n\n* `provisioned_on_demand_capacity` The number of On-Demand units that have been provisioned for the instance\nfleet to fulfill TargetOnDemandCapacity. This provisioned capacity might be less than or greater than TargetOnDemandCapacity.\n\n* `provisioned_spot_capacity` The number of Spot units that have been provisioned for this instance fleet\nto fulfill TargetSpotCapacity. This provisioned capacity might be less than or greater than TargetSpotCapacity.\n\n* `status` The current status of the instance fleet.\n\n## Import\n\nEMR Instance Fleet can be imported with the EMR Cluster identifier and Instance Fleet identifier separated by a forward slash (`/`), e.g.,\n\n```console\n$ terraform import aws_emr_instance_fleet.example j-123456ABCDEF/if-15EK4O09RZLNR\n```\n",
    "basename": "emr_instance_fleet.html"
  },
  "emr_instance_group.html": {
    "subcategory": "Elastic Map Reduce (EMR)",
    "layout": "aws",
    "page_title": "AWS: aws_emr_instance_group",
    "description": "Provides an Elastic MapReduce Cluster Instance Group",
    "preview": "# Resource: aws_emr_instance_group\n\nProvides an Elastic MapReduce …",
    "content": "\n\n# Resource: aws_emr_instance_group\n\nProvides an Elastic MapReduce Cluster Instance Group configuration.\nSee [Amazon Elastic MapReduce Documentation](https://aws.amazon.com/documentation/emr/) for more information.\n\n~> **NOTE:** At this time, Instance Groups cannot be destroyed through the API nor\nweb interface. Instance Groups are destroyed when the EMR Cluster is destroyed.\nTerraform will resize any Instance Group to zero when destroying the resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_emr_instance_group\" \"task\" {\n  cluster_id     = aws_emr_cluster.tf-test-cluster.id\n  instance_count = 1\n  instance_type  = \"m5.xlarge\"\n  name           = \"my little instance group\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` (Required) Human friendly name given to the instance group. Changing this forces a new resource to be created.\n* `cluster_id` (Required) ID of the EMR Cluster to attach to. Changing this forces a new resource to be created.\n* `instance_type` (Required) The EC2 instance type for all instances in the instance group. Changing this forces a new resource to be created.\n* `instance_count` (optional) target number of instances for the instance group. defaults to 0.\n* `bid_price` - (Optional) If set, the bid price for each EC2 instance in the instance group, expressed in USD. By setting this attribute, the instance group is being declared as a Spot Instance, and will implicitly create a Spot request. Leave this blank to use On-Demand Instances.\n* `ebs_optimized` (Optional) Indicates whether an Amazon EBS volume is EBS-optimized. Changing this forces a new resource to be created.\n* `ebs_config` (Optional) One or more `ebs_config` blocks as defined below. Changing this forces a new resource to be created.\n* `autoscaling_policy` - (Optional) The autoscaling policy document. This is a JSON formatted string. See [EMR Auto Scaling](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-automatic-scaling.html)\n* `configurations_json` - (Optional) A JSON string for supplying list of configurations specific to the EMR instance group. Note that this can only be changed when using EMR release 5.21 or later.\n\n```terraform\nresource \"aws_emr_instance_group\" \"task\" {\n  # ... other configuration ...\n\n  configurations_json = <<EOF\n  [\n    {\n      \"Classification\": \"hadoop-env\",\n      \"Configurations\": [\n        {\n          \"Classification\": \"export\",\n          \"Properties\": {\n            \"JAVA_HOME\": \"/usr/lib/jvm/java-1.8.0\"\n          }\n        }\n      ],\n      \"Properties\": {}\n    }\n  ]\nEOF\n}\n```\n\n`ebs_config` supports the following:\n\n* `iops` - (Optional) The number of I/O operations per second (IOPS) that the volume supports.\n* `size` - (Optional) The volume size, in gibibytes (GiB). This can be a number from 1 - 1024. If the volume type is EBS-optimized, the minimum value is 10.\n* `type` - (Optional) The volume type. Valid options are 'gp2', 'io1' and 'standard'.\n* `volumes_per_instance` - (Optional) The number of EBS Volumes to attach per instance.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The EMR Instance ID\n* `running_instance_count` The number of instances currently running in this instance group.\n* `status` The current status of the instance group.\n\n## Import\n\nEMR task instance group can be imported using their EMR Cluster id and Instance Group id separated by a forward-slash `/`, e.g.,\n\n```\n$ terraform import aws_emr_instance_group.task_greoup j-123456ABCDEF/ig-15EK4O09RZLNR\n```\n",
    "basename": "emr_instance_group.html"
  },
  "emr_managed_scaling_policy.html": {
    "subcategory": "Elastic Map Reduce (EMR)",
    "layout": "aws",
    "page_title": "AWS: aws_emr_managed_scaling_policy",
    "description": "Provides a resource for EMR Managed Scaling policy",
    "preview": "# Resource: aws_emr_managed_scaling_policy\n\nProvides a Managed …",
    "content": "\n\n# Resource: aws_emr_managed_scaling_policy\n\nProvides a Managed Scaling policy for EMR Cluster. With Amazon EMR versions 5.30.0 and later (except for Amazon EMR 6.0.0), you can enable EMR managed scaling to automatically increase or decrease the number of instances or units in your cluster based on workload. See [Using EMR Managed Scaling in Amazon EMR](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-managed-scaling.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_emr_cluster\" \"sample\" {\n  name          = \"emr-sample-cluster\"\n  release_label = \"emr-5.30.0\"\n\n  master_instance_group {\n    instance_type = \"m4.large\"\n  }\n\n  core_instance_group {\n    instance_type = \"c4.large\"\n  }\n  # skip ...\n}\n\nresource \"aws_emr_managed_scaling_policy\" \"samplepolicy\" {\n  cluster_id = aws_emr_cluster.sample.id\n  compute_limits {\n    unit_type                       = \"Instances\"\n    minimum_capacity_units          = 2\n    maximum_capacity_units          = 10\n    maximum_ondemand_capacity_units = 2\n    maximum_core_capacity_units     = 10\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_id` - (Required) The id of the EMR cluster\n* `compute_limits` - (Required) Configuration block with compute limit settings. Described below.\n\n### compute_limits\n\n* `unit_type` - (Required) The unit type used for specifying a managed scaling policy. Valid Values: `InstanceFleetUnits` | `Instances` | `VCPU`\n* `minimum_capacity_units` - (Required) The lower boundary of EC2 units. It is measured through VCPU cores or instances for instance groups and measured through units for instance fleets. Managed scaling activities are not allowed beyond this boundary. The limit only applies to the core and task nodes. The master node cannot be scaled after initial configuration.\n* `maximum_capacity_units` - (Required) The upper boundary of EC2 units. It is measured through VCPU cores or instances for instance groups and measured through units for instance fleets. Managed scaling activities are not allowed beyond this boundary. The limit only applies to the core and task nodes. The master node cannot be scaled after initial configuration.\n* `maximum_ondemand_capacity_units` - (Optional) The upper boundary of On-Demand EC2 units. It is measured through VCPU cores or instances for instance groups and measured through units for instance fleets. The On-Demand units are not allowed to scale beyond this boundary. The parameter is used to split capacity allocation between On-Demand and Spot instances.\n* `maximum_core_capacity_units` - (Optional) The upper boundary of EC2 units for core node type in a cluster. It is measured through VCPU cores or instances for instance groups and measured through units for instance fleets. The core units are not allowed to scale beyond this boundary. The parameter is used to split capacity allocation between core and task nodes.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nEMR Managed Scaling Policies can be imported via the EMR Cluster identifier, e.g.,\n\n```console\n$ terraform import aws_emr_managed_scaling_policy.example j-123456ABCDEF\n```\n",
    "basename": "emr_managed_scaling_policy.html"
  },
  "emr_security_configuration.html": {
    "subcategory": "Elastic Map Reduce (EMR)",
    "layout": "aws",
    "page_title": "AWS: aws_emr_security_configuration",
    "description": "Provides a resource to manage AWS EMR Security Configurations",
    "preview": "# Resource: aws_emr_security_configuration\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_emr_security_configuration\n\nProvides a resource to manage AWS EMR Security Configurations\n\n## Example Usage\n\n```terraform\nresource \"aws_emr_security_configuration\" \"foo\" {\n  name = \"emrsc_other\"\n\n  configuration = <<EOF\n{\n  \"EncryptionConfiguration\": {\n    \"AtRestEncryptionConfiguration\": {\n      \"S3EncryptionConfiguration\": {\n        \"EncryptionMode\": \"SSE-S3\"\n      },\n      \"LocalDiskEncryptionConfiguration\": {\n        \"EncryptionKeyProviderType\": \"AwsKms\",\n        \"AwsKmsKey\": \"arn:aws:kms:us-west-2:187416307283:alias/tf_emr_test_key\"\n      }\n    },\n    \"EnableInTransitEncryption\": false,\n    \"EnableAtRestEncryption\": true\n  }\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the EMR Security Configuration. By default generated by Terraform.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified\n  prefix. Conflicts with `name`.\n* `configuration` - (Required) A JSON formatted Security Configuration\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the EMR Security Configuration (Same as the `name`)\n* `name` - The Name of the EMR Security Configuration\n* `configuration` - The JSON formatted Security Configuration\n* `creation_date` - Date the Security Configuration was created\n\n## Import\n\nEMR Security Configurations can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_emr_security_configuration.sc example-sc-name\n```\n",
    "basename": "emr_security_configuration.html"
  },
  "emr_studio.html": {
    "subcategory": "Elastic Map Reduce (EMR)",
    "layout": "aws",
    "page_title": "AWS: aws_emr_studio",
    "description": "Provides an Elastic MapReduce Studio",
    "preview": "# Resource: aws_emr_studio\n\nProvides an Elastic MapReduce Studio.\n …",
    "content": "\n\n# Resource: aws_emr_studio\n\nProvides an Elastic MapReduce Studio.\n\n## Example Usage\n\n```terraform\nresource \"aws_emr_studio\" \"example\" {\n  auth_mode                   = \"SSO\"\n  default_s3_location         = \"s3://${aws_s3_bucket.test.bucket}/test\"\n  engine_security_group_id    = aws_security_group.test.id\n  name                        = \"example\"\n  service_role                = aws_iam_role.test.arn\n  subnet_ids                  = [aws_subnet.test.id]\n  user_role                   = aws_iam_role.test.arn\n  vpc_id                      = aws_vpc.test.id\n  workspace_security_group_id = aws_security_group.test.id\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `auth_mode`- (Required) Specifies whether the Studio authenticates users using IAM or Amazon Web Services SSO. Valid values are `SSO` or `IAM`.\n* `default_s3_location` - (Required) The Amazon S3 location to back up Amazon EMR Studio Workspaces and notebook files.\n* `name` - (Required) A descriptive name for the Amazon EMR Studio.\n* `engine_security_group_id` - (Required) The ID of the Amazon EMR Studio Engine security group. The Engine security group allows inbound network traffic from the Workspace security group, and it must be in the same VPC specified by `vpc_id`.\n* `service_role` - (Required) The IAM role that the Amazon EMR Studio assumes. The service role provides a way for Amazon EMR Studio to interoperate with other Amazon Web Services services.\n* `subnet_ids` - (Required) A list of subnet IDs to associate with the Amazon EMR Studio. A Studio can have a maximum of 5 subnets. The subnets must belong to the VPC specified by `vpc_id`. Studio users can create a Workspace in any of the specified subnets.\n* `vpc_id` - (Required) The ID of the Amazon Virtual Private Cloud (Amazon VPC) to associate with the Studio.\n* `workspace_security_group_id` - (Required) The ID of the Amazon EMR Studio Workspace security group. The Workspace security group allows outbound network traffic to resources in the Engine security group, and it must be in the same VPC specified by `vpc_id`.\n\nThe following arguments are optional:\n\n* `description` - (Optional) A detailed description of the Amazon EMR Studio.\n* `idp_auth_url` - (Optional) The authentication endpoint of your identity provider (IdP). Specify this value when you use IAM authentication and want to let federated users log in to a Studio with the Studio URL and credentials from your IdP. Amazon EMR Studio redirects users to this endpoint to enter credentials.\n* `idp_relay_state_parameter_name` - (Optional) The name that your identity provider (IdP) uses for its RelayState parameter. For example, RelayState or TargetSource. Specify this value when you use IAM authentication and want to let federated users log in to a Studio using the Studio URL. The RelayState parameter differs by IdP.\n* `tags` - (Optional) list of tags to apply to the EMR Cluster. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `user_role` - (Optional) - The IAM user role that users and groups assume when logged in to an Amazon EMR Studio. Only specify a User Role when you use Amazon Web Services SSO authentication. The permissions attached to the User Role can be scoped down for each user or group using session policies.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn`- ARN of the studio.\n* `url` - The unique access URL of the Amazon EMR Studio.\n\n## Import\n\nEMR studios can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_emr_studio.studio es-123456ABCDEF\n```\n",
    "basename": "emr_studio.html"
  },
  "emr_studio_session_mapping.html": {
    "subcategory": "Elastic Map Reduce (EMR)",
    "layout": "aws",
    "page_title": "AWS: aws_emr_studio_session_mapping",
    "description": "Provides an Elastic MapReduce Studio",
    "preview": "# Resource: aws_emr_studio_session_mapping\n\nProvides an Elastic …",
    "content": "\n\n# Resource: aws_emr_studio_session_mapping\n\nProvides an Elastic MapReduce Studio Session Mapping.\n\n## Example Usage\n\n```terraform\nresource \"aws_emr_studio_session_mapping\" \"example\" {\n  studio_id          = aws_emr_studio.example.id\n  identity_type      = \"USER\"\n  identity_id        = \"example\"\n  session_policy_arn = aws_iam_policy.example.arn\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `identity_id`- (Optional) The globally unique identifier (GUID) of the user or group from the Amazon Web Services SSO Identity Store.\n* `identity_name` - (Optional) The name of the user or group from the Amazon Web Services SSO Identity Store.\n* `identity_type` - (Required) Specifies whether the identity to map to the Amazon EMR Studio is a `USER` or a `GROUP`.\n* `session_policy_arn` - (Required) The Amazon Resource Name (ARN) for the session policy that will be applied to the user or group. You should specify the ARN for the session policy that you want to apply, not the ARN of your user role.\n* `studio_id` - (Required) The ID of the Amazon EMR Studio to which the user or group will be mapped.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id`- The id of the Elastic MapReduce Studio Session Mapping.\n\n## Import\n\nEMR studio session mappings can be imported using the `id`, e.g., `studio-id:identity-type:identity-id`\n\n```\n$ terraform import aws_emr_studio_session_mapping.example es-xxxxx:USER:xxxxx-xxx-xxx\n```\n",
    "basename": "emr_studio_session_mapping.html"
  },
  "flow_log.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_flow_log",
    "description": "Provides a VPC/Subnet/ENI Flow Log",
    "preview": "# Resource: aws_flow_log\n\nProvides a VPC/Subnet/ENI Flow Log to …",
    "content": "\n\n# Resource: aws_flow_log\n\nProvides a VPC/Subnet/ENI Flow Log to capture IP traffic for a specific network\ninterface, subnet, or VPC. Logs are sent to a CloudWatch Log Group or a S3 Bucket.\n\n## Example Usage\n\n### CloudWatch Logging\n\n```terraform\nresource \"aws_flow_log\" \"example\" {\n  iam_role_arn    = aws_iam_role.example.arn\n  log_destination = aws_cloudwatch_log_group.example.arn\n  traffic_type    = \"ALL\"\n  vpc_id          = aws_vpc.example.id\n}\n\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_iam_role\" \"example\" {\n  name = \"example\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"vpc-flow-logs.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"example\" {\n  name = \"example\"\n  role = aws_iam_role.example.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\",\n        \"logs:DescribeLogGroups\",\n        \"logs:DescribeLogStreams\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n```\n\n### S3 Logging\n\n```terraform\nresource \"aws_flow_log\" \"example\" {\n  log_destination      = aws_s3_bucket.example.arn\n  log_destination_type = \"s3\"\n  traffic_type         = \"ALL\"\n  vpc_id               = aws_vpc.example.id\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n```\n\n### S3 Logging in Apache Parquet format with per-hour partitions\n\n```terraform\nresource \"aws_flow_log\" \"example\" {\n  log_destination      = aws_s3_bucket.example.arn\n  log_destination_type = \"s3\"\n  traffic_type         = \"ALL\"\n  vpc_id               = aws_vpc.example.id\n  destination_options {\n    file_format        = \"parquet\"\n    per_hour_partition = true\n  }\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n```\n\n## Argument Reference\n\n~> **NOTE:** One of `eni_id`, `subnet_id`, or `vpc_id` must be specified.\n\nThe following arguments are supported:\n\n* `traffic_type` - (Required) The type of traffic to capture. Valid values: `ACCEPT`,`REJECT`, `ALL`.\n* `eni_id` - (Optional) Elastic Network Interface ID to attach to\n* `iam_role_arn` - (Optional) The ARN for the IAM role that's used to post flow logs to a CloudWatch Logs log group\n* `log_destination_type` - (Optional) The type of the logging destination. Valid values: `cloud-watch-logs`, `s3`. Default: `cloud-watch-logs`.\n* `log_destination` - (Optional) The ARN of the logging destination.\n* `log_group_name` - (Optional) *Deprecated:* Use `log_destination` instead. The name of the CloudWatch log group.\n* `subnet_id` - (Optional) Subnet ID to attach to\n* `vpc_id` - (Optional) VPC ID to attach to\n* `log_format` - (Optional) The fields to include in the flow log record, in the order in which they should appear.\n* `max_aggregation_interval` - (Optional) The maximum interval of time\n  during which a flow of packets is captured and aggregated into a flow\n  log record. Valid Values: `60` seconds (1 minute) or `600` seconds (10\n  minutes). Default: `600`.\n* `destination_options` - (Optional) Describes the destination options for a flow log. More details below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### destination_options\n\nDescribes the destination options for a flow log.\n\n* `file_format` - (Optional) The format for the flow log. Default value: `plain-text`. Valid values: `plain-text`, `parquet`.\n* `hive_compatible_partitions` - (Optional) Indicates whether to use Hive-compatible prefixes for flow logs stored in Amazon S3. Default value: `false`.\n* `per_hour_partition` - (Optional) Indicates whether to partition the flow log per hour. This reduces the cost and response time for queries. Default value: `false`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Flow Log ID\n* `arn` - The ARN of the Flow Log.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nFlow Logs can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_flow_log.test_flow_log fl-1a2b3c4d\n```\n",
    "basename": "flow_log.html"
  },
  "fms_admin_account.html": {
    "subcategory": "Firewall Manager (FMS)",
    "layout": "aws",
    "page_title": "AWS: aws_fms_admin_account",
    "description": "Provides a resource to associate/disassociate an AWS Firewall Manager administrator account",
    "preview": "# Resource: aws_fms_admin_account\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_fms_admin_account\n\nProvides a resource to associate/disassociate an AWS Firewall Manager administrator account. This operation must be performed in the `us-east-1` region.\n\n## Example Usage\n\n```terraform\nresource \"aws_fms_admin_account\" \"example\" {}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The AWS account ID to associate with AWS Firewall Manager as the AWS Firewall Manager administrator account. This can be an AWS Organizations master account or a member account. Defaults to the current account. Must be configured to perform drift detection.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The AWS account ID of the AWS Firewall Manager administrator account.\n\n## Import\n\nFirewall Manager administrator account association can be imported using the account ID, e.g.,\n\n```\n$ terraform import aws_fms_admin_account.example 123456789012\n```\n",
    "basename": "fms_admin_account.html"
  },
  "fms_policy.html": {
    "subcategory": "Firewall Manager (FMS)",
    "layout": "aws",
    "page_title": "AWS: aws_fms_policy",
    "description": "Provides a resource to create an AWS Firewall Manager policy",
    "preview": "# Resource: aws_fms_policy\n\nProvides a resource to create an AWS …",
    "content": "\n\n# Resource: aws_fms_policy\n\nProvides a resource to create an AWS Firewall Manager policy. You need to be using AWS organizations and have enabled the Firewall Manager administrator account.\n\n## Example Usage\n\n```terraform\nresource \"aws_fms_policy\" \"example\" {\n  name                  = \"FMS-Policy-Example\"\n  exclude_resource_tags = false\n  remediation_enabled   = false\n  resource_type_list    = [\"AWS::ElasticLoadBalancingV2::LoadBalancer\"]\n\n  security_service_policy_data {\n    type = \"WAF\"\n\n    managed_service_data = jsonencode({\n      type = \"WAF\",\n      ruleGroups = [{\n        id = aws_wafregional_rule_group.example.id\n        overrideAction = {\n          type = \"COUNT\"\n        }\n      }]\n      defaultAction = {\n        type = \"BLOCK\"\n      }\n      overrideCustomerWebACLAssociation = false\n    })\n  }\n}\n\nresource \"aws_wafregional_rule_group\" \"example\" {\n  metric_name = \"WAFRuleGroupExample\"\n  name        = \"WAF-Rule-Group-Example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required, Forces new resource) The friendly name of the AWS Firewall Manager Policy.\n* `delete_all_policy_resources` - (Optional) If true, the request will also perform a clean-up process. Defaults to `true`. More information can be found here [AWS Firewall Manager delete policy](https://docs.aws.amazon.com/fms/2018-01-01/APIReference/API_DeletePolicy.html)\n* `exclude_map` - (Optional) A map of lists of accounts and OU's to exclude from the policy.\n* `exclude_resource_tags` - (Required, Forces new resource) A boolean value, if true the tags that are specified in the `resource_tags` are not protected by this policy. If set to false and resource_tags are populated, resources that contain tags will be protected by this policy.\n* `include_map` - (Optional) A map of lists of accounts and OU's to include in the policy.\n* `remediation_enabled` - (Required) A boolean value, indicates if the policy should automatically applied to resources that already exist in the account.\n* `resource_tags` - (Optional) A map of resource tags, that if present will filter protections on resources based on the exclude_resource_tags.\n* `resource_type` - (Optional) A resource type to protect. Conflicts with `resource_type_list`. See the [FMS API Reference](https://docs.aws.amazon.com/fms/2018-01-01/APIReference/API_Policy.html#fms-Type-Policy-ResourceType) for more information about supported values.\n* `resource_type_list` - (Optional) A list of resource types to protect. Conflicts with `resource_type`. See the [FMS API Reference](https://docs.aws.amazon.com/fms/2018-01-01/APIReference/API_Policy.html#fms-Type-Policy-ResourceType) for more information about supported values.\n* `security_service_policy_data` - (Required) The objects to include in Security Service Policy Data. Documented below.\n\n## `exclude_map` Configuration Block\n\n* `account` - (Optional) A list of AWS Organization member Accounts that you want to exclude from this AWS FMS Policy.\n* `orgunit` - (Optional) A list of AWS Organizational Units that you want to exclude from this AWS FMS Policy. Specifying an OU is the equivalent of specifying all accounts in the OU and in any of its child OUs, including any child OUs and accounts that are added at a later time.\n\nYou can specify inclusions or exclusions, but not both. If you specify an `include_map`, AWS Firewall Manager applies the policy to all accounts specified by the `include_map`, and does not evaluate any `exclude_map` specifications. If you do not specify an `include_map`, then Firewall Manager applies the policy to all accounts except for those specified by the `exclude_map`.\n\n## `include_map` Configuration Block\n\n* `account` - (Optional) A list of AWS Organization member Accounts that you want to include for this AWS FMS Policy.\n* `orgunit` - (Optional) A list of AWS Organizational Units that you want to include for this AWS FMS Policy. Specifying an OU is the equivalent of specifying all accounts in the OU and in any of its child OUs, including any child OUs and accounts that are added at a later time.\n\nYou can specify inclusions or exclusions, but not both. If you specify an `include_map`, AWS Firewall Manager applies the policy to all accounts specified by the `include_map`, and does not evaluate any `exclude_map` specifications. If you do not specify an `include_map`, then Firewall Manager applies the policy to all accounts except for those specified by the `exclude_map`.\n\n## `security_service_policy_data` Configuration Block\n\n* `managed_service_data` (Optional) Details about the service that are specific to the service type, in JSON format. For service type `SHIELD_ADVANCED`, this is an empty string. Examples depending on `type` can be found in the [AWS Firewall Manager SecurityServicePolicyData API Reference](https://docs.aws.amazon.com/fms/2018-01-01/APIReference/API_SecurityServicePolicyData.html).\n* `type` - (Required, Forces new resource) The service that the policy is using to protect the resources. For the current list of supported types, please refer to the [AWS Firewall Manager SecurityServicePolicyData API Type Reference](https://docs.aws.amazon.com/fms/2018-01-01/APIReference/API_SecurityServicePolicyData.html#fms-Type-SecurityServicePolicyData-Type).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The AWS account ID of the AWS Firewall Manager administrator account.\n* `policy_update_token` - A unique identifier for each update to the policy.\n\n## Import\n\nFirewall Manager policies can be imported using the policy ID, e.g.,\n\n```\n$ terraform import aws_fms_policy.example 5be49585-a7e3-4c49-dde1-a179fe4a619a\n```\n",
    "basename": "fms_policy.html"
  },
  "fsx_backup.html": {
    "subcategory": "File System (FSx)",
    "layout": "aws",
    "page_title": "AWS: aws_fsx_backup",
    "description": "Manages a FSx Backup.",
    "preview": "# Resource: aws_fsx_backup\n\nProvides a FSx Backup resource.\n\n## …",
    "content": "\n\n# Resource: aws_fsx_backup\n\nProvides a FSx Backup resource.\n\n## Example Usage\n\n## Lustre Example\n\n```terraform\nresource \"aws_fsx_backup\" \"example\" {\n  file_system_id = aws_fsx_lustre_file_system.example.id\n}\n\nresource \"aws_fsx_lustre_file_system\" \"example\" {\n  storage_capacity            = 1200\n  subnet_ids                  = [aws_subnet.example.id]\n  deployment_type             = \"PERSISTENT_1\"\n  per_unit_storage_throughput = 50\n}\n```\n\n## Windows Example\n\n```terraform\nresource \"aws_fsx_backup\" \"example\" {\n  file_system_id = aws_fsx_windows_file_system.example.id\n}\n\nresource \"aws_fsx_windows_file_system\" \"example\" {\n  active_directory_id = aws_directory_service_directory.eample.id\n  skip_final_backup   = true\n  storage_capacity    = 32\n  subnet_ids          = [aws_subnet.example1.id]\n  throughput_capacity = 8\n}\n```\n\n## ONTAP Example\n\n```terraform\nresource \"aws_fsx_backup\" \"example\" {\n  volume_id = aws_fsx_ontap_volume.example.id\n}\n\nresource \"aws_fsx_ontap_volume\" \"example\" {\n  name                       = \"example\"\n  junction_path              = \"/example\"\n  size_in_megabytes          = 1024\n  storage_efficiency_enabled = true\n  storage_virtual_machine_id = aws_fsx_ontap_storage_virtual_machine.test.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\nNote - Only file_system_id or volume_id can be specified. file_system_id is used for Lustre and Windows, volume_id is used for ONTAP.\n\n* `file_system_id` - (Optional) The ID of the file system to back up. Required if backing up Lustre or Windows file systems.\n* `tags` - (Optional) A map of tags to assign to the file system. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level. If you have set `copy_tags_to_backups` to true, and you specify one or more tags, no existing file system tags are copied from the file system to the backup.\n* `volume_id` - (Optional) The ID of the volume to back up. Required if backing up a ONTAP Volume.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name of the backup.\n* `id` - Identifier of the backup, e.g., `fs-12345678`\n* `kms_key_id` -  The ID of the AWS Key Management Service (AWS KMS) key used to encrypt the backup of the Amazon FSx file system's data at rest.\n* `owner_id` - AWS account identifier that created the file system.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `type` - The type of the file system backup.\n\n## Timeouts\n\n`aws_fsx_backup` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `10m`) How long to wait for the backup to be created.\n* `delete` - (Default `10m`) How long to wait for the backup to be deleted.\n\n## Import\n\nFSx Backups can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_fsx_backup.example fs-543ab12b1ca672f33\n```\n",
    "basename": "fsx_backup.html"
  },
  "fsx_lustre_file_system.html": {
    "subcategory": "File System (FSx)",
    "layout": "aws",
    "page_title": "AWS: aws_fsx_lustre_file_system",
    "description": "Manages a FSx Lustre File System.",
    "preview": "# Resource: aws_fsx_lustre_file_system\n\nManages a FSx Lustre File …",
    "content": "\n\n# Resource: aws_fsx_lustre_file_system\n\nManages a FSx Lustre File System. See the [FSx Lustre Guide](https://docs.aws.amazon.com/fsx/latest/LustreGuide/what-is.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_fsx_lustre_file_system\" \"example\" {\n  import_path      = \"s3://${aws_s3_bucket.example.bucket}\"\n  storage_capacity = 1200\n  subnet_ids       = [aws_subnet.example.id]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `storage_capacity` - (Optional) The storage capacity (GiB) of the file system. Minimum of `1200`. See more details at [Allowed values for Fsx storage capacity](https://docs.aws.amazon.com/fsx/latest/APIReference/API_CreateFileSystem.html#FSx-CreateFileSystem-request-StorageCapacity). Update is allowed only for `SCRATCH_2` and `PERSISTENT_1` deployment types, See more details at [Fsx Storage Capacity Update](https://docs.aws.amazon.com/fsx/latest/APIReference/API_UpdateFileSystem.html#FSx-UpdateFileSystem-request-StorageCapacity). Required when not creating filesystem for a backup.\n* `subnet_ids` - (Required) A list of IDs for the subnets that the file system will be accessible from. File systems currently support only one subnet. The file server is also launched in that subnet's Availability Zone.\n* `backup_id` - (Optional) The ID of the source backup to create the filesystem from.\n* `export_path` - (Optional) S3 URI (with optional prefix) where the root of your Amazon FSx file system is exported. Can only be specified with `import_path` argument and the path must use the same Amazon S3 bucket as specified in `import_path`. Set equal to `import_path` to overwrite files on export. Defaults to `s3://{IMPORT BUCKET}/FSxLustre{CREATION TIMESTAMP}`.\n* `import_path` - (Optional) S3 URI (with optional prefix) that you're using as the data repository for your FSx for Lustre file system. For example, `s3://example-bucket/optional-prefix/`.\n* `imported_file_chunk_size` - (Optional) For files imported from a data repository, this value determines the stripe count and maximum amount of data per file (in MiB) stored on a single physical disk. Can only be specified with `import_path` argument. Defaults to `1024`. Minimum of `1` and maximum of `512000`.\n* `security_group_ids` - (Optional) A list of IDs for the security groups that apply to the specified network interfaces created for file system access. These security groups will apply to all network interfaces.\n* `tags` - (Optional) A map of tags to assign to the file system. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `weekly_maintenance_start_time` - (Optional) The preferred start time (in `d:HH:MM` format) to perform weekly maintenance, in the UTC time zone.\n* `deployment_type` - (Optional) - The filesystem deployment type. One of: `SCRATCH_1`, `SCRATCH_2`, `PERSISTENT_1`.\n* `kms_key_id` - (Optional) ARN for the KMS Key to encrypt the file system at rest, applicable for `PERSISTENT_1` deployment_type. Defaults to an AWS managed KMS Key.\n* `per_unit_storage_throughput` - (Optional) - Describes the amount of read and write throughput for each 1 tebibyte of storage, in MB/s/TiB, required for the `PERSISTENT_1` deployment_type. Valid values for `SSD` storage_type are 50, 100, 200. Valid values for `HDD` storage_type are 12, 40.\n* `automatic_backup_retention_days` - (Optional) The number of days to retain automatic backups. Setting this to 0 disables automatic backups. You can retain automatic backups for a maximum of 90 days. only valid for `PERSISTENT_1` deployment_type.\n* `storage_type` - (Optional) - The filesystem storage type. Either `SSD` or `HDD`, defaults to `SSD`. `HDD` is only supported on `PERSISTENT_1` deployment types.\n* `drive_cache_type` - (Optional) - The type of drive cache used by `PERSISTENT_1` filesystems that are provisioned with `HDD` storage_type. Required for `HDD` storage_type, set to either `READ` or `NONE`.\n* `daily_automatic_backup_start_time` - (Optional) A recurring daily time, in the format HH:MM. HH is the zero-padded hour of the day (0-23), and MM is the zero-padded minute of the hour. For example, 05:00 specifies 5 AM daily. only valid for `PERSISTENT_1` deployment_type. Requires `automatic_backup_retention_days` to be set.\n* `auto_import_policy` - (Optional) How Amazon FSx keeps your file and directory listings up to date as you add or modify objects in your linked S3 bucket. see [Auto Import Data Repo](https://docs.aws.amazon.com/fsx/latest/LustreGuide/autoimport-data-repo.html) for more details.\n* `copy_tags_to_backups` - (Optional) A boolean flag indicating whether tags for the file system should be copied to backups. Applicable for `PERSISTENT_1` deployment_type. The default value is false.\n* `data_compression_type` - (Optional) Sets the data compression configuration for the file system. Valid values are `LZ4` and `NONE`. Default value is `NONE`. Unsetting this value reverts the compression type back to `NONE`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name of the file system.\n* `dns_name` - DNS name for the file system, e.g., `fs-12345678.fsx.us-west-2.amazonaws.com`\n* `id` - Identifier of the file system, e.g., `fs-12345678`\n* `network_interface_ids` - Set of Elastic Network Interface identifiers from which the file system is accessible. As explained in the [documentation](https://docs.aws.amazon.com/fsx/latest/LustreGuide/mounting-on-premises.html), the first network interface returned is the primary network interface.\n* `mount_name` - The value to be used when mounting the filesystem.\n* `owner_id` - AWS account identifier that created the file system.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` - Identifier of the Virtual Private Cloud for the file system.\n\n## Timeouts\n\n`aws_fsx_lustre_file_system` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `30m`) How long to wait for the file system to be created.\n* `update` - (Default `30m`) How long to wait for the file system to be updated.\n* `delete` - (Default `30m`) How long to wait for the file system to be deleted.\n\n## Import\n\nFSx File Systems can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_fsx_lustre_file_system.example fs-543ab12b1ca672f33\n```\n\nCertain resource arguments, like `security_group_ids`, do not have a FSx API method for reading the information after creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_fsx_lustre_file_system\" \"example\" {\n  # ... other configuration ...\n  security_group_ids = [aws_security_group.example.id]\n\n  # There is no FSx API for reading security_group_ids\n  lifecycle {\n    ignore_changes = [security_group_ids]\n  }\n}\n```\n",
    "basename": "fsx_lustre_file_system.html"
  },
  "fsx_ontap_file_system.html": {
    "subcategory": "File System (FSx)",
    "layout": "aws",
    "page_title": "AWS: aws_fsx_ontap_file_system",
    "description": "Manages an Amazon FSx for NetApp ONTAP file system.",
    "preview": "# Resource: aws_fsx_ontap_file_system\n\nManages an Amazon FSx for …",
    "content": "\n\n# Resource: aws_fsx_ontap_file_system\n\nManages an Amazon FSx for NetApp ONTAP file system.\nSee the [FSx ONTAP User Guide](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_fsx_ontap_file_system\" \"test\" {\n  storage_capacity    = 1024\n  subnet_ids          = [aws_subnet.test1.id, aws_subnet.test2.id]\n  deployment_type     = \"MULTI_AZ_1\"\n  throughput_capacity = 512\n  preferred_subnet_id = aws_subnet.test1.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `storage_capacity` - (Optional) The storage capacity (GiB) of the file system. Valid values between `1024` and `196608`.\n* `subnet_ids` - (Required) A list of IDs for the subnets that the file system will be accessible from. Exactly 2 subnets need to be provided.\n* `preferred_subnet_id` - (Required) The ID for a subnet. A subnet is a range of IP addresses in your virtual private cloud (VPC).\n* `security_group_ids` - (Optional) A list of IDs for the security groups that apply to the specified network interfaces created for file system access. These security groups will apply to all network interfaces.\n* `weekly_maintenance_start_time` - (Optional) The preferred start time (in `d:HH:MM` format) to perform weekly maintenance, in the UTC time zone.\n* `deployment_type` - (Optional) - The filesystem deployment type. Only `MULTI_AZ_1` is supported.\n* `kms_key_id` - (Optional) ARN for the KMS Key to encrypt the file system at rest, Defaults to an AWS managed KMS Key.\n* `automatic_backup_retention_days` - (Optional) The number of days to retain automatic backups. Setting this to 0 disables automatic backups. You can retain automatic backups for a maximum of 90 days.\n* `storage_type` - (Optional) - The filesystem storage type. defaults to `SSD`.\n* `daily_automatic_backup_start_time` - (Optional) A recurring daily time, in the format HH:MM. HH is the zero-padded hour of the day (0-23), and MM is the zero-padded minute of the hour. For example, 05:00 specifies 5 AM daily. Requires `automatic_backup_retention_days` to be set.\n* `disk_iops_configuration` - (Optional) The SSD IOPS configuration for the Amazon FSx for NetApp ONTAP file system. See [Disk Iops Configuration](#disk-iops-configuration) Below.\n* `endpoint_ip_address_range` - (Optional) Specifies the IP address range in which the endpoints to access your file system will be created. By default, Amazon FSx selects an unused IP address range for you from the 198.19.* range.\n* `storage_type` - (Optional) - The filesystem storage type. defaults to `SSD`.\n* `fsx_admin_password` - (Optional) The ONTAP administrative password for the fsxadmin user that you can use to administer your file system using the ONTAP CLI and REST API.\n* `route_table_ids` - (Optional) Specifies the VPC route tables in which your file system's endpoints will be created. You should specify all VPC route tables associated with the subnets in which your clients are located. By default, Amazon FSx selects your VPC's default route table.\n* `tags` - (Optional) A map of tags to assign to the file system. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Disk Iops Configuration\n\n* `iops` - (Optional) - The total number of SSD IOPS provisioned for the file system.\n* `mode` - (Optional) - Specifies whether the number of IOPS for the file system is using the system. Valid values are `AUTOMATIC` and `USER_PROVISIONED`. Default value is `AUTOMATIC`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name of the file system.\n* `dns_name` - DNS name for the file system, e.g., `fs-12345678.fsx.us-west-2.amazonaws.com`\n* `endpoints` - The endpoints that are used to access data or to manage the file system using the NetApp ONTAP CLI, REST API, or NetApp SnapMirror. See [Endpoints](#endpoints) below.\n* `id` - Identifier of the file system, e.g., `fs-12345678`\n* `network_interface_ids` - Set of Elastic Network Interface identifiers from which the file system is accessible The first network interface returned is the primary network interface.\n* `owner_id` - AWS account identifier that created the file system.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` - Identifier of the Virtual Private Cloud for the file system.\n\n### Endpoints\n\n* `intercluster` - An endpoint for managing your file system by setting up NetApp SnapMirror with other ONTAP systems. See [Endpoint](#endpoint).\n* `management` - An endpoint for managing your file system using the NetApp ONTAP CLI and NetApp ONTAP API. See [Endpoint](#endpoint).\n\n#### Endpoint\n\n* `dns_name` - The Domain Name Service (DNS) name for the file system. You can mount your file system using its DNS name.\n* `ip_addresses` - IP addresses of the file system endpoint.\n\n## Timeouts\n\n`aws_fsx_ontap_file_system` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `60m`) How long to wait for the file system to be created.\n* `update` - (Default `60m`) How long to wait for the file system to be updated.\n* `delete` - (Default `60m`) How long to wait for the file system to be deleted.\n\n## Import\n\nFSx File Systems can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_fsx_ontap_file_system.example fs-543ab12b1ca672f33\n```\n\nCertain resource arguments, like `security_group_ids`, do not have a FSx API method for reading the information after creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_fsx_ontap_file_system\" \"example\" {\n  # ... other configuration ...\n  security_group_ids = [aws_security_group.example.id]\n\n  # There is no FSx API for reading security_group_ids\n  lifecycle {\n    ignore_changes = [security_group_ids]\n  }\n}\n```\n",
    "basename": "fsx_ontap_file_system.html"
  },
  "fsx_ontap_storage_virtual_machine.html": {
    "subcategory": "File System (FSx)",
    "layout": "aws",
    "page_title": "AWS: aws_fsx_ontap_storage_virtual_machine",
    "description": "Manages a FSx Storage Virtual Machine.",
    "preview": "# Resource: aws_fsx_ontap_storage_virtual_machine\n\nManages a FSx …",
    "content": "\n\n# Resource: aws_fsx_ontap_storage_virtual_machine\n\nManages a FSx Storage Virtual Machine.\nSee the [FSx ONTAP User Guide](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/managing-svms.html) for more information.\n\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_fsx_ontap_storage_virtual_machine\" \"test\" {\n  file_system_id = aws_fsx_ontap_file_system.test.id\n  name           = \"test\"\n}\n```\n\n### Using a Self-Managed Microsoft Active Directory\n\nAdditional information for using AWS Directory Service with ONTAP File Systems can be found in the [FSx ONTAP Guide](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/self-managed-AD.html).\n\n```terraform\nresource \"aws_fsx_ontap_storage_virtual_machine\" \"test\" {\n  file_system_id = aws_fsx_ontap_file_system.test.id\n  name           = \"mysvm\"\n\n  active_directory_configuration {\n    netbios_name = \"mysvm\"\n    self_managed_active_directory_configuration {\n      dns_ips     = [\"10.0.0.111\", \"10.0.0.222\"]\n      domain_name = \"corp.example.com\"\n      password    = \"avoid-plaintext-passwords\"\n      username    = \"Admin\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `active_directory_configuration` - (Optional) Configuration block that Amazon FSx uses to join the FSx ONTAP Storage Virtual Machine(SVM) to your Microsoft Active Directory (AD) directory. Detailed below.\n* `file_system_id` - (Required) The ID of the Amazon FSx ONTAP File System that this SVM will be created on.\n* `name` - (Required) The name of the SVM. You can use a maximum of 47 alphanumeric characters, plus the underscore (_) special character.\n* `root_volume_security_style` - (Optional) Specifies the root volume security style, Valid values are `UNIX`, `NTFS`, and `MIXED`. All volumes created under this SVM will inherit the root security style unless the security style is specified on the volume. Default value is `UNIX`.\n* `tags` - (Optional) A map of tags to assign to the storage virtual machine. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### active_directory_configuration\n\nThe following arguments are supported for `active_directory_configuration` configuration block:\n\n* `netbios_name` - (Required) The NetBIOS name of the Active Directory computer object that will be created for your SVM. This is often the same as the SVM name but can be different. It is limited to 15 characters because of standard NetBIOS naming limits.\n* `self_managed_active_directory` - (Optional) Configuration block that Amazon FSx uses to join the SVM to your self-managed (including on-premises) Microsoft Active Directory (AD) directory.\n\n### self_managed_active_directory\n\nThe following arguments are supported for `self_managed_active_directory` configuration block:\n\n* `dns_ips` - (Required) A list of up to three IP addresses of DNS servers or domain controllers in the self-managed AD directory.\n* `domain_name` - (Required) The fully qualified domain name of the self-managed AD directory. For example, `corp.example.com`.\n* `password` - (Required) The password for the service account on your self-managed AD domain that Amazon FSx will use to join to your AD domain.\n* `username` - (Required) The user name for the service account on your self-managed AD domain that Amazon FSx will use to join to your AD domain.\n* `file_system_administrators_group` - (Optional) The name of the domain group whose members are granted administrative privileges for the SVM. The group that you specify must already exist in your domain. Defaults to `Domain Admins`.\n* `organizational_unit_distinguished_name` - (Optional) The fully qualified distinguished name of the organizational unit within your self-managed AD directory that the Windows File Server instance will join. For example, `OU=FSx,DC=yourdomain,DC=corp,DC=com`. Only accepts OU as the direct parent of the SVM. If none is provided, the SVM is created in the default location of your self-managed AD directory. To learn more, see [RFC 2253](https://tools.ietf.org/html/rfc2253).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name of the storage virtual machine.\n* `endpoints` - The endpoints that are used to access data or to manage the storage virtual machine using the NetApp ONTAP CLI, REST API, or NetApp SnapMirror. See [Endpoints](#endpoints) below.\n* `id` - Identifier of the storage virtual machine, e.g., `svm-12345678`\n* `subtype` - Describes the SVM's subtype, e.g. `DEFAULT`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `uuid` - The SVM's UUID (universally unique identifier).\n\n### Endpoints\n\n* `iscsi` - An endpoint for accessing data on your storage virtual machine via iSCSI protocol. See [Endpoint](#endpoint).\n* `management` - An endpoint for managing your file system using the NetApp ONTAP CLI and NetApp ONTAP API. See [Endpoint](#endpoint).\n* `nfs` - An endpoint for accessing data on your storage virtual machine via NFS protocol. See [Endpoint](#endpoint).\n* `smb` - An endpoint for accessing data on your storage virtual machine via SMB protocol. This is only set if an active_directory_configuration has been set. See [Endpoint](#endpoint).\n\n#### Endpoint\n\n* `dns_name` - The Domain Name Service (DNS) name for the storage virtual machine. You can mount your storage virtual machine using its DNS name.\n* `ip_addresses` - IP addresses of the storage virtual machine endpoint.\n\n## Timeouts\n\n`aws_fsx_ontap_storage_virtual_machine` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `30m`) How long to wait for the storage virtual machine to be created.\n* `delete` - (Default `30m`) How long to wait for the storage virtual machine to be deleted.\n* `update` - (Default `30m`) How long to wait for the storage virtual machine to be updated.\n\n## Import\n\nFSx Storage Virtual Machine can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_fsx_ontap_storage_virtual_machine.example svm-12345678abcdef123\n```\n\nCertain resource arguments, like `svm_admin_password` and the `self_managed_active_directory` configuation block `password`, do not have a FSx API method for reading the information after creation. If these arguments are set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_fsx_ontap_storage_virtual_machine\" \"example\" {\n  # ... other configuration ...\n\n  svm_admin_password = \"avoid-plaintext-passwords\"\n\n  # There is no FSx API for reading svm_admin_password\n  lifecycle {\n    ignore_changes = [svm_admin_password]\n  }\n}\n```\n",
    "basename": "fsx_ontap_storage_virtual_machine.html"
  },
  "fsx_ontap_volume.html": {
    "subcategory": "File System (FSx)",
    "layout": "aws",
    "page_title": "AWS: aws_fsx_ontap_volume",
    "description": "Manages a FSx ONTAP Volume.",
    "preview": "# Resource: aws_fsx_ontap_volume\n\nManages a FSx ONTAP Volume.\nSee …",
    "content": "\n\n# Resource: aws_fsx_ontap_volume\n\nManages a FSx ONTAP Volume.\nSee the [FSx ONTAP User Guide](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/managing-volumes.html) for more information.\n\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_fsx_ontap_volume\" \"test\" {\n  name                       = \"test\"\n  junction_path              = \"/test\"\n  size_in_megabytes          = 1024\n  storage_efficiency_enabled = true\n  storage_virtual_machine_id = aws_fsx_ontap_storage_virtual_machine.test.id\n}\n```\n\n### Using Tiering Policy\n\nAdditional information on tiering policy with ONTAP Volumes can be found in the [FSx ONTAP Guide](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/managing-volumes.html).\n\n```terraform\nresource \"aws_fsx_ontap_volume\" \"test\" {\n  name                       = \"test\"\n  junction_path              = \"/test\"\n  size_in_megabytes          = 1024\n  storage_efficiency_enabled = true\n  storage_virtual_machine_id = aws_fsx_ontap_storage_virtual_machine.test.id\n\n  tiering_policy {\n    name           = \"AUTO\"\n    cooling_period = 31\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Volume. You can use a maximum of 203 alphanumeric characters, plus the underscore (_) special character.\n* `junction_path` - (Required) Specifies the location in the storage virtual machine's namespace where the volume is mounted. The junction_path must have a leading forward slash, such as `/vol3`\n* `security_style` - (Optional) Specifies the volume security style, Valid values are `UNIX`, `NTFS`, and `MIXED`. Default value is `UNIX`.\n* `size_in_megabytes` - (Required) Specifies the size of the volume, in megabytes (MB), that you are creating.\n* `storage_efficiency_enabled` - (Required) Set to true to enable deduplication, compression, and compaction storage efficiency features on the volume.\n* `storage_virtual_machine_id` - (Required) Specifies the storage virtual machine in which to create the volume.\n* `tags` - (Optional) A map of tags to assign to the volume. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### tiering_policy\n\nThe following arguments are supported for `tiering_policy` configuration block:\n\n* `name` - (Required) Specifies the tiering policy for the ONTAP volume for moving data to the capacity pool storage. Valid values are `SNAPSHOT_ONLY`, `AUTO`, `ALL`, `NONE`. Default value is `SNAPSHOT_ONLY`.\n* `cooling_policy` - (Optional) Specifies the number of days that user data in a volume must remain inactive before it is considered \"cold\" and moved to the capacity pool. Used with `AUTO` and `SNAPSHOT_ONLY` tiering policies only. Valid values are whole numbers between 2 and 183. Default values are 31 days for `AUTO` and 2 days for `SNAPSHOT_ONLY`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name of the volune.\n* `id` - Identifier of the volume, e.g., `fsvol-12345678`\n* `file_system_id` - Describes the file system for the volume, e.g. `fs-12345679`\n* `flexcache_endpoint_type` - Specifies the FlexCache endpoint type of the volume, Valid values are `NONE`, `ORIGIN`, `CACHE`. Default value is `NONE`. These can be set by the ONTAP CLI or API and are use with FlexCache feature.\n* `ontap_volume_type` - Specifies the type of volume, Valid values are `RW`, `DP`,  and `LS`. Default value is `RW`. These can be set by the ONTAP CLI or API. This setting is used as part of migration and replication [Migrating to Amazon FSx for NetApp ONTAP](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/migrating-fsx-ontap.html)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `uuid` - The Volume's UUID (universally unique identifier).\n* `volume_type` - The type of volume, currently the only valid value is `ONTAP`.\n\n## Timeouts\n\n`aws_fsx_ontap_volume` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `30m`) How long to wait for the storage virtual machine to be created.\n* `delete` - (Default `30m`) How long to wait for the storage virtual machine to be deleted.\n* `update` - (Default `30m`) How long to wait for the storage virtual machine to be updated.\n\n## Import\n\nFSx ONTAP volume can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_fsx_ontap_volume.example fsvol-12345678abcdef123\n```",
    "basename": "fsx_ontap_volume.html"
  },
  "fsx_windows_file_system.html": {
    "subcategory": "File System (FSx)",
    "layout": "aws",
    "page_title": "AWS: aws_fsx_windows_file_system",
    "description": "Manages a FSx Windows File System.",
    "preview": "# Resource: aws_fsx_windows_file_system\n\nManages a FSx Windows File …",
    "content": "\n\n# Resource: aws_fsx_windows_file_system\n\nManages a FSx Windows File System. See the [FSx Windows Guide](https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html) for more information.\n\n~> **NOTE:** Either the `active_directory_id` argument or `self_managed_active_directory` configuration block must be specified.\n\n## Example Usage\n\n### Using AWS Directory Service\n\nAdditional information for using AWS Directory Service with Windows File Systems can be found in the [FSx Windows Guide](https://docs.aws.amazon.com/fsx/latest/WindowsGuide/fsx-aws-managed-ad.html).\n\n```terraform\nresource \"aws_fsx_windows_file_system\" \"example\" {\n  active_directory_id = aws_directory_service_directory.example.id\n  kms_key_id          = aws_kms_key.example.arn\n  storage_capacity    = 300\n  subnet_ids          = [aws_subnet.example.id]\n  throughput_capacity = 1024\n}\n```\n\n### Using a Self-Managed Microsoft Active Directory\n\nAdditional information for using AWS Directory Service with Windows File Systems can be found in the [FSx Windows Guide](https://docs.aws.amazon.com/fsx/latest/WindowsGuide/self-managed-AD.html).\n\n```terraform\nresource \"aws_fsx_windows_file_system\" \"example\" {\n  kms_key_id          = aws_kms_key.example.arn\n  storage_capacity    = 300\n  subnet_ids          = [aws_subnet.example.id]\n  throughput_capacity = 1024\n\n  self_managed_active_directory {\n    dns_ips     = [\"10.0.0.111\", \"10.0.0.222\"]\n    domain_name = \"corp.example.com\"\n    password    = \"avoid-plaintext-passwords\"\n    username    = \"Admin\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `storage_capacity` - (Optional) Storage capacity (GiB) of the file system. Minimum of 32 and maximum of 65536. If the storage type is set to `HDD` the minimum value is 2000. Required when not creating filesystem for a backup.\n* `subnet_ids` - (Required) A list of IDs for the subnets that the file system will be accessible from. To specify more than a single subnet set `deployment_type` to `MULTI_AZ_1`.\n* `throughput_capacity` - (Required) Throughput (megabytes per second) of the file system in power of 2 increments. Minimum of `8` and maximum of `2048`.\n* `backup_id` - (Optional) The ID of the source backup to create the filesystem from.\n* `active_directory_id` - (Optional) The ID for an existing Microsoft Active Directory instance that the file system should join when it's created. Cannot be specified with `self_managed_active_directory`.\n* `aliases` - (Optional) An array DNS alias names that you want to associate with the Amazon FSx file system.  For more information, see [Working with DNS Aliases](https://docs.aws.amazon.com/fsx/latest/WindowsGuide/managing-dns-aliases.html)\n* `automatic_backup_retention_days` - (Optional) The number of days to retain automatic backups. Minimum of `0` and maximum of `90`. Defaults to `7`. Set to `0` to disable.\n* `copy_tags_to_backups` - (Optional) A boolean flag indicating whether tags on the file system should be copied to backups. Defaults to `false`.\n* `daily_automatic_backup_start_time` - (Optional) The preferred time (in `HH:MM` format) to take daily automatic backups, in the UTC time zone.\n* `kms_key_id` - (Optional) ARN for the KMS Key to encrypt the file system at rest. Defaults to an AWS managed KMS Key.\n* `security_group_ids` - (Optional) A list of IDs for the security groups that apply to the specified network interfaces created for file system access. These security groups will apply to all network interfaces.\n* `self_managed_active_directory` - (Optional) Configuration block that Amazon FSx uses to join the Windows File Server instance to your self-managed (including on-premises) Microsoft Active Directory (AD) directory. Cannot be specified with `active_directory_id`. Detailed below.\n* `skip_final_backup` - (Optional) When enabled, will skip the default final backup taken when the file system is deleted. This configuration must be applied separately before attempting to delete the resource to have the desired behavior. Defaults to `false`.\n* `tags` - (Optional) A map of tags to assign to the file system. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `weekly_maintenance_start_time` - (Optional) The preferred start time (in `d:HH:MM` format) to perform weekly maintenance, in the UTC time zone.\n* `deployment_type` - (Optional) Specifies the file system deployment type, valid values are `MULTI_AZ_1`, `SINGLE_AZ_1` and `SINGLE_AZ_2`. Default value is `SINGLE_AZ_1`.\n* `preferred_subnet_id` - (Optional) Specifies the subnet in which you want the preferred file server to be located. Required for when deployment type is `MULTI_AZ_1`.\n* `audit_log_configuration` - (Optional) The configuration that Amazon FSx for Windows File Server uses to audit and log user accesses of files, folders, and file shares on the Amazon FSx for Windows File Server file system. See below.\n* `storage_type` - (Optional) Specifies the storage type, Valid values are `SSD` and `HDD`. `HDD` is supported on `SINGLE_AZ_2` and `MULTI_AZ_1` Windows file system deployment types. Default value is `SSD`.\n\n### self_managed_active_directory\n\nThe following arguments are supported for `self_managed_active_directory` configuration block:\n\n* `dns_ips` - (Required) A list of up to two IP addresses of DNS servers or domain controllers in the self-managed AD directory. The IP addresses need to be either in the same VPC CIDR range as the file system or in the private IP version 4 (IPv4) address ranges as specified in [RFC 1918](https://tools.ietf.org/html/rfc1918).\n* `domain_name` - (Required) The fully qualified domain name of the self-managed AD directory. For example, `corp.example.com`.\n* `password` - (Required) The password for the service account on your self-managed AD domain that Amazon FSx will use to join to your AD domain.\n* `username` - (Required) The user name for the service account on your self-managed AD domain that Amazon FSx will use to join to your AD domain.\n* `file_system_administrators_group` - (Optional) The name of the domain group whose members are granted administrative privileges for the file system. Administrative privileges include taking ownership of files and folders, and setting audit controls (audit ACLs) on files and folders. The group that you specify must already exist in your domain. Defaults to `Domain Admins`.\n* `organizational_unit_distinguished_name` - (Optional) The fully qualified distinguished name of the organizational unit within your self-managed AD directory that the Windows File Server instance will join. For example, `OU=FSx,DC=yourdomain,DC=corp,DC=com`. Only accepts OU as the direct parent of the file system. If none is provided, the FSx file system is created in the default location of your self-managed AD directory. To learn more, see [RFC 2253](https://tools.ietf.org/html/rfc2253).\n\n### audit_log_configuration\n\n* `audit_log_destination` - (Optional) The Amazon Resource Name (ARN) for the destination of the audit logs. The destination can be any Amazon CloudWatch Logs log group ARN or Amazon Kinesis Data Firehose delivery stream ARN. Can be specified when `file_access_audit_log_level` and `file_share_access_audit_log_level` are not set to `DISABLED`. The name of the Amazon CloudWatch Logs log group must begin with the `/aws/fsx` prefix. The name of the Amazon Kinesis Data Firehouse delivery stream must begin with the `aws-fsx` prefix. If you do not provide a destination in `audit_log_destionation`, Amazon FSx will create and use a log stream in the CloudWatch Logs /aws/fsx/windows log group.\n* `file_access_audit_log_level` - (Optional) Sets which attempt type is logged by Amazon FSx for file and folder accesses. Valid values are `SUCCESS_ONLY`, `FAILURE_ONLY`, `SUCCESS_AND_FAILURE`, and `DISABLED`. Default value is `DISABLED`.\n* `file_share_access_audit_log_level` - (Optional) Sets which attempt type is logged by Amazon FSx for file share accesses. Valid values are `SUCCESS_ONLY`, `FAILURE_ONLY`, `SUCCESS_AND_FAILURE`, and `DISABLED`. Default value is `DISABLED`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name of the file system.\n* `dns_name` - DNS name for the file system, e.g., `fs-12345678.corp.example.com` (domain name matching the Active Directory domain name)\n* `id` - Identifier of the file system, e.g., `fs-12345678`\n* `network_interface_ids` - Set of Elastic Network Interface identifiers from which the file system is accessible.\n* `owner_id` - AWS account identifier that created the file system.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `vpc_id` - Identifier of the Virtual Private Cloud for the file system.\n* `preferred_file_server_ip` - The IP address of the primary, or preferred, file server.\n* `remote_administration_endpoint` - For `MULTI_AZ_1` deployment types, use this endpoint when performing administrative tasks on the file system using Amazon FSx Remote PowerShell. For `SINGLE_AZ_1` deployment types, this is the DNS name of the file system.\n\n## Timeouts\n\n`aws_fsx_windows_file_system` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n* `create` - (Default `45m`) How long to wait for the file system to be created.\n* `delete` - (Default `30m`) How long to wait for the file system to be deleted.\n* `update` - (Default `45m`) How long to wait for the file system to be updated.\n\n## Import\n\nFSx File Systems can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_fsx_windows_file_system.example fs-543ab12b1ca672f33\n```\n\nCertain resource arguments, like `security_group_ids` and the `self_managed_active_directory` configuation block `password`, do not have a FSx API method for reading the information after creation. If these arguments are set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_fsx_windows_file_system\" \"example\" {\n  # ... other configuration ...\n\n  security_group_ids = [aws_security_group.example.id]\n\n  # There is no FSx API for reading security_group_ids\n  lifecycle {\n    ignore_changes = [security_group_ids]\n  }\n}\n```\n",
    "basename": "fsx_windows_file_system.html"
  },
  "gamelift_alias.html": {
    "subcategory": "Gamelift",
    "layout": "aws",
    "page_title": "AWS: aws_gamelift_alias",
    "description": "Provides a Gamelift Alias resource.",
    "preview": "# Resource: aws_gamelift_alias\n\nProvides a Gamelift Alias resource.\n …",
    "content": "\n\n# Resource: aws_gamelift_alias\n\nProvides a Gamelift Alias resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_gamelift_alias\" \"example\" {\n  name        = \"example-alias\"\n  description = \"Example Description\"\n\n  routing_strategy {\n    message = \"Example Message\"\n    type    = \"TERMINAL\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the alias.\n* `description` - (Optional) Description of the alias.\n* `routing_strategy` - (Required) Specifies the fleet and/or routing type to use for the alias.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Nested Fields\n\n#### `routing_strategy`\n\n* `fleet_id` - (Optional) ID of the Gamelift Fleet to point the alias to.\n* `message` - (Optional) Message text to be used with the `TERMINAL` routing strategy.\n* `type` - (Required) Type of routing strategyE.g., `SIMPLE` or `TERMINAL`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Alias ID.\n* `arn` - Alias ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGamelift Aliases can be imported using the ID, e.g.,\n\n```\n$ terraform import aws_gamelift_alias.example <alias-id>\n```\n",
    "basename": "gamelift_alias.html"
  },
  "gamelift_build.html": {
    "subcategory": "Gamelift",
    "layout": "aws",
    "page_title": "AWS: aws_gamelift_build",
    "description": "Provides a Gamelift Build resource.",
    "preview": "# Resource: aws_gamelift_build\n\nProvides an Gamelift Build resource. …",
    "content": "\n\n# Resource: aws_gamelift_build\n\nProvides an Gamelift Build resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_gamelift_build\" \"test\" {\n  name             = \"example-build\"\n  operating_system = \"WINDOWS_2012\"\n\n  storage_location {\n    bucket   = aws_s3_bucket.test.bucket\n    key      = aws_s3_bucket_object.test.key\n    role_arn = aws_iam_role.test.arn\n  }\n\n  depends_on = [aws_iam_role_policy.test]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the build\n* `operating_system` - (Required) Operating system that the game server binaries are built to run onE.g., `WINDOWS_2012`, `AMAZON_LINUX` or `AMAZON_LINUX_2`.\n* `storage_location` - (Required) Information indicating where your game build files are stored. See below.\n* `version` - (Optional) Version that is associated with this build.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Nested Fields\n\n#### `storage_location`\n\n* `bucket` - (Required) Name of your S3 bucket.\n* `key` - (Required) Name of the zip file containing your build files.\n* `role_arn` - (Required) ARN of the access role that allows Amazon GameLift to access your S3 bucket.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Gamelift Build ID.\n* `arn` - Gamelift Build ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGamelift Builds cannot be imported at this time.\n",
    "basename": "gamelift_build.html"
  },
  "gamelift_fleet.html": {
    "subcategory": "Gamelift",
    "layout": "aws",
    "page_title": "AWS: aws_gamelift_fleet",
    "description": "Provides a Gamelift Fleet resource.",
    "preview": "# Resource: aws_gamelift_fleet\n\nProvides a Gamelift Fleet resource.\n …",
    "content": "\n\n# Resource: aws_gamelift_fleet\n\nProvides a Gamelift Fleet resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_gamelift_fleet\" \"example\" {\n  build_id          = aws_gamelift_build.example.id\n  ec2_instance_type = \"t2.micro\"\n  fleet_type        = \"ON_DEMAND\"\n  name              = \"example-fleet-name\"\n\n  runtime_configuration {\n    server_process {\n      concurrent_executions = 1\n      launch_path           = \"C:\\\\game\\\\GomokuServer.exe\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `build_id` - (Required) ID of the Gamelift Build to be deployed on the fleet.\n* `description` - (Optional) Human-readable description of the fleet.\n* `ec2_inbound_permission` - (Optional) Range of IP addresses and port settings that permit inbound traffic to access server processes running on the fleet. See below.\n* `ec2_instance_type` - (Required) Name of an EC2 instance typeE.g., `t2.micro`\n* `fleet_type` - (Optional) Type of fleet. This value must be `ON_DEMAND` or `SPOT`. Defaults to `ON_DEMAND`.\n* `instance_role_arn` - (Optional) ARN of an IAM role that instances in the fleet can assume.\n* `metric_groups` - (Optional) List of names of metric groups to add this fleet to. A metric group tracks metrics across all fleets in the group. Defaults to `default`.\n* `name` - (Required) The name of the fleet.\n* `new_game_session_protection_policy` - (Optional) Game session protection policy to apply to all instances in this fleetE.g., `FullProtection`. Defaults to `NoProtection`.\n* `resource_creation_limit_policy` - (Optional) Policy that limits the number of game sessions an individual player can create over a span of time for this fleet. See below.\n* `runtime_configuration` - (Optional) Instructions for launching server processes on each instance in the fleet. See below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Nested Fields\n\n#### `ec2_inbound_permission`\n\n* `from_port` - (Required) Starting value for a range of allowed port numbers.\n* `ip_range` - (Required) Range of allowed IP addresses expressed in CIDR notationE.g., `000.000.000.000/[subnet mask]` or `0.0.0.0/[subnet mask]`.\n* `protocol` - (Required) Network communication protocol used by the fleetE.g., `TCP` or `UDP`\n* `to_port` - (Required) Ending value for a range of allowed port numbers. Port numbers are end-inclusive. This value must be higher than `from_port`.\n\n#### `resource_creation_limit_policy`\n\n* `new_game_sessions_per_creator` - (Optional) Maximum number of game sessions that an individual can create during the policy period.\n* `policy_period_in_minutes` - (Optional) Time span used in evaluating the resource creation limit policy.\n\n#### `runtime_configuration`\n\n* `game_session_activation_timeout_seconds` - (Optional) Maximum amount of time (in seconds) that a game session can remain in status `ACTIVATING`.\n* `max_concurrent_game_session_activations` - (Optional) Maximum number of game sessions with status `ACTIVATING` to allow on an instance simultaneously.\n* `server_process` - (Optional) Collection of server process configurations that describe which server processes to run on each instance in a fleet. See below.\n\n#### `server_process`\n\n* `concurrent_executions` - (Required) Number of server processes using this configuration to run concurrently on an instance.\n* `launch_path` - (Required) Location of the server executable in a game build. All game builds are installed on instances at the root : for Windows instances `C:\\game`, and for Linux instances `/local/game`.\n* `parameters` - (Optional) Optional list of parameters to pass to the server executable on launch.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Fleet ID.\n* `arn` - Fleet ARN.\n* `operating_system` - Operating system of the fleet's computing resources.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_gamelift_fleet` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `70m`) How long to wait for a fleet to be created.\n* `delete` - (Default `20m`) How long to wait for a fleet to be deleted.\n\n## Import\n\nGamelift Fleets cannot be imported at this time.\n",
    "basename": "gamelift_fleet.html"
  },
  "gamelift_game_session_queue.html": {
    "subcategory": "Gamelift",
    "layout": "aws",
    "page_title": "AWS: aws_gamelift_game_session_queue",
    "description": "Provides a Gamelift Game Session Queue resource.",
    "preview": "# Resource: aws_gamelift_game_session_queue\n\nProvides an Gamelift …",
    "content": "\n\n# Resource: aws_gamelift_game_session_queue\n\nProvides an Gamelift Game Session Queue resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_gamelift_game_session_queue\" \"test\" {\n  name = \"example-session-queue\"\n\n  destinations = [\n    aws_gamelift_fleet.us_west_2_fleet.arn,\n    aws_gamelift_fleet.eu_central_1_fleet.arn,\n  ]\n\n  player_latency_policy {\n    maximum_individual_player_latency_milliseconds = 100\n    policy_duration_seconds                        = 5\n  }\n\n  player_latency_policy {\n    maximum_individual_player_latency_milliseconds = 200\n  }\n\n  timeout_in_seconds = 60\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the session queue.\n* `timeout_in_seconds` - (Required) Maximum time a game session request can remain in the queue.\n* `destinations` - (Optional) List of fleet/alias ARNs used by session queue for placing game sessions.\n* `player_latency_policy` - (Optional) One or more policies used to choose fleet based on player latency. See below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Nested Fields\n\n#### `player_latency_policy`\n\n* `maximum_individual_player_latency_milliseconds` - (Required) Maximum latency value that is allowed for any player.\n* `policy_duration_seconds` - (Optional) Length of time that the policy is enforced while placing a new game session. Absence of value for this attribute means that the policy is enforced until the queue times out.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Game Session Queue ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGamelift Game Session Queues can be imported by their `name`, e.g.,\n\n```\n$ terraform import aws_gamelift_game_session_queue.example example\n```\n",
    "basename": "gamelift_game_session_queue.html"
  },
  "glacier_vault.html": {
    "subcategory": "Glacier",
    "layout": "aws",
    "page_title": "AWS: aws_glacier_vault",
    "description": "Provides a Glacier Vault.",
    "preview": "# Resource: aws_glacier_vault\n\nProvides a Glacier Vault Resource. …",
    "content": "\n\n# Resource: aws_glacier_vault\n\nProvides a Glacier Vault Resource. You can refer to the [Glacier Developer Guide](https://docs.aws.amazon.com/amazonglacier/latest/dev/working-with-vaults.html) for a full explanation of the Glacier Vault functionality\n\n~> **NOTE:** When removing a Glacier Vault, the Vault must be empty.\n\n## Example Usage\n\n```terraform\nresource \"aws_sns_topic\" \"aws_sns_topic\" {\n  name = \"glacier-sns-topic\"\n}\n\nresource \"aws_glacier_vault\" \"my_archive\" {\n  name = \"MyArchive\"\n\n  notification {\n    sns_topic = aws_sns_topic.aws_sns_topic.arn\n    events    = [\"ArchiveRetrievalCompleted\", \"InventoryRetrievalCompleted\"]\n  }\n\n  access_policy = <<EOF\n{\n    \"Version\":\"2012-10-17\",\n    \"Statement\":[\n       {\n          \"Sid\": \"add-read-only-perm\",\n          \"Principal\": \"*\",\n          \"Effect\": \"Allow\",\n          \"Action\": [\n             \"glacier:InitiateJob\",\n             \"glacier:GetJobOutput\"\n          ],\n          \"Resource\": \"arn:aws:glacier:eu-west-1:432981146916:vaults/MyArchive\"\n       }\n    ]\n}\nEOF\n\n  tags = {\n    Test = \"MyArchive\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Vault. Names can be between 1 and 255 characters long and the valid characters are a-z, A-Z, 0-9, '_' (underscore), '-' (hyphen), and '.' (period).\n* `access_policy` - (Optional) The policy document. This is a JSON formatted string.\n  The heredoc syntax or `file` function is helpful here. Use the [Glacier Developer Guide](https://docs.aws.amazon.com/amazonglacier/latest/dev/vault-access-policy.html) for more information on Glacier Vault Policy\n* `notification` - (Optional) The notifications for the Vault. Fields documented below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n**notification** supports the following:\n\n* `events` - (Required) You can configure a vault to publish a notification for `ArchiveRetrievalCompleted` and `InventoryRetrievalCompleted` events.\n* `sns_topic` - (Required) The SNS Topic ARN.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `location` - The URI of the vault that was created.\n* `arn` - The ARN of the vault.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGlacier Vaults can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_glacier_vault.archive my_archive\n```\n",
    "basename": "glacier_vault.html"
  },
  "glacier_vault_lock.html": {
    "subcategory": "Glacier",
    "layout": "aws",
    "page_title": "AWS: aws_glacier_vault_lock",
    "description": "Manages a Glacier Vault Lock.",
    "preview": "# Resource: aws_glacier_vault_lock\n\nManages a Glacier Vault Lock. …",
    "content": "\n\n# Resource: aws_glacier_vault_lock\n\nManages a Glacier Vault Lock. You can refer to the [Glacier Developer Guide](https://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock.html) for a full explanation of the Glacier Vault Lock functionality.\n\n~> **NOTE:** This resource allows you to test Glacier Vault Lock policies by setting the `complete_lock` argument to `false`. When testing policies in this manner, the Glacier Vault Lock automatically expires after 24 hours and Terraform will show this resource as needing recreation after that time. To permanently apply the policy, set the `complete_lock` argument to `true`. When changing `complete_lock` to `true`, it is expected the resource will show as recreating.\n\n!> **WARNING:** Once a Glacier Vault Lock is completed, it is immutable. The deletion of the Glacier Vault Lock is not be possible and attempting to remove it from Terraform will return an error. Set the `ignore_deletion_error` argument to `true` and apply this configuration before attempting to delete this resource via Terraform or use `terraform state rm` to remove this resource from Terraform management.\n\n## Example Usage\n\n### Testing Glacier Vault Lock Policy\n\n```terraform\nresource \"aws_glacier_vault\" \"example\" {\n  name = \"example\"\n}\n\ndata \"aws_iam_policy_document\" \"example\" {\n  statement {\n    actions   = [\"glacier:DeleteArchive\"]\n    effect    = \"Deny\"\n    resources = [aws_glacier_vault.example.arn]\n\n    condition {\n      test     = \"NumericLessThanEquals\"\n      variable = \"glacier:ArchiveAgeinDays\"\n      values   = [\"365\"]\n    }\n  }\n}\n\nresource \"aws_glacier_vault_lock\" \"example\" {\n  complete_lock = false\n  policy        = data.aws_iam_policy_document.example.json\n  vault_name    = aws_glacier_vault.example.name\n}\n```\n\n### Permanently Applying Glacier Vault Lock Policy\n\n```terraform\nresource \"aws_glacier_vault_lock\" \"example\" {\n  complete_lock = true\n  policy        = data.aws_iam_policy_document.example.json\n  vault_name    = aws_glacier_vault.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `complete_lock` - (Required) Boolean whether to permanently apply this Glacier Lock Policy. Once completed, this cannot be undone. If set to `false`, the Glacier Lock Policy remains in a testing mode for 24 hours. After that time, the Glacier Lock Policy is automatically removed by Glacier and the Terraform resource will show as needing recreation. Changing this from `false` to `true` will show as resource recreation, which is expected. Changing this from `true` to `false` is not possible unless the Glacier Vault is recreated at the same time.\n* `policy` - (Required) JSON string containing the IAM policy to apply as the Glacier Vault Lock policy.\n* `vault_name` - (Required) The name of the Glacier Vault.\n* `ignore_deletion_error` - (Optional) Allow Terraform to ignore the error returned when attempting to delete the Glacier Lock Policy. This can be used to delete or recreate the Glacier Vault via Terraform, for example, if the Glacier Vault Lock policy permits that action. This should only be used in conjunction with `complete_lock` being set to `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Glacier Vault name.\n\n## Import\n\nGlacier Vault Locks can be imported using the Glacier Vault name, e.g.,\n\n```\n$ terraform import aws_glacier_vault_lock.example example-vault\n```\n",
    "basename": "glacier_vault_lock.html"
  },
  "globalaccelerator_accelerator.html": {
    "subcategory": "Global Accelerator",
    "layout": "aws",
    "page_title": "AWS: aws_globalaccelerator_accelerator",
    "description": "Provides a Global Accelerator accelerator.",
    "preview": "# Resource: aws_globalaccelerator_accelerator\n\nCreates a Global …",
    "content": "\n\n# Resource: aws_globalaccelerator_accelerator\n\nCreates a Global Accelerator accelerator.\n\n## Example Usage\n\n```terraform\nresource \"aws_globalaccelerator_accelerator\" \"example\" {\n  name            = \"Example\"\n  ip_address_type = \"IPV4\"\n  enabled         = true\n\n  attributes {\n    flow_logs_enabled   = true\n    flow_logs_s3_bucket = \"example-bucket\"\n    flow_logs_s3_prefix = \"flow-logs/\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the accelerator.\n* `ip_address_type` - (Optional) The value for the address type. Defaults to `IPV4`. Valid values: `IPV4`.\n* `enabled` - (Optional) Indicates whether the accelerator is enabled. Defaults to `true`. Valid values: `true`, `false`.\n* `attributes` - (Optional) The attributes of the accelerator. Fields documented below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n**attributes** supports the following attributes:\n\n* `flow_logs_enabled` - (Optional) Indicates whether flow logs are enabled. Defaults to `false`. Valid values: `true`, `false`.\n* `flow_logs_s3_bucket` - (Optional) The name of the Amazon S3 bucket for the flow logs. Required if `flow_logs_enabled` is `true`.\n* `flow_logs_s3_prefix` - (Optional) The prefix for the location in the Amazon S3 bucket for the flow logs. Required if `flow_logs_enabled` is `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the accelerator.\n* `dns_name` - The DNS name of the accelerator. For example, `a5d53ff5ee6bca4ce.awsglobalaccelerator.com`.\n* `hosted_zone_id` --  The Global Accelerator Route 53 zone ID that can be used to\n  route an [Alias Resource Record Set][1] to the Global Accelerator. This attribute\n  is simply an alias for the zone ID `Z2BJ6XQ5FK7U4H`.\n* `ip_sets` - IP address set associated with the accelerator.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n**ip_sets** exports the following attributes:\n\n* `ip_addresses` - A list of IP addresses in the IP address set.\n* `ip_family` - The type of IP addresses included in this IP set.\n\n[1]: https://docs.aws.amazon.com/Route53/latest/APIReference/API_AliasTarget.html\n\n## Timeouts\n\n`aws_globalaccelerator_accelerator` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `30 minutes`) How long to wait for the Global Accelerator Accelerator to be created.\n* `update` - (Default `30 minutes`) How long to wait for the Global Accelerator Accelerator to be updated.\n\n## Import\n\nGlobal Accelerator accelerators can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_globalaccelerator_accelerator.example arn:aws:globalaccelerator::111111111111:accelerator/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n```\n",
    "basename": "globalaccelerator_accelerator.html"
  },
  "globalaccelerator_endpoint_group.html": {
    "subcategory": "Global Accelerator",
    "layout": "aws",
    "page_title": "AWS: aws_globalaccelerator_endpoint_group",
    "description": "Provides a Global Accelerator endpoint group.",
    "preview": "# Resource: aws_globalaccelerator_endpoint_group\n\nProvides a Global …",
    "content": "\n\n# Resource: aws_globalaccelerator_endpoint_group\n\nProvides a Global Accelerator endpoint group.\n\n## Example Usage\n\n```terraform\nresource \"aws_globalaccelerator_endpoint_group\" \"example\" {\n  listener_arn = aws_globalaccelerator_listener.example.id\n\n  endpoint_configuration {\n    endpoint_id = aws_lb.example.arn\n    weight      = 100\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `listener_arn` - (Required) The Amazon Resource Name (ARN) of the listener.\n* `endpoint_group_region` (Optional) - The name of the AWS Region where the endpoint group is located.\n* `health_check_interval_seconds` - (Optional) The time—10 seconds or 30 seconds—between each health check for an endpoint. The default value is 30.\n* `health_check_path` - (Optional) If the protocol is HTTP/S, then this specifies the path that is the destination for health check targets. The default value is slash (`/`). Terraform will only perform drift detection of its value when present in a configuration.\n* `health_check_port` - (Optional) The port that AWS Global Accelerator uses to check the health of endpoints that are part of this endpoint group. The default port is the listener port that this endpoint group is associated with. If listener port is a list of ports, Global Accelerator uses the first port in the list.\nTerraform will only perform drift detection of its value when present in a configuration.\n* `health_check_protocol` - (Optional) The protocol that AWS Global Accelerator uses to check the health of endpoints that are part of this endpoint group. The default value is TCP.\n* `threshold_count` - (Optional) The number of consecutive health checks required to set the state of a healthy endpoint to unhealthy, or to set an unhealthy endpoint to healthy. The default value is 3.\n* `traffic_dial_percentage` - (Optional) The percentage of traffic to send to an AWS Region. Additional traffic is distributed to other endpoint groups for this listener. The default value is 100.\n* `endpoint_configuration` - (Optional) The list of endpoint objects. Fields documented below.\n* `port_override` - (Optional) Override specific listener ports used to route traffic to endpoints that are part of this endpoint group. Fields documented below.\n\n**endpoint_configuration** supports the following attributes:\n\n* `client_ip_preservation_enabled` - (Optional) Indicates whether client IP address preservation is enabled for an Application Load Balancer endpoint. See the [AWS documentation](https://docs.aws.amazon.com/global-accelerator/latest/dg/preserve-client-ip-address.html) for more details. The default value is `false`.\n**Note:** When client IP address preservation is enabled, the Global Accelerator service creates an EC2 Security Group in the VPC named `GlobalAccelerator` that must be deleted (potentially outside of Terraform) before the VPC will successfully delete. If this EC2 Security Group is not deleted, Terraform will retry the VPC deletion for a few minutes before reporting a `DependencyViolation` error. This cannot be resolved by re-running Terraform.\n* `endpoint_id` - (Optional) An ID for the endpoint. If the endpoint is a Network Load Balancer or Application Load Balancer, this is the Amazon Resource Name (ARN) of the resource. If the endpoint is an Elastic IP address, this is the Elastic IP address allocation ID.\n* `weight` - (Optional) The weight associated with the endpoint. When you add weights to endpoints, you configure AWS Global Accelerator to route traffic based on proportions that you specify.\n\n**port_override** supports the following attributes:\n\n* `endpoint_port` - (Required) The endpoint port that you want a listener port to be mapped to. This is the port on the endpoint, such as the Application Load Balancer or Amazon EC2 instance.\n* `listener_port` - (Required) The listener port that you want to map to a specific endpoint port. This is the port that user traffic arrives to the Global Accelerator on.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the endpoint group.\n* `arn` - The Amazon Resource Name (ARN) of the endpoint group.\n\n## Timeouts\n\n`aws_globalaccelerator_endpoint_group` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `30 minutes`) How long to wait for the Global Accelerator Endpoint Group to be created.\n* `update` - (Default `30 minutes`) How long to wait for the Global Accelerator Endpoint Group to be updated.\n* `delete` - (Default `30 minutes`) How long to wait for the Global Accelerator Endpoint Group to be deleted.\n\n## Import\n\nGlobal Accelerator endpoint groups can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_globalaccelerator_endpoint_group.example arn:aws:globalaccelerator::111111111111:accelerator/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/listener/xxxxxxx/endpoint-group/xxxxxxxx\n```\n",
    "basename": "globalaccelerator_endpoint_group.html"
  },
  "globalaccelerator_listener.html": {
    "subcategory": "Global Accelerator",
    "layout": "aws",
    "page_title": "AWS: aws_globalaccelerator_listener",
    "description": "Provides a Global Accelerator listener.",
    "preview": "# Resource: aws_globalaccelerator_listener\n\nProvides a Global …",
    "content": "\n\n# Resource: aws_globalaccelerator_listener\n\nProvides a Global Accelerator listener.\n\n## Example Usage\n\n```terraform\nresource \"aws_globalaccelerator_accelerator\" \"example\" {\n  name            = \"Example\"\n  ip_address_type = \"IPV4\"\n  enabled         = true\n\n  attributes {\n    flow_logs_enabled   = true\n    flow_logs_s3_bucket = \"example-bucket\"\n    flow_logs_s3_prefix = \"flow-logs/\"\n  }\n}\n\nresource \"aws_globalaccelerator_listener\" \"example\" {\n  accelerator_arn = aws_globalaccelerator_accelerator.example.id\n  client_affinity = \"SOURCE_IP\"\n  protocol        = \"TCP\"\n\n  port_range {\n    from_port = 80\n    to_port   = 80\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `accelerator_arn` - (Required) The Amazon Resource Name (ARN) of your accelerator.\n* `client_affinity` - (Optional) Direct all requests from a user to the same endpoint. Valid values are `NONE`, `SOURCE_IP`. Default: `NONE`. If `NONE`, Global Accelerator uses the \"five-tuple\" properties of source IP address, source port, destination IP address, destination port, and protocol to select the hash value. If `SOURCE_IP`, Global Accelerator uses the \"two-tuple\" properties of source (client) IP address and destination IP address to select the hash value.\n* `protocol` - (Optional) The protocol for the connections from clients to the accelerator. Valid values are `TCP`, `UDP`.\n* `port_range` - (Optional) The list of port ranges for the connections from clients to the accelerator. Fields documented below.\n\n**port_range** supports the following attributes:\n\n* `from_port` - (Optional) The first port in the range of ports, inclusive.\n* `to_port` - (Optional) The last port in the range of ports, inclusive.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the listener.\n\n## Timeouts\n\n`aws_globalaccelerator_listener` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `30 minutes`) How long to wait for the Global Accelerator Listener to be created.\n* `update` - (Default `30 minutes`) How long to wait for the Global Accelerator Listener to be updated.\n* `delete` - (Default `30 minutes`) How long to wait for the Global Accelerator Listener to be deleted.\n\n## Import\n\nGlobal Accelerator listeners can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_globalaccelerator_listener.example arn:aws:globalaccelerator::111111111111:accelerator/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/listener/xxxxxxxx\n```\n",
    "basename": "globalaccelerator_listener.html"
  },
  "glue_catalog_database.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_catalog_database",
    "description": "Provides a Glue Catalog Database.",
    "preview": "# Resource: aws_glue_catalog_database\n\nProvides a Glue Catalog …",
    "content": "\n\n# Resource: aws_glue_catalog_database\n\nProvides a Glue Catalog Database Resource. You can refer to the [Glue Developer Guide](http://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html) for a full explanation of the Glue Data Catalog functionality\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_catalog_database\" \"aws_glue_catalog_database\" {\n  name = \"MyCatalogDatabase\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `catalog_id` - (Optional) ID of the Glue Catalog to create the database in. If omitted, this defaults to the AWS Account ID.\n* `description` - (Optional) Description of the database.\n* `location_uri` - (Optional) Location of the database (for example, an HDFS path).\n* `name` - (Required) Name of the database. The acceptable characters are lowercase letters, numbers, and the underscore character.\n* `parameters` - (Optional) List of key-value pairs that define parameters and properties of the database.\n* `target_database` - (Optional) Configuration block for a target database for resource linking. See [`target_database`](#target_database) below.\n\n### target_database\n\n* `catalog_id` - (Required) ID of the Data Catalog in which the database resides.\n* `database_name` - (Required) Name of the catalog database.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the Glue Catalog Database.\n* `id` - Catalog ID and name of the database\n\n## Import\n\nGlue Catalog Databases can be imported using the `catalog_id:name`. If you have not set a Catalog ID specify the AWS Account ID that the database is in, e.g.,\n\n```\n$ terraform import aws_glue_catalog_database.database 123456789012:my_database\n```\n",
    "basename": "glue_catalog_database.html"
  },
  "glue_catalog_table.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_catalog_table",
    "description": "Provides a Glue Catalog Table.",
    "preview": "# Resource: aws_glue_catalog_table\n\nProvides a Glue Catalog Table …",
    "content": "\n\n# Resource: aws_glue_catalog_table\n\nProvides a Glue Catalog Table Resource. You can refer to the [Glue Developer Guide](http://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html) for a full explanation of the Glue Data Catalog functionality.\n\n## Example Usage\n\n### Basic Table\n\n```terraform\nresource \"aws_glue_catalog_table\" \"aws_glue_catalog_table\" {\n  name          = \"MyCatalogTable\"\n  database_name = \"MyCatalogDatabase\"\n}\n```\n\n### Parquet Table for Athena\n\n```terraform\nresource \"aws_glue_catalog_table\" \"aws_glue_catalog_table\" {\n  name          = \"MyCatalogTable\"\n  database_name = \"MyCatalogDatabase\"\n\n  table_type = \"EXTERNAL_TABLE\"\n\n  parameters = {\n    EXTERNAL              = \"TRUE\"\n    \"parquet.compression\" = \"SNAPPY\"\n  }\n\n  storage_descriptor {\n    location      = \"s3://my-bucket/event-streams/my-stream\"\n    input_format  = \"org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat\"\n    output_format = \"org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat\"\n\n    ser_de_info {\n      name                  = \"my-stream\"\n      serialization_library = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\"\n\n      parameters = {\n        \"serialization.format\" = 1\n      }\n    }\n\n    columns {\n      name = \"my_string\"\n      type = \"string\"\n    }\n\n    columns {\n      name = \"my_double\"\n      type = \"double\"\n    }\n\n    columns {\n      name    = \"my_date\"\n      type    = \"date\"\n      comment = \"\"\n    }\n\n    columns {\n      name    = \"my_bigint\"\n      type    = \"bigint\"\n      comment = \"\"\n    }\n\n    columns {\n      name    = \"my_struct\"\n      type    = \"struct<my_nested_string:string>\"\n      comment = \"\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the table. For Hive compatibility, this must be entirely lowercase.\n* `database_name` - (Required) Name of the metadata database where the table metadata resides. For Hive compatibility, this must be all lowercase.\n\nThe follow arguments are optional:\n\n* `catalog_id` - (Optional) ID of the Glue Catalog and database to create the table in. If omitted, this defaults to the AWS Account ID plus the database name.\n* `description` - (Optional) Description of the table.\n* `owner` - (Optional) Owner of the table.\n* `parameters` - (Optional) Properties associated with this table, as a list of key-value pairs.\n* `partition_index` - (Optional) Configuration block for a maximum of 3 partition indexes. See [`partition_index`](#partition_index) below.\n* `partition_keys` - (Optional) Configuration block of columns by which the table is partitioned. Only primitive types are supported as partition keys. See [`partition_keys`](#partition_keys) below.\n* `retention` - (Optional) Retention time for this table.\n* `storage_descriptor` - (Optional) Configuration block for information about the physical storage of this table. For more information, refer to the [Glue Developer Guide](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-tables.html#aws-glue-api-catalog-tables-StorageDescriptor). See [`storage_descriptor`](#storage_descriptor) below.\n* `table_type` - (Optional) Type of this table (EXTERNAL_TABLE, VIRTUAL_VIEW, etc.). While optional, some Athena DDL queries such as `ALTER TABLE` and `SHOW CREATE TABLE` will fail if this argument is empty.\n* `target_table` - (Optional) Configuration block of a target table for resource linking. See [`target_table`](#target_table) below.\n* `view_expanded_text` - (Optional) If the table is a view, the expanded text of the view; otherwise null.\n* `view_original_text` - (Optional) If the table is a view, the original text of the view; otherwise null.\n\n### partition_index\n\n* `index_name` - (Required) Name of the partition index.\n* `keys` - (Required) Keys for the partition index.\n\n### partition_keys\n\n* `comment` - (Optional) Free-form text comment.\n* `name` - (Required) Name of the Partition Key.\n* `type` - (Optional) Datatype of data in the Partition Key.\n\n### storage_descriptor\n\n* `bucket_columns` - (Optional) List of reducer grouping columns, clustering columns, and bucketing columns in the table.\n* `columns` - (Optional) Configuration block for columns in the table. See [`columns`](#columns) below.\n* `compressed` - (Optional) Whether the data in the table is compressed.\n* `input_format` - (Optional) Input format: SequenceFileInputFormat (binary), or TextInputFormat, or a custom format.\n* `location` - (Optional) Physical location of the table. By default this takes the form of the warehouse location, followed by the database location in the warehouse, followed by the table name.\n* `number_of_buckets` - (Optional) Must be specified if the table contains any dimension columns.\n* `output_format` - (Optional) Output format: SequenceFileOutputFormat (binary), or IgnoreKeyTextOutputFormat, or a custom format.\n* `parameters` - (Optional) User-supplied properties in key-value form.\n* `schema_reference` - (Optional) Object that references a schema stored in the AWS Glue Schema Registry. When creating a table, you can pass an empty list of columns for the schema, and instead use a schema reference. See [Schema Reference](#schema-reference) below.\n* `ser_de_info` - (Optional) Configuration block for serialization and deserialization (\"SerDe\") information. See [`ser_de_info`](#ser_de_info) below.\n* `skewed_info` - (Optional) Configuration block with information about values that appear very frequently in a column (skewed values). See [`skewed_info`](#skewed_info) below.\n* `sort_columns` - (Optional) Configuration block for the sort order of each bucket in the table. See [`sort_columns`](#sort_columns) below.\n* `stored_as_sub_directories` - (Optional) Whether the table data is stored in subdirectories.\n\n#### columns\n\n* `comment` - (Optional) Free-form text comment.\n* `name` - (Required) Name of the Column.\n* `parameters` - (Optional) Key-value pairs defining properties associated with the column.\n* `type` - (Optional) Datatype of data in the Column.\n\n#### schema_reference\n\n* `schema_id` - (Optional) Configuration block that contains schema identity fields. Either this or the `schema_version_id` has to be provided. See [`schema_id`](#schema_id) below.\n* `schema_version_id` - (Optional) Unique ID assigned to a version of the schema. Either this or the `schema_id` has to be provided.\n* `schema_version_number` - (Required) Version number of the schema.\n\n##### schema_id\n\n* `registry_name` - (Optional) Name of the schema registry that contains the schema. Must be provided when `schema_name` is specified and conflicts with `schema_arn`.\n* `schema_arn` - (Optional) ARN of the schema. One of `schema_arn` or `schema_name` has to be provided.\n* `schema_name` - (Optional) Name of the schema. One of `schema_arn` or `schema_name` has to be provided.\n\n#### ser_de_info\n\n* `name` - (Optional) Name of the SerDe.\n* `parameters` - (Optional) Map of initialization parameters for the SerDe, in key-value form.\n* `serialization_library` - (Optional) Usually the class that implements the SerDe. An example is `org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe`.\n\n#### sort_columns\n\n* `column` - (Required) Name of the column.\n* `sort_order` - (Required) Whether the column is sorted in ascending (`1`) or descending order (`0`).\n\n#### skewed_info\n\n* `skewed_column_names` - (Optional) List of names of columns that contain skewed values.\n* `skewed_column_value_location_maps` - (Optional) List of values that appear so frequently as to be considered skewed.\n* `skewed_column_values` - (Optional) Map of skewed values to the columns that contain them.\n\n### target_table\n\n* `catalog_id` - (Required) ID of the Data Catalog in which the table resides.\n* `database_name` - (Required) Name of the catalog database that contains the target table.\n* `name` - (Required) Name of the target table.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the Glue Table.\n* `id` - Catalog ID, Database name and of the name table.\n\n## Import\n\nGlue Tables can be imported with their catalog ID (usually AWS account ID), database name, and table name, e.g.,\n\n```\n$ terraform import aws_glue_catalog_table.MyTable 123456789012:MyDatabase:MyTable\n```\n",
    "basename": "glue_catalog_table.html"
  },
  "glue_classifier.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_classifier",
    "description": "Provides an Glue Classifier resource.",
    "preview": "# Resource: aws_glue_classifier\n\nProvides a Glue Classifier …",
    "content": "\n\n# Resource: aws_glue_classifier\n\nProvides a Glue Classifier resource.\n\n~> **NOTE:** It is only valid to create one type of classifier (csv, grok, JSON, or XML). Changing classifier types will recreate the classifier.\n\n## Example Usage\n\n### Csv Classifier\n\n```terraform\nresource \"aws_glue_classifier\" \"example\" {\n  name = \"example\"\n\n  csv_classifier {\n    allow_single_column    = false\n    contains_header        = \"PRESENT\"\n    delimiter              = \",\"\n    disable_value_trimming = false\n    header                 = [\"example1\", \"example2\"]\n    quote_symbol           = \"'\"\n  }\n}\n```\n\n### Grok Classifier\n\n```terraform\nresource \"aws_glue_classifier\" \"example\" {\n  name = \"example\"\n\n  grok_classifier {\n    classification = \"example\"\n    grok_pattern   = \"example\"\n  }\n}\n```\n\n### JSON Classifier\n\n```terraform\nresource \"aws_glue_classifier\" \"example\" {\n  name = \"example\"\n\n  json_classifier {\n    json_path = \"example\"\n  }\n}\n```\n\n### XML Classifier\n\n```terraform\nresource \"aws_glue_classifier\" \"example\" {\n  name = \"example\"\n\n  xml_classifier {\n    classification = \"example\"\n    row_tag        = \"example\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `csv_classifier` - (Optional) A classifier for Csv content. Defined below.\n* `grok_classifier` – (Optional) A classifier that uses grok patterns. Defined below.\n* `json_classifier` – (Optional) A classifier for JSON content. Defined below.\n* `name` – (Required) The name of the classifier.\n* `xml_classifier` – (Optional) A classifier for XML content. Defined below.\n\n### csv_classifier\n\n* `allow_single_column` - (Optional) Enables the processing of files that contain only one column.\n* `contains_header` - (Optional) Indicates whether the CSV file contains a header. This can be one of \"ABSENT\", \"PRESENT\", or \"UNKNOWN\".\n* `delimiter` - (Optional) The delimiter used in the Csv to separate columns.\n* `disable_value_trimming` - (Optional) Specifies whether to trim column values.\n* `header` - (Optional) A list of strings representing column names.\n* `quote_symbol` - (Optional) A custom symbol to denote what combines content into a single column value. It must be different from the column delimiter.\n\n### grok_classifier\n\n* `classification` - (Required) An identifier of the data format that the classifier matches, such as Twitter, JSON, Omniture logs, Amazon CloudWatch Logs, and so on.\n* `custom_patterns` - (Optional) Custom grok patterns used by this classifier.\n* `grok_pattern` - (Required) The grok pattern used by this classifier.\n\n### json_classifier\n\n* `json_path` - (Required) A `JsonPath` string defining the JSON data for the classifier to classify. AWS Glue supports a subset of `JsonPath`, as described in [Writing JsonPath Custom Classifiers](https://docs.aws.amazon.com/glue/latest/dg/custom-classifier.html#custom-classifier-json).\n\n### xml_classifier\n\n* `classification` - (Required) An identifier of the data format that the classifier matches.\n* `row_tag` - (Required) The XML tag designating the element that contains each record in an XML document being parsed. Note that this cannot identify a self-closing element (closed by `/>`). An empty row element that contains only attributes can be parsed as long as it ends with a closing tag (for example, `<row item_a=\"A\" item_b=\"B\"></row>` is okay, but `<row item_a=\"A\" item_b=\"B\" />` is not).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Name of the classifier\n\n## Import\n\nGlue Classifiers can be imported using their name, e.g.,\n\n```\n$ terraform import aws_glue_classifier.MyClassifier MyClassifier\n```\n",
    "basename": "glue_classifier.html"
  },
  "glue_connection.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_connection",
    "description": "Provides an Glue Connection resource.",
    "preview": "# Resource: aws_glue_connection\n\nProvides a Glue Connection …",
    "content": "\n\n# Resource: aws_glue_connection\n\nProvides a Glue Connection resource.\n\n## Example Usage\n\n### Non-VPC Connection\n\n```terraform\nresource \"aws_glue_connection\" \"example\" {\n  connection_properties = {\n    JDBC_CONNECTION_URL = \"jdbc:mysql://example.com/exampledatabase\"\n    PASSWORD            = \"examplepassword\"\n    USERNAME            = \"exampleusername\"\n  }\n\n  name = \"example\"\n}\n```\n\n### VPC Connection\n\nFor more information, see the [AWS Documentation](https://docs.aws.amazon.com/glue/latest/dg/populate-add-connection.html#connection-JDBC-VPC).\n\n```terraform\nresource \"aws_glue_connection\" \"example\" {\n  connection_properties = {\n    JDBC_CONNECTION_URL = \"jdbc:mysql://${aws_rds_cluster.example.endpoint}/exampledatabase\"\n    PASSWORD            = \"examplepassword\"\n    USERNAME            = \"exampleusername\"\n  }\n\n  name = \"example\"\n\n  physical_connection_requirements {\n    availability_zone      = aws_subnet.example.availability_zone\n    security_group_id_list = [aws_security_group.example.id]\n    subnet_id              = aws_subnet.example.id\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `catalog_id` – (Optional) The ID of the Data Catalog in which to create the connection. If none is supplied, the AWS account ID is used by default.\n* `connection_properties` – (Optional) A map of key-value pairs used as parameters for this connection.\n* `connection_type` – (Optional) The type of the connection. Supported are: `JDBC`, `MONGODB`, `KAFKA`, and `NETWORK`. Defaults to `JBDC`.\n* `description` – (Optional) Description of the connection.\n* `match_criteria` – (Optional) A list of criteria that can be used in selecting this connection.\n* `name` – (Required) The name of the connection.\n* `physical_connection_requirements` - (Optional) A map of physical connection requirements, such as VPC and SecurityGroup. Defined below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### physical_connection_requirements\n\n* `availability_zone` - (Optional) The availability zone of the connection. This field is redundant and implied by `subnet_id`, but is currently an api requirement.\n* `security_group_id_list` - (Optional) The security group ID list used by the connection.\n* `subnet_id` - (Optional) The subnet ID used by the connection.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Catalog ID and name of the connection\n* `arn` - The ARN of the Glue Connection.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGlue Connections can be imported using the `CATALOG-ID` (AWS account ID if not custom) and `NAME`, e.g.,\n\n```\n$ terraform import aws_glue_connection.MyConnection 123456789012:MyConnection\n```\n",
    "basename": "glue_connection.html"
  },
  "glue_crawler.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_crawler",
    "description": "Manages a Glue Crawler",
    "preview": "# Resource: aws_glue_crawler\n\nManages a Glue Crawler. More …",
    "content": "\n\n# Resource: aws_glue_crawler\n\nManages a Glue Crawler. More information can be found in the [AWS Glue Developer Guide](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html)\n\n## Example Usage\n\n### DynamoDB Target Example\n\n```terraform\nresource \"aws_glue_crawler\" \"example\" {\n  database_name = aws_glue_catalog_database.example.name\n  name          = \"example\"\n  role          = aws_iam_role.example.arn\n\n  dynamodb_target {\n    path = \"table-name\"\n  }\n}\n```\n\n### JDBC Target Example\n\n```terraform\nresource \"aws_glue_crawler\" \"example\" {\n  database_name = aws_glue_catalog_database.example.name\n  name          = \"example\"\n  role          = aws_iam_role.example.arn\n\n  jdbc_target {\n    connection_name = aws_glue_connection.example.name\n    path            = \"database-name/%\"\n  }\n}\n```\n\n### S3 Target Example\n\n```terraform\nresource \"aws_glue_crawler\" \"example\" {\n  database_name = aws_glue_catalog_database.example.name\n  name          = \"example\"\n  role          = aws_iam_role.example.arn\n\n  s3_target {\n    path = \"s3://${aws_s3_bucket.example.bucket}\"\n  }\n}\n```\n\n\n### Catalog Target Example\n\n```terraform\nresource \"aws_glue_crawler\" \"example\" {\n  database_name = aws_glue_catalog_database.example.name\n  name          = \"example\"\n  role          = aws_iam_role.example.arn\n\n  catalog_target {\n    database_name = aws_glue_catalog_database.example.name\n    tables        = [aws_glue_catalog_table.example.name]\n  }\n\n  schema_change_policy {\n    delete_behavior = \"LOG\"\n  }\n\n  configuration = <<EOF\n{\n  \"Version\":1.0,\n  \"Grouping\": {\n    \"TableGroupingPolicy\": \"CombineCompatibleSchemas\"\n  }\n}\nEOF\n}\n```\n\n### MongoDB Target Example\n\n```terraform\nresource \"aws_glue_crawler\" \"example\" {\n  database_name = aws_glue_catalog_database.example.name\n  name          = \"example\"\n  role          = aws_iam_role.example.arn\n\n  mongodb_target {\n    connection_name = aws_glue_connection.example.name\n    path            = \"database-name/%\"\n  }\n}\n```\n\n### Configuration Settings Example\n\n```terraform\nresource \"aws_glue_crawler\" \"events_crawler\" {\n  database_name = aws_glue_catalog_database.glue_database.name\n  schedule      = \"cron(0 1 * * ? *)\"\n  name          = \"events_crawler_${var.environment_name}\"\n  role          = aws_iam_role.glue_role.arn\n  tags          = var.tags\n\n  configuration = jsonencode(\n    {\n      Grouping = {\n        TableGroupingPolicy = \"CombineCompatibleSchemas\"\n      }\n      CrawlerOutput = {\n        Partitions = { AddOrUpdateBehavior = \"InheritFromTable\" }\n      }\n      Version = 1\n    }\n  )\n\n  s3_target {\n    path = \"s3://${aws_s3_bucket.data_lake_bucket.bucket}\"\n  }\n}\n```\n\n## Argument Reference\n\n~> **NOTE:** Must specify at least one of `dynamodb_target`, `jdbc_target`, `s3_target` or `catalog_target`.\n\nThe following arguments are supported:\n\n* `database_name` (Required) Glue database where results are written.\n* `name` (Required) Name of the crawler.\n* `role` (Required) The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.\n* `classifiers` (Optional) List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.\n* `configuration` (Optional) JSON string of configuration information. For more details see [Setting Crawler Configuration Options](https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html).\n* `description` (Optional) Description of the crawler.\n* `dynamodb_target` (Optional) List of nested DynamoDB target arguments. See [Dynamodb Target](#dynamodb-target) below.\n* `jdbc_target` (Optional) List of nested JBDC target arguments. See [JDBC Target](#jdbc-target) below.\n* `s3_target` (Optional) List nested Amazon S3 target arguments. See [S3 Target](#s3-target) below.\n* `mongodb_target` (Optional) List nested MongoDB target arguments. See [MongoDB Target](#mongodb-target) below.\n* `schedule` (Optional) A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.\n* `schema_change_policy` (Optional) Policy for the crawler's update and deletion behavior. See [Schema Change Policy](#schema-change-policy) below.\n* `lineage_configuration` (Optional) Specifies data lineage configuration settings for the crawler. See [Lineage Configuration](#lineage-configuration) below.\n* `recrawl_policy` (Optional)  A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.. See [Recrawl Policy](#recrawl-policy) below.\n* `security_configuration` (Optional) The name of Security Configuration to be used by the crawler\n* `table_prefix` (Optional) The table prefix used for catalog tables that are created.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Dynamodb Target\n\n* `path` - (Required) The name of the DynamoDB table to crawl.\n* `scan_all` - (Optional) Indicates whether to scan all the records, or to sample rows from the table. Scanning all the records can take a long time when the table is not a high throughput table.  defaults to `true`.\n* `scan_rate` - (Optional) The percentage of the configured read capacity units to use by the AWS Glue crawler. The valid values are null or a value between 0.1 to 1.5.\n\n### JDBC Target\n\n* `connection_name` - (Required) The name of the connection to use to connect to the JDBC target.\n* `path` - (Required) The path of the JDBC target.\n* `exclusions` - (Optional) A list of glob patterns used to exclude from the crawl.\n\n### S3 Target\n\n* `path` - (Required) The path to the Amazon S3 target.\n* `connection_name` - (Optional) The name of a connection which allows crawler to access data in S3 within a VPC.\n* `exclusions` - (Optional) A list of glob patterns used to exclude from the crawl.\n* `sample_size` - (Optional) Sets the number of files in each leaf folder to be crawled when crawling sample files in a dataset. If not set, all the files are crawled. A valid value is an integer between 1 and 249.\n* `event_queue_arn` - (Optional) The ARN of the SQS queue to receive S3 notifications from.\n* `dlq_event_queue_arn` - (Optional) The ARN of the dead-letter SQS queue.\n\n### Catalog Target\n\n* `database_name` - (Required) The name of the Glue database to be synchronized.\n* `tables` - (Required) A list of catalog tables to be synchronized.\n\n~> **Note:** `deletion_behavior` of catalog target doesn't support `DEPRECATE_IN_DATABASE`.\n\n-> **Note:** `configuration` for catalog target crawlers will have `{ ... \"Grouping\": { \"TableGroupingPolicy\": \"CombineCompatibleSchemas\"} }` by default.\n\n\n### MongoDB Target\n\n* `connection_name` - (Required) The name of the connection to use to connect to the Amazon DocumentDB or MongoDB target.\n* `path` - (Required) The path of the Amazon DocumentDB or MongoDB target (database/collection).\n* `scan_all` - (Optional) Indicates whether to scan all the records, or to sample rows from the table. Scanning all the records can take a long time when the table is not a high throughput table. Default value is `true`.\n\n### Schema Change Policy\n\n* `delete_behavior` - (Optional) The deletion behavior when the crawler finds a deleted object. Valid values: `LOG`, `DELETE_FROM_DATABASE`, or `DEPRECATE_IN_DATABASE`. Defaults to `DEPRECATE_IN_DATABASE`.\n* `update_behavior` - (Optional) The update behavior when the crawler finds a changed schema. Valid values: `LOG` or `UPDATE_IN_DATABASE`. Defaults to `UPDATE_IN_DATABASE`.\n\n### Lineage Configuration\n\n* `crawler_lineage_settings` - (Optional) Specifies whether data lineage is enabled for the crawler. Valid values are: `ENABLE` and `DISABLE`. Default value is `Disable`.\n\n### Recrawl Policy\n\n* `recrawl_behavior` - (Optional) Specifies whether to crawl the entire dataset again or to crawl only folders that were added since the last crawler run. Valid Values are: `CRAWL_EVERYTHING` and `CRAWL_NEW_FOLDERS_ONLY`. Default value is `CRAWL_EVERYTHING`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Crawler name\n* `arn` - The ARN of the crawler\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGlue Crawlers can be imported using `name`, e.g.,\n\n```\n$ terraform import aws_glue_crawler.MyJob MyJob\n```\n",
    "basename": "glue_crawler.html"
  },
  "glue_data_catalog_encryption_settings.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_data_catalog_encryption_settings",
    "description": "Provides a Glue Data Catalog Encryption Settings resource.",
    "preview": "# Resource: aws_glue_data_catalog_encryption_settings\n\nProvides a …",
    "content": "\n\n# Resource: aws_glue_data_catalog_encryption_settings\n\nProvides a Glue Data Catalog Encryption Settings resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_data_catalog_encryption_settings\" \"example\" {\n  data_catalog_encryption_settings {\n    connection_password_encryption {\n      aws_kms_key_id                       = aws_kms_key.test.arn\n      return_connection_password_encrypted = true\n    }\n\n    encryption_at_rest {\n      catalog_encryption_mode = \"SSE-KMS\"\n      sse_aws_kms_key_id      = aws_kms_key.test.arn\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `data_catalog_encryption_settings` – (Required) The security configuration to set. see [Data Catalog Encryption Settings](#data_catalog_encryption_settings).\n* `catalog_id` – (Optional) The ID of the Data Catalog to set the security configuration for. If none is provided, the AWS account ID is used by default.\n\n### data_catalog_encryption_settings\n\n* `connection_password_encryption` - (Required) When connection password protection is enabled, the Data Catalog uses a customer-provided key to encrypt the password as part of CreateConnection or UpdateConnection and store it in the ENCRYPTED_PASSWORD field in the connection properties. You can enable catalog encryption or only password encryption. see [Connection Password Encryption](#connection_password_encryption).\n* `encryption_at_rest` - (Required) Specifies the encryption-at-rest configuration for the Data Catalog. see [Encryption At Rest](#encryption_at_rest).\n\n### connection_password_encryption\n\n* `return_connection_password_encrypted` - (Required) When set to `true`, passwords remain encrypted in the responses of GetConnection and GetConnections. This encryption takes effect independently of the catalog encryption.\n* `aws_kms_key_id` - (Optional) A KMS key ARN that is used to encrypt the connection password. If connection password protection is enabled, the caller of CreateConnection and UpdateConnection needs at least `kms:Encrypt` permission on the specified AWS KMS key, to encrypt passwords before storing them in the Data Catalog.\n\n### encryption_at_rest\n\n* `catalog_encryption_mode` - (Required) The encryption-at-rest mode for encrypting Data Catalog data. Valid values are `DISABLED` and `SSE-KMS`.\n* `sse_aws_kms_key_id` - (Optional) The ARN of the AWS KMS key to use for encryption at rest.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Data Catalog to set the security configuration for.\n\n## Import\n\nGlue Data Catalog Encryption Settings can be imported using `CATALOG-ID` (AWS account ID if not custom), e.g.,\n\n```\n$ terraform import aws_glue_data_catalog_encryption_settings.example 123456789012\n```\n",
    "basename": "glue_data_catalog_encryption_settings.html"
  },
  "glue_dev_endpoint": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_dev_endpoint",
    "description": "Provides a Glue Development Endpoint resource.",
    "preview": "# Resource: aws_glue_dev_endpoint\n\nProvides a Glue Development …",
    "content": "\n\n# Resource: aws_glue_dev_endpoint\n\nProvides a Glue Development Endpoint resource.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_glue_dev_endpoint\" \"example\" {\n  name     = \"foo\"\n  role_arn = aws_iam_role.example.arn\n}\n\nresource \"aws_iam_role\" \"example\" {\n  name               = \"AWSGlueServiceRole-foo\"\n  assume_role_policy = data.aws_iam_policy_document.example.json\n}\n\ndata \"aws_iam_policy_document\" \"example\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"glue.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example-AWSGlueServiceRole\" {\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole\"\n  role       = aws_iam_role.example.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `arguments` - (Optional) A map of arguments used to configure the endpoint.\n* `extra_jars_s3_path` - (Optional) Path to one or more Java Jars in an S3 bucket that should be loaded in this endpoint.\n* `extra_python_libs_s3_path` - (Optional) Path(s) to one or more Python libraries in an S3 bucket that should be loaded in this endpoint. Multiple values must be complete paths separated by a comma.\n* `glue_version` - (Optional) -  Specifies the versions of Python and Apache Spark to use. Defaults to AWS Glue version 0.9.\n* `name` - (Required) The name of this endpoint. It must be unique in your account.\n* `number_of_nodes` - (Optional) The number of AWS Glue Data Processing Units (DPUs) to allocate to this endpoint. Conflicts with `worker_type`.\n* `number_of_workers` - (Optional) The number of workers of a defined worker type that are allocated to this endpoint. This field is available only when you choose worker type G.1X or G.2X.\n* `public_key` - (Optional) The public key to be used by this endpoint for authentication.\n* `public_keys` - (Optional) A list of public keys to be used by this endpoint for authentication.\n* `role_arn` - (Required) The IAM role for this endpoint.\n* `security_configuration` - (Optional) The name of the Security Configuration structure to be used with this endpoint.\n* `security_group_ids` - (Optional) Security group IDs for the security groups to be used by this endpoint.\n* `subnet_id` - (Optional) The subnet ID for the new endpoint to use.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `worker_type` - (Optional) The type of predefined worker that is allocated to this endpoint. Accepts a value of Standard, G.1X, or G.2X.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the endpoint.\n* `name` - The name of the new endpoint.\n* `private_address` - A private IP address to access the endpoint within a VPC, if this endpoint is created within one.\n* `public_address` - The public IP address used by this endpoint. The PublicAddress field is present only when you create a non-VPC endpoint.\n* `yarn_endpoint_address` - The YARN endpoint address used by this endpoint.\n* `zeppelin_remote_spark_interpreter_port` - The Apache Zeppelin port for the remote Apache Spark interpreter.\n* `availability_zone` - The AWS availability zone where this endpoint is located.\n* `vpc_id` - he ID of the VPC used by this endpoint.\n* `status` - The current status of this endpoint.\n* `failure_reason` - The reason for a current failure in this endpoint.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nA Glue Development Endpoint can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_glue_dev_endpoint.example foo\n```",
    "basename": "glue_dev_endpoint"
  },
  "glue_job.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_job",
    "description": "Provides an Glue Job resource.",
    "preview": "# Resource: aws_glue_job\n\nProvides a Glue Job resource.\n\n-> Glue …",
    "content": "\n\n# Resource: aws_glue_job\n\nProvides a Glue Job resource.\n\n-> Glue functionality, such as monitoring and logging of jobs, is typically managed with the `default_arguments` argument. See the [Special Parameters Used by AWS Glue](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html) topic in the Glue developer guide for additional information.\n\n## Example Usage\n\n### Python Job\n\n```terraform\nresource \"aws_glue_job\" \"example\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.example.arn\n\n  command {\n    script_location = \"s3://${aws_s3_bucket.example.bucket}/example.py\"\n  }\n}\n```\n\n### Scala Job\n\n```terraform\nresource \"aws_glue_job\" \"example\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.example.arn\n\n  command {\n    script_location = \"s3://${aws_s3_bucket.example.bucket}/example.scala\"\n  }\n\n  default_arguments = {\n    \"--job-language\" = \"scala\"\n  }\n}\n```\n\n### Enabling CloudWatch Logs and Metrics\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name              = \"example\"\n  retention_in_days = 14\n}\n\nresource \"aws_glue_job\" \"example\" {\n  # ... other configuration ...\n\n  default_arguments = {\n    # ... potentially other arguments ...\n    \"--continuous-log-logGroup\"          = aws_cloudwatch_log_group.example.name\n    \"--enable-continuous-cloudwatch-log\" = \"true\"\n    \"--enable-continuous-log-filter\"     = \"true\"\n    \"--enable-metrics\"                   = \"\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `command` – (Required) The command of the job. Defined below.\n* `connections` – (Optional) The list of connections used for this job.\n* `default_arguments` – (Optional) The map of default arguments for this job. You can specify arguments here that your own job-execution script consumes, as well as arguments that AWS Glue itself consumes. For information about how to specify and consume your own Job arguments, see the [Calling AWS Glue APIs in Python](http://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html) topic in the developer guide. For information about the key-value pairs that AWS Glue consumes to set up your job, see the [Special Parameters Used by AWS Glue](http://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-glue-arguments.html) topic in the developer guide.\n* `non_overridable_arguments` – (Optional) Non-overridable arguments for this job, specified as name-value pairs.\n* `description` – (Optional) Description of the job.\n* `execution_property` – (Optional) Execution property of the job. Defined below.\n* `glue_version` - (Optional) The version of glue to use, for example \"1.0\". For information about available versions, see the [AWS Glue Release Notes](https://docs.aws.amazon.com/glue/latest/dg/release-notes.html).\n* `max_capacity` – (Optional) The maximum number of AWS Glue data processing units (DPUs) that can be allocated when this job runs. `Required` when `pythonshell` is set, accept either `0.0625` or `1.0`. Use `number_of_workers` and `worker_type` arguments instead with `glue_version` `2.0` and above.\n* `max_retries` – (Optional) The maximum number of times to retry this job if it fails.\n* `name` – (Required) The name you assign to this job. It must be unique in your account.\n* `notification_property` - (Optional) Notification property of the job. Defined below.\n* `role_arn` – (Required) The ARN of the IAM role associated with this job.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `timeout` – (Optional) The job timeout in minutes. The default is 2880 minutes (48 hours).\n* `security_configuration` - (Optional) The name of the Security Configuration to be associated with the job.\n* `worker_type` - (Optional) The type of predefined worker that is allocated when a job runs. Accepts a value of Standard, G.1X, or G.2X.\n* `number_of_workers` - (Optional) The number of workers of a defined workerType that are allocated when a job runs.\n\n### command Argument Reference\n\n* `name` - (Optional) The name of the job command. Defaults to `glueetl`. Use `pythonshell` for Python Shell Job Type, `max_capacity` needs to be set if `pythonshell` is chosen.\n* `script_location` - (Required) Specifies the S3 path to a script that executes a job.\n* `python_version` - (Optional) The Python version being used to execute a Python shell job. Allowed values are 2 or 3.\n\n### execution_property Argument Reference\n\n* `max_concurrent_runs` - (Optional) The maximum number of concurrent runs allowed for a job. The default is 1.\n\n### notification_property Argument Reference\n\n* `notify_delay_after` - (Optional) After a job run starts, the number of minutes to wait before sending a job run delay notification.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of Glue Job\n* `id` - Job name\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGlue Jobs can be imported using `name`, e.g.,\n\n```\n$ terraform import aws_glue_job.MyJob MyJob\n```\n",
    "basename": "glue_job.html"
  },
  "glue_ml_transform.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_ml_transform",
    "description": "Provides a Glue ML Transform resource.",
    "preview": "# Resource: aws_glue_ml_transform\n\nProvides a Glue ML Transform …",
    "content": "\n\n# Resource: aws_glue_ml_transform\n\nProvides a Glue ML Transform resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_ml_transform\" \"test\" {\n  name     = \"example\"\n  role_arn = aws_iam_role.test.arn\n\n  input_record_tables {\n    database_name = aws_glue_catalog_table.test.database_name\n    table_name    = aws_glue_catalog_table.test.name\n  }\n\n  parameters {\n    transform_type = \"FIND_MATCHES\"\n\n    find_matches_parameters {\n      primary_key_column_name = \"my_column_1\"\n    }\n  }\n\n  depends_on = [aws_iam_role_policy_attachment.test]\n}\n\nresource \"aws_glue_catalog_database\" \"test\" {\n  name = \"example\"\n}\n\nresource \"aws_glue_catalog_table\" \"test\" {\n  name               = \"example\"\n  database_name      = aws_glue_catalog_database.test.name\n  owner              = \"my_owner\"\n  retention          = 1\n  table_type         = \"VIRTUAL_VIEW\"\n  view_expanded_text = \"view_expanded_text_1\"\n  view_original_text = \"view_original_text_1\"\n\n  storage_descriptor {\n    bucket_columns            = [\"bucket_column_1\"]\n    compressed                = false\n    input_format              = \"SequenceFileInputFormat\"\n    location                  = \"my_location\"\n    number_of_buckets         = 1\n    output_format             = \"SequenceFileInputFormat\"\n    stored_as_sub_directories = false\n\n    parameters = {\n      param1 = \"param1_val\"\n    }\n\n    columns {\n      name    = \"my_column_1\"\n      type    = \"int\"\n      comment = \"my_column1_comment\"\n    }\n\n    columns {\n      name    = \"my_column_2\"\n      type    = \"string\"\n      comment = \"my_column2_comment\"\n    }\n\n    ser_de_info {\n      name = \"ser_de_name\"\n\n      parameters = {\n        param1 = \"param_val_1\"\n      }\n\n      serialization_library = \"org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe\"\n    }\n\n    sort_columns {\n      column     = \"my_column_1\"\n      sort_order = 1\n    }\n\n    skewed_info {\n      skewed_column_names = [\n        \"my_column_1\",\n      ]\n\n      skewed_column_value_location_maps = {\n        my_column_1 = \"my_column_1_val_loc_map\"\n      }\n\n      skewed_column_values = [\n        \"skewed_val_1\",\n      ]\n    }\n  }\n\n  partition_keys {\n    name    = \"my_column_1\"\n    type    = \"int\"\n    comment = \"my_column_1_comment\"\n  }\n\n  partition_keys {\n    name    = \"my_column_2\"\n    type    = \"string\"\n    comment = \"my_column_2_comment\"\n  }\n\n  parameters = {\n    param1 = \"param1_val\"\n  }\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` – (Required) The name you assign to this ML Transform. It must be unique in your account.\n* `input_record_tables` - (Required)  A list of AWS Glue table definitions used by the transform. see [Input Record Tables](#input_record_tables).\n* `parameters` - (Required) The algorithmic parameters that are specific to the transform type used. Conditionally dependent on the transform type. see [Parameters](#parameters).\n* `role_arn` – (Required) The ARN of the IAM role associated with this ML Transform.\n* `description` – (Optional) Description of the ML Transform.\n* `glue_version` - (Optional) The version of glue to use, for example \"1.0\". For information about available versions, see the [AWS Glue Release Notes](https://docs.aws.amazon.com/glue/latest/dg/release-notes.html).\n* `max_capacity` – (Optional) The number of AWS Glue data processing units (DPUs) that are allocated to task runs for this transform. You can allocate from `2` to `100` DPUs; the default is `10`. `max_capacity` is a mutually exclusive option with `number_of_workers` and `worker_type`.\n* `max_retries` – (Optional) The maximum number of times to retry this ML Transform if it fails.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `timeout` – (Optional) The ML Transform timeout in minutes. The default is 2880 minutes (48 hours).\n* `worker_type` - (Optional) The type of predefined worker that is allocated when an ML Transform runs. Accepts a value of `Standard`, `G.1X`, or `G.2X`. Required with `number_of_workers`.\n* `number_of_workers` - (Optional) The number of workers of a defined `worker_type` that are allocated when an ML Transform runs. Required with `worker_type`.\n\n### input_record_tables\n\n* `database_name` - (Required) A database name in the AWS Glue Data Catalog.\n* `table_name` - (Required) A table name in the AWS Glue Data Catalog.\n* `catalog_id` - (Optional) A unique identifier for the AWS Glue Data Catalog.\n* `connection_name`- (Optional) The name of the connection to the AWS Glue Data Catalog.\n\n### parameters\n\n* `transform_type` - (Required) The type of machine learning transform. For information about the types of machine learning transforms, see [Creating Machine Learning Transforms](http://docs.aws.amazon.com/glue/latest/dg/add-job-machine-learning-transform.html).\n* `find_matches_parameters` - (Required) The parameters for the find matches algorithm. see [Find Matches Parameters](#find_matches_parameters).\n\n#### find_matches_parameters\n\n* `accuracy_cost_trade_off` - (Optional) The value that is selected when tuning your transform for a balance between accuracy and cost.\n* `enforce_provided_labels` - (Optional) The value to switch on or off to force the output to match the provided labels from users.\n* `precision_recall_trade_off` - (Optional) The value selected when tuning your transform for a balance between precision and recall.\n* `primary_key_column_name` - (Optional) The name of a column that uniquely identifies rows in the source table.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of Glue ML Transform.\n* `id` - Glue ML Transform ID.\n* `label_count` - The number of labels available for this transform.\n* `schema` - The object that represents the schema that this transform accepts. see [Schema](#schema).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n### schema\n\n* `name` - The name of the column.\n* `data_type` - The type of data in the column.\n\n## Import\n\nGlue ML Transforms can be imported using `id`, e.g.,\n\n```\n$ terraform import aws_glue_ml_transform.example tfm-c2cafbe83b1c575f49eaca9939220e2fcd58e2d5\n```\n",
    "basename": "glue_ml_transform.html"
  },
  "glue_partition.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_partition",
    "description": "Provides a Glue Partition.",
    "preview": "# Resource: aws_glue_partition\n\nProvides a Glue Partition Resource.\n …",
    "content": "\n\n# Resource: aws_glue_partition\n\nProvides a Glue Partition Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_partition\" \"example\" {\n  database_name = \"some-database\"\n  table_name    = \"some-table\"\n  values        = [\"some-value\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `database_name` - (Required) Name of the metadata database where the table metadata resides. For Hive compatibility, this must be all lowercase.\n* `partition_values` - (Required) The values that define the partition.\n* `catalog_id` - (Optional) ID of the Glue Catalog and database to create the table in. If omitted, this defaults to the AWS Account ID plus the database name.\n* `storage_descriptor` - (Optional) A [storage descriptor](#storage_descriptor) object containing information about the physical storage of this table. You can refer to the [Glue Developer Guide](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-tables.html#aws-glue-api-catalog-tables-StorageDescriptor) for a full explanation of this object.\n* `parameters` - (Optional) Properties associated with this table, as a list of key-value pairs.\n\n##### storage_descriptor\n\n* `columns` - (Optional) A list of the [Columns](#column) in the table.\n* `location` - (Optional) The physical location of the table. By default this takes the form of the warehouse location, followed by the database location in the warehouse, followed by the table name.\n* `input_format` - (Optional) The input format: SequenceFileInputFormat (binary), or TextInputFormat, or a custom format.\n* `output_format` - (Optional) The output format: SequenceFileOutputFormat (binary), or IgnoreKeyTextOutputFormat, or a custom format.\n* `compressed` - (Optional) True if the data in the table is compressed, or False if not.\n* `number_of_buckets` - (Optional) Must be specified if the table contains any dimension columns.\n* `ser_de_info` - (Optional) [Serialization/deserialization (SerDe)](#ser_de_info) information.\n* `bucket_columns` - (Optional) A list of reducer grouping columns, clustering columns, and bucketing columns in the table.\n* `sort_columns` - (Optional) A list of [Order](#sort_column) objects specifying the sort order of each bucket in the table.\n* `parameters` - (Optional) User-supplied properties in key-value form.\n* `skewed_info` - (Optional) Information about values that appear very frequently in a column (skewed values).\n* `stored_as_sub_directories` - (Optional) True if the table data is stored in subdirectories, or False if not.\n\n##### column\n\n* `name` - (Required) The name of the Column.\n* `type` - (Optional) The datatype of data in the Column.\n* `comment` - (Optional) Free-form text comment.\n\n##### ser_de_info\n\n* `name` - (Optional) Name of the SerDe.\n* `parameters` - (Optional) A map of initialization parameters for the SerDe, in key-value form.\n* `serialization_library` - (Optional) Usually the class that implements the SerDe. An example is: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe.\n\n##### sort_columns\n\n* `column` - (Required) The name of the column.\n* `sort_order` - (Required) Indicates that the column is sorted in ascending order (== 1), or in descending order (==0).\n\n##### skewed_info\n\n* `skewed_column_names` - (Optional) A list of names of columns that contain skewed values.\n* `skewed_column_value_location_maps` - (Optional) A list of values that appear so frequently as to be considered skewed.\n* `skewed_column_values` - (Optional) A map of skewed values to the columns that contain them.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - partition id.\n* `creation_time` - The time at which the partition was created.\n* `last_analyzed_time` - The last time at which column statistics were computed for this partition.\n* `last_accessed_time` - The last time at which the partition was accessed.\n\n## Import\n\nGlue Partitions can be imported with their catalog ID (usually AWS account ID), database name, table name and partition values e.g.,\n\n```\n$ terraform import aws_glue_partition.part 123456789012:MyDatabase:MyTable:val1#val2\n```\n",
    "basename": "glue_partition.html"
  },
  "glue_partition_index.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_partition_index",
    "description": "Provides a Glue Partition Index.",
    "preview": "# Resource: aws_glue_partition_index\n\n## Example Usage\n\n```terraform …",
    "content": "\n\n# Resource: aws_glue_partition_index\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_catalog_database\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_glue_catalog_table\" \"example\" {\n  name               = \"example\"\n  database_name      = aws_glue_catalog_database.example.name\n  owner              = \"my_owner\"\n  retention          = 1\n  table_type         = \"VIRTUAL_VIEW\"\n  view_expanded_text = \"view_expanded_text_1\"\n  view_original_text = \"view_original_text_1\"\n\n  storage_descriptor {\n    bucket_columns            = [\"bucket_column_1\"]\n    compressed                = false\n    input_format              = \"SequenceFileInputFormat\"\n    location                  = \"my_location\"\n    number_of_buckets         = 1\n    output_format             = \"SequenceFileInputFormat\"\n    stored_as_sub_directories = false\n\n    parameters = {\n      param1 = \"param1_val\"\n    }\n\n    columns {\n      name    = \"my_column_1\"\n      type    = \"int\"\n      comment = \"my_column1_comment\"\n    }\n\n    columns {\n      name    = \"my_column_2\"\n      type    = \"string\"\n      comment = \"my_column2_comment\"\n    }\n\n    ser_de_info {\n      name = \"ser_de_name\"\n\n      parameters = {\n        param1 = \"param_val_1\"\n      }\n\n      serialization_library = \"org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe\"\n    }\n\n    sort_columns {\n      column     = \"my_column_1\"\n      sort_order = 1\n    }\n\n    skewed_info {\n      skewed_column_names = [\n        \"my_column_1\",\n      ]\n\n      skewed_column_value_location_maps = {\n        my_column_1 = \"my_column_1_val_loc_map\"\n      }\n\n      skewed_column_values = [\n        \"skewed_val_1\",\n      ]\n    }\n  }\n\n  partition_keys {\n    name    = \"my_column_1\"\n    type    = \"int\"\n    comment = \"my_column_1_comment\"\n  }\n\n  partition_keys {\n    name    = \"my_column_2\"\n    type    = \"string\"\n    comment = \"my_column_2_comment\"\n  }\n\n  parameters = {\n    param1 = \"param1_val\"\n  }\n}\n\nresource \"aws_glue_partition_index\" \"example\" {\n  database_name = aws_glue_catalog_database.example.name\n  table_name    = aws_glue_catalog_table.example.name\n\n  partition_index {\n    index_name = \"example\"\n    keys       = [\"my_column_1\", \"my_column_2\"]\n  }\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `table_name` - (Required) Name of the table. For Hive compatibility, this must be entirely lowercase.\n* `database_name` - (Required) Name of the metadata database where the table metadata resides. For Hive compatibility, this must be all lowercase.\n* `partition_index` - (Required) Configuration block for a partition index. See [`partition_index`](#partition_index) below.\n* `catalog_id` - (Optional) The catalog ID where the table resides.\n\n\n### partition_index\n\n* `index_name` - (Required) Name of the partition index.\n* `keys` - (Required) Keys for the partition index.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Catalog ID, Database name, table name, and index name.\n\n## Import\n\nGlue Partition Indexes can be imported with their catalog ID (usually AWS account ID), database name, table name, and index name, e.g.,\n\n```\n$ terraform import aws_glue_partition_index.example 123456789012:MyDatabase:MyTable:index-name\n```\n",
    "basename": "glue_partition_index.html"
  },
  "glue_registry.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_registry",
    "description": "Provides a Glue Registry resource.",
    "preview": "# Resource: aws_glue_registry\n\nProvides a Glue Registry resource.\n …",
    "content": "\n\n# Resource: aws_glue_registry\n\nProvides a Glue Registry resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_registry\" \"example\" {\n  registry_name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `registry_name` – (Required) The Name of the registry.\n* `description` – (Optional) A description of the registry.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of Glue Registry.\n* `id` - Amazon Resource Name (ARN) of Glue Registry.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGlue Registries can be imported using `arn`, e.g.,\n\n```\n$ terraform import aws_glue_registry.example arn:aws:glue:us-west-2:123456789012:registry/example\n```\n",
    "basename": "glue_registry.html"
  },
  "glue_resource_policy.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_resource_policy",
    "description": "Provides a resource to configure the aws glue resource policy.",
    "preview": "# Resource: aws_glue_resource_policy\n\nProvides a Glue resource …",
    "content": "\n\n# Resource: aws_glue_resource_policy\n\nProvides a Glue resource policy. Only one can exist per region.\n\n## Example Usage\n\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_partition\" \"current\" {}\n\ndata \"aws_region\" \"current\" {}\n\ndata \"aws_iam_policy_document\" \"glue-example-policy\" {\n  statement {\n    actions = [\n      \"glue:CreateTable\",\n    ]\n    resources = [\"arn:${data.aws_partition.current.partition}:glue:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:*\"]\n    principals {\n      identifiers = [\"*\"]\n      type        = \"AWS\"\n    }\n  }\n}\n\nresource \"aws_glue_resource_policy\" \"example\" {\n  policy = data.aws_iam_policy_document.glue-example-policy.json\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy` – (Required) The policy to be applied to the aws glue data catalog.\n* `enable_hybrid` - (Optional) Indicates that you are using both methods to grant cross-account. Valid values are `TRUE` and `FALSE`. Note the terraform will not perform drift detetction on this field as its not return on read.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nGlue Resource Policy can be imported using the account ID:\n\n```\n$ terraform import aws_glue_resource_policy.Test 12356789012\n```\n",
    "basename": "glue_resource_policy.html"
  },
  "glue_schema.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_schema",
    "description": "Provides a Glue Schema resource.",
    "preview": "# Resource: aws_glue_schema\n\nProvides a Glue Schema resource.\n\n## …",
    "content": "\n\n# Resource: aws_glue_schema\n\nProvides a Glue Schema resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_schema\" \"example\" {\n  schema_name       = \"example\"\n  registry_arn      = aws_glue_registry.test.arn\n  data_format       = \"AVRO\"\n  compatibility     = \"NONE\"\n  schema_definition = \"{\\\"type\\\": \\\"record\\\", \\\"name\\\": \\\"r1\\\", \\\"fields\\\": [ {\\\"name\\\": \\\"f1\\\", \\\"type\\\": \\\"int\\\"}, {\\\"name\\\": \\\"f2\\\", \\\"type\\\": \\\"string\\\"} ]}\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `schema_name` – (Required) The Name of the schema.\n* `registry_arn` - (Required) The ARN of the Glue Registry to create the schema in.\n* `data_format` - (Required) The data format of the schema definition. Currently only `AVRO` is supported.\n* `compatibility` - (Required) The compatibility mode of the schema. Values values are: `NONE`, `DISABLED`, `BACKWARD`, `BACKWARD_ALL`, `FORWARD`, `FORWARD_ALL`, `FULL`, and `FULL_ALL`.\n* `schema_definition` - (Required) The schema definition using the `data_format` setting for `schema_name`.\n* `description` – (Optional) A description of the schema.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the schema.\n* `id` - Amazon Resource Name (ARN) of the schema.\n* `registry_name` - The name of the Glue Registry.\n* `latest_schema_version` - The latest version of the schema associated with the returned schema definition.\n* `next_schema_version` - The next version of the schema associated with the returned schema definition.\n* `schema_checkpoint` - The version number of the checkpoint (the last time the compatibility mode was changed).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGlue Registries can be imported using `arn`, e.g.,\n\n```\n$ terraform import aws_glue_schema.example arn:aws:glue:us-west-2:123456789012:schema/example/example\n```\n",
    "basename": "glue_schema.html"
  },
  "glue_security_configuration.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_security_configuration",
    "description": "Manages a Glue Security Configuration",
    "preview": "# Resource: aws_glue_security_configuration\n\nManages a Glue Security …",
    "content": "\n\n# Resource: aws_glue_security_configuration\n\nManages a Glue Security Configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_security_configuration\" \"example\" {\n  name = \"example\"\n\n  encryption_configuration {\n    cloudwatch_encryption {\n      cloudwatch_encryption_mode = \"DISABLED\"\n    }\n\n    job_bookmarks_encryption {\n      job_bookmarks_encryption_mode = \"DISABLED\"\n    }\n\n    s3_encryption {\n      kms_key_arn        = data.aws_kms_key.example.arn\n      s3_encryption_mode = \"SSE-KMS\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `encryption_configuration` – (Required) Configuration block containing encryption configuration. Detailed below.\n* `name` – (Required) Name of the security configuration.\n\n### encryption_configuration Argument Reference\n\n* `cloudwatch_encryption ` - (Required) A `cloudwatch_encryption ` block as described below, which contains encryption configuration for CloudWatch.\n* `job_bookmarks_encryption ` - (Required) A `job_bookmarks_encryption ` block as described below, which contains encryption configuration for job bookmarks.\n* `s3_encryption` - (Required) A `s3_encryption ` block as described below, which contains encryption configuration for S3 data.\n\n#### cloudwatch_encryption Argument Reference\n\n* `cloudwatch_encryption_mode` - (Optional) Encryption mode to use for CloudWatch data. Valid values: `DISABLED`, `SSE-KMS`. Default value: `DISABLED`.\n* `kms_key_arn` - (Optional) Amazon Resource Name (ARN) of the KMS key to be used to encrypt the data.\n\n#### job_bookmarks_encryption Argument Reference\n\n* `job_bookmarks_encryption_mode` - (Optional) Encryption mode to use for job bookmarks data. Valid values: `CSE-KMS`, `DISABLED`. Default value: `DISABLED`.\n* `kms_key_arn` - (Optional) Amazon Resource Name (ARN) of the KMS key to be used to encrypt the data.\n\n#### s3_encryption Argument Reference\n\n* `s3_encryption_mode` - (Optional) Encryption mode to use for S3 data. Valid values: `DISABLED`, `SSE-KMS`, `SSE-S3`. Default value: `DISABLED`.\n* `kms_key_arn` - (Optional) Amazon Resource Name (ARN) of the KMS key to be used to encrypt the data.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Glue security configuration name\n\n## Import\n\nGlue Security Configurations can be imported using `name`, e.g.,\n\n```\n$ terraform import aws_glue_security_configuration.example example\n```\n",
    "basename": "glue_security_configuration.html"
  },
  "glue_trigger.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_trigger",
    "description": "Manages a Glue Trigger resource.",
    "preview": "# Resource: aws_glue_trigger\n\nManages a Glue Trigger resource.\n\n## …",
    "content": "\n\n# Resource: aws_glue_trigger\n\nManages a Glue Trigger resource.\n\n## Example Usage\n\n### Conditional Trigger\n\n```terraform\nresource \"aws_glue_trigger\" \"example\" {\n  name = \"example\"\n  type = \"CONDITIONAL\"\n\n  actions {\n    job_name = aws_glue_job.example1.name\n  }\n\n  predicate {\n    conditions {\n      job_name = aws_glue_job.example2.name\n      state    = \"SUCCEEDED\"\n    }\n  }\n}\n```\n\n### On-Demand Trigger\n\n```terraform\nresource \"aws_glue_trigger\" \"example\" {\n  name = \"example\"\n  type = \"ON_DEMAND\"\n\n  actions {\n    job_name = aws_glue_job.example.name\n  }\n}\n```\n\n### Scheduled Trigger\n\n```terraform\nresource \"aws_glue_trigger\" \"example\" {\n  name     = \"example\"\n  schedule = \"cron(15 12 * * ? *)\"\n  type     = \"SCHEDULED\"\n\n  actions {\n    job_name = aws_glue_job.example.name\n  }\n}\n```\n\n### Conditional Trigger with Crawler Action\n\n**Note:** Triggers can have both a crawler action and a crawler condition, just no example provided.\n\n```terraform\nresource \"aws_glue_trigger\" \"example\" {\n  name = \"example\"\n  type = \"CONDITIONAL\"\n\n  actions {\n    crawler_name = aws_glue_crawler.example1.name\n  }\n\n  predicate {\n    conditions {\n      job_name = aws_glue_job.example2.name\n      state    = \"SUCCEEDED\"\n    }\n  }\n}\n```\n\n### Conditional Trigger with Crawler Condition\n\n**Note:** Triggers can have both a crawler action and a crawler condition, just no example provided.\n\n```terraform\nresource \"aws_glue_trigger\" \"example\" {\n  name = \"example\"\n  type = \"CONDITIONAL\"\n\n  actions {\n    job_name = aws_glue_job.example1.name\n  }\n\n  predicate {\n    conditions {\n      crawler_name = aws_glue_crawler.example2.name\n      crawl_state  = \"SUCCEEDED\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `actions` – (Required) List of actions initiated by this trigger when it fires. See [Actions](#actions) Below.\n* `description` – (Optional) A description of the new trigger.\n* `enabled` – (Optional) Start the trigger. Defaults to `true`.\n* `name` – (Required) The name of the trigger.\n* `predicate` – (Optional) A predicate to specify when the new trigger should fire. Required when trigger type is `CONDITIONAL`. See [Predicate](#predicate) Below.\n* `schedule` – (Optional) A cron expression used to specify the schedule. [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html)\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `type` – (Required) The type of trigger. Valid values are `CONDITIONAL`, `ON_DEMAND`, and `SCHEDULED`.\n* `workflow_name` - (Optional) A workflow to which the trigger should be associated to. Every workflow graph (DAG) needs a starting trigger (`ON_DEMAND` or `SCHEDULED` type) and can contain multiple additional `CONDITIONAL` triggers.\n\n### Actions\n\n* `arguments` - (Optional) Arguments to be passed to the job. You can specify arguments here that your own job-execution script consumes, as well as arguments that AWS Glue itself consumes.\n* `crawler_name` - (Optional) The name of the crawler to be executed. Conflicts with `job_name`.\n* `job_name` - (Optional) The name of a job to be executed. Conflicts with `crawler_name`.\n* `timeout` - (Optional) The job run timeout in minutes. It overrides the timeout value of the job.\n* `security_configuration` - (Optional) The name of the Security Configuration structure to be used with this action.\n* `notification_property` - (Optional) Specifies configuration properties of a job run notification. See [Notification Property](#notification-property) details below.\n\n#### Notification Property\n\n* `notify_delay_after` - (Optional) After a job run starts, the number of minutes to wait before sending a job run delay notification.\n\n### Predicate\n\n* `conditions` - (Required) A list of the conditions that determine when the trigger will fire. See [Conditions](#conditions).\n* `logical` - (Optional) How to handle multiple conditions. Defaults to `AND`. Valid values are `AND` or `ANY`.\n\n#### Conditions\n\n* `job_name` - (Optional) The name of the job to watch. If this is specified, `state` must also be specified. Conflicts with `crawler_name`.\n* `state` - (Optional) The condition job state. Currently, the values supported are `SUCCEEDED`, `STOPPED`, `TIMEOUT` and `FAILED`. If this is specified, `job_name` must also be specified. Conflicts with `crawler_state`.\n* `crawler_name` - (Optional) The name of the crawler to watch. If this is specified, `crawl_state` must also be specified. Conflicts with `job_name`.\n* `crawl_state` - (Optional) The condition crawl state. Currently, the values supported are `RUNNING`, `SUCCEEDED`, `CANCELLED`, and `FAILED`. If this is specified, `crawler_name` must also be specified. Conflicts with `state`.\n* `logical_operator` - (Optional) A logical operator. Defaults to `EQUALS`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of Glue Trigger\n* `id` - Trigger name\n* `state` - The current state of the trigger.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_glue_trigger` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `5m`) How long to wait for a trigger to be created.\n- `delete` - (Default `5m`) How long to wait for a trigger to be deleted.\n\n## Import\n\nGlue Triggers can be imported using `name`, e.g.,\n\n```\n$ terraform import aws_glue_trigger.MyTrigger MyTrigger\n```\n",
    "basename": "glue_trigger.html"
  },
  "glue_user_defined_function.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_user_defined_function",
    "description": "Provides a Glue User Defined Function.",
    "preview": "# Resource: aws_glue_user_defined_function\n\nProvides a Glue User …",
    "content": "\n\n# Resource: aws_glue_user_defined_function\n\nProvides a Glue User Defined Function Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_catalog_database\" \"example\" {\n  name = \"my_database\"\n}\n\nresource \"aws_glue_user_defined_function\" \"example\" {\n  name          = \"my_func\"\n  catalog_id    = aws_glue_catalog_database.example.catalog_id\n  database_name = aws_glue_catalog_database.example.name\n  class_name    = \"class\"\n  owner_name    = \"owner\"\n  owner_type    = \"GROUP\"\n\n  resource_uris {\n    resource_type = \"ARCHIVE\"\n    uri           = \"uri\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the function.\n* `catalog_id` - (Optional) ID of the Glue Catalog to create the function in. If omitted, this defaults to the AWS Account ID.\n* `database_name` - (Required) The name of the Database to create the Function.\n* `class_name` - (Required) The Java class that contains the function code.\n* `owner_name` - (Required) The owner of the function.\n* `owner_type` - (Required) The owner type. can be one of `USER`, `ROLE`, and `GROUP`.\n* `resource_uris` - (Optional) The configuration block for Resource URIs. See [resource uris](#resource-uris) below for more details.\n\n### Resource URIs\n\n* `resource_type` - (Required) The type of the resource. can be one of `JAR`, `FILE`, and `ARCHIVE`.\n* `uri` - (Required) The URI for accessing the resource.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id`- The id of the Glue User Defined Function.\n* `arn`- The ARN of the Glue User Defined Function.\n* `create_date`- The time at which the function was created.\n\n## Import\n\nGlue User Defined Functions can be imported using the `catalog_id:database_name:function_name`. If you have not set a Catalog ID specify the AWS Account ID that the database is in, e.g.,\n\n```\n$ terraform import aws_glue_user_defined_function.func 123456789012:my_database:my_func\n```\n",
    "basename": "glue_user_defined_function.html"
  },
  "glue_workflow.html": {
    "subcategory": "Glue",
    "layout": "aws",
    "page_title": "AWS: aws_glue_workflow",
    "description": "Provides a Glue Workflow resource.",
    "preview": "# Resource: aws_glue_workflow\n\nProvides a Glue Workflow resource. …",
    "content": "\n\n# Resource: aws_glue_workflow\n\nProvides a Glue Workflow resource.\nThe workflow graph (DAG) can be build using the `aws_glue_trigger` resource.\nSee the example below for creating a graph with four nodes (two triggers and two jobs).\n\n## Example Usage\n\n```terraform\nresource \"aws_glue_workflow\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_glue_trigger\" \"example-start\" {\n  name          = \"trigger-start\"\n  type          = \"ON_DEMAND\"\n  workflow_name = aws_glue_workflow.example.name\n\n  actions {\n    job_name = \"example-job\"\n  }\n}\n\nresource \"aws_glue_trigger\" \"example-inner\" {\n  name          = \"trigger-inner\"\n  type          = \"CONDITIONAL\"\n  workflow_name = aws_glue_workflow.example.name\n\n  predicate {\n    conditions {\n      job_name = \"example-job\"\n      state    = \"SUCCEEDED\"\n    }\n  }\n\n  actions {\n    job_name = \"another-example-job\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` – (Required) The name you assign to this workflow.\n* `default_run_properties` – (Optional) A map of default run properties for this workflow. These properties are passed to all jobs associated to the workflow.\n* `description` – (Optional) Description of the workflow.\n* `max_concurrent_runs` - (Optional) Prevents exceeding the maximum number of concurrent runs of any of the component jobs. If you leave this parameter blank, there is no limit to the number of concurrent workflow runs.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of Glue Workflow\n* `id` - Workflow name\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGlue Workflows can be imported using `name`, e.g.,\n\n```\n$ terraform import aws_glue_workflow.MyWorkflow MyWorkflow\n```\n",
    "basename": "glue_workflow.html"
  },
  "guardduty_detector.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_detector",
    "description": "Provides a resource to manage a GuardDuty detector",
    "preview": "# Resource: aws_guardduty_detector\n\nProvides a resource to manage a …",
    "content": "\n\n# Resource: aws_guardduty_detector\n\nProvides a resource to manage a GuardDuty detector.\n\n~> **NOTE:** Deleting this resource is equivalent to \"disabling\" GuardDuty for an AWS region, which removes all existing findings. You can set the `enable` attribute to `false` to instead \"suspend\" monitoring and feedback reporting while keeping existing data. See the [Suspending or Disabling Amazon GuardDuty documentation](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_suspend-disable.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_guardduty_detector\" \"MyDetector\" {\n  enable = true\n\n  datasources {\n    s3_logs {\n      enable = true\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `enable` - (Optional) Enable monitoring and feedback reporting. Setting to `false` is equivalent to \"suspending\" GuardDuty. Defaults to `true`.\n* `finding_publishing_frequency` - (Optional) Specifies the frequency of notifications sent for subsequent finding occurrences. If the detector is a GuardDuty member account, the value is determined by the GuardDuty primary account and cannot be modified, otherwise defaults to `SIX_HOURS`. For standalone and GuardDuty primary accounts, it must be configured in Terraform to enable drift detection. Valid values for standalone and primary accounts: `FIFTEEN_MINUTES`, `ONE_HOUR`, `SIX_HOURS`. See [AWS Documentation](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_findings_cloudwatch.html#guardduty_findings_cloudwatch_notification_frequency) for more information.\n* `datasources` - (Optional) Describes which data sources will be enabled for the detector. See [Data Sources](#data-sources) below for more details.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Data Sources\n\nThe `datasources` block supports the following:\n\n* `s3_logs` - (Optional) Describes whether S3 data event logs are enabled as a data source. See [S3 Logs](#s3-logs) below for more details.\n\n### S3 Logs\n\nThis `s3_logs` block supports the following:\n\n* `enable` - (Required) If true, enables [S3 Protection](https://docs.aws.amazon.com/guardduty/latest/ug/s3_detection.html). Defaults to `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `account_id` - The AWS account ID of the GuardDuty detector\n* `arn` - Amazon Resource Name (ARN) of the GuardDuty detector\n* `id` - The ID of the GuardDuty detector\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGuardDuty detectors can be imported using the detector ID, e.g.,\n\n```\n$ terraform import aws_guardduty_detector.MyDetector 00b00fd5aecc0ab60a708659477e9617\n```\n",
    "basename": "guardduty_detector.html"
  },
  "guardduty_filter.html": {
    "layout": "aws",
    "subcategory": "GuardDuty",
    "page_title": "AWS: aws_guardduty_filter",
    "description": "Provides a resource to manage a GuardDuty filter",
    "preview": "# Resource: aws_guardduty_filter\n\nProvides a resource to manage a …",
    "content": "\n\n# Resource: aws_guardduty_filter\n\nProvides a resource to manage a GuardDuty filter.\n\n## Example Usage\n\n```terraform\nresource \"aws_guardduty_filter\" \"MyFilter\" {\n  name        = \"MyFilter\"\n  action      = \"ARCHIVE\"\n  detector_id = aws_guardduty_detector.example.id\n  rank        = 1\n\n  finding_criteria {\n    criterion {\n      field  = \"region\"\n      equals = [\"eu-west-1\"]\n    }\n\n    criterion {\n      field      = \"service.additionalInfo.threatListName\"\n      not_equals = [\"some-threat\", \"another-threat\"]\n    }\n\n    criterion {\n      field        = \"updatedAt\"\n      greater_than = \"2020-01-01T00:00:00Z\"\n      less_than    = \"2020-02-01T00:00:00Z\"\n    }\n\n    criterion {\n      field                 = \"severity\"\n      greater_than_or_equal = \"4\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `detector_id` - (Required) ID of a GuardDuty detector, attached to your account.\n* `name` - (Required) The name of your filter.\n* `description` - (Optional) Description of the filter.\n* `rank` - (Required) Specifies the position of the filter in the list of current filters. Also specifies the order in which this filter is applied to the findings.\n* `action` - (Required) Specifies the action that is to be applied to the findings that match the filter. Can be one of `ARCHIVE` or `NOOP`.\n* `tags` (Optional) - The tags that you want to add to the Filter resource. A tag consists of a key and a value. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `finding_criteria` (Required) - Represents the criteria to be used in the filter for querying findings. Contains one or more `criterion` blocks, documented [below](#criterion).\n\n### criterion\n\nThe `criterion` block suports the following:\n\n* `field` - (Required) The name of the field to be evaluated. The full list of field names can be found in [AWS documentation](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_filter-findings.html#filter_criteria).\n* `equals` - (Optional) List of string values to be evaluated.\n* `not_equals` - (Optional) List of string values to be evaluated.\n* `greater_than` - (Optional) A value to be evaluated. Accepts either an integer or a date in [RFC 3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `greater_than_or_equal` - (Optional) A value to be evaluated. Accepts either an integer or a date in [RFC 3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `less_than` - (Optional) A value to be evaluated. Accepts either an integer or a date in [RFC 3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `less_than_or_equal` - (Optional) A value to be evaluated. Accepts either an integer or a date in [RFC 3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the GuardDuty filter.\n* `id` - A compound field, consisting of the ID of the GuardDuty detector and the name of the filter.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGuardDuty filters can be imported using the detector ID and filter's name separated by a colon, e.g.,\n\n```\n$ terraform import aws_guardduty_filter.MyFilter 00b00fd5aecc0ab60a708659477e9617:MyFilter\n```\n",
    "basename": "guardduty_filter.html"
  },
  "guardduty_invite_accepter.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_invite_accepter",
    "description": "Provides a resource to accept a pending GuardDuty invite on creation, ensure the detector has the correct primary account on read, and disassociate with the primary account upon removal.",
    "preview": "# Resource: aws_guardduty_invite_accepter\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_guardduty_invite_accepter\n\nProvides a resource to accept a pending GuardDuty invite on creation, ensure the detector has the correct primary account on read, and disassociate with the primary account upon removal.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  alias = \"primary\"\n}\n\nprovider \"aws\" {\n  alias = \"member\"\n}\n\nresource \"aws_guardduty_invite_accepter\" \"member\" {\n  depends_on = [aws_guardduty_member.member]\n  provider   = aws.member\n\n  detector_id       = aws_guardduty_detector.member.id\n  master_account_id = aws_guardduty_detector.primary.account_id\n}\n\nresource \"aws_guardduty_member\" \"member\" {\n  provider    = aws.primary\n  account_id  = aws_guardduty_detector.member.account_id\n  detector_id = aws_guardduty_detector.primary.id\n  email       = \"required@example.com\"\n  invite      = true\n}\n\nresource \"aws_guardduty_detector\" \"primary\" {\n  provider = aws.primary\n}\n\nresource \"aws_guardduty_detector\" \"member\" {\n  provider = aws.member\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `detector_id` - (Required) The detector ID of the member GuardDuty account.\n* `master_account_id` - (Required) AWS account ID for primary account.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - GuardDuty member detector ID\n\n## Timeouts\n\n`aws_guardduty_invite_accepter` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `1m`) How long to wait for an invite to accept.\n\n## Import\n\n`aws_guardduty_invite_accepter` can be imported using the the member GuardDuty detector ID, e.g.,\n\n```\n$ terraform import aws_guardduty_invite_accepter.member 00b00fd5aecc0ab60a708659477e9617\n```\n",
    "basename": "guardduty_invite_accepter.html"
  },
  "guardduty_ipset.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_ipset",
    "description": "Provides a resource to manage a GuardDuty IPSet",
    "preview": "# Resource: aws_guardduty_ipset\n\nProvides a resource to manage a …",
    "content": "\n\n# Resource: aws_guardduty_ipset\n\nProvides a resource to manage a GuardDuty IPSet.\n\n~> **Note:** Currently in GuardDuty, users from member accounts cannot upload and further manage IPSets. IPSets that are uploaded by the primary account are imposed on GuardDuty functionality in its member accounts. See the [GuardDuty API Documentation](https://docs.aws.amazon.com/guardduty/latest/ug/create-ip-set.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_guardduty_ipset\" \"example\" {\n  activate    = true\n  detector_id = aws_guardduty_detector.primary.id\n  format      = \"TXT\"\n  location    = \"https://s3.amazonaws.com/${aws_s3_bucket_object.MyIPSet.bucket}/${aws_s3_bucket_object.MyIPSet.key}\"\n  name        = \"MyIPSet\"\n}\n\nresource \"aws_guardduty_detector\" \"primary\" {\n  enable = true\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  acl = \"private\"\n}\n\nresource \"aws_s3_bucket_object\" \"MyIPSet\" {\n  acl     = \"public-read\"\n  content = \"10.0.0.0/8\\n\"\n  bucket  = aws_s3_bucket.bucket.id\n  key     = \"MyIPSet\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `activate` - (Required) Specifies whether GuardDuty is to start using the uploaded IPSet.\n* `detector_id` - (Required) The detector ID of the GuardDuty.\n* `format` - (Required) The format of the file that contains the IPSet. Valid values: `TXT` | `STIX` | `OTX_CSV` | `ALIEN_VAULT` | `PROOF_POINT` | `FIRE_EYE`\n* `location` - (Required) The URI of the file that contains the IPSet.\n* `name` - (Required) The friendly name to identify the IPSet.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the GuardDuty IPSet.\n* `id` - The ID of the GuardDuty IPSet.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGuardDuty IPSet can be imported using the the primary GuardDuty detector ID and IPSet ID, e.g.,\n\n```\n$ terraform import aws_guardduty_ipset.MyIPSet 00b00fd5aecc0ab60a708659477e9617:123456789012\n```\n",
    "basename": "guardduty_ipset.html"
  },
  "guardduty_member.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_member",
    "description": "Provides a resource to manage a GuardDuty member",
    "preview": "# Resource: aws_guardduty_member\n\nProvides a resource to manage a …",
    "content": "\n\n# Resource: aws_guardduty_member\n\nProvides a resource to manage a GuardDuty member. To accept invitations in member accounts, see the [`aws_guardduty_invite_accepter` resource](/docs/providers/aws/r/guardduty_invite_accepter.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_guardduty_detector\" \"primary\" {\n  enable = true\n}\n\nresource \"aws_guardduty_detector\" \"member\" {\n  provider = aws.dev\n\n  enable = true\n}\n\nresource \"aws_guardduty_member\" \"member\" {\n  account_id         = aws_guardduty_detector.member.account_id\n  detector_id        = aws_guardduty_detector.primary.id\n  email              = \"required@example.com\"\n  invite             = true\n  invitation_message = \"please accept guardduty invitation\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Required) AWS account ID for member account.\n* `detector_id` - (Required) The detector ID of the GuardDuty account where you want to create member accounts.\n* `email` - (Required) Email address for member account.\n* `invite` - (Optional) Boolean whether to invite the account to GuardDuty as a member. Defaults to `false`. To detect if an invitation needs to be (re-)sent, the Terraform state value is `true` based on a `relationship_status` of `Disabled`, `Enabled`, `Invited`, or `EmailVerificationInProgress`.\n* `invitation_message` - (Optional) Message for invitation.\n* `disable_email_notification` - (Optional) Boolean whether an email notification is sent to the accounts. Defaults to `false`.\n\n## Timeouts\n\n`aws_guardduty_member` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `60s`) How long to wait for a verification to be done against inviting GuardDuty member account.\n- `update` - (Default `60s`) How long to wait for a verification to be done against inviting GuardDuty member account.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the GuardDuty member\n* `relationship_status` - The status of the relationship between the member account and its primary account. More information can be found in [Amazon GuardDuty API Reference](https://docs.aws.amazon.com/guardduty/latest/ug/get-members.html).\n\n## Import\n\nGuardDuty members can be imported using the the primary GuardDuty detector ID and member AWS account ID, e.g.,\n\n```\n$ terraform import aws_guardduty_member.MyMember 00b00fd5aecc0ab60a708659477e9617:123456789012\n```\n",
    "basename": "guardduty_member.html"
  },
  "guardduty_organization_admin_account.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_organization_admin_account",
    "description": "Manages a GuardDuty Organization Admin Account",
    "preview": "# Resource: aws_guardduty_organization_admin_account\n\nManages a …",
    "content": "\n\n# Resource: aws_guardduty_organization_admin_account\n\nManages a GuardDuty Organization Admin Account. The AWS account utilizing this resource must be an Organizations primary account. More information about Organizations support in GuardDuty can be found in the [GuardDuty User Guide](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_organizations.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"guardduty.amazonaws.com\"]\n  feature_set                   = \"ALL\"\n}\n\nresource \"aws_guardduty_detector\" \"example\" {}\n\nresource \"aws_guardduty_organization_admin_account\" \"example\" {\n  depends_on = [aws_organizations_organization.example]\n\n  admin_account_id = \"123456789012\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `admin_account_id` - (Required) AWS account identifier to designate as a delegated administrator for GuardDuty.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - AWS account identifier.\n\n## Import\n\nGuardDuty Organization Admin Account can be imported using the AWS account ID, e.g.,\n\n```\n$ terraform import aws_guardduty_organization_admin_account.example 123456789012\n```\n",
    "basename": "guardduty_organization_admin_account.html"
  },
  "guardduty_organization_configuration.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_organization_configuration",
    "description": "Manages the GuardDuty Organization Configuration",
    "preview": "# Resource: aws_guardduty_organization_configuration\n\nManages the …",
    "content": "\n\n# Resource: aws_guardduty_organization_configuration\n\nManages the GuardDuty Organization Configuration in the current AWS Region. The AWS account utilizing this resource must have been assigned as a delegated Organization administrator account, e.g., via the [`aws_guardduty_organization_admin_account` resource](/docs/providers/aws/r/guardduty_organization_admin_account.html). More information about Organizations support in GuardDuty can be found in the [GuardDuty User Guide](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_organizations.html).\n\n~> **NOTE:** This is an advanced Terraform resource. Terraform will automatically assume management of the GuardDuty Organization Configuration without import and perform no actions on removal from the Terraform configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_guardduty_detector\" \"example\" {\n  enable = true\n}\n\nresource \"aws_guardduty_organization_configuration\" \"example\" {\n  auto_enable = true\n  detector_id = aws_guardduty_detector.example.id\n\n  datasources {\n    s3_logs {\n      auto_enable = true\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `auto_enable` - (Required) When this setting is enabled, all new accounts that are created in, or added to, the organization are added as a member accounts of the organization’s GuardDuty delegated administrator and GuardDuty is enabled in that AWS Region.\n* `detector_id` - (Required) The detector ID of the GuardDuty account.\n* `datasources` - (Optional) Configuration for the collected datasources.\n\n`datasources` supports the following:\n\n* `s3_logs` - (Optional) Configuration for the builds to store logs to S3.\n\n`s3_logs` supports the following:\n\n* `auto_enable` - (Optional) Set to `true` if you want S3 data event logs to be automatically enabled for new members of the organization. Default: `false`\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier of the GuardDuty Detector.\n\n## Import\n\nGuardDuty Organization Configurations can be imported using the GuardDuty Detector ID, e.g.,\n\n```\n$ terraform import aws_guardduty_organization_configuration.example 00b00fd5aecc0ab60a708659477e9617\n```\n",
    "basename": "guardduty_organization_configuration.html"
  },
  "guardduty_publishing_destination.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_publishing_destination",
    "description": "Provides a resource to manage a GuardDuty PublishingDestination",
    "preview": "# Resource: aws_guardduty_publishing_destination\n\nProvides a …",
    "content": "\n\n# Resource: aws_guardduty_publishing_destination\n\nProvides a resource to manage a GuardDuty PublishingDestination. Requires an existing GuardDuty Detector.\n\n## Example Usage\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_region\" \"current\" {}\n\ndata \"aws_iam_policy_document\" \"bucket_pol\" {\n  statement {\n    sid = \"Allow PutObject\"\n    actions = [\n      \"s3:PutObject\"\n    ]\n\n    resources = [\n      \"${aws_s3_bucket.gd_bucket.arn}/*\"\n    ]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"guardduty.amazonaws.com\"]\n    }\n  }\n\n  statement {\n    sid = \"Allow GetBucketLocation\"\n    actions = [\n      \"s3:GetBucketLocation\"\n    ]\n\n    resources = [\n      aws_s3_bucket.gd_bucket.arn\n    ]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"guardduty.amazonaws.com\"]\n    }\n  }\n}\n\ndata \"aws_iam_policy_document\" \"kms_pol\" {\n\n  statement {\n    sid = \"Allow GuardDuty to encrypt findings\"\n    actions = [\n      \"kms:GenerateDataKey\"\n    ]\n\n    resources = [\n      \"arn:aws:kms:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:key/*\"\n    ]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"guardduty.amazonaws.com\"]\n    }\n  }\n\n  statement {\n    sid = \"Allow all users to modify/delete key (test only)\"\n    actions = [\n      \"kms:*\"\n    ]\n\n    resources = [\n      \"arn:aws:kms:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:key/*\"\n    ]\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"]\n    }\n  }\n\n}\n\nresource \"aws_guardduty_detector\" \"test_gd\" {\n  enable = true\n}\n\nresource \"aws_s3_bucket\" \"gd_bucket\" {\n  bucket        = \"example\"\n  acl           = \"private\"\n  force_destroy = true\n}\n\nresource \"aws_s3_bucket_policy\" \"gd_bucket_policy\" {\n  bucket = aws_s3_bucket.gd_bucket.id\n  policy = data.aws_iam_policy_document.bucket_pol.json\n}\n\nresource \"aws_kms_key\" \"gd_key\" {\n  description             = \"Temporary key for AccTest of TF\"\n  deletion_window_in_days = 7\n  policy                  = data.aws_iam_policy_document.kms_pol.json\n}\n\nresource \"aws_guardduty_publishing_destination\" \"test\" {\n  detector_id     = aws_guardduty_detector.test_gd.id\n  destination_arn = aws_s3_bucket.gd_bucket.arn\n  kms_key_arn     = aws_kms_key.gd_key.arn\n\n  depends_on = [\n    aws_s3_bucket_policy.gd_bucket_policy,\n  ]\n}\n```\n\n~> **Note:** Please do not use this simple example for Bucket-Policy and KMS Key Policy in a production environment. It is much too open for such a use-case. Refer to the AWS documentation here: https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_exportfindings.html\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `detector_id` - (Required) The detector ID of the GuardDuty.\n* `destination_arn` - (Required) The bucket arn and prefix under which the findings get exported. Bucket-ARN is required, the prefix is optional and will be `AWSLogs/[Account-ID]/GuardDuty/[Region]/` if not provided\n* `kms_key_arn` - (Required) The ARN of the KMS key used to encrypt GuardDuty findings. GuardDuty enforces this to be encrypted.\n* `destination_type`- (Optional) Currently there is only \"S3\" available as destination type which is also the default value\n\n\n~> **Note:** In case of missing permissions (S3 Bucket Policy _or_ KMS Key permissions) the resource will fail to create. If the permissions are changed after resource creation, this can be asked from the AWS API via the \"DescribePublishingDestination\" call (https://docs.aws.amazon.com/cli/latest/reference/guardduty/describe-publishing-destination.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the GuardDuty PublishingDestination and the detector ID. Format: `<DetectorID>:<PublishingDestinationID>`\n\n## Import\n\nGuardDuty PublishingDestination can be imported using the the master GuardDuty detector ID and PublishingDestinationID, e.g.,\n\n```\n$ terraform import aws_guardduty_publishing_destination.test a4b86f26fa42e7e7cf0d1c333ea77777:a4b86f27a0e464e4a7e0516d242f1234\n```\n",
    "basename": "guardduty_publishing_destination.html"
  },
  "guardduty_threatintelset.html": {
    "subcategory": "GuardDuty",
    "layout": "aws",
    "page_title": "AWS: aws_guardduty_threatintelset",
    "description": "Provides a resource to manage a GuardDuty ThreatIntelSet",
    "preview": "# Resource: aws_guardduty_threatintelset\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_guardduty_threatintelset\n\nProvides a resource to manage a GuardDuty ThreatIntelSet.\n\n~> **Note:** Currently in GuardDuty, users from member accounts cannot upload and further manage ThreatIntelSets. ThreatIntelSets that are uploaded by the primary account are imposed on GuardDuty functionality in its member accounts. See the [GuardDuty API Documentation](https://docs.aws.amazon.com/guardduty/latest/ug/create-threat-intel-set.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_guardduty_detector\" \"primary\" {\n  enable = true\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  acl = \"private\"\n}\n\nresource \"aws_s3_bucket_object\" \"MyThreatIntelSet\" {\n  acl     = \"public-read\"\n  content = \"10.0.0.0/8\\n\"\n  bucket  = aws_s3_bucket.bucket.id\n  key     = \"MyThreatIntelSet\"\n}\n\nresource \"aws_guardduty_threatintelset\" \"MyThreatIntelSet\" {\n  activate    = true\n  detector_id = aws_guardduty_detector.primary.id\n  format      = \"TXT\"\n  location    = \"https://s3.amazonaws.com/${aws_s3_bucket_object.MyThreatIntelSet.bucket}/${aws_s3_bucket_object.MyThreatIntelSet.key}\"\n  name        = \"MyThreatIntelSet\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `activate` - (Required) Specifies whether GuardDuty is to start using the uploaded ThreatIntelSet.\n* `detector_id` - (Required) The detector ID of the GuardDuty.\n* `format` - (Required) The format of the file that contains the ThreatIntelSet. Valid values: `TXT` | `STIX` | `OTX_CSV` | `ALIEN_VAULT` | `PROOF_POINT` | `FIRE_EYE`\n* `location` - (Required) The URI of the file that contains the ThreatIntelSet.\n* `name` - (Required) The friendly name to identify the ThreatIntelSet.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the GuardDuty ThreatIntelSet.\n* `id` - The ID of the GuardDuty ThreatIntelSet and the detector ID. Format: `<DetectorID>:<ThreatIntelSetID>`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nGuardDuty ThreatIntelSet can be imported using the the primary GuardDuty detector ID and ThreatIntelSetID, e.g.,\n\n```\n$ terraform import aws_guardduty_threatintelset.MyThreatIntelSet 00b00fd5aecc0ab60a708659477e9617:123456789012\n```\n",
    "basename": "guardduty_threatintelset.html"
  },
  "iam_access_key.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_access_key",
    "description": "Provides an IAM access key. This is a set of credentials that allow API requests to be made as an IAM user.",
    "preview": "# Resource: aws_iam_access_key\n\nProvides an IAM access key. This is …",
    "content": "\n\n# Resource: aws_iam_access_key\n\nProvides an IAM access key. This is a set of credentials that allow API requests to be made as an IAM user.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_access_key\" \"lb\" {\n  user    = aws_iam_user.lb.name\n  pgp_key = \"keybase:some_person_that_exists\"\n}\n\nresource \"aws_iam_user\" \"lb\" {\n  name = \"loadbalancer\"\n  path = \"/system/\"\n}\n\nresource \"aws_iam_user_policy\" \"lb_ro\" {\n  name = \"test\"\n  user = aws_iam_user.lb.name\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:Describe*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n\noutput \"secret\" {\n  value = aws_iam_access_key.lb.encrypted_secret\n}\n```\n\n```terraform\nresource \"aws_iam_user\" \"test\" {\n  name = \"test\"\n  path = \"/test/\"\n}\n\nresource \"aws_iam_access_key\" \"test\" {\n  user = aws_iam_user.test.name\n}\n\noutput \"aws_iam_smtp_password_v4\" {\n  value = aws_iam_access_key.test.ses_smtp_password_v4\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `pgp_key` - (Optional) Either a base-64 encoded PGP public key, or a keybase username in the form `keybase:some_person_that_exists`, for use in the `encrypted_secret` output attribute.\n* `status` - (Optional) Access key status to apply. Defaults to `Active`. Valid values are `Active` and `Inactive`.\n* `user` - (Required) IAM user to associate with this access key.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `create_date` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) that the access key was created.\n* `encrypted_secret` - Encrypted secret, base64 encoded, if `pgp_key` was specified. This attribute is not available for imported resources. The encrypted secret may be decrypted using the command line, for example: `terraform output -raw encrypted_secret | base64 --decode | keybase pgp decrypt`.\n* `encrypted_ses_smtp_password_v4` - Encrypted SES SMTP password, base64 encoded, if `pgp_key` was specified. This attribute is not available for imported resources. The encrypted password may be decrypted using the command line, for example: `terraform output -raw encrypted_ses_smtp_password_v4 | base64 --decode | keybase pgp decrypt`.\n* `id` - Access key ID.\n* `key_fingerprint` - Fingerprint of the PGP key used to encrypt the secret. This attribute is not available for imported resources.\n* `secret` - Secret access key. This attribute is not available for imported resources. Note that this will be written to the state file. If you use this, please protect your backend state file judiciously. Alternatively, you may supply a `pgp_key` instead, which will prevent the secret from being stored in plaintext, at the cost of preventing the use of the secret key in automation.\n* `ses_smtp_password_v4` - Secret access key converted into an SES SMTP password by applying [AWS's documented Sigv4 conversion algorithm](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-credentials.html#smtp-credentials-convert). This attribute is not available for imported resources. As SigV4 is region specific, valid Provider regions are `ap-south-1`, `ap-southeast-2`, `eu-central-1`, `eu-west-1`, `us-east-1` and `us-west-2`. See current [AWS SES regions](https://docs.aws.amazon.com/general/latest/gr/rande.html#ses_region).\n\n## Import\n\nIAM Access Keys can be imported using the identifier, e.g.,\n\n```\n$ terraform import aws_iam_access_key.example AKIA1234567890\n```\n\nResource attributes such as `encrypted_secret`, `key_fingerprint`, `pgp_key`, `secret`, `ses_smtp_password_v4`, and `encrypted_ses_smtp_password_v4` are not available for imported resources as this information cannot be read from the IAM API.\n",
    "basename": "iam_access_key.html"
  },
  "iam_account_alias.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_account_alias",
    "description": "Manages the account alias for the AWS Account.",
    "preview": "# Resource: aws_iam_account_alias\n\n-> **Note:** There is only a …",
    "content": "\n\n# Resource: aws_iam_account_alias\n\n-> **Note:** There is only a single account alias per AWS account.\n\nManages the account alias for the AWS Account.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_account_alias\" \"alias\" {\n  account_alias = \"my-account-alias\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_alias` - (Required) The account alias\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nThe current Account Alias can be imported using the `account_alias`, e.g.,\n\n```\n$ terraform import aws_iam_account_alias.alias my-account-alias\n```\n",
    "basename": "iam_account_alias.html"
  },
  "iam_account_password_policy.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_account_password_policy",
    "description": "Manages Password Policy for the AWS Account.",
    "preview": "# Resource: aws_iam_account_password_policy\n\n-> **Note:** There is …",
    "content": "\n\n# Resource: aws_iam_account_password_policy\n\n-> **Note:** There is only a single policy allowed per AWS account. An existing policy will be lost when using this resource as an effect of this limitation.\n\nManages Password Policy for the AWS Account.\nSee more about [Account Password Policy](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html)\nin the official AWS docs.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_account_password_policy\" \"strict\" {\n  minimum_password_length        = 8\n  require_lowercase_characters   = true\n  require_numbers                = true\n  require_uppercase_characters   = true\n  require_symbols                = true\n  allow_users_to_change_password = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `allow_users_to_change_password` - (Optional) Whether to allow users to change their own password\n* `hard_expiry` - (Optional) Whether users are prevented from setting a new password after their password has expired (i.e., require administrator reset)\n* `max_password_age` - (Optional) The number of days that an user password is valid.\n* `minimum_password_length` - (Optional) Minimum length to require for user passwords.\n* `password_reuse_prevention` - (Optional) The number of previous passwords that users are prevented from reusing.\n* `require_lowercase_characters` - (Optional) Whether to require lowercase characters for user passwords.\n* `require_numbers` - (Optional) Whether to require numbers for user passwords.\n* `require_symbols` - (Optional) Whether to require symbols for user passwords.\n* `require_uppercase_characters` - (Optional) Whether to require uppercase characters for user passwords.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `expire_passwords` - Indicates whether passwords in the account expire. Returns `true` if `max_password_age` contains a value greater than `0`. Returns `false` if it is `0` or _not present_.\n\n\n## Import\n\nIAM Account Password Policy can be imported using the word `iam-account-password-policy`, e.g.,\n\n```\n$ terraform import aws_iam_account_password_policy.strict iam-account-password-policy\n```\n",
    "basename": "iam_account_password_policy.html"
  },
  "iam_group.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_group",
    "description": "Provides an IAM group.",
    "preview": "# Resource: aws_iam_group\n\nProvides an IAM group.\n\n## Example Usage\n …",
    "content": "\n\n# Resource: aws_iam_group\n\nProvides an IAM group.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_group\" \"developers\" {\n  name = \"developers\"\n  path = \"/users/\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The group's name. The name must consist of upper and lowercase alphanumeric characters with no spaces. You can also include any of the following characters: `=,.@-_.`. Group names are not distinguished by case. For example, you cannot create groups named both \"ADMINS\" and \"admins\".\n* `path` - (Optional, default \"/\") Path in which to create the group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The group's ID.\n* `arn` - The ARN assigned by AWS for this group.\n* `name` - The group's name.\n* `path` - The path of the group in IAM.\n* `unique_id` - The [unique ID][1] assigned by AWS.\n\n  [1]: https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html#GUIDs\n\n## Import\n\nIAM Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_iam_group.developers developers\n```\n",
    "basename": "iam_group.html"
  },
  "iam_group_membership.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_group_membership",
    "description": "Provides a top level resource to manage IAM Group membership for IAM Users.",
    "preview": "# Resource: aws_iam_group_membership\n\n~> **WARNING:** Multiple …",
    "content": "\n\n# Resource: aws_iam_group_membership\n\n~> **WARNING:** Multiple aws_iam_group_membership resources with the same group name will produce inconsistent behavior!\n\nProvides a top level resource to manage IAM Group membership for IAM Users. For\nmore information on managing IAM Groups or IAM Users, see [IAM Groups][1] or\n[IAM Users][2]\n\n~> **Note:** `aws_iam_group_membership` will conflict with itself if used more than once with the same group. To non-exclusively manage the users in a group, see the\n[`aws_iam_user_group_membership` resource][3].\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_group_membership\" \"team\" {\n  name = \"tf-testing-group-membership\"\n\n  users = [\n    aws_iam_user.user_one.name,\n    aws_iam_user.user_two.name,\n  ]\n\n  group = aws_iam_group.group.name\n}\n\nresource \"aws_iam_group\" \"group\" {\n  name = \"test-group\"\n}\n\nresource \"aws_iam_user\" \"user_one\" {\n  name = \"test-user\"\n}\n\nresource \"aws_iam_user\" \"user_two\" {\n  name = \"test-user-two\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name to identify the Group Membership\n* `users` - (Required) A list of IAM User names to associate with the Group\n* `group` – (Required) The IAM Group name to attach the list of `users` to\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `name` - The name to identify the Group Membership\n* `users` - list of IAM User names\n* `group` – IAM Group name\n\n\n[1]: /docs/providers/aws/r/iam_group.html\n[2]: /docs/providers/aws/r/iam_user.html\n[3]: /docs/providers/aws/r/iam_user_group_membership.html\n",
    "basename": "iam_group_membership.html"
  },
  "iam_group_policy.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_group_policy",
    "description": "Provides an IAM policy attached to a group.",
    "preview": "# Resource: aws_iam_group_policy\n\nProvides an IAM policy attached to …",
    "content": "\n\n# Resource: aws_iam_group_policy\n\nProvides an IAM policy attached to a group.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_group_policy\" \"my_developer_policy\" {\n  name  = \"my_developer_policy\"\n  group = aws_iam_group.my_developers.name\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"ec2:Describe*\",\n        ]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_group\" \"my_developers\" {\n  name = \"developers\"\n  path = \"/users/\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy` - (Required) The policy document. This is a JSON formatted string. For more information about building IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy)\n* `name` - (Optional) The name of the policy. If omitted, Terraform will\nassign a random, unique name.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified\n  prefix. Conflicts with `name`.\n* `group` - (Required) The IAM group to attach to the policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The group policy ID.\n* `group` - The group to which this policy applies.\n* `name` - The name of the policy.\n* `policy` - The policy document attached to the group.\n\n## Import\n\nIAM Group Policies can be imported using the `group_name:group_policy_name`, e.g.,\n\n```\n$ terraform import aws_iam_group_policy.mypolicy group_of_mypolicy_name:mypolicy_name\n```\n",
    "basename": "iam_group_policy.html"
  },
  "iam_group_policy_attachment": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_group_policy_attachment",
    "description": "Attaches a Managed IAM Policy to an IAM group",
    "preview": "# Resource: aws_iam_group_policy_attachment\n\nAttaches a Managed IAM …",
    "content": "\n\n# Resource: aws_iam_group_policy_attachment\n\nAttaches a Managed IAM Policy to an IAM group\n\n~> **NOTE:** The usage of this resource conflicts with the `aws_iam_policy_attachment` resource and will permanently show a difference if both are defined.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_group\" \"group\" {\n  name = \"test-group\"\n}\n\nresource \"aws_iam_policy\" \"policy\" {\n  name        = \"test-policy\"\n  description = \"A test policy\"\n  policy      = \"{ ... policy JSON ... }\"\n}\n\nresource \"aws_iam_group_policy_attachment\" \"test-attach\" {\n  group      = aws_iam_group.group.name\n  policy_arn = aws_iam_policy.policy.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `group`  (Required) - The group the policy should be applied to\n* `policy_arn`  (Required) - The ARN of the policy you want to apply\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nIAM group policy attachments can be imported using the group name and policy arn separated by `/`.\n\n```\n$ terraform import aws_iam_group_policy_attachment.test-attach test-group/arn:aws:iam::xxxxxxxxxxxx:policy/test-policy\n```\n",
    "basename": "iam_group_policy_attachment"
  },
  "iam_instance_profile.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_instance_profile",
    "description": "Provides an IAM instance profile.",
    "preview": "# Resource: aws_iam_instance_profile\n\nProvides an IAM instance …",
    "content": "\n\n# Resource: aws_iam_instance_profile\n\nProvides an IAM instance profile.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_instance_profile\" \"test_profile\" {\n  name = \"test_profile\"\n  role = aws_iam_role.role.name\n}\n\nresource \"aws_iam_role\" \"role\" {\n  name = \"test_role\"\n  path = \"/\"\n\n  assume_role_policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"sts:AssumeRole\",\n            \"Principal\": {\n               \"Service\": \"ec2.amazonaws.com\"\n            },\n            \"Effect\": \"Allow\",\n            \"Sid\": \"\"\n        }\n    ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are optional:\n\n* `name` - (Optional, Forces new resource) Name of the instance profile. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`. Can be a string of characters consisting of upper and lowercase alphanumeric characters and these special characters: `_`, `+`, `=`, `,`, `.`, `@`, `-`. Spaces are not allowed.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `path` - (Optional, default \"/\") Path to the instance profile. For more information about paths, see [IAM Identifiers](https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html) in the IAM User Guide. Can be a string of characters consisting of either a forward slash (`/`) by itself or a string that must begin and end with forward slashes. Can include any ASCII character from the ! (\\u0021) through the DEL character (\\u007F), including most punctuation characters, digits, and upper and lowercase letters.\n* `role` - (Optional) Name of the role to add to the profile.\n* `tags` - (Optional) Map of resource tags for the IAM Instance Profile. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN assigned by AWS to the instance profile.\n* `create_date` - Creation timestamp of the instance profile.\n* `id` - Instance profile's ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `unique_id` - [Unique ID][1] assigned by AWS.\n\n  [1]: https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html#GUIDs\n\n\n## Import\n\nInstance Profiles can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_iam_instance_profile.test_profile app-instance-profile-1\n```\n",
    "basename": "iam_instance_profile.html"
  },
  "iam_openid_connect_provider.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_openid_connect_provider",
    "description": "Provides an IAM OpenID Connect provider.",
    "preview": "# Resource: aws_iam_openid_connect_provider\n\nProvides an IAM OpenID …",
    "content": "\n\n# Resource: aws_iam_openid_connect_provider\n\nProvides an IAM OpenID Connect provider.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_openid_connect_provider\" \"default\" {\n  url = \"https://accounts.google.com\"\n\n  client_id_list = [\n    \"266362248691-342342xasdasdasda-apps.googleusercontent.com\",\n  ]\n\n  thumbprint_list = []\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `url` - (Required) The URL of the identity provider. Corresponds to the _iss_ claim.\n* `client_id_list` - (Required) A list of client IDs (also known as audiences). When a mobile or web app registers with an OpenID Connect provider, they establish a value that identifies the application. (This is the value that's sent as the client_id parameter on OAuth requests.)\n* `thumbprint_list` - (Required) A list of server certificate thumbprints for the OpenID Connect (OIDC) identity provider's server certificate(s).\n* `tags` - (Optional) Map of resource tags for the IAM OIDC provider. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS for this provider.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nIAM OpenID Connect Providers can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_iam_openid_connect_provider.default arn:aws:iam::123456789012:oidc-provider/accounts.google.com\n```\n",
    "basename": "iam_openid_connect_provider.html"
  },
  "iam_policy.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_policy",
    "description": "Provides an IAM policy.",
    "preview": "# Resource: aws_iam_policy\n\nProvides an IAM policy.\n\n## Example …",
    "content": "\n\n# Resource: aws_iam_policy\n\nProvides an IAM policy.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_policy\" \"policy\" {\n  name        = \"test_policy\"\n  path        = \"/\"\n  description = \"My test policy\"\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"ec2:Describe*\",\n        ]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },\n    ]\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional, Forces new resource) Description of the IAM policy.\n* `name` - (Optional, Forces new resource) The name of the policy. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `path` - (Optional, default \"/\") Path in which to create the policy.\n  See [IAM Identifiers](https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html) for more information.\n* `policy` - (Required) The policy document. This is a JSON formatted string. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy)\n* `tags` - (Optional) Map of resource tags for the IAM Policy. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN assigned by AWS to this policy.\n* `arn` - The ARN assigned by AWS to this policy.\n* `description` - The description of the policy.\n* `name` - The name of the policy.\n* `path` - The path of the policy in IAM.\n* `policy` - The policy document.\n* `policy_id` - The policy's ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nIAM Policies can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_iam_policy.administrator arn:aws:iam::123456789012:policy/UsersManageOwnCredentials\n```\n",
    "basename": "iam_policy.html"
  },
  "iam_policy_attachment.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_policy_attachment",
    "description": "Attaches a Managed IAM Policy to user(s), role(s), and/or group(s)",
    "preview": "# Resource: aws_iam_policy_attachment\n\nAttaches a Managed IAM Policy …",
    "content": "\n\n# Resource: aws_iam_policy_attachment\n\nAttaches a Managed IAM Policy to user(s), role(s), and/or group(s)\n\n!> **WARNING:** The aws_iam_policy_attachment resource creates **exclusive** attachments of IAM policies. Across the entire AWS account, all of the users/roles/groups to which a single policy is attached must be declared by a single aws_iam_policy_attachment resource. This means that even any users/roles/groups that have the attached policy via any other mechanism (including other Terraform resources) will have that attached policy revoked by this resource. Consider `aws_iam_role_policy_attachment`, `aws_iam_user_policy_attachment`, or `aws_iam_group_policy_attachment` instead. These resources do not enforce exclusive attachment of an IAM policy.\n\n~> **NOTE:** The usage of this resource conflicts with the `aws_iam_group_policy_attachment`, `aws_iam_role_policy_attachment`, and `aws_iam_user_policy_attachment` resources and will permanently show a difference if both are defined.\n\n~> **NOTE:** For a given role, this resource is incompatible with using the [`aws_iam_role` resource](/docs/providers/aws/r/iam_role.html) `managed_policy_arns` argument. When using that argument and this resource, both will attempt to manage the role's managed policy attachments and Terraform will show a permanent difference.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_user\" \"user\" {\n  name = \"test-user\"\n}\n\nresource \"aws_iam_role\" \"role\" {\n  name = \"test-role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_group\" \"group\" {\n  name = \"test-group\"\n}\n\nresource \"aws_iam_policy\" \"policy\" {\n  name        = \"test-policy\"\n  description = \"A test policy\"\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:Describe*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_policy_attachment\" \"test-attach\" {\n  name       = \"test-attachment\"\n  users      = [aws_iam_user.user.name]\n  roles      = [aws_iam_role.role.name]\n  groups     = [aws_iam_group.group.name]\n  policy_arn = aws_iam_policy.policy.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name`    (Required) - The name of the attachment. This cannot be an empty string.\n* `users`   (Optional) - The user(s) the policy should be applied to\n* `roles`   (Optional) - The role(s) the policy should be applied to\n* `groups`  (Optional) - The group(s) the policy should be applied to\n* `policy_arn`  (Required) - The ARN of the policy you want to apply\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The policy's ID.\n* `name` - The name of the attachment.\n",
    "basename": "iam_policy_attachment.html"
  },
  "iam_role.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_role",
    "description": "Provides an IAM role.",
    "preview": "# Resource: aws_iam_role\n\nProvides an IAM role.\n\n~> **NOTE:** If …",
    "content": "\n\n# Resource: aws_iam_role\n\nProvides an IAM role.\n\n~> **NOTE:** If policies are attached to the role via the [`aws_iam_policy_attachment` resource](/docs/providers/aws/r/iam_policy_attachment.html) and you are modifying the role `name` or `path`, the `force_detach_policies` argument must be set to `true` and applied before attempting the operation otherwise you will encounter a `DeleteConflict` error. The [`aws_iam_role_policy_attachment` resource (recommended)](/docs/providers/aws/r/iam_role_policy_attachment.html) does not have this requirement.\n\n~> **NOTE:** If you use this resource's `managed_policy_arns` argument or `inline_policy` configuration blocks, this resource will take over exclusive management of the role's respective policy types (e.g., both policy types if both arguments are used). These arguments are incompatible with other ways of managing a role's policies, such as [`aws_iam_policy_attachment`](/docs/providers/aws/r/iam_policy_attachment.html), [`aws_iam_role_policy_attachment`](/docs/providers/aws/r/iam_role_policy_attachment.html), and [`aws_iam_role_policy`](/docs/providers/aws/r/iam_role_policy.html). If you attempt to manage a role's policies by multiple means, you will get resource cycling and/or errors.\n\n## Example Usage\n\n### Basic Example\n\n```terraform\nresource \"aws_iam_role\" \"test_role\" {\n  name = \"test_role\"\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Sid    = \"\"\n        Principal = {\n          Service = \"ec2.amazonaws.com\"\n        }\n      },\n    ]\n  })\n\n  tags = {\n    tag-key = \"tag-value\"\n  }\n}\n```\n\n### Example of Using Data Source for Assume Role Policy\n\n```terraform\ndata \"aws_iam_policy_document\" \"instance-assume-role-policy\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"ec2.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"instance\" {\n  name               = \"instance_role\"\n  path               = \"/system/\"\n  assume_role_policy = data.aws_iam_policy_document.instance-assume-role-policy.json\n}\n```\n\n### Example of Exclusive Inline Policies\n\nThis example creates an IAM role with two inline IAM policies. If someone adds another inline policy out-of-band, on the next apply, Terraform will remove that policy. If someone deletes these policies out-of-band, Terraform will recreate them.\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name               = \"yak_role\"\n  assume_role_policy = data.aws_iam_policy_document.instance_assume_role_policy.json # (not shown)\n\n  inline_policy {\n    name = \"my_inline_policy\"\n\n    policy = jsonencode({\n      Version = \"2012-10-17\"\n      Statement = [\n        {\n          Action   = [\"ec2:Describe*\"]\n          Effect   = \"Allow\"\n          Resource = \"*\"\n        },\n      ]\n    })\n  }\n\n  inline_policy {\n    name   = \"policy-8675309\"\n    policy = data.aws_iam_policy_document.inline_policy.json\n  }\n}\n\ndata \"aws_iam_policy_document\" \"inline_policy\" {\n  statement {\n    actions   = [\"ec2:DescribeAccountAttributes\"]\n    resources = [\"*\"]\n  }\n}\n```\n\n### Example of Removing Inline Policies\n\nThis example creates an IAM role with what appears to be empty IAM `inline_policy` argument instead of using `inline_policy` as a configuration block. The result is that if someone were to add an inline policy out-of-band, on the next apply, Terraform will remove that policy.\n\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name               = \"yak_role\"\n  assume_role_policy = data.aws_iam_policy_document.instance_assume_role_policy.json # (not shown)\n\n  inline_policy {}\n}\n```\n\n### Example of Exclusive Managed Policies\n\nThis example creates an IAM role and attaches two managed IAM policies. If someone attaches another managed policy out-of-band, on the next apply, Terraform will detach that policy. If someone detaches these policies out-of-band, Terraform will attach them again.\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name                = \"yak_role\"\n  assume_role_policy  = data.aws_iam_policy_document.instance_assume_role_policy.json # (not shown)\n  managed_policy_arns = [aws_iam_policy.policy_one.arn, aws_iam_policy.policy_two.arn]\n}\n\nresource \"aws_iam_policy\" \"policy_one\" {\n  name = \"policy-618033\"\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action   = [\"ec2:Describe*\"]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_policy\" \"policy_two\" {\n  name = \"policy-381966\"\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action   = [\"s3:ListAllMyBuckets\", \"s3:ListBucket\", \"s3:HeadBucket\"]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },\n    ]\n  })\n}\n```\n\n### Example of Removing Managed Policies\n\nThis example creates an IAM role with an empty `managed_policy_arns` argument. If someone attaches a policy out-of-band, on the next apply, Terraform will detach that policy.\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name                = \"yak_role\"\n  assume_role_policy  = data.aws_iam_policy_document.instance_assume_role_policy.json # (not shown)\n  managed_policy_arns = []\n}\n```\n\n## Argument Reference\n\nThe following argument is required:\n\n* `assume_role_policy` - (Required) Policy that grants an entity permission to assume the role.\n\n~> **NOTE:** The `assume_role_policy` is very similar to but slightly different than a standard IAM policy and cannot use an `aws_iam_policy` resource.  However, it _can_ use an `aws_iam_policy_document` [data source](/docs/providers/aws/d/iam_policy_document.html). See the example above of how this works.\n\nThe following arguments are optional:\n\n* `description` - (Optional) Description of the role.\n* `force_detach_policies` - (Optional) Whether to force detaching any policies the role has before destroying it. Defaults to `false`.\n* `inline_policy` - (Optional) Configuration block defining an exclusive set of IAM inline policies associated with the IAM role. See below. If no blocks are configured, Terraform will not manage any inline policies in this resource. Configuring one empty block (i.e., `inline_policy {}`) will cause Terraform to remove _all_ inline policies added out of band on `apply`.\n* `managed_policy_arns` - (Optional) Set of exclusive IAM managed policy ARNs to attach to the IAM role. If this attribute is not configured, Terraform will ignore policy attachments to this resource. When configured, Terraform will align the role's managed policy attachments with this set by attaching or detaching managed policies. Configuring an empty set (i.e., `managed_policy_arns = []`) will cause Terraform to remove _all_ managed policy attachments.\n* `max_session_duration` - (Optional) Maximum session duration (in seconds) that you want to set for the specified role. If you do not specify a value for this setting, the default maximum of one hour is applied. This setting can have a value from 1 hour to 12 hours.\n* `name` - (Optional, Forces new resource) Friendly name of the role. If omitted, Terraform will assign a random, unique name. See [IAM Identifiers](https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html) for more information.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique friendly name beginning with the specified prefix. Conflicts with `name`.\n* `path` - (Optional) Path to the role. See [IAM Identifiers](https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html) for more information.\n* `permissions_boundary` - (Optional) ARN of the policy that is used to set the permissions boundary for the role.\n* `tags` - Key-value mapping of tags for the IAM role. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### inline_policy\n\nThis configuration block supports the following:\n\n~> **NOTE:** Since one empty block (i.e., `inline_policy {}`) is valid syntactically to remove out of band policies on `apply`, `name` and `policy` are technically _optional_. However, they are both _required_ in order to manage actual inline policies. Not including one or the other may not result in Terraform errors but will result in unpredictable and incorrect behavior.\n\n* `name` - (Required) Name of the role policy.\n* `policy` - (Required) Policy document as a JSON formatted string. For more information about building IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/tutorials/terraform/aws-iam-policy).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) specifying the role.\n* `create_date` - Creation date of the IAM role.\n* `id` - Name of the role.\n* `name` - Name of the role.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `unique_id` - Stable and unique string identifying the role.\n\n## Import\n\nIAM Roles can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_iam_role.developer developer_name\n```\n",
    "basename": "iam_role.html"
  },
  "iam_role_policy.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_role_policy",
    "description": "Provides an IAM role policy.",
    "preview": "# Resource: aws_iam_role_policy\n\nProvides an IAM role inline policy. …",
    "content": "\n\n# Resource: aws_iam_role_policy\n\nProvides an IAM role inline policy.\n\n~> **NOTE:** For a given role, this resource is incompatible with using the [`aws_iam_role` resource](/docs/providers/aws/r/iam_role.html) `inline_policy` argument. When using that argument and this resource, both will attempt to manage the role's inline policies and Terraform will show a permanent difference.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_role_policy\" \"test_policy\" {\n  name = \"test_policy\"\n  role = aws_iam_role.test_role.id\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"ec2:Describe*\",\n        ]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_role\" \"test_role\" {\n  name = \"test_role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Sid    = \"\"\n        Principal = {\n          Service = \"ec2.amazonaws.com\"\n        }\n      },\n    ]\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the role policy. If omitted, Terraform will\nassign a random, unique name.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified\n  prefix. Conflicts with `name`.\n* `policy` - (Required) The inline policy document. This is a JSON formatted string. For more information about building IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy)\n* `role` - (Required) The IAM role to attach to the policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The role policy ID, in the form of `role_name:role_policy_name`.\n* `name` - The name of the policy.\n* `policy` - The policy document attached to the role.\n* `role` - The name of the role associated with the policy.\n\n## Import\n\nIAM Role Policies can be imported using the `role_name:role_policy_name`, e.g.,\n\n```\n$ terraform import aws_iam_role_policy.mypolicy role_of_mypolicy_name:mypolicy_name\n```\n",
    "basename": "iam_role_policy.html"
  },
  "iam_role_policy_attachment": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_role_policy_attachment",
    "description": "Attaches a Managed IAM Policy to an IAM role",
    "preview": "# Resource: aws_iam_role_policy_attachment\n\nAttaches a Managed IAM …",
    "content": "\n\n# Resource: aws_iam_role_policy_attachment\n\nAttaches a Managed IAM Policy to an IAM role\n\n~> **NOTE:** The usage of this resource conflicts with the `aws_iam_policy_attachment` resource and will permanently show a difference if both are defined.\n\n~> **NOTE:** For a given role, this resource is incompatible with using the [`aws_iam_role` resource](/docs/providers/aws/r/iam_role.html) `managed_policy_arns` argument. When using that argument and this resource, both will attempt to manage the role's managed policy attachments and Terraform will show a permanent difference.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_role\" \"role\" {\n  name = \"test-role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_policy\" \"policy\" {\n  name        = \"test-policy\"\n  description = \"A test policy\"\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:Describe*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"test-attach\" {\n  role       = aws_iam_role.role.name\n  policy_arn = aws_iam_policy.policy.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `role`  (Required) - The name of the IAM role to which the policy should be applied\n* `policy_arn` (Required) - The ARN of the policy you want to apply\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nIAM role policy attachments can be imported using the role name and policy arn separated by `/`.\n\n```\n$ terraform import aws_iam_role_policy_attachment.test-attach test-role/arn:aws:iam::xxxxxxxxxxxx:policy/test-policy\n```\n",
    "basename": "iam_role_policy_attachment"
  },
  "iam_saml_provider.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_saml_provider",
    "description": "Provides an IAM SAML provider.",
    "preview": "# Resource: aws_iam_saml_provider\n\nProvides an IAM SAML provider.\n …",
    "content": "\n\n# Resource: aws_iam_saml_provider\n\nProvides an IAM SAML provider.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_saml_provider\" \"default\" {\n  name                   = \"myprovider\"\n  saml_metadata_document = file(\"saml-metadata.xml\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the provider to create.\n* `saml_metadata_document` - (Required) An XML document generated by an identity provider that supports SAML 2.0.\n* `tags` - (Optional) Map of resource tags for the IAM SAML provider. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS for this provider.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `valid_until` - The expiration date and time for the SAML provider in RFC1123 format, e.g., `Mon, 02 Jan 2006 15:04:05 MST`.\n\n## Import\n\nIAM SAML Providers can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_iam_saml_provider.default arn:aws:iam::123456789012:saml-provider/SAMLADFS\n```\n",
    "basename": "iam_saml_provider.html"
  },
  "iam_server_certificate.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_server_certificate",
    "description": "Provides an IAM Server Certificate",
    "preview": "# Resource: aws_iam_server_certificate\n\nProvides an IAM Server …",
    "content": "\n\n# Resource: aws_iam_server_certificate\n\nProvides an IAM Server Certificate resource to upload Server Certificates.\nCerts uploaded to IAM can easily work with other AWS services such as:\n\n- AWS Elastic Beanstalk\n- Elastic Load Balancing\n- CloudFront\n- AWS OpsWorks\n\nFor information about server certificates in IAM, see [Managing Server\nCertificates][2] in AWS Documentation.\n\n~> **Note:** All arguments including the private key will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n**Using certs on file:**\n\n```terraform\nresource \"aws_iam_server_certificate\" \"test_cert\" {\n  name             = \"some_test_cert\"\n  certificate_body = file(\"self-ca-cert.pem\")\n  private_key      = file(\"test-key.pem\")\n}\n```\n\n**Example with cert in-line:**\n\n```terraform\nresource \"aws_iam_server_certificate\" \"test_cert_alt\" {\n  name = \"alt_test_cert\"\n\n  certificate_body = <<EOF\n-----BEGIN CERTIFICATE-----\n[......] # cert contents\n-----END CERTIFICATE-----\nEOF\n\n  private_key = <<EOF\n-----BEGIN RSA PRIVATE KEY-----\n[......] # cert contents\n-----END RSA PRIVATE KEY-----\nEOF\n}\n```\n\n**Use in combination with an AWS ELB resource:**\n\nSome properties of an IAM Server Certificates cannot be updated while they are\nin use. In order for Terraform to effectively manage a Certificate in this situation, it is\nrecommended you utilize the `name_prefix` attribute and enable the\n`create_before_destroy` [lifecycle block][lifecycle]. This will allow Terraform\nto create a new, updated `aws_iam_server_certificate` resource and replace it in\ndependant resources before attempting to destroy the old version.\n\n```terraform\nresource \"aws_iam_server_certificate\" \"test_cert\" {\n  name_prefix      = \"example-cert\"\n  certificate_body = file(\"self-ca-cert.pem\")\n  private_key      = file(\"test-key.pem\")\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_elb\" \"ourapp\" {\n  name                      = \"terraform-asg-deployment-example\"\n  availability_zones        = [\"us-west-2a\"]\n  cross_zone_load_balancing = true\n\n  listener {\n    instance_port      = 8000\n    instance_protocol  = \"http\"\n    lb_port            = 443\n    lb_protocol        = \"https\"\n    ssl_certificate_id = aws_iam_server_certificate.test_cert.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the Server Certificate. Do not include the\n  path in this value. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified\n  prefix. Conflicts with `name`.\n* `certificate_body` – (Required) The contents of the public key certificate in\n  PEM-encoded format.\n* `certificate_chain` – (Optional) The contents of the certificate chain.\n  This is typically a concatenation of the PEM-encoded public key certificates\n  of the chain.\n* `private_key` – (Required) The contents of the private key in PEM-encoded format.\n* `path` - (Optional) The IAM path for the server certificate.  If it is not\n    included, it defaults to a slash (/). If this certificate is for use with\n    AWS CloudFront, the path must be in format `/cloudfront/your_path_here`.\n    See [IAM Identifiers][1] for more details on IAM Paths.\n* `tags` - (Optional) Map of resource tags for the server certificate. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n~> **NOTE:** AWS performs behind-the-scenes modifications to some certificate files if they do not adhere to a specific format. These modifications will result in terraform forever believing that it needs to update the resources since the local and AWS file contents will not match after theses modifications occur. In order to prevent this from happening you must ensure that all your PEM-encoded files use UNIX line-breaks and that `certificate_body` contains only one certificate. All other certificates should go in `certificate_chain`. It is common for some Certificate Authorities to issue certificate files that have DOS line-breaks and that are actually multiple certificates concatenated together in order to form a full certificate chain.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) specifying the server certificate.\n* `expiration` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) on which the certificate is set to expire.\n* `id` - The unique Server Certificate name\n* `name` - The name of the Server Certificate\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `upload_date` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) when the server certificate was uploaded.\n\n## Import\n\nIAM Server Certificates can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_iam_server_certificate.certificate example.com-certificate-until-2018\n```\n\n[1]: https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html\n[2]: https://docs.aws.amazon.com/IAM/latest/UserGuide/ManagingServerCerts.html\n[lifecycle]: /docs/configuration/resources.html\n",
    "basename": "iam_server_certificate.html"
  },
  "iam_service_linked_role.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_service_linked_role",
    "description": "Provides an IAM service-linked role.",
    "preview": "# Resource: aws_iam_service_linked_role\n\nProvides an [IAM …",
    "content": "\n\n# Resource: aws_iam_service_linked_role\n\nProvides an [IAM service-linked role](https://docs.aws.amazon.com/IAM/latest/UserGuide/using-service-linked-roles.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_service_linked_role\" \"elasticbeanstalk\" {\n  aws_service_name = \"elasticbeanstalk.amazonaws.com\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `aws_service_name` - (Required, Forces new resource) The AWS service to which this role is attached. You use a string similar to a URL but without the `http://` in front. For example: `elasticbeanstalk.amazonaws.com`. To find the full list of services that support service-linked roles, check [the docs](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_aws-services-that-work-with-iam.html).\n* `custom_suffix` - (Optional, forces new resource) Additional string appended to the role name. Not all AWS services support custom suffixes.\n* `description` - (Optional) The description of the role.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the role.\n* `arn` - The Amazon Resource Name (ARN) specifying the role.\n* `create_date` - The creation date of the IAM role.\n* `name` - The name of the role.\n* `path` - The path of the role.\n* `unique_id` - The stable and unique string identifying the role.\n\n## Import\n\nIAM service-linked roles can be imported using role ARN, e.g.,\n\n```\n$ terraform import aws_iam_service_linked_role.elasticbeanstalk arn:aws:iam::123456789012:role/aws-service-role/elasticbeanstalk.amazonaws.com/AWSServiceRoleForElasticBeanstalk\n```\n",
    "basename": "iam_service_linked_role.html"
  },
  "iam_user.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_user",
    "description": "Provides an IAM user.",
    "preview": "# Resource: aws_iam_user\n\nProvides an IAM user.\n\n~> *NOTE:* If …",
    "content": "\n\n# Resource: aws_iam_user\n\nProvides an IAM user.\n\n~> *NOTE:* If policies are attached to the user via the [`aws_iam_policy_attachment` resource](/docs/providers/aws/r/iam_policy_attachment.html) and you are modifying the user `name` or `path`, the `force_destroy` argument must be set to `true` and applied before attempting the operation otherwise you will encounter a `DeleteConflict` error. The [`aws_iam_user_policy_attachment` resource (recommended)](/docs/providers/aws/r/iam_user_policy_attachment.html) does not have this requirement.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_user\" \"lb\" {\n  name = \"loadbalancer\"\n  path = \"/system/\"\n\n  tags = {\n    tag-key = \"tag-value\"\n  }\n}\n\nresource \"aws_iam_access_key\" \"lb\" {\n  user = aws_iam_user.lb.name\n}\n\nresource \"aws_iam_user_policy\" \"lb_ro\" {\n  name = \"test\"\n  user = aws_iam_user.lb.name\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"ec2:Describe*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The user's name. The name must consist of upper and lowercase alphanumeric characters with no spaces. You can also include any of the following characters: `=,.@-_.`. User names are not distinguished by case. For example, you cannot create users named both \"TESTUSER\" and \"testuser\".\n* `path` - (Optional, default \"/\") Path in which to create the user.\n* `permissions_boundary` - (Optional) The ARN of the policy that is used to set the permissions boundary for the user.\n* `force_destroy` - (Optional, default false) When destroying this user, destroy even if it\n  has non-Terraform-managed IAM access keys, login profile or MFA devices. Without `force_destroy`\n  a user with non-Terraform-managed access keys and login profile will fail to be destroyed.\n* `tags` - Key-value map of tags for the IAM user. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS for this user.\n* `name` - The user's name.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `unique_id` - The [unique ID][1] assigned by AWS.\n\n  [1]: https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html#GUIDs\n\n\n## Import\n\nIAM Users can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_iam_user.lb loadbalancer\n```\n",
    "basename": "iam_user.html"
  },
  "iam_user_group_membership.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_user_group_membership",
    "description": "Provides a resource for adding an IAM User to IAM Groups without conflicting\nwith itself.",
    "preview": "# Resource: aws_iam_user_group_membership\n\nProvides a resource for …",
    "content": "\n\n# Resource: aws_iam_user_group_membership\n\nProvides a resource for adding an [IAM User][2] to [IAM Groups][1]. This\nresource can be used multiple times with the same user for non-overlapping\ngroups.\n\nTo exclusively manage the users in a group, see the\n[`aws_iam_group_membership` resource][3].\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_user_group_membership\" \"example1\" {\n  user = aws_iam_user.user1.name\n\n  groups = [\n    aws_iam_group.group1.name,\n    aws_iam_group.group2.name,\n  ]\n}\n\nresource \"aws_iam_user_group_membership\" \"example2\" {\n  user = aws_iam_user.user1.name\n\n  groups = [\n    aws_iam_group.group3.name,\n  ]\n}\n\nresource \"aws_iam_user\" \"user1\" {\n  name = \"user1\"\n}\n\nresource \"aws_iam_group\" \"group1\" {\n  name = \"group1\"\n}\n\nresource \"aws_iam_group\" \"group2\" {\n  name = \"group2\"\n}\n\nresource \"aws_iam_group\" \"group3\" {\n  name = \"group3\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `user` - (Required) The name of the [IAM User][2] to add to groups\n* `groups` - (Required) A list of [IAM Groups][1] to add the user to\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n[1]: /docs/providers/aws/r/iam_group.html\n[2]: /docs/providers/aws/r/iam_user.html\n[3]: /docs/providers/aws/r/iam_group_membership.html\n\n## Import\n\nIAM user group membership can be imported using the user name and group names separated by `/`.\n\n```\n$ terraform import aws_iam_user_group_membership.example1 user1/group1/group2\n```\n",
    "basename": "iam_user_group_membership.html"
  },
  "iam_user_login_profile.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_user_login_profile",
    "description": "Manages an IAM User Login Profile",
    "preview": "# Resource: aws_iam_user_login_profile\n\nManages an IAM User Login …",
    "content": "\n\n# Resource: aws_iam_user_login_profile\n\nManages an IAM User Login Profile with limited support for password creation during Terraform resource creation. Uses PGP to encrypt the password for safe transport to the user. PGP keys can be obtained from Keybase.\n\n-> To reset an IAM User login password via Terraform, you can use the [`terraform taint` command](https://www.terraform.io/docs/commands/taint.html) or change any of the arguments.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_user\" \"example\" {\n  name          = \"example\"\n  path          = \"/\"\n  force_destroy = true\n}\n\nresource \"aws_iam_user_login_profile\" \"example\" {\n  user    = aws_iam_user.example.name\n  pgp_key = \"keybase:some_person_that_exists\"\n}\n\noutput \"password\" {\n  value = aws_iam_user_login_profile.example.encrypted_password\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `user` - (Required) The IAM user's name.\n* `pgp_key` - (Required) Either a base-64 encoded PGP public key, or a keybase username in the form `keybase:username`. Only applies on resource creation. Drift detection is not possible with this argument.\n* `password_length` - (Optional, default 20) The length of the generated password on resource creation. Only applies on resource creation. Drift detection is not possible with this argument.\n* `password_reset_required` - (Optional, default \"true\") Whether the user should be forced to reset the generated password on resource creation. Only applies on resource creation. Drift detection is not possible with this argument.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `key_fingerprint` - The fingerprint of the PGP key used to encrypt the password. Only available if password was handled on Terraform resource creation, not import.\n* `encrypted_password` - The encrypted password, base64 encoded. Only available if password was handled on Terraform resource creation, not import.\n\n~> **NOTE:** The encrypted password may be decrypted using the command line,\n   for example: `terraform output password | base64 --decode | keybase pgp decrypt`.\n\n## Import\n\nIAM User Login Profiles can be imported without password information support via the IAM User name, e.g.,\n\n```sh\n$ terraform import aws_iam_user_login_profile.example myusername\n```\n\nSince Terraform has no method to read the PGP or password information during import, use the [Terraform resource `lifecycle` configuration block `ignore_changes` argument](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to ignore them unless password recreation is desiredE.g.,\n\n```terraform\nresource \"aws_iam_user_login_profile\" \"example\" {\n  # ... other configuration ...\n\n  lifecycle {\n    ignore_changes = [\n      password_length,\n      password_reset_required,\n      pgp_key,\n    ]\n  }\n}\n```\n",
    "basename": "iam_user_login_profile.html"
  },
  "iam_user_policy.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_user_policy",
    "description": "Provides an IAM policy attached to a user.",
    "preview": "# Resource: aws_iam_user_policy\n\nProvides an IAM policy attached to …",
    "content": "\n\n# Resource: aws_iam_user_policy\n\nProvides an IAM policy attached to a user.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_user_policy\" \"lb_ro\" {\n  name = \"test\"\n  user = aws_iam_user.lb.name\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"ec2:Describe*\",\n        ]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_user\" \"lb\" {\n  name = \"loadbalancer\"\n  path = \"/system/\"\n}\n\nresource \"aws_iam_access_key\" \"lb\" {\n  user = aws_iam_user.lb.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy` - (Required) The policy document. This is a JSON formatted string. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `name` - (Optional) The name of the policy. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `user` - (Required) IAM user to which to attach this policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The user policy ID, in the form of `user_name:user_policy_name`.\n* `name` - The name of the policy (always set).\n\n## Import\n\nIAM User Policies can be imported using the `user_name:user_policy_name`, e.g.,\n\n```\n$ terraform import aws_iam_user_policy.mypolicy user_of_mypolicy_name:mypolicy_name\n```\n",
    "basename": "iam_user_policy.html"
  },
  "iam_user_policy_attachment": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_user_policy_attachment",
    "description": "Attaches a Managed IAM Policy to an IAM user",
    "preview": "# Resource: aws_iam_user_policy_attachment\n\nAttaches a Managed IAM …",
    "content": "\n\n# Resource: aws_iam_user_policy_attachment\n\nAttaches a Managed IAM Policy to an IAM user\n\n~> **NOTE:** The usage of this resource conflicts with the `aws_iam_policy_attachment` resource and will permanently show a difference if both are defined.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_user\" \"user\" {\n  name = \"test-user\"\n}\n\nresource \"aws_iam_policy\" \"policy\" {\n  name        = \"test-policy\"\n  description = \"A test policy\"\n  policy      = \"{ ... policy JSON ... }\"\n}\n\nresource \"aws_iam_user_policy_attachment\" \"test-attach\" {\n  user       = aws_iam_user.user.name\n  policy_arn = aws_iam_policy.policy.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `user`        (Required) - The user the policy should be applied to\n* `policy_arn`  (Required) - The ARN of the policy you want to apply\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nIAM user policy attachments can be imported using the user name and policy arn separated by `/`.\n\n```\n$ terraform import aws_iam_user_policy_attachment.test-attach test-user/arn:aws:iam::xxxxxxxxxxxx:policy/test-policy\n```\n",
    "basename": "iam_user_policy_attachment"
  },
  "iam_user_ssh_key.html": {
    "subcategory": "IAM",
    "layout": "aws",
    "page_title": "AWS: aws_iam_user_ssh_key",
    "description": "Uploads an SSH public key and associates it with the specified IAM user.",
    "preview": "# Resource: aws_iam_user_ssh_key\n\nUploads an SSH public key and …",
    "content": "\n\n# Resource: aws_iam_user_ssh_key\n\nUploads an SSH public key and associates it with the specified IAM user.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_user\" \"user\" {\n  name = \"test-user\"\n  path = \"/\"\n}\n\nresource \"aws_iam_user_ssh_key\" \"user\" {\n  username   = aws_iam_user.user.name\n  encoding   = \"SSH\"\n  public_key = \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQD3F6tyPEFEzV0LX3X8BsXdMsQz1x2cEikKDEY0aIj41qgxMCP/iteneqXSIFZBp5vizPvaoIR3Um9xK7PGoW8giupGn+EPuxIA4cDM4vzOqOkiMPhz5XK0whEjkVzTo4+S0puvDZuwIsdiW9mxhJc7tgBNL0cYlWSYVkz4G/fslNfRPW5mYAM49f4fhtxPb5ok4Q2Lg9dPKVHO/Bgeu5woMc7RY0p1ej6D4CKFE6lymSDJpW0YHX/wqE9+cfEauh7xZcG0q9t2ta6F6fmX0agvpFyZo8aFbXeUBr7osSCJNgvavWbM/06niWrOvYX2xwWdhXmXSrbX8ZbabVohBK41 mytest@mydomain.com\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `username` - (Required) The name of the IAM user to associate the SSH public key with.\n* `encoding` - (Required) Specifies the public key encoding format to use in the response. To retrieve the public key in ssh-rsa format, use `SSH`. To retrieve the public key in PEM format, use `PEM`.\n* `public_key` - (Required) The SSH public key. The public key must be encoded in ssh-rsa format or PEM format.\n* `status` - (Optional) The status to assign to the SSH public key. Active means the key can be used for authentication with an AWS CodeCommit repository. Inactive means the key cannot be used. Default is `active`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `ssh_public_key_id` - The unique identifier for the SSH public key.\n* `fingerprint` - The MD5 message digest of the SSH public key.\n\n## Import\n\nSSH public keys can be imported using the `username`, `ssh_public_key_id`, and `encoding` e.g.,\n\n```\n$ terraform import aws_iam_user_ssh_key.user user:APKAJNCNNJICVN7CFKCA:SSH\n```\n",
    "basename": "iam_user_ssh_key.html"
  },
  "imagebuilder_component.html": {
    "subcategory": "Image Builder",
    "layout": "aws",
    "page_title": "AWS: aws_imagebuilder_component",
    "description": "Manage an Image Builder Component",
    "preview": "# Resource: aws_imagebuilder_component\n\nManages an Image Builder …",
    "content": "\n\n# Resource: aws_imagebuilder_component\n\nManages an Image Builder Component.\n\n## Example Usage\n\n### Inline Data Document\n\n```terraform\nresource \"aws_imagebuilder_component\" \"example\" {\n  data = yamlencode({\n    phases = [{\n      name = \"build\"\n      steps = [{\n        action = \"ExecuteBash\"\n        inputs = {\n          commands = [\"echo 'hello world'\"]\n        }\n        name      = \"example\"\n        onFailure = \"Continue\"\n      }]\n    }]\n    schemaVersion = 1.0\n  })\n  name     = \"example\"\n  platform = \"Linux\"\n  version  = \"1.0.0\"\n}\n```\n\n### URI Document\n\n```terraform\nresource \"aws_imagebuilder_component\" \"example\" {\n  name     = \"example\"\n  platform = \"Linux\"\n  uri      = \"s3://${aws_s3_bucket_object.example.bucket}/${aws_s3_bucket_object.example.key}\"\n  version  = \"1.0.0\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the component.\n* `platform` - (Required) Platform of the component.\n* `version` - (Required) Version of the component.\n\nThe following attributes are optional:\n\n* `change_description` - (Optional) Change description of the component.\n* `data` - (Optional) Inline YAML string with data of the component. Exactly one of `data` and `uri` can be specified. Terraform will only perform drift detection of its value when present in a configuration.\n* `description` - (Optional) Description of the component.\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of the Key Management Service (KMS) Key used to encrypt the component.\n* `supported_os_versions` - (Optional) Set of Operating Systems (OS) supported by the component.\n* `tags` - (Optional) Key-value map of resource tags for the component. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `uri` - (Optional) S3 URI with data of the component. Exactly one of `data` and `uri` can be specified.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - (Required) Amazon Resource Name (ARN) of the component.\n* `date_created` - Date the component was created.\n* `encrypted` - Encryption status of the component.\n* `owner` - Owner of the component.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `type` - Type of the component.\n\n## Import\n\n`aws_imagebuilder_components` resources can be imported by using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_imagebuilder_component.example arn:aws:imagebuilder:us-east-1:123456789012:component/example/1.0.0/1\n```\n\nCertain resource arguments, such as `uri`, cannot be read via the API and imported into Terraform. Terraform will display a difference for these arguments the first run after import if declared in the Terraform configuration for an imported resource.\n",
    "basename": "imagebuilder_component.html"
  },
  "imagebuilder_distribution_configuration.html": {
    "subcategory": "Image Builder",
    "layout": "aws",
    "page_title": "AWS: aws_imagebuilder_distribution_configuration",
    "description": "Manage an Image Builder Distribution Configuration",
    "preview": "# Resource: aws_imagebuilder_distribution_configuration\n\nManages an …",
    "content": "\n\n# Resource: aws_imagebuilder_distribution_configuration\n\nManages an Image Builder Distribution Configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_imagebuilder_distribution_configuration\" \"example\" {\n  name = \"example\"\n\n  distribution {\n    ami_distribution_configuration {\n      ami_tags = {\n        CostCenter = \"IT\"\n      }\n\n      name = \"example-{{ imagebuilder:buildDate }}\"\n\n      launch_permission {\n        user_ids = [\"123456789012\"]\n      }\n    }\n\n    region = \"us-east-1\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the distribution configuration.\n* `distribution` - (Required) One or more configuration blocks with distribution settings. Detailed below.\n\nThe following arguments are optional:\n\n* `description` - (Optional) Description of the distribution configuration.\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of the Key Management Service (KMS) Key used to encrypt the distribution configuration.\n* `tags` - (Optional) Key-value map of resource tags for the distribution configuration. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### distribution\n\nThe following arguments are required:\n\n* `region` - (Required) AWS Region for the distribution.\n\nThe following arguments are optional:\n\n* `ami_distribution_configuration` - (Optional) Configuration block with Amazon Machine Image (AMI) distribution settings. Detailed below.\n* `license_configuration_arns` - (Optional) Set of Amazon Resource Names (ARNs) of License Manager License Configurations.\n\n### ami_distribution_configuration\n\nThe following arguments are optional:\n\n* `ami_tags` - (Optional) Key-value map of tags to apply to the distributed AMI.\n* `description` - (Optional) Description to apply to the distributed AMI.\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of the Key Management Service (KMS) Key to encrypt the distributed AMI.\n* `launch_permission` - (Optional) Configuration block of EC2 launch permissions to apply to the distributed AMI. Detailed below.\n* `name` - (Optional) Name to apply to the distributed AMI.\n* `target_account_ids` - (Optional) Set of AWS Account identifiers to distribute the AMI.\n\n### launch_permission\n\nThe following arguments are optional:\n\n* `user_groups` - (Optional) Set of EC2 launch permission user groups to assign. Use `all` to distribute a public AMI.\n* `user_ids` - (Optional) Set of AWS Account identifiers to assign.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - (Required) Amazon Resource Name (ARN) of the distribution configuration.\n* `date_created` - Date the distribution configuration was created.\n* `date_updated` - Date the distribution configuration was updated.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_imagebuilder_distribution_configurations` resources can be imported by using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_imagebuilder_distribution_configuration.example arn:aws:imagebuilder:us-east-1:123456789012:distribution-configuration/example\n```\n",
    "basename": "imagebuilder_distribution_configuration.html"
  },
  "imagebuilder_image.html": {
    "subcategory": "Image Builder",
    "layout": "aws",
    "page_title": "AWS: aws_imagebuilder_image",
    "description": "Manages an Image Builder Image",
    "preview": "# Resource: aws_imagebuilder_image\n\nManages an Image Builder Image.\n …",
    "content": "\n\n# Resource: aws_imagebuilder_image\n\nManages an Image Builder Image.\n\n## Example Usage\n\n```terraform\nresource \"aws_imagebuilder_image\" \"example\" {\n  distribution_configuration_arn   = aws_imagebuilder_distribution_configuration.example.arn\n  image_recipe_arn                 = aws_imagebuilder_image_recipe.example.arn\n  infrastructure_configuration_arn = aws_imagebuilder_infrastructure_configuration.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `image_recipe_arn` - (Required) Amazon Resource Name (ARN) of the Image Builder Infrastructure Recipe.\n* `infrastructure_configuration_arn` - (Required) Amazon Resource Name (ARN) of the Image Builder Infrastructure Configuration.\n\nThe following arguments are optional:\n\n* `distribution_configuration_arn` - (Optional) Amazon Resource Name (ARN) of the Image Builder Distribution Configuration.\n* `enhanced_image_metadata_enabled` - (Optional) Whether additional information about the image being created is collected. Defaults to `true`.\n* `image_tests_configuration` - (Optional) Configuration block with image tests configuration. Detailed below.\n* `tags` - (Optional) Key-value map of resource tags for the Image Builder Image. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### image_tests_configuration\n\nThe following arguments are optional:\n\n* `image_tests_enabled` - (Optional) Whether image tests are enabled. Defaults to `true`.\n* `timeout_minutes` - (Optional) Number of minutes before image tests time out. Valid values are between `60` and `1440`. Defaults to `720`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the image.\n* `date_created` - Date the image was created.\n* `platform` - Platform of the image.\n* `os_version` - Operating System version of the image.\n* `output_resources` - List of objects with resources created by the image.\n    * `amis` - Set of objects with each Amazon Machine Image (AMI) created.\n        * `account_id` - Account identifier of the AMI.\n        * `description` - Description of the AMI.\n        * `image` - Identifier of the AMI.\n        * `name` - Name of the AMI.\n        * `region` - Region of the AMI.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version` - Version of the image.\n\n## Timeouts\n\n`aws_imagebuilder_image` provides the following [Timeouts](/docs/configuration/resources.html#timeouts) configuration options:\n\n* `create` - (Default `60m`) How long to wait for the image to be built, tested, and distributed.\n\n## Import\n\n`aws_imagebuilder_image` resources can be imported using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_imagebuilder_image.example arn:aws:imagebuilder:us-east-1:123456789012:image/example/1.0.0/1\n```\n",
    "basename": "imagebuilder_image.html"
  },
  "imagebuilder_image_pipeline.html": {
    "subcategory": "Image Builder",
    "layout": "aws",
    "page_title": "AWS: aws_imagebuilder_image_pipeline",
    "description": "Manages an Image Builder Image Pipeline",
    "preview": "# Resource: aws_imagebuilder_image_pipeline\n\nManages an Image …",
    "content": "\n\n# Resource: aws_imagebuilder_image_pipeline\n\nManages an Image Builder Image Pipeline.\n\n## Example Usage\n\n```terraform\nresource \"aws_imagebuilder_image_pipeline\" \"example\" {\n  image_recipe_arn                 = aws_imagebuilder_image_recipe.example.arn\n  infrastructure_configuration_arn = aws_imagebuilder_infrastructure_configuration.example.arn\n  name                             = \"example\"\n\n  schedule {\n    schedule_expression = \"cron(0 0 * * ? *)\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `image_recipe_arn` - (Required) Amazon Resource Name (ARN) of the Image Builder Infrastructure Recipe.\n* `infrastructure_configuration_arn` - (Required) Amazon Resource Name (ARN) of the Image Builder Infrastructure Configuration.\n* `name` - (Required) Name of the image pipeline.\n\nThe following arguments are optional:\n\n* `description` - (Optional) Description of the image pipeline.\n* `distribution_configuration_arn` - (Optional) Amazon Resource Name (ARN) of the Image Builder Distribution Configuration.\n* `enhanced_image_metadata_enabled` - (Optional) Whether additional information about the image being created is collected. Defaults to `true`.\n* `image_tests_configuration` - (Optional) Configuration block with image tests configuration. Detailed below.\n* `schedule` - (Optional) Configuration block with schedule settings. Detailed below.\n* `status` - (Optional) Status of the image pipeline. Valid values are `DISABLED` and `ENABLED`. Defaults to `ENABLED`.\n* `tags` - (Optional) Key-value map of resource tags for the image pipeline. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### image_tests_configuration\n\nThe following arguments are optional:\n\n* `image_tests_enabled` - (Optional) Whether image tests are enabled. Defaults to `true`.\n* `timeout_minutes` - (Optional) Number of minutes before image tests time out. Valid values are between `60` and `1440`. Defaults to `720`.\n\n### schedule\n\nThe following arguments are required:\n\n* `schedule_expression` - (Required) Cron expression of how often the pipeline start condition is evaluated. For example, `cron(0 0 * * ? *)` is evaluated every day at midnight UTC. Configurations using the five field syntax that was previously accepted by the API, such as `cron(0 0 * * *)`, must be updated to the six field syntax. For more information, see the [Image Builder User Guide](https://docs.aws.amazon.com/imagebuilder/latest/userguide/cron-expressions.html).\n\nThe following arguments are optional:\n\n* `pipeline_execution_start_condition` - (Optional) Condition when the pipeline should trigger a new image build. Valid values are `EXPRESSION_MATCH_AND_DEPENDENCY_UPDATES_AVAILABLE` and `EXPRESSION_MATCH_ONLY`. Defaults to `EXPRESSION_MATCH_AND_DEPENDENCY_UPDATES_AVAILABLE`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the image pipeline.\n* `date_created` - Date the image pipeline was created.\n* `date_last_run` - Date the image pipeline was last run.\n* `date_next_run` - Date the image pipeline will run next.\n* `date_updated` - Date the image pipeline was updated.\n* `platform` - Platform of the image pipeline.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_imagebuilder_image_pipeline` resources can be imported using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_imagebuilder_image_pipeline.example arn:aws:imagebuilder:us-east-1:123456789012:image-pipeline/example\n```\n",
    "basename": "imagebuilder_image_pipeline.html"
  },
  "imagebuilder_image_recipe.html": {
    "subcategory": "Image Builder",
    "layout": "aws",
    "page_title": "AWS: aws_imagebuilder_image_recipe",
    "description": "Manage an Image Builder Image Recipe",
    "preview": "# Resource: aws_imagebuilder_image_recipe\n\nManages an Image Builder …",
    "content": "\n\n# Resource: aws_imagebuilder_image_recipe\n\nManages an Image Builder Image Recipe.\n\n## Example Usage\n\n```terraform\nresource \"aws_imagebuilder_image_recipe\" \"example\" {\n  block_device_mapping {\n    device_name = \"/dev/xvdb\"\n\n    ebs {\n      delete_on_termination = true\n      volume_size           = 100\n      volume_type           = \"gp2\"\n    }\n  }\n\n  component {\n    component_arn = aws_imagebuilder_component.example.arn\n  }\n\n  name         = \"example\"\n  parent_image = \"arn:${data.aws_partition.current.partition}:imagebuilder:${data.aws_region.current.name}:aws:image/amazon-linux-2-x86/x.x.x\"\n  version      = \"1.0.0\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `component` - (Required) Ordered configuration block(s) with components for the image recipe. Detailed below.\n* `name` - (Required) Name of the image recipe.\n* `parent_image` - (Required) Platform of the image recipe.\n* `version` - (Required) Version of the image recipe.\n\nThe following attributes are optional:\n\n* `block_device_mapping` - (Optional) Configuration block(s) with block device mappings for the the image recipe. Detailed below.\n* `description` - (Optional) Description of the image recipe.\n* `tags` - (Optional) Key-value map of resource tags for the image recipe. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `working_directory` - (Optional) The working directory to be used during build and test workflows.\n\n### block_device_mapping\n\nThe following arguments are optional:\n\n* `device_name` - (Optional) Name of the device. For example, `/dev/sda` or `/dev/xvdb`.\n* `ebs` - (Optional) Configuration block with Elastic Block Storage (EBS) block device mapping settings. Detailed below.\n* `no_device` - (Optional) Set to `true` to remove a mapping from the parent image.\n* `virtual_name` - (Optional) Virtual device name. For example, `ephemeral0`. Instance store volumes are numbered starting from 0.\n\n#### ebs\n\nThe following arguments are optional:\n\n* `delete_on_termination` - (Optional) Whether to delete the volume on termination. Defaults to unset, which is the value inherited from the parent image.\n* `encrypted` - (Optional) Whether to encrypt the volume. Defaults to unset, which is the value inherited from the parent image.\n* `iops` - (Optional) Number of Input/Output (I/O) operations per second to provision for an `io1` or `io2` volume.\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of the Key Management Service (KMS) Key for encryption.\n* `snapshot_id` - (Optional) Identifier of the EC2 Volume Snapshot.\n* `volume_size` - (Optional) Size of the volume, in GiB.\n* `volume_type` - (Optional) Type of the volume. For example, `gp2` or `io2`.\n\n### component\n\nThe following arguments are required:\n\n* `component_arn` - (Required) Amazon Resource Name (ARN) of the Image Builder Component to associate.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - (Required) Amazon Resource Name (ARN) of the image recipe.\n* `date_created` - Date the image recipe was created.\n* `owner` - Owner of the image recipe.\n* `platform` - Platform of the image recipe.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_imagebuilder_image_recipe` resources can be imported by using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_imagebuilder_image_recipe.example arn:aws:imagebuilder:us-east-1:123456789012:image-recipe/example/1.0.0\n```\n",
    "basename": "imagebuilder_image_recipe.html"
  },
  "imagebuilder_infrastructure_configuration.html": {
    "subcategory": "Image Builder",
    "layout": "aws",
    "page_title": "AWS: aws_imagebuilder_infrastructure_configuration",
    "description": "Manages an Image Builder Infrastructure Configuration",
    "preview": "# Resource: aws_imagebuilder_infrastructure_configuration\n\nManages …",
    "content": "\n\n# Resource: aws_imagebuilder_infrastructure_configuration\n\nManages an Image Builder Infrastructure Configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_imagebuilder_infrastructure_configuration\" \"example\" {\n  description                   = \"example description\"\n  instance_profile_name         = aws_iam_instance_profile.example.name\n  instance_types                = [\"t2.nano\", \"t3.micro\"]\n  key_pair                      = aws_key_pair.example.key_name\n  name                          = \"example\"\n  security_group_ids            = [aws_security_group.example.id]\n  sns_topic_arn                 = aws_sns_topic.example.arn\n  subnet_id                     = aws_subnet.main.id\n  terminate_instance_on_failure = true\n\n  logging {\n    s3_logs {\n      s3_bucket_name = aws_s3_bucket.example.bucket\n      s3_key_prefix  = \"logs\"\n    }\n  }\n\n  tags = {\n    foo = \"bar\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `instance_profile_name` - (Required) Name of IAM Instance Profile.\n* `name` - (Required) Name for the configuration.\n\nThe following arguments are optional:\n\n* `description` - (Optional) Description for the configuration.\n* `instance_types` - (Optional) Set of EC2 Instance Types.\n* `key_pair` - (Optional) Name of EC2 Key Pair.\n* `logging` - (Optional) Configuration block with logging settings. Detailed below.\n* `resource_tags` - (Optional) Key-value map of resource tags to assign to infrastructure created by the configuration.\n* `security_group_ids` - (Optional) Set of EC2 Security Group identifiers.\n* `sns_topic_arn` - (Optional) Amazon Resource Name (ARN) of SNS Topic.\n* `subnet_id` - (Optional) EC2 Subnet identifier. Also requires `security_group_ids` argument.\n* `tags` - (Optional) Key-value map of resource tags to assign to the configuration. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `terminate_instance_on_failure` - (Optional) Enable if the instance should be terminated when the pipeline fails. Defaults to `false`.\n\n### logging\n\nThe following arguments are required:\n\n* `s3_logs` - (Required) Configuration block with S3 logging settings. Detailed below.\n\n### s3_logs\n\nThe following arguments are required:\n\n* `s3_bucket_name` - (Required) Name of the S3 Bucket.\n\nThe following arguments are optional:\n\n* `s3_key_prefix` - (Optional) Prefix to use for S3 logs. Defaults to `/`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the configuration.\n* `arn` - Amazon Resource Name (ARN) of the configuration.\n* `date_created` - Date when the configuration was created.\n* `date_updated` - Date when the configuration was updated.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_imagebuilder_infrastructure_configuration` can be imported using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_imagebuilder_infrastructure_configuration.example arn:aws:imagebuilder:us-east-1:123456789012:infrastructure-configuration/example\n```\n",
    "basename": "imagebuilder_infrastructure_configuration.html"
  },
  "inspector_assessment_target.html": {
    "subcategory": "Inspector",
    "layout": "aws",
    "page_title": "AWS: aws_inspector_assessment_target",
    "description": "Provides a Inspector assessment target.",
    "preview": "# Resource: aws_inspector_assessment_target\n\nProvides a Inspector …",
    "content": "\n\n# Resource: aws_inspector_assessment_target\n\nProvides a Inspector assessment target\n\n## Example Usage\n\n```terraform\nresource \"aws_inspector_resource_group\" \"bar\" {\n  tags = {\n    Name = \"foo\"\n    Env  = \"bar\"\n  }\n}\n\nresource \"aws_inspector_assessment_target\" \"foo\" {\n  name               = \"assessment target\"\n  resource_group_arn = aws_inspector_resource_group.bar.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the assessment target.\n* `resource_group_arn` (Optional) Inspector Resource Group Amazon Resource Name (ARN) stating tags for instance matching. If not specified, all EC2 instances in the current AWS account and region are included in the assessment target.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The target assessment ARN.\n\n## Import\n\nInspector Assessment Targets can be imported via their Amazon Resource Name (ARN), e.g.,\n\n```sh\n$ terraform import aws_inspector_assessment_target.example arn:aws:inspector:us-east-1:123456789012:target/0-xxxxxxx\n```\n",
    "basename": "inspector_assessment_target.html"
  },
  "inspector_assessment_template.html": {
    "subcategory": "Inspector",
    "layout": "aws",
    "page_title": "AWS: aws_inspector_assessment_template",
    "description": "Provides a Inspector assessment template.",
    "preview": "# Resource: aws_inspector_assessment_template\n\nProvides a Inspector …",
    "content": "\n\n# Resource: aws_inspector_assessment_template\n\nProvides a Inspector assessment template\n\n## Example Usage\n\n```terraform\nresource \"aws_inspector_assessment_template\" \"example\" {\n  name       = \"example\"\n  target_arn = aws_inspector_assessment_target.example.arn\n  duration   = 3600\n\n  rules_package_arns = [\n    \"arn:aws:inspector:us-west-2:758058086616:rulespackage/0-9hgA516p\",\n    \"arn:aws:inspector:us-west-2:758058086616:rulespackage/0-H5hpSawc\",\n    \"arn:aws:inspector:us-west-2:758058086616:rulespackage/0-JJOtZiqQ\",\n    \"arn:aws:inspector:us-west-2:758058086616:rulespackage/0-vg5GGHSD\",\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the assessment template.\n* `target_arn` - (Required) The assessment target ARN to attach the template to.\n* `duration` - (Required) The duration of the inspector run.\n* `rules_package_arns` - (Required) The rules to be used during the run.\n* `tags` - (Optional) Key-value map of tags for the Inspector assessment template. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The template assessment ARN.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_inspector_assessment_template` can be imported by using the template assessment ARN, e.g.,\n\n```\n$ terraform import aws_inspector_assessment_template.example arn:aws:inspector:us-west-2:123456789012:target/0-9IaAzhGR/template/0-WEcjR8CH\n```\n",
    "basename": "inspector_assessment_template.html"
  },
  "inspector_resource_group.html": {
    "subcategory": "Inspector",
    "layout": "aws",
    "page_title": "AWS: aws_inspector_resource_group",
    "description": "Provides an Amazon Inspector resource group resource.",
    "preview": "# Resource: aws_inspector_resource_group\n\nProvides an Amazon …",
    "content": "\n\n# Resource: aws_inspector_resource_group\n\nProvides an Amazon Inspector resource group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_inspector_resource_group\" \"example\" {\n  tags = {\n    Name = \"foo\"\n    Env  = \"bar\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `tags` - (Required) Key-value map of tags that are used to select the EC2 instances to be included in an [Amazon Inspector assessment target](/docs/providers/aws/r/inspector_assessment_target.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The resource group ARN.\n",
    "basename": "inspector_resource_group.html"
  },
  "instance.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_instance",
    "description": "Provides an EC2 instance resource. This allows instances to be created, updated, and deleted. Instances also support provisioning.",
    "preview": "# Resource: aws_instance\n\nProvides an EC2 instance resource. This …",
    "content": "\n\n# Resource: aws_instance\n\nProvides an EC2 instance resource. This allows instances to be created, updated, and deleted. Instances also support [provisioning](https://www.terraform.io/docs/provisioners/index.html).\n\n## Example Usage\n\n### Basic Example Using AMI Lookup\n\n```terraform\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n\n  owners = [\"099720109477\"] # Canonical\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = \"t3.micro\"\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n```\n\n### Network and Credit Specification Example\n\n```terraform\nresource \"aws_vpc\" \"my_vpc\" {\n  cidr_block = \"172.16.0.0/16\"\n\n  tags = {\n    Name = \"tf-example\"\n  }\n}\n\nresource \"aws_subnet\" \"my_subnet\" {\n  vpc_id            = aws_vpc.my_vpc.id\n  cidr_block        = \"172.16.10.0/24\"\n  availability_zone = \"us-west-2a\"\n\n  tags = {\n    Name = \"tf-example\"\n  }\n}\n\nresource \"aws_network_interface\" \"foo\" {\n  subnet_id   = aws_subnet.my_subnet.id\n  private_ips = [\"172.16.10.100\"]\n\n  tags = {\n    Name = \"primary_network_interface\"\n  }\n}\n\nresource \"aws_instance\" \"foo\" {\n  ami           = \"ami-005e54dee72cc1d00\" # us-west-2\n  instance_type = \"t2.micro\"\n\n  network_interface {\n    network_interface_id = aws_network_interface.foo.id\n    device_index         = 0\n  }\n\n  credit_specification {\n    cpu_credits = \"unlimited\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `ami` - (Optional) AMI to use for the instance. Required unless `launch_template` is specified and the Launch Template specifes an AMI. If an AMI is specified in the Launch Template, setting `ami` will override the AMI specified in the Launch Template.\n* `associate_public_ip_address` - (Optional) Whether to associate a public IP address with an instance in a VPC.\n* `availability_zone` - (Optional) AZ to start the instance in.\n* `capacity_reservation_specification` - (Optional) Describes an instance's Capacity Reservation targeting option. See [Capacity Reservation Specification](#capacity-reservation-specification) below for more details.\n\n-> **NOTE:** Changing `cpu_core_count` and/or `cpu_threads_per_core` will cause the resource to be destroyed and re-created.\n\n* `cpu_core_count` - (Optional) Sets the number of CPU cores for an instance. This option is only supported on creation of instance type that support CPU Options [CPU Cores and Threads Per CPU Core Per Instance Type](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html#cpu-options-supported-instances-values) - specifying this option for unsupported instance types will return an error from the EC2 API.\n* `cpu_threads_per_core` - (Optional - has no effect unless `cpu_core_count` is also set)  If set to to 1, hyperthreading is disabled on the launched instance. Defaults to 2 if not set. See [Optimizing CPU Options](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html) for more information.\n* `credit_specification` - (Optional) Configuration block for customizing the credit specification of the instance. See [Credit Specification](#credit-specification) below for more details. Terraform will only perform drift detection of its value when present in a configuration. Removing this configuration on existing instances will only stop managing it. It will not change the configuration back to the default for the instance type.\n* `disable_api_termination` - (Optional) If true, enables [EC2 Instance Termination Protection](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html#Using_ChangingDisableAPITermination).\n* `ebs_block_device` - (Optional) One or more configuration blocks with additional EBS block devices to attach to the instance. Block device configurations only apply on resource creation. See [Block Devices](#ebs-ephemeral-and-root-block-devices) below for details on attributes and drift detection. When accessing this as an attribute reference, it is a set of objects.\n* `ebs_optimized` - (Optional) If true, the launched EC2 instance will be EBS-optimized. Note that if this is not set on an instance type that is optimized by default then this will show as disabled but if the instance type is optimized by default then there is no need to set this and there is no effect to disabling it. See the [EBS Optimized section](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html) of the AWS User Guide for more information.\n* `enclave_options` - (Optional) Enable Nitro Enclaves on launched instances. See [Enclave Options](#enclave-options) below for more details.\n* `ephemeral_block_device` - (Optional) One or more configuration blocks to customize Ephemeral (also known as \"Instance Store\") volumes on the instance. See [Block Devices](#ebs-ephemeral-and-root-block-devices) below for details. When accessing this as an attribute reference, it is a set of objects.\n* `get_password_data` - (Optional) If true, wait for password data to become available and retrieve it. Useful for getting the administrator password for instances running Microsoft Windows. The password data is exported to the `password_data` attribute. See [GetPasswordData](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_GetPasswordData.html) for more information.\n* `hibernation` - (Optional) If true, the launched EC2 instance will support hibernation.\n* `host_id` - (Optional) ID of a dedicated host that the instance will be assigned to. Use when an instance is to be launched on a specific dedicated host.\n* `iam_instance_profile` - (Optional) IAM Instance Profile to launch the instance with. Specified as the name of the Instance Profile. Ensure your credentials have the correct permission to assign the instance profile according to the [EC2 documentation](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html#roles-usingrole-ec2instance-permissions), notably `iam:PassRole`.\n* `instance_initiated_shutdown_behavior` - (Optional) Shutdown behavior for the instance. Amazon defaults this to `stop` for EBS-backed instances and `terminate` for instance-store instances. Cannot be set on instance-store instances. See [Shutdown Behavior](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html#Using_ChangingInstanceInitiatedShutdownBehavior) for more information.\n* `instance_type` - (Optional) The instance type to use for the instance. Updates to this field will trigger a stop/start of the EC2 instance.\n* `ipv6_address_count`- (Optional) A number of IPv6 addresses to associate with the primary network interface. Amazon EC2 chooses the IPv6 addresses from the range of your subnet.\n* `ipv6_addresses` - (Optional) Specify one or more IPv6 addresses from the range of the subnet to associate with the primary network interface\n* `key_name` - (Optional) Key name of the Key Pair to use for the instance; which can be managed using [the `aws_key_pair` resource](key_pair.html).\n* `launch_template` - (Optional) Specifies a Launch Template to configure the instance. Parameters configured on this resource will override the corresponding parameters in the Launch Template.\n  See [Launch Template Specification](#launch-template-specification) below for more details.\n* `metadata_options` - (Optional) Customize the metadata options of the instance. See [Metadata Options](#metadata-options) below for more details.\n* `monitoring` - (Optional) If true, the launched EC2 instance will have detailed monitoring enabled. (Available since v0.6.0)\n* `network_interface` - (Optional) Customize network interfaces to be attached at instance boot time. See [Network Interfaces](#network-interfaces) below for more details.\n* `placement_group` - (Optional) Placement Group to start the instance in.\n* `placement_partition_number` - (Optional) The number of the partition the instance is in. Valid only if [the `aws_placement_group` resource's](placement_group.html) `strategy` argument is set to `\"partition\"`.\n* `private_ip` - (Optional) Private IP address to associate with the instance in a VPC.\n* `root_block_device` - (Optional) Configuration block to customize details about the root block device of the instance. See [Block Devices](#ebs-ephemeral-and-root-block-devices) below for details. When accessing this as an attribute reference, it is a list containing one object.\n* `secondary_private_ips` - (Optional) A list of secondary private IPv4 addresses to assign to the instance's primary network interface (eth0) in a VPC. Can only be assigned to the primary network interface (eth0) attached at instance creation, not a pre-existing network interface i.e., referenced in a `network_interface` block. Refer to the [Elastic network interfaces documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#AvailableIpPerENI) to see the maximum number of private IP addresses allowed per instance type.\n* `security_groups` - (Optional, EC2-Classic and default VPC only) A list of security group names to associate with.\n\n-> **NOTE:** If you are creating Instances in a VPC, use `vpc_security_group_ids` instead.\n\n* `source_dest_check` - (Optional) Controls if traffic is routed to the instance when the destination address does not match the instance. Used for NAT or VPNs. Defaults true.\n* `subnet_id` - (Optional) VPC Subnet ID to launch in.\n* `tags` - (Optional) A map of tags to assign to the resource. Note that these tags apply to the instance and not block storage devices. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `tenancy` - (Optional) Tenancy of the instance (if the instance is running in a VPC). An instance with a tenancy of dedicated runs on single-tenant hardware. The host tenancy is not supported for the import-instance command.\n* `user_data` - (Optional) User data to provide when launching the instance. Do not pass gzip-compressed data via this argument; see `user_data_base64` instead.\n* `user_data_base64` - (Optional) Can be used instead of `user_data` to pass base64-encoded binary data directly. Use this instead of `user_data` whenever the value is not a valid UTF-8 string. For example, gzip-encoded user data must be base64-encoded and passed via this argument to avoid corruption.\n* `volume_tags` - (Optional) A map of tags to assign, at instance-creation time, to root and EBS volumes.\n\n~> **NOTE:** Do not use `volume_tags` if you plan to manage block device tags outside the `aws_instance` configuration, such as using `tags` in an [`aws_ebs_volume`](/docs/providers/aws/r/ebs_volume.html) resource attached via [`aws_volume_attachment`](/docs/providers/aws/r/volume_attachment.html). Doing so will result in resource cycling and inconsistent behavior.\n\n* `vpc_security_group_ids` - (Optional, VPC only) A list of security group IDs to associate with.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 10 mins) Used when launching the instance (until it reaches the initial `running` state)\n* `update` - (Defaults to 10 mins) Used when stopping and starting the instance when necessary during update - e.g., when changing instance type\n* `delete` - (Defaults to 20 mins) Used when terminating the instance\n\n### Capacity Reservation Specification\n\n~> **NOTE:** You can specify only one argument at a time. If you specify both `capacity_reservation_preference` and `capacity_reservation_target`, the request fails. Modifying `capacity_reservation_preference` or `capacity_reservation_target` in this block requires the instance to be in `stopped` state.\n\nCapacity reservation specification can be applied/modified to the EC2 Instance at creation time or when the instance is `stopped`.\n\nThe `capacity_reservation_specification` block supports the following:\n\n* `capacity_reservation_preference` - (Optional) Indicates the instance's Capacity Reservation preferences. Can be `\"open\"` or `\"none\"`. (Default: `\"open\"`).\n* `capacity_reservation_target` - (Optional) Information about the target Capacity Reservation. See [Capacity Reservation Target](#capacity-reservation-target) below for more details.\n\nFor more information, see the documentation on [Capacity Reservations](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/capacity-reservations-using.html).\n\n### Capacity Reservation Target\n\n~> **NOTE:** Modifying `capacity_reservation_id` in this block requires the instance to be in `stopped` state.\n\nDescribes a target Capacity Reservation.\n\nThis `capacity_reservation_target` block supports the following:\n\n* `capacity_reservation_id` - (Optional) The ID of the Capacity Reservation in which to run the instance.\n\n### Credit Specification\n\nThe `credit_specification` block supports the following:\n\n* `cpu_credits` - (Optional) Credit option for CPU usage. Valid values include `standard` or `unlimited`. T3 instances are launched as unlimited by default. T2 instances are launched as standard by default.\n\n### EBS, Ephemeral, and Root Block Devices\n\nEach of the `*_block_device` attributes control a portion of the EC2 Instance's \"Block Device Mapping\". For more information, see the [AWS Block Device Mapping documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html).\n\nThe `root_block_device` block supports the following:\n\n* `delete_on_termination` - (Optional) Whether the volume should be destroyed on instance termination. Defaults to `true`.\n* `encrypted` - (Optional) Whether to enable volume encryption. Defaults to `false`. Must be configured to perform drift detection.\n* `iops` - (Optional) Amount of provisioned [IOPS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html). Only valid for volume_type of `io1`, `io2` or `gp3`.\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of the KMS Key to use when encrypting the volume. Must be configured to perform drift detection.\n* `tags` - (Optional) A map of tags to assign to the device.\n* `throughput` - (Optional) Throughput to provision for a volume in mebibytes per second (MiB/s). This is only valid for `volume_type` of `gp3`.\n* `volume_size` - (Optional) Size of the volume in gibibytes (GiB).\n* `volume_type` - (Optional) Type of volume. Valid values include `standard`, `gp2`, `gp3`, `io1`, `io2`, `sc1`, or `st1`. Defaults to `gp2`.\n\nModifying any of the `root_block_device` settings other than `volume_size` or `tags` requires resource replacement.\n\nEach `ebs_block_device` block supports the following:\n\n* `delete_on_termination` - (Optional) Whether the volume should be destroyed on instance termination. Defaults to `true`.\n* `device_name` - (Required) Name of the device to mount.\n* `encrypted` - (Optional) Enables [EBS encryption](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html) on the volume. Defaults to `false`. Cannot be used with `snapshot_id`. Must be configured to perform drift detection.\n* `iops` - (Optional) Amount of provisioned [IOPS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html). Only valid for volume_type of `io1`, `io2` or `gp3`.\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of the KMS Key to use when encrypting the volume. Must be configured to perform drift detection.\n* `snapshot_id` - (Optional) Snapshot ID to mount.\n* `tags` - (Optional) A map of tags to assign to the device.\n* `throughput` - (Optional) Throughput to provision for a volume in mebibytes per second (MiB/s). This is only valid for `volume_type` of `gp3`.\n* `volume_size` - (Optional) Size of the volume in gibibytes (GiB).\n* `volume_type` - (Optional) Type of volume. Valid values include `standard`, `gp2`, `gp3`, `io1`, `io2`, `sc1`, or `st1`. Defaults to `gp2`.\n\n~> **NOTE:** Currently, changes to the `ebs_block_device` configuration of _existing_ resources cannot be automatically detected by Terraform. To manage changes and attachments of an EBS block to an instance, use the `aws_ebs_volume` and `aws_volume_attachment` resources instead. If you use `ebs_block_device` on an `aws_instance`, Terraform will assume management over the full set of non-root EBS block devices for the instance, treating additional block devices as drift. For this reason, `ebs_block_device` cannot be mixed with external `aws_ebs_volume` and `aws_volume_attachment` resources for a given instance.\n\nEach `ephemeral_block_device` block supports the following:\n\n* `device_name` - The name of the block device to mount on the instance.\n* `no_device` - (Optional) Suppresses the specified device included in the AMI's block device mapping.\n* `virtual_name` - (Optional) [Instance Store Device Name](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#InstanceStoreDeviceNames) (e.g., `ephemeral0`).\n\nEach AWS Instance type has a different set of Instance Store block devices available for attachment. AWS [publishes a list](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#StorageOnInstanceTypes) of which ephemeral devices are available on each type. The devices are always identified by the `virtual_name` in the format `ephemeral{0..N}`.\n\n### Enclave Options\n\n-> **NOTE:** Changing `enabled` will cause the resource to be destroyed and re-created.\n\nEnclave options apply to the instance at boot time.\n\nThe `enclave_options` block supports the following:\n\n* `enabled` - (Optional) Whether Nitro Enclaves will be enabled on the instance. Defaults to `false`.\n\nFor more information, see the documentation on [Nitro Enclaves](https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave.html).\n\n### Metadata Options\n\nMetadata options can be applied/modified to the EC2 Instance at any time.\n\nThe `metadata_options` block supports the following:\n\n* `http_endpoint` - (Optional) Whether the metadata service is available. Valid values include `enabled` or `disabled`. Defaults to `enabled`.\n* `http_put_response_hop_limit` - (Optional) Desired HTTP PUT response hop limit for instance metadata requests. The larger the number, the further instance metadata requests can travel. Valid values are integer from `1` to `64`. Defaults to `1`.\n* `http_tokens` - (Optional) Whether or not the metadata service requires session tokens, also referred to as _Instance Metadata Service Version 2 (IMDSv2)_. Valid values include `optional` or `required`. Defaults to `optional`.\n\nFor more information, see the documentation on the [Instance Metadata Service](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html).\n\n### Network Interfaces\n\nEach of the `network_interface` blocks attach a network interface to an EC2 Instance during boot time. However, because the network interface is attached at boot-time, replacing/modifying the network interface **WILL** trigger a recreation of the EC2 Instance. If you should need at any point to detach/modify/re-attach a network interface to the instance, use the `aws_network_interface` or `aws_network_interface_attachment` resources instead.\n\nThe `network_interface` configuration block _does_, however, allow users to supply their own network interface to be used as the default network interface on an EC2 Instance, attached at `eth0`.\n\nEach `network_interface` block supports the following:\n\n* `delete_on_termination` - (Optional) Whether or not to delete the network interface on instance termination. Defaults to `false`. Currently, the only valid value is `false`, as this is only supported when creating new network interfaces when launching an instance.\n* `device_index` - (Required) Integer index of the network interface attachment. Limited by instance type.\n* `network_interface_id` - (Required) ID of the network interface to attach.\n\n### Launch Template Specification\n\n-> **Note:** Launch Template parameters will be used only once during instance creation. If you want to update existing instance you need to change parameters\ndirectly. Updating Launch Template specification will force a new instance.\n\nAny other instance parameters that you specify will override the same parameters in the launch template.\n\nThe `launch_template` block supports the following:\n\n* `id` - The ID of the launch template. Conflicts with `name`.\n* `name` - The name of the launch template. Conflicts with `id`.\n* `version` - Template version. Can be a specific version number, `$Latest` or `$Default`. The default value is `$Default`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the instance.\n* `capacity_reservation_specification` - Capacity reservation specification of the instance.\n* `instance_state` - The state of the instance. One of: `pending`, `running`, `shutting-down`, `terminated`, `stopping`, `stopped`. See [Instance Lifecycle](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html) for more information.\n* `outpost_arn` - The ARN of the Outpost the instance is assigned to.\n* `password_data` - Base-64 encoded encrypted password data for the instance. Useful for getting the administrator password for instances running Microsoft Windows. This attribute is only exported if `get_password_data` is true. Note that this encrypted value will be stored in the state file, as with all exported attributes. See [GetPasswordData](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_GetPasswordData.html) for more information.\n* `primary_network_interface_id` - The ID of the instance's primary network interface.\n* `private_dns` - The private DNS name assigned to the instance. Can only be used inside the Amazon EC2, and only available if you've enabled DNS hostnames for your VPC.\n* `public_dns` - The public DNS name assigned to the instance. For EC2-VPC, this is only available if you've enabled DNS hostnames for your VPC.\n* `public_ip` - The public IP address assigned to the instance, if applicable. **NOTE**: If you are using an [`aws_eip`](/docs/providers/aws/r/eip.html) with your instance, you should refer to the EIP's address directly and not use `public_ip` as this field will change after the EIP is attached.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\nFor `ebs_block_device`, in addition to the arguments above, the following attribute is exported:\n\n* `volume_id` - ID of the volume. For example, the ID can be accessed like this, `aws_instance.web.ebs_block_device.2.volume_id`.\n\nFor `root_block_device`, in addition to the arguments above, the following attributes are exported:\n\n* `volume_id` - ID of the volume. For example, the ID can be accessed like this, `aws_instance.web.root_block_device.0.volume_id`.\n* `device_name` - Device name, e.g., `/dev/sdh` or `xvdh`.\n\n## Import\n\nInstances can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_instance.web i-12345678\n```\n",
    "basename": "instance.html"
  },
  "internet_gateway.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_internet_gateway",
    "description": "Provides a resource to create a VPC Internet Gateway.",
    "preview": "# Resource: aws_internet_gateway\n\nProvides a resource to create a …",
    "content": "\n\n# Resource: aws_internet_gateway\n\nProvides a resource to create a VPC Internet Gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_internet_gateway\" \"gw\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = {\n    Name = \"main\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Required) The VPC ID to create in.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n-> **Note:** It's recommended to denote that the AWS Instance or Elastic IP depends on the Internet Gateway. For example:\n\n```terraform\nresource \"aws_internet_gateway\" \"gw\" {\n  vpc_id = aws_vpc.main.id\n}\n\nresource \"aws_instance\" \"foo\" {\n  # ... other arguments ...\n\n  depends_on = [aws_internet_gateway.gw]\n}\n```\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Internet Gateway.\n* `arn` - The ARN of the Internet Gateway.\n* `owner_id` - The ID of the AWS account that owns the internet gateway.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nInternet Gateways can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_internet_gateway.gw igw-c0a643a9\n```\n",
    "basename": "internet_gateway.html"
  },
  "iot_authorizer.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_authorizer",
    "description": "Creates and manages an AWS IoT Authorizer.",
    "preview": "# Resource: aws_iot_authorizer\n\nCreates and manages an AWS IoT …",
    "content": "\n\n# Resource: aws_iot_authorizer\n\nCreates and manages an AWS IoT Authorizer.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_authorizer\" \"example\" {\n  name                    = \"example\"\n  authorizer_function_arn = aws_lambda_function.example.arn\n  signing_disabled        = false\n  status                  = \"ACTIVE\"\n  token_key_name          = \"Token-Header\"\n\n  token_signing_public_keys = {\n    Key1 = \"${file(\"test-fixtures/iot-authorizer-signing-key.pem\")}\"\n  }\n}\n```\n\n## Argument Reference\n\n* `authorizer_function_arn` - (Required) The ARN of the authorizer's Lambda function.\n* `name` - (Required) The name of the authorizer.\n* `signing_disabled` - (Optional) Specifies whether AWS IoT validates the token signature in an authorization request. Default: `false`.\n* `status` - (Optional) The status of Authorizer request at creation. Valid values: `ACTIVE`, `INACTIVE`. Default: `ACTIVE`.\n* `token_key_name` - (Optional) The name of the token key used to extract the token from the HTTP headers. This value is required if signing is enabled in your authorizer.\n* `token_signing_public_keys` - (Optional) The public keys used to verify the digital signature returned by your custom authentication service. This value is required if signing is enabled in your authorizer.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the authorizer.\n\n## Import\n\nIOT Authorizers can be imported using the name, e.g.,\n\n```\n$ terraform import aws_iot_authorizer.example example\n```\n",
    "basename": "iot_authorizer.html"
  },
  "iot_certificate.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_certificate",
    "description": "Creates and manages an AWS IoT certificate.",
    "preview": "# Resource: aws_iot_certificate\n\nCreates and manages an AWS IoT …",
    "content": "\n\n# Resource: aws_iot_certificate\n\nCreates and manages an AWS IoT certificate.\n\n## Example Usage\n\n### With CSR\n\n```terraform\nresource \"aws_iot_certificate\" \"cert\" {\n  csr    = file(\"/my/csr.pem\")\n  active = true\n}\n```\n\n### Without CSR\n\n```terraform\nresource \"aws_iot_certificate\" \"cert\" {\n  active = true\n}\n```\n\n## Argument Reference\n\n* `active` - (Required)  Boolean flag to indicate if the certificate should be active\n* `csr` - (Optional) The certificate signing request. Review\n  [CreateCertificateFromCsr](https://docs.aws.amazon.com/iot/latest/apireference/API_CreateCertificateFromCsr.html)\n  for more information on generating a certificate from a certificate signing request (CSR).\n  If none is specified both the certificate and keys will be generated, review [CreateKeysAndCertificate](https://docs.aws.amazon.com/iot/latest/apireference/API_CreateKeysAndCertificate.html)\n  for more information on generating keys and a certificate.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The internal ID assigned to this certificate.\n* `arn` - The ARN of the created certificate.\n* `certificate_pem` - The certificate data, in PEM format.\n* `public_key` - When no CSR is provided, the public key.\n* `private_key` - When no CSR is provided, the private key.\n\n",
    "basename": "iot_certificate.html"
  },
  "iot_policy.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_policy",
    "description": "Provides an IoT policy.",
    "preview": "# Resource: aws_iot_policy\n\nProvides an IoT policy.\n\n## Example …",
    "content": "\n\n# Resource: aws_iot_policy\n\nProvides an IoT policy.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_policy\" \"pubsub\" {\n  name = \"PubSubToAnyTopic\"\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"iot:*\",\n        ]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },\n    ]\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the policy.\n* `policy` - (Required) The policy document. This is a JSON formatted string. Use the [IoT Developer Guide](http://docs.aws.amazon.com/iot/latest/developerguide/iot-policies.html) for more information on IoT Policies. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS to this policy.\n* `name` - The name of this policy.\n* `default_version_id` - The default version of this policy.\n* `policy` - The policy document.\n\n## Import\n\nIoT policies can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_iot_policy.pubsub PubSubToAnyTopic\n```\n",
    "basename": "iot_policy.html"
  },
  "iot_policy_attachment.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_policy_attachment",
    "description": "Provides an IoT policy attachment.",
    "preview": "# Resource: aws_iot_policy_attachment\n\nProvides an IoT policy …",
    "content": "\n\n# Resource: aws_iot_policy_attachment\n\nProvides an IoT policy attachment.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_policy\" \"pubsub\" {\n  name = \"PubSubToAnyTopic\"\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"iot:*\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iot_certificate\" \"cert\" {\n  csr    = file(\"csr.pem\")\n  active = true\n}\n\nresource \"aws_iot_policy_attachment\" \"att\" {\n  policy = aws_iot_policy.pubsub.name\n  target = aws_iot_certificate.cert.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy` - (Required) The name of the policy to attach.\n* `target` - (Required) The identity to which the policy is attached.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "iot_policy_attachment.html"
  },
  "iot_role_alias.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_role_alias",
    "description": "Provides an IoT role alias.",
    "preview": "# Resource: aws_iot_role_alias\n\nProvides an IoT role alias.\n\n## …",
    "content": "\n\n# Resource: aws_iot_role_alias\n\nProvides an IoT role alias.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_role\" \"role\" {\n  name = \"dynamodb-access-role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"credentials.iot.amazonaws.com\",\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iot_role_alias\" \"alias\" {\n  alias    = \"Thermostat-dynamodb-access-role-alias\"\n  role_arn = aws_iam_role.role.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `alias` - (Required) The name of the role alias.\n* `role_arn` - (Required) The identity of the role to which the alias refers.\n* `credential_duration` - (Optional) The duration of the credential, in seconds. If you do not specify a value for this setting, the default maximum of one hour is applied. This setting can have a value from 900 seconds (15 minutes) to 3600 seconds (60 minutes).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS to this role alias.\n\n## Import\n\nIOT Role Alias can be imported via the alias, e.g.,\n\n```sh\n$ terraform import aws_iot_role_alias.example myalias\n```\n",
    "basename": "iot_role_alias.html"
  },
  "iot_thing.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_thing",
    "description": "Creates and manages an AWS IoT Thing.",
    "preview": "# Resource: aws_iot_thing\n\nCreates and manages an AWS IoT Thing.\n\n## …",
    "content": "\n\n# Resource: aws_iot_thing\n\nCreates and manages an AWS IoT Thing.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_thing\" \"example\" {\n  name = \"example\"\n\n  attributes = {\n    First = \"examplevalue\"\n  }\n}\n```\n\n## Argument Reference\n\n* `name` - (Required) The name of the thing.\n* `attributes` - (Optional) Map of attributes of the thing.\n* `thing_type_name` - (Optional) The thing type name.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `default_client_id` - The default client ID.\n* `version` - The current version of the thing record in the registry.\n* `arn` - The ARN of the thing.\n\n## Import\n\nIOT Things can be imported using the name, e.g.,\n\n```\n$ terraform import aws_iot_thing.example example\n```\n",
    "basename": "iot_thing.html"
  },
  "iot_thing_group.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_thing_group",
    "description": "Manages an AWS IoT Thing Group.",
    "preview": "# Resource: aws_iot_thing_group\n\nManages an AWS IoT Thing Group.\n\n## …",
    "content": "\n\n# Resource: aws_iot_thing_group\n\nManages an AWS IoT Thing Group.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_thing_group\" \"parent\" {\n  name = \"parent\"\n}\n\nresource \"aws_iot_thing_group\" \"example\" {\n  name = \"example\"\n\n  parent_group_name = aws_iot_thing_group.parent.name\n\n  properties {\n    attribute_payload {\n      attributes = {\n        One = \"11111\"\n        Two = \"TwoTwo\"\n      }\n    }\n    description = \"This is my thing group\"\n  }\n\n  tags = {\n    terraform = \"true\"\n  }\n}\n```\n\n## Argument Reference\n\n* `name` - (Required) The name of the Thing Group.\n* `parent_group_name` - (Optional) The name of the parent Thing Group.\n* `properties` - (Optional) The Thing Group properties. Defined below.\n* `tags` - (Optional) Key-value mapping of resource tags\n\n### properties Reference\n\n* `attribute_payload` - (Optional) The Thing Group attributes. Defined below.\n* `description` - (Optional) A description of the Thing Group.\n\n### attribute_payload Reference\n\n* `attributes` - (Optional) Key-value map.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the Thing Group.\n* `id` - The Thing Group ID.\n* `version` - The current version of the Thing Group record in the registry.\n\n## Import\n\nIoT Things Groups can be imported using the name, e.g.\n\n```\n$ terraform import aws_iot_thing_group.example example\n```\n",
    "basename": "iot_thing_group.html"
  },
  "iot_thing_group_membership.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_thing_group_membership",
    "description": "Adds an IoT Thing to an IoT Thing Group.",
    "preview": "# Resource: aws_iot_thing_group_membership\n\nAdds an IoT Thing to an …",
    "content": "\n\n# Resource: aws_iot_thing_group_membership\n\nAdds an IoT Thing to an IoT Thing Group.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_thing_group_membership\" \"example\" {\n  thing_name       = \"example-thing\"\n  thing_group_name = \"example-group\"\n\n  override_dynamic_group = true\n}\n```\n\n## Argument Reference\n\n* `thing_name` - (Required) The name of the thing to add to a group.\n* `thing_group_name` - (Required) The name of the group to which you are adding a thing.\n* `override_dynamic_group` - (Optional) Override dynamic thing groups with static thing groups when 10-group limit is reached. If a thing belongs to 10 thing groups, and one or more of those groups are dynamic thing groups, adding a thing to a static group removes the thing from the last dynamic group.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The membership ID.\n\n## Import\n\nIoT Thing Group Membership can be imported using the thing group name and thing name.\n\n```\n$ terraform import aws_iot_thing_group_membership.example thing_group_name/thing_name\n```\n",
    "basename": "iot_thing_group_membership.html"
  },
  "iot_thing_principal_attachment.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_thing_principal_attachment",
    "description": "Provides AWS IoT Thing Principal attachment.",
    "preview": "# Resource: aws_iot_thing_principal_attachment\n\nAttaches Principal …",
    "content": "\n\n# Resource: aws_iot_thing_principal_attachment\n\nAttaches Principal to AWS IoT Thing.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_thing\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_iot_certificate\" \"cert\" {\n  csr    = file(\"csr.pem\")\n  active = true\n}\n\nresource \"aws_iot_thing_principal_attachment\" \"att\" {\n  principal = aws_iot_certificate.cert.arn\n  thing     = aws_iot_thing.example.name\n}\n```\n\n## Argument Reference\n\n* `principal` - (Required) The AWS IoT Certificate ARN or Amazon Cognito Identity ID.\n* `thing` - (Required) The name of the thing.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "iot_thing_principal_attachment.html"
  },
  "iot_thing_type.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_thing_type",
    "description": "Creates and manages an AWS IoT Thing Type.",
    "preview": "# Resource: aws_iot_thing_type\n\nCreates and manages an AWS IoT Thing …",
    "content": "\n\n# Resource: aws_iot_thing_type\n\nCreates and manages an AWS IoT Thing Type.\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_thing_type\" \"foo\" {\n  name = \"my_iot_thing\"\n}\n```\n\n## Argument Reference\n\n* `name` - (Required, Forces New Resource) The name of the thing type.\n* `deprecated` - (Optional, Defaults to false) Whether the thing type is deprecated. If true, no new things could be associated with this type.\n* `properties` - (Optional), Configuration block that can contain the following properties of the thing type:\n    * `description` - (Optional, Forces New Resource) The description of the thing type.\n    * `searchable_attributes` - (Optional, Forces New Resource) A list of searchable thing attribute names.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the created AWS IoT Thing Type.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nIOT Thing Types can be imported using the name, e.g.,\n\n```\n$ terraform import aws_iot_thing_type.example example\n```\n",
    "basename": "iot_thing_type.html"
  },
  "iot_topic_rule.html": {
    "subcategory": "IoT",
    "layout": "aws",
    "page_title": "AWS: aws_iot_topic_rule",
    "description": "Creates and manages an AWS IoT topic rule",
    "preview": "# Resource: aws_iot_topic_rule\n\n## Example Usage\n\n```terraform …",
    "content": "\n\n# Resource: aws_iot_topic_rule\n\n## Example Usage\n\n```terraform\nresource \"aws_iot_topic_rule\" \"rule\" {\n  name        = \"MyRule\"\n  description = \"Example rule\"\n  enabled     = true\n  sql         = \"SELECT * FROM 'topic/test'\"\n  sql_version = \"2016-03-23\"\n\n  sns {\n    message_format = \"RAW\"\n    role_arn       = aws_iam_role.role.arn\n    target_arn     = aws_sns_topic.mytopic.arn\n  }\n\n  error_action {\n    sns {\n      message_format = \"RAW\"\n      role_arn       = aws_iam_role.role.arn\n      target_arn     = aws_sns_topic.myerrortopic.arn\n    }\n  }\n}\n\nresource \"aws_sns_topic\" \"mytopic\" {\n  name = \"mytopic\"\n}\n\nresource \"aws_sns_topic\" \"myerrortopic\" {\n  name = \"myerrortopic\"\n}\n\nresource \"aws_iam_role\" \"role\" {\n  name = \"myrole\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"iot.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"iam_policy_for_lambda\" {\n  name = \"mypolicy\"\n  role = aws_iam_role.role.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"sns:Publish\"\n        ],\n        \"Resource\": \"${aws_sns_topic.mytopic.arn}\"\n    }\n  ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\n* `name` - (Required) The name of the rule.\n* `description` - (Optional) The description of the rule.\n* `enabled` - (Required) Specifies whether the rule is enabled.\n* `sql` - (Required) The SQL statement used to query the topic. For more information, see AWS IoT SQL Reference (http://docs.aws.amazon.com/iot/latest/developerguide/iot-rules.html#aws-iot-sql-reference) in the AWS IoT Developer Guide.\n* `sql_version` - (Required) The version of the SQL rules engine to use when evaluating the rule.\n* `error_action` - (Optional) Configuration block with error action to be associated with the rule. See the documentation for `cloudwatch_alarm`, `cloudwatch_metric`, `dynamodb`, `dynamodbv2`, `elasticsearch`, `firehose`, `iot_analytics`, `iot_events`, `kinesis`, `lambda`, `republish`, `s3`, `step_functions`, `sns`, `sqs` configuration blocks for further configuration details.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `cloudwatch_alarm` object takes the following arguments:\n\n* `alarm_name` - (Required) The CloudWatch alarm name.\n* `role_arn` - (Required) The IAM role ARN that allows access to the CloudWatch alarm.\n* `state_reason` - (Required) The reason for the alarm change.\n* `state_value` - (Required) The value of the alarm state. Acceptable values are: OK, ALARM, INSUFFICIENT_DATA.\n\nThe `cloudwatch_metric` object takes the following arguments:\n\n* `metric_name` - (Required) The CloudWatch metric name.\n* `metric_namespace` - (Required) The CloudWatch metric namespace name.\n* `metric_timestamp` - (Optional) An optional Unix timestamp (http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html#about_timestamp).\n* `metric_unit` - (Required) The metric unit (supported units can be found here: http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html#Unit)\n* `metric_value` - (Required) The CloudWatch metric value.\n* `role_arn` - (Required) The IAM role ARN that allows access to the CloudWatch metric.\n\nThe `dynamodb` object takes the following arguments:\n\n* `hash_key_field` - (Required) The hash key name.\n* `hash_key_type` - (Optional) The hash key type. Valid values are \"STRING\" or \"NUMBER\".\n* `hash_key_value` - (Required) The hash key value.\n* `payload_field` - (Optional) The action payload.\n* `range_key_field` - (Optional) The range key name.\n* `range_key_type` - (Optional) The range key type. Valid values are \"STRING\" or \"NUMBER\".\n* `range_key_value` - (Optional) The range key value.\n* `operation` - (Optional) The operation. Valid values are \"INSERT\", \"UPDATE\", or \"DELETE\".\n* `role_arn` - (Required) The ARN of the IAM role that grants access to the DynamoDB table.\n* `table_name` - (Required) The name of the DynamoDB table.\n\nThe `dynamodbv2` object takes the following arguments:\n\n* `put_item` - (Required) Configuration block with DynamoDB Table to which the message will be written. Nested arguments below.\n    * `table_name` - (Required) The name of the DynamoDB table.\n* `role_arn` - (Required) The ARN of the IAM role that grants access to the DynamoDB table.\n\nThe `elasticsearch` object takes the following arguments:\n\n* `endpoint` - (Required) The endpoint of your Elasticsearch domain.\n* `id` - (Required) The unique identifier for the document you are storing.\n* `index` - (Required) The Elasticsearch index where you want to store your data.\n* `role_arn` - (Required) The IAM role ARN that has access to Elasticsearch.\n* `type` - (Required) The type of document you are storing.\n\nThe `firehose` object takes the following arguments:\n\n* `delivery_stream_name` - (Required) The delivery stream name.\n* `role_arn` - (Required) The IAM role ARN that grants access to the Amazon Kinesis Firehose stream.\n* `separator` - (Optional) A character separator that is used to separate records written to the Firehose stream. Valid values are: '\\n' (newline), '\\t' (tab), '\\r\\n' (Windows newline), ',' (comma).\n\nThe `kinesis` object takes the following arguments:\n\n* `partition_key` - (Optional) The partition key.\n* `role_arn` - (Required) The ARN of the IAM role that grants access to the Amazon Kinesis stream.\n* `stream_name` - (Required) The name of the Amazon Kinesis stream.\n\nThe `lambda` object takes the following arguments:\n\n* `function_arn` - (Required) The ARN of the Lambda function.\n\nThe `republish` object takes the following arguments:\n\n* `role_arn` - (Required) The ARN of the IAM role that grants access.\n* `topic` - (Required) The name of the MQTT topic the message should be republished to.\n* `qos` - (Optional) The Quality of Service (QoS) level to use when republishing messages. Valid values are 0 or 1. The default value is 0.\n\nThe `s3` object takes the following arguments:\n\n* `bucket_name` - (Required) The Amazon S3 bucket name.\n* `key` - (Required) The object key.\n* `role_arn` - (Required) The ARN of the IAM role that grants access.\n\nThe `sns` object takes the following arguments:\n\n* `message_format` - (Required) The message format of the message to publish. Accepted values are \"JSON\" and \"RAW\".\n* `role_arn` - (Required) The ARN of the IAM role that grants access.\n* `target_arn` - (Required) The ARN of the SNS topic.\n\nThe `sqs` object takes the following arguments:\n\n* `queue_url` - (Required) The URL of the Amazon SQS queue.\n* `role_arn` - (Required) The ARN of the IAM role that grants access.\n* `use_base64` - (Required) Specifies whether to use Base64 encoding.\n\nThe `step_functions` object takes the following arguments:\n\n* `execution_name_prefix` - (Optional) The prefix used to generate, along with a UUID, the unique state machine execution name.\n* `state_machine_name` - (Required) The name of the Step Functions state machine whose execution will be started.\n* `role_arn` - (Required) The ARN of the IAM role that grants access to start execution of the state machine.\n\nThe `iot_analytics` object takes the following arguments:\n\n* `channel_name` - (Required) Name of AWS IOT Analytics channel.\n* `role_arn` - (Required) The ARN of the IAM role that grants access.\n\nThe `iot_events` object takes the following arguments:\n\n* `input_name` - (Required) The name of the AWS IoT Events input.\n* `role_arn` - (Required) The ARN of the IAM role that grants access.\n* `message_id` - (Optional) Use this to ensure that only one input (message) with a given messageId is processed by an AWS IoT Events detector.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the topic rule\n* `arn` - The ARN of the topic rule\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nIoT Topic Rules can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_iot_topic_rule.rule <name>\n```\n",
    "basename": "iot_topic_rule.html"
  },
  "key_pair.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_key_pair",
    "description": "Provides a Key Pair resource. Currently this supports importing an existing key pair but not creating a new key pair.",
    "preview": "# Resource: aws_key_pair\n\nProvides an [EC2 key …",
    "content": "\n\n# Resource: aws_key_pair\n\nProvides an [EC2 key pair](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html) resource. A key pair is used to control login access to EC2 instances.\n\nCurrently this resource requires an existing user-supplied key pair. This key pair's public key will be registered with AWS to allow logging-in to EC2 instances.\n\nWhen importing an existing key pair the public key material may be in any format supported by AWS. Supported formats (per the [AWS documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#how-to-generate-your-own-key-and-import-it-to-aws)) are:\n\n* OpenSSH public key format (the format in ~/.ssh/authorized_keys)\n* Base64 encoded DER format\n* SSH public key file format as specified in RFC4716\n\n## Example Usage\n\n```terraform\nresource \"aws_key_pair\" \"deployer\" {\n  key_name   = \"deployer-key\"\n  public_key = \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQD3F6tyPEFEzV0LX3X8BsXdMsQz1x2cEikKDEY0aIj41qgxMCP/iteneqXSIFZBp5vizPvaoIR3Um9xK7PGoW8giupGn+EPuxIA4cDM4vzOqOkiMPhz5XK0whEjkVzTo4+S0puvDZuwIsdiW9mxhJc7tgBNL0cYlWSYVkz4G/fslNfRPW5mYAM49f4fhtxPb5ok4Q2Lg9dPKVHO/Bgeu5woMc7RY0p1ej6D4CKFE6lymSDJpW0YHX/wqE9+cfEauh7xZcG0q9t2ta6F6fmX0agvpFyZo8aFbXeUBr7osSCJNgvavWbM/06niWrOvYX2xwWdhXmXSrbX8ZbabVohBK41 email@example.com\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `key_name` - (Optional) The name for the key pair.\n* `key_name_prefix` - (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `key_name`.\n* `public_key` - (Required) The public key material.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The key pair name.\n* `arn` - The key pair ARN.\n* `key_name` - The key pair name.\n* `key_pair_id` - The key pair ID.\n* `fingerprint` - The MD5 public key fingerprint as specified in section 4 of RFC 4716.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nKey Pairs can be imported using the `key_name`, e.g.,\n\n```\n$ terraform import aws_key_pair.deployer deployer-key\n```\n\n~> **NOTE:** The AWS API does not include the public key in the response, so `terraform apply` will attempt to replace the key pair. There is currently no supported workaround for this limitation.\n",
    "basename": "key_pair.html"
  },
  "kinesis_analytics_application.html": {
    "subcategory": "Kinesis Data Analytics (SQL Applications)",
    "layout": "aws",
    "page_title": "AWS: aws_kinesis_analytics_application",
    "description": "Provides a AWS Kinesis Analytics Application",
    "preview": "# Resource: aws_kinesis_analytics_application\n\nProvides a Kinesis …",
    "content": "\n\n# Resource: aws_kinesis_analytics_application\n\nProvides a Kinesis Analytics Application resource. Kinesis Analytics is a managed service that\nallows processing and analyzing streaming data using standard SQL.\n\nFor more details, see the [Amazon Kinesis Analytics Documentation][1].\n\n-> **Note:** To manage Amazon Kinesis Data Analytics for Apache Flink applications, use the [`aws_kinesisanalyticsv2_application`](/docs/providers/aws/r/kinesisanalyticsv2_application.html) resource.\n\n## Example Usage\n\n### Kinesis Stream Input\n\n```terraform\nresource \"aws_kinesis_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-test\"\n  shard_count = 1\n}\n\nresource \"aws_kinesis_analytics_application\" \"test_application\" {\n  name = \"kinesis-analytics-application-test\"\n\n  inputs {\n    name_prefix = \"test_prefix\"\n\n    kinesis_stream {\n      resource_arn = aws_kinesis_stream.test_stream.arn\n      role_arn     = aws_iam_role.test.arn\n    }\n\n    parallelism {\n      count = 1\n    }\n\n    schema {\n      record_columns {\n        mapping  = \"$.test\"\n        name     = \"test\"\n        sql_type = \"VARCHAR(8)\"\n      }\n\n      record_encoding = \"UTF-8\"\n\n      record_format {\n        mapping_parameters {\n          json {\n            record_row_path = \"$\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n### Starting An Application\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name = \"analytics\"\n}\n\nresource \"aws_cloudwatch_log_stream\" \"example\" {\n  name           = \"example-kinesis-application\"\n  log_group_name = aws_cloudwatch_log_group.example.name\n}\n\nresource \"aws_kinesis_stream\" \"example\" {\n  name        = \"example-kinesis-stream\"\n  shard_count = 1\n}\n\nresource \"aws_kinesis_firehose_delivery_stream\" \"example\" {\n  name        = \"example-kinesis-delivery-stream\"\n  destination = \"extended_s3\"\n\n  extended_s3_configuration {\n    bucket_arn = aws_s3_bucket.example.arn\n    role_arn   = aws_iam_role.example.arn\n  }\n}\n\nresource \"aws_kinesis_analytics_application\" \"test\" {\n  name = \"example-application\"\n\n  cloudwatch_logging_options {\n    log_stream_arn = aws_cloudwatch_log_stream.example.arn\n    role_arn       = aws_iam_role.example.arn\n  }\n\n  inputs {\n    name_prefix = \"example_prefix\"\n\n    schema {\n      record_columns {\n        name     = \"COLUMN_1\"\n        sql_type = \"INTEGER\"\n      }\n\n      record_format {\n        mapping_parameters {\n          csv {\n            record_column_delimiter = \",\"\n            record_row_delimiter    = \"|\"\n          }\n        }\n      }\n    }\n\n    kinesis_stream {\n      resource_arn = aws_kinesis_stream.example.arn\n      role_arn     = aws_iam_role.example.arn\n    }\n\n    starting_position_configuration {\n      starting_position = \"NOW\"\n    }\n  }\n\n  outputs {\n    name = \"OUTPUT_1\"\n\n    schema {\n      record_format_type = \"CSV\"\n    }\n\n    kinesis_firehose {\n      resource_arn = aws_kinesis_firehose_delivery_stream.example.arn\n      role_arn     = aws_iam_role.example.arn\n    }\n  }\n\n  start_application = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the Kinesis Analytics Application.\n* `code` - (Optional) SQL Code to transform input data, and generate output.\n* `description` - (Optional) Description of the application.\n* `cloudwatch_logging_options` - (Optional) The CloudWatch log stream options to monitor application errors.\nSee [CloudWatch Logging Options](#cloudwatch-logging-options) below for more details.\n* `inputs` - (Optional) Input configuration of the application. See [Inputs](#inputs) below for more details.\n* `outputs` - (Optional) Output destination configuration of the application. See [Outputs](#outputs) below for more details.\n* `reference_data_sources` - (Optional) An S3 Reference Data Source for the application.\nSee [Reference Data Sources](#reference-data-sources) below for more details.\n* `start_application` - (Optional) Whether to start or stop the Kinesis Analytics Application. To start an application, an input with a defined `starting_position` must be configured.\nTo modify an application's starting position, first stop the application by setting `start_application = false`, then update `starting_position` and set `start_application = true`.\n* `tags` - Key-value map of tags for the Kinesis Analytics Application. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### CloudWatch Logging Options\n\nConfigure a CloudWatch Log Stream to monitor application errors.\n\nThe `cloudwatch_logging_options` block supports the following:\n\n* `log_stream_arn` - (Required) The ARN of the CloudWatch Log Stream.\n* `role_arn` - (Required) The ARN of the IAM Role used to send application messages.\n\n### Inputs\n\nConfigure an Input for the Kinesis Analytics Application. You can only have 1 Input configured.\n\nThe `inputs` block supports the following:\n\n* `name_prefix` - (Required) The Name Prefix to use when creating an in-application stream.\n* `schema` - (Required) The Schema format of the data in the streaming source. See [Source Schema](#source-schema) below for more details.\n* `kinesis_firehose` - (Optional) The Kinesis Firehose configuration for the streaming source. Conflicts with `kinesis_stream`.\nSee [Kinesis Firehose](#kinesis-firehose) below for more details.\n* `kinesis_stream` - (Optional) The Kinesis Stream configuration for the streaming source. Conflicts with `kinesis_firehose`.\nSee [Kinesis Stream](#kinesis-stream) below for more details.\n* `parallelism` - (Optional) The number of Parallel in-application streams to create.\nSee [Parallelism](#parallelism) below for more details.\n* `processing_configuration` - (Optional) The Processing Configuration to transform records as they are received from the stream.\nSee [Processing Configuration](#processing-configuration) below for more details.\n* `starting_position_configuration` (Optional) The point at which the application starts processing records from the streaming source.\nSee [Starting Position Configuration](#starting-position-configuration) below for more details.\n\n### Outputs\n\nConfigure Output destinations for the Kinesis Analytics Application. You can have a maximum of 3 destinations configured.\n\nThe `outputs` block supports the following:\n\n* `name` - (Required) The Name of the in-application stream.\n* `schema` - (Required) The Schema format of the data written to the destination. See [Destination Schema](#destination-schema) below for more details.\n* `kinesis_firehose` - (Optional) The Kinesis Firehose configuration for the destination stream. Conflicts with `kinesis_stream`.\nSee [Kinesis Firehose](#kinesis-firehose) below for more details.\n* `kinesis_stream` - (Optional) The Kinesis Stream configuration for the destination stream. Conflicts with `kinesis_firehose`.\nSee [Kinesis Stream](#kinesis-stream) below for more details.\n* `lambda` - (Optional) The Lambda function destination. See [Lambda](#lambda) below for more details.\n\n### Reference Data Sources\n\nAdd a Reference Data Source to the Kinesis Analytics Application. You can only have 1 Reference Data Source.\n\nThe `reference_data_sources` block supports the following:\n\n* `schema` - (Required) The Schema format of the data in the streaming source. See [Source Schema](#source-schema) below for more details.\n* `table_name` - (Required) The in-application Table Name.\n* `s3` - (Optional) The S3 configuration for the reference data source. See [S3 Reference](#s3-reference) below for more details.\n\n#### Kinesis Firehose\n\nConfiguration for a Kinesis Firehose delivery stream.\n\nThe `kinesis_firehose` block supports the following:\n\n* `resource_arn` - (Required) The ARN of the Kinesis Firehose delivery stream.\n* `role_arn` - (Required) The ARN of the IAM Role used to access the stream.\n\n#### Kinesis Stream\n\nConfiguration for a Kinesis Stream.\n\nThe `kinesis_stream` block supports the following:\n\n* `resource_arn` - (Required) The ARN of the Kinesis Stream.\n* `role_arn` - (Required) The ARN of the IAM Role used to access the stream.\n\n#### Destination Schema\n\nThe Schema format of the data in the destination.\n\nThe `schema` block supports the following:\n\n* `record_format_type` - (Required) The Format Type of the records on the output stream. Can be `CSV` or `JSON`.\n\n#### Source Schema\n\nThe Schema format of the data in the streaming source.\n\nThe `schema` block supports the following:\n\n* `record_columns` - (Required) The Record Column mapping for the streaming source data element.\nSee [Record Columns](#record-columns) below for more details.\n* `record_format` - (Required) The Record Format and mapping information to schematize a record.\nSee [Record Format](#record-format) below for more details.\n* `record_encoding` - (Optional) The Encoding of the record in the streaming source.\n\n#### Parallelism\n\nConfigures the number of Parallel in-application streams to create.\n\nThe `parallelism` block supports the following:\n\n* `count` - (Required) The Count of streams.\n\n#### Processing Configuration\n\nThe Processing Configuration to transform records as they are received from the stream.\n\nThe `processing_configuration` block supports the following:\n\n* `lambda` - (Required) The Lambda function configuration. See [Lambda](#lambda) below for more details.\n\n#### Lambda\n\nThe Lambda function that pre-processes records in the stream.\n\nThe `lambda` block supports the following:\n\n* `resource_arn` - (Required) The ARN of the Lambda function.\n* `role_arn` - (Required) The ARN of the IAM Role used to access the Lambda function.\n\n#### Starting Position Configuration\n\nThe point at which the application reads from the streaming source.\n\nThe `starting_position_configuration` block supports the following:\n\n* `starting_position` - (Required) The starting position on the stream. Valid values: `LAST_STOPPED_POINT`, `NOW`, `TRIM_HORIZON`.\n\n#### Record Columns\n\nThe Column mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nThe `record_columns` block supports the following:\n\n* `name` - (Required) Name of the column.\n* `sql_type` - (Required) The SQL Type of the column.\n* `mapping` - (Optional) The Mapping reference to the data element.\n\n#### Record Format\n\nThe Record Format and relevant mapping information that should be applied to schematize the records on the stream.\n\nThe `record_format` block supports the following:\n\n* `record_format_type` - (Required) The type of Record Format. Can be `CSV` or `JSON`.\n* `mapping_parameters` - (Optional) The Mapping Information for the record format.\nSee [Mapping Parameters](#mapping-parameters) below for more details.\n\n#### Mapping Parameters\n\nProvides Mapping information specific to the record format on the streaming source.\n\nThe `mapping_parameters` block supports the following:\n\n* `csv` - (Optional) Mapping information when the record format uses delimiters.\nSee [CSV Mapping Parameters](#csv-mapping-parameters) below for more details.\n* `json` - (Optional) Mapping information when JSON is the record format on the streaming source.\nSee [JSON Mapping Parameters](#json-mapping-parameters) below for more details.\n\n#### CSV Mapping Parameters\n\nMapping information when the record format uses delimiters.\n\nThe `csv` block supports the following:\n\n* `record_column_delimiter` - (Required) The Column Delimiter.\n* `record_row_delimiter` - (Required) The Row Delimiter.\n\n#### JSON Mapping Parameters\n\nMapping information when JSON is the record format on the streaming source.\n\nThe `json` block supports the following:\n\n* `record_row_path` - (Required) Path to the top-level parent that contains the records.\n\n#### S3 Reference\n\nIdentifies the S3 bucket and object that contains the reference data.\n\nThe `s3` blcok supports the following:\n\n* `bucket_arn` - (Required) The S3 Bucket ARN.\n* `file_key` - (Required) The File Key name containing reference data.\n* `role_arn` - (Required) The IAM Role ARN to read the data.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the Kinesis Analytics Application.\n* `arn` - The ARN of the Kinesis Analytics Appliation.\n* `create_timestamp` - The Timestamp when the application version was created.\n* `last_update_timestamp` - The Timestamp when the application was last updated.\n* `status` - The Status of the application.\n* `version` - The Version of the application.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[1]: https://docs.aws.amazon.com/kinesisanalytics/latest/dev/what-is.html\n\n## Import\n\nKinesis Analytics Application can be imported by using ARN, e.g.,\n\n```\n$ terraform import aws_kinesis_analytics_application.example arn:aws:kinesisanalytics:us-west-2:1234567890:application/example\n```\n",
    "basename": "kinesis_analytics_application.html"
  },
  "kinesis_firehose_delivery_stream.html": {
    "subcategory": "Kinesis Firehose",
    "layout": "aws",
    "page_title": "AWS: aws_kinesis_firehose_delivery_stream",
    "description": "Provides a AWS Kinesis Firehose Delivery Stream",
    "preview": "# Resource: aws_kinesis_firehose_delivery_stream\n\nProvides a Kinesis …",
    "content": "\n\n# Resource: aws_kinesis_firehose_delivery_stream\n\nProvides a Kinesis Firehose Delivery Stream resource. Amazon Kinesis Firehose is a fully managed, elastic service to easily deliver real-time data streams to destinations such as Amazon S3 and Amazon Redshift.\n\nFor more details, see the [Amazon Kinesis Firehose Documentation][1].\n\n## Example Usage\n\n### Extended S3 Destination\n\n```terraform\nresource \"aws_kinesis_firehose_delivery_stream\" \"extended_s3_stream\" {\n  name        = \"terraform-kinesis-firehose-extended-s3-test-stream\"\n  destination = \"extended_s3\"\n\n  extended_s3_configuration {\n    role_arn   = aws_iam_role.firehose_role.arn\n    bucket_arn = aws_s3_bucket.bucket.arn\n\n    processing_configuration {\n      enabled = \"true\"\n\n      processors {\n        type = \"Lambda\"\n\n        parameters {\n          parameter_name  = \"LambdaArn\"\n          parameter_value = \"${aws_lambda_function.lambda_processor.arn}:$LATEST\"\n        }\n      }\n    }\n  }\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"tf-test-bucket\"\n  acl    = \"private\"\n}\n\nresource \"aws_iam_role\" \"firehose_role\" {\n  name = \"firehose_test_role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"firehose.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role\" \"lambda_iam\" {\n  name = \"lambda_iam\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_lambda_function\" \"lambda_processor\" {\n  filename      = \"lambda.zip\"\n  function_name = \"firehose_lambda_processor\"\n  role          = aws_iam_role.lambda_iam.arn\n  handler       = \"exports.handler\"\n  runtime       = \"nodejs12.x\"\n}\n```\n\n### S3 Destination (deprecated)\n\n```terraform\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"tf-test-bucket\"\n  acl    = \"private\"\n}\n\nresource \"aws_iam_role\" \"firehose_role\" {\n  name = \"firehose_test_role\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"firehose.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_kinesis_firehose_delivery_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-firehose-test-stream\"\n  destination = \"s3\"\n\n  s3_configuration {\n    role_arn   = aws_iam_role.firehose_role.arn\n    bucket_arn = aws_s3_bucket.bucket.arn\n  }\n}\n```\n\n### Redshift Destination\n\n```terraform\nresource \"aws_redshift_cluster\" \"test_cluster\" {\n  cluster_identifier = \"tf-redshift-cluster\"\n  database_name      = \"test\"\n  master_username    = \"testuser\"\n  master_password    = \"T3stPass\"\n  node_type          = \"dc1.large\"\n  cluster_type       = \"single-node\"\n}\n\nresource \"aws_kinesis_firehose_delivery_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-firehose-test-stream\"\n  destination = \"redshift\"\n\n  s3_configuration {\n    role_arn           = aws_iam_role.firehose_role.arn\n    bucket_arn         = aws_s3_bucket.bucket.arn\n    buffer_size        = 10\n    buffer_interval    = 400\n    compression_format = \"GZIP\"\n  }\n\n  redshift_configuration {\n    role_arn           = aws_iam_role.firehose_role.arn\n    cluster_jdbcurl    = \"jdbc:redshift://${aws_redshift_cluster.test_cluster.endpoint}/${aws_redshift_cluster.test_cluster.database_name}\"\n    username           = \"testuser\"\n    password           = \"T3stPass\"\n    data_table_name    = \"test-table\"\n    copy_options       = \"delimiter '|'\" # the default delimiter\n    data_table_columns = \"test-col\"\n    s3_backup_mode     = \"Enabled\"\n\n    s3_backup_configuration {\n      role_arn           = aws_iam_role.firehose_role.arn\n      bucket_arn         = aws_s3_bucket.bucket.arn\n      buffer_size        = 15\n      buffer_interval    = 300\n      compression_format = \"GZIP\"\n    }\n  }\n}\n```\n\n### Elasticsearch Destination\n\n```terraform\nresource \"aws_elasticsearch_domain\" \"test_cluster\" {\n  domain_name = \"firehose-es-test\"\n}\n\nresource \"aws_kinesis_firehose_delivery_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-firehose-test-stream\"\n  destination = \"elasticsearch\"\n\n  s3_configuration {\n    role_arn           = aws_iam_role.firehose_role.arn\n    bucket_arn         = aws_s3_bucket.bucket.arn\n    buffer_size        = 10\n    buffer_interval    = 400\n    compression_format = \"GZIP\"\n  }\n\n  elasticsearch_configuration {\n    domain_arn = aws_elasticsearch_domain.test_cluster.arn\n    role_arn   = aws_iam_role.firehose_role.arn\n    index_name = \"test\"\n    type_name  = \"test\"\n\n    processing_configuration {\n      enabled = \"true\"\n\n      processors {\n        type = \"Lambda\"\n\n        parameters {\n          parameter_name  = \"LambdaArn\"\n          parameter_value = \"${aws_lambda_function.lambda_processor.arn}:$LATEST\"\n        }\n      }\n    }\n  }\n}\n```\n\n### Elasticsearch Destination With VPC\n\n```terraform\nresource \"aws_elasticsearch_domain\" \"test_cluster\" {\n  domain_name = \"es-test\"\n\n  cluster_config {\n    instance_count         = 2\n    zone_awareness_enabled = true\n    instance_type          = \"t2.small.elasticsearch\"\n  }\n\n  ebs_options {\n    ebs_enabled = true\n    volume_size = 10\n  }\n\n  vpc_options {\n    security_group_ids = [aws_security_group.first.id]\n    subnet_ids         = [aws_subnet.first.id, aws_subnet.second.id]\n  }\n}\n\nresource \"aws_iam_role_policy\" \"firehose-elasticsearch\" {\n  name   = \"elasticsearch\"\n  role   = aws_iam_role.firehose.id\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"es:*\"\n      ],\n      \"Resource\": [\n        \"${aws_elasticsearch_domain.test_cluster.arn}\",\n        \"${aws_elasticsearch_domain.test_cluster.arn}/*\"\n      ]\n        },\n        {\n          \"Effect\": \"Allow\",\n          \"Action\": [\n            \"ec2:DescribeVpcs\",\n            \"ec2:DescribeVpcAttribute\",\n            \"ec2:DescribeSubnets\",\n            \"ec2:DescribeSecurityGroups\",\n            \"ec2:DescribeNetworkInterfaces\",\n            \"ec2:CreateNetworkInterface\",\n            \"ec2:CreateNetworkInterfacePermission\",\n            \"ec2:DeleteNetworkInterface\"\n          ],\n          \"Resource\": [\n            \"*\"\n          ]\n        }\n  ]\n}\nEOF\n}\n\nresource \"aws_kinesis_firehose_delivery_stream\" \"test\" {\n  depends_on = [aws_iam_role_policy.firehose-elasticsearch]\n\n  name        = \"terraform-kinesis-firehose-es\"\n  destination = \"elasticsearch\"\n  s3_configuration {\n    role_arn   = aws_iam_role.firehose.arn\n    bucket_arn = aws_s3_bucket.bucket.arn\n  }\n  elasticsearch_configuration {\n    domain_arn = aws_elasticsearch_domain.test_cluster.arn\n    role_arn   = aws_iam_role.firehose.arn\n    index_name = \"test\"\n    type_name  = \"test\"\n\n    vpc_config {\n      subnet_ids         = [aws_subnet.first.id, aws_subnet.second.id]\n      security_group_ids = [aws_security_group.first.id]\n      role_arn           = aws_iam_role.firehose.arn\n    }\n  }\n}\n```\n\n### Splunk Destination\n\n```terraform\nresource \"aws_kinesis_firehose_delivery_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-firehose-test-stream\"\n  destination = \"splunk\"\n\n  s3_configuration {\n    role_arn           = aws_iam_role.firehose.arn\n    bucket_arn         = aws_s3_bucket.bucket.arn\n    buffer_size        = 10\n    buffer_interval    = 400\n    compression_format = \"GZIP\"\n  }\n\n  splunk_configuration {\n    hec_endpoint               = \"https://http-inputs-mydomain.splunkcloud.com:443\"\n    hec_token                  = \"51D4DA16-C61B-4F5F-8EC7-ED4301342A4A\"\n    hec_acknowledgment_timeout = 600\n    hec_endpoint_type          = \"Event\"\n    s3_backup_mode             = \"FailedEventsOnly\"\n  }\n}\n```\n\n### HTTP Endpoint (e.g., New Relic) Destination\n\n```terraform\nresource \"aws_kinesis_firehose_delivery_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-firehose-test-stream\"\n  destination = \"http_endpoint\"\n\n  s3_configuration {\n    role_arn           = aws_iam_role.firehose.arn\n    bucket_arn         = aws_s3_bucket.bucket.arn\n    buffer_size        = 10\n    buffer_interval    = 400\n    compression_format = \"GZIP\"\n  }\n\n  http_endpoint_configuration {\n    url                = \"https://aws-api.newrelic.com/firehose/v1\"\n    name               = \"New Relic\"\n    access_key         = \"my-key\"\n    buffering_size     = 15\n    buffering_interval = 600\n    role_arn           = aws_iam_role.firehose.arn\n    s3_backup_mode     = \"FailedDataOnly\"\n\n    request_configuration {\n      content_encoding = \"GZIP\"\n\n      common_attributes {\n        name  = \"testname\"\n        value = \"testvalue\"\n      }\n\n      common_attributes {\n        name  = \"testname2\"\n        value = \"testvalue2\"\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A name to identify the stream. This is unique to the\nAWS account and region the Stream is created in.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `kinesis_source_configuration` - (Optional) Allows the ability to specify the kinesis stream that is used as the source of the firehose delivery stream.\n* `server_side_encryption` - (Optional) Encrypt at rest options.\nServer-side encryption should not be enabled when a kinesis stream is configured as the source of the firehose delivery stream.\n* `destination` – (Required) This is the destination to where the data is delivered. The only options are `s3` (Deprecated, use `extended_s3` instead), `extended_s3`, `redshift`, `elasticsearch`, `splunk`, and `http_endpoint`.\n* `s3_configuration` - (Optional) Required for non-S3 destinations. For S3 destination, use `extended_s3_configuration` instead. Configuration options for the s3 destination (or the intermediate bucket if the destination\nis redshift). More details are given below.\n* `extended_s3_configuration` - (Optional, only Required when `destination` is `extended_s3`) Enhanced configuration options for the s3 destination. More details are given below.\n* `redshift_configuration` - (Optional) Configuration options if redshift is the destination.\nUsing `redshift_configuration` requires the user to also specify a\n`s3_configuration` block. More details are given below.\n* `elasticsearch_configuration` - (Optional) Configuration options if elasticsearch is the destination. More details are given below.\n* `splunk_configuration` - (Optional) Configuration options if splunk is the destination. More details are given below.\n* `http_endpoint_configuration` - (Optional) Configuration options if http_endpoint is the destination. requires the user to also specify a `s3_configuration` block.  More details are given below.\n\nThe `kinesis_source_configuration` object supports the following:\n\n* `kinesis_stream_arn` (Required) The kinesis stream used as the source of the firehose delivery stream.\n* `role_arn` (Required) The ARN of the role that provides access to the source Kinesis stream.\n\nThe `server_side_encryption` object supports the following:\n\n* `enabled` - (Optional) Whether to enable encryption at rest. Default is `false`.\n* `key_type`- (Optional) Type of encryption key. Default is `AWS_OWNED_CMK`. Valid values are `AWS_OWNED_CMK` and `CUSTOMER_MANAGED_CMK`\n* `key_arn` - (Optional) Amazon Resource Name (ARN) of the encryption key. Required when `key_type` is `CUSTOMER_MANAGED_CMK`.\n\nThe (DEPRECATED) `s3_configuration`  object supports the following:\n\n* `role_arn` - (Required) The ARN of the AWS credentials.\n* `bucket_arn` - (Required) The ARN of the S3 bucket\n* `prefix` - (Optional) The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket\n* `buffer_size` - (Optional) Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5.\n                                We recommend setting SizeInMBs to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec set SizeInMBs to be 10 MB or higher.\n* `buffer_interval` - (Optional) Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300.\n* `compression_format` - (Optional) The compression format. If no value is specified, the default is `UNCOMPRESSED`. Other supported values are `GZIP`, `ZIP`, `Snappy`, & `HADOOP_SNAPPY`.\n* `kms_key_arn` - (Optional) Specifies the KMS key ARN the stream will use to encrypt data. If not set, no encryption will\nbe used.\n* `cloudwatch_logging_options` - (Optional) The CloudWatch Logging Options for the delivery stream. More details are given below\n\nThe `extended_s3_configuration` object supports the same fields from `s3_configuration` as well as the following:\n\n* `data_format_conversion_configuration` - (Optional) Nested argument for the serializer, deserializer, and schema for converting data from the JSON format to the Parquet or ORC format before writing it to Amazon S3. More details given below.\n* `error_output_prefix` - (Optional) Prefix added to failed records before writing them to S3. This prefix appears immediately following the bucket name.\n* `processing_configuration` - (Optional) The data processing configuration.  More details are given below.\n* `s3_backup_mode` - (Optional) The Amazon S3 backup mode.  Valid values are `Disabled` and `Enabled`.  Default value is `Disabled`.\n* `s3_backup_configuration` - (Optional) The configuration for backup in Amazon S3. Required if `s3_backup_mode` is `Enabled`. Supports the same fields as `s3_configuration` object.\n\nThe `redshift_configuration` object supports the following:\n\n* `cluster_jdbcurl` - (Required) The jdbcurl of the redshift cluster.\n* `username` - (Required) The username that the firehose delivery stream will assume. It is strongly recommended that the username and password provided is used exclusively for Amazon Kinesis Firehose purposes, and that the permissions for the account are restricted for Amazon Redshift INSERT permissions.\n* `password` - (Required) The password for the username above.\n* `retry_duration` - (Optional) The length of time during which Firehose retries delivery after a failure, starting from the initial request and including the first attempt. The default value is 3600 seconds (60 minutes). Firehose does not retry if the value of DurationInSeconds is 0 (zero) or if the first delivery attempt takes longer than the current value.\n* `role_arn` - (Required) The arn of the role the stream assumes.\n* `s3_backup_mode` - (Optional) The Amazon S3 backup mode.  Valid values are `Disabled` and `Enabled`.  Default value is `Disabled`.\n* `s3_backup_configuration` - (Optional) The configuration for backup in Amazon S3. Required if `s3_backup_mode` is `Enabled`. Supports the same fields as `s3_configuration` object.\n* `data_table_name` - (Required) The name of the table in the redshift cluster that the s3 bucket will copy to.\n* `copy_options` - (Optional) Copy options for copying the data from the s3 intermediate bucket into redshift, for example to change the default delimiter. For valid values, see the [AWS documentation](http://docs.aws.amazon.com/firehose/latest/APIReference/API_CopyCommand.html)\n* `data_table_columns` - (Optional) The data table columns that will be targeted by the copy command.\n* `cloudwatch_logging_options` - (Optional) The CloudWatch Logging Options for the delivery stream. More details are given below\n* `processing_configuration` - (Optional) The data processing configuration.  More details are given below.\n\nThe `elasticsearch_configuration` object supports the following:\n\n* `buffering_interval` - (Optional) Buffer incoming data for the specified period of time, in seconds between 60 to 900, before delivering it to the destination.  The default value is 300s.\n* `buffering_size` - (Optional) Buffer incoming data to the specified size, in MBs between 1 to 100, before delivering it to the destination.  The default value is 5MB.\n* `domain_arn` - (Optional) The ARN of the Amazon ES domain.  The IAM role must have permission for `DescribeElasticsearchDomain`, `DescribeElasticsearchDomains`, and `DescribeElasticsearchDomainConfig` after assuming `RoleARN`.  The pattern needs to be `arn:.*`. Conflicts with `cluster_endpoint`.\n* `cluster_endpoint` - (Optional) The endpoint to use when communicating with the cluster. Conflicts with `domain_arn`.\n* `index_name` - (Required) The Elasticsearch index name.\n* `index_rotation_period` - (Optional) The Elasticsearch index rotation period.  Index rotation appends a timestamp to the IndexName to facilitate expiration of old data.  Valid values are `NoRotation`, `OneHour`, `OneDay`, `OneWeek`, and `OneMonth`.  The default value is `OneDay`.\n* `retry_duration` - (Optional) After an initial failure to deliver to Amazon Elasticsearch, the total amount of time, in seconds between 0 to 7200, during which Firehose re-attempts delivery (including the first attempt).  After this time has elapsed, the failed documents are written to Amazon S3.  The default value is 300s.  There will be no retry if the value is 0.\n* `role_arn` - (Required) The ARN of the IAM role to be assumed by Firehose for calling the Amazon ES Configuration API and for indexing documents.  The pattern needs to be `arn:.*`.\n* `s3_backup_mode` - (Optional) Defines how documents should be delivered to Amazon S3.  Valid values are `FailedDocumentsOnly` and `AllDocuments`.  Default value is `FailedDocumentsOnly`.\n* `type_name` - (Optional) The Elasticsearch type name with maximum length of 100 characters.\n* `cloudwatch_logging_options` - (Optional) The CloudWatch Logging Options for the delivery stream. More details are given below\n* `vpc_config` - (Optional) The VPC configuration for the delivery stream to connect to Elastic Search associated with the VPC. More details are given below\n* `processing_configuration` - (Optional) The data processing configuration.  More details are given below.\n\nThe `splunk_configuration` objects supports the following:\n\n* `hec_acknowledgment_timeout` - (Optional) The amount of time, in seconds between 180 and 600, that Kinesis Firehose waits to receive an acknowledgment from Splunk after it sends it data.\n* `hec_endpoint` - (Required) The HTTP Event Collector (HEC) endpoint to which Kinesis Firehose sends your data.\n* `hec_endpoint_type` - (Optional) The HEC endpoint type. Valid values are `Raw` or `Event`. The default value is `Raw`.\n* `hec_token` - (Required) The GUID that you obtain from your Splunk cluster when you create a new HEC endpoint.\n* `s3_backup_mode` - (Optional) Defines how documents should be delivered to Amazon S3.  Valid values are `FailedEventsOnly` and `AllEvents`.  Default value is `FailedEventsOnly`.\n* `retry_duration` - (Optional) After an initial failure to deliver to Splunk, the total amount of time, in seconds between 0 to 7200, during which Firehose re-attempts delivery (including the first attempt).  After this time has elapsed, the failed documents are written to Amazon S3.  The default value is 300s.  There will be no retry if the value is 0.\n* `cloudwatch_logging_options` - (Optional) The CloudWatch Logging Options for the delivery stream. More details are given below.\n* `processing_configuration` - (Optional) The data processing configuration.  More details are given below.\n\nThe `http_endpoint_configuration` objects supports the following:\n\n* `url` - (Required) The HTTP endpoint URL to which Kinesis Firehose sends your data.\n* `name` - (Optional) The HTTP endpoint name.\n* `access_key` - (Optional) The access key required for Kinesis Firehose to authenticate with the HTTP endpoint selected as the destination.\n* `role_arn` - (Required) Kinesis Data Firehose uses this IAM role for all the permissions that the delivery stream needs. The pattern needs to be `arn:.*`.\n* `s3_backup_mode` - (Optional) Defines how documents should be delivered to Amazon S3.  Valid values are `FailedDataOnly` and `AllData`.  Default value is `FailedDataOnly`.\n* `buffering_size` - (Optional) Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5.\n* `buffering_interval` - (Optional) Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300 (5 minutes).\n* `cloudwatch_logging_options` - (Optional) The CloudWatch Logging Options for the delivery stream. More details are given below.\n* `processing_configuration` - (Optional) The data processing configuration.  More details are given below.\n* `request_configuration` - (Optional) The request configuration.  More details are given below.\n* `retry_duration` - (Optional) Total amount of seconds Firehose spends on retries. This duration starts after the initial attempt fails, It does not include the time periods during which Firehose waits for acknowledgment from the specified destination after each attempt. Valid values between `0` and `7200`. Default is `300`.\n\nThe `cloudwatch_logging_options` object supports the following:\n\n* `enabled` - (Optional) Enables or disables the logging. Defaults to `false`.\n* `log_group_name` - (Optional) The CloudWatch group name for logging. This value is required if `enabled` is true.\n* `log_stream_name` - (Optional) The CloudWatch log stream name for logging. This value is required if `enabled` is true.\n\nThe `processing_configuration` object supports the following:\n\n* `enabled` - (Optional) Enables or disables data processing.\n* `processors` - (Optional) Array of data processors. More details are given below\n\nThe `processors` array objects support the following:\n\n* `type` - (Required) The type of processor. Valid Values: `Lambda`\n* `parameters` - (Optional) Array of processor parameters. More details are given below\n\nThe `parameters` array objects support the following:\n\n* `parameter_name` - (Required) Parameter name. Valid Values: `LambdaArn`, `NumberOfRetries`, `RoleArn`, `BufferSizeInMBs`, `BufferIntervalInSeconds`\n* `parameter_value` - (Required) Parameter value. Must be between 1 and 512 length (inclusive). When providing a Lambda ARN, you should specify the resource version as well.\n\n~> **NOTE:** Parameters with default values, including `NumberOfRetries`(default: 3), `RoleArn`(default: firehose role ARN), `BufferSizeInMBs`(default: 3), and `BufferIntervalInSeconds`(default: 60), are not stored in terraform state. To prevent perpetual differences, it is therefore recommended to only include parameters with non-default values.\n\nThe `request_configuration` object supports the following:\n\n* `content_encoding` - (Optional) Kinesis Data Firehose uses the content encoding to compress the body of a request before sending the request to the destination. Valid values are `NONE` and `GZIP`.  Default value is `NONE`.\n* `common_attributes` - (Optional) Describes the metadata sent to the HTTP endpoint destination. More details are given below\n\nThe `common_attributes` array objects support the following:\n\n* `name` - (Required) The name of the HTTP endpoint common attribute.\n* `value` - (Optional) The value of the HTTP endpoint common attribute.\n\nThe `vpc_config` object supports the following:\n\n* `subnet_ids` - (Required) A list of subnet IDs to associate with Kinesis Firehose.\n* `security_group_ids` - (Required) A list of security group IDs to associate with Kinesis Firehose.\n* `role_arn` - (Required) The ARN of the IAM role to be assumed by Firehose for calling the Amazon EC2 configuration API and for creating network interfaces. Make sure role has necessary [IAM permissions](https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-es-vpc)\n\n### data_format_conversion_configuration\n\n~> **NOTE:** Once configured, the data format conversion configuration can only be disabled, in which the configuration values will remain, but will not be active. It is not currently possible to completely remove the configuration without recreating the resource.\n\nExample:\n\n```terraform\nresource \"aws_kinesis_firehose_delivery_stream\" \"example\" {\n  # ... other configuration ...\n  extended_s3_configuration {\n    # Must be at least 64\n    buffer_size = 128\n\n    # ... other configuration ...\n    data_format_conversion_configuration {\n      input_format_configuration {\n        deserializer {\n          hive_json_ser_de {}\n        }\n      }\n\n      output_format_configuration {\n        serializer {\n          orc_ser_de {}\n        }\n      }\n\n      schema_configuration {\n        database_name = aws_glue_catalog_table.example.database_name\n        role_arn      = aws_iam_role.example.arn\n        table_name    = aws_glue_catalog_table.example.name\n      }\n    }\n  }\n}\n```\n\n* `input_format_configuration` - (Required) Nested argument that specifies the deserializer that you want Kinesis Data Firehose to use to convert the format of your data from JSON. More details below.\n* `output_format_configuration` - (Required) Nested argument that specifies the serializer that you want Kinesis Data Firehose to use to convert the format of your data to the Parquet or ORC format. More details below.\n* `schema_configuration` - (Required) Nested argument that specifies the AWS Glue Data Catalog table that contains the column information. More details below.\n* `enabled` - (Optional) Defaults to `true`. Set it to `false` if you want to disable format conversion while preserving the configuration details.\n\n#### input_format_configuration\n\n* `deserializer` - (Required) Nested argument that specifies which deserializer to use. You can choose either the Apache Hive JSON SerDe or the OpenX JSON SerDe. More details below.\n\n##### deserializer\n\n~> **NOTE:** One of the deserializers must be configured. If no nested configuration needs to occur simply declare as `XXX_json_ser_de = []` or `XXX_json_ser_de {}`.\n\n* `hive_json_ser_de` - (Optional) Nested argument that specifies the native Hive / HCatalog JsonSerDe. More details below.\n* `open_x_json_ser_de` - (Optional) Nested argument that specifies the OpenX SerDe. More details below.\n\n###### hive_json_ser_de\n\n* `timestamp_formats` - (Optional) A list of how you want Kinesis Data Firehose to parse the date and time stamps that may be present in your input data JSON. To specify these format strings, follow the pattern syntax of JodaTime's DateTimeFormat format strings. For more information, see [Class DateTimeFormat](https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html). You can also use the special value millis to parse time stamps in epoch milliseconds. If you don't specify a format, Kinesis Data Firehose uses java.sql.Timestamp::valueOf by default.\n\n###### open_x_json_ser_de\n\n* `case_insensitive` - (Optional) When set to true, which is the default, Kinesis Data Firehose converts JSON keys to lowercase before deserializing them.\n* `column_to_json_key_mappings` - (Optional) A map of column names to JSON keys that aren't identical to the column names. This is useful when the JSON contains keys that are Hive keywords. For example, timestamp is a Hive keyword. If you have a JSON key named timestamp, set this parameter to `{ ts = \"timestamp\" }` to map this key to a column named ts.\n* `convert_dots_in_json_keys_to_underscores` - (Optional) When set to `true`, specifies that the names of the keys include dots and that you want Kinesis Data Firehose to replace them with underscores. This is useful because Apache Hive does not allow dots in column names. For example, if the JSON contains a key whose name is \"a.b\", you can define the column name to be \"a_b\" when using this option. Defaults to `false`.\n\n#### output_format_configuration\n\n* `serializer` - (Required) Nested argument that specifies which serializer to use. You can choose either the ORC SerDe or the Parquet SerDe. More details below.\n\n##### serializer\n\n~> **NOTE:** One of the serializers must be configured. If no nested configuration needs to occur simply declare as `XXX_ser_de = []` or `XXX_ser_de {}`.\n\n* `orc_ser_de` - (Optional) Nested argument that specifies converting data to the ORC format before storing it in Amazon S3. For more information, see [Apache ORC](https://orc.apache.org/docs/). More details below.\n* `parquet_ser_de` - (Optional) Nested argument that specifies converting data to the Parquet format before storing it in Amazon S3. For more information, see [Apache Parquet](https://parquet.apache.org/documentation/latest/). More details below.\n\n###### orc_ser_de\n\n* `block_size_bytes` - (Optional) The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.\n* `bloom_filter_columns` - (Optional) A list of column names for which you want Kinesis Data Firehose to create bloom filters.\n* `bloom_filter_false_positive_probability` - (Optional) The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the Bloom filter. The default value is `0.05`, the minimum is `0`, and the maximum is `1`.\n* `compression` - (Optional) The compression code to use over data blocks. The default is `SNAPPY`.\n* `dictionary_key_threshold` - (Optional) A float that represents the fraction of the total number of non-null rows. To turn off dictionary encoding, set this fraction to a number that is less than the number of distinct keys in a dictionary. To always use dictionary encoding, set this threshold to `1`.\n* `enable_padding` - (Optional) Set this to `true` to indicate that you want stripes to be padded to the HDFS block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `false`.\n* `format_version` - (Optional) The version of the file to write. The possible values are `V0_11` and `V0_12`. The default is `V0_12`.\n* `padding_tolerance` - (Optional) A float between 0 and 1 that defines the tolerance for block padding as a decimal fraction of stripe size. The default value is `0.05`, which means 5 percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB block. In such a case, if the available size within the block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that space. This ensures that no stripe crosses block boundaries and causes remote reads within a node-local task. Kinesis Data Firehose ignores this parameter when `enable_padding` is `false`.\n* `row_index_stride` - (Optional) The number of rows between index entries. The default is `10000` and the minimum is `1000`.\n* `stripe_size_bytes` - (Optional) The number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.\n\n###### parquet_ser_de\n\n* `block_size_bytes` - (Optional) The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.\n* `compression` - (Optional) The compression code to use over data blocks. The possible values are `UNCOMPRESSED`, `SNAPPY`, and `GZIP`, with the default being `SNAPPY`. Use `SNAPPY` for higher decompression speed. Use `GZIP` if the compression ratio is more important than speed.\n* `enable_dictionary_compression` - (Optional) Indicates whether to enable dictionary compression.\n* `max_padding_bytes` - (Optional) The maximum amount of padding to apply. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `0`.\n* `page_size_bytes` - (Optional) The Parquet page size. Column chunks are divided into pages. A page is conceptually an indivisible unit (in terms of compression and encoding). The minimum value is 64 KiB and the default is 1 MiB.\n* `writer_version` - (Optional) Indicates the version of row format to output. The possible values are `V1` and `V2`. The default is `V1`.\n\n#### schema_configuration\n\n* `database_name` - (Required) Specifies the name of the AWS Glue database that contains the schema for the output data.\n* `role_arn` - (Required) The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.\n* `table_name` - (Required) Specifies the AWS Glue table that contains the column information that constitutes your data schema.\n* `catalog_id` - (Optional) The ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account ID is used by default.\n* `region` - (Optional) If you don't specify an AWS Region, the default is the current region.\n* `version_id` - (Optional) Specifies the table version for the output data schema. Defaults to `LATEST`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) specifying the Stream\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[1]: https://aws.amazon.com/documentation/firehose/\n\n## Import\n\nKinesis Firehose Delivery streams can be imported using the stream ARN, e.g.,\n\n```\n$ terraform import aws_kinesis_firehose_delivery_stream.foo arn:aws:firehose:us-east-1:XXX:deliverystream/example\n```\n\nNote: Import does not work for stream destination `s3`. Consider using `extended_s3` since `s3` destination is deprecated.\n",
    "basename": "kinesis_firehose_delivery_stream.html"
  },
  "kinesis_stream.html": {
    "subcategory": "Kinesis",
    "layout": "aws",
    "page_title": "AWS: aws_kinesis_stream",
    "description": "Provides a AWS Kinesis Stream",
    "preview": "# Resource: aws_kinesis_stream\n\nProvides a Kinesis Stream resource. …",
    "content": "\n\n# Resource: aws_kinesis_stream\n\nProvides a Kinesis Stream resource. Amazon Kinesis is a managed service that\nscales elastically for real-time processing of streaming big data.\n\nFor more details, see the [Amazon Kinesis Documentation][1].\n\n## Example Usage\n\n```terraform\nresource \"aws_kinesis_stream\" \"test_stream\" {\n  name             = \"terraform-kinesis-test\"\n  shard_count      = 1\n  retention_period = 48\n\n  shard_level_metrics = [\n    \"IncomingBytes\",\n    \"OutgoingBytes\",\n  ]\n\n  stream_mode_details {\n    stream_mode = \"PROVISIONED\"\n  }\n\n  tags = {\n    Environment = \"test\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A name to identify the stream. This is unique to the AWS account and region the Stream is created in.\n* `shard_count` – (Optional) The number of shards that the stream will use. If the `stream_mode` is `PROVISIONED`, this field is required.\nAmazon has guidelines for specifying the Stream size that should be referenced when creating a Kinesis stream. See [Amazon Kinesis Streams][2] for more.\n* `retention_period` - (Optional) Length of time data records are accessible after they are added to the stream. The maximum value of a stream's retention period is 8760 hours. Minimum value is 24. Default is 24.\n* `shard_level_metrics` - (Optional) A list of shard-level CloudWatch metrics which can be enabled for the stream. See [Monitoring with CloudWatch][3] for more. Note that the value ALL should not be used; instead you should provide an explicit list of metrics you wish to enable.\n* `enforce_consumer_deletion` - (Optional) A boolean that indicates all registered consumers should be deregistered from the stream so that the stream can be destroyed without error. The default value is `false`.\n* `encryption_type` - (Optional) The encryption type to use. The only acceptable values are `NONE` or `KMS`. The default value is `NONE`.\n* `kms_key_id` - (Optional) The GUID for the customer-managed KMS key to use for encryption. You can also use a Kinesis-owned master key by specifying the alias `alias/aws/kinesis`.\n* `stream_mode_details` - (Optional) Indicates the [capacity mode](https://docs.aws.amazon.com/streams/latest/dev/how-do-i-size-a-stream.html) of the data stream. Detailed below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### stream_mode_details Configuration Block\n\n* `stream_mode` - (Required) Specifies the capacity mode of the stream. Must be either `PROVISIONED` or `ON_DEMAND`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique Stream id\n* `name` - The unique Stream name\n* `shard_count` - The count of Shards for this Stream\n* `arn` - The Amazon Resource Name (ARN) specifying the Stream (same as `id`)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_kinesis_stream` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `5 minutes`)  Used for Creating a Kinesis Stream\n- `update` - (Default `120 minutes`) Used for Updating a Kinesis Stream\n- `delete` - (Default `120 minutes`) Used for Destroying a Kinesis Stream\n\n## Import\n\nKinesis Streams can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_kinesis_stream.test_stream terraform-kinesis-test\n```\n\n[1]: https://aws.amazon.com/documentation/kinesis/\n[2]: https://docs.aws.amazon.com/kinesis/latest/dev/amazon-kinesis-streams.html\n[3]: https://docs.aws.amazon.com/streams/latest/dev/monitoring-with-cloudwatch.html\n",
    "basename": "kinesis_stream.html"
  },
  "kinesis_stream_consumer.html": {
    "subcategory": "Kinesis",
    "layout": "aws",
    "page_title": "AWS: aws_kinesis_stream_consumer",
    "description": "Manages a Kinesis Stream Consumer.",
    "preview": "# Resource: aws_kinesis_stream_consumer\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_kinesis_stream_consumer\n\nProvides a resource to manage a Kinesis Stream Consumer.\n\n-> **Note:** You can register up to 20 consumers per stream. A given consumer can only be registered with one stream at a time.\n\nFor more details, see the [Amazon Kinesis Stream Consumer Documentation][1].\n\n## Example Usage\n\n```terraform\nresource \"aws_kinesis_stream\" \"example\" {\n  name        = \"example-stream\"\n  shard_count = 1\n}\n\nresource \"aws_kinesis_stream_consumer\" \"example\" {\n  name       = \"example-consumer\"\n  stream_arn = aws_kinesis_stream.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required, Forces new resource) Name of the stream consumer.\n* `stream_arn` – (Required, Forces new resource) Amazon Resource Name (ARN) of the data stream the consumer is registered with.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the stream consumer.\n* `creation_timestamp` - Approximate timestamp in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) of when the stream consumer was created.\n* `id` - Amazon Resource Name (ARN) of the stream consumer.\n\n## Import\n\nKinesis Stream Consumers can be imported using the Amazon Resource Name (ARN) e.g.,\n\n```\n$ terraform import aws_kinesis_stream_consumer.example arn:aws:kinesis:us-west-2:123456789012:stream/example/consumer/example:1616044553\n```\n\n[1]: https://docs.aws.amazon.com/streams/latest/dev/amazon-kinesis-consumers.html",
    "basename": "kinesis_stream_consumer.html"
  },
  "kinesis_video_stream.html": {
    "subcategory": "Kinesis Video",
    "layout": "aws",
    "page_title": "AWS: aws_kinesis_video_stream",
    "description": "Provides a AWS Kinesis Video Stream",
    "preview": "# Resource: aws_kinesis_video_stream\n\nProvides a Kinesis Video …",
    "content": "\n\n# Resource: aws_kinesis_video_stream\n\nProvides a Kinesis Video Stream resource. Amazon Kinesis Video Streams makes it easy to securely stream video from connected devices to AWS for analytics, machine learning (ML), playback, and other processing.\n\nFor more details, see the [Amazon Kinesis Documentation][1].\n\n## Example Usage\n\n```terraform\nresource \"aws_kinesis_video_stream\" \"default\" {\n  name                    = \"terraform-kinesis-video-stream\"\n  data_retention_in_hours = 1\n  device_name             = \"kinesis-video-device-name\"\n  media_type              = \"video/h264\"\n\n  tags = {\n    Name = \"terraform-kinesis-video-stream\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A name to identify the stream. This is unique to the\nAWS account and region the Stream is created in.\n* `data_retention_in_hours` – (Optional) The number of hours that you want to retain the data in the stream. Kinesis Video Streams retains the data in a data store that is associated with the stream. The default value is `0`, indicating that the stream does not persist data.\n* `device_name` - (Optional) The name of the device that is writing to the stream. **In the current implementation, Kinesis Video Streams does not use this name.**\n* `kms_key_id` - (Optional) The ID of the AWS Key Management Service (AWS KMS) key that you want Kinesis Video Streams to use to encrypt stream data. If no key ID is specified, the default, Kinesis Video-managed key (`aws/kinesisvideo`) is used.\n* `media_type` - (Optional) The media type of the stream. Consumers of the stream can use this information when processing the stream. For more information about media types, see [Media Types][2]. If you choose to specify the MediaType, see [Naming Requirements][3] for guidelines.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique Stream id\n* `arn` - The Amazon Resource Name (ARN) specifying the Stream (same as `id`)\n* `creation_time` - A time stamp that indicates when the stream was created.\n* `version` - The version of the stream.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_kinesis_video_stream` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `5 minutes`)  Used for Creating a Kinesis Stream\n- `update` - (Default `120 minutes`) Used for Updating a Kinesis Stream\n- `delete` - (Default `120 minutes`) Used for Destroying a Kinesis Stream\n\n## Import\n\nKinesis Streams can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_kinesis_video_stream.test_stream arn:aws:kinesisvideo:us-west-2:123456789012:stream/terraform-kinesis-test/1554978910975\n```\n\n[1]: https://aws.amazon.com/documentation/kinesis/\n[2]: http://www.iana.org/assignments/media-types/media-types.xhtml\n[3]: https://tools.ietf.org/html/rfc6838#section-4.2\n",
    "basename": "kinesis_video_stream.html"
  },
  "kinesisanalyticsv2_application.html": {
    "subcategory": "Kinesis Data Analytics v2 (SQL and Flink Applications)",
    "layout": "aws",
    "page_title": "AWS: aws_kinesisanalyticsv2_application",
    "description": "Manages a Kinesis Analytics v2 Application.",
    "preview": "# Resource: aws_kinesisanalyticsv2_application\n\nManages a Kinesis …",
    "content": "\n\n# Resource: aws_kinesisanalyticsv2_application\n\nManages a Kinesis Analytics v2 Application.\nThis resource can be used to manage both Kinesis Data Analytics for SQL applications and Kinesis Data Analytics for Apache Flink applications.\n\n-> **Note:** Kinesis Data Analytics for SQL applications created using this resource cannot currently be viewed in the AWS Console. To manage Kinesis Data Analytics for SQL applications that can also be viewed in the AWS Console, use the [`aws_kinesis_analytics_application`](/docs/providers/aws/r/kinesis_analytics_application.html) resource.\n\n## Example Usage\n\n### Apache Flink Application\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example-flink-application\"\n}\n\nresource \"aws_s3_bucket_object\" \"example\" {\n  bucket = aws_s3_bucket.example.bucket\n  key    = \"example-flink-application\"\n  source = \"flink-app.jar\"\n}\n\nresource \"aws_kinesisanalyticsv2_application\" \"example\" {\n  name                   = \"example-flink-application\"\n  runtime_environment    = \"FLINK-1_8\"\n  service_execution_role = aws_iam_role.example.arn\n\n  application_configuration {\n    application_code_configuration {\n      code_content {\n        s3_content_location {\n          bucket_arn = aws_s3_bucket.example.arn\n          file_key   = aws_s3_bucket_object.example.key\n        }\n      }\n\n      code_content_type = \"ZIPFILE\"\n    }\n\n    environment_properties {\n      property_group {\n        property_group_id = \"PROPERTY-GROUP-1\"\n\n        property_map = {\n          Key1 = \"Value1\"\n        }\n      }\n\n      property_group {\n        property_group_id = \"PROPERTY-GROUP-2\"\n\n        property_map = {\n          KeyA = \"ValueA\"\n          KeyB = \"ValueB\"\n        }\n      }\n    }\n\n    flink_application_configuration {\n      checkpoint_configuration {\n        configuration_type = \"DEFAULT\"\n      }\n\n      monitoring_configuration {\n        configuration_type = \"CUSTOM\"\n        log_level          = \"DEBUG\"\n        metrics_level      = \"TASK\"\n      }\n\n      parallelism_configuration {\n        auto_scaling_enabled = true\n        configuration_type   = \"CUSTOM\"\n        parallelism          = 10\n        parallelism_per_kpu  = 4\n      }\n    }\n  }\n\n  tags = {\n    Environment = \"test\"\n  }\n}\n```\n\n### SQL Application\n\n```terraform\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name = \"example-sql-application\"\n}\n\nresource \"aws_cloudwatch_log_stream\" \"example\" {\n  name           = \"example-sql-application\"\n  log_group_name = aws_cloudwatch_log_group.example.name\n}\n\nresource \"aws_kinesisanalyticsv2_application\" \"example\" {\n  name                   = \"example-sql-application\"\n  runtime_environment    = \"SQL-1.0\"\n  service_execution_role = aws_iam_role.example.arn\n\n  application_configuration {\n    application_code_configuration {\n      code_content {\n        text_content = \"SELECT 1;\\n\"\n      }\n\n      code_content_type = \"PLAINTEXT\"\n    }\n\n    sql_application_configuration {\n      input {\n        name_prefix = \"PREFIX_1\"\n\n        input_parallelism {\n          count = 3\n        }\n\n        input_schema {\n          record_column {\n            name     = \"COLUMN_1\"\n            sql_type = \"VARCHAR(8)\"\n            mapping  = \"MAPPING-1\"\n          }\n\n          record_column {\n            name     = \"COLUMN_2\"\n            sql_type = \"DOUBLE\"\n          }\n\n          record_encoding = \"UTF-8\"\n\n          record_format {\n            record_format_type = \"CSV\"\n\n            mapping_parameters {\n              csv_mapping_parameters {\n                record_column_delimiter = \",\"\n                record_row_delimiter    = \"\\n\"\n              }\n            }\n          }\n        }\n\n        kinesis_streams_input {\n          resource_arn = aws_kinesis_stream.example.arn\n        }\n      }\n\n      output {\n        name = \"OUTPUT_1\"\n\n        destination_schema {\n          record_format_type = \"JSON\"\n        }\n\n        lambda_output {\n          resource_arn = aws_lambda_function.example.arn\n        }\n      }\n\n      output {\n        name = \"OUTPUT_2\"\n\n        destination_schema {\n          record_format_type = \"CSV\"\n        }\n\n        kinesis_firehose_output {\n          resource_arn = aws_kinesis_firehose_delivery_stream.example.arn\n        }\n      }\n\n      reference_data_source {\n        table_name = \"TABLE-1\"\n\n        reference_schema {\n          record_column {\n            name     = \"COLUMN_1\"\n            sql_type = \"INTEGER\"\n          }\n\n          record_format {\n            record_format_type = \"JSON\"\n\n            mapping_parameters {\n              json_mapping_parameters {\n                record_row_path = \"$\"\n              }\n            }\n          }\n        }\n\n        s3_reference_data_source {\n          bucket_arn = aws_s3_bucket.example.arn\n          file_key   = \"KEY-1\"\n        }\n      }\n    }\n  }\n\n  cloudwatch_logging_options {\n    log_stream_arn = aws_cloudwatch_log_stream.example.arn\n  }\n}\n```\n\n### VPC Configuration\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example-flink-application\"\n}\n\nresource \"aws_s3_bucket_object\" \"example\" {\n  bucket = aws_s3_bucket.example.bucket\n  key    = \"example-flink-application\"\n  source = \"flink-app.jar\"\n}\n\nresource \"aws_kinesisanalyticsv2_application\" \"example\" {\n  name                   = \"example-flink-application\"\n  runtime_environment    = \"FLINK-1_8\"\n  service_execution_role = aws_iam_role.example.arn\n\n  application_configuration {\n    application_code_configuration {\n      code_content {\n        s3_content_location {\n          bucket_arn = aws_s3_bucket.example.arn\n          file_key   = aws_s3_bucket_object.example.key\n        }\n      }\n\n      code_content_type = \"ZIPFILE\"\n    }\n\n    vpc_configuration {\n      security_group_ids = [aws_security_group.example[0].id, aws_security_group.example[1].id]\n      subnet_ids         = [aws_subnet.example.id]\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the application.\n* `runtime_environment` - (Required) The runtime environment for the application. Valid values: `SQL-1_0`, `FLINK-1_6`, `FLINK-1_8`, `FLINK-1_11`, `FLINK-1_13`.\n* `service_execution_role` - (Required) The ARN of the [IAM role](/docs/providers/aws/r/iam_role.html) used by the application to access Kinesis data streams, Kinesis Data Firehose delivery streams, Amazon S3 objects, and other external resources.\n* `application_configuration` - (Optional) The application's configuration\n* `cloudwatch_logging_options` - (Optional) A [CloudWatch log stream](/docs/providers/aws/r/cloudwatch_log_stream.html) to monitor application configuration errors.\n* `description` - (Optional) A summary description of the application.\n* `force_stop` - (Optional) Whether to force stop an unresponsive Flink-based application.\n* `start_application` - (Optional) Whether to start or stop the application.\n* `tags` - (Optional) A map of tags to assign to the application. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `application_configuration` object supports the following:\n\n* `application_code_configuration` - (Required) The code location and type parameters for the application.\n* `application_snapshot_configuration` - (Optional) Describes whether snapshots are enabled for a Flink-based application.\n* `environment_properties` - (Optional) Describes execution properties for a Flink-based application.\n* `flink_application_configuration` - (Optional) The configuration of a Flink-based application.\n* `run_configuration` - (Optional) Describes the starting properties for a Flink-based application.\n* `sql_application_configuration` - (Optional) The configuration of a SQL-based application.\n* `vpc_configuration` - (Optional) The VPC configuration of a Flink-based application.\n\nThe `application_code_configuration` object supports the following:\n\n* `code_content_type` - (Required) Specifies whether the code content is in text or zip format. Valid values: `PLAINTEXT`, `ZIPFILE`.\n* `code_content` - (Optional) The location and type of the application code.\n\nThe `code_content` object supports the following:\n\n* `s3_content_location` - (Optional) Information about the Amazon S3 bucket containing the application code.\n* `text_content` - (Optional) The text-format code for the application.\n\nThe `s3_content_location` object supports the following:\n\n* `bucket_arn` - (Required) The ARN for the S3 bucket containing the application code.\n* `file_key` - (Required) The file key for the object containing the application code.\n* `object_version` - (Optional) The version of the object containing the application code.\n\nThe `application_snapshot_configuration` object supports the following:\n\n* `snapshots_enabled` - (Required) Describes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nThe `environment_properties` object supports the following:\n\n* `property_group` - (Required) Describes the execution property groups.\n\nThe `property_group` object supports the following:\n\n* `property_group_id` - (Required) The key of the application execution property key-value map.\n* `property_map` - (Required) Application execution property key-value map.\n\nThe `flink_application_configuration` object supports the following:\n\n* `checkpoint_configuration` - (Optional) Describes an application's checkpointing configuration.\n* `monitoring_configuration` - (Optional) Describes configuration parameters for CloudWatch logging for an application.\n* `parallelism_configuration` - (Optional) Describes parameters for how an application executes multiple tasks simultaneously.\n\nThe `checkpoint_configuration` object supports the following:\n\n* `configuration_type` - (Required) Describes whether the application uses Kinesis Data Analytics' default checkpointing behavior. Valid values: `CUSTOM`, `DEFAULT`. Set this attribute to `CUSTOM` in order for any specified `checkpointing_enabled`, `checkpoint_interval`, or `min_pause_between_checkpoints` attribute values to be effective. If this attribute is set to `DEFAULT`, the application will always use the following values:\n    * `checkpointing_enabled = true`\n    * `checkpoint_interval = 60000`\n    * `min_pause_between_checkpoints = 5000`\n* `checkpointing_enabled` - (Optional) Describes whether checkpointing is enabled for a Flink-based Kinesis Data Analytics application.\n* `checkpoint_interval` - (Optional) Describes the interval in milliseconds between checkpoint operations.\n* `min_pause_between_checkpoints` - (Optional) Describes the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start.\n\nThe `monitoring_configuration` object supports the following:\n\n* `configuration_type` - (Required) Describes whether to use the default CloudWatch logging configuration for an application. Valid values: `CUSTOM`, `DEFAULT`. Set this attribute to `CUSTOM` in order for any specified `log_level` or `metrics_level` attribute values to be effective.\n* `log_level` - (Optional) Describes the verbosity of the CloudWatch Logs for an application. Valid values: `DEBUG`, `ERROR`, `INFO`, `WARN`.\n* `metrics_level` - (Optional) Describes the granularity of the CloudWatch Logs for an application. Valid values: `APPLICATION`, `OPERATOR`, `PARALLELISM`, `TASK`.\n\nThe `parallelism_configuration` object supports the following:\n\n* `configuration_type` - (Required) Describes whether the application uses the default parallelism for the Kinesis Data Analytics service. Valid values: `CUSTOM`, `DEFAULT`. Set this attribute to `CUSTOM` in order for any specified `auto_scaling_enabled`, `parallelism`, or `parallelism_per_kpu` attribute values to be effective.\n* `auto_scaling_enabled` - (Optional) Describes whether the Kinesis Data Analytics service can increase the parallelism of the application in response to increased throughput.\n* `parallelism` - (Optional) Describes the initial number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform.\n* `parallelism_per_kpu` - (Optional) Describes the number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform per Kinesis Processing Unit (KPU) used by the application.\n\nThe `run_configuration` object supports the following:\n\n* `application_restore_configuration` - (Optional) The restore behavior of a restarting application.\n* `flink_run_configuration` - (Optional) The starting parameters for a Flink-based Kinesis Data Analytics application.\n\nThe `application_restore_configuration` object supports the following:\n\n* `application_restore_type` - (Required) Specifies how the application should be restored. Valid values: `RESTORE_FROM_CUSTOM_SNAPSHOT`, `RESTORE_FROM_LATEST_SNAPSHOT`, `SKIP_RESTORE_FROM_SNAPSHOT`.\n* `snapshot_name` - (Optional) The identifier of an existing snapshot of application state to use to restart an application. The application uses this value if `RESTORE_FROM_CUSTOM_SNAPSHOT` is specified for `application_restore_type`.\n\nThe `flink_run_configuration` object supports the following:\n\n* `allow_non_restored_state` - (Optional) When restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. Default is `false`.\n\nThe `sql_application_configuration` object supports the following:\n\n* `input` - (Optional) The input stream used by the application.\n* `output` - (Optional) The destination streams used by the application.\n* `reference_data_source` - (Optional) The reference data source used by the application.\n\nThe `input` object supports the following:\n\n* `input_schema` - (Required) Describes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n* `name_prefix` - (Required) The name prefix to use when creating an in-application stream.\n* `input_parallelism` - (Optional) Describes the number of in-application streams to create.\n* `input_processing_configuration` - (Optional) The input processing configuration for the input.\nAn input processor transforms records as they are received from the stream, before the application's SQL code executes.\n* `input_starting_position_configuration` (Optional) The point at which the application starts processing records from the streaming source.\n* `kinesis_firehose_input` - (Optional) If the streaming source is a [Kinesis Data Firehose delivery stream](/docs/providers/aws/r/kinesis_firehose_delivery_stream.html), identifies the delivery stream's ARN.\n* `kinesis_streams_input` - (Optional) If the streaming source is a [Kinesis data stream](/docs/providers/aws/r/kinesis_stream.html), identifies the stream's Amazon Resource Name (ARN).\n\nThe `input_parallelism` object supports the following:\n\n* `count` - (Optional) The number of in-application streams to create.\n\nThe `input_processing_configuration` object supports the following:\n\n* `input_lambda_processor` - (Required) Describes the [Lambda function](/docs/providers/aws/r/lambda_function.html) that is used to preprocess the records in the stream before being processed by your application code.\n\nThe `input_lambda_processor` object supports the following:\n\n* `resource_arn` - (Required) The ARN of the Lambda function that operates on records in the stream.\n\nThe `input_schema` object supports the following:\n\n* `record_column` - (Required) Describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n* `record_format` - (Required) Specifies the format of the records on the streaming source.\n* `record_encoding` - (Optional) Specifies the encoding of the records in the streaming source. For example, `UTF-8`.\n\nThe `record_column` object supports the following:\n\n* `name` - (Required) The name of the column that is created in the in-application input stream or reference table.\n* `sql_type` - (Required) The type of column created in the in-application input stream or reference table.\n* `mapping` - (Optional) A reference to the data element in the streaming input or the reference data source.\n\nThe `record_format` object supports the following:\n\n* `mapping_parameters` - (Required) Provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n* `record_format_type` - (Required) The type of record format. Valid values: `CSV`, `JSON`.\n\nThe `mapping_parameters` object supports the following:\n\n* `csv_mapping_parameters` - (Optional) Provides additional mapping information when the record format uses delimiters (for example, CSV).\n* `json_mapping_parameters` - (Optional) Provides additional mapping information when JSON is the record format on the streaming source.\n\nThe `csv_mapping_parameters` object supports the following:\n\n* `record_column_delimiter` - (Required) The column delimiter. For example, in a CSV format, a comma (`,`) is the typical column delimiter.\n* `record_row_delimiter` - (Required) The row delimiter. For example, in a CSV format, `\\n` is the typical row delimiter.\n\nThe `json_mapping_parameters` object supports the following:\n\n* `record_row_path` - (Required) The path to the top-level parent that contains the records.\n\nThe `input_starting_position_configuration` object supports the following:\n\n~> **NOTE**: To modify an application's starting position, first stop the application by setting `start_application = false`, then update `starting_position` and set `start_application = true`.\n\n* `input_starting_position` - (Required) The starting position on the stream. Valid values: `LAST_STOPPED_POINT`, `NOW`, `TRIM_HORIZON`.\n\nThe `kinesis_firehose_input` object supports the following:\n\n* `resource_arn` - (Required) The ARN of the delivery stream.\n\nThe `kinesis_streams_input` object supports the following:\n\n* `resource_arn` - (Required) The ARN of the input Kinesis data stream to read.\n\nThe `output` object supports the following:\n\n* `destination_schema` - (Required) Describes the data format when records are written to the destination.\n* `name` - (Required) The name of the in-application stream.\n* `kinesis_firehose_output` - (Optional) Identifies a [Kinesis Data Firehose delivery stream](/docs/providers/aws/r/kinesis_firehose_delivery_stream.html) as the destination.\n* `kinesis_streams_output` - (Optional) Identifies a [Kinesis data stream](/docs/providers/aws/r/kinesis_stream.html) as the destination.\n* `lambda_output` - (Optional) Identifies a [Lambda function](/docs/providers/aws/r/lambda_function.html) as the destination.\n\nThe `destination_schema` object supports the following:\n\n* `record_format_type` - (Required) Specifies the format of the records on the output stream. Valid values: `CSV`, `JSON`.\n\nThe `kinesis_firehose_output` object supports the following:\n\n* `resource_arn` - (Required) The ARN of the destination delivery stream to write to.\n\nThe `kinesis_streams_output` object supports the following:\n\n* `resource_arn` - (Required) The ARN of the destination Kinesis data stream to write to.\n\nThe `lambda_output` object supports the following:\n\n* `resource_arn` - (Required) The ARN of the destination Lambda function to write to.\n\nThe `reference_data_source` object supports the following:\n\n* `reference_schema` - (Required) Describes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n* `s3_reference_data_source` - (Required) Identifies the S3 bucket and object that contains the reference data.\n* `table_name` - (Required) The name of the in-application table to create.\n\nThe `reference_schema` object supports the following:\n\n* `record_column` - (Required) Describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n* `record_format` - (Required) Specifies the format of the records on the streaming source.\n* `record_encoding` - (Optional) Specifies the encoding of the records in the streaming source. For example, `UTF-8`.\n\nThe `s3_reference_data_source` object supports the following:\n\n* `bucket_arn` - (Required) The ARN of the S3 bucket.\n* `file_key` - (Required) The object key name containing the reference data.\n\nThe `vpc_configuration` object supports the following:\n\n* `security_group_ids` - (Required) The [Security Group](/docs/providers/aws/r/security_group.html) IDs used by the VPC configuration.\n* `subnet_ids` - (Required) The [Subnet](/docs/providers/aws/r/subnet.html) IDs used by the VPC configuration.\n\nThe `cloudwatch_logging_options` object supports the following:\n\n* `log_stream_arn` - (Required) The ARN of the CloudWatch log stream to receive application messages.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The application identifier.\n* `arn` - The ARN of the application.\n* `create_timestamp` - The current timestamp when the application was created.\n* `last_update_timestamp` - The current timestamp when the application was last updated.\n* `status` - The status of the application.\n* `version_id` - The current application version. Kinesis Data Analytics updates the `version_id` each time the application is updated.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_kinesisanalyticsv2_application` can be imported by using the application ARN, e.g.,\n\n```\n$ terraform import aws_kinesisanalyticsv2_application.example arn:aws:kinesisanalytics:us-west-2:123456789012:application/example-sql-application\n```\n",
    "basename": "kinesisanalyticsv2_application.html"
  },
  "kinesisanalyticsv2_application_snapshot.html": {
    "subcategory": "Kinesis Data Analytics v2 (SQL and Flink Applications)",
    "layout": "aws",
    "page_title": "AWS: aws_kinesisanalyticsv2_application_snapshot",
    "description": "Manages a Kinesis Analytics v2 Application Snapshot.",
    "preview": "# Resource: aws_kinesisanalyticsv2_application_snapshot\n\nManages a …",
    "content": "\n\n# Resource: aws_kinesisanalyticsv2_application_snapshot\n\nManages a Kinesis Analytics v2 Application Snapshot.\nSnapshots are the AWS implementation of [Flink Savepoints](https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/savepoints.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_kinesisanalyticsv2_application_snapshot\" \"example\" {\n  application_name = aws_kinesisanalyticsv2_application.example.name\n  snapshot_name    = \"example-snapshot\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_name` - (Required) The name of an existing  [Kinesis Analytics v2 Application](/docs/providers/aws/r/kinesisanalyticsv2_application.html). Note that the application must be running for a snapshot to be created.\n* `snapshot_name` - (Required) The name of the application snapshot.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The application snapshot identifier.\n* `application_version_id` - The current application version ID when the snapshot was created.\n* `snapshot_creation_timestamp` - The timestamp of the application snapshot.\n\n## Import\n\n`aws_kinesisanalyticsv2_application` can be imported by using `application_name` together with `snapshot_name`, e.g.,\n\n```\n$ terraform import aws_kinesisanalyticsv2_application_snapshot.example example-application/example-snapshot\n```\n",
    "basename": "kinesisanalyticsv2_application_snapshot.html"
  },
  "kms_alias.html": {
    "subcategory": "KMS",
    "layout": "aws",
    "page_title": "AWS: aws_kms_alias",
    "description": "Provides a display name for a customer master key.",
    "preview": "# Resource: aws_kms_alias\n\nProvides an alias for a KMS customer …",
    "content": "\n\n# Resource: aws_kms_alias\n\nProvides an alias for a KMS customer master key. AWS Console enforces 1-to-1 mapping between aliases & keys,\nbut API (hence Terraform too) allows you to create as many aliases as\nthe [account limits](http://docs.aws.amazon.com/kms/latest/developerguide/limits.html) allow you.\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"a\" {}\n\nresource \"aws_kms_alias\" \"a\" {\n  name          = \"alias/my-key-alias\"\n  target_key_id = aws_kms_key.a.key_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n\n* `name` - (Optional) The display name of the alias. The name must start with the word \"alias\" followed by a forward slash (alias/)\n* `name_prefix` - (Optional) Creates an unique alias beginning with the specified prefix.\nThe name must start with the word \"alias\" followed by a forward slash (alias/).  Conflicts with `name`.\n* `target_key_id` - (Required) Identifier for the key for which the alias is for, can be either an ARN or key_id.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the key alias.\n* `target_key_arn` - The Amazon Resource Name (ARN) of the target key identifier.\n\n## Import\n\nKMS aliases can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_kms_alias.a alias/my-key-alias\n```\n",
    "basename": "kms_alias.html"
  },
  "kms_ciphertext.html": {
    "subcategory": "KMS",
    "layout": "aws",
    "page_title": "AWS: aws_kms_ciphertext",
    "description": "Provides ciphertext encrypted using a KMS key",
    "preview": "# Resource: aws_kms_ciphertext\n\nThe KMS ciphertext resource allows …",
    "content": "\n\n# Resource: aws_kms_ciphertext\n\nThe KMS ciphertext resource allows you to encrypt plaintext into ciphertext\nby using an AWS KMS customer master key. The value returned by this resource\nis stable across every apply. For a changing ciphertext value each apply, see\nthe [`aws_kms_ciphertext` data source](/docs/providers/aws/d/kms_ciphertext.html).\n\n~> **Note:** All arguments including the plaintext be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"oauth_config\" {\n  description = \"oauth config\"\n  is_enabled  = true\n}\n\nresource \"aws_kms_ciphertext\" \"oauth\" {\n  key_id = aws_kms_key.oauth_config.key_id\n\n  plaintext = <<EOF\n{\n  \"client_id\": \"e587dbae22222f55da22\",\n  \"client_secret\": \"8289575d00000ace55e1815ec13673955721b8a5\"\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `plaintext` - (Required) Data to be encrypted. Note that this may show up in logs, and it will be stored in the state file.\n* `key_id` - (Required) Globally unique key ID for the customer master key.\n* `context` - (Optional) An optional mapping that makes up the encryption context.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `ciphertext_blob` - Base64 encoded ciphertext\n",
    "basename": "kms_ciphertext.html"
  },
  "kms_external_key.html": {
    "subcategory": "KMS",
    "layout": "aws",
    "page_title": "AWS: aws_kms_external_key",
    "description": "Manages a single-Region or multi-Region primary KMS key that uses external key material.",
    "preview": "# Resource: aws_kms_external_key\n\nManages a single-Region or …",
    "content": "\n\n# Resource: aws_kms_external_key\n\nManages a single-Region or multi-Region primary KMS key that uses external key material.\nTo instead manage a single-Region or multi-Region primary KMS key where AWS automatically generates and potentially rotates key material, see the [`aws_kms_key` resource](/docs/providers/aws/r/kms_key.html).\n\n~> **Note:** All arguments including the key material will be stored in the raw state as plain-text. [Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_external_key\" \"example\" {\n  description = \"KMS EXTERNAL for AMI encryption\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bypass_policy_lockout_safety_check` - (Optional) Specifies whether to disable the policy lockout check performed when creating or updating the key's policy. Setting this value to `true` increases the risk that the key becomes unmanageable. For more information, refer to the scenario in the [Default Key Policy](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default-allow-root-enable-iam) section in the AWS Key Management Service Developer Guide. Defaults to `false`.\n* `deletion_window_in_days` - (Optional) Duration in days after which the key is deleted after destruction of the resource. Must be between `7` and `30` days. Defaults to `30`.\n* `description` - (Optional) Description of the key.\n* `enabled` - (Optional) Specifies whether the key is enabled. Keys pending import can only be `false`. Imported keys default to `true` unless expired.\n* `key_material_base64` - (Optional) Base64 encoded 256-bit symmetric encryption key material to import. The CMK is permanently associated with this key material. The same key material can be reimported, but you cannot import different key material.\n* `multi_region` - (Optional) Indicates whether the KMS key is a multi-Region (`true`) or regional (`false`) key. Defaults to `false`.\n* `policy` - (Optional) A key policy JSON document. If you do not provide a key policy, AWS KMS attaches a default key policy to the CMK.\n* `tags` - (Optional) A key-value map of tags to assign to the key. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `valid_to` - (Optional) Time at which the imported key material expires. When the key material expires, AWS KMS deletes the key material and the CMK becomes unusable. If not specified, key material does not expire. Valid values: [RFC3339 time string](https://tools.ietf.org/html/rfc3339#section-5.8) (`YYYY-MM-DDTHH:MM:SSZ`)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the key.\n* `expiration_model` - Whether the key material expires. Empty when pending key material import, otherwise `KEY_MATERIAL_EXPIRES` or `KEY_MATERIAL_DOES_NOT_EXPIRE`.\n* `id` - The unique identifier for the key.\n* `key_state` - The state of the CMK.\n* `key_usage` - The cryptographic operations for which you can use the CMK.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nKMS External Keys can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_kms_external_key.a arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\n```\n",
    "basename": "kms_external_key.html"
  },
  "kms_grant.html": {
    "subcategory": "KMS",
    "layout": "aws",
    "page_title": "AWS: aws_kms_grant",
    "description": "Provides a resource-based access control mechanism for KMS Customer Master Keys.",
    "preview": "# Resource: aws_kms_grant\n\nProvides a resource-based access control …",
    "content": "\n\n# Resource: aws_kms_grant\n\nProvides a resource-based access control mechanism for a KMS customer master key.\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"a\" {}\n\nresource \"aws_iam_role\" \"a\" {\n  name = \"iam-role-for-grant\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_kms_grant\" \"a\" {\n  name              = \"my-grant\"\n  key_id            = aws_kms_key.a.key_id\n  grantee_principal = aws_iam_role.a.arn\n  operations        = [\"Encrypt\", \"Decrypt\", \"GenerateDataKey\"]\n\n  constraints {\n    encryption_context_equals = {\n      Department = \"Finance\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resources) A friendly name for identifying the grant.\n* `key_id` - (Required, Forces new resources) The unique identifier for the customer master key (CMK) that the grant applies to. Specify the key ID or the Amazon Resource Name (ARN) of the CMK. To specify a CMK in a different AWS account, you must use the key ARN.\n* `grantee_principal` - (Required, Forces new resources) The principal that is given permission to perform the operations that the grant permits in ARN format. Note that due to eventual consistency issues around IAM principals, terraform's state may not always be refreshed to reflect what is true in AWS.\n* `operations` - (Required, Forces new resources) A list of operations that the grant permits. The permitted values are: `Decrypt`, `Encrypt`, `GenerateDataKey`, `GenerateDataKeyWithoutPlaintext`, `ReEncryptFrom`, `ReEncryptTo`, `Sign`, `Verify`, `GetPublicKey`, `CreateGrant`, `RetireGrant`, `DescribeKey`, `GenerateDataKeyPair`, or `GenerateDataKeyPairWithoutPlaintext`.\n* `retiring_principal` - (Optional, Forces new resources) The principal that is given permission to retire the grant by using RetireGrant operation in ARN format. Note that due to eventual consistency issues around IAM principals, terraform's state may not always be refreshed to reflect what is true in AWS.\n* `constraints` - (Optional, Forces new resources) A structure that you can use to allow certain operations in the grant only when the desired encryption context is present. For more information about encryption context, see [Encryption Context](http://docs.aws.amazon.com/kms/latest/developerguide/encryption-context.html).\n* `grant_creation_tokens` - (Optional, Forces new resources) A list of grant tokens to be used when creating the grant. See [Grant Tokens](http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#grant_token) for more information about grant tokens.\n* `retire_on_delete` -(Defaults to false, Forces new resources) If set to false (the default) the grants will be revoked upon deletion, and if set to true the grants will try to be retired upon deletion. Note that retiring grants requires special permissions, hence why we default to revoking grants.\n  See [RetireGrant](https://docs.aws.amazon.com/kms/latest/APIReference/API_RetireGrant.html) for more information.\n\nThe `constraints` block supports the following arguments:\n\n* `encryption_context_equals` - (Optional) A list of key-value pairs that must match the encryption context in subsequent cryptographic operation requests. The grant allows the operation only when the encryption context in the request is the same as the encryption context specified in this constraint. Conflicts with `encryption_context_subset`.\n* `encryption_context_subset` - (Optional) A list of key-value pairs that must be included in the encryption context of subsequent cryptographic operation requests. The grant allows the cryptographic operation only when the encryption context in the request includes the key-value pairs specified in this constraint, although it can include additional key-value pairs. Conflicts with `encryption_context_equals`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `grant_id` - The unique identifier for the grant.\n* `grant_token` - The grant token for the created grant. For more information, see [Grant Tokens](http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#grant_token).\n\n## Import\n\nKMS Grants can be imported using the Key ID and Grant ID separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_kms_grant.test 1234abcd-12ab-34cd-56ef-1234567890ab: abcde1237f76e4ba7987489ac329fbfba6ad343d6f7075dbd1ef191f0120514\n```\n",
    "basename": "kms_grant.html"
  },
  "kms_key.html": {
    "subcategory": "KMS",
    "layout": "aws",
    "page_title": "AWS: aws_kms_key",
    "description": "Manages a single-Region or multi-Region primary KMS key.",
    "preview": "# Resource: aws_kms_key\n\nManages a single-Region or multi-Region …",
    "content": "\n\n# Resource: aws_kms_key\n\nManages a single-Region or multi-Region primary KMS key.\n\n## Example Usage\n\n```terraform\nresource \"aws_kms_key\" \"a\" {\n  description             = \"KMS key 1\"\n  deletion_window_in_days = 10\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) The description of the key as viewed in AWS console.\n* `key_usage` - (Optional) Specifies the intended use of the key. Valid values: `ENCRYPT_DECRYPT` or `SIGN_VERIFY`.\nDefaults to `ENCRYPT_DECRYPT`.\n* `customer_master_key_spec` - (Optional) Specifies whether the key contains a symmetric key or an asymmetric key pair and the encryption algorithms or signing algorithms that the key supports.\nValid values: `SYMMETRIC_DEFAULT`,  `RSA_2048`, `RSA_3072`, `RSA_4096`, `ECC_NIST_P256`, `ECC_NIST_P384`, `ECC_NIST_P521`, or `ECC_SECG_P256K1`. Defaults to `SYMMETRIC_DEFAULT`. For help with choosing a key spec, see the [AWS KMS Developer Guide](https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-choose.html).\n* `policy` - (Optional) A valid policy JSON document. Although this is a key policy, not an IAM policy, an [`aws_iam_policy_document`](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/iam_policy_document), in the form that designates a principal, can be used. For more information about building policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n~> **NOTE:** Note: All KMS keys must have a key policy. If a key policy is not specified, AWS gives the KMS key a [default key policy](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default) that gives all principals in the owning account unlimited access to all KMS operations for the key. This default key policy effectively delegates all access control to IAM policies and KMS grants.\n\n* `bypass_policy_lockout_safety_check` - (Optional) A flag to indicate whether to bypass the key policy lockout safety check.\nSetting this value to true increases the risk that the KMS key becomes unmanageable. Do not set this value to true indiscriminately.\nFor more information, refer to the scenario in the [Default Key Policy](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default-allow-root-enable-iam) section in the _AWS Key Management Service Developer Guide_.\nThe default value is `false`.\n* `deletion_window_in_days` - (Optional) The waiting period, specified in number of days. After the waiting period ends, AWS KMS deletes the KMS key.\nIf you specify a value, it must be between `7` and `30`, inclusive. If you do not specify a value, it defaults to `30`.\nIf the KMS key is a multi-Region primary key with replicas, the waiting period begins when the last of its replica keys is deleted. Otherwise, the waiting period begins immediately.\n* `is_enabled` - (Optional) Specifies whether the key is enabled. Defaults to `true`.\n* `enable_key_rotation` - (Optional) Specifies whether [key rotation](http://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html) is enabled. Defaults to false.\n* `multi_region` - (Optional) Indicates whether the KMS key is a multi-Region (`true`) or regional (`false`) key. Defaults to `false`.\n* `tags` - (Optional) A map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the key.\n* `key_id` - The globally unique identifier for the key.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nKMS Keys can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_kms_key.a 1234abcd-12ab-34cd-56ef-1234567890ab\n```\n",
    "basename": "kms_key.html"
  },
  "kms_replica_external_key.html": {
    "subcategory": "KMS",
    "layout": "aws",
    "page_title": "AWS: aws_replica_external kms_key",
    "description": "Manages a KMS multi-Region replica key that uses external key material.",
    "preview": "# Resource: aws_kms_replica_external_key\n\nManages a KMS multi-Region …",
    "content": "\n\n# Resource: aws_kms_replica_external_key\n\nManages a KMS multi-Region replica key that uses external key material.\nSee the [AWS KMS Developer Guide](https://docs.aws.amazon.com/kms/latest/developerguide/multi-region-keys-import.html) for more information on importing key material into multi-Region keys.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  alias  = \"primary\"\n  region = \"us-east-1\"\n}\n\nprovider \"aws\" {\n  region = \"us-west-2\"\n}\n\nresource \"aws_kms_external_key\" \"primary\" {\n  provider = aws.primary\n\n  description             = \"Multi-Region primary key\"\n  deletion_window_in_days = 30\n  multi_region            = true\n  enabled                 = true\n\n  key_material_base64 = \"...\"\n}\n\nresource \"aws_kms_replica_external_key\" \"replica\" {\n  description             = \"Multi-Region replica key\"\n  deletion_window_in_days = 7\n  primary_key_arn         = aws_kms_external.primary.arn\n\n  key_material_base64 = \"...\" # Must be the same key material as the primary's.\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bypass_policy_lockout_safety_check` - (Optional) A flag to indicate whether to bypass the key policy lockout safety check.\nSetting this value to true increases the risk that the KMS key becomes unmanageable. Do not set this value to true indiscriminately.\nFor more information, refer to the scenario in the [Default Key Policy](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default-allow-root-enable-iam) section in the _AWS Key Management Service Developer Guide_.\nThe default value is `false`.\n* `deletion_window_in_days` - (Optional) The waiting period, specified in number of days. After the waiting period ends, AWS KMS deletes the KMS key.\nIf you specify a value, it must be between `7` and `30`, inclusive. If you do not specify a value, it defaults to `30`.\n* `description` - (Optional) A description of the KMS key.\n* `enabled` - (Optional) Specifies whether the replica key is enabled. Disabled KMS keys cannot be used in cryptographic operations. Keys pending import can only be `false`. Imported keys default to `true` unless expired.\n* `key_material_base64` - (Optional) Base64 encoded 256-bit symmetric encryption key material to import. The KMS key is permanently associated with this key material. The same key material can be [reimported](https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html#reimport-key-material), but you cannot import different key material.\n* `policy` - (Optional) The key policy to attach to the KMS key. If you do not specify a key policy, AWS KMS attaches the [default key policy](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default) to the KMS key.\nFor more information about building policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `primary_key_arn` - (Required) The ARN of the multi-Region primary key to replicate. The primary key must be in a different AWS Region of the same AWS Partition. You can create only one replica of a given primary key in each AWS Region.\n* `tags` - (Optional) A map of tags to assign to the replica key. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `valid_to` - (Optional) Time at which the imported key material expires. When the key material expires, AWS KMS deletes the key material and the key becomes unusable. If not specified, key material does not expire. Valid values: [RFC3339 time string](https://tools.ietf.org/html/rfc3339#section-5.8) (`YYYY-MM-DDTHH:MM:SSZ`)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the replica key. The key ARNs of related multi-Region keys differ only in the Region value.\n* `expiration_model` - Whether the key material expires. Empty when pending key material import, otherwise `KEY_MATERIAL_EXPIRES` or `KEY_MATERIAL_DOES_NOT_EXPIRE`.\n* `key_id` - The key ID of the replica key. Related multi-Region keys have the same key ID.\n* `key_state` - The state of the replica key.\n* `key_usage` - The [cryptographic operations](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#cryptographic-operations) for which you can use the KMS key. This is a shared property of multi-Region keys.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nKMS multi-Region replica keys can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_kms_replica_external_key.example 1234abcd-12ab-34cd-56ef-1234567890ab\n```\n",
    "basename": "kms_replica_external_key.html"
  },
  "kms_replica_key.html": {
    "subcategory": "KMS",
    "layout": "aws",
    "page_title": "AWS: aws_replica_kms_key",
    "description": "Manages a KMS multi-Region replica key.",
    "preview": "# Resource: aws_kms_replica_key\n\nManages a KMS multi-Region replica …",
    "content": "\n\n# Resource: aws_kms_replica_key\n\nManages a KMS multi-Region replica key.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  alias  = \"primary\"\n  region = \"us-east-1\"\n}\n\nprovider \"aws\" {\n  region = \"us-west-2\"\n}\n\nresource \"aws_kms_key\" \"primary\" {\n  provider = aws.primary\n\n  description             = \"Multi-Region primary key\"\n  deletion_window_in_days = 30\n  multi_region            = true\n}\n\nresource \"aws_kms_replica_key\" \"replica\" {\n  description             = \"Multi-Region replica key\"\n  deletion_window_in_days = 7\n  primary_key_arn         = aws_kms_key.primary.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bypass_policy_lockout_safety_check` - (Optional) A flag to indicate whether to bypass the key policy lockout safety check.\nSetting this value to true increases the risk that the KMS key becomes unmanageable. Do not set this value to true indiscriminately.\nFor more information, refer to the scenario in the [Default Key Policy](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default-allow-root-enable-iam) section in the _AWS Key Management Service Developer Guide_.\nThe default value is `false`.\n* `deletion_window_in_days` - (Optional) The waiting period, specified in number of days. After the waiting period ends, AWS KMS deletes the KMS key.\nIf you specify a value, it must be between `7` and `30`, inclusive. If you do not specify a value, it defaults to `30`.\n* `description` - (Optional) A description of the KMS key.\n* `enabled` - (Optional) Specifies whether the replica key is enabled. Disabled KMS keys cannot be used in cryptographic operations. The default value is `true`.\n* `policy` - (Optional) The key policy to attach to the KMS key. If you do not specify a key policy, AWS KMS attaches the [default key policy](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default) to the KMS key.\nFor more information about building policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `primary_key_arn` - (Required) The ARN of the multi-Region primary key to replicate. The primary key must be in a different AWS Region of the same AWS Partition. You can create only one replica of a given primary key in each AWS Region.\n* `tags` - (Optional) A map of tags to assign to the replica key. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the replica key. The key ARNs of related multi-Region keys differ only in the Region value.\n* `key_id` - The key ID of the replica key. Related multi-Region keys have the same key ID.\n* `key_rotation_enabled` - A Boolean value that specifies whether key rotation is enabled. This is a shared property of multi-Region keys.\n* `key_spec` - The type of key material in the KMS key. This is a shared property of multi-Region keys.\n* `key_usage` - The [cryptographic operations](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#cryptographic-operations) for which you can use the KMS key. This is a shared property of multi-Region keys.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nKMS multi-Region replica keys can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_kms_replica_key.example 1234abcd-12ab-34cd-56ef-1234567890ab\n```\n",
    "basename": "kms_replica_key.html"
  },
  "lakeformation_data_lake_settings.html": {
    "subcategory": "Lake Formation",
    "layout": "aws",
    "page_title": "AWS: aws_lakeformation_data_lake_settings",
    "description": "Manages data lake administrators and default database and table permissions",
    "preview": "# Resource: aws_lakeformation_data_lake_settings\n\nManages Lake …",
    "content": "\n\n# Resource: aws_lakeformation_data_lake_settings\n\nManages Lake Formation principals designated as data lake administrators and lists of principal permission entries for default create database and default create table permissions.\n\n~> **NOTE:** Lake Formation introduces fine-grained access control for data in your data lake. Part of the changes include the `IAMAllowedPrincipals` principal in order to make Lake Formation backwards compatible with existing IAM and Glue permissions. For more information, see [Changing the Default Security Settings for Your Data Lake](https://docs.aws.amazon.com/lake-formation/latest/dg/change-settings.html) and [Upgrading AWS Glue Data Permissions to the AWS Lake Formation Model](https://docs.aws.amazon.com/lake-formation/latest/dg/upgrade-glue-lake-formation.html).\n\n## Example Usage\n\n### Data Lake Admins\n\n```terraform\nresource \"aws_lakeformation_data_lake_settings\" \"example\" {\n  admins = [aws_iam_user.test.arn, aws_iam_role.test.arn]\n}\n```\n\n### Create Default Permissions\n\n```terraform\nresource \"aws_lakeformation_data_lake_settings\" \"example\" {\n  admins = [aws_iam_user.test.arn, aws_iam_role.test.arn]\n\n  create_database_default_permissions {\n    permissions = [\"SELECT\", \"ALTER\", \"DROP\"]\n    principal   = aws_iam_user.test.arn\n  }\n\n  create_table_default_permissions {\n    permissions = [\"ALL\"]\n    principal   = aws_iam_role.test.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are optional:\n\n* `admins` – (Optional) Set of ARNs of AWS Lake Formation principals (IAM users or roles).\n* `catalog_id` – (Optional) Identifier for the Data Catalog. By default, the account ID.\n* `create_database_default_permissions` - (Optional) Up to three configuration blocks of principal permissions for default create database permissions. Detailed below.\n* `create_table_default_permissions` - (Optional) Up to three configuration blocks of principal permissions for default create table permissions. Detailed below.\n* `trusted_resource_owners` – (Optional) List of the resource-owning account IDs that the caller's account can use to share their user access details (user ARNs).\n\n~> **NOTE:** Although optional, not including `admins`, `create_database_default_permissions`, `create_table_default_permissions`, and/or `trusted_resource_owners` results in the setting being cleared.\n\n### create_database_default_permissions\n\nThe following arguments are optional:\n\n* `permissions` - (Optional) List of permissions that are granted to the principal. Valid values may include `ALL`, `SELECT`, `ALTER`, `DROP`, `DELETE`, `INSERT`, `DESCRIBE`, and `CREATE_TABLE`. For more details, see [Lake Formation Permissions Reference](https://docs.aws.amazon.com/lake-formation/latest/dg/lf-permissions-reference.html).\n* `principal` - (Optional) Principal who is granted permissions. To enforce metadata and underlying data access control only by IAM on new databases and tables set `principal` to `IAM_ALLOWED_PRINCIPALS` and `permissions` to `[\"ALL\"]`.\n\n### create_table_default_permissions\n\nThe following arguments are optional:\n\n* `permissions` - (Optional) List of permissions that are granted to the principal. Valid values may include `ALL`, `SELECT`, `ALTER`, `DROP`, `DELETE`, `INSERT`, and `DESCRIBE`. For more details, see [Lake Formation Permissions Reference](https://docs.aws.amazon.com/lake-formation/latest/dg/lf-permissions-reference.html).\n* `principal` - (Optional) Principal who is granted permissions. To enforce metadata and underlying data access control only by IAM on new databases and tables set `principal` to `IAM_ALLOWED_PRINCIPALS` and `permissions` to `[\"ALL\"]`.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "lakeformation_data_lake_settings.html"
  },
  "lakeformation_permissions.html": {
    "subcategory": "Lake Formation",
    "layout": "aws",
    "page_title": "AWS: aws_lakeformation_permissions",
    "description": "Grants permissions to the principal to access metadata in the Data Catalog and data organized in underlying data storage such as Amazon S3.",
    "preview": "# Resource: aws_lakeformation_permissions\n\nGrants permissions to the …",
    "content": "\n\n# Resource: aws_lakeformation_permissions\n\nGrants permissions to the principal to access metadata in the Data Catalog and data organized in underlying data storage such as Amazon S3. Permissions are granted to a principal, in a Data Catalog, relative to a Lake Formation resource, which includes the Data Catalog, databases, and tables. For more information, see [Security and Access Control to Metadata and Data in Lake Formation](https://docs.aws.amazon.com/lake-formation/latest/dg/security-data-access.html).\n\n!> **WARNING:** Lake Formation permissions are not in effect by default within AWS. Using this resource will not secure your data and will result in errors if you do not change the security settings for existing resources and the default security settings for new resources. See [Default Behavior and `IAMAllowedPrincipals`](#default-behavior-and-iamallowedprincipals) for additional details.\n\n~> **NOTE:** In general, the `principal` should _NOT_ be a Lake Formation administrator or the entity (e.g., IAM role) that is running Terraform. Administrators have implicit permissions. These should be managed by granting or not granting administrator rights using `aws_lakeformation_data_lake_settings`, _not_ with this resource.\n\n## Default Behavior and `IAMAllowedPrincipals`\n\n**_Lake Formation permissions are not in effect by default within AWS._** `IAMAllowedPrincipals` (i.e., `IAM_ALLOWED_PRINCIPALS`) conflicts with individual Lake Formation permissions (i.e., non-`IAMAllowedPrincipals` permissions), will cause unexpected behavior, and may result in errors.\n\nWhen using Lake Formation, choose ONE of the following options as they are mutually exclusive:\n\n1. Use this resource (`aws_lakeformation_permissions`), change the default security settings using [`aws_lakeformation_data_lake_settings`](/docs/providers/aws/r/lakeformation_data_lake_settings.html), and remove existing `IAMAllowedPrincipals` permissions\n2. Use `IAMAllowedPrincipals` without `aws_lakeformation_permissions`\n\nThis example shows removing the `IAMAllowedPrincipals` default security settings and making the caller a Lake Formation admin. Since `create_database_default_permissions` and `create_table_default_permissions` are not set in the [`aws_lakeformation_data_lake_settings`](/docs/providers/aws/r/lakeformation_data_lake_settings.html) resource, they are cleared.\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_iam_session_context\" \"current\" {\n  arn = data.aws_caller_identity.current.arn\n}\n\nresource \"aws_lakeformation_data_lake_settings\" \"test\" {\n  admins = [data.aws_iam_session_context.current.issuer_arn]\n}\n```\n\nTo remove existing `IAMAllowedPrincipals` permissions, use the [AWS Lake Formation Console](https://console.aws.amazon.com/lakeformation/) or [AWS CLI](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lakeformation/batch-revoke-permissions.html).\n\n`IAMAllowedPrincipals` is a hook to maintain backwards compatibility with AWS Glue. `IAMAllowedPrincipals` is a pseudo-entity group that acts like a Lake Formation principal. The group includes any IAM users and roles that are allowed access to your Data Catalog resources by your IAM policies.\n\nThis is Lake Formation's default behavior:\n\n* Lake Formation grants `Super` permission to `IAMAllowedPrincipals` on all existing AWS Glue Data Catalog resources.\n* Lake Formation enables \"Use only IAM access control\" for new Data Catalog resources.\n\nFor more details, see [Changing the Default Security Settings for Your Data Lake](https://docs.aws.amazon.com/lake-formation/latest/dg/change-settings.html).\n\n### Problem Using `IAMAllowedPrincipals`\n\nAWS does not support combining `IAMAllowedPrincipals` permissions and non-`IAMAllowedPrincipals` permissions. Doing so results in unexpected permissions and behaviors. For example, this configuration grants a user `SELECT` on a column in a table.\n\n```terraform\nresource \"aws_glue_catalog_database\" \"example\" {\n  name = \"sadabate\"\n}\n\nresource \"aws_glue_catalog_table\" \"example\" {\n  name          = \"abelt\"\n  database_name = aws_glue_catalog_database.test.name\n\n  storage_descriptor {\n    columns {\n      name = \"event\"\n      type = \"string\"\n    }\n  }\n}\n\nresource \"aws_lakeformation_permissions\" \"example\" {\n  permissions = [\"SELECT\"]\n  principal   = \"arn:aws:iam:us-east-1:123456789012:user/SanHolo\"\n\n  table_with_columns {\n    database_name = aws_glue_catalog_table.example.database_name\n    name          = aws_glue_catalog_table.example.name\n    column_names  = [\"event\"]\n  }\n}\n```\n\nThe resulting permissions depend on whether the table had `IAMAllowedPrincipals` (IAP) permissions or not.\n\n| Result With IAP | Result Without IAP |\n| ---- | ---- |\n| `SELECT` column wildcard (i.e., all columns) | `SELECT` on `\"event\"` (as expected) |\n\n## Using Lake Formation Permissions\n\nLake Formation grants implicit permissions to data lake administrators, database creators, and table creators. These implicit permissions cannot be revoked _per se_. If this resource reads implicit permissions, it will attempt to revoke them, which causes an error when the resource is destroyed.\n\nThere are two ways to avoid these errors. First, and the way we recommend, is to avoid using this resource with principals that have implicit permissions. A second, error-prone option, is to grant explicit permissions (and `permissions_with_grant_option`) to \"overwrite\" a principal's implicit permissions, which you can then revoke with this resource. For more information, see [Implicit Lake Formation Permissions](https://docs.aws.amazon.com/lake-formation/latest/dg/implicit-permissions.html).\n\nIf the `principal` is also a data lake administrator, AWS grants implicit permissions that can cause errors using this resource. For example, AWS implicitly grants a `principal`/administrator `permissions` and `permissions_with_grant_option` of `ALL`, `ALTER`, `DELETE`, `DESCRIBE`, `DROP`, `INSERT`, and `SELECT` on a table. If you use this resource to explicitly grant the `principal`/administrator `permissions` but _not_ `permissions_with_grant_option` of `ALL`, `ALTER`, `DELETE`, `DESCRIBE`, `DROP`, `INSERT`, and `SELECT` on the table, this resource will read the implicit `permissions_with_grant_option` and attempt to revoke them when the resource is destroyed. Doing so will cause an `InvalidInputException: No permissions revoked` error because you cannot revoke implicit permissions _per se_. To workaround this problem, explicitly grant the `principal`/administrator `permissions` _and_ `permissions_with_grant_option`, which can then be revoked. Similarly, granting a `principal`/administrator permissions on a table with columns and providing `column_names`, will result in a `InvalidInputException: Permissions modification is invalid` error because you are narrowing the implicit permissions. Instead, set `wildcard` to `true` and remove the `column_names`.\n\n## Example Usage\n\n### Grant Permissions For A Lake Formation S3 Resource\n\n```terraform\nresource \"aws_lakeformation_permissions\" \"example\" {\n  principal   = aws_iam_role.workflow_role.arn\n  permissions = [\"ALL\"]\n\n  data_location {\n    arn = aws_lakeformation_resource.example.arn\n  }\n}\n```\n\n### Grant Permissions For A Glue Catalog Database\n\n```terraform\nresource \"aws_lakeformation_permissions\" \"example\" {\n  role        = aws_iam_role.workflow_role.arn\n  permissions = [\"CREATE_TABLE\", \"ALTER\", \"DROP\"]\n\n  database {\n    name       = aws_glue_catalog_database.example.name\n    catalog_id = \"110376042874\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `permissions` – (Required) List of permissions granted to the principal. Valid values may include `ALL`, `ALTER`, `CREATE_DATABASE`, `CREATE_TABLE`, `DATA_LOCATION_ACCESS`, `DELETE`, `DESCRIBE`, `DROP`, `INSERT`, and `SELECT`. For details on each permission, see [Lake Formation Permissions Reference](https://docs.aws.amazon.com/lake-formation/latest/dg/lf-permissions-reference.html).\n* `principal` – (Required) Principal to be granted the permissions on the resource. Supported principals include `IAM_ALLOWED_PRINCIPALS` (see [Default Behavior and `IAMAllowedPrincipals`](#default-behavior-and-iamallowedprincipals) above), IAM roles, users, groups, SAML groups and users, QuickSight groups, OUs, and organizations as well as AWS account IDs for cross-account permissions. For more information, see [Lake Formation Permissions Reference](https://docs.aws.amazon.com/lake-formation/latest/dg/lf-permissions-reference.html).\n\n~> **NOTE:** We highly recommend that the `principal` _NOT_ be a Lake Formation administrator (granted using `aws_lakeformation_data_lake_settings`). The entity (e.g., IAM role) running Terraform will most likely need to be a Lake Formation administrator. As such, the entity will have implicit permissions and does not need permissions granted through this resource.\n\nOne of the following is required:\n\n* `catalog_resource` - (Optional) Whether the permissions are to be granted for the Data Catalog. Defaults to `false`.\n* `data_location` - (Optional) Configuration block for a data location resource. Detailed below.\n* `database` - (Optional) Configuration block for a database resource. Detailed below.\n* `table` - (Optional) Configuration block for a table resource. Detailed below.\n* `table_with_columns` - (Optional) Configuration block for a table with columns resource. Detailed below.\n\nThe following arguments are optional:\n\n* `catalog_id` – (Optional) Identifier for the Data Catalog. By default, the account ID. The Data Catalog is the persistent metadata store. It contains database definitions, table definitions, and other control information to manage your Lake Formation environment.\n* `permissions_with_grant_option` - (Optional) Subset of `permissions` which the principal can pass.\n\n### data_location\n\nThe following argument is required:\n\n* `arn` – (Required) Amazon Resource Name (ARN) that uniquely identifies the data location resource.\n\nThe following argument is optional:\n\n* `catalog_id` - (Optional) Identifier for the Data Catalog where the location is registered with Lake Formation. By default, it is the account ID of the caller.\n\n### database\n\nThe following argument is required:\n\n* `name` – (Required) Name of the database resource. Unique to the Data Catalog.\n\nThe following argument is optional:\n\n* `catalog_id` - (Optional) Identifier for the Data Catalog. By default, it is the account ID of the caller.\n\n### table\n\nThe following argument is required:\n\n* `database_name` – (Required) Name of the database for the table. Unique to a Data Catalog.\n* `name` - (Required, at least one of `name` or `wildcard`) Name of the table.\n* `wildcard` - (Required, at least one of `name` or `wildcard`) Whether to use a wildcard representing every table under a database. Defaults to `false`.\n\nThe following arguments are optional:\n\n* `catalog_id` - (Optional) Identifier for the Data Catalog. By default, it is the account ID of the caller.\n\n### table_with_columns\n\nThe following arguments are required:\n\n* `column_names` - (Required, at least one of `column_names` or `wildcard`) Set of column names for the table.\n* `database_name` – (Required) Name of the database for the table with columns resource. Unique to the Data Catalog.\n* `name` – (Required) Name of the table resource.\n* `wildcard` - (Required, at least one of `column_names` or `wildcard`) Whether to use a column wildcard. If `excluded_column_names` is included, `wildcard` must be set to `true` to avoid Terraform reporting a difference.\n\nThe following arguments are optional:\n\n* `catalog_id` - (Optional) Identifier for the Data Catalog. By default, it is the account ID of the caller.\n* `excluded_column_names` - (Optional) Set of column names for the table to exclude. If `excluded_column_names` is included, `wildcard` must be set to `true` to avoid Terraform reporting a difference.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "lakeformation_permissions.html"
  },
  "lakeformation_resource.html": {
    "subcategory": "Lake Formation",
    "layout": "aws",
    "page_title": "AWS: aws_lakeformation_resource",
    "description": "Registers a Lake Formation resource as managed by the Data Catalog.",
    "preview": "# Resource: aws_lakeformation_resource\n\nRegisters a Lake Formation …",
    "content": "\n\n# Resource: aws_lakeformation_resource\n\nRegisters a Lake Formation resource (e.g., S3 bucket) as managed by the Data Catalog. In other words, the S3 path is added to the data lake.\n\nChoose a role that has read/write access to the chosen Amazon S3 path or use the service-linked role. When you register the S3 path, the service-linked role and a new inline policy are created on your behalf. Lake Formation adds the first path to the inline policy and attaches it to the service-linked role. When you register subsequent paths, Lake Formation adds the path to the existing policy.\n\n## Example Usage\n\n```terraform\ndata \"aws_s3_bucket\" \"example\" {\n  bucket = \"an-example-bucket\"\n}\n\nresource \"aws_lakeformation_resource\" \"example\" {\n  arn = data.aws_s3_bucket.example.arn\n}\n```\n\n## Argument Reference\n\n* `arn` – (Required) Amazon Resource Name (ARN) of the resource, an S3 path.\n* `role_arn` – (Optional) Role that has read/write access to the resource. If not provided, the Lake Formation service-linked role must exist and is used.\n\n~> **NOTE:** AWS does not support registering an S3 location with an IAM role and subsequently updating the S3 location registration to a service-linked role.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `last_modified` - (Optional) The date and time the resource was last modified in [RFC 3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n",
    "basename": "lakeformation_resource.html"
  },
  "lambda_alias.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_alias",
    "description": "Creates a Lambda function alias.",
    "preview": "# Resource: aws_lambda_alias\n\nCreates a Lambda function alias. …",
    "content": "\n\n# Resource: aws_lambda_alias\n\nCreates a Lambda function alias. Creates an alias that points to the specified Lambda function version.\n\nFor information about Lambda and how to use it, see [What is AWS Lambda?][1]\nFor information about function aliases, see [CreateAlias][2] and [AliasRoutingConfiguration][3] in the API docs.\n\n## Example Usage\n\n```terraform\nresource \"aws_lambda_alias\" \"test_lambda_alias\" {\n  name             = \"my_alias\"\n  description      = \"a sample description\"\n  function_name    = aws_lambda_function.lambda_function_test.arn\n  function_version = \"1\"\n\n  routing_config {\n    additional_version_weights = {\n      \"2\" = 0.5\n    }\n  }\n}\n```\n\n## Argument Reference\n\n* `name` - (Required) Name for the alias you are creating. Pattern: `(?!^[0-9]+$)([a-zA-Z0-9-_]+)`\n* `description` - (Optional) Description of the alias.\n* `function_name` - (Required) Lambda Function name or ARN.\n* `function_version` - (Required) Lambda function version for which you are creating the alias. Pattern: `(\\$LATEST|[0-9]+)`.\n* `routing_config` - (Optional) The Lambda alias' route configuration settings. Fields documented below\n\nFor **routing_config** the following attributes are supported:\n\n* `additional_version_weights` - (Optional) A map that defines the proportion of events that should be sent to different versions of a lambda function.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) identifying your Lambda function alias.\n* `invoke_arn` - The ARN to be used for invoking Lambda Function from API Gateway - to be used in [`aws_api_gateway_integration`](/docs/providers/aws/r/api_gateway_integration.html)'s `uri`\n\n[1]: http://docs.aws.amazon.com/lambda/latest/dg/welcome.html\n[2]: http://docs.aws.amazon.com/lambda/latest/dg/API_CreateAlias.html\n[3]: https://docs.aws.amazon.com/lambda/latest/dg/API_AliasRoutingConfiguration.html\n\n## Import\n\nLambda Function Aliases can be imported using the `function_name/alias`, e.g.,\n\n```\n$ terraform import aws_lambda_alias.test_lambda_alias my_test_lambda_function/my_alias\n```\n",
    "basename": "lambda_alias.html"
  },
  "lambda_code_signing_config.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_code_signing_config",
    "description": "Provides a Lambda Code Signing Config resource.",
    "preview": "# Resource: aws_lambda_code_signing_config\n\nProvides a Lambda Code …",
    "content": "\n\n# Resource: aws_lambda_code_signing_config\n\nProvides a Lambda Code Signing Config resource. A code signing configuration defines a list of allowed signing profiles and defines the code-signing validation policy (action to be taken if deployment validation checks fail).\n\nFor information about Lambda code signing configurations and how to use them, see [configuring code signing for Lambda functions][1]\n\n## Example Usage\n\n```terraform\nresource \"aws_lambda_code_signing_config\" \"new_csc\" {\n  allowed_publishers {\n    signing_profile_version_arns = [\n      aws_signer_signing_profile.example1.arn,\n      aws_signer_signing_profile.example2.arn,\n    ]\n  }\n\n  policies {\n    untrusted_artifact_on_deployment = \"Warn\"\n  }\n\n  description = \"My awesome code signing config.\"\n}\n```\n\n## Argument Reference\n\n* `allowed_publishers` (Required) A configuration block of allowed publishers as signing profiles for this code signing configuration. Detailed below.\n* `policies` (Optional) A configuration block of code signing policies that define the actions to take if the validation checks fail. Detailed below.\n* `description` - (Optional) Descriptive name for this code signing configuration.\n\nThe `allowed_publishers` block supports the following argument:\n\n* `signing_profile_version_arns` - (Required) The Amazon Resource Name (ARN) for each of the signing profiles. A signing profile defines a trusted user who can sign a code package.\n\nThe `policies` block supports the following argument:\n\n* `untrusted_artifact_on_deployment` - (Required) Code signing configuration policy for deployment validation failure. If you set the policy to Enforce, Lambda blocks the deployment request if code-signing validation checks fail. If you set the policy to Warn, Lambda allows the deployment and creates a CloudWatch log. Valid values: `Warn`, `Enforce`. Default value: `Warn`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the code signing configuration.\n* `config_id` - Unique identifier for the code signing configuration.\n* `last_modified` - The date and time that the code signing configuration was last modified.\n\n[1]: https://docs.aws.amazon.com/lambda/latest/dg/configuration-codesigning.html\n\n## Import\n\nCode Signing Configs can be imported using their ARN, e.g.,\n\n```\n$ terraform import aws_lambda_code_signing_config.imported_csc arn:aws:lambda:us-west-2:123456789012:code-signing-config:csc-0f6c334abcdea4d8b\n```\n",
    "basename": "lambda_code_signing_config.html"
  },
  "lambda_event_source_mapping.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_event_source_mapping",
    "description": "Provides a Lambda event source mapping. This allows Lambda functions to get events from Kinesis, DynamoDB, SQS, Amazon MQ and Managed Streaming for Apache Kafka (MSK).",
    "preview": "# Resource: aws_lambda_event_source_mapping\n\nProvides a Lambda event …",
    "content": "\n\n# Resource: aws_lambda_event_source_mapping\n\nProvides a Lambda event source mapping. This allows Lambda functions to get events from Kinesis, DynamoDB, SQS, Amazon MQ and Managed Streaming for Apache Kafka (MSK).\n\nFor information about Lambda and how to use it, see [What is AWS Lambda?][1].\nFor information about event source mappings, see [CreateEventSourceMapping][2] in the API docs.\n\n## Example Usage\n\n### DynamoDB\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  event_source_arn  = aws_dynamodb_table.example.stream_arn\n  function_name     = aws_lambda_function.example.arn\n  starting_position = \"LATEST\"\n}\n```\n\n### Kinesis\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  event_source_arn  = aws_kinesis_stream.example.arn\n  function_name     = aws_lambda_function.example.arn\n  starting_position = \"LATEST\"\n}\n```\n\n### Managed Streaming for Apache Kafka (MSK)\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  event_source_arn  = aws_msk_cluster.example.arn\n  function_name     = aws_lambda_function.example.arn\n  topics            = [\"Example\"]\n  starting_position = \"TRIM_HORIZON\"\n}\n```\n\n### Self Managed Apache Kafka\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  function_name     = aws_lambda_function.example.arn\n  topics            = [\"Example\"]\n  starting_position = \"TRIM_HORIZON\"\n\n  self_managed_event_source {\n    endpoints = {\n      KAFKA_BOOTSTRAP_SERVERS = \"kafka1.example.com:9092,kafka2.example.com:9092\"\n    }\n  }\n\n  source_access_configuration {\n    type = \"VPC_SUBNET\"\n    uri  = \"subnet:subnet-example1\"\n  }\n\n  source_access_configuration {\n    type = \"VPC_SUBNET\"\n    uri  = \"subnet:subnet-example2\"\n  }\n\n  source_access_configuration {\n    type = \"VPC_SECURITY_GROUP\"\n    uri  = \"security_group:sg-example\"\n  }\n}\n```\n\n### SQS\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  event_source_arn = aws_sqs_queue.sqs_queue_test.arn\n  function_name    = aws_lambda_function.example.arn\n}\n```\n\n### SQS with event filter\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  event_source_arn = aws_sqs_queue.sqs_queue_test.arn\n  function_name    = aws_lambda_function.example.arn\n\n  filter_criteria {\n    filter {\n      pattern = jsonencode({\n        body = {\n          Temperature : [{ numeric : [\">\", 0, \"<=\", 100] }]\n          Location : [\"New York\"]\n        }\n      })\n    }\n  }\n}\n```\n\n### Amazon MQ (ActiveMQ)\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  batch_size       = 10\n  event_source_arn = aws_mq_broker.example.arn\n  enabled          = true\n  function_name    = aws_lambda_function.example.arn\n  queues           = [\"example\"]\n\n  source_access_configuration {\n    type = \"BASIC_AUTH\"\n    uri  = aws_secretsmanager_secret_version.example.arn\n  }\n}\n```\n\n### Amazon MQ (RabbitMQ)\n\n```terraform\nresource \"aws_lambda_event_source_mapping\" \"example\" {\n  batch_size       = 1\n  event_source_arn = aws_mq_broker.example.arn\n  enabled          = true\n  function_name    = aws_lambda_function.example.arn\n  queues           = [\"example\"]\n\n  source_access_configuration {\n    type = \"VIRTUAL_HOST\"\n    uri  = \"/example\"\n  }\n\n  source_access_configuration {\n    type = \"BASIC_AUTH\"\n    uri  = aws_secretsmanager_secret_version.example.arn\n  }\n}\n```\n\n## Argument Reference\n\n* `batch_size` - (Optional) The largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to `100` for DynamoDB, Kinesis, MQ and MSK, `10` for SQS.\n* `bisect_batch_on_function_error`: - (Optional) If the function returns an error, split the batch in two and retry. Only available for stream sources (DynamoDB and Kinesis). Defaults to `false`.\n* `destination_config`: - (Optional) An Amazon SQS queue or Amazon SNS topic destination for failed records. Only available for stream sources (DynamoDB and Kinesis). Detailed below.\n* `enabled` - (Optional) Determines if the mapping will be enabled on creation. Defaults to `true`.\n* `event_source_arn` - (Optional) The event source ARN - this is required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker or MSK cluster.  It is incompatible with a Self Managed Kafka source.\n* `filter_criteria` - (Optional) The criteria to use for [event filtering](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html) Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.\n* `function_name` - (Required) The name or the ARN of the Lambda function that will be subscribing to events.\n* `function_response_types` - (Optional) A list of current response type enums applied to the event source mapping for [AWS Lambda checkpointing](https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-ddb-batchfailurereporting). Only available for stream sources (DynamoDB and Kinesis). Valid values: `ReportBatchItemFailures`.\n* `maximum_batching_window_in_seconds` - (Optional) The maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer (or accumulate in the case of an SQS queue event source) until either `maximum_batching_window_in_seconds` expires or `batch_size` has been met. For streaming event sources, defaults to as soon as records are available in the stream. If the batch it reads from the stream/queue only has one record in it, Lambda only sends one record to the function. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.\n* `maximum_record_age_in_seconds`: - (Optional) The maximum age of a record that Lambda sends to a function for processing. Only available for stream sources (DynamoDB and Kinesis). Must be either -1 (forever, and the default value) or between 60 and 604800 (inclusive).\n* `maximum_retry_attempts`: - (Optional) The maximum number of times to retry when the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of -1 (forever), maximum of 10000.\n* `parallelization_factor`: - (Optional) The number of batches to process from each shard concurrently. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of 1, maximum of 10.\n* `queues` - (Optional) The name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. A single queue name must be specified.\n* `self_managed_event_source`: - (Optional) For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include `source_access_configuration`. Detailed below.\n* `source_access_configuration`: (Optional) For Self Managed Kafka sources, the access configuration for the source. If set, configuration must also include `self_managed_event_source`. Detailed below.\n* `starting_position` - (Optional) The position in the stream where AWS Lambda should start reading. Must be one of `AT_TIMESTAMP` (Kinesis only), `LATEST` or `TRIM_HORIZON` if getting events from Kinesis, DynamoDB or MSK. Must not be provided if getting events from SQS. More information about these positions can be found in the [AWS DynamoDB Streams API Reference](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_streams_GetShardIterator.html) and [AWS Kinesis API Reference](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#Kinesis-GetShardIterator-request-ShardIteratorType).\n* `starting_position_timestamp` - (Optional) A timestamp in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) of the data record which to start reading when using `starting_position` set to `AT_TIMESTAMP`. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.\n* `topics` - (Optional) The name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.\n* `tumbling_window_in_seconds` - (Optional) The duration in seconds of a processing window for [AWS Lambda streaming analytics](https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html#services-kinesis-windows). The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).\n\n### destination_config Configuration Block\n\n* `on_failure` - (Optional) The destination configuration for failed invocations. Detailed below.\n\n#### destination_config on_failure Configuration Block\n\n* `destination_arn` - (Required) The Amazon Resource Name (ARN) of the destination resource.\n\n### filter_criteria Configuration Block\n\n* `filter` - (Optional) A set of up to 5 filter. If an event satisfies at least one, Lambda sends the event to the function or adds it to the next batch. Detailed below.\n\n#### filter_criteria filter Configuration Block\n\n* `pattern` - (Optional) A filter pattern up to 4096 characters. See [Filter Rule Syntax](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html#filtering-syntax).\n\n### self_managed_event_source Configuration Block\n\n* `endpoints` - (Required) A map of endpoints for the self managed source.  For Kafka self-managed sources, the key should be `KAFKA_BOOTSTRAP_SERVERS` and the value should be a string with a comma separated list of broker endpoints.\n\n### source_access_configuration Configuration Block\n\n* `type` - (Required) The type of this configuration.  For Self Managed Kafka you will need to supply blocks for type `VPC_SUBNET` and `VPC_SECURITY_GROUP`.\n* `uri` - (Required) The URI for this configuration.  For type `VPC_SUBNET` the value should be `subnet:subnet_id` where `subnet_id` is the value you would find in an aws_subnet resource's id attribute.  For type `VPC_SECURITY_GROUP` the value should be `security_group:security_group_id` where `security_group_id` is the value you would find in an aws_security_group resource's id attribute.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `function_arn` - The the ARN of the Lambda function the event source mapping is sending events to. (Note: this is a computed value that differs from `function_name` above.)\n* `last_modified` - The date this resource was last modified.\n* `last_processing_result` - The result of the last AWS Lambda invocation of your Lambda function.\n* `state` - The state of the event source mapping.\n* `state_transition_reason` - The reason the event source mapping is in its current state.\n* `uuid` - The UUID of the created event source mapping.\n\n\n[1]: http://docs.aws.amazon.com/lambda/latest/dg/welcome.html\n[2]: http://docs.aws.amazon.com/lambda/latest/dg/API_CreateEventSourceMapping.html\n\n\n## Import\n\nLambda event source mappings can be imported using the `UUID` (event source mapping identifier), e.g.,\n\n```\n$ terraform import aws_lambda_event_source_mapping.event_source_mapping 12345kxodurf3443\n```\n",
    "basename": "lambda_event_source_mapping.html"
  },
  "lambda_function.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_function",
    "description": "Provides a Lambda Function resource. Lambda allows you to trigger execution of code in response to events in AWS, enabling serverless backend solutions. The Lambda Function itself includes source code and runtime configuration.",
    "preview": "# Resource: aws_lambda_function\n\nProvides a Lambda Function …",
    "content": "\n\n# Resource: aws_lambda_function\n\nProvides a Lambda Function resource. Lambda allows you to trigger execution of code in response to events in AWS, enabling serverless backend solutions. The Lambda Function itself includes source code and runtime configuration.\n\nFor information about Lambda and how to use it, see [What is AWS Lambda?][1]\n\nFor a detailed example of setting up Lambda and API Gateway, see [Serverless Applications with AWS Lambda and API Gateway.][11]\n\n~> **NOTE:** Due to [AWS Lambda improved VPC networking changes that began deploying in September 2019](https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/), EC2 subnets and security groups associated with Lambda Functions can take up to 45 minutes to successfully delete. Terraform AWS Provider version 2.31.0 and later automatically handles this increased timeout, however prior versions require setting the customizable deletion timeouts of those Terraform resources to 45 minutes (`delete = \"45m\"`). AWS and HashiCorp are working together to reduce the amount of time required for resource deletion and updates can be tracked in this [GitHub issue](https://github.com/hashicorp/terraform-provider-aws/issues/10329).\n\n-> To give an external source (like an EventBridge Rule, SNS, or S3) permission to access the Lambda function, use the [`aws_lambda_permission`](lambda_permission.html) resource. See [Lambda Permission Model][4] for more details. On the other hand, the `role` argument of this resource is the function's execution role for identity and access to AWS services and resources.\n\n## Example Usage\n\n### Basic Example\n\n```terraform\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\n  filename      = \"lambda_function_payload.zip\"\n  function_name = \"lambda_function_name\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"index.test\"\n\n  # The filebase64sha256() function is available in Terraform 0.11.12 and later\n  # For Terraform 0.11.11 and earlier, use the base64sha256() function and the file() function:\n  # source_code_hash = \"${base64sha256(file(\"lambda_function_payload.zip\"))}\"\n  source_code_hash = filebase64sha256(\"lambda_function_payload.zip\")\n\n  runtime = \"nodejs12.x\"\n\n  environment {\n    variables = {\n      foo = \"bar\"\n    }\n  }\n}\n```\n\n### Lambda Layers\n\n~> **NOTE:** The `aws_lambda_layer_version` attribute values for `arn` and `layer_arn` were swapped in version 2.0.0 of the Terraform AWS Provider. For version 1.x, use `layer_arn` references. For version 2.x, use `arn` references.\n\n```terraform\nresource \"aws_lambda_layer_version\" \"example\" {\n  # ... other configuration ...\n}\n\nresource \"aws_lambda_function\" \"example\" {\n  # ... other configuration ...\n  layers = [aws_lambda_layer_version.example.arn]\n}\n```\n\n### Lambda File Systems\n\nLambda File Systems allow you to connect an Amazon Elastic File System (EFS) file system to a Lambda function to share data across function invocations, access existing data including large files, and save function state.\n\n```terraform\n# A lambda function connected to an EFS file system\nresource \"aws_lambda_function\" \"example\" {\n  # ... other configuration ...\n\n  file_system_config {\n    # EFS file system access point ARN\n    arn = aws_efs_access_point.access_point_for_lambda.arn\n\n    # Local mount path inside the lambda function. Must start with '/mnt/'.\n    local_mount_path = \"/mnt/efs\"\n  }\n\n  vpc_config {\n    # Every subnet should be able to reach an EFS mount target in the same Availability Zone. Cross-AZ mounts are not permitted.\n    subnet_ids         = [aws_subnet.subnet_for_lambda.id]\n    security_group_ids = [aws_security_group.sg_for_lambda.id]\n  }\n\n  # Explicitly declare dependency on EFS mount target.\n  # When creating or updating Lambda functions, mount target must be in 'available' lifecycle state.\n  depends_on = [aws_efs_mount_target.alpha]\n}\n\n# EFS file system\nresource \"aws_efs_file_system\" \"efs_for_lambda\" {\n  tags = {\n    Name = \"efs_for_lambda\"\n  }\n}\n\n# Mount target connects the file system to the subnet\nresource \"aws_efs_mount_target\" \"alpha\" {\n  file_system_id  = aws_efs_file_system.efs_for_lambda.id\n  subnet_id       = aws_subnet.subnet_for_lambda.id\n  security_groups = [aws_security_group.sg_for_lambda.id]\n}\n\n# EFS access point used by lambda file system\nresource \"aws_efs_access_point\" \"access_point_for_lambda\" {\n  file_system_id = aws_efs_file_system.efs_for_lambda.id\n\n  root_directory {\n    path = \"/lambda\"\n    creation_info {\n      owner_gid   = 1000\n      owner_uid   = 1000\n      permissions = \"777\"\n    }\n  }\n\n  posix_user {\n    gid = 1000\n    uid = 1000\n  }\n}\n```\n\n### Lambda retries\n\nLambda Functions allow you to configure error handling for asynchronous invocation. The settings that it supports are `Maximum age of event` and `Retry attempts` as stated in [Lambda documentation for Configuring error handling for asynchronous invocation](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-errors). To configure these settings, refer to the [aws_lambda_function_event_invoke_config resource](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function_event_invoke_config).\n\n## CloudWatch Logging and Permissions\n\nFor more information about CloudWatch Logs for Lambda, see the [Lambda User Guide](https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-logs.html).\n\n```terraform\nvariable \"lambda_function_name\" {\n  default = \"lambda_function_name\"\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\n  function_name = var.lambda_function_name\n\n  # ... other configuration ...\n  depends_on = [\n    aws_iam_role_policy_attachment.lambda_logs,\n    aws_cloudwatch_log_group.example,\n  ]\n}\n\n# This is to optionally manage the CloudWatch Log Group for the Lambda Function.\n# If skipping this resource configuration, also add \"logs:CreateLogGroup\" to the IAM policy below.\nresource \"aws_cloudwatch_log_group\" \"example\" {\n  name              = \"/aws/lambda/${var.lambda_function_name}\"\n  retention_in_days = 14\n}\n\n# See also the following AWS managed policy: AWSLambdaBasicExecutionRole\nresource \"aws_iam_policy\" \"lambda_logging\" {\n  name        = \"lambda_logging\"\n  path        = \"/\"\n  description = \"IAM policy for logging from a lambda\"\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:*:*:*\",\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"lambda_logs\" {\n  role       = aws_iam_role.iam_for_lambda.name\n  policy_arn = aws_iam_policy.lambda_logging.arn\n}\n```\n\n## Specifying the Deployment Package\n\nAWS Lambda expects source code to be provided as a deployment package whose structure varies depending on which `runtime` is in use. See [Runtimes][6] for the valid values of `runtime`. The expected structure of the deployment package can be found in [the AWS Lambda documentation for each runtime][8].\n\nOnce you have created your deployment package you can specify it either directly as a local file (using the `filename` argument) or indirectly via Amazon S3 (using the `s3_bucket`, `s3_key` and `s3_object_version` arguments). When providing the deployment package via S3 it may be useful to use [the `aws_s3_bucket_object` resource](s3_bucket_object.html) to upload it.\n\nFor larger deployment packages it is recommended by Amazon to upload via S3, since the S3 API has better support for uploading large files efficiently.\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `function_name` - (Required) Unique name for your Lambda Function.\n* `role` - (Required) Amazon Resource Name (ARN) of the function's execution role. The role provides the function's identity and access to AWS services and resources.\n\nThe following arguments are optional:\n\n* `architectures` - (Optional) Instruction set architecture for your Lambda function. Valid values are `[\"x86_64\"]` and `[\"arm64\"]`. Default is `[\"x86_64\"]`. Removing this attribute, function's architecture stay the same.\n* `code_signing_config_arn` - (Optional) To enable code signing for this function, specify the ARN of a code-signing configuration. A code-signing configuration includes a set of signing profiles, which define the trusted publishers for this function.\n* `dead_letter_config` - (Optional) Configuration block. Detailed below.\n* `description` - (Optional) Description of what your Lambda Function does.\n* `environment` - (Optional) Configuration block. Detailed below.\n* `file_system_config` - (Optional) Configuration block. Detailed below.\n* `filename` - (Optional) Path to the function's deployment package within the local filesystem. Conflicts with `image_uri`, `s3_bucket`, `s3_key`, and `s3_object_version`.\n* `handler` - (Optional) Function [entrypoint][3] in your code.\n* `image_config` - (Optional) Configuration block. Detailed below.\n* `image_uri` - (Optional) ECR image URI containing the function's deployment package. Conflicts with `filename`, `s3_bucket`, `s3_key`, and `s3_object_version`.\n* `kms_key_arn` - (Optional) Amazon Resource Name (ARN) of the AWS Key Management Service (KMS) key that is used to encrypt environment variables. If this configuration is not provided when environment variables are in use, AWS Lambda uses a default service key. If this configuration is provided when environment variables are not in use, the AWS Lambda API does not save this configuration and Terraform will show a perpetual difference of adding the key. To fix the perpetual difference, remove this configuration.\n* `layers` - (Optional) List of Lambda Layer Version ARNs (maximum of 5) to attach to your Lambda Function. See [Lambda Layers][10]\n* `memory_size` - (Optional) Amount of memory in MB your Lambda Function can use at runtime. Defaults to `128`. See [Limits][5]\n* `package_type` - (Optional) Lambda deployment package type. Valid values are `Zip` and `Image`. Defaults to `Zip`.\n* `publish` - (Optional) Whether to publish creation/change as new Lambda Function Version. Defaults to `false`.\n* `reserved_concurrent_executions` - (Optional) Amount of reserved concurrent executions for this lambda function. A value of `0` disables lambda from being triggered and `-1` removes any concurrency limitations. Defaults to Unreserved Concurrency Limits `-1`. See [Managing Concurrency][9]\n* `runtime` - (Optional) Identifier of the function's runtime. See [Runtimes][6] for valid values.\n* `s3_bucket` - (Optional) S3 bucket location containing the function's deployment package. Conflicts with `filename` and `image_uri`. This bucket must reside in the same AWS region where you are creating the Lambda function.\n* `s3_key` - (Optional) S3 key of an object containing the function's deployment package. Conflicts with `filename` and `image_uri`.\n* `s3_object_version` - (Optional) Object version containing the function's deployment package. Conflicts with `filename` and `image_uri`.\n* `source_code_hash` - (Optional) Used to trigger updates. Must be set to a base64-encoded SHA256 hash of the package file specified with either `filename` or `s3_key`. The usual way to set this is `filebase64sha256(\"file.zip\")` (Terraform 0.11.12 and later) or `base64sha256(file(\"file.zip\"))` (Terraform 0.11.11 and earlier), where \"file.zip\" is the local filename of the lambda function source archive.\n* `tags` - (Optional) Map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `timeout` - (Optional) Amount of time your Lambda Function has to run in seconds. Defaults to `3`. See [Limits][5].\n* `tracing_config` - (Optional) Configuration block. Detailed below.\n* `vpc_config` - (Optional) Configuration block. Detailed below.\n\n### dead_letter_config\n\nDead letter queue configuration that specifies the queue or topic where Lambda sends asynchronous events when they fail processing. For more information, see [Dead Letter Queues](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#dlq).\n\n* `target_arn` - (Required) ARN of an SNS topic or SQS queue to notify when an invocation fails. If this option is used, the function's IAM role must be granted suitable access to write to the target object, which means allowing either the `sns:Publish` or `sqs:SendMessage` action on this ARN, depending on which service is targeted.\n\n### environment\n\n* `variables` - (Optional) Map of environment variables that are accessible from the function code during execution.\n\n### file_system_config\n\nConnection settings for an EFS file system. Before creating or updating Lambda functions with `file_system_config`, EFS mount targets must be in available lifecycle state. Use `depends_on` to explicitly declare this dependency. See [Using Amazon EFS with Lambda][12].\n\n* `arn` - (Required) Amazon Resource Name (ARN) of the Amazon EFS Access Point that provides access to the file system.\n* `local_mount_path` - (Required) Path where the function can access the file system, starting with /mnt/.\n\n### image_config\n\nContainer image configuration values that override the values in the container image Dockerfile.\n\n* `command` - (Optional) Parameters that you want to pass in with `entry_point`.\n* `entry_point` - (Optional) Entry point to your application, which is typically the location of the runtime executable.\n* `working_directory` - (Optional) Working directory.\n\n### tracing_config\n\n* `mode` - (Required) Whether to to sample and trace a subset of incoming requests with AWS X-Ray. Valid values are `PassThrough` and `Active`. If `PassThrough`, Lambda will only trace the request from an upstream service if it contains a tracing header with \"sampled=1\". If `Active`, Lambda will respect any tracing header it receives from an upstream service. If no tracing header is received, Lambda will call X-Ray for a tracing decision.\n\n### vpc_config\n\nFor network connectivity to AWS resources in a VPC, specify a list of security groups and subnets in the VPC. When you connect a function to a VPC, it can only access resources and the internet through that VPC. See [VPC Settings][7].\n\n~> **NOTE:** If both `subnet_ids` and `security_group_ids` are empty then `vpc_config` is considered to be empty or unset.\n\n* `security_group_ids` - (Required) List of security group IDs associated with the Lambda function.\n* `subnet_ids` - (Required) List of subnet IDs associated with the Lambda function.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) identifying your Lambda Function.\n* `invoke_arn` - ARN to be used for invoking Lambda Function from API Gateway - to be used in [`aws_api_gateway_integration`](/docs/providers/aws/r/api_gateway_integration.html)'s `uri`.\n* `last_modified` - Date this resource was last modified.\n* `qualified_arn` - ARN identifying your Lambda Function Version (if versioning is enabled via `publish = true`).\n* `signing_job_arn` - ARN of the signing job.\n* `signing_profile_version_arn` - ARN of the signing profile version.\n* `source_code_size` - Size in bytes of the function .zip file.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version` - Latest published version of your Lambda Function.\n* `vpc_config.vpc_id` - ID of the VPC.\n\n[1]: https://docs.aws.amazon.com/lambda/latest/dg/welcome.html\n[2]: https://docs.aws.amazon.com/lambda/latest/dg/walkthrough-s3-events-adminuser-create-test-function-create-function.html\n[3]: https://docs.aws.amazon.com/lambda/latest/dg/walkthrough-custom-events-create-test-function.html\n[4]: https://docs.aws.amazon.com/lambda/latest/dg/intro-permission-model.html\n[5]: https://docs.aws.amazon.com/lambda/latest/dg/limits.html\n[6]: https://docs.aws.amazon.com/lambda/latest/dg/API_CreateFunction.html#SSS-CreateFunction-request-Runtime\n[7]: https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html\n[8]: https://docs.aws.amazon.com/lambda/latest/dg/deployment-package-v2.html\n[9]: https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html\n[10]: https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\n[11]: https://learn.hashicorp.com/terraform/aws/lambda-api-gateway\n[12]: https://docs.aws.amazon.com/lambda/latest/dg/services-efs.html\n[13]: https://docs.aws.amazon.com/lambda/latest/dg/lambda-images.html\n\n## Timeouts\n\n`aws_lambda_function` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `10m`) How long to wait for slow uploads or EC2 throttling errors.\n\n## Import\n\nLambda Functions can be imported using the `function_name`, e.g.,\n\n```\n$ terraform import aws_lambda_function.test_lambda my_test_lambda_function\n```\n",
    "basename": "lambda_function.html"
  },
  "lambda_function_event_invoke_config.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_function_event_invoke_config",
    "description": "Manages an asynchronous invocation configuration for a Lambda Function or Alias.",
    "preview": "# Resource: aws_lambda_function_event_invoke_config\n\nManages an …",
    "content": "\n\n# Resource: aws_lambda_function_event_invoke_config\n\nManages an asynchronous invocation configuration for a Lambda Function or Alias. More information about asynchronous invocations and the configurable values can be found in the [Lambda Developer Guide](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html).\n\n## Example Usage\n\n### Destination Configuration\n\n~> **NOTE:** Ensure the Lambda Function IAM Role has necessary permissions for the destination, such as `sqs:SendMessage` or `sns:Publish`, otherwise the API will return a generic `InvalidParameterValueException: The destination ARN arn:PARTITION:SERVICE:REGION:ACCOUNT:RESOURCE is invalid.` error.\n\n```terraform\nresource \"aws_lambda_function_event_invoke_config\" \"example\" {\n  function_name = aws_lambda_alias.example.function_name\n\n  destination_config {\n    on_failure {\n      destination = aws_sqs_queue.example.arn\n    }\n\n    on_success {\n      destination = aws_sns_topic.example.arn\n    }\n  }\n}\n```\n\n### Error Handling Configuration\n\n```terraform\nresource \"aws_lambda_function_event_invoke_config\" \"example\" {\n  function_name                = aws_lambda_alias.example.function_name\n  maximum_event_age_in_seconds = 60\n  maximum_retry_attempts       = 0\n}\n```\n\n### Configuration for Alias Name\n\n```terraform\nresource \"aws_lambda_function_event_invoke_config\" \"example\" {\n  function_name = aws_lambda_alias.example.function_name\n  qualifier     = aws_lambda_alias.example.name\n\n  # ... other configuration ...\n}\n```\n\n### Configuration for Function Latest Unpublished Version\n\n```terraform\nresource \"aws_lambda_function_event_invoke_config\" \"example\" {\n  function_name = aws_lambda_function.example.function_name\n  qualifier     = \"$LATEST\"\n\n  # ... other configuration ...\n}\n```\n\n### Configuration for Function Published Version\n\n```terraform\nresource \"aws_lambda_function_event_invoke_config\" \"example\" {\n  function_name = aws_lambda_function.example.function_name\n  qualifier     = aws_lambda_function.example.version\n\n  # ... other configuration ...\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `function_name` - (Required) Name or Amazon Resource Name (ARN) of the Lambda Function, omitting any version or alias qualifier.\n\nThe following arguments are optional:\n\n* `destination_config` - (Optional) Configuration block with destination configuration. See below for details.\n* `maximum_event_age_in_seconds` - (Optional) Maximum age of a request that Lambda sends to a function for processing in seconds. Valid values between 60 and 21600.\n* `maximum_retry_attempts` - (Optional) Maximum number of times to retry when the function returns an error. Valid values between 0 and 2. Defaults to 2.\n* `qualifier` - (Optional) Lambda Function published version, `$LATEST`, or Lambda Alias name.\n\n### destination_config Configuration Block\n\n~> **NOTE:** At least one of `on_failure` or `on_success` must be configured when using this configuration block, otherwise remove it completely to prevent perpetual differences in Terraform runs.\n\nThe following arguments are optional:\n\n* `on_failure` - (Optional) Configuration block with destination configuration for failed asynchronous invocations. See below for details.\n* `on_success` - (Optional) Configuration block with destination configuration for successful asynchronous invocations. See below for details.\n\n#### destination_config on_failure Configuration Block\n\nThe following arguments are required:\n\n* `destination` - (Required) Amazon Resource Name (ARN) of the destination resource. See the [Lambda Developer Guide](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations) for acceptable resource types and associated IAM permissions.\n\n#### destination_config on_success Configuration Block\n\nThe following arguments are required:\n\n* `destination` - (Required) Amazon Resource Name (ARN) of the destination resource. See the [Lambda Developer Guide](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations) for acceptable resource types and associated IAM permissions.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Fully qualified Lambda Function name or Amazon Resource Name (ARN)\n\n## Import\n\nLambda Function Event Invoke Configs can be imported using the fully qualified Function name or Amazon Resource Name (ARN), e.g.,\n\nARN without qualifier (all versions and aliases):\n\n```\n$ terraform import aws_lambda_function_event_invoke_config.example arn:aws:us-east-1:123456789012:function:my_function\n```\n\nARN with qualifier:\n\n```\n$ terraform import aws_lambda_function_event_invoke_config.example arn:aws:us-east-1:123456789012:function:my_function:production\n```\n\nName without qualifier (all versions and aliases):\n\n```\n$ terraform import aws_lambda_function_event_invoke_config.example my_function\n```\n\nName with qualifier:\n\n```\n$ terraform import aws_lambda_function_event_invoke_config.example my_function:production\n```\n",
    "basename": "lambda_function_event_invoke_config.html"
  },
  "lambda_layer_version.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_layer_version",
    "description": "Provides a Lambda Layer Version resource. Lambda Layers allow you to reuse shared bits of code across multiple lambda functions.",
    "preview": "# Resource: aws_lambda_layer_version\n\nProvides a Lambda Layer …",
    "content": "\n\n# Resource: aws_lambda_layer_version\n\nProvides a Lambda Layer Version resource. Lambda Layers allow you to reuse shared bits of code across multiple lambda functions.\n\nFor information about Lambda Layers and how to use them, see [AWS Lambda Layers][1].\n\n~> **NOTE:** Setting `skip_destroy` to `true` means that the AWS Provider will _not_ destroy any layer version, even when running `terraform destroy`. Layer versions are thus intentional dangling resources that are _not_ managed by Terraform and may incur extra expense in your AWS account.\n\n## Example Usage\n\n```terraform\nresource \"aws_lambda_layer_version\" \"lambda_layer\" {\n  filename   = \"lambda_layer_payload.zip\"\n  layer_name = \"lambda_layer_name\"\n\n  compatible_runtimes = [\"nodejs12.x\"]\n}\n```\n\n## Specifying the Deployment Package\n\nAWS Lambda Layers expect source code to be provided as a deployment package whose structure varies depending on which `compatible_runtimes` this layer specifies.\nSee [Runtimes][2] for the valid values of `compatible_runtimes`.\n\nOnce you have created your deployment package you can specify it either directly as a local file (using the `filename` argument) or\nindirectly via Amazon S3 (using the `s3_bucket`, `s3_key` and `s3_object_version` arguments). When providing the deployment\npackage via S3 it may be useful to use [the `aws_s3_bucket_object` resource](s3_bucket_object.html) to upload it.\n\nFor larger deployment packages it is recommended by Amazon to upload via S3, since the S3 API has better support for uploading large files efficiently.\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `layer_name` - (Required) Unique name for your Lambda Layer\n\nThe following arguments are optional:\n\n* `compatible_architectures` - (Optional) List of [Architectures][4] this layer is compatible with. Currently `x86_64` and `arm64` can be specified.\n* `compatible_runtimes` - (Optional) List of [Runtimes][2] this layer is compatible with. Up to 5 runtimes can be specified.\n* `description` - (Optional) Description of what your Lambda Layer does.\n* `filename` (Optional) Path to the function's deployment package within the local filesystem. If defined, The `s3_`-prefixed options cannot be used.\n* `license_info` - (Optional) License info for your Lambda Layer. See [License Info][3].\n* `s3_bucket` - (Optional) S3 bucket location containing the function's deployment package. Conflicts with `filename`. This bucket must reside in the same AWS region where you are creating the Lambda function.\n* `s3_key` - (Optional) S3 key of an object containing the function's deployment package. Conflicts with `filename`.\n* `s3_object_version` - (Optional) Object version containing the function's deployment package. Conflicts with `filename`.\n* `skip_destroy` - (Optional) Whether to retain the old version of a previously deployed Lambda Layer. Default is `false`. When this is not set to `true`, changing any of `compatible_architectures`, `compatible_runtimes`, `description`, `filename`, `layer_name`, `license_info`, `s3_bucket`, `s3_key`, `s3_object_version`, or `source_code_hash` forces deletion of the existing layer version and creation of a new layer version.\n* `source_code_hash` - (Optional) Used to trigger updates. Must be set to a base64-encoded SHA256 hash of the package file specified with either `filename` or `s3_key`. The usual way to set this is `${filebase64sha256(\"file.zip\")}` (Terraform 0.11.12 or later) or `${base64sha256(file(\"file.zip\"))}` (Terraform 0.11.11 and earlier), where \"file.zip\" is the local filename of the lambda layer source archive.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the Lambda Layer with version.\n* `created_date` - Date this resource was created.\n* `layer_arn` - ARN of the Lambda Layer without version.\n* `signing_job_arn` - ARN of a signing job.\n* `signing_profile_version_arn` - ARN for a signing profile version.\n* `source_code_size` - Size in bytes of the function .zip file.\n* `version` - Lambda Layer version.\n\n[1]: https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\n[2]: https://docs.aws.amazon.com/lambda/latest/dg/API_PublishLayerVersion.html#SSS-PublishLayerVersion-request-CompatibleRuntimes\n[3]: https://docs.aws.amazon.com/lambda/latest/dg/API_PublishLayerVersion.html#SSS-PublishLayerVersion-request-LicenseInfo\n[4]: https://docs.aws.amazon.com/lambda/latest/dg/API_PublishLayerVersion.html#SSS-PublishLayerVersion-request-CompatibleArchitectures\n\n## Import\n\nLambda Layers can be imported using `arn`.\n\n```\n$ terraform import \\\n    aws_lambda_layer_version.test_layer \\\n    arn:aws:lambda:_REGION_:_ACCOUNT_ID_:layer:_LAYER_NAME_:_LAYER_VERSION_\n```\n",
    "basename": "lambda_layer_version.html"
  },
  "lambda_layer_version_permission.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_layer_version_permission",
    "description": "Provides a Lambda Layer Version Permission resource.",
    "preview": "# Resource: aws_lambda_layer_version_permission\n\nProvides a Lambda …",
    "content": "\n\n# Resource: aws_lambda_layer_version_permission\n\nProvides a Lambda Layer Version Permission resource. It allows you to share you own Lambda Layers to another account by account ID, to all accounts in AWS organization or even to all AWS accounts.\n\nFor information about Lambda Layer Permissions and how to use them, see [Using Resource-based Policies for AWS Lambda][1]\n\n## Example Usage\n\n```terraform\nresource \"aws_lambda_layer_version_permission\" \"lambda_layer_permission\" {\n  layer_name     = \"arn:aws:lambda:us-west-2:123456654321:layer:test_layer1\"\n  version_number = 1\n  principal      = \"111111111111\"\n  action         = \"lambda:GetLayerVersion\"\n  statement_id   = \"dev-account\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `action` - (Required) Action, which will be allowed. `lambda:GetLayerVersion` value is suggested by AWS documantation.\n* `layer_name` (Required) The name or ARN of the Lambda Layer, which you want to grant access to.\n* `organization_id` - (Optional) An identifier of AWS Organization, which should be able to use your Lambda Layer. `principal` should be equal to `*` if `organization_id` provided.\n* `principal` - (Required) AWS account ID which should be able to use your Lambda Layer. `*` can be used here, if you want to share your Lambda Layer widely.\n* `statement_id` - (Required) The name of Lambda Layer Permission, for example `dev-account` - human readable note about what is this permission for.\n* `version_number` (Required) Version of Lambda Layer, which you want to grant access to. Note: permissions only apply to a single version of a layer.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The `layer_name` and `version_number`, separated by a comma (`,`).\n* `revision_id` - A unique identifier for the current revision of the policy.\n* `policy` - Full Lambda Layer Permission policy.\n\n## Import\n\nLambda Layer Permissions can be imported using `layer_name` and `version_number`, separated by a comma (`,`).\n\n```sh\n$ terraform import aws_lambda_layer_version_permission.example arn:aws:lambda:us-west-2:123456654321:layer:test_layer1,1\n```\n\n[1]: https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html#permissions-resource-xaccountlayer\n",
    "basename": "lambda_layer_version_permission.html"
  },
  "lambda_permission.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_permission",
    "description": "Creates a Lambda function permission.",
    "preview": "# Resource: aws_lambda_permission\n\nGives an external source (like an …",
    "content": "\n\n# Resource: aws_lambda_permission\n\nGives an external source (like an EventBridge Rule, SNS, or S3) permission to access the Lambda function.\n\n## Example Usage\n\n```terraform\nresource \"aws_lambda_permission\" \"allow_cloudwatch\" {\n  statement_id  = \"AllowExecutionFromCloudWatch\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.test_lambda.function_name\n  principal     = \"events.amazonaws.com\"\n  source_arn    = \"arn:aws:events:eu-west-1:111122223333:rule/RunDaily\"\n  qualifier     = aws_lambda_alias.test_alias.name\n}\n\nresource \"aws_lambda_alias\" \"test_alias\" {\n  name             = \"testalias\"\n  description      = \"a sample description\"\n  function_name    = aws_lambda_function.test_lambda.function_name\n  function_version = \"$LATEST\"\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\n  filename      = \"lambdatest.zip\"\n  function_name = \"lambda_function_name\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"exports.handler\"\n  runtime       = \"nodejs12.x\"\n}\n\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Sid    = \"\"\n        Principal = {\n          Service = \"lambda.amazonaws.com\"\n        }\n      },\n    ]\n  })\n}\n```\n\n## Usage with SNS\n\n```terraform\nresource \"aws_lambda_permission\" \"with_sns\" {\n  statement_id  = \"AllowExecutionFromSNS\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.func.function_name\n  principal     = \"sns.amazonaws.com\"\n  source_arn    = aws_sns_topic.default.arn\n}\n\nresource \"aws_sns_topic\" \"default\" {\n  name = \"call-lambda-maybe\"\n}\n\nresource \"aws_sns_topic_subscription\" \"lambda\" {\n  topic_arn = aws_sns_topic.default.arn\n  protocol  = \"lambda\"\n  endpoint  = aws_lambda_function.func.arn\n}\n\nresource \"aws_lambda_function\" \"func\" {\n  filename      = \"lambdatest.zip\"\n  function_name = \"lambda_called_from_sns\"\n  role          = aws_iam_role.default.arn\n  handler       = \"exports.handler\"\n  runtime       = \"python3.6\"\n}\n\nresource \"aws_iam_role\" \"default\" {\n  name = \"iam_for_lambda_with_sns\"\n\n  # Terraform's \"jsonencode\" function converts a\n  # Terraform expression result to valid JSON syntax.\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Sid    = \"\"\n        Principal = {\n          Service = \"lambda.amazonaws.com\"\n        }\n      },\n    ]\n  })\n}\n```\n\n## Specify Lambda permissions for API Gateway REST API\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"MyDemoAPI\" {\n  name        = \"MyDemoAPI\"\n  description = \"This is my API for demonstration purposes\"\n}\n\nresource \"aws_lambda_permission\" \"lambda_permission\" {\n  statement_id  = \"AllowMyDemoAPIInvoke\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = \"MyDemoFunction\"\n  principal     = \"apigateway.amazonaws.com\"\n\n  # The /*/*/* part allows invocation from any stage, method and resource path\n  # within API Gateway REST API.\n  source_arn = \"${aws_api_gateway_rest_api.MyDemoAPI.execution_arn}/*/*/*\"\n}\n```\n\n## Usage with CloudWatch log group\n\n```terraform\nresource \"aws_lambda_permission\" \"logging\" {\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.logging.function_name\n  principal     = \"logs.eu-west-1.amazonaws.com\"\n  source_arn    = \"${aws_cloudwatch_log_group.default.arn}:*\"\n}\n\nresource \"aws_cloudwatch_log_group\" \"default\" {\n  name = \"/default\"\n}\n\nresource \"aws_cloudwatch_log_subscription_filter\" \"logging\" {\n  depends_on      = [aws_lambda_permission.logging]\n  destination_arn = aws_lambda_function.logging.arn\n  filter_pattern  = \"\"\n  log_group_name  = aws_cloudwatch_log_group.default.name\n  name            = \"logging_default\"\n}\n\nresource \"aws_lambda_function\" \"logging\" {\n  filename      = \"lamba_logging.zip\"\n  function_name = \"lambda_called_from_cloudwatch_logs\"\n  handler       = \"exports.handler\"\n  role          = aws_iam_role.default.arn\n  runtime       = \"python3.6\"\n}\n\nresource \"aws_iam_role\" \"default\" {\n  name = \"iam_for_lambda_called_from_cloudwatch_logs\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n```\n\n## Argument Reference\n\n* `action` - (Required) The AWS Lambda action you want to allow in this statement. (e.g., `lambda:InvokeFunction`)\n* `event_source_token` - (Optional) The Event Source Token to validate.  Used with [Alexa Skills][1].\n* `function_name` - (Required) Name of the Lambda function whose resource policy you are updating\n* `principal` - (Required) The principal who is getting this permissionE.g., `s3.amazonaws.com`, an AWS account ID, or any valid AWS service principal such as `events.amazonaws.com` or `sns.amazonaws.com`.\n* `qualifier` - (Optional) Query parameter to specify function version or alias name. The permission will then apply to the specific qualified ARNE.g., `arn:aws:lambda:aws-region:acct-id:function:function-name:2`\n* `source_account` - (Optional) This parameter is used for S3 and SES. The AWS account ID (without a hyphen) of the source owner.\n* `source_arn` - (Optional) When the principal is an AWS service, the ARN of the specific resource within that service to grant permission to.\n  Without this, any resource from `principal` will be granted permission – even if that resource is from another account.\n  For S3, this should be the ARN of the S3 Bucket.\n  For EventBridge events, this should be the ARN of the EventBridge Rule.\n  For API Gateway, this should be the ARN of the API, as described [here][2].\n* `statement_id` - (Optional) A unique statement identifier. By default generated by Terraform.\n* `statement_id_prefix` - (Optional) A statement identifier prefix. Terraform will generate a unique suffix. Conflicts with `statement_id`.\n\n[1]: https://developer.amazon.com/docs/custom-skills/host-a-custom-skill-as-an-aws-lambda-function.html#use-aws-cli\n[2]: https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-control-access-using-iam-policies-to-invoke-api.html\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nLambda permission statements can be imported using function_name/statement_id, with an optional qualifier, e.g.,\n\n```\n$ terraform import aws_lambda_permission.test_lambda_permission my_test_lambda_function/AllowExecutionFromCloudWatch\n\n$ terraform import aws_lambda_permission.test_lambda_permission my_test_lambda_function:qualifier_name/AllowExecutionFromCloudWatch\n```\n",
    "basename": "lambda_permission.html"
  },
  "lambda_provisioned_concurrency_config.html": {
    "subcategory": "Lambda",
    "layout": "aws",
    "page_title": "AWS: aws_lambda_provisioned_concurrency_config",
    "description": "Manages a Lambda Provisioned Concurrency Configuration",
    "preview": "# Resource: aws_lambda_provisioned_concurrency_config\n\nManages a …",
    "content": "\n\n# Resource: aws_lambda_provisioned_concurrency_config\n\nManages a Lambda Provisioned Concurrency Configuration.\n\n## Example Usage\n\n### Alias Name\n\n```terraform\nresource \"aws_lambda_provisioned_concurrency_config\" \"example\" {\n  function_name                     = aws_lambda_alias.example.function_name\n  provisioned_concurrent_executions = 1\n  qualifier                         = aws_lambda_alias.example.name\n}\n```\n\n### Function Version\n\n```terraform\nresource \"aws_lambda_provisioned_concurrency_config\" \"example\" {\n  function_name                     = aws_lambda_function.example.function_name\n  provisioned_concurrent_executions = 1\n  qualifier                         = aws_lambda_function.example.version\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `function_name` - (Required) Name or Amazon Resource Name (ARN) of the Lambda Function.\n* `provisioned_concurrent_executions` - (Required) Amount of capacity to allocate. Must be greater than or equal to `1`.\n* `qualifier` - (Required) Lambda Function version or Lambda Alias name.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Lambda Function name and qualifier separated by a colon (`:`).\n\n## Timeouts\n\n`aws_lambda_provisioned_concurrency_config` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `15 minutes`) How long to wait for the Lambda Provisioned Concurrency Config to be ready on creation.\n* `update` - (Default `15 minutes`) How long to wait for the Lambda Provisioned Concurrency Config to be ready on update.\n\n## Import\n\nLambda Provisioned Concurrency Configs can be imported using the `function_name` and `qualifier` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_lambda_provisioned_concurrency_config.example my_function:production\n```\n",
    "basename": "lambda_provisioned_concurrency_config.html"
  },
  "launch_configuration.html": {
    "subcategory": "Autoscaling",
    "layout": "aws",
    "page_title": "AWS: aws_launch_configuration",
    "description": "Provides a resource to create a new launch configuration, used for autoscaling groups.",
    "preview": "# Resource: aws_launch_configuration\n\nProvides a resource to create …",
    "content": "\n\n# Resource: aws_launch_configuration\n\nProvides a resource to create a new launch configuration, used for autoscaling groups.\n\n## Example Usage\n\n```terraform\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-trusty-14.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n\n  owners = [\"099720109477\"] # Canonical\n}\n\nresource \"aws_launch_configuration\" \"as_conf\" {\n  name          = \"web_config\"\n  image_id      = data.aws_ami.ubuntu.id\n  instance_type = \"t2.micro\"\n}\n```\n\n## Using with AutoScaling Groups\n\nLaunch Configurations cannot be updated after creation with the Amazon\nWeb Service API. In order to update a Launch Configuration, Terraform will\ndestroy the existing resource and create a replacement. In order to effectively\nuse a Launch Configuration resource with an [AutoScaling Group resource][1],\nit's recommended to specify `create_before_destroy` in a [lifecycle][2] block.\nEither omit the Launch Configuration `name` attribute, or specify a partial name\nwith `name_prefix`.  Example:\n\n```terraform\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-trusty-14.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n\n  owners = [\"099720109477\"] # Canonical\n}\n\nresource \"aws_launch_configuration\" \"as_conf\" {\n  name_prefix   = \"terraform-lc-example-\"\n  image_id      = data.aws_ami.ubuntu.id\n  instance_type = \"t2.micro\"\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_autoscaling_group\" \"bar\" {\n  name                 = \"terraform-asg-example\"\n  launch_configuration = aws_launch_configuration.as_conf.name\n  min_size             = 1\n  max_size             = 2\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\nWith this setup Terraform generates a unique name for your Launch\nConfiguration and can then update the AutoScaling Group without conflict before\ndestroying the previous Launch Configuration.\n\n## Using with Spot Instances\n\nLaunch configurations can set the spot instance pricing to be used for the\nAuto Scaling Group to reserve instances. Simply specifying the `spot_price`\nparameter will set the price on the Launch Configuration which will attempt to\nreserve your instances at this price.  See the [AWS Spot Instance\ndocumentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html)\nfor more information or how to launch [Spot Instances][3] with Terraform.\n\n```terraform\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-trusty-14.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n\n  owners = [\"099720109477\"] # Canonical\n}\n\nresource \"aws_launch_configuration\" \"as_conf\" {\n  image_id      = data.aws_ami.ubuntu.id\n  instance_type = \"m4.large\"\n  spot_price    = \"0.001\"\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_autoscaling_group\" \"bar\" {\n  name                 = \"terraform-asg-example\"\n  launch_configuration = aws_launch_configuration.as_conf.name\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the launch configuration. If you leave\n  this blank, Terraform will auto-generate a unique name. Conflicts with `name_prefix`.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified\n  prefix. Conflicts with `name`.\n* `image_id` - (Required) The EC2 image ID to launch.\n* `instance_type` - (Required) The size of instance to launch.\n* `iam_instance_profile` - (Optional) The name attribute of the IAM instance profile to associate\n     with launched instances.\n* `key_name` - (Optional) The key name that should be used for the instance.\n* `metadata_options` - The metadata options for the instance.\n    * `http_endpoint` - The state of the metadata service: `enabled`, `disabled`.\n    * `http_tokens` - If session tokens are required: `optional`, `required`.\n    * `http_put_response_hop_limit` - The desired HTTP PUT response hop limit for instance metadata requests.\n* `security_groups` - (Optional) A list of associated security group IDS.\n* `associate_public_ip_address` - (Optional) Associate a public ip address with an instance in a VPC.\n* `vpc_classic_link_id` - (Optional) The ID of a ClassicLink-enabled VPC. Only applies to EC2-Classic instances. (eg. `vpc-2730681a`)\n* `vpc_classic_link_security_groups` - (Optional) The IDs of one or more security groups for the specified ClassicLink-enabled VPC (eg. `sg-46ae3d11`).\n* `user_data` - (Optional) The user data to provide when launching the instance. Do not pass gzip-compressed data via this argument; see `user_data_base64` instead.\n* `user_data_base64` - (Optional) Can be used instead of `user_data` to pass base64-encoded binary data directly. Use this instead of `user_data` whenever the value is not a valid UTF-8 string. For example, gzip-encoded user data must be base64-encoded and passed via this argument to avoid corruption.\n* `enable_monitoring` - (Optional) Enables/disables detailed monitoring. This is enabled by default.\n* `ebs_optimized` - (Optional) If true, the launched EC2 instance will be EBS-optimized.\n* `root_block_device` - (Optional) Customize details about the root block\n  device of the instance. See [Block Devices](#block-devices) below for details.\n* `ebs_block_device` - (Optional) Additional EBS block devices to attach to the\n  instance.  See [Block Devices](#block-devices) below for details.\n* `ephemeral_block_device` - (Optional) Customize Ephemeral (also known as\n  \"Instance Store\") volumes on the instance. See [Block Devices](#block-devices) below for details.\n* `spot_price` - (Optional; Default: On-demand price) The maximum price to use for reserving spot instances.\n* `placement_tenancy` - (Optional) The tenancy of the instance. Valid values are\n  `\"default\"` or `\"dedicated\"`, see [AWS's Create Launch Configuration](http://docs.aws.amazon.com/AutoScaling/latest/APIReference/API_CreateLaunchConfiguration.html)\n  for more details\n\n## Block devices\n\nEach of the `*_block_device` attributes controls a portion of the AWS\nLaunch Configuration's \"Block Device Mapping\". It's a good idea to familiarize yourself with [AWS's Block Device\nMapping docs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html)\nto understand the implications of using these attributes.\n\nThe `root_block_device` mapping supports the following:\n\n* `volume_type` - (Optional) The type of volume. Can be `\"standard\"`, `\"gp2\"`, `\"gp3\"`, `\"st1\"`, `\"sc1\"`\n  or `\"io1\"`. (Default: `\"standard\"`).\n* `volume_size` - (Optional) The size of the volume in gigabytes.\n* `iops` - (Optional) The amount of provisioned\n  [IOPS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html).\n  This must be set with a `volume_type` of `\"io1\"`.\n* `throughput` - (Optional) The throughput (MiBps) to provision for a `gp3` volume.\n* `delete_on_termination` - (Optional) Whether the volume should be destroyed\n  on instance termination (Default: `true`).\n* `encrypted` - (Optional) Whether the volume should be encrypted or not. (Default: `false`).\n\nModifying any of the `root_block_device` settings requires resource\nreplacement.\n\nEach `ebs_block_device` supports the following:\n\n* `device_name` - (Required) The name of the device to mount.\n* `snapshot_id` - (Optional) The Snapshot ID to mount.\n* `volume_type` - (Optional) The type of volume. Can be `\"standard\"`, `\"gp2\"`, `\"gp3\"`, `\"st1\"`, `\"sc1\"`\n  or `\"io1\"`. (Default: `\"standard\"`).\n* `volume_size` - (Optional) The size of the volume in gigabytes.\n* `iops` - (Optional) The amount of provisioned\n  [IOPS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html).\n  This must be set with a `volume_type` of `\"io1\"`.\n* `throughput` - (Optional) The throughput (MiBps) to provision for a `gp3` volume.\n* `delete_on_termination` - (Optional) Whether the volume should be destroyed\n  on instance termination (Default: `true`).\n* `encrypted` - (Optional) Whether the volume should be encrypted or not. Do not use this option if you are using `snapshot_id` as the encrypted flag will be determined by the snapshot. (Default: `false`).\n* `no_device` - (Optional) Whether the device in the block device mapping of the AMI is suppressed.\n\nModifying any `ebs_block_device` currently requires resource replacement.\n\nEach `ephemeral_block_device` supports the following:\n\n* `device_name` - The name of the block device to mount on the instance.\n* `virtual_name` - The [Instance Store Device\n  Name](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#InstanceStoreDeviceNames)\n  (e.g., `\"ephemeral0\"`)\n\nEach AWS Instance type has a different set of Instance Store block devices\navailable for attachment. AWS [publishes a\nlist](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#StorageOnInstanceTypes)\nof which ephemeral devices are available on each type. The devices are always\nidentified by the `virtual_name` in the format `\"ephemeral{0..N}\"`.\n\n~> **NOTE:** Changes to `*_block_device` configuration of _existing_ resources\ncannot currently be detected by Terraform. After updating to block device\nconfiguration, resource recreation can be manually triggered by using the\n[`taint` command](https://www.terraform.io/docs/commands/taint.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the launch configuration.\n* `arn` - The Amazon Resource Name of the launch configuration.\n* `name` - The name of the launch configuration.\n\n[1]: /docs/providers/aws/r/autoscaling_group.html\n[2]: https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html\n[3]: /docs/providers/aws/r/spot_instance_request.html\n\n## Import\n\nLaunch configurations can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_launch_configuration.as_conf terraform-lg-123456\n```\n",
    "basename": "launch_configuration.html"
  },
  "launch_template.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_launch_template",
    "description": "Provides an EC2 launch template resource. Can be used to create instances or auto scaling groups.",
    "preview": "# Resource: aws_launch_template\n\nProvides an EC2 launch template …",
    "content": "\n\n# Resource: aws_launch_template\n\nProvides an EC2 launch template resource. Can be used to create instances or auto scaling groups.\n\n## Example Usage\n\n```terraform\nresource \"aws_launch_template\" \"foo\" {\n  name = \"foo\"\n\n  block_device_mappings {\n    device_name = \"/dev/sda1\"\n\n    ebs {\n      volume_size = 20\n    }\n  }\n\n  capacity_reservation_specification {\n    capacity_reservation_preference = \"open\"\n  }\n\n  cpu_options {\n    core_count       = 4\n    threads_per_core = 2\n  }\n\n  credit_specification {\n    cpu_credits = \"standard\"\n  }\n\n  disable_api_termination = true\n\n  ebs_optimized = true\n\n  elastic_gpu_specifications {\n    type = \"test\"\n  }\n\n  elastic_inference_accelerator {\n    type = \"eia1.medium\"\n  }\n\n  iam_instance_profile {\n    name = \"test\"\n  }\n\n  image_id = \"ami-test\"\n\n  instance_initiated_shutdown_behavior = \"terminate\"\n\n  instance_market_options {\n    market_type = \"spot\"\n  }\n\n  instance_type = \"t2.micro\"\n\n  kernel_id = \"test\"\n\n  key_name = \"test\"\n\n  license_specification {\n    license_configuration_arn = \"arn:aws:license-manager:eu-west-1:123456789012:license-configuration:lic-0123456789abcdef0123456789abcdef\"\n  }\n\n  metadata_options {\n    http_endpoint               = \"enabled\"\n    http_tokens                 = \"required\"\n    http_put_response_hop_limit = 1\n  }\n\n  monitoring {\n    enabled = true\n  }\n\n  network_interfaces {\n    associate_public_ip_address = true\n  }\n\n  placement {\n    availability_zone = \"us-west-2a\"\n  }\n\n  ram_disk_id = \"test\"\n\n  vpc_security_group_ids = [\"sg-12345678\"]\n\n  tag_specifications {\n    resource_type = \"instance\"\n\n    tags = {\n      Name = \"test\"\n    }\n  }\n\n  user_data = filebase64(\"${path.module}/example.sh\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - The name of the launch template. If you leave this blank, Terraform will auto-generate a unique name.\n* `name_prefix` - Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` - Description of the launch template.\n* `default_version` - Default Version of the launch template.\n* `update_default_version` - Whether to update Default Version each update. Conflicts with `default_version`.\n* `block_device_mappings` - Specify volumes to attach to the instance besides the volumes specified by the AMI.\n  See [Block Devices](#block-devices) below for details.\n* `capacity_reservation_specification` - Targeting for EC2 capacity reservations. See [Capacity Reservation Specification](#capacity-reservation-specification) below for more details.\n* `cpu_options` - The CPU options for the instance. See [CPU Options](#cpu-options) below for more details.\n* `credit_specification` - Customize the credit specification of the instance. See [Credit\n  Specification](#credit-specification) below for more details.\n* `disable_api_termination` - If `true`, enables [EC2 Instance\n  Termination Protection](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html#Using_ChangingDisableAPITermination)\n* `ebs_optimized` - If `true`, the launched EC2 instance will be EBS-optimized.\n* `elastic_gpu_specifications` - The elastic GPU to attach to the instance. See [Elastic GPU](#elastic-gpu)\n  below for more details.\n* `elastic_inference_accelerator` - (Optional) Configuration block containing an Elastic Inference Accelerator to attach to the instance. See [Elastic Inference Accelerator](#elastic-inference-accelerator) below for more details.\n* `iam_instance_profile` - The IAM Instance Profile to launch the instance with. See [Instance Profile](#instance-profile)\n  below for more details.\n* `image_id` - The AMI from which to launch the instance.\n* `instance_initiated_shutdown_behavior` - Shutdown behavior for the instance. Can be `stop` or `terminate`.\n  (Default: `stop`).\n* `instance_market_options` - The market (purchasing) option for the instance. See [Market Options](#market-options)\n  below for details.\n* `instance_type` - The type of the instance.\n* `kernel_id` - The kernel ID.\n* `key_name` - The key name to use for the instance.\n* `license_specification` - A list of license specifications to associate with. See [License Specification](#license-specification) below for more details.\n* `metadata_options` - (Optional) Customize the metadata options for the instance. See [Metadata Options](#metadata-options) below for more details.\n* `monitoring` - The monitoring option for the instance. See [Monitoring](#monitoring) below for more details.\n* `network_interfaces` - Customize network interfaces to be attached at instance boot time. See [Network\n  Interfaces](#network-interfaces) below for more details.\n* `placement` - The placement of the instance. See [Placement](#placement) below for more details.\n* `ram_disk_id` - The ID of the RAM disk.\n* `security_group_names` - A list of security group names to associate with. If you are creating Instances in a VPC, use\n  `vpc_security_group_ids` instead.\n* `vpc_security_group_ids` - A list of security group IDs to associate with. Conflicts with `network_interfaces.security_groups`\n* `tag_specifications` - The tags to apply to the resources during launch. See [Tag Specifications](#tag-specifications) below for more details.\n* `tags` - (Optional) A map of tags to assign to the launch template. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `user_data` - The Base64-encoded user data to provide when launching the instance.\n* `hibernation_options` - The hibernation options for the instance. See [Hibernation Options](#hibernation-options) below for more details.\n* `enclave_options` - (Optional) Enable Nitro Enclaves on launched instances. See [Enclave Options](#enclave-options) below for more details.\n\n### Block devices\n\nConfigure additional volumes of the instance besides specified by the AMI. It's a good idea to familiarize yourself with\n  [AWS's Block Device Mapping docs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html)\n  to understand the implications of using these attributes.\n\nTo find out more information for an existing AMI to override the configuration, such as `device_name`, you can use the [AWS CLI ec2 describe-images command](https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-images.html).\n\nEach `block_device_mappings` supports the following:\n\n* `device_name` - The name of the device to mount.\n* `ebs` - Configure EBS volume properties.\n* `no_device` - Suppresses the specified device included in the AMI's block device mapping.\n* `virtual_name` - The [Instance Store Device\n  Name](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#InstanceStoreDeviceNames)\n  (e.g., `\"ephemeral0\"`).\n\nThe `ebs` block supports the following:\n\n* `delete_on_termination` - Whether the volume should be destroyed on instance termination. Defaults to `false` if not set. See [Preserving Amazon EBS Volumes on Instance Termination](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html#preserving-volumes-on-termination) for more information.\n* `encrypted` - Enables [EBS encryption](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html)\n  on the volume (Default: `false`). Cannot be used with `snapshot_id`.\n* `iops` - The amount of provisioned\n  [IOPS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html).\n  This must be set with a `volume_type` of `\"io1/io2\"`.\n* `kms_key_id` - The ARN of the AWS Key Management Service (AWS KMS) customer master key (CMK) to use when creating the encrypted volume.\n `encrypted` must be set to `true` when this is set.\n* `snapshot_id` - The Snapshot ID to mount.\n* `throughput` - The throughput to provision for a `gp3` volume in MiB/s (specified as an integer, e.g., 500), with a maximum of 1,000 MiB/s.\n* `volume_size` - The size of the volume in gigabytes.\n* `volume_type` - The volume type. Can be `standard`, `gp2`, `gp3`, `io1`, `io2`, `sc1` or `st1` (Default: `gp2`).\n\n### Capacity Reservation Specification\n\nThe `capacity_reservation_specification` block supports the following:\n\n* `capacity_reservation_preference` - Indicates the instance's Capacity Reservation preferences. Can be `open` or `none`. (Default `none`).\n* `capacity_reservation_target` - Used to target a specific Capacity Reservation:\n\nThe `capacity_reservation_target` block supports the following:\n\n* `capacity_reservation_id` - The ID of the Capacity Reservation to target.\n\n### CPU Options\n\nThe `cpu_options` block supports the following:\n\n* `core_count` - The number of CPU cores for the instance.\n* `threads_per_core` - The number of threads per CPU core. To disable Intel Hyper-Threading Technology for the instance, specify a value of 1.\nOtherwise, specify the default value of 2.\n\nBoth number of CPU cores and threads per core must be specified. Valid number of CPU cores and threads per core for the instance type can be found in the [CPU Options Documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html?shortFooter=true#cpu-options-supported-instances-values)\n\n### Credit Specification\n\nCredit specification can be applied/modified to the EC2 Instance at any time.\n\nThe `credit_specification` block supports the following:\n\n* `cpu_credits` - The credit option for CPU usage. Can be `\"standard\"` or `\"unlimited\"`. T3 instances are launched as unlimited by default. T2 instances are launched as standard by default.\n\n### Elastic GPU\n\nAttach an elastic GPU the instance.\n\nThe `elastic_gpu_specifications` block supports the following:\n\n* `type` - The [Elastic GPU Type](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/elastic-gpus.html#elastic-gpus-basics)\n\n### Elastic Inference Accelerator\n\nAttach an Elastic Inference Accelerator to the instance. Additional information about Elastic Inference in EC2 can be found in the [EC2 User Guide](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-inference.html).\n\nThe `elastic_inference_accelerator` configuration block supports the following:\n\n* `type` - (Required) Accelerator type.\n\n### Instance Profile\n\nThe [IAM Instance Profile](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html)\nto attach.\n\nThe `iam_instance_profile` block supports the following:\n\n* `arn` - The Amazon Resource Name (ARN) of the instance profile.\n* `name` - The name of the instance profile.\n\n### License Specification\n\nAssociate one of more license configurations.\n\nThe `license_specification` block supports the following:\n\n* `license_configuration_arn` - (Required) ARN of the license configuration.\n\n### Market Options\n\nThe market (purchasing) option for the instances.\n\nThe `instance_market_options` block supports the following:\n\n* `market_type` - The market type. Can be `spot`.\n* `spot_options` - The options for [Spot Instance](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html)\n\nThe `spot_options` block supports the following:\n\n* `block_duration_minutes` - The required duration in minutes. This value must be a multiple of 60.\n* `instance_interruption_behavior` - The behavior when a Spot Instance is interrupted. Can be `hibernate`,\n  `stop`, or `terminate`. (Default: `terminate`).\n* `max_price` - The maximum hourly price you're willing to pay for the Spot Instances.\n* `spot_instance_type` - The Spot Instance request type. Can be `one-time`, or `persistent`.\n* `valid_until` - The end date of the request.\n\n### Metadata Options\n\nThe metadata options for the instances.\n\nThe `metadata_options` block supports the following:\n\n* `http_endpoint` - (Optional) Whether the metadata service is available. Can be `\"enabled\"` or `\"disabled\"`. (Default: `\"enabled\"`).\n* `http_tokens` - (Optional) Whether or not the metadata service requires session tokens, also referred to as _Instance Metadata Service Version 2 (IMDSv2)_. Can be `\"optional\"` or `\"required\"`. (Default: `\"optional\"`).\n* `http_put_response_hop_limit` - (Optional) The desired HTTP PUT response hop limit for instance metadata requests. The larger the number, the further instance metadata requests can travel. Can be an integer from `1` to `64`. (Default: `1`).\n* `http_protocol_ipv6` - (Optional) Enables or disables the IPv6 endpoint for the instance metadata service. (Default: `disabled`).\n\nFor more information, see the documentation on the [Instance Metadata Service](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html).\n\n### Monitoring\n\nThe `monitoring` block supports the following:\n\n* `enabled` - If `true`, the launched EC2 instance will have detailed monitoring enabled.\n\n### Network Interfaces\n\nAttaches one or more [Network Interfaces](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html) to the instance.\n\nCheck limitations for autoscaling group in [Creating an Auto Scaling Group Using a Launch Template Guide](https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-launch-template.html#limitations)\n\nEach `network_interfaces` block supports the following:\n\n* `associate_carrier_ip_address` - Associate a Carrier IP address with `eth0` for a new network interface. Use this option when you launch an instance in a Wavelength Zone and want to associate a Carrier IP address with the network interface. Boolean value.\n* `associate_public_ip_address` - Associate a public ip address with the network interface.  Boolean value.\n* `delete_on_termination` - Whether the network interface should be destroyed on instance termination. Defaults to `false` if not set.\n* `description` - Description of the network interface.\n* `device_index` - The integer index of the network interface attachment.\n* `interface_type` - The type of network interface. To create an Elastic Fabric Adapter (EFA), specify `efa`.\n* `ipv6_addresses` - One or more specific IPv6 addresses from the IPv6 CIDR block range of your subnet. Conflicts with `ipv6_address_count`\n* `ipv6_address_count` - The number of IPv6 addresses to assign to a network interface. Conflicts with `ipv6_addresses`\n* `network_interface_id` - The ID of the network interface to attach.\n* `network_card_index` - The index of the network card. Some instance types support multiple network cards. The primary network interface must be assigned to network card index 0. The default is network card index 0.\n* `private_ip_address` - The primary private IPv4 address.\n* `ipv4_address_count` - The number of secondary private IPv4 addresses to assign to a network interface. Conflicts with `ipv4_addresses`\n* `ipv4_addresses` - One or more private IPv4 addresses to associate. Conflicts with `ipv4_address_count`\n* `security_groups` - A list of security group IDs to associate.\n* `subnet_id` - The VPC Subnet ID to associate.\n\n### Placement\n\nThe [Placement Group](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html) of the instance.\n\nThe `placement` block supports the following:\n\n* `affinity` - The affinity setting for an instance on a Dedicated Host.\n* `availability_zone` - The Availability Zone for the instance.\n* `group_name` - The name of the placement group for the instance.\n* `host_id` - The ID of the Dedicated Host for the instance.\n* `host_resource_group_arn` - The ARN of the Host Resource Group in which to launch instances.\n* `spread_domain` - Reserved for future use.\n* `tenancy` - The tenancy of the instance (if the instance is running in a VPC). Can be `default`, `dedicated`, or `host`.\n* `partition_number` - The number of the partition the instance should launch in. Valid only if the placement group strategy is set to partition.\n\n### Hibernation Options\n\nThe `hibernation_options` block supports the following:\n\n* `configured` - If set to `true`, the launched EC2 instance will hibernation enabled.\n\n### Enclave Options\n\nThe `enclave_options` block supports the following:\n\n* `enabled` - If set to `true`, Nitro Enclaves will be enabled on the instance.\n\nFor more information, see the documentation on [Nitro Enclaves](https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave.html).\n\n### Tag Specifications\n\nThe tags to apply to the resources during launch. You can tag instances, volumes, elastic GPUs and spot instance requests. More information can be found in the [EC2 API documentation](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_LaunchTemplateTagSpecificationRequest.html).\n\nEach `tag_specifications` block supports the following:\n\n* `resource_type` - The type of resource to tag.\n* `tags` - A map of tags to assign to the resource.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the launch template.\n* `id` - The ID of the launch template.\n* `latest_version` - The latest version of the launch template.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nLaunch Templates can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_launch_template.web lt-12345678\n```\n",
    "basename": "launch_template.html"
  },
  "lb.html": {
    "subcategory": "Elastic Load Balancing v2 (ALB/NLB)",
    "layout": "aws",
    "page_title": "AWS: aws_lb",
    "description": "Provides a Load Balancer resource.",
    "preview": "# Resource: aws_lb\n\nProvides a Load Balancer resource.\n\n~> **Note:** …",
    "content": "\n\n# Resource: aws_lb\n\nProvides a Load Balancer resource.\n\n~> **Note:** `aws_alb` is known as `aws_lb`. The functionality is identical.\n\n## Example Usage\n\n### Application Load Balancer\n\n```terraform\nresource \"aws_lb\" \"test\" {\n  name               = \"test-lb-tf\"\n  internal           = false\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.lb_sg.id]\n  subnets            = [for subnet in aws_subnet.public : subnet.id]\n\n  enable_deletion_protection = true\n\n  access_logs {\n    bucket  = aws_s3_bucket.lb_logs.bucket\n    prefix  = \"test-lb\"\n    enabled = true\n  }\n\n  tags = {\n    Environment = \"production\"\n  }\n}\n```\n\n### Network Load Balancer\n\n```terraform\nresource \"aws_lb\" \"test\" {\n  name               = \"test-lb-tf\"\n  internal           = false\n  load_balancer_type = \"network\"\n  subnets            = [for subnet in aws_subnet.public : subnet.id]\n\n  enable_deletion_protection = true\n\n  tags = {\n    Environment = \"production\"\n  }\n}\n```\n\n### Specifying Elastic IPs\n\n```terraform\nresource \"aws_lb\" \"example\" {\n  name               = \"example\"\n  load_balancer_type = \"network\"\n\n  subnet_mapping {\n    subnet_id     = aws_subnet.example1.id\n    allocation_id = aws_eip.example1.id\n  }\n\n  subnet_mapping {\n    subnet_id     = aws_subnet.example2.id\n    allocation_id = aws_eip.example2.id\n  }\n}\n```\n\n### Specifying private IP addresses for an internal-facing load balancer\n\n```terraform\nresource \"aws_lb\" \"example\" {\n  name               = \"example\"\n  load_balancer_type = \"network\"\n\n  subnet_mapping {\n    subnet_id            = aws_subnet.example1.id\n    private_ipv4_address = \"10.0.1.15\"\n  }\n\n  subnet_mapping {\n    subnet_id            = aws_subnet.example2.id\n    private_ipv4_address = \"10.0.2.15\"\n  }\n}\n```\n\n## Argument Reference\n\n~> **NOTE:** Please note that internal LBs can only use `ipv4` as the ip_address_type. You can only change to `dualstack` ip_address_type if the selected subnets are IPv6 enabled.\n\n~> **NOTE:** Please note that one of either `subnets` or `subnet_mapping` is required.\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the LB. This name must be unique within your AWS account, can have a maximum of 32 characters,\nmust contain only alphanumeric characters or hyphens, and must not begin or end with a hyphen. If not specified,\nTerraform will autogenerate a name beginning with `tf-lb`.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `internal` - (Optional) If true, the LB will be internal.\n* `load_balancer_type` - (Optional) The type of load balancer to create. Possible values are `application`, `gateway`, or `network`. The default value is `application`.\n* `security_groups` - (Optional) A list of security group IDs to assign to the LB. Only valid for Load Balancers of type `application`.\n* `drop_invalid_header_fields` - (Optional) Indicates whether HTTP headers with header fields that are not valid are removed by the load balancer (true) or routed to targets (false). The default is false. Elastic Load Balancing requires that message header names contain only alphanumeric characters and hyphens. Only valid for Load Balancers of type `application`.\n* `access_logs` - (Optional) An Access Logs block. Access Logs documented below.\n* `subnets` - (Optional) A list of subnet IDs to attach to the LB. Subnets\ncannot be updated for Load Balancers of type `network`. Changing this value\nfor load balancers of type `network` will force a recreation of the resource.\n* `subnet_mapping` - (Optional) A subnet mapping block as documented below.\n* `idle_timeout` - (Optional) The time in seconds that the connection is allowed to be idle. Only valid for Load Balancers of type `application`. Default: 60.\n* `enable_deletion_protection` - (Optional) If true, deletion of the load balancer will be disabled via\n   the AWS API. This will prevent Terraform from deleting the load balancer. Defaults to `false`.\n* `enable_cross_zone_load_balancing` - (Optional) If true, cross-zone load balancing of the load balancer will be enabled.\n   This is a `network` load balancer feature. Defaults to `false`.\n* `enable_http2` - (Optional) Indicates whether HTTP/2 is enabled in `application` load balancers. Defaults to `true`.\n* `enable_waf_fail_open` - (Optional) Indicates whether to allow a WAF-enabled load balancer to route requests to targets if it is unable to forward the request to AWS WAF. Defaults to `false`.\n* `customer_owned_ipv4_pool` - (Optional) The ID of the customer owned ipv4 pool to use for this load balancer.\n* `ip_address_type` - (Optional) The type of IP addresses used by the subnets for your load balancer. The possible values are `ipv4` and `dualstack`\n* `desync_mitigation_mode` - (Optional) Determines how the load balancer handles requests that might pose a security risk to an application due to HTTP desync. Valid values are `monitor`, `defensive` (default), `strictest`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nAccess Logs (`access_logs`) support the following:\n\n* `bucket` - (Required) The S3 bucket name to store the logs in.\n* `prefix` - (Optional) The S3 bucket prefix. Logs are stored in the root if not configured.\n* `enabled` - (Optional) Boolean to enable / disable `access_logs`. Defaults to `false`, even when `bucket` is specified.\n\nSubnet Mapping (`subnet_mapping`) blocks support the following:\n\n* `subnet_id` - (Required) The id of the subnet of which to attach to the load balancer. You can specify only one subnet per Availability Zone.\n* `allocation_id` - (Optional) The allocation ID of the Elastic IP address.\n* `private_ipv4_address` - (Optional) A private ipv4 address within the subnet to assign to the internal-facing load balancer.\n* `ipv6_address` - (Optional) An ipv6 address within the subnet to assign to the internet-facing load balancer.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the load balancer (matches `arn`).\n* `arn` - The ARN of the load balancer (matches `id`).\n* `arn_suffix` - The ARN suffix for use with CloudWatch Metrics.\n* `dns_name` - The DNS name of the load balancer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `zone_id` - The canonical hosted zone ID of the load balancer (to be used in a Route 53 Alias record).\n* `subnet_mapping.*.outpost_id` - ID of the Outpost containing the load balancer.\n\n## Timeouts\n\n`aws_lb` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for Creating LB\n- `update` - (Default `10 minutes`) Used for LB modifications\n- `delete` - (Default `10 minutes`) Used for destroying LB\n\n## Import\n\nLBs can be imported using their ARN, e.g.,\n\n```\n$ terraform import aws_lb.bar arn:aws:elasticloadbalancing:us-west-2:123456789012:loadbalancer/app/my-load-balancer/50dc6c495c0c9188\n```\n",
    "basename": "lb.html"
  },
  "lb_cookie_stickiness_policy.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_lb_cookie_stickiness_policy",
    "description": "Provides a load balancer cookie stickiness policy, which allows an ELB to control the sticky session lifetime of the browser.",
    "preview": "# Resource: aws_lb_cookie_stickiness_policy\n\nProvides a load …",
    "content": "\n\n# Resource: aws_lb_cookie_stickiness_policy\n\nProvides a load balancer cookie stickiness policy, which allows an ELB to control the sticky session lifetime of the browser.\n\n## Example Usage\n\n```terraform\nresource \"aws_elb\" \"lb\" {\n  name               = \"test-lb\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port     = 8000\n    instance_protocol = \"http\"\n    lb_port           = 80\n    lb_protocol       = \"http\"\n  }\n}\n\nresource \"aws_lb_cookie_stickiness_policy\" \"foo\" {\n  name                     = \"foo-policy\"\n  load_balancer            = aws_elb.lb.id\n  lb_port                  = 80\n  cookie_expiration_period = 600\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the stickiness policy.\n* `load_balancer` - (Required) The load balancer to which the policy\n  should be attached.\n* `lb_port` - (Required) The load balancer port to which the policy\n  should be applied. This must be an active listener on the load\nbalancer.\n* `cookie_expiration_period` - (Optional) The time period after which\n  the session cookie should be considered stale, expressed in seconds.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the policy.\n* `name` - The name of the stickiness policy.\n* `load_balancer` - The load balancer to which the policy is attached.\n* `lb_port` - The load balancer port to which the policy is applied.\n* `cookie_expiration_period` - The time period after which the session cookie is considered stale, expressed in seconds.\n",
    "basename": "lb_cookie_stickiness_policy.html"
  },
  "lb_listener.html": {
    "subcategory": "Elastic Load Balancing v2 (ALB/NLB)",
    "layout": "aws",
    "page_title": "AWS: aws_lb_listener",
    "description": "Provides a Load Balancer Listener resource.",
    "preview": "# Resource: aws_lb_listener\n\nProvides a Load Balancer Listener …",
    "content": "\n\n# Resource: aws_lb_listener\n\nProvides a Load Balancer Listener resource.\n\n~> **Note:** `aws_alb_listener` is known as `aws_lb_listener`. The functionality is identical.\n\n## Example Usage\n\n### Forward Action\n\n```terraform\nresource \"aws_lb\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_target_group\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  load_balancer_arn = aws_lb.front_end.arn\n  port              = \"443\"\n  protocol          = \"HTTPS\"\n  ssl_policy        = \"ELBSecurityPolicy-2016-08\"\n  certificate_arn   = \"arn:aws:iam::187416307283:server-certificate/test_cert_rab3wuqwgja25ct3n4jdj2tzu4\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.front_end.arn\n  }\n}\n```\n\nTo a NLB:\n\n```hcl\nresource \"aws_lb_listener\" \"front_end\" {\n  load_balancer_arn = aws_lb.front_end.arn\n  port              = \"443\"\n  protocol          = \"TLS\"\n  certificate_arn   = \"arn:aws:iam::187416307283:server-certificate/test_cert_rab3wuqwgja25ct3n4jdj2tzu4\"\n  alpn_policy       = \"HTTP2Preferred\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.front_end.arn\n  }\n}\n```\n\n### Redirect Action\n\n```terraform\nresource \"aws_lb\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  load_balancer_arn = aws_lb.front_end.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"redirect\"\n\n    redirect {\n      port        = \"443\"\n      protocol    = \"HTTPS\"\n      status_code = \"HTTP_301\"\n    }\n  }\n}\n```\n\n### Fixed-response Action\n\n```terraform\nresource \"aws_lb\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  load_balancer_arn = aws_lb.front_end.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"fixed-response\"\n\n    fixed_response {\n      content_type = \"text/plain\"\n      message_body = \"Fixed response content\"\n      status_code  = \"200\"\n    }\n  }\n}\n```\n\n### Authenticate-cognito Action\n\n```terraform\nresource \"aws_lb\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_target_group\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_cognito_user_pool\" \"pool\" {\n  # ...\n}\n\nresource \"aws_cognito_user_pool_client\" \"client\" {\n  # ...\n}\n\nresource \"aws_cognito_user_pool_domain\" \"domain\" {\n  # ...\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  load_balancer_arn = aws_lb.front_end.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"authenticate-cognito\"\n\n    authenticate_cognito {\n      user_pool_arn       = aws_cognito_user_pool.pool.arn\n      user_pool_client_id = aws_cognito_user_pool_client.client.id\n      user_pool_domain    = aws_cognito_user_pool_domain.domain.domain\n    }\n  }\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.front_end.arn\n  }\n}\n```\n\n### Authenticate-OIDC Action\n\n```terraform\nresource \"aws_lb\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_target_group\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  load_balancer_arn = aws_lb.front_end.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"authenticate-oidc\"\n\n    authenticate_oidc {\n      authorization_endpoint = \"https://example.com/authorization_endpoint\"\n      client_id              = \"client_id\"\n      client_secret          = \"client_secret\"\n      issuer                 = \"https://example.com\"\n      token_endpoint         = \"https://example.com/token_endpoint\"\n      user_info_endpoint     = \"https://example.com/user_info_endpoint\"\n    }\n  }\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.front_end.arn\n  }\n}\n```\n\n### Gateway Load Balancer Listener\n\n```terraform\nresource \"aws_lb\" \"example\" {\n  load_balancer_type = \"gateway\"\n  name               = \"example\"\n\n  subnet_mapping {\n    subnet_id = aws_subnet.example.id\n  }\n}\n\nresource \"aws_lb_target_group\" \"example\" {\n  name     = \"example\"\n  port     = 6081\n  protocol = \"GENEVE\"\n  vpc_id   = aws_vpc.example.id\n\n  health_check {\n    port     = 80\n    protocol = \"HTTP\"\n  }\n}\n\nresource \"aws_lb_listener\" \"example\" {\n  load_balancer_arn = aws_lb.example.id\n\n  default_action {\n    target_group_arn = aws_lb_target_group.example.id\n    type             = \"forward\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `default_action` - (Required) Configuration block for default actions. Detailed below.\n* `load_balancer_arn` - (Required, Forces New Resource) ARN of the load balancer.\n\nThe following arguments are optional:\n\n* `alpn_policy` - (Optional)  Name of the Application-Layer Protocol Negotiation (ALPN) policy. Can be set if `protocol` is `TLS`. Valid values are `HTTP1Only`, `HTTP2Only`, `HTTP2Optional`, `HTTP2Preferred`, and `None`.\n* `certificate_arn` - (Optional) ARN of the default SSL server certificate. Exactly one certificate is required if the protocol is HTTPS. For adding additional SSL certificates, see the [`aws_lb_listener_certificate` resource](/docs/providers/aws/r/lb_listener_certificate.html).\n* `port` - (Optional) Port on which the load balancer is listening. Not valid for Gateway Load Balancers.\n* `protocol` - (Optional) Protocol for connections from clients to the load balancer. For Application Load Balancers, valid values are `HTTP` and `HTTPS`, with a default of `HTTP`. For Network Load Balancers, valid values are `TCP`, `TLS`, `UDP`, and `TCP_UDP`. Not valid to use `UDP` or `TCP_UDP` if dual-stack mode is enabled. Not valid for Gateway Load Balancers.\n* `ssl_policy` - (Optional) Name of the SSL Policy for the listener. Required if `protocol` is `HTTPS` or `TLS`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n~> **NOTE::** Please note that listeners that are attached to Application Load Balancers must use either `HTTP` or `HTTPS` protocols while listeners that are attached to Network Load Balancers must use the `TCP` protocol.\n\n### default_action\n\nThe following arguments are required:\n\n* `type` - (Required) Type of routing action. Valid values are `forward`, `redirect`, `fixed-response`, `authenticate-cognito` and `authenticate-oidc`.\n\nThe following arguments are optional:\n\n* `authenticate_cognito` - (Optional) Configuration block for using Amazon Cognito to authenticate users. Specify only when `type` is `authenticate-cognito`. Detailed below.\n* `authenticate_oidc` - (Optional) Configuration block for an identity provider that is compliant with OpenID Connect (OIDC). Specify only when `type` is `authenticate-oidc`. Detailed below.\n* `fixed_response` - (Optional) Information for creating an action that returns a custom HTTP response. Required if `type` is `fixed-response`.\n* `forward` - (Optional) Configuration block for creating an action that distributes requests among one or more target groups. Specify only if `type` is `forward`. If you specify both `forward` block and `target_group_arn` attribute, you can specify only one target group using `forward` and it must be the same target group specified in `target_group_arn`. Detailed below.\n* `order` - (Optional) Order for the action. This value is required for rules with multiple actions. The action with the lowest value for order is performed first. Valid values are between `1` and `50000`.\n* `redirect` - (Optional) Configuration block for creating a redirect action. Required if `type` is `redirect`. Detailed below.\n* `target_group_arn` - (Optional) ARN of the Target Group to which to route traffic. Specify only if `type` is `forward` and you want to route to a single target group. To route to one or more target groups, use a `forward` block instead.\n\n#### authenticate_cognito\n\nThe following arguments are required:\n\n* `user_pool_arn` - (Required) ARN of the Cognito user pool.\n* `user_pool_client_id` - (Required) ID of the Cognito user pool client.\n* `user_pool_domain` - (Required) Domain prefix or fully-qualified domain name of the Cognito user pool.\n\nThe following arguments are optional:\n\n* `authentication_request_extra_params` - (Optional) Query parameters to include in the redirect request to the authorization endpoint. Max: 10. Detailed below.\n* `on_unauthenticated_request` - (Optional) Behavior if the user is not authenticated. Valid values are `deny`, `allow` and `authenticate`.\n* `scope` - (Optional) Set of user claims to be requested from the IdP.\n* `session_cookie_name` - (Optional) Name of the cookie used to maintain session information.\n* `session_timeout` - (Optional) Maximum duration of the authentication session, in seconds.\n\n##### authentication_request_extra_params\n\n* `key` - (Required) Key of query parameter.\n* `value` - (Required) Value of query parameter.\n\n#### authenticate_oidc\n\nThe following arguments are required:\n\n* `authorization_endpoint` - (Required) Authorization endpoint of the IdP.\n* `client_id` - (Required) OAuth 2.0 client identifier.\n* `client_secret` - (Required) OAuth 2.0 client secret.\n* `issuer` - (Required) OIDC issuer identifier of the IdP.\n* `token_endpoint` - (Required) Token endpoint of the IdP.\n* `user_info_endpoint` - (Required) User info endpoint of the IdP.\n\nThe following arguments are optional:\n\n* `authentication_request_extra_params` - (Optional) Query parameters to include in the redirect request to the authorization endpoint. Max: 10.\n* `on_unauthenticated_request` - (Optional) Behavior if the user is not authenticated. Valid values: `deny`, `allow` and `authenticate`\n* `scope` - (Optional) Set of user claims to be requested from the IdP.\n* `session_cookie_name` - (Optional) Name of the cookie used to maintain session information.\n* `session_timeout` - (Optional) Maximum duration of the authentication session, in seconds.\n\n#### fixed_response\n\nThe following arguments are required:\n\n* `content_type` - (Required) Content type. Valid values are `text/plain`, `text/css`, `text/html`, `application/javascript` and `application/json`.\n\nThe following arguments are optional:\n\n* `message_body` - (Optional) Message body.\n* `status_code` - (Optional) HTTP response code. Valid values are `2XX`, `4XX`, or `5XX`.\n\n#### forward\n\nThe following arguments are required:\n\n* `target_group` - (Required) Set of 1-5 target group blocks. Detailed below.\n\nThe following arguments are optional:\n\n* `stickiness` - (Optional) Configuration block for target group stickiness for the rule. Detailed below.\n\n##### target_group\n\nThe following arguments are required:\n\n* `arn` - (Required) ARN of the target group.\n\nThe following arguments are optional:\n\n* `weight` - (Optional) Weight. The range is 0 to 999.\n\n##### stickiness\n\nThe following arguments are required:\n\n* `duration` - (Required) Time period, in seconds, during which requests from a client should be routed to the same target group. The range is 1-604800 seconds (7 days).\n\nThe following arguments are optional:\n\n* `enabled` - (Optional) Whether target group stickiness is enabled. Default is `false`.\n\n#### redirect\n\n~> **NOTE::** You can reuse URI components using the following reserved keywords: `#{protocol}`, `#{host}`, `#{port}`, `#{path}` (the leading \"/\" is removed) and `#{query}`.\n\nThe following arguments are required:\n\n* `status_code` - (Required) HTTP redirect code. The redirect is either permanent (`HTTP_301`) or temporary (`HTTP_302`).\n\nThe following arguments are optional:\n\n* `host` - (Optional) Hostname. This component is not percent-encoded. The hostname can contain `#{host}`. Defaults to `#{host}`.\n* `path` - (Optional) Absolute path, starting with the leading \"/\". This component is not percent-encoded. The path can contain #{host}, #{path}, and #{port}. Defaults to `/#{path}`.\n* `port` - (Optional) Port. Specify a value from `1` to `65535` or `#{port}`. Defaults to `#{port}`.\n* `protocol` - (Optional) Protocol. Valid values are `HTTP`, `HTTPS`, or `#{protocol}`. Defaults to `#{protocol}`.\n* `query` - (Optional) Query parameters, URL-encoded when necessary, but not percent-encoded. Do not include the leading \"?\". Defaults to `#{query}`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the listener (matches `id`).\n* `id` - ARN of the listener (matches `arn`).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nListeners can be imported using their ARN, e.g.,\n\n```\n$ terraform import aws_lb_listener.front_end arn:aws:elasticloadbalancing:us-west-2:187416307283:listener/app/front-end-alb/8e4497da625e2d8a/9ab28ade35828f96\n```\n",
    "basename": "lb_listener.html"
  },
  "lb_listener_certificate.html": {
    "subcategory": "Elastic Load Balancing v2 (ALB/NLB)",
    "layout": "aws",
    "page_title": "AWS: aws_lb_listener_certificate",
    "description": "Provides a Load Balancer Listener Certificate resource.",
    "preview": "# Resource: aws_lb_listener_certificate\n\nProvides a Load Balancer …",
    "content": "\n\n# Resource: aws_lb_listener_certificate\n\nProvides a Load Balancer Listener Certificate resource.\n\nThis resource is for additional certificates and does not replace the default certificate on the listener.\n\n~> **Note:** `aws_alb_listener_certificate` is known as `aws_lb_listener_certificate`. The functionality is identical.\n\n## Example Usage\n\n```terraform\nresource \"aws_acm_certificate\" \"example\" {\n  # ...\n}\n\nresource \"aws_lb\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_listener_certificate\" \"example\" {\n  listener_arn    = aws_lb_listener.front_end.arn\n  certificate_arn = aws_acm_certificate.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `listener_arn` - (Required, Forces New Resource) The ARN of the listener to which to attach the certificate.\n* `certificate_arn` - (Required, Forces New Resource) The ARN of the certificate to attach to the listener.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The `listener_arn` and `certificate_arn` separated by a `_`.\n\n## Import\n\nListener Certificates can be imported using their id, e.g.,\n\n```\n$ terraform import aws_lb_listener_certificate.example arn:aws:elasticloadbalancing:us-west-2:123456789012:listener/app/test/8e4497da625e2d8a/9ab28ade35828f96/67b3d2d36dd7c26b_arn:aws:iam::123456789012:server-certificate/tf-acc-test-6453083910015726063\n```\n",
    "basename": "lb_listener_certificate.html"
  },
  "lb_listener_rule.html": {
    "subcategory": "Elastic Load Balancing v2 (ALB/NLB)",
    "layout": "aws",
    "page_title": "AWS: aws_lb_listener_rule",
    "description": "Provides a Load Balancer Listener Rule resource.",
    "preview": "# Resource: aws_lb_listener_rule\n\nProvides a Load Balancer Listener …",
    "content": "\n\n# Resource: aws_lb_listener_rule\n\nProvides a Load Balancer Listener Rule resource.\n\n~> **Note:** `aws_alb_listener_rule` is known as `aws_lb_listener_rule`. The functionality is identical.\n\n## Example Usage\n\n```terraform\nresource \"aws_lb\" \"front_end\" {\n  # ...\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  # Other parameters\n}\n\nresource \"aws_lb_listener_rule\" \"static\" {\n  listener_arn = aws_lb_listener.front_end.arn\n  priority     = 100\n\n  action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.static.arn\n  }\n\n  condition {\n    path_pattern {\n      values = [\"/static/*\"]\n    }\n  }\n\n  condition {\n    host_header {\n      values = [\"example.com\"]\n    }\n  }\n}\n\n# Forward action\n\nresource \"aws_lb_listener_rule\" \"host_based_weighted_routing\" {\n  listener_arn = aws_lb_listener.front_end.arn\n  priority     = 99\n\n  action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.static.arn\n  }\n\n  condition {\n    host_header {\n      values = [\"my-service.*.terraform.io\"]\n    }\n  }\n}\n\n# Weighted Forward action\n\nresource \"aws_lb_listener_rule\" \"host_based_routing\" {\n  listener_arn = aws_lb_listener.front_end.arn\n  priority     = 99\n\n  action {\n    type = \"forward\"\n    forward {\n      target_group {\n        arn    = aws_lb_target_group.main.arn\n        weight = 80\n      }\n\n      target_group {\n        arn    = aws_lb_target_group.canary.arn\n        weight = 20\n      }\n\n      stickiness {\n        enabled  = true\n        duration = 600\n      }\n    }\n  }\n\n  condition {\n    host_header {\n      values = [\"my-service.*.terraform.io\"]\n    }\n  }\n}\n\n# Redirect action\n\nresource \"aws_lb_listener_rule\" \"redirect_http_to_https\" {\n  listener_arn = aws_lb_listener.front_end.arn\n\n  action {\n    type = \"redirect\"\n\n    redirect {\n      port        = \"443\"\n      protocol    = \"HTTPS\"\n      status_code = \"HTTP_301\"\n    }\n  }\n\n  condition {\n    http_header {\n      http_header_name = \"X-Forwarded-For\"\n      values           = [\"192.168.1.*\"]\n    }\n  }\n}\n\n# Fixed-response action\n\nresource \"aws_lb_listener_rule\" \"health_check\" {\n  listener_arn = aws_lb_listener.front_end.arn\n\n  action {\n    type = \"fixed-response\"\n\n    fixed_response {\n      content_type = \"text/plain\"\n      message_body = \"HEALTHY\"\n      status_code  = \"200\"\n    }\n  }\n\n  condition {\n    query_string {\n      key   = \"health\"\n      value = \"check\"\n    }\n\n    query_string {\n      value = \"bar\"\n    }\n  }\n}\n\n# Authenticate-cognito Action\n\nresource \"aws_cognito_user_pool\" \"pool\" {\n  # ...\n}\n\nresource \"aws_cognito_user_pool_client\" \"client\" {\n  # ...\n}\n\nresource \"aws_cognito_user_pool_domain\" \"domain\" {\n  # ...\n}\n\nresource \"aws_lb_listener_rule\" \"admin\" {\n  listener_arn = aws_lb_listener.front_end.arn\n\n  action {\n    type = \"authenticate-cognito\"\n\n    authenticate_cognito {\n      user_pool_arn       = aws_cognito_user_pool.pool.arn\n      user_pool_client_id = aws_cognito_user_pool_client.client.id\n      user_pool_domain    = aws_cognito_user_pool_domain.domain.domain\n    }\n  }\n\n  action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.static.arn\n  }\n}\n\n# Authenticate-oidc Action\n\nresource \"aws_lb_listener_rule\" \"oidc\" {\n  listener_arn = aws_lb_listener.front_end.arn\n\n  action {\n    type = \"authenticate-oidc\"\n\n    authenticate_oidc {\n      authorization_endpoint = \"https://example.com/authorization_endpoint\"\n      client_id              = \"client_id\"\n      client_secret          = \"client_secret\"\n      issuer                 = \"https://example.com\"\n      token_endpoint         = \"https://example.com/token_endpoint\"\n      user_info_endpoint     = \"https://example.com/user_info_endpoint\"\n    }\n  }\n\n  action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.static.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `listener_arn` - (Required, Forces New Resource) The ARN of the listener to which to attach the rule.\n* `priority` - (Optional) The priority for the rule between `1` and `50000`. Leaving it unset will automatically set the rule with next available priority after currently existing highest rule. A listener can't have multiple rules with the same priority.\n* `action` - (Required) An Action block. Action blocks are documented below.\n* `condition` - (Required) A Condition block. Multiple condition blocks of different types can be set and all must be satisfied for the rule to match. Condition blocks are documented below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Action Blocks\n\nAction Blocks (for `action`) support the following:\n\n* `type` - (Required) The type of routing action. Valid values are `forward`, `redirect`, `fixed-response`, `authenticate-cognito` and `authenticate-oidc`.\n* `target_group_arn` - (Optional) The ARN of the Target Group to which to route traffic. Specify only if `type` is `forward` and you want to route to a single target group. To route to one or more target groups, use a `forward` block instead.\n* `forward` - (Optional) Information for creating an action that distributes requests among one or more target groups. Specify only if `type` is `forward`. If you specify both `forward` block and `target_group_arn` attribute, you can specify only one target group using `forward` and it must be the same target group specified in `target_group_arn`.\n* `redirect` - (Optional) Information for creating a redirect action. Required if `type` is `redirect`.\n* `fixed_response` - (Optional) Information for creating an action that returns a custom HTTP response. Required if `type` is `fixed-response`.\n* `authenticate_cognito` - (Optional) Information for creating an authenticate action using Cognito. Required if `type` is `authenticate-cognito`.\n* `authenticate_oidc` - (Optional) Information for creating an authenticate action using OIDC. Required if `type` is `authenticate-oidc`.\n\nForward Blocks (for `forward`) support the following:\n\n* `target_group` - (Required) One or more target groups block.\n* `stickiness` - (Optional) The target group stickiness for the rule.\n\nTarget Group Blocks (for `target_group`) supports the following:\n\n* `arn` - (Required) The Amazon Resource Name (ARN) of the target group.\n* `weight` - (Optional) The weight. The range is 0 to 999.\n\nTarget Group Stickiness Config Blocks (for `stickiness`) supports the following:\n\n* `enabled` - (Required) Indicates whether target group stickiness is enabled.\n* `duration` - (Optional) The time period, in seconds, during which requests from a client should be routed to the same target group. The range is 1-604800 seconds (7 days).\n\nRedirect Blocks (for `redirect`) support the following:\n\n~> **NOTE::** You can reuse URI components using the following reserved keywords: `#{protocol}`, `#{host}`, `#{port}`, `#{path}` (the leading \"/\" is removed) and `#{query}`.\n\n* `host` - (Optional) The hostname. This component is not percent-encoded. The hostname can contain `#{host}`. Defaults to `#{host}`.\n* `path` - (Optional) The absolute path, starting with the leading \"/\". This component is not percent-encoded. The path can contain #{host}, #{path}, and #{port}. Defaults to `/#{path}`.\n* `port` - (Optional) The port. Specify a value from `1` to `65535` or `#{port}`. Defaults to `#{port}`.\n* `protocol` - (Optional) The protocol. Valid values are `HTTP`, `HTTPS`, or `#{protocol}`. Defaults to `#{protocol}`.\n* `query` - (Optional) The query parameters, URL-encoded when necessary, but not percent-encoded. Do not include the leading \"?\". Defaults to `#{query}`.\n* `status_code` - (Required) The HTTP redirect code. The redirect is either permanent (`HTTP_301`) or temporary (`HTTP_302`).\n\nFixed-response Blocks (for `fixed_response`) support the following:\n\n* `content_type` - (Required) The content type. Valid values are `text/plain`, `text/css`, `text/html`, `application/javascript` and `application/json`.\n* `message_body` - (Optional) The message body.\n* `status_code` - (Optional) The HTTP response code. Valid values are `2XX`, `4XX`, or `5XX`.\n\nAuthenticate Cognito Blocks (for `authenticate_cognito`) supports the following:\n\n* `authentication_request_extra_params` - (Optional) The query parameters to include in the redirect request to the authorization endpoint. Max: 10.\n* `on_unauthenticated_request` - (Optional) The behavior if the user is not authenticated. Valid values: `deny`, `allow` and `authenticate`\n* `scope` - (Optional) The set of user claims to be requested from the IdP.\n* `session_cookie_name` - (Optional) The name of the cookie used to maintain session information.\n* `session_timeout` - (Optional) The maximum duration of the authentication session, in seconds.\n* `user_pool_arn` - (Required) The ARN of the Cognito user pool.\n* `user_pool_client_id` - (Required) The ID of the Cognito user pool client.\n* `user_pool_domain` - (Required) The domain prefix or fully-qualified domain name of the Cognito user pool.\n\nAuthenticate OIDC Blocks (for `authenticate_oidc`) supports the following:\n\n* `authentication_request_extra_params` - (Optional) The query parameters to include in the redirect request to the authorization endpoint. Max: 10.\n* `authorization_endpoint` - (Required) The authorization endpoint of the IdP.\n* `client_id` - (Required) The OAuth 2.0 client identifier.\n* `client_secret` - (Required) The OAuth 2.0 client secret.\n* `issuer` - (Required) The OIDC issuer identifier of the IdP.\n* `on_unauthenticated_request` - (Optional) The behavior if the user is not authenticated. Valid values: `deny`, `allow` and `authenticate`\n* `scope` - (Optional) The set of user claims to be requested from the IdP.\n* `session_cookie_name` - (Optional) The name of the cookie used to maintain session information.\n* `session_timeout` - (Optional) The maximum duration of the authentication session, in seconds.\n* `token_endpoint` - (Required) The token endpoint of the IdP.\n* `user_info_endpoint` - (Required) The user info endpoint of the IdP.\n\nAuthentication Request Extra Params Blocks (for `authentication_request_extra_params`) supports the following:\n\n* `key` - (Required) The key of query parameter\n* `value` - (Required) The value of query parameter\n\n### Condition Blocks\n\nOne or more condition blocks can be set per rule. Most condition types can only be specified once per rule except for `http-header` and `query-string` which can be specified multiple times.\n\nCondition Blocks (for `condition`) support the following:\n\n* `host_header` - (Optional) Contains a single `values` item which is a list of host header patterns to match. The maximum size of each pattern is 128 characters. Comparison is case insensitive. Wildcard characters supported: * (matches 0 or more characters) and ? (matches exactly 1 character). Only one pattern needs to match for the condition to be satisfied.\n* `http_header` - (Optional) HTTP headers to match. [HTTP Header block](#http-header-blocks) fields documented below.\n* `http_request_method` - (Optional) Contains a single `values` item which is a list of HTTP request methods or verbs to match. Maximum size is 40 characters. Only allowed characters are A-Z, hyphen (-) and underscore (\\_). Comparison is case sensitive. Wildcards are not supported. Only one needs to match for the condition to be satisfied. AWS recommends that GET and HEAD requests are routed in the same way because the response to a HEAD request may be cached.\n* `path_pattern` - (Optional) Contains a single `values` item which is a list of path patterns to match against the request URL. Maximum size of each pattern is 128 characters. Comparison is case sensitive. Wildcard characters supported: * (matches 0 or more characters) and ? (matches exactly 1 character). Only one pattern needs to match for the condition to be satisfied. Path pattern is compared only to the path of the URL, not to its query string. To compare against the query string, use a `query_string` condition.\n* `query_string` - (Optional) Query strings to match. [Query String block](#query-string-blocks) fields documented below.\n* `source_ip` - (Optional) Contains a single `values` item which is a list of source IP CIDR notations to match. You can use both IPv4 and IPv6 addresses. Wildcards are not supported. Condition is satisfied if the source IP address of the request matches one of the CIDR blocks. Condition is not satisfied by the addresses in the `X-Forwarded-For` header, use `http_header` condition instead.\n\n~> **NOTE::** Exactly one of `host_header`, `http_header`, `http_request_method`, `path_pattern`, `query_string` or `source_ip` must be set per condition.\n\n#### HTTP Header Blocks\n\nHTTP Header Blocks (for `http_header`) support the following:\n\n* `http_header_name` - (Required) Name of HTTP header to search. The maximum size is 40 characters. Comparison is case insensitive. Only RFC7240 characters are supported. Wildcards are not supported. You cannot use HTTP header condition to specify the host header, use a `host-header` condition instead.\n* `values` - (Required) List of header value patterns to match. Maximum size of each pattern is 128 characters. Comparison is case insensitive. Wildcard characters supported: * (matches 0 or more characters) and ? (matches exactly 1 character). If the same header appears multiple times in the request they will be searched in order until a match is found. Only one pattern needs to match for the condition to be satisfied. To require that all of the strings are a match, create one condition block per string.\n\n#### Query String Blocks\n\nQuery String Blocks (for `query_string`) support the following:\n\n* `values` - (Required) Query string pairs or values to match. Query String Value blocks documented below. Multiple `values` blocks can be specified, see example above. Maximum size of each string is 128 characters. Comparison is case insensitive. Wildcard characters supported: * (matches 0 or more characters) and ? (matches exactly 1 character). To search for a literal '\\*' or '?' character in a query string, escape the character with a backslash (\\\\). Only one pair needs to match for the condition to be satisfied.\n\nQuery String Value Blocks (for `query_string.values`) support the following:\n\n* `key` - (Optional) Query string key pattern to match.\n* `value` - (Required) Query string value pattern to match.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the rule (matches `arn`)\n* `arn` - The ARN of the rule (matches `id`)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRules can be imported using their ARN, e.g.,\n\n```\n$ terraform import aws_lb_listener_rule.front_end arn:aws:elasticloadbalancing:us-west-2:187416307283:listener-rule/app/test/8e4497da625e2d8a/9ab28ade35828f96/67b3d2d36dd7c26b\n```\n",
    "basename": "lb_listener_rule.html"
  },
  "lb_ssl_negotiation_policy.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_lb_ssl_negotiation_policy",
    "description": "Provides a load balancer SSL negotiation policy, which allows an ELB to control which ciphers and protocols are supported during SSL negotiations between a client and a load balancer.",
    "preview": "# Resource: aws_lb_ssl_negotiation_policy\n\nProvides a load balancer …",
    "content": "\n\n# Resource: aws_lb_ssl_negotiation_policy\n\nProvides a load balancer SSL negotiation policy, which allows an ELB to control the ciphers and protocols that are supported during SSL negotiations between a client and a load balancer.\n\n## Example Usage\n\n```terraform\nresource \"aws_elb\" \"lb\" {\n  name               = \"test-lb\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port      = 8000\n    instance_protocol  = \"https\"\n    lb_port            = 443\n    lb_protocol        = \"https\"\n    ssl_certificate_id = \"arn:aws:iam::123456789012:server-certificate/certName\"\n  }\n}\n\nresource \"aws_lb_ssl_negotiation_policy\" \"foo\" {\n  name          = \"foo-policy\"\n  load_balancer = aws_elb.lb.id\n  lb_port       = 443\n\n  attribute {\n    name  = \"Protocol-TLSv1\"\n    value = \"false\"\n  }\n\n  attribute {\n    name  = \"Protocol-TLSv1.1\"\n    value = \"false\"\n  }\n\n  attribute {\n    name  = \"Protocol-TLSv1.2\"\n    value = \"true\"\n  }\n\n  attribute {\n    name  = \"Server-Defined-Cipher-Order\"\n    value = \"true\"\n  }\n\n  attribute {\n    name  = \"ECDHE-RSA-AES128-GCM-SHA256\"\n    value = \"true\"\n  }\n\n  attribute {\n    name  = \"AES128-GCM-SHA256\"\n    value = \"true\"\n  }\n\n  attribute {\n    name  = \"EDH-RSA-DES-CBC3-SHA\"\n    value = \"false\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the SSL negotiation policy.\n* `load_balancer` - (Required) The load balancer to which the policy\n  should be attached.\n* `lb_port` - (Required) The load balancer port to which the policy\n  should be applied. This must be an active listener on the load\nbalancer.\n* `attribute` - (Optional) An SSL Negotiation policy attribute. Each has two properties:\n    * `name` - The name of the attribute\n    * `value` - The value of the attribute\n\nTo set your attributes, please see the [AWS Elastic Load Balancing Developer Guide](http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-security-policy-table.html) for a listing of the supported SSL protocols, SSL options, and SSL ciphers.\n\n~> **NOTE:** The AWS documentation references Server Order Preference, which the AWS Elastic Load Balancing API refers to as `Server-Defined-Cipher-Order`. If you wish to set Server Order Preference, use this value instead.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the policy.\n* `name` - The name of the stickiness policy.\n* `load_balancer` - The load balancer to which the policy is attached.\n* `lb_port` - The load balancer port to which the policy is applied.\n* `attribute` - The SSL Negotiation policy attributes.\n",
    "basename": "lb_ssl_negotiation_policy.html"
  },
  "lb_target_group.html": {
    "subcategory": "Elastic Load Balancing v2 (ALB/NLB)",
    "layout": "aws",
    "page_title": "AWS: aws_lb_target_group",
    "description": "Provides a Target Group resource for use with Load Balancers.",
    "preview": "# Resource: aws_lb_target_group\n\nProvides a Target Group resource …",
    "content": "\n\n# Resource: aws_lb_target_group\n\nProvides a Target Group resource for use with Load Balancer resources.\n\n~> **Note:** `aws_alb_target_group` is known as `aws_lb_target_group`. The functionality is identical.\n\n## Example Usage\n\n### Instance Target Group\n\n```terraform\nresource \"aws_lb_target_group\" \"test\" {\n  name     = \"tf-example-lb-tg\"\n  port     = 80\n  protocol = \"HTTP\"\n  vpc_id   = aws_vpc.main.id\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n```\n\n### IP Target Group\n\n```terraform\nresource \"aws_lb_target_group\" \"ip-example\" {\n  name        = \"tf-example-lb-tg\"\n  port        = 80\n  protocol    = \"HTTP\"\n  target_type = \"ip\"\n  vpc_id      = aws_vpc.main.id\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n```\n\n### Lambda Target Group\n\n```terraform\nresource \"aws_lb_target_group\" \"lambda-example\" {\n  name        = \"tf-example-lb-tg\"\n  target_type = \"lambda\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `connection_termination` - (Optional) Whether to terminate connections at the end of the deregistration timeout on Network Load Balancers. See [doc](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#deregistration-delay) for more information. Default is `false`.\n* `deregistration_delay` - (Optional) Amount time for Elastic Load Balancing to wait before changing the state of a deregistering target from draining to unused. The range is 0-3600 seconds. The default value is 300 seconds.\n* `health_check` - (Optional, Maximum of 1) Health Check configuration block. Detailed below.\n* `lambda_multi_value_headers_enabled` - (Optional) Whether the request and response headers exchanged between the load balancer and the Lambda function include arrays of values or strings. Only applies when `target_type` is `lambda`. Default is `false`.\n* `load_balancing_algorithm_type` - (Optional) Determines how the load balancer selects targets when routing requests. Only applicable for Application Load Balancer Target Groups. The value is `round_robin` or `least_outstanding_requests`. The default is `round_robin`.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`. Cannot be longer than 6 characters.\n* `name` - (Optional, Forces new resource) Name of the target group. If omitted, Terraform will assign a random, unique name.\n* `port` - (May be required, Forces new resource) Port on which targets receive traffic, unless overridden when registering a specific target. Required when `target_type` is `instance` or `ip`. Does not apply when `target_type` is `lambda`.\n* `preserve_client_ip` - (Optional) Whether client IP preservation is enabled. See [doc](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation) for more information.\n* `protocol_version` - (Optional, Forces new resource) Only applicable when `protocol` is `HTTP` or `HTTPS`. The protocol version. Specify GRPC to send requests to targets using gRPC. Specify HTTP2 to send requests to targets using HTTP/2. The default is HTTP1, which sends requests to targets using HTTP/1.1\n* `protocol` - (May be required, Forces new resource) Protocol to use for routing traffic to the targets. Should be one of `GENEVE`, `HTTP`, `HTTPS`, `TCP`, `TCP_UDP`, `TLS`, or `UDP`. Required when `target_type` is `instance` or `ip`. Does not apply when `target_type` is `lambda`.\n* `proxy_protocol_v2` - (Optional) Whether to enable support for proxy protocol v2 on Network Load Balancers. See [doc](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#proxy-protocol) for more information. Default is `false`.\n* `slow_start` - (Optional) Amount time for targets to warm up before the load balancer sends them a full share of requests. The range is 30-900 seconds or 0 to disable. The default value is 0 seconds.\n* `stickiness` - (Optional, Maximum of 1) Stickiness configuration block. Detailed below.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `target_type` - (May be required, Forces new resource) Type of target that you must specify when registering targets with this target group. See [doc](https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_CreateTargetGroup.html) for supported values. The default is `instance`.\n  \n  Note that you can't specify targets for a target group using both instance IDs and IP addresses.\n  \n  If the target type is `ip`, specify IP addresses from the subnets of the virtual private cloud (VPC) for the target group, the RFC 1918 range (10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16), and the RFC 6598 range (100.64.0.0/10). You can't specify publicly routable IP addresses.\n  \n  Network Load Balancers do not support the `lambda` target type.\n  \n  Application Load Balancers do not support the `alb` target type.\n* `vpc_id` - (Optional, Forces new resource) Identifier of the VPC in which to create the target group. Required when `target_type` is `instance` or `ip`. Does not apply when `target_type` is `lambda`.\n\n### health_check\n\n~> **Note:** The Health Check parameters you can set vary by the `protocol` of the Target Group. Many parameters cannot be set to custom values for `network` load balancers at this time. See http://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_CreateTargetGroup.html for a complete reference. Keep in mind, that health checks produce actual requests to the backend. The underlying function is invoked when `target_type` is set to `lambda`.\n\n* `enabled` - (Optional) Whether health checks are enabled. Defaults to `true`.\n* `healthy_threshold` - (Optional) Number of consecutive health checks successes required before considering an unhealthy target healthy. Defaults to 3.\n* `interval` - (Optional) Approximate amount of time, in seconds, between health checks of an individual target. Minimum value 5 seconds, Maximum value 300 seconds. For `lambda` target groups, it needs to be greater as the `timeout` of the underlying `lambda`. Default 30 seconds.\n* `matcher` (May be required) Response codes to use when checking for a healthy responses from a target. You can specify multiple values (for example, \"200,202\" for HTTP(s) or \"0,12\" for GRPC) or a range of values (for example, \"200-299\" or \"0-99\"). Required for HTTP/HTTPS/GRPC ALB. Only applies to Application Load Balancers (i.e., HTTP/HTTPS/GRPC) not Network Load Balancers (i.e., TCP).\n* `path` - (May be required) Destination for the health check request. Required for HTTP/HTTPS ALB and HTTP NLB. Only applies to HTTP/HTTPS.\n* `port` - (Optional) Port to use to connect with the target. Valid values are either ports 1-65535, or `traffic-port`. Defaults to `traffic-port`.\n* `protocol` - (Optional) Protocol to use to connect with the target. Defaults to `HTTP`. Not applicable when `target_type` is `lambda`.\n* `timeout` - (Optional) Amount of time, in seconds, during which no response means a failed health check. For Application Load Balancers, the range is 2 to 120 seconds, and the default is 5 seconds for the `instance` target type and 30 seconds for the `lambda` target type. For Network Load Balancers, you cannot set a custom value, and the default is 10 seconds for TCP and HTTPS health checks and 6 seconds for HTTP health checks.\n* `unhealthy_threshold` - (Optional) Number of consecutive health check failures required before considering the target unhealthy. For Network Load Balancers, this value must be the same as the `healthy_threshold`. Defaults to 3.\n\n### stickiness\n\n~> **NOTE:** Currently, an NLB (i.e., protocol of `HTTP` or `HTTPS`) can have an invalid `stickiness` block with `type` set to `lb_cookie` as long as `enabled` is set to `false`. However, please update your configurations to avoid errors in a future version of the provider: either remove the invalid `stickiness` block or set the `type` to `source_ip`.\n\n* `cookie_duration` - (Optional) Only used when the type is `lb_cookie`. The time period, in seconds, during which requests from a client should be routed to the same target. After this time period expires, the load balancer-generated cookie is considered stale. The range is 1 second to 1 week (604800 seconds). The default value is 1 day (86400 seconds).\n* `cookie_name` - (Optional) Name of the application based cookie. AWSALB, AWSALBAPP, and AWSALBTG prefixes are reserved and cannot be used. Only needed when type is `app_cookie`.\n* `enabled` - (Optional) Boolean to enable / disable `stickiness`. Default is `true`.\n* `type` - (Required) The type of sticky sessions. The only current possible values are `lb_cookie`, `app_cookie` for ALBs, and `source_ip` for NLBs.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn_suffix` - ARN suffix for use with CloudWatch Metrics.\n* `arn` - ARN of the Target Group (matches `id`).\n* `id` - ARN of the Target Group (matches `arn`).\n* `name` - Name of the Target Group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nTarget Groups can be imported using their ARN, e.g.,\n\n```\n$ terraform import aws_lb_target_group.app_front_end arn:aws:elasticloadbalancing:us-west-2:187416307283:targetgroup/app-front-end/20cfe21448b66314\n```\n",
    "basename": "lb_target_group.html"
  },
  "lb_target_group_attachment.html": {
    "subcategory": "Elastic Load Balancing v2 (ALB/NLB)",
    "layout": "aws",
    "page_title": "AWS: aws_lb_target_group_attachment",
    "description": "Provides the ability to register instances and containers with a LB\ntarget group",
    "preview": "# Resource: aws_lb_target_group_attachment\n\nProvides the ability to …",
    "content": "\n\n# Resource: aws_lb_target_group_attachment\n\nProvides the ability to register instances and containers with an Application Load Balancer (ALB) or Network Load Balancer (NLB) target group. For attaching resources with Elastic Load Balancer (ELB), see the [`aws_elb_attachment` resource](/docs/providers/aws/r/elb_attachment.html).\n\n~> **Note:** `aws_alb_target_group_attachment` is known as `aws_lb_target_group_attachment`. The functionality is identical.\n\n## Example Usage\n\n```terraform\nresource \"aws_lb_target_group_attachment\" \"test\" {\n  target_group_arn = aws_lb_target_group.test.arn\n  target_id        = aws_instance.test.id\n  port             = 80\n}\n\nresource \"aws_lb_target_group\" \"test\" {\n  # ... other configuration ...\n}\n\nresource \"aws_instance\" \"test\" {\n  # ... other configuration ...\n}\n```\n\n## Usage with lambda\n\n```terraform\nresource \"aws_lambda_permission\" \"with_lb\" {\n  statement_id  = \"AllowExecutionFromlb\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.test.arn\n  principal     = \"elasticloadbalancing.amazonaws.com\"\n  source_arn    = aws_lb_target_group.test.arn\n}\n\nresource \"aws_lb_target_group\" \"test\" {\n  name        = \"test\"\n  target_type = \"lambda\"\n}\n\nresource \"aws_lambda_function\" \"test\" {\n  # ... other configuration ...\n}\n\nresource \"aws_lb_target_group_attachment\" \"test\" {\n  target_group_arn = aws_lb_target_group.test.arn\n  target_id        = aws_lambda_function.test.arn\n  depends_on       = [aws_lambda_permission.with_lb]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `target_group_arn` - (Required) The ARN of the target group with which to register targets\n* `target_id` (Required) The ID of the target. This is the Instance ID for an instance, or the container ID for an ECS container. If the target type is ip, specify an IP address. If the target type is lambda, specify the arn of lambda. If the target type is alb, specify the arn of alb.\n* `port` - (Optional) The port on which targets receive traffic.\n* `availability_zone` - (Optional) The Availability Zone where the IP address of the target is to be registered. If the private ip address is outside of the VPC scope, this value must be set to 'all'.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A unique identifier for the attachment\n\n## Import\n\nTarget Group Attachments cannot be imported.\n\n",
    "basename": "lb_target_group_attachment.html"
  },
  "lex_bot.html": {
    "subcategory": "Lex",
    "layout": "aws",
    "page_title": "AWS: aws_lex_bot",
    "description": "Provides an Amazon Lex bot resource.",
    "preview": "# Resource: aws_lex_bot\n\nProvides an Amazon Lex Bot resource. For …",
    "content": "\n\n# Resource: aws_lex_bot\n\nProvides an Amazon Lex Bot resource. For more information see\n[Amazon Lex: How It Works](https://docs.aws.amazon.com/lex/latest/dg/how-it-works.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_lex_bot\" \"order_flowers_bot\" {\n  abort_statement {\n    message {\n      content      = \"Sorry, I am not able to assist at this time\"\n      content_type = \"PlainText\"\n    }\n  }\n\n  child_directed = false\n\n  clarification_prompt {\n    max_attempts = 2\n\n    message {\n      content      = \"I didn't understand you, what would you like to do?\"\n      content_type = \"PlainText\"\n    }\n  }\n\n  create_version              = false\n  description                 = \"Bot to order flowers on the behalf of a user\"\n  idle_session_ttl_in_seconds = 600\n\n  intent {\n    intent_name    = \"OrderFlowers\"\n    intent_version = \"1\"\n  }\n\n  locale           = \"en-US\"\n  name             = \"OrderFlowers\"\n  process_behavior = \"BUILD\"\n  voice_id         = \"Salli\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `abort_statement` - (Required) The message that Amazon Lex uses to abort a conversation. Attributes are documented under [statement](#statement).\n* `child_directed` - (Required) By specifying true, you confirm that your use of Amazon Lex is related to a website, program, or other application that is directed or targeted, in whole or in part, to children under age 13 and subject to COPPA. For more information see the [Amazon Lex FAQ](https://aws.amazon.com/lex/faqs#data-security) and the [Amazon Lex PutBot API Docs](https://docs.aws.amazon.com/lex/latest/dg/API_PutBot.html#lex-PutBot-request-childDirected).\n* `clarification_prompt` - (Required) The message that Amazon Lex uses when it doesn't understand the user's request. Attributes are documented under [prompt](#prompt).\n* `create_version` - (Optional) Determines if a new bot version is created when the initial resource is created and on each update. Defaults to `false`.\n* `description` - (Optional) A description of the bot. Must be less than or equal to 200 characters in length.\n* `detect_sentiment` - (Optional) When set to true user utterances are sent to Amazon Comprehend for sentiment analysis. If you don't specify detectSentiment, the default is `false`.\n* `enable_model_improvements` - (Optional) Set to `true` to enable access to natural language understanding improvements. When you set the `enable_model_improvements` parameter to true you can use the `nlu_intent_confidence_threshold` parameter to configure confidence scores. For more information, see [Confidence Scores](https://docs.aws.amazon.com/lex/latest/dg/confidence-scores.html). You can only set the `enable_model_improvements` parameter in certain Regions. If you set the parameter to true, your bot has access to accuracy improvements. For more information see the [Amazon Lex Bot PutBot API Docs](https://docs.aws.amazon.com/lex/latest/dg/API_PutBot.html#lex-PutBot-request-enableModelImprovements).\n* `idle_session_ttl_in_seconds` - (Optional) The maximum time in seconds that Amazon Lex retains the data gathered in a conversation. Default is `300`. Must be a number between 60 and 86400 (inclusive).\n* `locale` - (Optional) Specifies the target locale for the bot. Any intent used in the bot must be compatible with the locale of the bot. For available locales, see [Amazon Lex Bot PutBot API Docs](https://docs.aws.amazon.com/lex/latest/dg/API_PutBot.html#lex-PutBot-request-locale). Default is `en-US`.\n* `intent` - (Required) A set of Intent objects. Each intent represents a command that a user can express. Attributes are documented under [intent](#intent). Can have up to 100 Intent objects.\n* `name` - (Required) The name of the bot that you want to create, case sensitive. Must be between 2 and 50 characters in length.\n* `nlu_intent_confidence_threshold` - (Optional) Determines the threshold where Amazon Lex will insert the AMAZON.FallbackIntent, AMAZON.KendraSearchIntent, or both when returning alternative intents in a PostContent or PostText response. AMAZON.FallbackIntent and AMAZON.KendraSearchIntent are only inserted if they are configured for the bot. For more information see [Amazon Lex Bot PutBot API Docs](https://docs.aws.amazon.com/lex/latest/dg/API_PutBot.html#lex-PutBot-request-nluIntentConfidenceThreshold) This value requires `enable_model_improvements` to be set to `true` and the default is `0`. Must be a float between 0 and 1.\n* `process_behavior` - (Optional) If you set the `process_behavior` element to `BUILD`, Amazon Lex builds the bot so that it can be run. If you set the element to `SAVE` Amazon Lex saves the bot, but doesn't build it. Default is `SAVE`.\n* `voice_id` - (Optional) The Amazon Polly voice ID that you want Amazon Lex to use for voice interactions with the user. The locale configured for the voice must match the locale of the bot. For more information, see [Available Voices](http://docs.aws.amazon.com/polly/latest/dg/voicelist.html) in the Amazon Polly Developer Guide.\n\n### intent\n\nIdentifies the specific version of an intent.\n\n* `intent_name` - (Required) The name of the intent. Must be less than or equal to 100 characters in length.\n* `intent_version` - (Required) The version of the intent. Must be less than or equal to 64 characters in length.\n\n### message\n\nThe message object that provides the message text and its type.\n\n* `content` - (Required) The text of the message.\n* `content_type` - (Required) The content type of the message string.\n* `group_number` - (Optional) Identifies the message group that the message belongs to. When a group\nis assigned to a message, Amazon Lex returns one message from each group in the response.\n\n### prompt\n\nObtains information from the user. To define a prompt, provide one or more messages and specify the\nnumber of attempts to get information from the user. If you provide more than one message, Amazon\nLex chooses one of the messages to use to prompt the user.\n\n* `max_attempts` - (Required) The number of times to prompt the user for information.\n* `message` - (Required) A set of messages, each of which provides a message string and its type.\nYou can specify the message string in plain text or in Speech Synthesis Markup Language (SSML).\nAttributes are documented under [message](#message).\n* `response_card` - (Optional) The response card. Amazon Lex will substitute session attributes and\nslot values into the response card. For more information, see\n[Example: Using a Response Card](https://docs.aws.amazon.com/lex/latest/dg/ex-resp-card.html).\n\n### statement\n\nA statement is a map with a set of message maps and an optional response card string. Messages\nconvey information to the user. At runtime, Amazon Lex selects the message to convey.\n\n* `message` - (Required) A set of messages, each of which provides a message string and its type. You\ncan specify the message string in plain text or in Speech Synthesis Markup Language (SSML). Attributes\nare documented under [message](#message).\n* `response_card` - (Optional) The response card. Amazon Lex will substitute session attributes and\nslot values into the response card. For more information, see\n[Example: Using a Response Card](https://docs.aws.amazon.com/lex/latest/dg/ex-resp-card.html).\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 5 mins) Used when creating the bot\n* `update` - (Defaults to 5 mins) Used when updating the bot\n* `delete` - (Defaults to 5 mins) Used when deleting the bot\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `checksum` - Checksum identifying the version of the bot that was created. The checksum is not\nincluded as an argument because the resource will add it automatically when updating the bot.\n* `created_date` - The date when the bot version was created.\n* `failure_reason` - If status is FAILED, Amazon Lex provides the reason that it failed to build the bot.\n* `last_updated_date` - The date when the $LATEST version of this bot was updated.\n* `status` - When you send a request to create or update a bot, Amazon Lex sets the status response\nelement to BUILDING. After Amazon Lex builds the bot, it sets status to READY. If Amazon Lex can't\nbuild the bot, it sets status to FAILED. Amazon Lex returns the reason for the failure in the\nfailure_reason response element.\n* `version` - The version of the bot.\n\n## Import\n\nBots can be imported using their name.\n\n```\n$ terraform import aws_lex_bot.order_flowers_bot OrderFlowers\n```\n",
    "basename": "lex_bot.html"
  },
  "lex_bot_alias.html": {
    "subcategory": "Lex",
    "layout": "aws",
    "page_title": "AWS: aws_lex_bot_alias",
    "description": "Provides an Amazon Lex Bot Alias resource.",
    "preview": "# Resource: aws_lex_bot_alias\n\nProvides an Amazon Lex Bot Alias …",
    "content": "\n\n# Resource: aws_lex_bot_alias\n\nProvides an Amazon Lex Bot Alias resource. For more information see\n[Amazon Lex: How It Works](https://docs.aws.amazon.com/lex/latest/dg/how-it-works.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_lex_bot_alias\" \"order_flowers_prod\" {\n  bot_name    = \"OrderFlowers\"\n  bot_version = \"1\"\n  description = \"Production Version of the OrderFlowers Bot.\"\n  name        = \"OrderFlowersProd\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bot_name` - (Required) The name of the bot.\n* `bot_version` - (Required) The name of the bot.\n* `conversation_logs` - (Optional) The settings that determine how Amazon Lex uses conversation logs for the alias. Attributes are documented under [conversation_logs](#conversation_logs).\n* `description` - (Optional) A description of the alias. Must be less than or equal to 200 characters in length.\n* `name` - (Required) The name of the alias. The name is not case sensitive. Must be less than or equal to 100 characters in length.\n\n### conversation_logs\n\nContains information about conversation log settings.\n\n* `iam_role_arn` - (Required) The Amazon Resource Name (ARN) of the IAM role used to write your logs to CloudWatch Logs or an S3 bucket. Must be between 20 and 2048 characters in length.\n* `log_settings` - (Optional) The settings for your conversation logs. You can log text, audio, or both. Attributes are documented under [log_settings](#log_settings).\n\n### log_settings\n\nThe settings for conversation logs.\n\n* `destination` - (Required) The destination where logs are delivered. Options are `CLOUDWATCH_LOGS` or `S3`.\n* `kms_key_arn` - (Optional) The Amazon Resource Name (ARN) of the key used to encrypt audio logs in an S3 bucket. This can only be specified when `destination` is set to `S3`. Must be between 20 and 2048 characters in length.\n* `log_type` - (Required) The type of logging that is enabled. Options are `AUDIO` or `TEXT`.\n* `resource_arn` - (Required) The Amazon Resource Name (ARN) of the CloudWatch Logs log group or S3 bucket where the logs are delivered. Must be less than or equal to 2048 characters in length.\n* `resource_prefix` - (Computed) The prefix of the S3 object key for `AUDIO` logs or the log stream name for `TEXT` logs.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 1 mins) Used when creating the bot alias\n* `update` - (Defaults to 1 mins) Used when updating the bot alias\n* `delete` - (Defaults to 5 mins) Used when deleting the bot alias\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the bot alias.\n* `checksum` - Checksum of the bot alias.\n* `created_date` - The date that the bot alias was created.\n* `last_updated_date` - The date that the bot alias was updated. When you create a resource, the creation date and the last updated date are the same.\n\n## Import\n\nBot aliases can be imported using an ID with the format `bot_name:bot_alias_name`.\n\n```\n$ terraform import aws_lex_bot_alias.order_flowers_prod OrderFlowers:OrderFlowersProd\n```\n",
    "basename": "lex_bot_alias.html"
  },
  "lex_intent.html": {
    "subcategory": "Lex",
    "layout": "aws",
    "page_title": "AWS: aws_lex_intent",
    "description": "Provides an Amazon Lex intent resource.",
    "preview": "# Resource: aws_lex_intent\n\nProvides an Amazon Lex Intent resource. …",
    "content": "\n\n# Resource: aws_lex_intent\n\nProvides an Amazon Lex Intent resource. For more information see\n[Amazon Lex: How It Works](https://docs.aws.amazon.com/lex/latest/dg/how-it-works.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_lex_intent\" \"order_flowers_intent\" {\n  confirmation_prompt {\n    max_attempts = 2\n\n    message {\n      content      = \"Okay, your {FlowerType} will be ready for pickup by {PickupTime} on {PickupDate}.  Does this sound okay?\"\n      content_type = \"PlainText\"\n    }\n  }\n\n  create_version = false\n  name           = \"OrderFlowers\"\n  description    = \"Intent to order a bouquet of flowers for pick up\"\n\n  fulfillment_activity {\n    type = \"ReturnIntent\"\n  }\n\n  rejection_statement {\n    message {\n      content      = \"Okay, I will not place your order.\"\n      content_type = \"PlainText\"\n    }\n  }\n\n  sample_utterances = [\n    \"I would like to order some flowers\",\n    \"I would like to pick up flowers\",\n  ]\n\n  slot {\n    description = \"The type of flowers to pick up\"\n    name        = \"FlowerType\"\n    priority    = 1\n\n    sample_utterances = [\n      \"I would like to order {FlowerType}\",\n    ]\n\n    slot_constraint   = \"Required\"\n    slot_type         = \"FlowerTypes\"\n    slot_type_version = \"$$LATEST\"\n\n    value_elicitation_prompt {\n      max_attempts = 2\n\n      message {\n        content      = \"What type of flowers would you like to order?\"\n        content_type = \"PlainText\"\n      }\n    }\n  }\n\n  slot {\n    description = \"The date to pick up the flowers\"\n    name        = \"PickupDate\"\n    priority    = 2\n\n    sample_utterances = [\n      \"I would like to order {FlowerType}\",\n    ]\n\n    slot_constraint   = \"Required\"\n    slot_type         = \"AMAZON.DATE\"\n    slot_type_version = \"$$LATEST\"\n\n    value_elicitation_prompt {\n      max_attempts = 2\n\n      message {\n        content      = \"What day do you want the {FlowerType} to be picked up?\"\n        content_type = \"PlainText\"\n      }\n    }\n  }\n\n  slot {\n    description = \"The time to pick up the flowers\"\n    name        = \"PickupTime\"\n    priority    = 3\n\n    sample_utterances = [\n      \"I would like to order {FlowerType}\",\n    ]\n\n    slot_constraint   = \"Required\"\n    slot_type         = \"AMAZON.TIME\"\n    slot_type_version = \"$$LATEST\"\n\n    value_elicitation_prompt {\n      max_attempts = 2\n\n      message {\n        content      = \"Pick up the {FlowerType} at what time on {PickupDate}?\"\n        content_type = \"PlainText\"\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `conclusion_statement` - (Optional) The statement that you want Amazon Lex to convey to the user\nafter the intent is successfully fulfilled by the Lambda function. This element is relevant only if\nyou provide a Lambda function in the `fulfillment_activity`. If you return the intent to the client\napplication, you can't specify this element. The `follow_up_prompt` and `conclusion_statement` are\nmutually exclusive. You can specify only one. Attributes are documented under [statement](#statement).\n* `confirmation_prompt` - (Optional) Prompts the user to confirm the intent. This question should\nhave a yes or no answer. You you must provide both the `rejection_statement` and `confirmation_prompt`,\nor neither. Attributes are documented under [prompt](#prompt).\n* `create_version` - (Optional) Determines if a new slot type version is created when the initial\nresource is created and on each update. Defaults to `false`.\n* `description` - (Optional) A description of the intent. Must be less than or equal to 200 characters in length.\n* `dialog_code_hook` - (Optional) Specifies a Lambda function to invoke for each user input. You can\ninvoke this Lambda function to personalize user interaction. Attributes are documented under [code_hook](#code_hook).\n* `follow_up_prompt` - (Optional) Amazon Lex uses this prompt to solicit additional activity after\nfulfilling an intent. For example, after the OrderPizza intent is fulfilled, you might prompt the\nuser to order a drink. The `follow_up_prompt` field and the `conclusion_statement` field are mutually\nexclusive. You can specify only one. Attributes are documented under [follow_up_prompt](#follow_up_prompt).\n* `fulfillment_activity` - (Required) Describes how the intent is fulfilled. For example, after a\nuser provides all of the information for a pizza order, `fulfillment_activity` defines how the bot\nplaces an order with a local pizza store. Attributes are documented under [fulfillment_activity](#fulfillment_activity).\n* `name` - (Required) The name of the intent, not case sensitive. Must be less than or equal to 100 characters in length.\n* `parent_intent_signature` - (Optional) A unique identifier for the built-in intent to base this\nintent on. To find the signature for an intent, see\n[Standard Built-in Intents](https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/built-in-intent-ref/standard-intents)\nin the Alexa Skills Kit.\n* `rejection_statement` - (Optional) When the user answers \"no\" to the question defined in\n`confirmation_prompt`, Amazon Lex responds with this statement to acknowledge that the intent was\ncanceled. You must provide both the `rejection_statement` and the `confirmation_prompt`, or neither.\nAttributes are documented under [statement](#statement).\n* `sample_utterances` - (Optional) An array of utterances (strings) that a user might say to signal\nthe intent. For example, \"I want {PizzaSize} pizza\", \"Order {Quantity} {PizzaSize} pizzas\".\nIn each utterance, a slot name is enclosed in curly braces. Must have between 1 and 10 items in the list, and each item must be less than or equal to 200 characters in length.\n* `slot` - (Optional) An list of intent slots. At runtime, Amazon Lex elicits required slot values\nfrom the user using prompts defined in the slots. Attributes are documented under [slot](#slot).\n\n### code_hook\n\nSpecifies a Lambda function that verifies requests to a bot or fulfills the user's request to a bot.\n\n* `message_version` - (Required) The version of the request-response that you want Amazon Lex to use\nto invoke your Lambda function. For more information, see\n[Using Lambda Functions](https://docs.aws.amazon.com/lex/latest/dg/using-lambda.html). Must be less than or equal to 5 characters in length.\n* `uri` - (Required) The Amazon Resource Name (ARN) of the Lambda function.\n\n### follow_up_prompt\n\nA prompt for additional activity after an intent is fulfilled. For example, after the OrderPizza\nintent is fulfilled, you might prompt the user to find out whether the user wants to order drinks.\n\n* `prompt` - (Required) Prompts for information from the user. Attributes are documented under [prompt](#prompt).\n* `rejection_statement` - (Optional) If the user answers \"no\" to the question defined in the prompt field,\nAmazon Lex responds with this statement to acknowledge that the intent was canceled. Attributes are\ndocumented below under [statement](#statement).\n\n### fulfillment_activity\n\nDescribes how the intent is fulfilled after the user provides all of the information required for the intent.\n\n* `type` - (Required) How the intent should be fulfilled, either by running a Lambda function or by\nreturning the slot data to the client application.\n* `code_hook` - (Optional) A description of the Lambda function that is run to fulfill the intent.\nRequired if type is CodeHook. Attributes are documented under [code_hook](#code_hook).\n\n### message\n\nThe message object that provides the message text and its type.\n\n* `content` - (Required) The text of the message. Must be less than or equal to 1000 characters in length.\n* `content_type` - (Required) The content type of the message string.\n* `group_number` - (Optional) Identifies the message group that the message belongs to. When a group\nis assigned to a message, Amazon Lex returns one message from each group in the response. Must be a number between 1 and 5 (inclusive).\n\n### prompt\n\nObtains information from the user. To define a prompt, provide one or more messages and specify the\nnumber of attempts to get information from the user. If you provide more than one message, Amazon\nLex chooses one of the messages to use to prompt the user.\n\n* `max_attempts` - (Required) The number of times to prompt the user for information. Must be a number between 1 and 5 (inclusive).\n* `message` - (Required) A set of messages, each of which provides a message string and its type.\nYou can specify the message string in plain text or in Speech Synthesis Markup Language (SSML).\nAttributes are documented under [message](#message). Must contain between 1 and 15 messages.\n* `response_card` - (Optional) The response card. Amazon Lex will substitute session attributes and\nslot values into the response card. For more information, see\n[Example: Using a Response Card](https://docs.aws.amazon.com/lex/latest/dg/ex-resp-card.html). Must be less than or equal to 50000 characters in length.\n\n### slot\n\nIdentifies the version of a specific slot.\n\n* `name` - (Required) The name of the intent slot that you want to create. The name is case sensitive. Must be less than or equal to 100 characters in length.\n* `slot_constraint` - (Required) Specifies whether the slot is required or optional.\n* `description` - (Optional) A description of the bot. Must be less than or equal to 200 characters in length.\n* `priority` - (Optional) Directs Lex the order in which to elicit this slot value from the user.\nFor example, if the intent has two slots with priorities 1 and 2, AWS Lex first elicits a value for\nthe slot with priority 1. If multiple slots share the same priority, the order in which Lex elicits\nvalues is arbitrary. Must be between 1 and 100.\n* `response_card` - (Optional) The response card. Amazon Lex will substitute session attributes and\nslot values into the response card. For more information, see\n[Example: Using a Response Card](https://docs.aws.amazon.com/lex/latest/dg/ex-resp-card.html). Must be less than or equal to 50000 characters in length.\n* `sample_utterances` - (Optional) If you know a specific pattern with which users might respond to\nan Amazon Lex request for a slot value, you can provide those utterances to improve accuracy. This\nis optional. In most cases, Amazon Lex is capable of understanding user utterances. Must have between 1 and 10 items in the list, and each item must be less than or equal to 200 characters in length.\n* `slot_type` - (Optional) The type of the slot, either a custom slot type that you defined or one of\nthe built-in slot types. Must be less than or equal to 100 characters in length.\n* `slot_type_version` - (Optional) The version of the slot type. Must be less than or equal to 64 characters in length.\n* `value_elicitation_prompt` - (Optional) The prompt that Amazon Lex uses to elicit the slot value\nfrom the user. Attributes are documented under [prompt](#prompt).\n\n### statement\n\nA statement is a map with a set of message maps and an optional response card string. Messages\nconvey information to the user. At runtime, Amazon Lex selects the message to convey.\n\n* `message` - (Required) A set of messages, each of which provides a message string and its type.\nYou can specify the message string in plain text or in Speech Synthesis Markup Language (SSML).\nAttributes are documented under [message](#message). Must contain between 1 and 15 messages.\n* `response_card` - (Optional) The response card. Amazon Lex will substitute session attributes and\nslot values into the response card. For more information, see\n[Example: Using a Response Card](https://docs.aws.amazon.com/lex/latest/dg/ex-resp-card.html). Must be less than or equal to 50000 characters in length.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 1 min) Used when creating the intent\n* `update` - (Defaults to 1 min) Used when updating the intent\n* `delete` - (Defaults to 5 mins) Used when deleting the intent\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the Lex intent.\n* `checksum` - Checksum identifying the version of the intent that was created. The checksum is not\nincluded as an argument because the resource will add it automatically when updating the intent.\n* `created_date` - The date when the intent version was created.\n* `last_updated_date` - The date when the $LATEST version of this intent was updated.\n* `version` - The version of the bot.\n\n## Import\n\nIntents can be imported using their name.\n\n```\n$ terraform import aws_lex_intent.order_flowers_intent OrderFlowers\n```\n",
    "basename": "lex_intent.html"
  },
  "lex_slot_type.html": {
    "subcategory": "Lex",
    "layout": "aws",
    "page_title": "AWS: aws_lex_slot_type",
    "description": "Provides details about a specific Amazon Lex Slot Type",
    "preview": "# Resource: aws_lex_slot_type\n\nProvides an Amazon Lex Slot Type …",
    "content": "\n\n# Resource: aws_lex_slot_type\n\nProvides an Amazon Lex Slot Type resource. For more information see\n[Amazon Lex: How It Works](https://docs.aws.amazon.com/lex/latest/dg/how-it-works.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_lex_slot_type\" \"flower_types\" {\n  create_version = true\n  description    = \"Types of flowers to order\"\n\n  enumeration_value {\n    synonyms = [\n      \"Lirium\",\n      \"Martagon\",\n    ]\n\n    value = \"lilies\"\n  }\n\n  enumeration_value {\n    synonyms = [\n      \"Eduardoregelia\",\n      \"Podonix\",\n    ]\n\n    value = \"tulips\"\n  }\n\n  name                     = \"FlowerTypes\"\n  value_selection_strategy = \"ORIGINAL_VALUE\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `enumeration_value` - (Required) A list of EnumerationValue objects that defines the values that\nthe slot type can take. Each value can have a list of synonyms, which are additional values that help\ntrain the machine learning model about the values that it resolves for a slot. Attributes are\ndocumented under [enumeration_value](#enumeration_value).\n* `name` - (Required) The name of the slot type. The name is not case sensitive. Must be less than or equal to 100 characters in length.\n* `create_version` - (Optional)\nDetermines if a new slot type version is created when the initial resource is created and on each\nupdate. Defaults to `false`.\n* `description` - (Optional) A description of the slot type. Must be less than or equal to 200 characters in length.\n* `value_selection_strategy` - (Optional) Determines the slot resolution strategy that Amazon Lex\nuses to return slot type values. `ORIGINAL_VALUE` returns the value entered by the user if the user\nvalue is similar to the slot value. `TOP_RESOLUTION` returns the first value in the resolution list\nif there is a resolution list for the slot, otherwise null is returned. Defaults to `ORIGINAL_VALUE`.\n\n### enumeration_value\n\nEach slot type can have a set of values. Each enumeration value represents a value the slot type\ncan take.\n\nFor example, a pizza ordering bot could have a slot type that specifies the type of crust that the\npizza should have. The slot type could include the values: thick, thin, stuffed.\n\n* `synonyms` - (Optional) Additional values related to the slot type value. Each item must be less than or equal to 140 characters in length.\n* `value` - (Required) The value of the slot type. Must be less than or equal to 140 characters in length.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 1 min) Used when creating the slot type\n* `update` - (Defaults to 1 min) Used when updating the slot type\n* `delete` - (Defaults to 5 mins) Used when deleting the slot type\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `checksum` - Checksum identifying the version of the slot type that was created. The checksum is\nnot included as an argument because the resource will add it automatically when updating the slot type.\n* `created_date` - The date when the slot type version was created.\n* `last_updated_date` - The date when the `$LATEST` version of this slot type was updated.\n* `version` - The version of the slot type.\n\n## Import\n\nSlot types can be imported using their name.\n\n```\n$ terraform import aws_lex_slot_type.flower_types FlowerTypes\n```\n",
    "basename": "lex_slot_type.html"
  },
  "licensemanager_association": {
    "subcategory": "License Manager",
    "layout": "aws",
    "page_title": "AWS: aws_licensemanager_association",
    "description": "Provides a License Manager association resource.",
    "preview": "# Resource: aws_licensemanager_association\n\nProvides a License …",
    "content": "\n\n# Resource: aws_licensemanager_association\n\nProvides a License Manager association.\n\n~> **Note:** License configurations can also be associated with launch templates by specifying the `license_specifications` block for an `aws_launch_template`.\n\n## Example Usage\n\n```terraform\ndata \"aws_ami\" \"example\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"amzn-ami-vpc-nat*\"]\n  }\n}\n\nresource \"aws_instance\" \"example\" {\n  ami           = data.aws_ami.example.id\n  instance_type = \"t2.micro\"\n}\n\nresource \"aws_licensemanager_license_configuration\" \"example\" {\n  name                  = \"Example\"\n  license_counting_type = \"Instance\"\n}\n\nresource \"aws_licensemanager_association\" \"example\" {\n  license_configuration_arn = aws_licensemanager_license_configuration.example.arn\n  resource_arn              = aws_instance.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `license_configuration_arn` - (Required) ARN of the license configuration.\n* `resource_arn` - (Required) ARN of the resource associated with the license configuration.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The license configuration ARN.\n\n## Import\n\nLicense configurations can be imported in the form `resource_arn,license_configuration_arn`, e.g.,\n\n```\n$ terraform import aws_licensemanager_association.example arn:aws:ec2:eu-west-1:123456789012:image/ami-123456789abcdef01,arn:aws:license-manager:eu-west-1:123456789012:license-configuration:lic-0123456789abcdef0123456789abcdef\n```\n",
    "basename": "licensemanager_association"
  },
  "licensemanager_license_configuration": {
    "subcategory": "License Manager",
    "layout": "aws",
    "page_title": "AWS: aws_licensemanager_license_configuration",
    "description": "Provides a License Manager license configuration resource.",
    "preview": "# Resource: aws_licensemanager_license_configuration\n\nProvides a …",
    "content": "\n\n# Resource: aws_licensemanager_license_configuration\n\nProvides a License Manager license configuration resource.\n\n~> **Note:** Removing the `license_count` attribute is not supported by the License Manager API - use `terraform taint aws_licensemanager_license_configuration.<id>` to recreate the resource instead.\n\n## Example Usage\n\n```terraform\nresource \"aws_licensemanager_license_configuration\" \"example\" {\n  name                     = \"Example\"\n  description              = \"Example\"\n  license_count            = 10\n  license_count_hard_limit = true\n  license_counting_type    = \"Socket\"\n\n  license_rules = [\n    \"#minimumSockets=2\",\n  ]\n\n  tags = {\n    foo = \"barr\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name of the license configuration.\n* `description` - (Optional) Description of the license configuration.\n* `license_count` - (Optional) Number of licenses managed by the license configuration.\n* `license_count_hard_limit` - (Optional) Sets the number of available licenses as a hard limit.\n* `license_counting_type` - (Required) Dimension to use to track license inventory. Specify either `vCPU`, `Instance`, `Core` or `Socket`.\n* `license_rules` - (Optional) Array of configured License Manager rules.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Rules\n\nLicense rules should be in the format of `#RuleType=RuleValue`. Supported rule types:\n\n* `minimumVcpus` - Resource must have minimum vCPU count in order to use the license. Default: 1\n* `maximumVcpus` - Resource must have maximum vCPU count in order to use the license. Default: unbounded, limit: 10000\n* `minimumCores` - Resource must have minimum core count in order to use the license. Default: 1\n* `maximumCores` - Resource must have maximum core count in order to use the license. Default: unbounded, limit: 10000\n* `minimumSockets` - Resource must have minimum socket count in order to use the license. Default: 1\n* `maximumSockets` - Resource must have maximum socket count in order to use the license. Default: unbounded, limit: 10000\n* `allowedTenancy` - Defines where the license can be used. If set, restricts license usage to selected tenancies. Specify a comma delimited list of `EC2-Default`, `EC2-DedicatedHost`, `EC2-DedicatedInstance`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The license configuration ARN.\n* `id` - The license configuration ARN.\n* `owner_account_id` - Account ID of the owner of the license configuration.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nLicense configurations can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_licensemanager_license_configuration.example arn:aws:license-manager:eu-west-1:123456789012:license-configuration:lic-0123456789abcdef0123456789abcdef\n```\n",
    "basename": "licensemanager_license_configuration"
  },
  "lightsail_domain.html": {
    "subcategory": "Lightsail",
    "layout": "aws",
    "page_title": "AWS: aws_lightsail_domain",
    "description": "Provides an Lightsail Domain",
    "preview": "# Resource: aws_lightsail_domain\n\nCreates a domain resource for the …",
    "content": "\n\n# Resource: aws_lightsail_domain\n\nCreates a domain resource for the specified domain (e.g., example.com).\nYou cannot register a new domain name using Lightsail. You must register\na domain name using Amazon Route 53 or another domain name registrar.\nIf you have already registered your domain, you can enter its name in\nthis parameter to manage the DNS records for that domain.\n\n~> **Note:** Lightsail is currently only supported in a limited number of AWS Regions, please see [\"Regions and Availability Zones in Amazon Lightsail\"](https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-regions-and-availability-zones-in-amazon-lightsail) for more details\n\n## Example Usage\n\n```terraform\nresource \"aws_lightsail_domain\" \"domain_test\" {\n  domain_name = \"mydomain.com\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Required) The name of the Lightsail domain to manage\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name used for this domain\n* `arn` - The ARN of the Lightsail domain\n",
    "basename": "lightsail_domain.html"
  },
  "lightsail_instance.html": {
    "subcategory": "Lightsail",
    "layout": "aws",
    "page_title": "AWS: aws_lightsail_instance",
    "description": "Provides an Lightsail Instance",
    "preview": "# Resource: aws_lightsail_instance\n\nProvides a Lightsail Instance. …",
    "content": "\n\n# Resource: aws_lightsail_instance\n\nProvides a Lightsail Instance. Amazon Lightsail is a service to provide easy virtual private servers\nwith custom software already setup. See [What is Amazon Lightsail?](https://lightsail.aws.amazon.com/ls/docs/getting-started/article/what-is-amazon-lightsail)\nfor more information.\n\n~> **Note:** Lightsail is currently only supported in a limited number of AWS Regions, please see [\"Regions and Availability Zones in Amazon Lightsail\"](https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-regions-and-availability-zones-in-amazon-lightsail) for more details\n\n## Example Usage\n\n```terraform\n# Create a new GitLab Lightsail Instance\nresource \"aws_lightsail_instance\" \"gitlab_test\" {\n  name              = \"custom_gitlab\"\n  availability_zone = \"us-east-1b\"\n  blueprint_id      = \"string\"\n  bundle_id         = \"string\"\n  key_pair_name     = \"some_key_name\"\n  tags = {\n    foo = \"bar\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Lightsail Instance. Names be unique within each AWS Region in your Lightsail account.\n* `availability_zone` - (Required) The Availability Zone in which to create your\ninstance (see list below)\n* `blueprint_id` - (Required) The ID for a virtual private server image. A list of available blueprint IDs can be obtained using the AWS CLI command: `aws lightsail get-blueprints`\n* `bundle_id` - (Required) The bundle of specification information (see list below)\n* `key_pair_name` - (Optional) The name of your key pair. Created in the\nLightsail console (cannot use `aws_key_pair` at this time)\n* `user_data` - (Optional) launch script to configure server with additional user data\n* `tags` - (Optional) A map of tags to assign to the resource. To create a key-only tag, use an empty string as the value. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Availability Zones\nLightsail currently supports the following Availability Zones (e.g., `us-east-1a`):\n\n- `ap-northeast-1{a,c,d}`\n- `ap-northeast-2{a,c}`\n- `ap-south-1{a,b}`\n- `ap-southeast-1{a,b,c}`\n- `ap-southeast-2{a,b,c}`\n- `ca-central-1{a,b}`\n- `eu-central-1{a,b,c}`\n- `eu-west-1{a,b,c}`\n- `eu-west-2{a,b,c}`\n- `eu-west-3{a,b,c}`\n- `us-east-1{a,b,c,d,e,f}`\n- `us-east-2{a,b,c}`\n- `us-west-2{a,b,c}`\n\n## Bundles\n\nLightsail currently supports the following Bundle IDs (e.g., an instance in `ap-northeast-1` would use `small_2_0`):\n\n### Prefix\n\nA Bundle ID starts with one of the below size prefixes:\n\n- `nano_`\n- `micro_`\n- `small_`\n- `medium_`\n- `large_`\n- `xlarge_`\n- `2xlarge_`\n\n### Suffix\n\nA Bundle ID ends with one of the following suffixes depending on Availability Zone:\n\n- ap-northeast-1: `2_0`\n- ap-northeast-2: `2_0`\n- ap-south-1: `2_1`\n- ap-southeast-1: `2_0`\n- ap-southeast-2: `2_2`\n- ca-central-1: `2_0`\n- eu-central-1: `2_0`\n- eu-west-1: `2_0`\n- eu-west-2: `2_0`\n- eu-west-3: `2_0`\n- us-east-1: `2_0`\n- us-east-2: `2_0`\n- us-west-2: `2_0`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the Lightsail instance (matches `arn`).\n* `arn` - The ARN of the Lightsail instance (matches `id`).\n* `created_at` - The timestamp when the instance was created.\n* `ipv6_address` - (**Deprecated**) The first IPv6 address of the Lightsail instance. Use `ipv6_addresses` attribute instead.\n* `ipv6_addresses` - List of IPv6 addresses for the Lightsail instance.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nLightsail Instances can be imported using their name, e.g.,\n\n```\n$ terraform import aws_lightsail_instance.gitlab_test 'custom gitlab'\n```\n",
    "basename": "lightsail_instance.html"
  },
  "lightsail_instance_public_ports.html": {
    "subcategory": "Lightsail",
    "layout": "aws",
    "page_title": "AWS: aws_lightsail_instance_public_ports",
    "description": "Provides an Lightsail Instance",
    "preview": "# Resource: aws_lightsail_instance_public_ports\n\nOpens ports for a …",
    "content": "\n\n# Resource: aws_lightsail_instance_public_ports\n\nOpens ports for a specific Amazon Lightsail instance, and specifies the IP addresses allowed to connect to the instance through the ports, and the protocol.\n\n-> See [What is Amazon Lightsail?](https://lightsail.aws.amazon.com/ls/docs/getting-started/article/what-is-amazon-lightsail) for more information.\n\n~> **Note:** Lightsail is currently only supported in a limited number of AWS Regions, please see [\"Regions and Availability Zones in Amazon Lightsail\"](https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-regions-and-availability-zones-in-amazon-lightsail) for more details.\n\n## Example Usage\n\n```terraform\nresource \"aws_lightsail_instance\" \"test\" {\n  name              = \"yak_sail\"\n  availability_zone = data.aws_availability_zones.available.names[0]\n  blueprint_id      = \"amazon_linux\"\n  bundle_id         = \"nano_1_0\"\n}\n\nresource \"aws_lightsail_instance_public_ports\" \"test\" {\n  instance_name = aws_lightsail_instance.test.name\n\n  port_info {\n    protocol  = \"tcp\"\n    from_port = 80\n    to_port   = 80\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `instance_name` - (Required) Name of the Lightsail Instance.\n* `port_info` - (Required) Configuration block with port information. AWS closes all currently open ports that are not included in the `port_info`. Detailed below.\n\n### port_info\n\nThe following arguments are required:\n\n* `from_port` - (Required) First port in a range of open ports on an instance.\n* `protocol` - (Required) IP protocol name. Valid values are `tcp`, `all`, `udp`, and `icmp`.\n* `to_port` - (Required) Last port in a range of open ports on an instance.\n\nThe following arguments are optional:\n\n* `cidrs` - (Optional) Set of CIDR blocks.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ID of the resource.\n",
    "basename": "lightsail_instance_public_ports.html"
  },
  "lightsail_key_pair.html": {
    "subcategory": "Lightsail",
    "layout": "aws",
    "page_title": "AWS: aws_lightsail_key_pair",
    "description": "Provides an Lightsail Key Pair",
    "preview": "# Resource: aws_lightsail_key_pair\n\nProvides a Lightsail Key Pair, …",
    "content": "\n\n# Resource: aws_lightsail_key_pair\n\nProvides a Lightsail Key Pair, for use with Lightsail Instances. These key pairs\nare separate from EC2 Key Pairs, and must be created or imported for use with\nLightsail.\n\n~> **Note:** Lightsail is currently only supported in a limited number of AWS Regions, please see [\"Regions and Availability Zones in Amazon Lightsail\"](https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-regions-and-availability-zones-in-amazon-lightsail) for more details\n\n## Example Usage\n\n### Create New Key Pair\n\n```terraform\n# Create a new Lightsail Key Pair\nresource \"aws_lightsail_key_pair\" \"lg_key_pair\" {\n  name = \"lg_key_pair\"\n}\n```\n\n### Create New Key Pair with PGP Encrypted Private Key\n\n```terraform\nresource \"aws_lightsail_key_pair\" \"lg_key_pair\" {\n  name    = \"lg_key_pair\"\n  pgp_key = \"keybase:keybaseusername\"\n}\n```\n\n### Existing Public Key Import\n\n```terraform\nresource \"aws_lightsail_key_pair\" \"lg_key_pair\" {\n  name       = \"importing\"\n  public_key = file(\"~/.ssh/id_rsa.pub\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the Lightsail Key Pair. If omitted, a unique\nname will be generated by Terraform\n* `pgp_key` – (Optional) An optional PGP key to encrypt the resulting private\nkey material. Only used when creating a new key pair\n* `public_key` - (Required) The public key material. This public key will be\nimported into Lightsail\n\n~> **NOTE:** a PGP key is not required, however it is strongly encouraged.\nWithout a PGP key, the private key material will be stored in state unencrypted.\n`pgp_key` is ignored if `public_key` is supplied.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name used for this key pair\n* `arn` - The ARN of the Lightsail key pair\n* `fingerprint` - The MD5 public key fingerprint as specified in section 4 of RFC 4716.\n* `public_key` - the public key, base64 encoded\n* `private_key` - the private key, base64 encoded. This is only populated\nwhen creating a new key, and when no `pgp_key` is provided\n* `encrypted_private_key` – the private key material, base 64 encoded and\nencrypted with the given `pgp_key`. This is only populated when creating a new\nkey and `pgp_key` is supplied\n* `encrypted_fingerprint` - The MD5 public key fingerprint for the encrypted\nprivate key\n\n## Import\n\nLightsail Key Pairs cannot be imported, because the private and public key are\nonly available on initial creation.\n",
    "basename": "lightsail_key_pair.html"
  },
  "lightsail_static_ip.html": {
    "subcategory": "Lightsail",
    "layout": "aws",
    "page_title": "AWS: aws_lightsail_static_ip",
    "description": "Provides an Lightsail Static IP",
    "preview": "# Resource: aws_lightsail_static_ip\n\nAllocates a static IP address.\n …",
    "content": "\n\n# Resource: aws_lightsail_static_ip\n\nAllocates a static IP address.\n\n~> **Note:** Lightsail is currently only supported in a limited number of AWS Regions, please see [\"Regions and Availability Zones in Amazon Lightsail\"](https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-regions-and-availability-zones-in-amazon-lightsail) for more details\n\n## Example Usage\n\n```terraform\nresource \"aws_lightsail_static_ip\" \"test\" {\n  name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name for the allocated static IP\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the Lightsail static IP\n* `ip_address` - The allocated static IP address\n* `support_code` - The support code.\n",
    "basename": "lightsail_static_ip.html"
  },
  "lightsail_static_ip_attachment.html": {
    "subcategory": "Lightsail",
    "layout": "aws",
    "page_title": "AWS: aws_lightsail_static_ip_attachment",
    "description": "Provides an Lightsail Static IP Attachment",
    "preview": "# Resource: aws_lightsail_static_ip_attachment\n\nProvides a static IP …",
    "content": "\n\n# Resource: aws_lightsail_static_ip_attachment\n\nProvides a static IP address attachment - relationship between a Lightsail static IP & Lightsail instance.\n\n~> **Note:** Lightsail is currently only supported in a limited number of AWS Regions, please see [\"Regions and Availability Zones in Amazon Lightsail\"](https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-regions-and-availability-zones-in-amazon-lightsail) for more details\n\n## Example Usage\n\n```terraform\nresource \"aws_lightsail_static_ip_attachment\" \"test\" {\n  static_ip_name = aws_lightsail_static_ip.test.id\n  instance_name  = aws_lightsail_instance.test.id\n}\n\nresource \"aws_lightsail_static_ip\" \"test\" {\n  name = \"example\"\n}\n\nresource \"aws_lightsail_instance\" \"test\" {\n  name              = \"example\"\n  availability_zone = \"us-east-1b\"\n  blueprint_id      = \"string\"\n  bundle_id         = \"string\"\n  key_pair_name     = \"some_key_name\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `static_ip_name` - (Required) The name of the allocated static IP\n* `instance_name` - (Required) The name of the Lightsail instance to attach the IP to\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `ip_address` - The allocated static IP address\n",
    "basename": "lightsail_static_ip_attachment.html"
  },
  "load_balancer_backend_server_policy.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_load_balancer_backend_server_policy",
    "description": "Attaches a load balancer policy to an ELB backend server.",
    "preview": "# Resource: aws_load_balancer_backend_server_policy\n\nAttaches a load …",
    "content": "\n\n# Resource: aws_load_balancer_backend_server_policy\n\nAttaches a load balancer policy to an ELB backend server.\n\n\n## Example Usage\n\n```terraform\nresource \"aws_elb\" \"wu-tang\" {\n  name               = \"wu-tang\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port      = 443\n    instance_protocol  = \"http\"\n    lb_port            = 443\n    lb_protocol        = \"https\"\n    ssl_certificate_id = \"arn:aws:iam::000000000000:server-certificate/wu-tang.net\"\n  }\n\n  tags = {\n    Name = \"wu-tang\"\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-ca-pubkey-policy\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-ca-pubkey-policy\"\n  policy_type_name   = \"PublicKeyPolicyType\"\n\n  # The public key of a CA certificate file can be extracted with:\n  # $ cat wu-tang-ca.pem | openssl x509 -pubkey -noout | grep -v '\\-\\-\\-\\-' | tr -d '\\n' > wu-tang-pubkey\n  policy_attribute {\n    name  = \"PublicKey\"\n    value = file(\"wu-tang-pubkey\")\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-root-ca-backend-auth-policy\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-root-ca-backend-auth-policy\"\n  policy_type_name   = \"BackendServerAuthenticationPolicyType\"\n\n  policy_attribute {\n    name  = \"PublicKeyPolicyName\"\n    value = aws_load_balancer_policy.wu-tang-root-ca-pubkey-policy.policy_name\n  }\n}\n\nresource \"aws_load_balancer_backend_server_policy\" \"wu-tang-backend-auth-policies-443\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  instance_port      = 443\n\n  policy_names = [\n    aws_load_balancer_policy.wu-tang-root-ca-backend-auth-policy.policy_name,\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `load_balancer_name` - (Required) The load balancer to attach the policy to.\n* `policy_names` - (Required) List of Policy Names to apply to the backend server.\n* `instance_port` - (Required) The instance port to apply the policy to.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the policy.\n* `load_balancer_name` - The load balancer on which the policy is defined.\n* `instance_port` - The backend port the policies are applied to\n",
    "basename": "load_balancer_backend_server_policy.html"
  },
  "load_balancer_listener_policy.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_load_balancer_listener_policy",
    "description": "Attaches a load balancer policy to an ELB Listener.",
    "preview": "# Resource: aws_load_balancer_listener_policy\n\nAttaches a load …",
    "content": "\n\n# Resource: aws_load_balancer_listener_policy\n\nAttaches a load balancer policy to an ELB Listener.\n\n\n## Example Usage\n\n### Custom Policy\n\n```terraform\nresource \"aws_elb\" \"wu-tang\" {\n  name               = \"wu-tang\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port      = 443\n    instance_protocol  = \"http\"\n    lb_port            = 443\n    lb_protocol        = \"https\"\n    ssl_certificate_id = \"arn:aws:iam::000000000000:server-certificate/wu-tang.net\"\n  }\n\n  tags = {\n    Name = \"wu-tang\"\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-ssl\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-ssl\"\n  policy_type_name   = \"SSLNegotiationPolicyType\"\n\n  policy_attribute {\n    name  = \"ECDHE-ECDSA-AES128-GCM-SHA256\"\n    value = \"true\"\n  }\n\n  policy_attribute {\n    name  = \"Protocol-TLSv1.2\"\n    value = \"true\"\n  }\n}\n\nresource \"aws_load_balancer_listener_policy\" \"wu-tang-listener-policies-443\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  load_balancer_port = 443\n\n  policy_names = [\n    aws_load_balancer_policy.wu-tang-ssl.policy_name,\n  ]\n}\n```\n\nThis example shows how to customize the TLS settings of an HTTPS listener.\n\n### AWS Predefined Security Policy\n\n```terraform\nresource \"aws_elb\" \"wu-tang\" {\n  name               = \"wu-tang\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port      = 443\n    instance_protocol  = \"http\"\n    lb_port            = 443\n    lb_protocol        = \"https\"\n    ssl_certificate_id = \"arn:aws:iam::000000000000:server-certificate/wu-tang.net\"\n  }\n\n  tags = {\n    Name = \"wu-tang\"\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-ssl-tls-1-1\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-ssl\"\n  policy_type_name   = \"SSLNegotiationPolicyType\"\n\n  policy_attribute {\n    name  = \"Reference-Security-Policy\"\n    value = \"ELBSecurityPolicy-TLS-1-1-2017-01\"\n  }\n}\n\nresource \"aws_load_balancer_listener_policy\" \"wu-tang-listener-policies-443\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  load_balancer_port = 443\n\n  policy_names = [\n    aws_load_balancer_policy.wu-tang-ssl-tls-1-1.policy_name,\n  ]\n}\n```\n\nThis example shows how to add a [Predefined Security Policy for ELBs](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-policy-table.html)\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `load_balancer_name` - (Required) The load balancer to attach the policy to.\n* `load_balancer_port` - (Required) The load balancer listener port to apply the policy to.\n* `policy_names` - (Required) List of Policy Names to apply to the backend server.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the policy.\n* `load_balancer_name` - The load balancer on which the policy is defined.\n* `load_balancer_port` - The load balancer listener port the policies are applied to\n",
    "basename": "load_balancer_listener_policy.html"
  },
  "load_balancer_policy.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_load_balancer_policy",
    "description": "Provides a load balancer policy, which can be attached to an ELB listener or backend server.",
    "preview": "# Resource: aws_load_balancer_policy\n\nProvides a load balancer …",
    "content": "\n\n# Resource: aws_load_balancer_policy\n\nProvides a load balancer policy, which can be attached to an ELB listener or backend server.\n\n## Example Usage\n\n```terraform\nresource \"aws_elb\" \"wu-tang\" {\n  name               = \"wu-tang\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port      = 443\n    instance_protocol  = \"http\"\n    lb_port            = 443\n    lb_protocol        = \"https\"\n    ssl_certificate_id = \"arn:aws:iam::000000000000:server-certificate/wu-tang.net\"\n  }\n\n  tags = {\n    Name = \"wu-tang\"\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-ca-pubkey-policy\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-ca-pubkey-policy\"\n  policy_type_name   = \"PublicKeyPolicyType\"\n\n  # The public key of a CA certificate file can be extracted with:\n  # $ cat wu-tang-ca.pem | openssl x509 -pubkey -noout | grep -v '\\-\\-\\-\\-' | tr -d '\\n' > wu-tang-pubkey\n  policy_attribute {\n    name  = \"PublicKey\"\n    value = file(\"wu-tang-pubkey\")\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-root-ca-backend-auth-policy\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-root-ca-backend-auth-policy\"\n  policy_type_name   = \"BackendServerAuthenticationPolicyType\"\n\n  policy_attribute {\n    name  = \"PublicKeyPolicyName\"\n    value = aws_load_balancer_policy.wu-tang-root-ca-pubkey-policy.policy_name\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-ssl\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-ssl\"\n  policy_type_name   = \"SSLNegotiationPolicyType\"\n\n  policy_attribute {\n    name  = \"ECDHE-ECDSA-AES128-GCM-SHA256\"\n    value = \"true\"\n  }\n\n  policy_attribute {\n    name  = \"Protocol-TLSv1.2\"\n    value = \"true\"\n  }\n}\n\nresource \"aws_load_balancer_policy\" \"wu-tang-ssl-tls-1-1\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  policy_name        = \"wu-tang-ssl\"\n  policy_type_name   = \"SSLNegotiationPolicyType\"\n\n  policy_attribute {\n    name  = \"Reference-Security-Policy\"\n    value = \"ELBSecurityPolicy-TLS-1-1-2017-01\"\n  }\n}\n\nresource \"aws_load_balancer_backend_server_policy\" \"wu-tang-backend-auth-policies-443\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  instance_port      = 443\n\n  policy_names = [\n    aws_load_balancer_policy.wu-tang-root-ca-backend-auth-policy.policy_name,\n  ]\n}\n\nresource \"aws_load_balancer_listener_policy\" \"wu-tang-listener-policies-443\" {\n  load_balancer_name = aws_elb.wu-tang.name\n  load_balancer_port = 443\n\n  policy_names = [\n    aws_load_balancer_policy.wu-tang-ssl.policy_name,\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `load_balancer_name` - (Required) The load balancer on which the policy is defined.\n* `policy_name` - (Required) The name of the load balancer policy.\n* `policy_type_name` - (Required) The policy type.\n* `policy_attribute` - (Optional) Policy attribute to apply to the policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the policy.\n* `policy_name` - The name of the stickiness policy.\n* `policy_type_name` - The policy type of the policy.\n* `load_balancer_name` - The load balancer on which the policy is defined.\n",
    "basename": "load_balancer_policy.html"
  },
  "macie2_account.html": {
    "subcategory": "Macie",
    "layout": "aws",
    "page_title": "AWS: aws_macie2_account",
    "description": "Provides a resource to manage Amazon Macie on an AWS Account.",
    "preview": "# Resource: aws_macie2_account\n\nProvides a resource to manage an …",
    "content": "\n\n# Resource: aws_macie2_account\n\nProvides a resource to manage an [AWS Macie Account](https://docs.aws.amazon.com/macie/latest/APIReference/macie.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie2_account\" \"test\" {\n  finding_publishing_frequency = \"FIFTEEN_MINUTES\"\n  status                       = \"ENABLED\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `finding_publishing_frequency` -  (Optional) Specifies how often to publish updates to policy findings for the account. This includes publishing updates to AWS Security Hub and Amazon EventBridge (formerly called Amazon CloudWatch Events). Valid values are `FIFTEEN_MINUTES`, `ONE_HOUR` or `SIX_HOURS`.\n* `status` - (Optional) Specifies the status for the account. To enable Amazon Macie and start all Macie activities for the account, set this value to `ENABLED`. Valid values are `ENABLED` or `PAUSED`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the macie account.\n* `service_role` - The Amazon Resource Name (ARN) of the service-linked role that allows Macie to monitor and analyze data in AWS resources for the account.\n* `created_at` - The date and time, in UTC and extended RFC 3339 format, when the Amazon Macie account was created.\n* `updated_at` - The date and time, in UTC and extended RFC 3339 format, of the most recent change to the status of the Macie account.\n\n## Import\n\n`aws_macie2_account` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_macie2_account.example abcd1\n```\n",
    "basename": "macie2_account.html"
  },
  "macie2_classification_job.html": {
    "subcategory": "Macie",
    "layout": "aws",
    "page_title": "AWS: aws_macie2_classification_job",
    "description": "Provides a resource to manage an AWS Macie Classification Job.",
    "preview": "# Resource: aws_macie2_classification_job\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_macie2_classification_job\n\nProvides a resource to manage an [AWS Macie Classification Job](https://docs.aws.amazon.com/macie/latest/APIReference/jobs.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie2_account\" \"test\" {}\n\nresource \"aws_macie2_classification_job\" \"test\" {\n  job_type = \"ONE_TIME\"\n  name     = \"NAME OF THE CLASSIFICATION JOB\"\n  s3_job_definition {\n    bucket_definitions {\n      account_id = \"ACCOUNT ID\"\n      buckets    = [\"S3 BUCKET NAME\"]\n    }\n  }\n  depends_on = [aws_macie2_account.test]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `schedule_frequency` -  (Optional) The recurrence pattern for running the job. To run the job only once, don't specify a value for this property and set the value for the `job_type` property to `ONE_TIME`. (documented below)\n* `custom_data_identifier_ids` -  (Optional) The custom data identifiers to use for data analysis and classification.\n* `sampling_percentage` -  (Optional) The sampling depth, as a percentage, to apply when processing objects. This value determines the percentage of eligible objects that the job analyzes. If this value is less than 100, Amazon Macie selects the objects to analyze at random, up to the specified percentage, and analyzes all the data in those objects.\n* `name` -  (Optional) A custom name for the job. The name can contain as many as 500 characters. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`.\n* `name_prefix` -  (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` -  (Optional) A custom description of the job. The description can contain as many as 200 characters.\n* `initial_run` -  (Optional) Specifies whether to analyze all existing, eligible objects immediately after the job is created.\n* `job_type` -  (Required) The schedule for running the job. Valid values are: `ONE_TIME` - Run the job only once. If you specify this value, don't specify a value for the `schedule_frequency` property. `SCHEDULED` - Run the job on a daily, weekly, or monthly basis. If you specify this value, use the `schedule_frequency` property to define the recurrence pattern for the job.\n* `s3_job_definition` -  (Optional) The S3 buckets that contain the objects to analyze, and the scope of that analysis. (documented below)\n* `tags` -  (Optional) A map of key-value pairs that specifies the tags to associate with the job. A job can have a maximum of 50 tags. Each tag consists of a tag key and an associated tag value. The maximum length of a tag key is 128 characters. The maximum length of a tag value is 256 characters.\n* `job_status` -  (Optional) The status for the job. Valid values are: `CANCELLED`, `RUNNING` and `USER_PAUSED`\n\nThe `schedule_frequency` object supports the following:\n\n* `daily_schedule` -  (Optional) Specifies a daily recurrence pattern for running the job.\n* `weekly_schedule` -  (Optional) Specifies a weekly recurrence pattern for running the job.\n* `monthly_schedule` -  (Optional) Specifies a monthly recurrence pattern for running the job.\n\nThe `s3_job_definition` object supports the following:\n\n* `bucket_definitions` -  (Optional) An array of objects, one for each AWS account that owns buckets to analyze. Each object specifies the account ID for an account and one or more buckets to analyze for the account. (documented below)\n* `scoping` -  (Optional) The property- and tag-based conditions that determine which objects to include or exclude from the analysis. (documented below)\n\nThe `bucket_definitions` object supports the following:\n\n* `account_id` -  (Required) The unique identifier for the AWS account that owns the buckets.\n* `buckets` -  (Required) An array that lists the names of the buckets.\n\nThe `scoping` object supports the following:\n\n* `excludes` -  (Optional) The property- or tag-based conditions that determine which objects to exclude from the analysis. (documented below)\n* `includes` -  (Optional) The property- or tag-based conditions that determine which objects to include in the analysis. (documented below)\n\nThe `excludes` and `includes` object supports the following:\n\n* `and` -  (Optional) An array of conditions, one for each condition that determines which objects to include or exclude from the job. (documented below)\n\nThe `and` object supports the following:\n\n* `simple_scope_term` -  (Optional) A property-based condition that defines a property, operator, and one or more values for including or excluding an object from the job.  (documented below)\n* `tag_scope_term` -  (Optional) A tag-based condition that defines the operator and tag keys or tag key and value pairs for including or excluding an object from the job.  (documented below)\n\nThe `simple_scope_term` object supports the following:\n\n* `comparator` -  (Optional) The operator to use in a condition. Valid values are: `EQ`, `GT`, `GTE`, `LT`, `LTE`, `NE`, `CONTAINS`, `STARTS_WITH`\n* `values` -  (Optional) An array that lists the values to use in the condition.\n* `key` -  (Optional) The object property to use in the condition.\n\nThe `tag_scope_term` object supports the following:\n\n* `comparator` -  (Optional) The operator to use in the condition.\n* `tag_values` -  (Optional) The tag keys or tag key and value pairs to use in the condition.\n* `key` -  (Optional) The tag key to use in the condition.\n* `target` -  (Optional) The type of object to apply the condition to.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the macie classification job.\n* `created_at` -  The date and time, in UTC and extended RFC 3339 format, when the job was created.\n* `user_paused_details` - If the current status of the job is `USER_PAUSED`, specifies when the job was paused and when the job or job run will expire and be cancelled if it isn't resumed. This value is present only if the value for `job-status` is `USER_PAUSED`.\n\n## Import\n\n`aws_macie2_classification_job` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_macie2_classification_job.example abcd1\n```\n",
    "basename": "macie2_classification_job.html"
  },
  "macie2_custom_data_identifier.html": {
    "subcategory": "Macie",
    "layout": "aws",
    "page_title": "AWS: aws_macie2_custom_data_identifier",
    "description": "Provides a resource to manage an AWS Macie Custom Data Identifier.",
    "preview": "# Resource: aws_macie2_custom_data_identifier\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_macie2_custom_data_identifier\n\nProvides a resource to manage an [AWS Macie Custom Data Identifier](https://docs.aws.amazon.com/macie/latest/APIReference/custom-data-identifiers-id.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie2_account\" \"example\" {}\n\nresource \"aws_macie2_custom_data_identifier\" \"example\" {\n  name                   = \"NAME OF CUSTOM DATA IDENTIFIER\"\n  regex                  = \"[0-9]{3}-[0-9]{2}-[0-9]{4}\"\n  description            = \"DESCRIPTION\"\n  maximum_match_distance = 10\n  keywords               = [\"keyword\"]\n  ignore_words           = [\"ignore\"]\n\n  depends_on = [aws_macie2_account.test]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `regex` - (Optional) The regular expression (regex) that defines the pattern to match. The expression can contain as many as 512 characters.\n* `keywords` -  (Optional) An array that lists specific character sequences (keywords), one of which must be within proximity (`maximum_match_distance`) of the regular expression to match. The array can contain as many as 50 keywords. Each keyword can contain 3 - 90 characters. Keywords aren't case sensitive.\n* `ignore_words` - (Optional) An array that lists specific character sequences (ignore words) to exclude from the results. If the text matched by the regular expression is the same as any string in this array, Amazon Macie ignores it. The array can contain as many as 10 ignore words. Each ignore word can contain 4 - 90 characters. Ignore words are case sensitive.\n* `name` - (Optional) A custom name for the custom data identifier. The name can contain as many as 128 characters. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`.\n* `name_prefix` -  (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` - (Optional) A custom description of the custom data identifier. The description can contain as many as 512 characters.\n* `maximum_match_distance` - (Optional) The maximum number of characters that can exist between text that matches the regex pattern and the character sequences specified by the keywords array. Macie includes or excludes a result based on the proximity of a keyword to text that matches the regex pattern. The distance can be 1 - 300 characters. The default value is 50.\n* `tags` - (Optional) A map of key-value pairs that specifies the tags to associate with the custom data identifier.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the macie custom data identifier.\n* `deleted` - Specifies whether the custom data identifier was deleted. If you delete a custom data identifier, Amazon Macie doesn't delete it permanently. Instead, it soft deletes the identifier.\n* `created_at` - The date and time, in UTC and extended RFC 3339 format, when the Amazon Macie account was created.\n* `arn` - The Amazon Resource Name (ARN) of the custom data identifier.\n\n## Import\n\n`aws_macie2_custom_data_identifier` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_macie2_custom_data_identifier.example abcd1\n```\n",
    "basename": "macie2_custom_data_identifier.html"
  },
  "macie2_findings_filter.html": {
    "subcategory": "Macie",
    "layout": "aws",
    "page_title": "AWS: aws_macie2_findings_filter",
    "description": "Provides a resource to manage an Amazon Macie Findings Filter.",
    "preview": "# Resource: aws_macie2_findings_filter\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_macie2_findings_filter\n\nProvides a resource to manage an [Amazon Macie Findings Filter](https://docs.aws.amazon.com/macie/latest/APIReference/findingsfilters-id.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie2_account\" \"example\" {}\n\nresource \"aws_macie2_findings_filter\" \"test\" {\n  name        = \"NAME OF THE FINDINGS FILTER\"\n  description = \"DESCRIPTION\"\n  position    = 1\n  action      = \"ARCHIVE\"\n  finding_criteria {\n    criterion {\n      field = \"region\"\n      eq    = [data.aws_region.current.name]\n    }\n  }\n  depends_on = [aws_macie2_account.test]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `finding_criteria` - (Required) The criteria to use to filter findings.\n* `name` - (Optional) A custom name for the filter. The name must contain at least 3 characters and can contain as many as 64 characters. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`.\n* `name_prefix` -  (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` - (Optional) A custom description of the filter. The description can contain as many as 512 characters.\n* `action` - (Required) The action to perform on findings that meet the filter criteria (`finding_criteria`). Valid values are: `ARCHIVE`, suppress (automatically archive) the findings; and, `NOOP`, don't perform any action on the findings.\n* `position` - (Optional) The position of the filter in the list of saved filters on the Amazon Macie console. This value also determines the order in which the filter is applied to findings, relative to other filters that are also applied to the findings.\n* `tags` - (Optional) A map of key-value pairs that specifies the tags to associate with the filter.\n\nThe `finding_criteria` object supports the following:\n\n* `criterion` -  (Optional) A condition that specifies the property, operator, and one or more values to use to filter the results.  (documented below)\n\nThe `criterion` object supports the following:\n\n* `field` - (Required) The name of the field to be evaluated.\n* `eq_exact_match` - (Optional) The value for the property exclusively matches (equals an exact match for) all the specified values. If you specify multiple values, Amazon Macie uses AND logic to join the values.\n* `eq` - (Optional) The value for the property matches (equals) the specified value. If you specify multiple values, Amazon Macie uses OR logic to join the values.\n* `neq` - (Optional) The value for the property doesn't match (doesn't equal) the specified value. If you specify multiple values, Amazon Macie uses OR logic to join the values.\n* `lt` - (Optional) The value for the property is less than the specified value.\n* `lte` - (Optional) The value for the property is less than or equal to the specified value.\n* `gt` - (Optional) The value for the property is greater than the specified value.\n* `gte` - (Optional) The value for the property is greater than or equal to the specified value.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the macie Findings Filter.\n* `arn` - The Amazon Resource Name (ARN) of the Findings Filter.\n\n## Import\n\n`aws_macie2_findings_filter` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_macie2_findings_filter.example abcd1\n```\n",
    "basename": "macie2_findings_filter.html"
  },
  "macie2_invitation_accepter.html": {
    "subcategory": "Macie",
    "layout": "aws",
    "page_title": "AWS: aws_macie2_invitation_accepter",
    "description": "Provides a resource to manage an Amazon Macie Invitation Accepter.",
    "preview": "# Resource: aws_macie2_invitation_accepter\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_macie2_invitation_accepter\n\nProvides a resource to manage an [Amazon Macie Invitation Accepter](https://docs.aws.amazon.com/macie/latest/APIReference/invitations-accept.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie2_account\" \"primary\" {\n  provider = \"awsalternate\"\n}\n\nresource \"aws_macie2_account\" \"member\" {}\n\nresource \"aws_macie2_member\" \"primary\" {\n  provider           = \"awsalternate\"\n  account_id         = \"ACCOUNT ID\"\n  email              = \"EMAIL\"\n  invite             = true\n  invitation_message = \"Message of the invite\"\n  depends_on         = [aws_macie2_account.primary]\n}\n\nresource \"aws_macie2_invitation_accepter\" \"member\" {\n  administrator_account_id = \"ADMINISTRATOR ACCOUNT ID\"\n  depends_on               = [aws_macie2_member.primary]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `administrator_account_id` - (Required) The AWS account ID for the account that sent the invitation.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the macie invitation accepter.\n* `invitation_id` - The unique identifier for the invitation.\n\n## Import\n\n`aws_macie2_invitation_accepter` can be imported using the admin account ID, e.g.,\n\n```\n$ terraform import aws_macie2_invitation_accepter.example 123456789012\n```\n",
    "basename": "macie2_invitation_accepter.html"
  },
  "macie2_member.html": {
    "subcategory": "Macie",
    "layout": "aws",
    "page_title": "AWS: aws_macie2_member",
    "description": "Provides a resource to manage an Amazon Macie Member.",
    "preview": "# Resource: aws_macie2_member\n\nProvides a resource to manage an …",
    "content": "\n\n# Resource: aws_macie2_member\n\nProvides a resource to manage an [Amazon Macie Member](https://docs.aws.amazon.com/macie/latest/APIReference/members-id.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie2_account\" \"example\" {}\n\nresource \"aws_macie2_member\" \"example\" {\n  account_id                            = \"AWS ACCOUNT ID\"\n  email                                 = \"EMAIL\"\n  invite                                = true\n  invitation_message                    = \"Message of the invitation\"\n  invitation_disable_email_notification = true\n  depends_on                            = [aws_macie2_account.example]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Required) The AWS account ID for the account.\n* `email` - (Required) The email address for the account.\n* `tags` - (Optional) A map of key-value pairs that specifies the tags to associate with the account in Amazon Macie.\n* `status` - (Optional) Specifies the status for the account. To enable Amazon Macie and start all Macie activities for the account, set this value to `ENABLED`. Valid values are `ENABLED` or `PAUSED`.\n* `invite` - (Optional) Send an invitation to a member\n* `invitation_message` - (Optional) A custom message to include in the invitation. Amazon Macie adds this message to the standard content that it sends for an invitation.\n* `invitation_disable_email_notification` - (Optional) Specifies whether to send an email notification to the root user of each account that the invitation will be sent to. This notification is in addition to an alert that the root user receives in AWS Personal Health Dashboard. To send an email notification to the root user of each account, set this value to `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the macie Member.\n* `arn` - The Amazon Resource Name (ARN) of the account.\n* `relationship_status` - The current status of the relationship between the account and the administrator account.\n* `administrator_account_id` - The AWS account ID for the administrator account.\n* `invited_at` - The date and time, in UTC and extended RFC 3339 format, when an Amazon Macie membership invitation was last sent to the account. This value is null if a Macie invitation hasn't been sent to the account.\n* `updated_at` - The date and time, in UTC and extended RFC 3339 format, of the most recent change to the status of the relationship between the account and the administrator account.\n\n## Import\n\n`aws_macie2_member` can be imported using the account ID of the member account, e.g.,\n\n```\n$ terraform import aws_macie2_member.example 123456789012\n```\n",
    "basename": "macie2_member.html"
  },
  "macie2_organization_admin_account.html": {
    "subcategory": "Macie",
    "layout": "aws",
    "page_title": "AWS: aws_macie2_organization_admin_account",
    "description": "Provides a resource to manage an Amazon Macie Organization Admin Account.",
    "preview": "# Resource: aws_macie2_organization_admin_account\n\nProvides a …",
    "content": "\n\n# Resource: aws_macie2_organization_admin_account\n\nProvides a resource to manage an [Amazon Macie Organization Admin Account](https://docs.aws.amazon.com/macie/latest/APIReference/admin.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie2_account\" \"example\" {}\n\nresource \"aws_macie2_organization_admin_account\" \"test\" {\n  admin_account_id = \"ID OF THE ADMIN ACCOUNT\"\n  depends_on       = [aws_macie2_account.test]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `admin_account_id` - (Required) The AWS account ID for the account to designate as the delegated Amazon Macie administrator account for the organization.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the macie organization admin account.\n\n## Import\n\n`aws_macie2_organization_admin_account` can be imported using the id, e.g.,\n\n```\n$ terraform import aws_macie2_organization_admin_account.example abcd1\n```\n",
    "basename": "macie2_organization_admin_account.html"
  },
  "macie_member_account_association.html": {
    "subcategory": "Macie Classic",
    "layout": "aws",
    "page_title": "AWS: aws_macie_member_account_association",
    "description": "Associates an AWS account with Amazon Macie as a member account.",
    "preview": "# Resource: aws_macie_member_account_association\n\n~> **NOTE:** This …",
    "content": "\n\n# Resource: aws_macie_member_account_association\n\n~> **NOTE:** This resource interacts with [Amazon Macie Classic](https://docs.aws.amazon.com/macie/latest/userguide/what-is-macie.html). Macie Classic cannot be activated in new accounts. See the [FAQ](https://aws.amazon.com/macie/classic-faqs/) for more details.\n\nAssociates an AWS account with Amazon Macie as a member account.\n\n~> **NOTE:** Before using Amazon Macie for the first time it must be enabled manually. Instructions are [here](https://docs.aws.amazon.com/macie/latest/userguide/macie-setting-up.html#macie-setting-up-enable).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie_member_account_association\" \"example\" {\n  member_account_id = \"123456789012\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `member_account_id` - (Required) The ID of the AWS account that you want to associate with Amazon Macie as a member account.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the association.\n",
    "basename": "macie_member_account_association.html"
  },
  "macie_s3_bucket_association.html": {
    "subcategory": "Macie Classic",
    "layout": "aws",
    "page_title": "AWS: aws_macie_s3_bucket_association",
    "description": "Associates an S3 resource with Amazon Macie for monitoring and data classification.",
    "preview": "# Resource: aws_macie_s3_bucket_association\n\n~> **NOTE:** This …",
    "content": "\n\n# Resource: aws_macie_s3_bucket_association\n\n~> **NOTE:** This resource interacts with [Amazon Macie Classic](https://docs.aws.amazon.com/macie/latest/userguide/what-is-macie.html). Macie Classic cannot be activated in new accounts. See the [FAQ](https://aws.amazon.com/macie/classic-faqs/) for more details.\n\nAssociates an S3 resource with Amazon Macie for monitoring and data classification.\n\n~> **NOTE:** Before using Amazon Macie for the first time it must be enabled manually. Instructions are [here](https://docs.aws.amazon.com/macie/latest/userguide/macie-setting-up.html#macie-setting-up-enable).\n\n## Example Usage\n\n```terraform\nresource \"aws_macie_s3_bucket_association\" \"example\" {\n  bucket_name = \"tf-macie-example\"\n  prefix      = \"data\"\n\n  classification_type {\n    one_time = \"FULL\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket_name` - (Required) The name of the S3 bucket that you want to associate with Amazon Macie.\n* `classification_type` - (Optional) The configuration of how Amazon Macie classifies the S3 objects.\n* `member_account_id` - (Optional) The ID of the Amazon Macie member account whose S3 resources you want to associate with Macie. If `member_account_id` isn't specified, the action associates specified S3 resources with Macie for the current master account.\n* `prefix` - (Optional) Object key prefix identifying one or more S3 objects to which the association applies.\n\nThe `classification_type` object supports the following:\n\n* `continuous` - (Optional) A string value indicating that Macie perform a one-time classification of all of the existing objects in the bucket.\nThe only valid value is the default value, `FULL`.\n* `one_time` - (Optional) A string value indicating whether or not Macie performs a one-time classification of all of the existing objects in the bucket.\nValid values are `NONE` and `FULL`. Defaults to `NONE` indicating that Macie only classifies objects that are added after the association was created.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the association.\n",
    "basename": "macie_s3_bucket_association.html"
  },
  "main_route_table_association.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_main_route_table_association",
    "description": "Provides a resource for managing the main routing table of a VPC.",
    "preview": "# Resource: aws_main_route_table_association\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_main_route_table_association\n\nProvides a resource for managing the main routing table of a VPC.\n\n~> **NOTE:** **Do not** use both `aws_default_route_table` to manage a default route table **and** `aws_main_route_table_association` with the same VPC due to possible route conflicts. See [aws_default_route_table][tf-default-route-table] documentation for more details.\nFor more information, see the Amazon VPC User Guide on [Route Tables](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html). For information about managing normal route tables in Terraform, see [`aws_route_table`](/docs/providers/aws/r/route_table.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_main_route_table_association\" \"a\" {\n  vpc_id         = aws_vpc.foo.id\n  route_table_id = aws_route_table.bar.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Required) The ID of the VPC whose main route table should be set\n* `route_table_id` - (Required) The ID of the Route Table to set as the new\n  main route table for the target VPC\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Route Table Association\n* `original_route_table_id` - Used internally, see __Notes__ below\n\n## Notes\n\nOn VPC creation, the AWS API always creates an initial Main Route Table. This\nresource records the ID of that Route Table under `original_route_table_id`.\nThe \"Delete\" action for a `main_route_table_association` consists of resetting\nthis original table as the Main Route Table for the VPC. You'll see this\nadditional Route Table in the AWS console; it must remain intact in order for\nthe `main_route_table_association` delete to work properly.\n\n[aws-route-tables]: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#Route_Replacing_Main_Table\n[tf-route-tables]: /docs/providers/aws/r/route_table.html\n[tf-default-route-table]: /docs/providers/aws/r/default_route_table.html",
    "basename": "main_route_table_association.html"
  },
  "media_convert_queue.html": {
    "subcategory": "MediaConvert",
    "layout": "aws",
    "page_title": "AWS: aws_media_convert_queue",
    "description": "Provides an AWS Elemental MediaConvert Queue.",
    "preview": "# Resource: aws_media_convert_queue\n\nProvides an AWS Elemental …",
    "content": "\n\n# Resource: aws_media_convert_queue\n\nProvides an AWS Elemental MediaConvert Queue.\n\n## Example Usage\n\n```terraform\nresource \"aws_media_convert_queue\" \"test\" {\n  name = \"tf-test-queue\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A unique identifier describing the queue\n* `description` - (Optional) A description of the queue\n* `pricing_plan` - (Optional) Specifies whether the pricing plan for the queue is on-demand or reserved. Valid values are `ON_DEMAND` or `RESERVED`. Default to `ON_DEMAND`.\n* `reservation_plan_settings` - (Optional) A detail pricing plan of the  reserved queue. See below.\n* `status` - (Optional) A status of the queue. Valid values are `ACTIVE` or `RESERVED`. Default to `PAUSED`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Nested Fields\n\n#### `reservation_plan_settings`\n\n* `commitment` - (Required) The length of the term of your reserved queue pricing plan commitment. Valid value is `ONE_YEAR`.\n* `renewal_type` - (Required) Specifies whether the term of your reserved queue pricing plan. Valid values are `AUTO_RENEW` or `EXPIRE`.\n* `reserved_slots` - (Required) Specifies the number of reserved transcode slots (RTS) for queue.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The same as `name`\n* `arn` - The Arn of the queue\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nMedia Convert Queue can be imported via the queue name, e.g.,\n\n```\n$ terraform import aws_media_convert_queue.test tf-test-queue\n```\n",
    "basename": "media_convert_queue.html"
  },
  "media_package_channel.html": {
    "subcategory": "MediaPackage",
    "layout": "aws",
    "page_title": "AWS: aws_media_package_channel",
    "description": "Provides an AWS Elemental MediaPackage Channel.",
    "preview": "# Resource: aws_media_package_channel\n\nProvides an AWS Elemental …",
    "content": "\n\n# Resource: aws_media_package_channel\n\nProvides an AWS Elemental MediaPackage Channel.\n\n## Example Usage\n\n```terraform\nresource \"aws_media_package_channel\" \"kittens\" {\n  channel_id  = \"kitten-channel\"\n  description = \"A channel dedicated to amusing videos of kittens.\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `channel_id` - (Required) A unique identifier describing the channel\n* `description` - (Optional) A description of the channel\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The same as `channel_id`\n* `arn` - The ARN of the channel\n* `hls_ingest` - A single item list of HLS ingest information\n    * `ingest_endpoints` - A list of the ingest endpoints\n        * `password` - The password\n        * `url` - The URL\n        * `username` - The username\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nMedia Package Channels can be imported via the channel ID, e.g.,\n\n```\n$ terraform import aws_media_package_channel.kittens kittens-channel\n```\n",
    "basename": "media_package_channel.html"
  },
  "media_store_container.html": {
    "subcategory": "MediaStore",
    "layout": "aws",
    "page_title": "AWS: aws_media_store_container",
    "description": "Provides a MediaStore Container.",
    "preview": "# Resource: aws_media_store_container\n\nProvides a MediaStore …",
    "content": "\n\n# Resource: aws_media_store_container\n\nProvides a MediaStore Container.\n\n## Example Usage\n\n```terraform\nresource \"aws_media_store_container\" \"example\" {\n  name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the container. Must contain alphanumeric characters or underscores.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the container.\n* `endpoint` - The DNS endpoint of the container.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nMediaStore Container can be imported using the MediaStore Container Name, e.g.,\n\n```\n$ terraform import aws_media_store_container.example example\n```\n",
    "basename": "media_store_container.html"
  },
  "media_store_container_policy.html": {
    "subcategory": "MediaStore",
    "layout": "aws",
    "page_title": "AWS: aws_media_store_container_policy",
    "description": "Provides a MediaStore Container Policy.",
    "preview": "# Resource: aws_media_store_container_policy\n\nProvides a MediaStore …",
    "content": "\n\n# Resource: aws_media_store_container_policy\n\nProvides a MediaStore Container Policy.\n\n## Example Usage\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_media_store_container\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_media_store_container_policy\" \"example\" {\n  container_name = aws_media_store_container.example.name\n\n  policy = <<EOF\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [{\n\t\t\"Sid\": \"MediaStoreFullAccess\",\n\t\t\"Action\": [ \"mediastore:*\" ],\n\t\t\"Principal\": {\"AWS\" : \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"},\n\t\t\"Effect\": \"Allow\",\n\t\t\"Resource\": \"arn:aws:mediastore:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:container/${aws_media_store_container.example.name}/*\",\n\t\t\"Condition\": {\n\t\t\t\"Bool\": { \"aws:SecureTransport\": \"true\" }\n\t\t}\n\t}]\n}\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `container_name` - (Required) The name of the container.\n* `policy` - (Required) The contents of the policy. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nMediaStore Container Policy can be imported using the MediaStore Container Name, e.g.,\n\n```\n$ terraform import aws_media_store_container_policy.example example\n```\n",
    "basename": "media_store_container_policy.html"
  },
  "mq_broker.html": {
    "subcategory": "MQ",
    "layout": "aws",
    "page_title": "AWS: aws_mq_broker",
    "description": "Provides an MQ Broker Resource",
    "preview": "# Resource: aws_mq_broker\n\nProvides an Amazon MQ broker resource. …",
    "content": "\n\n# Resource: aws_mq_broker\n\nProvides an Amazon MQ broker resource. This resources also manages users for the broker.\n\n-> For more information on Amazon MQ, see [Amazon MQ documentation](https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/welcome.html).\n\n~> **NOTE:** Amazon MQ currently places limits on **RabbitMQ** brokers. For example, a RabbitMQ broker cannot have: instances with an associated IP address of an ENI attached to the broker, an associated LDAP server to authenticate and authorize broker connections, storage type `EFS`, audit logging, or `configuration` blocks. Although this resource allows you to create RabbitMQ users, RabbitMQ users cannot have console access or groups. Also, Amazon MQ does not return information about RabbitMQ users so drift detection is not possible.\n\n~> **NOTE:** Changes to an MQ Broker can occur when you change a parameter, such as `configuration` or `user`, and are reflected in the next maintenance window. Because of this, Terraform may report a difference in its planning phase because a modification has not yet taken place. You can use the `apply_immediately` flag to instruct the service to apply the change immediately (see documentation below). Using `apply_immediately` can result in a brief downtime as the broker reboots.\n\n~> **NOTE:** All arguments including the username and password will be stored in the raw state as plain-text. [Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n\n## Example Usage\n\n### Basic Example\n\n```terraform\nresource \"aws_mq_broker\" \"example\" {\n  broker_name = \"example\"\n\n  configuration {\n    id       = aws_mq_configuration.test.id\n    revision = aws_mq_configuration.test.latest_revision\n  }\n\n  engine_type        = \"ActiveMQ\"\n  engine_version     = \"5.15.9\"\n  host_instance_type = \"mq.t2.micro\"\n  security_groups    = [aws_security_group.test.id]\n\n  user {\n    username = \"ExampleUser\"\n    password = \"MindTheGap\"\n  }\n}\n```\n\n### High-throughput Optimized Example\n\nThis example shows the use of EBS storage for high-throughput optimized performance.\n\n```terraform\nresource \"aws_mq_broker\" \"example\" {\n  broker_name = \"example\"\n\n  configuration {\n    id       = aws_mq_configuration.test.id\n    revision = aws_mq_configuration.test.latest_revision\n  }\n\n  engine_type        = \"ActiveMQ\"\n  engine_version     = \"5.15.9\"\n  storage_type       = \"ebs\"\n  host_instance_type = \"mq.m5.large\"\n  security_groups    = [aws_security_group.test.id]\n\n  user {\n    username = \"ExampleUser\"\n    password = \"MindTheGap\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `broker_name` - (Required) Name of the broker.\n* `engine_type` - (Required) Type of broker engine. Valid values are `ActiveMQ` and `RabbitMQ`.\n* `engine_version` - (Required) Version of the broker engine. See the [AmazonMQ Broker Engine docs](https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/broker-engine.html) for supported versions. For example, `5.15.0`.\n* `host_instance_type` - (Required) Broker's instance type. For example, `mq.t3.micro`, `mq.m5.large`.\n* `user` - (Required) Configuration block for broker users. For `engine_type` of `RabbitMQ`, Amazon MQ does not return broker users preventing this resource from making user updates and drift detection. Detailed below.\n\nThe following arguments are optional:\n\n* `apply_immediately` - (Optional) Specifies whether any broker modifications are applied immediately, or during the next maintenance window. Default is `false`.\n* `authentication_strategy` - (Optional) Authentication strategy used to secure the broker. Valid values are `simple` and `ldap`. `ldap` is not supported for `engine_type` `RabbitMQ`.\n* `auto_minor_version_upgrade` - (Optional) Whether to automatically upgrade to new minor versions of brokers as Amazon MQ makes releases available.\n* `configuration` - (Optional) Configuration block for broker configuration. Applies to `engine_type` of `ActiveMQ` only. Detailed below.\n* `deployment_mode` - (Optional) Deployment mode of the broker. Valid values are `SINGLE_INSTANCE`, `ACTIVE_STANDBY_MULTI_AZ`, and `CLUSTER_MULTI_AZ`. Default is `SINGLE_INSTANCE`.\n* `encryption_options` - (Optional) Configuration block containing encryption options. Detailed below.\n* `ldap_server_metadata` - (Optional) Configuration block for the LDAP server used to authenticate and authorize connections to the broker. Not supported for `engine_type` `RabbitMQ`. Detailed below. (Currently, AWS may not process changes to LDAP server metadata.)\n* `logs` - (Optional) Configuration block for the logging configuration of the broker. Detailed below.\n* `maintenance_window_start_time` - (Optional) Configuration block for the maintenance window start time. Detailed below.\n* `publicly_accessible` - (Optional) Whether to enable connections from applications outside of the VPC that hosts the broker's subnets.\n* `security_groups` - (Optional) List of security group IDs assigned to the broker.\n* `storage_type` - (Optional) Storage type of the broker. For `engine_type` `ActiveMQ`, the valid values are `efs` and `ebs`, and the AWS-default is `efs`. For `engine_type` `RabbitMQ`, only `ebs` is supported. When using `ebs`, only the `mq.m5` broker instance type family is supported.\n* `subnet_ids` - (Optional) List of subnet IDs in which to launch the broker. A `SINGLE_INSTANCE` deployment requires one subnet. An `ACTIVE_STANDBY_MULTI_AZ` deployment requires multiple subnets.\n* `tags` - (Optional) Map of tags to assign to the broker. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### configuration\n\nThe following arguments are optional:\n\n* `id` - (Optional) The Configuration ID.\n* `revision` - (Optional) Revision of the Configuration.\n\n### encryption_options\n\nThe following arguments are optional:\n\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of Key Management Service (KMS) Customer Master Key (CMK) to use for encryption at rest. Requires setting `use_aws_owned_key` to `false`. To perform drift detection when AWS-managed CMKs or customer-managed CMKs are in use, this value must be configured.\n* `use_aws_owned_key` - (Optional) Whether to enable an AWS-owned KMS CMK that is not in your account. Defaults to `true`. Setting to `false` without configuring `kms_key_id` will create an AWS-managed CMK aliased to `aws/mq` in your account.\n\n### ldap_server_metadata\n\nThe following arguments are optional:\n\n* `hosts` - (Optional) List of a fully qualified domain name of the LDAP server and an optional failover server.\n* `role_base` - (Optional) Fully qualified name of the directory to search for a user’s groups.\n* `role_name` - (Optional) Specifies the LDAP attribute that identifies the group name attribute in the object returned from the group membership query.\n* `role_search_matching` - (Optional) Search criteria for groups.\n* `role_search_subtree` - (Optional) Whether the directory search scope is the entire sub-tree.\n* `service_account_password` - (Optional) Service account password.\n* `service_account_username` - (Optional) Service account username.\n* `user_base` - (Optional) Fully qualified name of the directory where you want to search for users.\n* `user_role_name` - (Optional) Specifies the name of the LDAP attribute for the user group membership.\n* `user_search_matching` - (Optional) Search criteria for users.\n* `user_search_subtree` - (Optional) Whether the directory search scope is the entire sub-tree.\n\n### logs\n\nThe following arguments are optional:\n\n* `audit` - (Optional) Enables audit logging. Auditing is only possible for `engine_type` of `ActiveMQ`. User management action made using JMX or the ActiveMQ Web Console is logged. Defaults to `false`.\n* `general` - (Optional) Enables general logging via CloudWatch. Defaults to `false`.\n\n### maintenance_window_start_time\n\nThe following arguments are required:\n\n* `day_of_week` - (Required) Day of the week, e.g., `MONDAY`, `TUESDAY`, or `WEDNESDAY`.\n* `time_of_day` - (Required) Time, in 24-hour format, e.g., `02:00`.\n* `time_zone` - (Required) Time zone in either the Country/City format or the UTC offset format, e.g., `CET`.\n\n~> **NOTE:** Amazon MQ currently does not support updating the maintenance window. Changes to the maintenance window start time will force a new broker to be created.\n\n### user\n\n* `console_access` - (Optional) Whether to enable access to the [ActiveMQ Web Console](http://activemq.apache.org/web-console.html) for the user. Applies to `engine_type` of `ActiveMQ` only.\n* `groups` - (Optional) List of groups (20 maximum) to which the ActiveMQ user belongs. Applies to `engine_type` of `ActiveMQ` only.\n* `password` - (Required) Password of the user. It must be 12 to 250 characters long, at least 4 unique characters, and must not contain commas.\n* `username` - (Required) Username of the user.\n\n~> **NOTE:** AWS currently does not support updating RabbitMQ users. Updates to users can only be in the RabbitMQ UI.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the broker.\n* `id` - Unique ID that Amazon MQ generates for the broker.\n* `instances` - List of information about allocated brokers (both active & standby).\n    * `instances.0.console_url` - The URL of the broker's [ActiveMQ Web Console](http://activemq.apache.org/web-console.html).\n    * `instances.0.ip_address` - IP Address of the broker.\n    * `instances.0.endpoints` - Broker's wire-level protocol endpoints in the following order & format referenceable e.g., as `instances.0.endpoints.0` (SSL):\n        * For `ActiveMQ`:\n            * `ssl://broker-id.mq.us-west-2.amazonaws.com:61617`\n            * `amqp+ssl://broker-id.mq.us-west-2.amazonaws.com:5671`\n            * `stomp+ssl://broker-id.mq.us-west-2.amazonaws.com:61614`\n            * `mqtt+ssl://broker-id.mq.us-west-2.amazonaws.com:8883`\n            * `wss://broker-id.mq.us-west-2.amazonaws.com:61619`\n        * For `RabbitMQ`:\n            * `amqps://broker-id.mq.us-west-2.amazonaws.com:5671`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nMQ Brokers can be imported using their broker id, e.g.,\n\n```\n$ terraform import aws_mq_broker.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "mq_broker.html"
  },
  "mq_configuration.html": {
    "subcategory": "MQ",
    "layout": "aws",
    "page_title": "AWS: aws_mq_configuration",
    "description": "Provides an MQ configuration Resource",
    "preview": "# Resource: aws_mq_configuration\n\nProvides an MQ Configuration …",
    "content": "\n\n# Resource: aws_mq_configuration\n\nProvides an MQ Configuration Resource.\n\nFor more information on Amazon MQ, see [Amazon MQ documentation](https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/welcome.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_mq_configuration\" \"example\" {\n  description    = \"Example Configuration\"\n  name           = \"example\"\n  engine_type    = \"ActiveMQ\"\n  engine_version = \"5.15.0\"\n\n  data = <<DATA\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<broker xmlns=\"http://activemq.apache.org/schema/core\">\n  <plugins>\n    <forcePersistencyModeBrokerPlugin persistenceFlag=\"true\"/>\n    <statisticsBrokerPlugin/>\n    <timeStampingBrokerPlugin ttlCeiling=\"86400000\" zeroExpirationOverride=\"86400000\"/>\n  </plugins>\n</broker>\nDATA\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `data` - (Required) Broker configuration in XML format. See [official docs](https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/amazon-mq-broker-configuration-parameters.html) for supported parameters and format of the XML.\n* `engine_type` - (Required) Type of broker engine. Valid values are `ActiveMQ` and `RabbitMQ`.\n* `engine_version` - (Required) Version of the broker engine.\n* `name` - (Required) Name of the configuration.\n\nThe following arguments are optional:\n\n* `authentication_strategy` - (Optional) Authentication strategy associated with the configuration. Valid values are `simple` and `ldap`. `ldap` is not supported for `engine_type` `RabbitMQ`.\n* `description` - (Optional) Description of the configuration.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the configuration.\n* `id` - Unique ID that Amazon MQ generates for the configuration.\n* `latest_revision` - Latest revision of the configuration.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nMQ Configurations can be imported using the configuration ID, e.g.,\n\n```\n$ terraform import aws_mq_configuration.example c-0187d1eb-88c8-475a-9b79-16ef5a10c94f\n```\n",
    "basename": "mq_configuration.html"
  },
  "msk_cluster.html": {
    "subcategory": "Managed Streaming for Kafka (MSK)",
    "layout": "aws",
    "page_title": "AWS: aws_msk_cluster",
    "description": "Terraform resource for managing an AWS Managed Streaming for Kafka cluster",
    "preview": "# Resource: aws_msk_cluster\n\nManages AWS Managed Streaming for Kafka …",
    "content": "\n\n# Resource: aws_msk_cluster\n\nManages AWS Managed Streaming for Kafka cluster\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"vpc\" {\n  cidr_block = \"192.168.0.0/22\"\n}\n\ndata \"aws_availability_zones\" \"azs\" {\n  state = \"available\"\n}\n\nresource \"aws_subnet\" \"subnet_az1\" {\n  availability_zone = data.aws_availability_zones.azs.names[0]\n  cidr_block        = \"192.168.0.0/24\"\n  vpc_id            = aws_vpc.vpc.id\n}\n\nresource \"aws_subnet\" \"subnet_az2\" {\n  availability_zone = data.aws_availability_zones.azs.names[1]\n  cidr_block        = \"192.168.1.0/24\"\n  vpc_id            = aws_vpc.vpc.id\n}\n\nresource \"aws_subnet\" \"subnet_az3\" {\n  availability_zone = data.aws_availability_zones.azs.names[2]\n  cidr_block        = \"192.168.2.0/24\"\n  vpc_id            = aws_vpc.vpc.id\n}\n\nresource \"aws_security_group\" \"sg\" {\n  vpc_id = aws_vpc.vpc.id\n}\n\nresource \"aws_kms_key\" \"kms\" {\n  description = \"example\"\n}\n\nresource \"aws_cloudwatch_log_group\" \"test\" {\n  name = \"msk_broker_logs\"\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"msk-broker-logs-bucket\"\n  acl    = \"private\"\n}\n\nresource \"aws_iam_role\" \"firehose_role\" {\n  name = \"firehose_test_role\"\n\n  assume_role_policy = <<EOF\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n  {\n    \"Action\": \"sts:AssumeRole\",\n    \"Principal\": {\n      \"Service\": \"firehose.amazonaws.com\"\n    },\n    \"Effect\": \"Allow\",\n    \"Sid\": \"\"\n  }\n  ]\n}\nEOF\n}\n\nresource \"aws_kinesis_firehose_delivery_stream\" \"test_stream\" {\n  name        = \"terraform-kinesis-firehose-msk-broker-logs-stream\"\n  destination = \"s3\"\n\n  s3_configuration {\n    role_arn   = aws_iam_role.firehose_role.arn\n    bucket_arn = aws_s3_bucket.bucket.arn\n  }\n\n  tags = {\n    LogDeliveryEnabled = \"placeholder\"\n  }\n\n  lifecycle {\n    ignore_changes = [\n      tags[\"LogDeliveryEnabled\"],\n    ]\n  }\n}\n\nresource \"aws_msk_cluster\" \"example\" {\n  cluster_name           = \"example\"\n  kafka_version          = \"2.4.1\"\n  number_of_broker_nodes = 3\n\n  broker_node_group_info {\n    instance_type   = \"kafka.m5.large\"\n    ebs_volume_size = 1000\n    client_subnets = [\n      aws_subnet.subnet_az1.id,\n      aws_subnet.subnet_az2.id,\n      aws_subnet.subnet_az3.id,\n    ]\n    security_groups = [aws_security_group.sg.id]\n  }\n\n  encryption_info {\n    encryption_at_rest_kms_key_arn = aws_kms_key.kms.arn\n  }\n\n  open_monitoring {\n    prometheus {\n      jmx_exporter {\n        enabled_in_broker = true\n      }\n      node_exporter {\n        enabled_in_broker = true\n      }\n    }\n  }\n\n  logging_info {\n    broker_logs {\n      cloudwatch_logs {\n        enabled   = true\n        log_group = aws_cloudwatch_log_group.test.name\n      }\n      firehose {\n        enabled         = true\n        delivery_stream = aws_kinesis_firehose_delivery_stream.test_stream.name\n      }\n      s3 {\n        enabled = true\n        bucket  = aws_s3_bucket.bucket.id\n        prefix  = \"logs/msk-\"\n      }\n    }\n  }\n\n  tags = {\n    foo = \"bar\"\n  }\n}\n\noutput \"zookeeper_connect_string\" {\n  value = aws_msk_cluster.example.zookeeper_connect_string\n}\n\noutput \"bootstrap_brokers_tls\" {\n  description = \"TLS connection host:port pairs\"\n  value       = aws_msk_cluster.example.bootstrap_brokers_tls\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `broker_node_group_info` - (Required) Configuration block for the broker nodes of the Kafka cluster.\n* `cluster_name` - (Required) Name of the MSK cluster.\n* `kafka_version` - (Required) Specify the desired Kafka software version.\n* `number_of_broker_nodes` - (Required) The desired total number of broker nodes in the kafka cluster.  It must be a multiple of the number of specified client subnets.\n* `client_authentication` - (Optional) Configuration block for specifying a client authentication. See below.\n* `configuration_info` - (Optional) Configuration block for specifying a MSK Configuration to attach to Kafka brokers. See below.\n* `encryption_info` - (Optional) Configuration block for specifying encryption. See below.\n* `enhanced_monitoring` - (Optional) Specify the desired enhanced MSK CloudWatch monitoring level.  See [Monitoring Amazon MSK with Amazon CloudWatch](https://docs.aws.amazon.com/msk/latest/developerguide/monitoring.html)\n* `open_monitoring` - (Optional) Configuration block for JMX and Node monitoring for the MSK cluster. See below.\n* `logging_info` - (Optional) Configuration block for streaming broker logs to Cloudwatch/S3/Kinesis Firehose. See below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### broker_node_group_info Argument Reference\n\n* `client_subnets` - (Required) A list of subnets to connect to in client VPC ([documentation](https://docs.aws.amazon.com/msk/1.0/apireference/clusters.html#clusters-prop-brokernodegroupinfo-clientsubnets)).\n* `ebs_volume_size` - (Required) The size in GiB of the EBS volume for the data drive on each broker node.\n* `instance_type` - (Required) Specify the instance type to use for the kafka brokersE.g., kafka.m5.large. ([Pricing info](https://aws.amazon.com/msk/pricing/))\n* `security_groups` - (Required) A list of the security groups to associate with the elastic network interfaces to control who can communicate with the cluster.\n* `az_distribution` - (Optional) The distribution of broker nodes across availability zones ([documentation](https://docs.aws.amazon.com/msk/1.0/apireference/clusters.html#clusters-model-brokerazdistribution)). Currently the only valid value is `DEFAULT`.\n\n### client_authentication Argument Reference\n\n* `sasl` - (Optional) Configuration block for specifying SASL client authentication. See below.\n* `tls` - (Optional) Configuration block for specifying TLS client authentication. See below.\n\n#### client_authentication sasl Argument Reference\n\n* `iam` - (Optional) Enables IAM client authentication. Defaults to `false`.\n* `scram` - (Optional) Enables SCRAM client authentication via AWS Secrets Manager. Defaults to `false`.\n\n#### client_authentication tls Argument Reference\n\n* `certificate_authority_arns` - (Optional) List of ACM Certificate Authority Amazon Resource Names (ARNs).\n\n### configuration_info Argument Reference\n\n* `arn` - (Required) Amazon Resource Name (ARN) of the MSK Configuration to use in the cluster.\n* `revision` - (Required) Revision of the MSK Configuration to use in the cluster.\n\n### encryption_info Argument Reference\n\n* `encryption_in_transit` - (Optional) Configuration block to specify encryption in transit. See below.\n* `encryption_at_rest_kms_key_arn` - (Optional) You may specify a KMS key short ID or ARN (it will always output an ARN) to use for encrypting your data at rest.  If no key is specified, an AWS managed KMS ('aws/msk' managed service) key will be used for encrypting the data at rest.\n\n#### encryption_info encryption_in_transit Argument Reference\n\n* `client_broker` - (Optional) Encryption setting for data in transit between clients and brokers. Valid values: `TLS`, `TLS_PLAINTEXT`, and `PLAINTEXT`. Default value is `TLS`.\n* `in_cluster` - (Optional) Whether data communication among broker nodes is encrypted. Default value: `true`.\n\n#### open_monitoring Argument Reference\n\n* `prometheus` - (Required) Configuration block for Prometheus settings for open monitoring. See below.\n\n#### open_monitoring prometheus Argument Reference\n\n* `jmx_exporter` - (Optional) Configuration block for JMX Exporter. See below.\n* `node_exporter` - (Optional) Configuration block for Node Exporter. See below.\n\n#### open_monitoring prometheus jmx_exporter Argument Reference\n\n* `enabled_in_broker` - (Required) Indicates whether you want to enable or disable the JMX Exporter.\n\n#### open_monitoring prometheus node_exporter Argument Reference\n\n* `enabled_in_broker` - (Required) Indicates whether you want to enable or disable the Node Exporter.\n\n#### logging_info Argument Reference\n\n* `broker_logs` - (Required) Configuration block for Broker Logs settings for logging info. See below.\n\n#### logging_info broker_logs cloudwatch_logs Argument Reference\n\n* `enabled` - (Optional) Indicates whether you want to enable or disable streaming broker logs to Cloudwatch Logs.\n* `log_group` - (Optional) Name of the Cloudwatch Log Group to deliver logs to.\n\n#### logging_info broker_logs firehose Argument Reference\n\n* `enabled` - (Optional) Indicates whether you want to enable or disable streaming broker logs to Kinesis Data Firehose.\n* `delivery_stream` - (Optional) Name of the Kinesis Data Firehose delivery stream to deliver logs to.\n\n#### logging_info broker_logs s3 Argument Reference\n\n* `enabled` - (Optional) Indicates whether you want to enable or disable streaming broker logs to S3.\n* `bucket` - (Optional) Name of the S3 bucket to deliver logs to.\n* `prefix` - (Optional) Prefix to append to the folder name.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the MSK cluster.\n* `bootstrap_brokers` - Comma separated list of one or more hostname:port pairs of kafka brokers suitable to bootstrap connectivity to the kafka cluster. Contains a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `PLAINTEXT` or `TLS_PLAINTEXT`. The resource sorts values alphabetically. AWS may not always return all endpoints so this value is not guaranteed to be stable across applies.\n* `bootstrap_brokers_sasl_iam` - One or more DNS names (or IP addresses) and SASL IAM port pairs. For example, `b-1.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9098,b-2.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9098,b-3.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9098`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS` and `client_authentication.0.sasl.0.iam` is set to `true`. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.\n* `bootstrap_brokers_sasl_scram` - One or more DNS names (or IP addresses) and SASL SCRAM port pairs. For example, `b-1.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9096,b-2.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9096,b-3.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9096`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS` and `client_authentication.0.sasl.0.scram` is set to `true`. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.\n* `bootstrap_brokers_tls` - One or more DNS names (or IP addresses) and TLS port pairs. For example, `b-1.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9094,b-2.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9094,b-3.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9094`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS`. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.\n* `current_version` - Current version of the MSK Cluster used for updates, e.g., `K13V1IB3VIYZZH`\n* `encryption_info.0.encryption_at_rest_kms_key_arn` - The ARN of the KMS key used for encryption at rest of the broker data volumes.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `zookeeper_connect_string` - A comma separated list of one or more hostname:port pairs to use to connect to the Apache Zookeeper cluster. The returned values are sorted alphbetically. The AWS API may not return all endpoints, so this value is not guaranteed to be stable across applies.\n* `zookeeper_connect_string_tls` - A comma separated list of one or more hostname:port pairs to use to connect to the Apache Zookeeper cluster via TLS. The returned values are sorted alphbetically. The AWS API may not return all endpoints, so this value is not guaranteed to be stable across applies.\n\n## Timeouts\n\n`aws_msk_cluster` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `120 minutes`) How long to wait for the MSK Cluster to be created.\n* `update` - (Default `120 minutes`) How long to wait for the MSK Cluster to be updated.\nNote that the `update` timeout is used separately for `ebs_volume_size`, `instance_type`, `number_of_broker_nodes`, `configuration_info`, `kafka_version` and monitoring and logging update timeouts.\n* `delete` - (Default `120 minutes`) How long to wait for the MSK Cluster to be deleted.\n\n## Import\n\nMSK clusters can be imported using the cluster `arn`, e.g.,\n\n```\n$ terraform import aws_msk_cluster.example arn:aws:kafka:us-west-2:123456789012:cluster/example/279c0212-d057-4dba-9aa9-1c4e5a25bfc7-3\n```\n",
    "basename": "msk_cluster.html"
  },
  "msk_configuration.html": {
    "subcategory": "Managed Streaming for Kafka (MSK)",
    "layout": "aws",
    "page_title": "AWS: aws_msk_configuration",
    "description": "Terraform resource for managing an Amazon Managed Streaming for Kafka configuration",
    "preview": "# Resource: aws_msk_configuration\n\nManages an Amazon Managed …",
    "content": "\n\n# Resource: aws_msk_configuration\n\nManages an Amazon Managed Streaming for Kafka configuration. More information can be found on the [MSK Developer Guide](https://docs.aws.amazon.com/msk/latest/developerguide/msk-configuration.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_msk_configuration\" \"example\" {\n  kafka_versions = [\"2.1.0\"]\n  name           = \"example\"\n\n  server_properties = <<PROPERTIES\nauto.create.topics.enable = true\ndelete.topic.enable = true\nPROPERTIES\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `server_properties` - (Required) Contents of the server.properties file. Supported properties are documented in the [MSK Developer Guide](https://docs.aws.amazon.com/msk/latest/developerguide/msk-configuration-properties.html).\n* `kafka_versions` - (Required) List of Apache Kafka versions which can use this configuration.\n* `name` - (Required) Name of the configuration.\n* `description` - (Optional) Description of the configuration.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the configuration.\n* `latest_revision` - Latest revision of the configuration.\n\n## Import\n\nMSK configurations can be imported using the configuration ARN, e.g.,\n\n```\n$ terraform import aws_msk_configuration.example arn:aws:kafka:us-west-2:123456789012:configuration/example/279c0212-d057-4dba-9aa9-1c4e5a25bfc7-3\n```\n",
    "basename": "msk_configuration.html"
  },
  "msk_scram_secret_association.html": {
    "subcategory": "Managed Streaming for Kafka (MSK)",
    "layout": "aws",
    "page_title": "AWS: aws_msk_scram_secret_association",
    "description": "Associates SCRAM secrets with a Managed Streaming for Kafka (MSK) cluster.",
    "preview": "# Resource: aws_msk_scram_secret_association\n\nAssociates SCRAM …",
    "content": "\n\n# Resource: aws_msk_scram_secret_association\n\nAssociates SCRAM secrets stored in the Secrets Manager service with a Managed Streaming for Kafka (MSK) cluster.\n\n-> **Note:** The following assumes the MSK cluster has SASL/SCRAM authentication enabled. See below for example usage or refer to the [Username/Password Authentication](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html) section of the MSK Developer Guide for more details.\n\nTo set up username and password authentication for a cluster, create an [`aws_secretsmanager_secret` resource](/docs/providers/aws/r/secretsmanager_secret.html) and associate\na username and password with the secret with an [`aws_secretsmanager_secret_version` resource](/docs/providers/aws/r/secretsmanager_secret_version.html). When creating a secret for the cluster,\nthe `name` must have the prefix `AmazonMSK_` and you must either use an existing custom AWS KMS key or create a new\ncustom AWS KMS key for your secret with the [`aws_kms_key` resource](/docs/providers/aws/r/kms_key.html). It is important to note that a policy is required for the `aws_secretsmanager_secret`\nresource in order for Kafka to be able to read it. This policy is attached automatically when the `aws_msk_scram_secret_association` is used,\nhowever, this policy will not be in terraform and as such, will present a diff on plan/apply. For that reason, you must use the [`aws_secretsmanager_secret_policy`\nresource](/docs/providers/aws/r/secretsmanager_secret_policy.html) as shown below in order to ensure that the state is in a clean state after the creation of secret and the association to the cluster.\n\n## Example Usage\n\n```terraform\nresource \"aws_msk_scram_secret_association\" \"example\" {\n  cluster_arn     = aws_msk_cluster.example.arn\n  secret_arn_list = [aws_secretsmanager_secret.example.arn]\n\n  depends_on = [aws_secretsmanager_secret_version.example]\n}\n\nresource \"aws_msk_cluster\" \"example\" {\n  cluster_name = \"example\"\n  # ... other configuration...\n  client_authentication {\n    sasl {\n      scram = true\n    }\n  }\n}\n\nresource \"aws_secretsmanager_secret\" \"example\" {\n  name       = \"AmazonMSK_example\"\n  kms_key_id = aws_kms_key.example.key_id\n}\n\nresource \"aws_kms_key\" \"example\" {\n  description = \"Example Key for MSK Cluster Scram Secret Association\"\n}\n\nresource \"aws_secretsmanager_secret_version\" \"example\" {\n  secret_id     = aws_secretsmanager_secret.example.id\n  secret_string = jsonencode({ username = \"user\", password = \"pass\" })\n}\n\nresource \"aws_secretsmanager_secret_policy\" \"example\" {\n  secret_arn = aws_secretsmanager_secret.example.arn\n  policy     = <<POLICY\n{\n  \"Version\" : \"2012-10-17\",\n  \"Statement\" : [ {\n    \"Sid\": \"AWSKafkaResourcePolicy\",\n    \"Effect\" : \"Allow\",\n    \"Principal\" : {\n      \"Service\" : \"kafka.amazonaws.com\"\n    },\n    \"Action\" : \"secretsmanager:getSecretValue\",\n    \"Resource\" : \"${aws_secretsmanager_secret.example.arn}\"\n  } ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_arn` - (Required, Forces new resource) Amazon Resource Name (ARN) of the MSK cluster.\n* `secret_arn_list` - (Required) List of AWS Secrets Manager secret ARNs.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the MSK cluster.\n\n## Import\n\nMSK SCRAM Secret Associations can be imported using the `id` e.g.,\n\n```\n$ terraform import aws_msk_scram_secret_association.example arn:aws:kafka:us-west-2:123456789012:cluster/example/279c0212-d057-4dba-9aa9-1c4e5a25bfc7-3\n```\n",
    "basename": "msk_scram_secret_association.html"
  },
  "mwaa_environment.html": {
    "subcategory": "Managed Workflows for Apache Airflow (MWAA)",
    "layout": "aws",
    "page_title": "AWS: aws_mwaa_environment",
    "description": "Creates a MWAA Environment",
    "preview": "# Resource: aws_mwaa_environment\n\nCreates a MWAA Environment …",
    "content": "\n\n# Resource: aws_mwaa_environment\n\nCreates a MWAA Environment resource.\n\n## Example Usage\n\nA MWAA Environment requires an IAM role (`aws_iam_role`), two subnets in the private zone (`aws_subnet`) and a versioned S3 bucket (`aws_s3_bucket`).\n\n### Basic Usage\n\n```terraform\nresource \"aws_mwaa_environment\" \"example\" {\n  dag_s3_path        = \"dags/\"\n  execution_role_arn = aws_iam_role.example.arn\n  name               = \"example\"\n\n  network_configuration {\n    security_group_ids = [aws_security_group.example.id]\n    subnet_ids         = aws_subnet.private[*].id\n  }\n\n  source_bucket_arn = aws_s3_bucket.example.arn\n}\n```\n\n### Example with Airflow configuration options\n\n```terraform\nresource \"aws_mwaa_environment\" \"example\" {\n  airflow_configuration_options = {\n    \"core.default_task_retries\" = 16\n    \"core.parallelism\"          = 1\n  }\n\n  dag_s3_path        = \"dags/\"\n  execution_role_arn = aws_iam_role.example.arn\n  name               = \"example\"\n\n  network_configuration {\n    security_group_ids = [aws_security_group.example.id]\n    subnet_ids         = aws_subnet.private[*].id\n  }\n\n  source_bucket_arn = aws_s3_bucket.example.arn\n}\n```\n\n### Example with logging configurations\n\nNote that Airflow task logs are enabled by default with the `INFO` log level.\n\n```terraform\nresource \"aws_mwaa_environment\" \"example\" {\n  dag_s3_path        = \"dags/\"\n  execution_role_arn = aws_iam_role.example.arn\n\n  logging_configuration {\n    dag_processing_logs {\n      enabled   = true\n      log_level = \"DEBUG\"\n    }\n\n    scheduler_logs {\n      enabled   = true\n      log_level = \"INFO\"\n    }\n\n    task_logs {\n      enabled   = true\n      log_level = \"WARNING\"\n    }\n\n    webserver_logs {\n      enabled   = true\n      log_level = \"ERROR\"\n    }\n\n    worker_logs {\n      enabled   = true\n      log_level = \"CRITICAL\"\n    }\n  }\n\n  name = \"example\"\n\n  network_configuration {\n    security_group_ids = [aws_security_group.example.id]\n    subnet_ids         = aws_subnet.private[*].id\n  }\n\n  source_bucket_arn = aws_s3_bucket.example.arn\n}\n```\n\n### Example with tags\n\n```terraform\nresource \"aws_mwaa_environment\" \"example\" {\n  dag_s3_path        = \"dags/\"\n  execution_role_arn = aws_iam_role.example.arn\n  name               = \"example\"\n\n  network_configuration {\n    security_group_ids = [aws_security_group.example.id]\n    subnet_ids         = aws_subnet.private[*].id\n  }\n\n  source_bucket_arn = aws_s3_bucket.example.arn\n\n  tags = {\n    Name        = \"example\"\n    Environment = \"production\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `airflow_configuration_options` - (Optional) The `airflow_configuration_options` parameter specifies airflow override options. Check the [Official documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-env-variables.html#configuring-env-variables-reference) for all possible configuration options.\n* `airflow_version` - (Optional) Airflow version of your environment, will be set by default to the latest version that MWAA supports.\n* `dag_s3_path` - (Required) The relative path to the DAG folder on your Amazon S3 storage bucket. For example, dags. For more information, see [Importing DAGs on Amazon MWAA](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import.html).\n* `environment_class` - (Optional) Environment class for the cluster. Possible options are `mw1.small`, `mw1.medium`, `mw1.large`. Will be set by default to `mw1.small`. Please check the [AWS Pricing](https://aws.amazon.com/de/managed-workflows-for-apache-airflow/pricing/) for more information about the environment classes.\n* `execution_role_arn` - (Required) The Amazon Resource Name (ARN) of the task execution role that the Amazon MWAA and its environment can assume. Check the [official AWS documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-create-role.html) for the detailed role specification.\n* `kms_key` - (Optional) The Amazon Resource Name (ARN) of your KMS key that you want to use for encryption. Will be set to the ARN of the managed KMS key `aws/airflow` by default. Please check the [Official Documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/custom-keys-certs.html) for more information.\n* `logging_configuration` - (Optional) The Apache Airflow logs you want to send to Amazon CloudWatch Logs.\n* `max_workers` - (Optional) The maximum number of workers that can be automatically scaled up. Value need to be between `1` and `25`. Will be `10` by default.\n* `min_workers` - (Optional) The minimum number of workers that you want to run in your environment. Will be `1` by default.\n* `name` - (Required) The name of the Apache Airflow Environment\n* `network_configuration` - (Required) Specifies the network configuration for your Apache Airflow Environment. This includes two private subnets as well as security groups for the Airflow environment. Each subnet requires internet connection, otherwise the deployment will fail. See [Network configuration](#network) below for details.\n* `plugins_s3_object_version` - (Optional) The plugins.zip file version you want to use.\n* `plugins_s3_path` - (Optional) The relative path to the plugins.zip file on your Amazon S3 storage bucket. For example, plugins.zip. If a relative path is provided in the request, then plugins_s3_object_version is required. For more information, see [Importing DAGs on Amazon MWAA](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import.html).\n* `requirements_s3_object_version` - (Optional) The requirements.txt file version you want to use.\n* `requirements_s3_path` - (Optional) The relative path to the requirements.txt file on your Amazon S3 storage bucket. For example, requirements.txt. If a relative path is provided in the request, then requirements_s3_object_version is required. For more information, see [Importing DAGs on Amazon MWAA](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import.html).\n* `source_bucket_arn` - (Required) The Amazon Resource Name (ARN) of your Amazon S3 storage bucket. For example, arn:aws:s3:::airflow-mybucketname.\n* `webserver_access_mode` - (Optional) Specifies whether the webserver should be accessible over the internet or via your specified VPC. Possible options: `PRIVATE_ONLY` (default) and `PUBLIC_ONLY`.\n* `weekly_maintenance_window_start` - (Optional) Specifies the start date for the weekly maintenance window.\n* `tags` - (Optional) A map of resource tags to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Logging configurations\n\nThe `logging_configuration` block supports the following arguments.\n\n* `dag_processing_logs` - (Optional) (Optional) Log configuration options for processing DAGs. See [Module logging configuration](#module-logging-configuration) for more information. Disabled by default.\n* `scheduler_logs` - (Optional) Log configuration options for the schedulers. See [Module logging configuration](#module-logging-configuration) for more information. Disabled by default.\n* `task_logs` - (Optional) Log configuration options for DAG tasks. See [Module logging configuration](#module-logging-configuration) for more information. Enabled by default with `INFO` log level.\n* `webserver_logs` - (Optional) Log configuration options for the webservers. See [Module logging configuration](#module-logging-configuration) for more information. Disabled by default.\n* `worker_logs` - (Optional) Log configuration options for the workers. See [Module logging configuration](#module-logging-configuration) for more information. Disabled by default.\n\n### Module logging configuration\n\nA configuration block to use for logging with respect to the various Apache Airflow services: DagProcessingLogs, SchedulerLogs, TaskLogs, WebserverLogs, and WorkerLogs. It supports the following arguments.\n\n* `enabled` - (Required) Enabling or disabling the collection of logs\n* `log_level` - (Optional) Logging level. Valid values: `CRITICAL`, `ERROR`, `WARNING`, `INFO`, `DEBUG`. Will be `INFO` by default.\n\n### Network configuration\n\nThe `network_configuration` block supports the following arguments. More information about the required subnet and security group settings can be found in the [official AWS documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/vpc-create.html).\n\n* `security_group_ids` - (Required) Security groups IDs for the environment. At least one of the security group needs to allow MWAA resources to talk to each other, otherwise MWAA cannot be provisioned.\n* `subnet_ids` - (Required)  The private subnet IDs in which the environment should be created. MWAA requires two subnets.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the MWAA Environment\n* `created_at` - The Created At date of the MWAA Environment\n* `logging_configuration[0].<LOG_CONFIGURATION_TYPE>[0].cloud_watch_log_group_arn` - Provides the ARN for the CloudWatch group where the logs will be published\n* `service_role_arn` - The Service Role ARN of the Amazon MWAA Environment\n* `status` - The status of the Amazon MWAA Environment\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `webserver_url` - The webserver URL of the MWAA Environment\n\n\n## Import\n\nMWAA Environment can be imported using `Name` e.g.,\n\n```\n$ terraform import aws_mwaa_environment.example MyAirflowEnvironment\n```\n",
    "basename": "mwaa_environment.html"
  },
  "nat_gateway.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_nat_gateway",
    "description": "Provides a resource to create a VPC NAT Gateway.",
    "preview": "# Resource: aws_nat_gateway\n\nProvides a resource to create a VPC NAT …",
    "content": "\n\n# Resource: aws_nat_gateway\n\nProvides a resource to create a VPC NAT Gateway.\n\n## Example Usage\n\n### Public NAT\n\n```terraform\nresource \"aws_nat_gateway\" \"example\" {\n  allocation_id = aws_eip.example.id\n  subnet_id     = aws_subnet.example.id\n\n  tags = {\n    Name = \"gw NAT\"\n  }\n\n  # To ensure proper ordering, it is recommended to add an explicit dependency\n  # on the Internet Gateway for the VPC.\n  depends_on = [aws_internet_gateway.example]\n}\n```\n\n### Private NAT\n\n```terraform\nresource \"aws_nat_gateway\" \"example\" {\n  connectivity_type = \"private\"\n  subnet_id         = aws_subnet.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `allocation_id` - (Optional) The Allocation ID of the Elastic IP address for the gateway. Required for `connectivity_type` of `public`.\n* `connectivity_type` - (Optional) Connectivity type for the gateway. Valid values are `private` and `public`. Defaults to `public`.\n* `subnet_id` - (Required) The Subnet ID of the subnet in which to place the gateway.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the NAT Gateway.\n* `allocation_id` - The Allocation ID of the Elastic IP address for the gateway.\n* `subnet_id` - The Subnet ID of the subnet in which the NAT gateway is placed.\n* `network_interface_id` - The ENI ID of the network interface created by the NAT gateway.\n* `private_ip` - The private IP address of the NAT Gateway.\n* `public_ip` - The public IP address of the NAT Gateway.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nNAT Gateways can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_nat_gateway.private_gw nat-05dba92075d71c408\n```\n",
    "basename": "nat_gateway.html"
  },
  "neptune_cluster.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_cluster",
    "description": "Provides an Neptune Cluster Resource",
    "preview": "# Resource: aws_neptune_cluster\n\nProvides an Neptune Cluster …",
    "content": "\n\n# Resource: aws_neptune_cluster\n\nProvides an Neptune Cluster Resource. A Cluster Resource defines attributes that are\napplied to the entire cluster of Neptune Cluster Instances.\n\nChanges to a Neptune Cluster can occur when you manually change a\nparameter, such as `backup_retention_period`, and are reflected in the next maintenance\nwindow. Because of this, Terraform may report a difference in its planning\nphase because a modification has not yet taken place. You can use the\n`apply_immediately` flag to instruct the service to apply the change immediately\n(see documentation below).\n\n## Example Usage\n\n```terraform\nresource \"aws_neptune_cluster\" \"default\" {\n  cluster_identifier                  = \"neptune-cluster-demo\"\n  engine                              = \"neptune\"\n  backup_retention_period             = 5\n  preferred_backup_window             = \"07:00-09:00\"\n  skip_final_snapshot                 = true\n  iam_database_authentication_enabled = true\n  apply_immediately                   = true\n}\n```\n\n~> **Note:** AWS Neptune does not support user name/password–based access control.\nSee the AWS [Docs](https://docs.aws.amazon.com/neptune/latest/userguide/limits.html) for more information.\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `apply_immediately` - (Optional) Specifies whether any cluster modifications are applied immediately, or during the next maintenance window. Default is `false`.\n* `availability_zones` - (Optional) A list of EC2 Availability Zones that instances in the Neptune cluster can be created in.\n* `backup_retention_period` - (Optional) The days to retain backups for. Default `1`\n* `cluster_identifier` - (Optional, Forces new resources) The cluster identifier. If omitted, Terraform will assign a random, unique identifier.\n* `cluster_identifier_prefix` - (Optional, Forces new resource) Creates a unique cluster identifier beginning with the specified prefix. Conflicts with `cluster_identifier`.\n* `copy_tags_to_snapshot` - (Optional) If set to true, tags are copied to any snapshot of the DB cluster that is created.\n* `enable_cloudwatch_logs_exports` - (Optional) A list of the log types this DB cluster is configured to export to Cloudwatch Logs. Currently only supports `audit`.\n* `engine` - (Optional) The name of the database engine to be used for this Neptune cluster. Defaults to `neptune`.\n* `engine_version` - (Optional) The database engine version.\n* `final_snapshot_identifier` - (Optional) The name of your final Neptune snapshot when this Neptune cluster is deleted. If omitted, no final snapshot will be made.\n* `iam_roles` - (Optional) A List of ARNs for the IAM roles to associate to the Neptune Cluster.\n* `iam_database_authentication_enabled` - (Optional) Specifies whether or not mappings of AWS Identity and Access Management (IAM) accounts to database accounts is enabled.\n* `kms_key_arn` - (Optional) The ARN for the KMS encryption key. When specifying `kms_key_arn`, `storage_encrypted` needs to be set to true.\n* `neptune_subnet_group_name` - (Optional) A Neptune subnet group to associate with this Neptune instance.\n* `neptune_cluster_parameter_group_name` - (Optional) A cluster parameter group to associate with the cluster.\n* `preferred_backup_window` - (Optional) The daily time range during which automated backups are created if automated backups are enabled using the BackupRetentionPeriod parameter. Time in UTC. Default: A 30-minute window selected at random from an 8-hour block of time per regionE.g., 04:00-09:00\n* `preferred_maintenance_window` - (Optional) The weekly time range during which system maintenance can occur, in (UTC) e.g., wed:04:00-wed:04:30\n* `port` - (Optional) The port on which the Neptune accepts connections. Default is `8182`.\n* `replication_source_identifier` - (Optional) ARN of a source Neptune cluster or Neptune instance if this Neptune cluster is to be created as a Read Replica.\n* `skip_final_snapshot` - (Optional) Determines whether a final Neptune snapshot is created before the Neptune cluster is deleted. If true is specified, no Neptune snapshot is created. If false is specified, a Neptune snapshot is created before the Neptune cluster is deleted, using the value from `final_snapshot_identifier`. Default is `false`.\n* `snapshot_identifier` - (Optional) Specifies whether or not to create this cluster from a snapshot. You can use either the name or ARN when specifying a Neptune cluster snapshot, or the ARN when specifying a Neptune snapshot.\n* `storage_encrypted` - (Optional) Specifies whether the Neptune cluster is encrypted. The default is `false` if not specified.\n* `tags` - (Optional) A map of tags to assign to the Neptune cluster. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_security_group_ids` - (Optional) List of VPC security groups to associate with the Cluster\n* `deletion_protection` - (Optional) A value that indicates whether the DB cluster has deletion protection enabled.The database can't be deleted when deletion protection is enabled. By default, deletion protection is disabled.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Neptune Cluster Amazon Resource Name (ARN)\n* `cluster_resource_id` - The Neptune Cluster Resource ID\n* `cluster_members` – List of Neptune Instances that are a part of this cluster\n* `endpoint` - The DNS address of the Neptune instance\n* `hosted_zone_id` - The Route53 Hosted Zone ID of the endpoint\n* `id` - The Neptune Cluster Identifier\n* `reader_endpoint` - A read-only endpoint for the Neptune cluster, automatically load-balanced across replicas\n* `status` - The Neptune instance status\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_neptune_cluster` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `120 minutes`) Used for Cluster creation\n- `update` - (Default `120 minutes`) Used for Cluster modifications\n- `delete` - (Default `120 minutes`) Used for destroying cluster. This includes any cleanup task during the destroying process.\n\n## Import\n\n`aws_neptune_cluster` can be imported by using the cluster identifier, e.g.,\n\n```\n$ terraform import aws_neptune_cluster.example my-cluster\n```\n",
    "basename": "neptune_cluster.html"
  },
  "neptune_cluster_endpoint.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_cluster_endpoint",
    "description": "Provides an Neptune Cluster Endpoint Resource",
    "preview": "# Resource: aws_neptune_cluster_endpoint\n\nProvides an Neptune …",
    "content": "\n\n# Resource: aws_neptune_cluster_endpoint\n\nProvides an Neptune Cluster Endpoint Resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_neptune_cluster_endpoint\" \"example\" {\n  cluster_identifier          = aws_neptune_cluster.test.cluster_identifier\n  cluster_endpoint_identifier = \"example\"\n  endpoint_type               = \"READER\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_identifier` - (Required, Forces new resources) The DB cluster identifier of the DB cluster associated with the endpoint.\n* `cluster_identifier_endpoint` - (Required, Forces new resources) The identifier of the endpoint.\n* `endpoint_type` - (Required) The type of the endpoint. One of: `READER`, `WRITER`, `ANY`.\n* `excluded_members` - (Optional) List of DB instance identifiers that aren't part of the custom endpoint group. All other eligible instances are reachable through the custom endpoint. Only relevant if the list of static members is empty.\n* `static_members` - (Optional) List of DB instance identifiers that are part of the custom endpoint group.\n* `tags` - (Optional) A map of tags to assign to the Neptune cluster. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Neptune Cluster Endpoint Amazon Resource Name (ARN).\n* `endpoint` - The DNS address of the endpoint.\n* `id` - The Neptune Cluster Endpoint Identifier.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_neptune_cluster_endpoint` can be imported by using the `cluster-identifier:endpoint-identfier`, e.g.,\n\n```\n$ terraform import aws_neptune_cluster_endpoint.example my-cluster:my-endpoint\n```\n",
    "basename": "neptune_cluster_endpoint.html"
  },
  "neptune_cluster_instance.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_cluster_instance",
    "description": "Provides an Neptune Cluster Resource Instance",
    "preview": "# Resource: aws_neptune_cluster_instance\n\nA Cluster Instance …",
    "content": "\n\n# Resource: aws_neptune_cluster_instance\n\nA Cluster Instance Resource defines attributes that are specific to a single instance in a Neptune Cluster.\n\nYou can simply add neptune instances and Neptune manages the replication. You can use the [count][1]\nmeta-parameter to make multiple instances and join them all to the same Neptune Cluster, or you may specify different Cluster Instance resources with various `instance_class` sizes.\n\n\n## Example Usage\n\nThe following example will create a neptune cluster with two neptune instances(one writer and one reader).\n\n```terraform\nresource \"aws_neptune_cluster\" \"default\" {\n  cluster_identifier                  = \"neptune-cluster-demo\"\n  engine                              = \"neptune\"\n  backup_retention_period             = 5\n  preferred_backup_window             = \"07:00-09:00\"\n  skip_final_snapshot                 = true\n  iam_database_authentication_enabled = true\n  apply_immediately                   = true\n}\n\nresource \"aws_neptune_cluster_instance\" \"example\" {\n  count              = 2\n  cluster_identifier = aws_neptune_cluster.default.id\n  engine             = \"neptune\"\n  instance_class     = \"db.r4.large\"\n  apply_immediately  = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `apply_immediately` - (Optional) Specifies whether any instance modifications\n  are applied immediately, or during the next maintenance window. Default is`false`.\n* `auto_minor_version_upgrade` - (Optional) Indicates that minor engine upgrades will be applied automatically to the instance during the maintenance window. Default is `true`.\n* `availability_zone` - (Optional) The EC2 Availability Zone that the neptune instance is created in.\n* `cluster_identifier` - (Required) The identifier of the [`aws_neptune_cluster`](/docs/providers/aws/r/neptune_cluster.html) in which to launch this instance.\n* `engine` - (Optional) The name of the database engine to be used for the neptune instance. Defaults to `neptune`. Valid Values: `neptune`.\n* `engine_version` - (Optional) The neptune engine version.\n* `identifier` - (Optional, Forces new resource) The identifier for the neptune instance, if omitted, Terraform will assign a random, unique identifier.\n* `identifier_prefix` - (Optional, Forces new resource) Creates a unique identifier beginning with the specified prefix. Conflicts with `identifier`.\n* `instance_class` - (Required) The instance class to use.\n* `neptune_subnet_group_name` - (Required if `publicly_accessible = false`, Optional otherwise) A subnet group to associate with this neptune instance. **NOTE:** This must match the `neptune_subnet_group_name` of the attached [`aws_neptune_cluster`](/docs/providers/aws/r/neptune_cluster.html).\n* `neptune_parameter_group_name` - (Optional) The name of the neptune parameter group to associate with this instance.\n* `port` - (Optional) The port on which the DB accepts connections. Defaults to `8182`.\n* `preferred_backup_window` - (Optional) The daily time range during which automated backups are created if automated backups are enabled. Eg: \"04:00-09:00\"\n* `preferred_maintenance_window` - (Optional) The window to perform maintenance in.\n  Syntax: \"ddd:hh24:mi-ddd:hh24:mi\". Eg: \"Mon:00:00-Mon:03:00\".\n* `promotion_tier` - (Optional) Default 0. Failover Priority setting on instance level. The reader who has lower tier has higher priority to get promoter to writer.\n* `publicly_accessible` - (Optional) Bool to control if instance is publicly accessible. Default is `false`.\n* `tags` - (Optional) A map of tags to assign to the instance. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `address` - The hostname of the instance. See also `endpoint` and `port`.\n* `arn` - Amazon Resource Name (ARN) of neptune instance\n* `dbi_resource_id` - The region-unique, immutable identifier for the neptune instance.\n* `endpoint` - The connection endpoint in `address:port` format.\n* `id` - The Instance identifier\n* `kms_key_arn` - The ARN for the KMS encryption key if one is set to the neptune cluster.\n* `storage_encrypted` - Specifies whether the neptune cluster is encrypted.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `writer` – Boolean indicating if this instance is writable. `False` indicates this instance is a read replica.\n\n[1]: https://www.terraform.io/docs/configuration/meta-arguments/count.html\n\n## Timeouts\n\n`aws_neptune_cluster_instance` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `90 minutes`) How long to wait for creating instances to become available.\n- `update` - (Default `90 minutes`) How long to wait for updating instances to complete updates.\n- `delete` - (Default `90 minutes`) How long to wait for deleting instances to become fully deleted.\n\n## Import\n\n`aws_neptune_cluster_instance` can be imported by using the instance identifier, e.g.,\n\n```\n$ terraform import aws_neptune_cluster_instance.example my-instance\n```\n",
    "basename": "neptune_cluster_instance.html"
  },
  "neptune_cluster_parameter_group.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_cluster_parameter_group",
    "description": "Manages a Neptune Cluster Parameter Group",
    "preview": "# Resource: aws_neptune_cluster_parameter_group\n\nManages a Neptune …",
    "content": "\n\n# Resource: aws_neptune_cluster_parameter_group\n\nManages a Neptune Cluster Parameter Group\n\n## Example Usage\n\n```terraform\nresource \"aws_neptune_cluster_parameter_group\" \"example\" {\n  family      = \"neptune1\"\n  name        = \"example\"\n  description = \"neptune cluster parameter group\"\n\n  parameter {\n    name  = \"neptune_enable_audit_log\"\n    value = 1\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the neptune cluster parameter group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `family` - (Required) The family of the neptune cluster parameter group.\n* `description` - (Optional) The description of the neptune cluster parameter group. Defaults to \"Managed by Terraform\".\n* `parameter` - (Optional) A list of neptune parameters to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nParameter blocks support the following:\n\n* `name` - (Required) The name of the neptune parameter.\n* `value` - (Required) The value of the neptune parameter.\n* `apply_method` - (Optional) Valid values are `immediate` and `pending-reboot`. Defaults to `pending-reboot`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The neptune cluster parameter group name.\n* `arn` - The ARN of the neptune cluster parameter group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nNeptune Cluster Parameter Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_neptune_cluster_parameter_group.cluster_pg production-pg-1\n```\n",
    "basename": "neptune_cluster_parameter_group.html"
  },
  "neptune_cluster_snapshot.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_cluster_snapshot",
    "description": "Manages a Neptune database cluster snapshot.",
    "preview": "# Resource: aws_neptune_cluster_snapshot\n\nManages a Neptune database …",
    "content": "\n\n# Resource: aws_neptune_cluster_snapshot\n\nManages a Neptune database cluster snapshot.\n\n## Example Usage\n\n```terraform\nresource \"aws_neptune_cluster_snapshot\" \"example\" {\n  db_cluster_identifier          = aws_neptune_cluster.example.id\n  db_cluster_snapshot_identifier = \"resourcetestsnapshot1234\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_cluster_identifier` - (Required) The DB Cluster Identifier from which to take the snapshot.\n* `db_cluster_snapshot_identifier` - (Required) The Identifier for the snapshot.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `allocated_storage` - Specifies the allocated storage size in gigabytes (GB).\n* `availability_zones` - List of EC2 Availability Zones that instances in the DB cluster snapshot can be restored in.\n* `db_cluster_snapshot_arn` - The Amazon Resource Name (ARN) for the DB Cluster Snapshot.\n* `engine` - Specifies the name of the database engine.\n* `engine_version` - Version of the database engine for this DB cluster snapshot.\n* `kms_key_id` - If storage_encrypted is true, the AWS KMS key identifier for the encrypted DB cluster snapshot.\n* `license_model` - License model information for the restored DB cluster.\n* `port` - Port that the DB cluster was listening on at the time of the snapshot.\n* `source_db_cluster_snapshot_identifier` - The DB Cluster Snapshot Arn that the DB Cluster Snapshot was copied from. It only has value in case of cross customer or cross region copy.\n* `storage_encrypted` - Specifies whether the DB cluster snapshot is encrypted.\n* `status` - The status of this DB Cluster Snapshot.\n* `vpc_id` - The VPC ID associated with the DB cluster snapshot.\n\n## Timeouts\n\n`aws_neptune_cluster_snapshot` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `20m`) How long to wait for the snapshot to be available.\n\n## Import\n\n`aws_neptune_cluster_snapshot` can be imported by using the cluster snapshot identifier, e.g.,\n\n```\n$ terraform import aws_neptune_cluster_snapshot.example my-cluster-snapshot\n```\n",
    "basename": "neptune_cluster_snapshot.html"
  },
  "neptune_event_subscription.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_event_subscription",
    "description": "Provides a Neptune event subscription resource.",
    "preview": "# Resource: aws_neptune_event_subscription\n\n## Example Usage\n …",
    "content": "\n\n# Resource: aws_neptune_event_subscription\n\n## Example Usage\n\n```terraform\nresource \"aws_neptune_cluster\" \"default\" {\n  cluster_identifier                  = \"neptune-cluster-demo\"\n  engine                              = \"neptune\"\n  backup_retention_period             = 5\n  preferred_backup_window             = \"07:00-09:00\"\n  skip_final_snapshot                 = true\n  iam_database_authentication_enabled = \"true\"\n  apply_immediately                   = \"true\"\n}\n\nresource \"aws_neptune_cluster_instance\" \"example\" {\n  cluster_identifier = aws_neptune_cluster.default.id\n  engine             = \"neptune\"\n  instance_class     = \"db.r4.large\"\n  apply_immediately  = \"true\"\n}\n\nresource \"aws_sns_topic\" \"default\" {\n  name = \"neptune-events\"\n}\n\nresource \"aws_neptune_event_subscription\" \"default\" {\n  name          = \"neptune-event-sub\"\n  sns_topic_arn = aws_sns_topic.default.arn\n\n  source_type = \"db-instance\"\n  source_ids  = [aws_neptune_cluster_instance.example.id]\n\n  event_categories = [\n    \"maintenance\",\n    \"availability\",\n    \"creation\",\n    \"backup\",\n    \"restoration\",\n    \"recovery\",\n    \"deletion\",\n    \"failover\",\n    \"failure\",\n    \"notification\",\n    \"configuration change\",\n    \"read replica\",\n  ]\n\n  tags = {\n    env = \"test\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `enabled` - (Optional) A boolean flag to enable/disable the subscription. Defaults to true.\n* `event_categories` - (Optional) A list of event categories for a `source_type` that you want to subscribe to. Run `aws neptune describe-event-categories` to find all the event categories.\n* `name` - (Optional) The name of the Neptune event subscription. By default generated by Terraform.\n* `name_prefix` - (Optional) The name of the Neptune event subscription. Conflicts with `name`.\n* `sns_topic_arn` - (Required) The ARN of the SNS topic to send events to.\n* `source_ids` - (Optional) A list of identifiers of the event sources for which events will be returned. If not specified, then all sources are included in the response. If specified, a `source_type` must also be specified.\n* `source_type` - (Optional) The type of source that will be generating the events. Valid options are `db-instance`, `db-security-group`, `db-parameter-group`, `db-snapshot`, `db-cluster` or `db-cluster-snapshot`. If not set, all sources will be subscribed to.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Neptune event notification subscription.\n* `arn` - The Amazon Resource Name of the Neptune event notification subscription.\n* `customer_aws_id` - The AWS customer account associated with the Neptune event notification subscription.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_neptune_event_subscription` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `40m`) How long to wait for creating event subscription to become available.\n- `delete` - (Default `40m`) How long to wait for deleting event subscription to become fully deleted.\n- `update` - (Default `40m`) How long to wait for updating event subscription to complete updates.\n\n## Import\n\n`aws_neptune_event_subscription` can be imported by using the event subscription name, e.g.,\n\n```\n$ terraform import aws_neptune_event_subscription.example my-event-subscription\n```\n",
    "basename": "neptune_event_subscription.html"
  },
  "neptune_parameter_group.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_parameter_group",
    "description": "Manages a Neptune Parameter Group",
    "preview": "# Resource: aws_neptune_parameter_group\n\nManages a Neptune Parameter …",
    "content": "\n\n# Resource: aws_neptune_parameter_group\n\nManages a Neptune Parameter Group\n\n## Example Usage\n\n```terraform\nresource \"aws_neptune_parameter_group\" \"example\" {\n  family = \"neptune1\"\n  name   = \"example\"\n\n  parameter {\n    name  = \"neptune_query_timeout\"\n    value = \"25\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required, Forces new resource) The name of the Neptune parameter group.\n* `family` - (Required) The family of the Neptune parameter group.\n* `description` - (Optional) The description of the Neptune parameter group. Defaults to \"Managed by Terraform\".\n* `parameter` - (Optional) A list of Neptune parameters to apply.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nParameter blocks support the following:\n\n* `name`  - (Required) The name of the Neptune parameter.\n* `value` - (Required) The value of the Neptune parameter.\n* `apply_method` - (Optional) The apply method of the Neptune parameter. Valid values are `immediate` and `pending-reboot`. Defaults to `pending-reboot`.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Neptune parameter group name.\n* `arn` - The Neptune parameter group Amazon Resource Name (ARN).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nNeptune Parameter Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_neptune_parameter_group.some_pg some-pg\n```\n",
    "basename": "neptune_parameter_group.html"
  },
  "neptune_subnet_group.html": {
    "subcategory": "Neptune",
    "layout": "aws",
    "page_title": "AWS: aws_neptune_subnet_group",
    "description": "Provides an Neptune subnet group resource.",
    "preview": "# Resource: aws_neptune_subnet_group\n\nProvides an Neptune subnet …",
    "content": "\n\n# Resource: aws_neptune_subnet_group\n\nProvides an Neptune subnet group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_neptune_subnet_group\" \"default\" {\n  name       = \"main\"\n  subnet_ids = [aws_subnet.frontend.id, aws_subnet.backend.id]\n\n  tags = {\n    Name = \"My neptune subnet group\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the neptune subnet group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` - (Optional) The description of the neptune subnet group. Defaults to \"Managed by Terraform\".\n* `subnet_ids` - (Required) A list of VPC subnet IDs.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The neptune subnet group name.\n* `arn` - The ARN of the neptune subnet group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nNeptune Subnet groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_neptune_subnet_group.default production-subnet-group\n```\n",
    "basename": "neptune_subnet_group.html"
  },
  "network_acl.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_network_acl",
    "description": "Provides an network ACL resource.",
    "preview": "# Resource: aws_network_acl\n\nProvides an network ACL resource. You …",
    "content": "\n\n# Resource: aws_network_acl\n\nProvides an network ACL resource. You might set up network ACLs with rules similar\nto your security groups in order to add an additional layer of security to your VPC.\n\n~> **NOTE on Network ACLs and Network ACL Rules:** Terraform currently\nprovides both a standalone [Network ACL Rule](network_acl_rule.html) resource and a Network ACL resource with rules\ndefined in-line. At this time you cannot use a Network ACL with in-line rules\nin conjunction with any Network ACL Rule resources. Doing so will cause\na conflict of rule settings and will overwrite rules.\n\n## Example Usage\n\n```terraform\nresource \"aws_network_acl\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  egress {\n    protocol   = \"tcp\"\n    rule_no    = 200\n    action     = \"allow\"\n    cidr_block = \"10.3.0.0/18\"\n    from_port  = 443\n    to_port    = 443\n  }\n\n  ingress {\n    protocol   = \"tcp\"\n    rule_no    = 100\n    action     = \"allow\"\n    cidr_block = \"10.3.0.0/18\"\n    from_port  = 80\n    to_port    = 80\n  }\n\n  tags = {\n    Name = \"main\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Required) The ID of the associated VPC.\n* `subnet_ids` - (Optional) A list of Subnet IDs to apply the ACL to\n* `ingress` - (Optional) Specifies an ingress rule. Parameters defined below.\n  This argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n* `egress` - (Optional) Specifies an egress rule. Parameters defined below.\n  This argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### egress and ingress\n\nBoth arguments are processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\nBoth `egress` and `ingress` support the following keys:\n\n* `from_port` - (Required) The from port to match.\n* `to_port` - (Required) The to port to match.\n* `rule_no` - (Required) The rule number. Used for ordering.\n* `action` - (Required) The action to take.\n* `protocol` - (Required) The protocol to match. If using the -1 'all'\nprotocol, you must specify a from and to port of 0.\n* `cidr_block` - (Optional) The CIDR block to match. This must be a\nvalid network mask.\n* `ipv6_cidr_block` - (Optional) The IPv6 CIDR block.\n* `icmp_type` - (Optional) The ICMP type to be used. Default 0.\n* `icmp_code` - (Optional) The ICMP type code to be used. Default 0.\n\n~> Note: For more information on ICMP types and codes, see here: https://www.iana.org/assignments/icmp-parameters/icmp-parameters.xhtml\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the network ACL\n* `arn` - The ARN of the network ACL\n* `owner_id` - The ID of the AWS account that owns the network ACL.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nNetwork ACLs can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_network_acl.main acl-7aaabd18\n```\n",
    "basename": "network_acl.html"
  },
  "network_acl_rule.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_network_acl_rule",
    "description": "Provides an network ACL Rule resource.",
    "preview": "# Resource: aws_network_acl_rule\n\nCreates an entry (a rule) in a …",
    "content": "\n\n# Resource: aws_network_acl_rule\n\nCreates an entry (a rule) in a network ACL with the specified rule number.\n\n~> **NOTE on Network ACLs and Network ACL Rules:** Terraform currently\nprovides both a standalone Network ACL Rule resource and a [Network ACL](network_acl.html) resource with rules\ndefined in-line. At this time you cannot use a Network ACL with in-line rules\nin conjunction with any Network ACL Rule resources. Doing so will cause\na conflict of rule settings and will overwrite rules.\n\n## Example Usage\n\n```terraform\nresource \"aws_network_acl\" \"bar\" {\n  vpc_id = aws_vpc.foo.id\n}\n\nresource \"aws_network_acl_rule\" \"bar\" {\n  network_acl_id = aws_network_acl.bar.id\n  rule_number    = 200\n  egress         = false\n  protocol       = \"tcp\"\n  rule_action    = \"allow\"\n  cidr_block     = aws_vpc.foo.cidr_block\n  from_port      = 22\n  to_port        = 22\n}\n```\n\n~> **Note:** One of either `cidr_block` or `ipv6_cidr_block` is required.\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `network_acl_id` - (Required) The ID of the network ACL.\n* `rule_number` - (Required) The rule number for the entry (for example, 100). ACL entries are processed in ascending order by rule number.\n* `egress` - (Optional, bool) Indicates whether this is an egress rule (rule is applied to traffic leaving the subnet). Default `false`.\n* `protocol` - (Required) The protocol. A value of -1 means all protocols.\n* `rule_action` - (Required) Indicates whether to allow or deny the traffic that matches the rule. Accepted values: `allow` | `deny`\n* `cidr_block` - (Optional) The network range to allow or deny, in CIDR notation (for example 172.16.0.0/24 ).\n* `ipv6_cidr_block` - (Optional) The IPv6 CIDR block to allow or deny.\n* `from_port` - (Optional) The from port to match.\n* `to_port` - (Optional) The to port to match.\n* `icmp_type` - (Optional) ICMP protocol: The ICMP type. Required if specifying ICMP for the protocolE.g., -1\n* `icmp_code` - (Optional) ICMP protocol: The ICMP code. Required if specifying ICMP for the protocolE.g., -1\n\n~> **NOTE:** If the value of `protocol` is `-1` or `all`, the `from_port` and `to_port` values will be ignored and the rule will apply to all ports.\n\n~> **NOTE:** If the value of `icmp_type` is `-1` (which results in a wildcard ICMP type), the `icmp_code` must also be set to `-1` (wildcard ICMP code).\n\n~> Note: For more information on ICMP types and codes, see here: https://www.iana.org/assignments/icmp-parameters/icmp-parameters.xhtml\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the network ACL Rule\n\n## Import\n\nIndividual rules can be imported using `NETWORK_ACL_ID:RULE_NUMBER:PROTOCOL:EGRESS`, where `PROTOCOL` can be a decimal (e.g., 6) or string (e.g., tcp) value.\nIf importing a rule previously provisioned by Terraform, the `PROTOCOL` must be the input value used at creation time.\nFor more information on protocol numbers and keywords, see here: https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml\n\nFor example, import a network ACL Rule with an argument like this:\n\n```console\n$ terraform import aws_network_acl_rule.my_rule acl-7aaabd18:100:tcp:false\n```\n\nOr by the procotol's decimal value:\n\n```console\n$ terraform import aws_network_acl_rule.my_rule acl-7aaabd18:100:6:false\n```\n",
    "basename": "network_acl_rule.html"
  },
  "network_interface": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_network_interface",
    "description": "Provides an Elastic network interface (ENI) resource.",
    "preview": "# Resource: aws_network_interface\n\nProvides an Elastic network …",
    "content": "\n\n# Resource: aws_network_interface\n\nProvides an Elastic network interface (ENI) resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_network_interface\" \"test\" {\n  subnet_id       = aws_subnet.public_a.id\n  private_ips     = [\"10.0.0.50\"]\n  security_groups = [aws_security_group.web.id]\n\n  attachment {\n    instance     = aws_instance.test.id\n    device_index = 1\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `subnet_id` - (Required) Subnet ID to create the ENI in.\n* `description` - (Optional) A description for the network interface.\n* `private_ips` - (Optional) List of private IPs to assign to the ENI.\n* `private_ips_count` - (Optional) Number of secondary private IPs to assign to the ENI. The total number of private IPs will be 1 + private_ips_count, as a primary private IP will be assiged to an ENI by default.\n* `ipv6_addresses` - (Optional) One or more specific IPv6 addresses from the IPv6 CIDR block range of your subnet. You can't use this option if you're specifying `ipv6_address_count`.\n* `ipv6_address_count` - (Optional) The number of IPv6 addresses to assign to a network interface. You can't use this option if specifying specific `ipv6_addresses`. If your subnet has the AssignIpv6AddressOnCreation attribute set to `true`, you can specify `0` to override this setting.\n* `security_groups` - (Optional) List of security group IDs to assign to the ENI.\n* `attachment` - (Optional) Block to define the attachment of the ENI. Documented below.\n* `source_dest_check` - (Optional) Whether to enable source destination checking for the ENI. Default true.\n* `ipv4_prefixes` - (Optional) One or more IPv4 prefixes assigned to the network interface.\n* `ipv4_prefix_count` - (Optional) The number of IPv4 prefixes that AWS automatically assigns to the network interface.\n* `ipv6_prefixes` - (Optional) One or more IPv6 prefixes assigned to the network interface.\n* `ipv6_prefix_count` - (Optional) The number of IPv6 prefixes that AWS automatically assigns to the network interface.\n\n-> **NOTE:** Changing `interface_type` will cause the resource to be destroyed and re-created.\n\n* `interface_type` - (Optional) Type of network interface to create. Set to `efa` for Elastic Fabric Adapter.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `attachment` block supports:\n\n* `instance` - (Required) ID of the instance to attach to.\n* `device_index` - (Required) Integer to define the devices index.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the network interface.\n* `id` - The ID of the network interface.\n* `mac_address` - The MAC address of the network interface.\n* `owner_id` - The AWS account ID of the owner of the network interface.\n* `private_dns_name` - The private DNS name of the network interface (IPv4).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nNetwork Interfaces can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_network_interface.test eni-e5aa89a3\n```\n",
    "basename": "network_interface"
  },
  "network_interface_attachment.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_network_interface_attachment",
    "description": "Attach an Elastic network interface (ENI) resource with EC2 instance.",
    "preview": "# Resource: aws_network_interface_attachment\n\nAttach an Elastic …",
    "content": "\n\n# Resource: aws_network_interface_attachment\n\nAttach an Elastic network interface (ENI) resource with EC2 instance.\n\n## Example Usage\n\n```terraform\nresource \"aws_network_interface_attachment\" \"test\" {\n  instance_id          = aws_instance.test.id\n  network_interface_id = aws_network_interface.test.id\n  device_index         = 0\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `instance_id` - (Required) Instance ID to attach.\n* `network_interface_id` - (Required) ENI ID to attach.\n* `device_index` - (Required) Network interface index (int).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `instance_id` - Instance ID.\n* `network_interface_id` - Network interface ID.\n* `attachment_id` - The ENI Attachment ID.\n* `status` - The status of the Network Interface Attachment.\n",
    "basename": "network_interface_attachment.html"
  },
  "network_interface_sg_attachment.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_network_interface_sg_attachment",
    "description": "Associates a security group with a network interface.",
    "preview": "# Resource: aws_network_interface_sg_attachment\n\nThis resource …",
    "content": "\n\n# Resource: aws_network_interface_sg_attachment\n\nThis resource attaches a security group to an Elastic Network Interface (ENI).\nIt can be used to attach a security group to any existing ENI, be it a\nsecondary ENI or one attached as the primary interface on an instance.\n\n~> **NOTE on instances, interfaces, and security groups:** Terraform currently\nprovides the capability to assign security groups via the [`aws_instance`][1]\nand the [`aws_network_interface`][2] resources. Using this resource in\nconjunction with security groups provided in-line in those resources will cause\nconflicts, and will lead to spurious diffs and undefined behavior - please use\none or the other.\n\n[1]: /docs/providers/aws/d/instance.html\n[2]: /docs/providers/aws/r/network_interface.html\n\n## Example Usage\n\nThe following provides a very basic example of setting up an instance (provided\nby `instance`) in the default security group, creating a security group\n(provided by `sg`) and then attaching the security group to the instance's\nprimary network interface via the `aws_network_interface_sg_attachment` resource,\nnamed `sg_attachment`:\n\n```terraform\ndata \"aws_ami\" \"ami\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"amzn-ami-hvm-*\"]\n  }\n\n  owners = [\"amazon\"]\n}\n\nresource \"aws_instance\" \"instance\" {\n  instance_type = \"t2.micro\"\n  ami           = data.aws_ami.ami.id\n\n  tags = {\n    type = \"terraform-test-instance\"\n  }\n}\n\nresource \"aws_security_group\" \"sg\" {\n  tags = {\n    type = \"terraform-test-security-group\"\n  }\n}\n\nresource \"aws_network_interface_sg_attachment\" \"sg_attachment\" {\n  security_group_id    = aws_security_group.sg.id\n  network_interface_id = aws_instance.instance.primary_network_interface_id\n}\n```\n\nIn this example, `instance` is provided by the `aws_instance` data source,\nfetching an external instance, possibly not managed by Terraform.\n`sg_attachment` then attaches to the output instance's `network_interface_id`:\n\n```terraform\ndata \"aws_instance\" \"instance\" {\n  instance_id = \"i-1234567890abcdef0\"\n}\n\nresource \"aws_security_group\" \"sg\" {\n  tags = {\n    type = \"terraform-test-security-group\"\n  }\n}\n\nresource \"aws_network_interface_sg_attachment\" \"sg_attachment\" {\n  security_group_id    = aws_security_group.sg.id\n  network_interface_id = data.aws_instance.instance.network_interface_id\n}\n```\n\n## Argument Reference\n\n* `security_group_id` - (Required) The ID of the security group.\n* `network_interface_id` - (Required) The ID of the network interface to attach to.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "network_interface_sg_attachment.html"
  },
  "networkfirewall_firewall.html": {
    "subcategory": "Network Firewall",
    "layout": "aws",
    "page_title": "AWS: aws_networkfirewall_firewall",
    "description": "Provides an AWS Network Firewall Firewall resource.",
    "preview": "# Resource: aws_networkfirewall_firewall\n\nProvides an AWS Network …",
    "content": "\n\n# Resource: aws_networkfirewall_firewall\n\nProvides an AWS Network Firewall Firewall Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_networkfirewall_firewall\" \"example\" {\n  name                = \"example\"\n  firewall_policy_arn = aws_networkfirewall_firewall_policy.example.arn\n  vpc_id              = aws_vpc.example.id\n  subnet_mapping {\n    subnet_id = aws_subnet.example.id\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `delete_protection` - (Optional) A boolean flag indicating whether it is possible to delete the firewall. Defaults to `false`.\n\n* `description` - (Optional) A friendly description of the firewall.\n\n* `firewall_policy_arn` - (Required) The Amazon Resource Name (ARN) of the VPC Firewall policy.\n\n* `firewall_policy_change_protection` - (Option) A boolean flag indicating whether it is possible to change the associated firewall policy. Defaults to `false`.\n\n* `name` - (Required, Forces new resource) A friendly name of the firewall.\n\n* `subnet_change_protection` - (Optional) A boolean flag indicating whether it is possible to change the associated subnet(s). Defaults to `false`.\n\n* `subnet_mapping` - (Required) Set of configuration blocks describing the public subnets. Each subnet must belong to a different Availability Zone in the VPC. AWS Network Firewall creates a firewall endpoint in each subnet. See [Subnet Mapping](#subnet-mapping) below for details.\n\n* `tags` - (Optional) Map of resource tags to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n* `vpc_id` - (Required, Forces new resource) The unique identifier of the VPC where AWS Network Firewall should create the firewall.\n\n### Subnet Mapping\n\nThe `subnet_mapping` block supports the following arguments:\n\n* `subnet_id` - (Required) The unique identifier for the subnet.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) that identifies the firewall.\n\n* `arn` - The Amazon Resource Name (ARN) that identifies the firewall.\n\n* `firewall_status` - Nested list of information about the current status of the firewall.\n    * `sync_states` - Set of subnets configured for use by the firewall.\n        * `attachment` - Nested list describing the attachment status of the firewall's association with a single VPC subnet.\n            * `endpoint_id` - The identifier of the firewall endpoint that AWS Network Firewall has instantiated in the subnet. You use this to identify the firewall endpoint in the VPC route tables, when you redirect the VPC traffic through the endpoint.\n            * `subnet_id` - The unique identifier of the subnet that you've specified to be used for a firewall endpoint.\n        * `availability_zone` - The Availability Zone where the subnet is configured.\n\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n* `update_token` - A string token used when updating a firewall.\n\n## Import\n\nNetwork Firewall Firewalls can be imported using their `ARN`.\n\n```\n$ terraform import aws_networkfirewall_firewall.example arn:aws:network-firewall:us-west-1:123456789012:firewall/example\n```\n",
    "basename": "networkfirewall_firewall.html"
  },
  "networkfirewall_firewall_policy.html": {
    "subcategory": "Network Firewall",
    "layout": "aws",
    "page_title": "AWS: aws_networkfirewall_firewall_policy",
    "description": "Provides an AWS Network Firewall Policy resource.",
    "preview": "# Resource: aws_networkfirewall_firewall_policy\n\nProvides an AWS …",
    "content": "\n\n# Resource: aws_networkfirewall_firewall_policy\n\nProvides an AWS Network Firewall Firewall Policy Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_networkfirewall_firewall_policy\" \"example\" {\n  name = \"example\"\n\n  firewall_policy {\n    stateless_default_actions          = [\"aws:pass\"]\n    stateless_fragment_default_actions = [\"aws:drop\"]\n    stateless_rule_group_reference {\n      priority     = 1\n      resource_arn = aws_networkfirewall_rule_group.example.arn\n    }\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n## Policy with a Custom Action for Stateless Inspection\n\n```terraform\nresource \"aws_networkfirewall_firewall_policy\" \"test\" {\n  name = \"example\"\n\n  firewall_policy {\n    stateless_default_actions          = [\"aws:pass\", \"ExampleCustomAction\"]\n    stateless_fragment_default_actions = [\"aws:drop\"]\n\n    stateless_custom_action {\n      action_definition {\n        publish_metric_action {\n          dimension {\n            value = \"1\"\n          }\n        }\n      }\n      action_name = \"ExampleCustomAction\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) A friendly description of the firewall policy.\n\n* `firewall_policy` - (Required) A configuration block describing the rule groups and policy actions to use in the firewall policy. See [Firewall Policy](#firewall-policy) below for details.\n\n* `name` - (Required, Forces new resource) A friendly name of the firewall policy.\n\n* `tags` - (Optional) Map of resource tags to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Firewall Policy\n\nThe `firewall_policy` block supports the following arguments:\n\n* `stateful_default_actions` - (Optional) Set of actions to take on a packet if it does not match any stateful rules in the policy. This can only be specified if the policy has a `stateful_engine_options` block with a `rule_order` value of `STRICT_ORDER`. You can specify one of either or neither values of `aws:drop_strict` or `aws:drop_established`, as well as any combination of `aws:alert_strict` and `aws:alert_established`.\n\n* `stateful_engine_options` - (Optional) A configuration block that defines options on how the policy handles stateful rules. See [Stateful Engine Options](#stateful-engine-options) below for details.\n\n* `stateful_rule_group_reference` - (Optional) Set of configuration blocks containing references to the stateful rule groups that are used in the policy. See [Stateful Rule Group Reference](#stateful-rule-group-reference) below for details.\n\n* `stateless_custom_action` - (Optional) Set of configuration blocks describing the custom action definitions that are available for use in the firewall policy's `stateless_default_actions`. See [Stateless Custom Action](#stateless-custom-action) below for details.\n\n* `stateless_default_actions` - (Required) Set of actions to take on a packet if it does not match any of the stateless rules in the policy. You must specify one of the standard actions including: `aws:drop`, `aws:pass`, or `aws:forward_to_sfe`.\nIn addition, you can specify custom actions that are compatible with your standard action choice. If you want non-matching packets to be forwarded for stateful inspection, specify `aws:forward_to_sfe`.\n\n* `stateless_fragment_default_actions` - (Required) Set of actions to take on a fragmented packet if it does not match any of the stateless rules in the policy. You must specify one of the standard actions including: `aws:drop`, `aws:pass`, or `aws:forward_to_sfe`.\nIn addition, you can specify custom actions that are compatible with your standard action choice. If you want non-matching packets to be forwarded for stateful inspection, specify `aws:forward_to_sfe`.\n\n* `stateless_rule_group_reference` - (Optional) Set of configuration blocks containing references to the stateless rule groups that are used in the policy. See [Stateless Rule Group Reference](#stateless-rule-group-reference) below for details.\n\n### Stateful Engine Options\nThe `stateful_engine_options` block supports the following argument:\n\n~> **NOTE:** If the `STRICT_ORDER` rule order is specified, this firewall policy can only reference stateful rule groups that utilize `STRICT_ORDER`.\n\n* `rule_order` - (Required) Indicates how to manage the order of stateful rule evaluation for the policy. Default value: `DEFAULT_ACTION_ORDER`. Valid values: `DEFAULT_ACTION_ORDER`, `STRICT_ORDER`.\n\n### Stateful Rule Group Reference\n\nThe `stateful_rule_group_reference` block supports the following arguments:\n\n* `priority` - (Optional) An integer setting that indicates the order in which to apply the stateful rule groups in a single policy. This argument must be specified if the policy has a `stateful_engine_options` block with a `rule_order` value of `STRICT_ORDER`. AWS Network Firewall applies each stateful rule group to a packet starting with the group that has the lowest priority setting.\n\n* `resource_arn` - (Required) The Amazon Resource Name (ARN) of the stateful rule group.\n\n### Stateless Custom Action\n\nThe `stateless_custom_action` block supports the following arguments:\n\n* `action_definition` - (Required) A configuration block describing the custom action associated with the `action_name`. See [Action Definition](#action-definition) below for details.\n\n* `action_name` - (Required, Forces new resource) A friendly name of the custom action.\n\n### Stateless Rule Group Reference\n\nThe `stateless_rule_group_reference` block supports the following arguments:\n\n* `priority` - (Required) An integer setting that indicates the order in which to run the stateless rule groups in a single policy. AWS Network Firewall applies each stateless rule group to a packet starting with the group that has the lowest priority setting.\n\n* `resource_arn` - (Required) The Amazon Resource Name (ARN) of the stateless rule group.\n\n### Action Definition\n\nThe `action_definition` block supports the following argument:\n\n* `publish_metric_action` - (Required) A configuration block describing the stateless inspection criteria that publishes the specified metrics to Amazon CloudWatch for the matching packet. You can pair this custom action with any of the standard stateless rule actions. See [Publish Metric Action](#publish-metric-action) below for details.\n\n### Publish Metric Action\n\nThe `publish_metric_action` block supports the following argument:\n\n* `dimension` - (Required) Set of configuration blocks describing dimension settings to use for Amazon CloudWatch custom metrics. See [Dimension](#dimension) below for more details.\n\n### Dimension\n\nThe `dimension` block supports the following argument:\n\n* `value` - (Required) The string value to use in the custom metric dimension.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) that identifies the firewall policy.\n\n* `arn` - The Amazon Resource Name (ARN) that identifies the firewall policy.\n\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n* `update_token` - A string token used when updating a firewall policy.\n\n## Import\n\nNetwork Firewall Policies can be imported using their `ARN`.\n\n```\n$ terraform import aws_networkfirewall_firewall_policy.example arn:aws:network-firewall:us-west-1:123456789012:firewall-policy/example\n```\n",
    "basename": "networkfirewall_firewall_policy.html"
  },
  "networkfirewall_logging_configuration.html": {
    "subcategory": "Network Firewall",
    "layout": "aws",
    "page_title": "AWS: aws_networkfirewall_logging_configuration",
    "description": "Provides an AWS Network Firewall Logging Configuration resource.",
    "preview": "# Resource: aws_networkfirewall_logging_configuration\n\nProvides an …",
    "content": "\n\n# Resource: aws_networkfirewall_logging_configuration\n\nProvides an AWS Network Firewall Logging Configuration Resource\n\n## Example Usage\n\n### Logging to S3\n\n```terraform\nresource \"aws_networkfirewall_logging_configuration\" \"example\" {\n  firewall_arn = aws_networkfirewall_firewall.example.arn\n  logging_configuration {\n    log_destination_config {\n      log_destination = {\n        bucketName = aws_s3_bucket.example.bucket\n        prefix     = \"/example\"\n      }\n      log_destination_type = \"S3\"\n      log_type             = \"FLOW\"\n    }\n  }\n}\n```\n\n### Logging to CloudWatch\n\n```terraform\nresource \"aws_networkfirewall_logging_configuration\" \"example\" {\n  firewall_arn = aws_networkfirewall_firewall.example.arn\n  logging_configuration {\n    log_destination_config {\n      log_destination = {\n        logGroup = aws_cloudwatch_log_group.example.name\n      }\n      log_destination_type = \"CloudWatchLogs\"\n      log_type             = \"ALERT\"\n    }\n  }\n}\n```\n\n### Logging to Kinesis Data Firehose\n\n```terraform\nresource \"aws_networkfirewall_logging_configuration\" \"example\" {\n  firewall_arn = aws_networkfirewall_firewall.example.arn\n  logging_configuration {\n    log_destination_config {\n      log_destination = {\n        deliveryStream = aws_kinesis_firehose_delivery_stream.example.name\n      }\n      log_destination_type = \"KinesisDataFirehose\"\n      log_type             = \"ALERT\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `firewall_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the Network Firewall firewall.\n\n* `logging_configuration` - (Required) A configuration block describing how AWS Network Firewall performs logging for a firewall. See [Logging Configuration](#logging-configuration) below for details.\n\n### Logging Configuration\n\nThe `logging_configuration` block supports the following arguments:\n\n* `log_destination_config` - (Required) Set of configuration blocks describing the logging details for a firewall. See [Log Destination Config](#log-destination-config) below for details. At most, only two blocks can be specified; one for `FLOW` logs and one for `ALERT` logs.\n\n### Log Destination Config\n\nThe `log_destination_config` block supports the following arguments:\n\n* `log_destination` - (Required) A map describing the logging destination for the chosen `log_destination_type`.\n    * For an Amazon S3 bucket, specify the key `bucketName` with the name of the bucket and optionally specify the key `prefix` with a path.\n    * For a CloudWatch log group, specify the key `logGroup` with the name of the CloudWatch log group.\n    * For a Kinesis Data Firehose delivery stream, specify the key `deliveryStream` with the name of the delivery stream.\n\n* `log_destination_type` - (Required) The location to send logs to. Valid values: `S3`, `CloudWatchLogs`, `KinesisDataFirehose`.\n\n* `log_type` - (Required) The type of log to send. Valid values: `ALERT` or `FLOW`. Alert logs report traffic that matches a `StatefulRule` with an action setting that sends a log message. Flow logs are standard network traffic flow logs.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the associated firewall.\n\n## Import\n\nNetwork Firewall Logging Configurations can be imported using the `firewall_arn` e.g\n\n```\n$ terraform import aws_networkfirewall_logging_configuration.example arn:aws:network-firewall:us-west-1:123456789012:firewall/example\n```\n",
    "basename": "networkfirewall_logging_configuration.html"
  },
  "networkfirewall_resource_policy.html": {
    "subcategory": "Network Firewall",
    "layout": "aws",
    "page_title": "AWS: aws_networkfirewall_resource_policy",
    "description": "Provides an AWS Network Firewall Resource Policy resource.",
    "preview": "# Resource: aws_networkfirewall_resource_policy\n\nProvides an AWS …",
    "content": "\n\n# Resource: aws_networkfirewall_resource_policy\n\nProvides an AWS Network Firewall Resource Policy Resource for a rule group or firewall policy.\n\n## Example Usage\n\n### For a Firewall Policy resource\n\n```terraform\nresource \"aws_networkfirewall_resource_policy\" \"example\" {\n  resource_arn = aws_networkfirewall_firewall_policy.example.arn\n  # policy's Action element must include all of the following operations\n  policy = jsonencode({\n    Statement = [{\n      Action = [\n        \"network-firewall:ListFirewallPolicies\",\n        \"network-firewall:CreateFirewall\",\n        \"network-firewall:UpdateFirewall\",\n        \"network-firewall:AssociateFirewallPolicy\"\n      ]\n      Effect   = \"Allow\"\n      Resource = aws_networkfirewall_firewall_policy.example.arn\n      Principal = {\n        AWS = \"arn:aws:iam::123456789012:root\"\n      }\n    }]\n    Version = \"2012-10-17\"\n  })\n}\n```\n\n### For a Rule Group resource\n\n```terraform\nresource \"aws_networkfirewall_resource_policy\" \"example\" {\n  resource_arn = aws_networkfirewall_rule_group.example.arn\n  # policy's Action element must include all of the following operations\n  policy = jsonencode({\n    Statement = [{\n      Action = [\n        \"network-firewall:ListRuleGroups\",\n        \"network-firewall:CreateFirewallPolicy\",\n        \"network-firewall:UpdateFirewallPolicy\"\n      ]\n      Effect   = \"Allow\"\n      Resource = aws_networkfirewall_rule_group.example.arn\n      Principal = {\n        AWS = \"arn:aws:iam::123456789012:root\"\n      }\n    }]\n    Version = \"2012-10-17\"\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy` - (Required) JSON formatted policy document that controls access to the Network Firewall resource. The policy must be provided **without whitespaces**.  It is recommended to use [jsonencode](https://www.terraform.io/docs/configuration/functions/jsonencode.html) for formatting as seen in the examples above. For more details, including available policy statement Actions, see the [Policy](https://docs.aws.amazon.com/network-firewall/latest/APIReference/API_PutResourcePolicy.html#API_PutResourcePolicy_RequestSyntax) parameter in the AWS API documentation.\n\n* `resource_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the rule group or firewall policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the rule group or firewall policy associated with the resource policy.\n\n## Import\n\nNetwork Firewall Resource Policies can be imported using the `resource_arn` e.g.,\n\n```\n$ terraform import aws_networkfirewall_resource_policy.example aws_networkfirewall_rule_group.example arn:aws:network-firewall:us-west-1:123456789012:stateful-rulegroup/example\n```\n",
    "basename": "networkfirewall_resource_policy.html"
  },
  "networkfirewall_rule_group.html": {
    "subcategory": "Network Firewall",
    "layout": "aws",
    "page_title": "AWS: aws_networkfirewall_rule_group",
    "description": "Provides an AWS Network Firewall Rule Group resource.",
    "preview": "# Resource: aws_networkfirewall_rule_group\n\nProvides an AWS Network …",
    "content": "\n\n# Resource: aws_networkfirewall_rule_group\n\nProvides an AWS Network Firewall Rule Group Resource\n\n## Example Usage\n\n### Stateful Inspection for denying access to a domain\n\n```terraform\nresource \"aws_networkfirewall_rule_group\" \"example\" {\n  capacity = 100\n  name     = \"example\"\n  type     = \"STATEFUL\"\n  rule_group {\n    rules_source {\n      rules_source_list {\n        generated_rules_type = \"DENYLIST\"\n        target_types         = [\"HTTP_HOST\"]\n        targets              = [\"test.example.com\"]\n      }\n    }\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n### Stateful Inspection for permitting packets from a source IP address\n\n```terraform\nresource \"aws_networkfirewall_rule_group\" \"example\" {\n  capacity    = 50\n  description = \"Permits http traffic from source\"\n  name        = \"example\"\n  type        = \"STATEFUL\"\n  rule_group {\n    rules_source {\n      dynamic \"stateful_rule\" {\n        for_each = local.ips\n        content {\n          action = \"PASS\"\n          header {\n            destination      = \"ANY\"\n            destination_port = \"ANY\"\n            protocol         = \"HTTP\"\n            direction        = \"ANY\"\n            source_port      = \"ANY\"\n            source           = stateful_rule.value\n          }\n          rule_option {\n            keyword = \"sid:1\"\n          }\n        }\n      }\n    }\n  }\n\n  tags = {\n    Name = \"permit HTTP from source\"\n  }\n}\n\nlocals {\n  ips = [\"1.1.1.1/32\", \"1.0.0.1/32\"]\n}\n```\n\n### Stateful Inspection for blocking packets from going to an intended destination\n\n```terraform\nresource \"aws_networkfirewall_rule_group\" \"example\" {\n  capacity = 100\n  name     = \"example\"\n  type     = \"STATEFUL\"\n  rule_group {\n    rules_source {\n      stateful_rule {\n        action = \"DROP\"\n        header {\n          destination      = \"124.1.1.24/32\"\n          destination_port = 53\n          direction        = \"ANY\"\n          protocol         = \"TCP\"\n          source           = \"1.2.3.4/32\"\n          source_port      = 53\n        }\n        rule_option {\n          keyword = \"sid:1\"\n        }\n      }\n    }\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n### Stateful Inspection from rules specifications defined in Suricata flat format\n\n```terraform\nresource \"aws_networkfirewall_rule_group\" \"example\" {\n  capacity = 100\n  name     = \"example\"\n  type     = \"STATEFUL\"\n  rules    = file(\"example.rules\")\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n### Stateful Inspection from rule group specifications using rule variables and Suricata format rules\n\n```terraform\nresource \"aws_networkfirewall_rule_group\" \"example\" {\n  capacity = 100\n  name     = \"example\"\n  type     = \"STATEFUL\"\n  rule_group {\n    rule_variables {\n      ip_sets {\n        key = \"WEBSERVERS_HOSTS\"\n        ip_set {\n          definition = [\"10.0.0.0/16\", \"10.0.1.0/24\", \"192.168.0.0/16\"]\n        }\n      }\n      ip_sets {\n        key = \"EXTERNAL_HOST\"\n        ip_set {\n          definition = [\"1.2.3.4/32\"]\n        }\n      }\n      port_sets {\n        key = \"HTTP_PORTS\"\n        port_set {\n          definition = [\"443\", \"80\"]\n        }\n      }\n    }\n    rules_source {\n      rules_string = file(\"suricata_rules_file\")\n    }\n  }\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n### Stateless Inspection with a Custom Action\n\n```terraform\nresource \"aws_networkfirewall_rule_group\" \"example\" {\n  description = \"Stateless Rate Limiting Rule\"\n  capacity    = 100\n  name        = \"example\"\n  type        = \"STATELESS\"\n  rule_group {\n    rules_source {\n      stateless_rules_and_custom_actions {\n        custom_action {\n          action_definition {\n            publish_metric_action {\n              dimension {\n                value = \"2\"\n              }\n            }\n          }\n          action_name = \"ExampleMetricsAction\"\n        }\n        stateless_rule {\n          priority = 1\n          rule_definition {\n            actions = [\"aws:pass\", \"ExampleMetricsAction\"]\n            match_attributes {\n              source {\n                address_definition = \"1.2.3.4/32\"\n              }\n              source_port {\n                from_port = 443\n                to_port   = 443\n              }\n              destination {\n                address_definition = \"124.1.1.5/32\"\n              }\n              destination_port {\n                from_port = 443\n                to_port   = 443\n              }\n              protocols = [6]\n              tcp_flag {\n                flags = [\"SYN\"]\n                masks = [\"SYN\", \"ACK\"]\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `capacity` - (Required, Forces new resource) The maximum number of operating resources that this rule group can use. For a stateless rule group, the capacity required is the sum of the capacity requirements of the individual rules. For a stateful rule group, the minimum capacity required is the number of individual rules.\n\n* `description` - (Optional) A friendly description of the rule group.\n\n* `name` - (Required, Forces new resource) A friendly name of the rule group.\n\n* `rule_group` - (Optional) A configuration block that defines the rule group rules. Required unless `rules` is specified. See [Rule Group](#rule-group) below for details.\n\n* `rules` - (Optional) The stateful rule group rules specifications in Suricata file format, with one rule per line. Use this to import your existing Suricata compatible rule groups. Required unless `rule_group` is specified.\n\n* `tags` - (Optional) A map of key:value pairs to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n* `type` - (Required) Whether the rule group is stateless (containing stateless rules) or stateful (containing stateful rules). Valid values include: `STATEFUL` or `STATELESS`.\n\n### Rule Group\n\nThe `rule_group` block supports the following argument:\n\n* `rule_variables` - (Optional) A configuration block that defines additional settings available to use in the rules defined in the rule group. Can only be specified for **stateful** rule groups. See [Rule Variables](#rule-variables) below for details.\n\n* `rules_source` - (Required) A configuration block that defines the stateful or stateless rules for the rule group. See [Rules Source](#rules-source) below for details.\n\n* `stateful_rule_options` - (Optional) A configuration block that defines stateful rule options for the rule group. See [Stateful Rule Options](#stateful-rule-options) below for details.\n\n### Rule Variables\n\nThe `rule_variables` block supports the following arguments:\n\n* `ip_sets` - (Optional) Set of configuration blocks that define IP address information. See [IP Sets](#ip-sets) below for details.\n\n* `port_sets` - (Optional) Set of configuration blocks that define port range information. See [Port Sets](#port-sets) below for details.\n\n### IP Sets\n\nThe `ip_sets` block supports the following arguments:\n\n* `key` - (Required) A unique alphanumeric string to identify the `ip_set`.\n\n* `ip_set` - (Required) A configuration block that defines a set of IP addresses. See [IP Set](#ip-set) below for details.\n\n### IP Set\n\nThe `ip_set` configuration block supports the following argument:\n\n* `definition` - (Required) Set of IP addresses and address ranges, in CIDR notation.\n\n### Port Sets\n\nThe `port_sets` block supports the following arguments:\n\n* `key` - (Required) An unique alphanumeric string to identify the `port_set`.\n\n* `port_set` - (Required) A configuration block that defines a set of port ranges. See [Port Set](#port-set) below for details.\n\n### Port Set\n\nThe `port_set` configuration block suppports the following argument:\n\n* `definition` - (Required) Set of port ranges.\n\n### Rules Source\n\nThe `rules_source` block supports the following arguments:\n\n~> **NOTE:** Only one of `rules_source_list`, `rules_string`, `stateful_rule`, or `stateless_rules_and_custom_actions` must be specified.\n\n* `rules_source_list` - (Optional) A configuration block containing **stateful** inspection criteria for a domain list rule group. See [Rules Source List](#rules-source-list) below for details.\n\n* `rules_string` - (Optional) The fully qualified name of a file in an S3 bucket that contains Suricata compatible intrusion preventions system (IPS) rules or the Suricata rules as a string. These rules contain **stateful** inspection criteria and the action to take for traffic that matches the criteria.\n\n* `stateful_rule` - (Optional) Set of configuration blocks containing **stateful** inspection criteria for 5-tuple rules to be used together in a rule group. See [Stateful Rule](#stateful-rule) below for details.\n\n* `stateless_rules_and_custom_actions` - (Optional) A configuration block containing **stateless** inspection criteria for a stateless rule group. See [Stateless Rules and Custom Actions](#stateless-rules-and-custom-actions) below for details.\n\n### Stateful Rule Options\n\nThe `stateful_rule_options` block supports the following argument:\n\n~> **NOTE:** If the `STRICT_ORDER` rule order is specified, this rule group can only be referenced in firewall policies that also utilize `STRICT_ORDER` for the stateful engine. `STRICT_ORDER` can only be specified when using a `rules_source` of `rules_string` or `stateful_rule`.\n\n* `rule_order` - (Required) Indicates how to manage the order of the rule evaluation for the rule group. Default value: `DEFAULT_ACTION_ORDER`. Valid values: `DEFAULT_ACTION_ORDER`, `STRICT_ORDER`.\n\n### Rules Source List\n\nThe `rules_source_list` block supports the following arguments:\n\n* `generated_rules_type` - (Required) String value to specify whether domains in the target list are allowed or denied access. Valid values: `ALLOWLIST`, `DENYLIST`.\n\n* `target_types` - (Required) Set of types of domain specifications that are provided in the `targets` argument. Valid values: `HTTP_HOST`, `TLS_SNI`.\n\n* `targets` - (Required) Set of domains that you want to inspect for in your traffic flows.\n\n### Stateful Rule\n\nThe `stateful_rule` block supports the following arguments:\n\n* `action` - (Required) Action to take with packets in a traffic flow when the flow matches the stateful rule criteria. For all actions, AWS Network Firewall performs the specified action and discontinues stateful inspection of the traffic flow. Valid values: `ALERT`, `DROP` or `PASS`.\n\n* `header` - (Required) A configuration block containing the stateful 5-tuple inspection criteria for the rule, used to inspect traffic flows. See [Header](#header) below for details.\n\n* `rule_option` - (Required) Set of configuration blocks containing additional settings for a stateful rule. See [Rule Option](#rule-option) below for details.\n\n### Stateless Rules and Custom Actions\n\nThe `stateless_rules_and_custom_actions` block supports the following arguments:\n\n* `custom_action` - (Optional) Set of configuration blocks containing custom action definitions that are available for use by the set of `stateless rule`. See [Custom Action](#custom-action) below for details.\n\n* `stateless_rule` - (Required) Set of configuration blocks containing the stateless rules for use in the stateless rule group. See [Stateless Rule](#stateless-rule) below for details.\n\n### Header\n\nThe `header` block supports the following arguments:\n\n* `destination` - (Required) The destination IP address or address range to inspect for, in CIDR notation. To match with any address, specify `ANY`.\n\n* `destination_port` - (Required) The destination port to inspect for. To match with any address, specify `ANY`.\n\n* `direction` - (Required) The direction of traffic flow to inspect. Valid values: `ANY` or `FORWARD`.\n\n* `protocol` - (Required) The protocol to inspect. Valid values: `IP`, `TCP`, `UDP`, `ICMP`, `HTTP`, `FTP`, `TLS`, `SMB`, `DNS`, `DCERPC`, `SSH`, `SMTP`, `IMAP`, `MSN`, `KRB5`, `IKEV2`, `TFTP`, `NTP`, `DHCP`.\n\n* `source` - (Required) The source IP address or address range for, in CIDR notation. To match with any address, specify `ANY`.\n\n* `source_port` - (Required) The source port to inspect for. To match with any address, specify `ANY`.\n\n### Rule Option\n\nThe `rule_option` block supports the following arguments:\n\n* `keyword` - (Required) Keyword defined by open source detection systems like Snort or Suricata for stateful rule inspection.\nSee [Snort General Rule Options](http://manual-snort-org.s3-website-us-east-1.amazonaws.com/node31.html) or [Suricata Rule Options](https://suricata.readthedocs.io/en/suricata-5.0.1/rules/intro.html#rule-options) for more details.\n\n* `settings` - (Optional) Set of strings for additional settings to use in stateful rule inspection.\n\n### Custom Action\n\nThe `custom_action` block supports the following arguments:\n\n* `action_definition` - (Required) A configuration block describing the custom action associated with the `action_name`. See [Action Definition](#action-definition) below for details.\n\n* `action_name` - (Required, Forces new resource) A friendly name of the custom action.\n\n### Stateless Rule\n\nThe `stateless_rule` block supports the following arguments:\n\n* `priority` - (Required) A setting that indicates the order in which to run this rule relative to all of the rules that are defined for a stateless rule group. AWS Network Firewall evaluates the rules in a rule group starting with the lowest priority setting.\n\n* `rule_definition` - (Required) A configuration block defining the stateless 5-tuple packet inspection criteria and the action to take on a packet that matches the criteria. See [Rule Definition](#rule-definition) below for details.\n\n### Rule Definition\n\nThe `rule_definition` block supports the following arguments:\n\n* `actions` - (Required) Set of actions to take on a packet that matches one of the stateless rule definition's `match_attributes`. For every rule you must specify 1 standard action, and you can add custom actions. Standard actions include: `aws:pass`, `aws:drop`, `aws:forward_to_sfe`.\n\n* `match_attributes` - (Required) A configuration block containing criteria for AWS Network Firewall to use to inspect an individual packet in stateless rule inspection. See [Match Attributes](#match-attributes) below for details.\n\n### Match Attributes\n\nThe `match_attributes` block supports the following arguments:\n\n* `destination` - (Optional) Set of configuration blocks describing the destination IP address and address ranges to inspect for, in CIDR notation. If not specified, this matches with any destination address. See [Destination](#destination) below for details.\n\n* `destination_port` - (Optional) Set of configuration blocks describing the destination ports to inspect for. If not specified, this matches with any destination port. See [Destination Port](#destination-port) below for details.\n\n* `protocols` - (Optional) Set of protocols to inspect for, specified using the protocol's assigned internet protocol number (IANA). If not specified, this matches with any protocol.\n\n* `source` - (Optional) Set of configuration blocks describing the source IP address and address ranges to inspect for, in CIDR notation. If not specified, this matches with any source address. See [Source](#source) below for details.\n\n* `source_port` - (Optional) Set of configuration blocks describing the source ports to inspect for. If not specified, this matches with any source port. See [Source Port](#source-port) below for details.\n\n* `tcp_flag` - (Optional) Set of configuration blocks containing the TCP flags and masks to inspect for. If not specified, this matches with any settings.\n\n### Action Definition\n\nThe `action_definition` block supports the following argument:\n\n* `publish_metric_action` - (Required) A configuration block describing the stateless inspection criteria that publishes the specified metrics to Amazon CloudWatch for the matching packet. You can pair this custom action with any of the standard stateless rule actions. See [Publish Metric Action](#publish-metric-action) below for details.\n\n### Publish Metric Action\n\nThe `publish_metric_action` block supports the following argument:\n\n* `dimension` - (Required) Set of configuration blocks containing the dimension settings to use for Amazon CloudWatch custom metrics. See [Dimension](#dimension) below for details.\n\n### Dimension\n\nThe `dimension` block supports the following argument:\n\n* `value` - (Required) The value to use in the custom metric dimension.\n\n### Destination\n\nThe `destination` block supports the following argument:\n\n* `address_definition` - (Required)  An IP address or a block of IP addresses in CIDR notation. AWS Network Firewall supports all address ranges for IPv4.\n\n### Destination Port\n\nThe `destination_port` block supports the following arguments:\n\n* `from_port` - (Required) The lower limit of the port range. This must be less than or equal to the `to_port`.\n\n* `to_port` - (Optional) The upper limit of the port range. This must be greater than or equal to the `from_port`.\n\n### Source\n\nThe `source` block supports the following argument:\n\n* `address_definition` - (Required)  An IP address or a block of IP addresses in CIDR notation. AWS Network Firewall supports all address ranges for IPv4.\n\n### Source Port\n\nThe `source_port` block supports the following arguments:\n\n* `from_port` - (Required) The lower limit of the port range. This must be less than or equal to the `to_port`.\n\n* `to_port` - (Optional) The upper limit of the port range. This must be greater than or equal to the `from_port`.\n\n### TCP Flag\n\nThe `tcp_flag` block supports the following arguments:\n\n* `flags` - (Required) Set of flags to look for in a packet. This setting can only specify values that are also specified in `masks`.\nValid values: `FIN`, `SYN`, `RST`, `PSH`, `ACK`, `URG`, `ECE`, `CWR`.\n\n* `masks` - (Optional) Set of flags to consider in the inspection. To inspect all flags, leave this empty.\nValid values: `FIN`, `SYN`, `RST`, `PSH`, `ACK`, `URG`, `ECE`, `CWR`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) that identifies the rule group.\n\n* `arn` - The Amazon Resource Name (ARN) that identifies the rule group.\n\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n* `update_token` - A string token used when updating the rule group.\n\n## Import\n\nNetwork Firewall Rule Groups can be imported using their `ARN`.\n\n```\n$ terraform import aws_networkfirewall_rule_group.example arn:aws:network-firewall:us-west-1:123456789012:stateful-rulegroup/example\n```\n",
    "basename": "networkfirewall_rule_group.html"
  },
  "opsworks_application.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_application",
    "description": "Provides an OpsWorks application resource.",
    "preview": "# Resource: aws_opsworks_application\n\nProvides an OpsWorks …",
    "content": "\n\n# Resource: aws_opsworks_application\n\nProvides an OpsWorks application resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_application\" \"foo-app\" {\n  name        = \"foobar application\"\n  short_name  = \"foobar\"\n  stack_id    = aws_opsworks_stack.main.id\n  type        = \"rails\"\n  description = \"This is a Rails application\"\n\n  domains = [\n    \"example.com\",\n    \"sub.example.com\",\n  ]\n\n  environment {\n    key    = \"key\"\n    value  = \"value\"\n    secure = false\n  }\n\n  app_source {\n    type     = \"git\"\n    revision = \"master\"\n    url      = \"https://github.com/example.git\"\n  }\n\n  enable_ssl = true\n\n  ssl_configuration {\n    private_key = file(\"./foobar.key\")\n    certificate = file(\"./foobar.crt\")\n  }\n\n  document_root         = \"public\"\n  auto_bundle_on_deploy = true\n  rails_env             = \"staging\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A human-readable name for the application.\n* `short_name` - (Required) A short, machine-readable name for the application. This can only be defined on resource creation and ignored on resource update.\n* `stack_id` - (Required) The id of the stack the application will belong to.\n* `type` - (Required) Opsworks application type. One of `aws-flow-ruby`, `java`, `rails`, `php`, `nodejs`, `static` or `other`.\n* `description` - (Optional) A description of the app.\n* `environment` - (Optional) Object to define environment variables.  Object is described below.\n* `enable_ssl` - (Optional) Whether to enable SSL for the app. This must be set in order to let `ssl_configuration.private_key`, `ssl_configuration.certificate` and `ssl_configuration.chain` take effect.\n* `ssl_configuration` - (Optional) The SSL configuration of the app. Object is described below.\n* `app_source` - (Optional) SCM configuration of the app as described below.\n* `data_source_arn` - (Optional) The data source's ARN.\n* `data_source_type` - (Optional) The data source's type one of `AutoSelectOpsworksMysqlInstance`, `OpsworksMysqlInstance`, or `RdsDbInstance`.\n* `data_source_database_name` - (Optional) The database name.\n* `domains` -  (Optional) A list of virtual host alias.\n* `document_root` - (Optional) Subfolder for the document root for application of type `rails`.\n* `auto_bundle_on_deploy` - (Optional) Run bundle install when deploying for application of type `rails`.\n* `rails_env` - (Required if `type` = `rails`) The name of the Rails environment for application of type `rails`.\n* `aws_flow_ruby_settings` - (Optional) Specify activity and workflow workers for your app using the aws-flow gem.\n\nAn `app_source` block supports the following arguments (can only be defined once per resource):\n\n* `type` - (Required) The type of source to use. For example, \"archive\".\n* `url` - (Required) The URL where the app resource can be found.\n* `username` - (Optional) Username to use when authenticating to the source.\n* `password` - (Optional) Password to use when authenticating to the source. Terraform cannot perform drift detection of this configuration.\n* `ssh_key` - (Optional) SSH key to use when authenticating to the source. Terraform cannot perform drift detection of this configuration.\n* `revision` - (Optional) For sources that are version-aware, the revision to use.\n\nAn `environment` block supports the following arguments:\n\n* `key` - (Required) Variable name.\n* `value` - (Required) Variable value.\n* `secure` - (Optional) Set visibility of the variable value to `true` or `false`.\n\nA `ssl_configuration` block supports the following arguments (can only be defined once per resource):\n\n* `private_key` - (Required) The private key; the contents of the certificate's domain.key file.\n* `certificate` - (Required) The contents of the certificate's domain.crt file.\n* `chain` - (Optional)  Can be used to specify an intermediate certificate authority key or client authentication.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the application.\n\n## Import\n\nOpsworks Application can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_opsworks_application.test <id>\n```\n",
    "basename": "opsworks_application.html"
  },
  "opsworks_custom_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_custom_layer",
    "description": "Provides an OpsWorks custom layer resource.",
    "preview": "# Resource: aws_opsworks_custom_layer\n\nProvides an OpsWorks custom …",
    "content": "\n\n# Resource: aws_opsworks_custom_layer\n\nProvides an OpsWorks custom layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_custom_layer\" \"custlayer\" {\n  name       = \"My Awesome Custom Layer\"\n  short_name = \"awesome\"\n  stack_id   = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A human-readable name for the layer.\n* `short_name` - (Required) A short, machine-readable name for the layer, which will be used to identify it in the Chef node JSON.\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n* `encrypted` - (Optional) Encrypt the volume.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nOpsWorks Custom Layers can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_opsworks_custom_layer.bar 00000000-0000-0000-0000-000000000000\n```\n",
    "basename": "opsworks_custom_layer.html"
  },
  "opsworks_ganglia_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_ganglia_layer",
    "description": "Provides an OpsWorks Ganglia layer resource.",
    "preview": "# Resource: aws_opsworks_ganglia_layer\n\nProvides an OpsWorks Ganglia …",
    "content": "\n\n# Resource: aws_opsworks_ganglia_layer\n\nProvides an OpsWorks Ganglia layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_ganglia_layer\" \"monitor\" {\n  stack_id = aws_opsworks_stack.main.id\n  password = \"foobarbaz\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `password` - (Required) The password to use for Ganglia.\n* `name` - (Optional) A human-readable name for the layer.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `url` - (Optional) The URL path to use for Ganglia. Defaults to \"/ganglia\".\n* `username` - (Optiona) The username to use for Ganglia. Defaults to \"opsworks\".\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "opsworks_ganglia_layer.html"
  },
  "opsworks_haproxy_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_haproxy_layer",
    "description": "Provides an OpsWorks HAProxy layer resource.",
    "preview": "# Resource: aws_opsworks_haproxy_layer\n\nProvides an OpsWorks haproxy …",
    "content": "\n\n# Resource: aws_opsworks_haproxy_layer\n\nProvides an OpsWorks haproxy layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_haproxy_layer\" \"lb\" {\n  stack_id       = aws_opsworks_stack.main.id\n  stats_password = \"foobarbaz\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `stats_password` - (Required) The password to use for HAProxy stats.\n* `name` - (Optional) A human-readable name for the layer.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `healthcheck_method` - (Optional) HTTP method to use for instance healthchecks. Defaults to \"OPTIONS\".\n* `healthcheck_url` - (Optional) URL path to use for instance healthchecks. Defaults to \"/\".\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `stats_enabled` - (Optional) Whether to enable HAProxy stats.\n* `stats_url` - (Optional) The HAProxy stats URL. Defaults to \"/haproxy?stats\".\n* `stats_user` - (Optional) The username for HAProxy stats. Defaults to \"opsworks\".\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "opsworks_haproxy_layer.html"
  },
  "opsworks_instance.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_instance",
    "description": "Provides an OpsWorks instance resource.",
    "preview": "# Resource: aws_opsworks_instance\n\nProvides an OpsWorks instance …",
    "content": "\n\n# Resource: aws_opsworks_instance\n\nProvides an OpsWorks instance resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_instance\" \"my-instance\" {\n  stack_id = aws_opsworks_stack.main.id\n\n  layer_ids = [\n    aws_opsworks_custom_layer.my-layer.id,\n  ]\n\n  instance_type = \"t2.micro\"\n  os            = \"Amazon Linux 2015.09\"\n  state         = \"stopped\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `instance_type` - (Required) The type of instance to start\n* `stack_id` - (Required) The id of the stack the instance will belong to.\n* `layer_ids` - (Required) The ids of the layers the instance will belong to.\n* `state` - (Optional) The desired state of the instance.  Can be either `\"running\"` or `\"stopped\"`.\n* `install_updates_on_boot` - (Optional) Controls where to install OS and package updates when the instance boots.  Defaults to `true`.\n* `auto_scaling_type` - (Optional) Creates load-based or time-based instances.  If set, can be either: `\"load\"` or `\"timer\"`.\n* `availability_zone` - (Optional) Name of the availability zone where instances will be created\n  by default.\n* `ebs_optimized` - (Optional) If true, the launched EC2 instance will be EBS-optimized.\n* `hostname` - (Optional) The instance's host name.\n* `architecture` - (Optional) Machine architecture for created instances.  Can be either `\"x86_64\"` (the default) or `\"i386\"`\n* `ami_id` - (Optional) The AMI to use for the instance.  If an AMI is specified, `os` must be `\"Custom\"`.\n* `os` - (Optional) Name of operating system that will be installed.\n* `root_device_type` - (Optional) Name of the type of root device instances will have by default.  Can be either `\"ebs\"` or `\"instance-store\"`\n* `ssh_key_name` - (Optional) Name of the SSH keypair that instances will have by default.\n* `agent_version` - (Optional) The AWS OpsWorks agent to install.  Defaults to `\"INHERIT\"`.\n* `subnet_id` - (Optional) Subnet ID to attach to\n* `tenancy` - (Optional) Instance tenancy to use. Can be one of `\"default\"`, `\"dedicated\"` or `\"host\"`\n* `virtualization_type` - (Optional) Keyword to choose what virtualization mode created instances\n  will use. Can be either `\"paravirtual\"` or `\"hvm\"`.\n* `root_block_device` - (Optional) Customize details about the root block\n  device of the instance. See [Block Devices](#block-devices) below for details.\n* `ebs_block_device` - (Optional) Additional EBS block devices to attach to the\n  instance.  See [Block Devices](#block-devices) below for details.\n* `ephemeral_block_device` - (Optional) Customize Ephemeral (also known as\n  \"Instance Store\") volumes on the instance. See [Block Devices](#block-devices) below for details.\n\n\n## Block devices\n\nEach of the `*_block_device` attributes controls a portion of the AWS\nInstance's \"Block Device Mapping\". It's a good idea to familiarize yourself with [AWS's Block Device\nMapping docs](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html)\nto understand the implications of using these attributes.\n\nThe `root_block_device` mapping supports the following:\n\n* `volume_type` - (Optional) The type of volume. Can be `\"standard\"`, `\"gp2\"`,\n  or `\"io1\"`. (Default: `\"standard\"`).\n* `volume_size` - (Optional) The size of the volume in gigabytes.\n* `iops` - (Optional) The amount of provisioned\n  [IOPS](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html).\n  This must be set with a `volume_type` of `\"io1\"`.\n* `delete_on_termination` - (Optional) Whether the volume should be destroyed\n  on instance termination (Default: `true`).\n\nModifying any of the `root_block_device` settings requires resource\nreplacement.\n\nEach `ebs_block_device` supports the following:\n\n* `device_name` - The name of the device to mount.\n* `snapshot_id` - (Optional) The Snapshot ID to mount.\n* `volume_type` - (Optional) The type of volume. Can be `\"standard\"`, `\"gp2\"`,\n  or `\"io1\"`. (Default: `\"standard\"`).\n* `volume_size` - (Optional) The size of the volume in gigabytes.\n* `iops` - (Optional) The amount of provisioned\n  [IOPS](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html).\n  This must be set with a `volume_type` of `\"io1\"`.\n* `delete_on_termination` - (Optional) Whether the volume should be destroyed\n  on instance termination (Default: `true`).\n\nModifying any `ebs_block_device` currently requires resource replacement.\n\nEach `ephemeral_block_device` supports the following:\n\n* `device_name` - The name of the block device to mount on the instance.\n* `virtual_name` - The [Instance Store Device\n  Name](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#InstanceStoreDeviceNames)\n  (e.g., `\"ephemeral0\"`)\n\nEach AWS Instance type has a different set of Instance Store block devices\navailable for attachment. AWS [publishes a\nlist](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#StorageOnInstanceTypes)\nof which ephemeral devices are available on each type. The devices are always\nidentified by the `virtual_name` in the format `\"ephemeral{0..N}\"`.\n\n~> **NOTE:** Currently, changes to `*_block_device` configuration of _existing_\nresources cannot be automatically detected by Terraform. After making updates\nto block device configuration, resource recreation can be manually triggered by\nusing the [`taint` command](https://www.terraform.io/docs/commands/taint.html).\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the OpsWorks instance.\n* `agent_version` - The AWS OpsWorks agent version.\n* `availability_zone` - The availability zone of the instance.\n* `ec2_instance_id` - EC2 instance ID\n* `ssh_key_name` - The key name of the instance\n* `public_dns` - The public DNS name assigned to the instance. For EC2-VPC, this\n  is only available if you've enabled DNS hostnames for your VPC\n* `public_ip` - The public IP address assigned to the instance, if applicable.\n* `private_dns` - The private DNS name assigned to the instance. Can only be\n  used inside the Amazon EC2, and only available if you've enabled DNS hostnames\n  for your VPC\n* `private_ip` - The private IP address assigned to the instance\n* `subnet_id` - The VPC subnet ID.\n* `tenancy` - The Instance tenancy\n* `security_group_ids` - The associated security groups.\n\n## Timeouts\n\n`aws_opsworks_instance` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used when the instance is created. It should cover the time needed for the instance to start successfully.\n- `delete` - (Default `10 minutes`) Used when the instance is deleted. It should cover the time needed for the instance to stop successfully.\n- `update` - (Default `10 minutes`) Used when the instance is changed. It should cover the time needed to either start or stop the instance.\n\n## Import\n\nOpsworks Instances can be imported using the `instance id`, e.g.,\n\n```\n$ terraform import aws_opsworks_instance.my_instance 4d6d1710-ded9-42a1-b08e-b043ad7af1e2\n```\n\n",
    "basename": "opsworks_instance.html"
  },
  "opsworks_java_app_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_java_app_layer",
    "description": "Provides an OpsWorks Java application layer resource.",
    "preview": "# Resource: aws_opsworks_java_app_layer\n\nProvides an OpsWorks Java …",
    "content": "\n\n# Resource: aws_opsworks_java_app_layer\n\nProvides an OpsWorks Java application layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_java_app_layer\" \"app\" {\n  stack_id = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `name` - (Optional) A human-readable name for the layer.\n* `app_server` - (Optional) Keyword for the application container to use. Defaults to \"tomcat\".\n* `app_server_version` - (Optional) Version of the selected application container to use. Defaults to \"7\".\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `jvm_type` - (Optional) Keyword for the type of JVM to use. Defaults to `openjdk`.\n* `jvm_options` - (Optional) Options to set for the JVM.\n* `jvm_version` - (Optional) Version of JVM to use. Defaults to \"7\".\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "opsworks_java_app_layer.html"
  },
  "opsworks_memcached_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_memcached_layer",
    "description": "Provides an OpsWorks memcached layer resource.",
    "preview": "# Resource: aws_opsworks_memcached_layer\n\nProvides an OpsWorks …",
    "content": "\n\n# Resource: aws_opsworks_memcached_layer\n\nProvides an OpsWorks memcached layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_memcached_layer\" \"cache\" {\n  stack_id = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `name` - (Optional) A human-readable name for the layer.\n* `allocated_memory` - (Optional) Amount of memory to allocate for the cache on each instance, in megabytes. Defaults to 512MB.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "opsworks_memcached_layer.html"
  },
  "opsworks_mysql_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_mysql_layer",
    "description": "Provides an OpsWorks MySQL layer resource.",
    "preview": "# Resource: aws_opsworks_mysql_layer\n\nProvides an OpsWorks MySQL …",
    "content": "\n\n# Resource: aws_opsworks_mysql_layer\n\nProvides an OpsWorks MySQL layer resource.\n\n~> **Note:** All arguments including the root password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_mysql_layer\" \"db\" {\n  stack_id = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `name` - (Optional) A human-readable name for the layer.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `root_password` - (Optional) Root password to use for MySQL.\n* `root_password_on_all_instances` - (Optional) Whether to set the root user password to all instances in the stack so they can access the instances in this layer.\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "opsworks_mysql_layer.html"
  },
  "opsworks_nodejs_app_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_nodejs_app_layer",
    "description": "Provides an OpsWorks NodeJS application layer resource.",
    "preview": "# Resource: aws_opsworks_nodejs_app_layer\n\nProvides an OpsWorks …",
    "content": "\n\n# Resource: aws_opsworks_nodejs_app_layer\n\nProvides an OpsWorks NodeJS application layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_nodejs_app_layer\" \"app\" {\n  stack_id = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `name` - (Optional) A human-readable name for the layer.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `nodejs_version` - (Optional) The version of NodeJS to use. Defaults to \"0.10.38\".\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "opsworks_nodejs_app_layer.html"
  },
  "opsworks_permission.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_permission",
    "description": "Provides an OpsWorks permission resource.",
    "preview": "# Resource: aws_opsworks_permission\n\nProvides an OpsWorks permission …",
    "content": "\n\n# Resource: aws_opsworks_permission\n\nProvides an OpsWorks permission resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_permission\" \"my_stack_permission\" {\n  allow_ssh  = true\n  allow_sudo = true\n  level      = \"iam_only\"\n  user_arn   = aws_iam_user.user.arn\n  stack_id   = aws_opsworks_stack.stack.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `allow_ssh` - (Optional) Whether the user is allowed to use SSH to communicate with the instance\n* `allow_sudo` - (Optional) Whether the user is allowed to use sudo to elevate privileges\n* `user_arn` - (Required) The user's IAM ARN to set permissions for\n* `level` - (Optional) The users permission level. Mus be one of `deny`, `show`, `deploy`, `manage`, `iam_only`\n* `stack_id` - (Required) The stack to set the permissions for\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The computed id of the permission. Please note that this is only used internally to identify the permission. This value is not used in aws.\n",
    "basename": "opsworks_permission.html"
  },
  "opsworks_php_app_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_php_app_layer",
    "description": "Provides an OpsWorks PHP application layer resource.",
    "preview": "# Resource: aws_opsworks_php_app_layer\n\nProvides an OpsWorks PHP …",
    "content": "\n\n# Resource: aws_opsworks_php_app_layer\n\nProvides an OpsWorks PHP application layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_php_app_layer\" \"app\" {\n  stack_id = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `name` - (Optional) A human-readable name for the layer.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nOpsWorks PHP Application Layers can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_opsworks_php_app_layer.bar 00000000-0000-0000-0000-000000000000\n```\n",
    "basename": "opsworks_php_app_layer.html"
  },
  "opsworks_rails_app_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_rails_app_layer",
    "description": "Provides an OpsWorks Ruby on Rails application layer resource.",
    "preview": "# Resource: aws_opsworks_rails_app_layer\n\nProvides an OpsWorks Ruby …",
    "content": "\n\n# Resource: aws_opsworks_rails_app_layer\n\nProvides an OpsWorks Ruby on Rails application layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_rails_app_layer\" \"app\" {\n  stack_id = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `name` - (Optional) A human-readable name for the layer.\n* `app_server` - (Optional) Keyword for the app server to use. Defaults to \"apache_passenger\".\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `bundler_version` - (Optional) When OpsWorks is managing Bundler, which version to use. Defaults to \"1.5.3\".\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `manage_bundler` - (Optional) Whether OpsWorks should manage bundler. On by default.\n* `passenger_version` - (Optional) The version of Passenger to use. Defaults to \"4.0.46\".\n* `ruby_version` - (Optional) The version of Ruby to use. Defaults to \"2.0.0\".\n* `rubygems_version` - (Optional) The version of RubyGems to use. Defaults to \"2.2.2\".\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the layer.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "opsworks_rails_app_layer.html"
  },
  "opsworks_rds_db_instance.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_rds_db_instance",
    "description": "Provides an OpsWorks RDS DB Instance resource.",
    "preview": "# Resource: aws_opsworks_rds_db_instance\n\nProvides an OpsWorks RDS …",
    "content": "\n\n# Resource: aws_opsworks_rds_db_instance\n\nProvides an OpsWorks RDS DB Instance resource.\n\n~> **Note:** All arguments including the username and password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_rds_db_instance\" \"my_instance\" {\n  stack_id            = aws_opsworks_stack.my_stack.id\n  rds_db_instance_arn = aws_db_instance.my_instance.arn\n  db_user             = \"someUser\"\n  db_password         = \"somePass\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The stack to register a db instance for. Changing this will force a new resource.\n* `rds_db_instance_arn` - (Required) The db instance to register for this stack. Changing this will force a new resource.\n* `db_user` - (Required) A db username\n* `db_password` - (Required) A db password\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The computed id. Please note that this is only used internally to identify the stack <-> instance relation. This value is not used in aws.\n",
    "basename": "opsworks_rds_db_instance.html"
  },
  "opsworks_stack.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_stack",
    "description": "Provides an OpsWorks stack resource.",
    "preview": "# Resource: aws_opsworks_stack\n\nProvides an OpsWorks stack resource. …",
    "content": "\n\n# Resource: aws_opsworks_stack\n\nProvides an OpsWorks stack resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_stack\" \"main\" {\n  name                         = \"awesome-stack\"\n  region                       = \"us-west-1\"\n  service_role_arn             = aws_iam_role.opsworks.arn\n  default_instance_profile_arn = aws_iam_instance_profile.opsworks.arn\n\n  tags = {\n    Name = \"foobar-terraform-stack\"\n  }\n\n  custom_json = <<EOT\n{\n \"foobar\": {\n    \"version\": \"1.0.0\"\n  }\n}\nEOT\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the stack.\n* `region` - (Required) The name of the region where the stack will exist.\n* `service_role_arn` - (Required) The ARN of an IAM role that the OpsWorks service will act as.\n* `default_instance_profile_arn` - (Required) The ARN of an IAM Instance Profile that created instances\n  will have by default.\n* `agent_version` - (Optional) If set to `\"LATEST\"`, OpsWorks will automatically install the latest version.\n* `berkshelf_version` - (Optional) If `manage_berkshelf` is enabled, the version of Berkshelf to use.\n* `color` - (Optional) Color to paint next to the stack's resources in the OpsWorks console.\n* `default_availability_zone` - (Optional) Name of the availability zone where instances will be created\n  by default. This is required unless you set `vpc_id`.\n* `configuration_manager_name` - (Optional) Name of the configuration manager to use. Defaults to \"Chef\".\n* `configuration_manager_version` - (Optional) Version of the configuration manager to use. Defaults to \"11.4\".\n* `custom_cookbooks_source` - (Optional) When `use_custom_cookbooks` is set, provide this sub-object as\n  described below.\n* `custom_json` - (Optional) User defined JSON passed to \"Chef\". Use a \"here doc\" for multiline JSON.\n* `default_os` - (Optional) Name of OS that will be installed on instances by default.\n* `default_root_device_type` - (Optional) Name of the type of root device instances will have by default.\n* `default_ssh_key_name` - (Optional) Name of the SSH keypair that instances will have by default.\n* `default_subnet_id` - (Optional) Id of the subnet in which instances will be created by default. Mandatory\n  if `vpc_id` is set, and forbidden if it isn't.\n* `hostname_theme` - (Optional) Keyword representing the naming scheme that will be used for instance hostnames\n  within this stack.\n* `manage_berkshelf` - (Optional) Boolean value controlling whether Opsworks will run Berkshelf for this stack.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `use_custom_cookbooks` - (Optional) Boolean value controlling whether the custom cookbook settings are\n  enabled.\n* `use_opsworks_security_groups` - (Optional) Boolean value controlling whether the standard OpsWorks\n  security groups apply to created instances.\n* `vpc_id` - (Optional) The id of the VPC that this stack belongs to.\n* `custom_json` - (Optional) Custom JSON attributes to apply to the entire stack.\n\nThe `custom_cookbooks_source` block supports the following arguments:\n\n* `type` - (Required) The type of source to use. For example, \"archive\".\n* `url` - (Required) The URL where the cookbooks resource can be found.\n* `username` - (Optional) Username to use when authenticating to the source.\n* `password` - (Optional) Password to use when authenticating to the source. Terraform cannot perform drift detection of this configuration.\n* `ssh_key` - (Optional) SSH key to use when authenticating to the source. Terraform cannot perform drift detection of this configuration.\n* `revision` - (Optional) For sources that are version-aware, the revision to use.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the stack.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nOpsWorks stacks can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_opsworks_stack.bar 00000000-0000-0000-0000-000000000000\n```\n",
    "basename": "opsworks_stack.html"
  },
  "opsworks_static_web_layer.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_static_web_layer",
    "description": "Provides an OpsWorks static web server layer resource.",
    "preview": "# Resource: aws_opsworks_static_web_layer\n\nProvides an OpsWorks …",
    "content": "\n\n# Resource: aws_opsworks_static_web_layer\n\nProvides an OpsWorks static web server layer resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_static_web_layer\" \"web\" {\n  stack_id = aws_opsworks_stack.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `stack_id` - (Required) The id of the stack the layer will belong to.\n* `name` - (Optional) A human-readable name for the layer.\n* `auto_assign_elastic_ips` - (Optional) Whether to automatically assign an elastic IP address to the layer's instances.\n* `auto_assign_public_ips` - (Optional) For stacks belonging to a VPC, whether to automatically assign a public IP address to each of the layer's instances.\n* `custom_instance_profile_arn` - (Optional) The ARN of an IAM profile that will be used for the layer's instances.\n* `custom_security_group_ids` - (Optional) Ids for a set of security groups to apply to the layer's instances.\n* `auto_healing` - (Optional) Whether to enable auto-healing for the layer.\n* `install_updates_on_boot` - (Optional) Whether to install OS and package updates on each instance when it boots.\n* `instance_shutdown_timeout` - (Optional) The time, in seconds, that OpsWorks will wait for Chef to complete after triggering the Shutdown event.\n* `elastic_load_balancer` - (Optional) Name of an Elastic Load Balancer to attach to this layer\n* `drain_elb_on_shutdown` - (Optional) Whether to enable Elastic Load Balancing connection draining.\n* `system_packages` - (Optional) Names of a set of system packages to install on the layer's instances.\n* `use_ebs_optimized_instances` - (Optional) Whether to use EBS-optimized instances.\n* `ebs_volume` - (Optional) `ebs_volume` blocks, as described below, will each create an EBS volume and connect it to the layer's instances.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe following extra optional arguments, all lists of Chef recipe names, allow\ncustom Chef recipes to be applied to layer instances at the five different\nlifecycle events, if custom cookbooks are enabled on the layer's stack:\n\n* `custom_configure_recipes`\n* `custom_deploy_recipes`\n* `custom_setup_recipes`\n* `custom_shutdown_recipes`\n* `custom_undeploy_recipes`\n\nAn `ebs_volume` block supports the following arguments:\n\n* `mount_point` - (Required) The path to mount the EBS volume on the layer's instances.\n* `size` - (Required) The size of the volume in gigabytes.\n* `number_of_disks` - (Required) The number of disks to use for the EBS volume.\n* `raid_level` - (Required) The RAID level to use for the volume.\n* `type` - (Optional) The type of volume to create. This may be `standard` (the default), `io1` or `gp2`.\n* `iops` - (Optional) For PIOPS volumes, the IOPS per disk.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The id of the layer.\n* `arn` - The Amazon Resource Name(ARN) of the layer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nOpsWorks static web server Layers can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_opsworks_static_web_layer.bar 00000000-0000-0000-0000-000000000000\n```\n",
    "basename": "opsworks_static_web_layer.html"
  },
  "opsworks_user_profile.html": {
    "subcategory": "OpsWorks",
    "layout": "aws",
    "page_title": "AWS: aws_opsworks_user_profile",
    "description": "Provides an OpsWorks User Profile resource.",
    "preview": "# Resource: aws_opsworks_user_profile\n\nProvides an OpsWorks User …",
    "content": "\n\n# Resource: aws_opsworks_user_profile\n\nProvides an OpsWorks User Profile resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_opsworks_user_profile\" \"my_profile\" {\n  user_arn     = aws_iam_user.user.arn\n  ssh_username = \"my_user\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `user_arn` - (Required) The user's IAM ARN\n* `allow_self_management` - (Optional) Whether users can specify their own SSH public key through the My Settings page\n* `ssh_username` - (Required) The ssh username, with witch this user wants to log in\n* `ssh_public_key` - (Optional) The users public key\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Same value as `user_arn`\n",
    "basename": "opsworks_user_profile.html"
  },
  "organizations_account.html": {
    "subcategory": "Organizations",
    "layout": "aws",
    "page_title": "AWS: aws_organizations_account",
    "description": "Provides a resource to create a member account in the current AWS Organization.",
    "preview": "# Resource: aws_organizations_account\n\nProvides a resource to create …",
    "content": "\n\n# Resource: aws_organizations_account\n\nProvides a resource to create a member account in the current organization.\n\n~> **Note:** Account management must be done from the organization's master account.\n\n!> **WARNING:** Deleting this Terraform resource will only remove an AWS account from an organization. Terraform will not close the account. The member account must be prepared to be a standalone account beforehand. See the [AWS Organizations documentation](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_remove.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_account\" \"account\" {\n  name  = \"my_new_account\"\n  email = \"john@doe.org\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A friendly name for the member account.\n* `email` - (Required) The email address of the owner to assign to the new member account. This email address must not already be associated with another AWS account.\n* `iam_user_access_to_billing` - (Optional) If set to `ALLOW`, the new account enables IAM users to access account billing information if they have the required permissions. If set to `DENY`, then only the root user of the new account can access account billing information.\n* `parent_id` - (Optional) Parent Organizational Unit ID or Root ID for the account. Defaults to the Organization default Root ID. A configuration must be present for this argument to perform drift detection.\n* `role_name` - (Optional) The name of an IAM role that Organizations automatically preconfigures in the new member account. This role trusts the master account, allowing users in the master account to assume the role, as permitted by the master account administrator. The role has administrator permissions in the new member account. The Organizations API provides no method for reading this information after account creation, so Terraform cannot perform drift detection on its value and will always show a difference for a configured value after import unless [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) is used.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN for this account.\n* `id` - The AWS account id\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nThe AWS member account can be imported by using the `account_id`, e.g.,\n\n```\n$ terraform import aws_organizations_account.my_org 111111111111\n```\n\nCertain resource arguments, like `role_name`, do not have an Organizations API method for reading the information after account creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_organizations_account\" \"account\" {\n  name      = \"my_new_account\"\n  email     = \"john@doe.org\"\n  role_name = \"myOrganizationRole\"\n\n  # There is no AWS Organizations API for reading role_name\n  lifecycle {\n    ignore_changes = [role_name]\n  }\n}\n```\n",
    "basename": "organizations_account.html"
  },
  "organizations_delegated_administrator.html": {
    "subcategory": "Organizations",
    "layout": "aws",
    "page_title": "AWS: aws_organizations_delegated_administrator",
    "description": "Provides a resource to manage an AWS Organizations Delegated Administrator.",
    "preview": "# Resource: aws_organizations_delegated_administrator\n\nProvides a …",
    "content": "\n\n# Resource: aws_organizations_delegated_administrator\n\nProvides a resource to manage an [AWS Organizations Delegated Administrator](https://docs.aws.amazon.com/organizations/latest/APIReference/API_RegisterDelegatedAdministrator.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_delegated_administrator\" \"example\" {\n  account_id        = \"AWS ACCOUNT ID\"\n  service_principal = \"Service principal\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Required) The account ID number of the member account in the organization to register as a delegated administrator.\n* `service_principal` - (Required) The service principal of the AWS service for which you want to make the member account a delegated administrator.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the delegated administrator.\n* `arn` - The Amazon Resource Name (ARN) of the delegated administrator's account.\n* `delegation_enabled_date` - The date when the account was made a delegated administrator.\n* `email` - The email address that is associated with the delegated administrator's AWS account.\n* `joined_method` - The method by which the delegated administrator's account joined the organization.\n* `joined_timestamp` - The date when the delegated administrator's account became a part of the organization.\n* `name` - The friendly name of the delegated administrator's account.\n* `status` - The status of the delegated administrator's account in the organization.\n\n## Import\n\n`aws_organizations_delegated_administrator` can be imported by using the account ID and its service principal, e.g.,\n\n```\n$ terraform import aws_organizations_delegated_administrator.example 123456789012/config.amazonaws.com\n```\n",
    "basename": "organizations_delegated_administrator.html"
  },
  "organizations_organization.html": {
    "subcategory": "Organizations",
    "layout": "aws",
    "page_title": "AWS: aws_organizations_organization",
    "description": "Provides a resource to create an organization.",
    "preview": "# Resource: aws_organizations_organization\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_organizations_organization\n\nProvides a resource to create an organization.\n\n!> **WARNING:** When migrating from a `feature_set` of `CONSOLIDATED_BILLING` to `ALL`, the Organization account owner will received an email stating the following: \"You started the process to enable all features for your AWS organization. As part of that process, all member accounts that joined your organization by invitation must approve the change. You don’t need approval from member accounts that you directly created from within your AWS organization.\" After all member accounts have accepted the invitation, the Organization account owner must then finalize the changes via the [AWS Console](https://console.aws.amazon.com/organizations/home#/organization/settings/migration-progress). Until these steps are performed, Terraform will perpetually show a difference, and the `DescribeOrganization` API will continue to show the `FeatureSet` as `CONSOLIDATED_BILLING`. See the [AWS Organizations documentation](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org_support-all-features.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_organization\" \"org\" {\n  aws_service_access_principals = [\n    \"cloudtrail.amazonaws.com\",\n    \"config.amazonaws.com\",\n  ]\n\n  feature_set = \"ALL\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `aws_service_access_principals` - (Optional) List of AWS service principal names for which you want to enable integration with your organization. This is typically in the form of a URL, such as service-abbreviation.amazonaws.com. Organization must have `feature_set` set to `ALL`. For additional information, see the [AWS Organizations User Guide](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_integrate_services.html).\n* `enabled_policy_types` - (Optional) List of Organizations policy types to enable in the Organization Root. Organization must have `feature_set` set to `ALL`. For additional information about valid policy types (e.g., `AISERVICES_OPT_OUT_POLICY`, `BACKUP_POLICY`, `SERVICE_CONTROL_POLICY`, and `TAG_POLICY`), see the [AWS Organizations API Reference](https://docs.aws.amazon.com/organizations/latest/APIReference/API_EnablePolicyType.html).\n* `feature_set` - (Optional) Specify \"ALL\" (default) or \"CONSOLIDATED_BILLING\".\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `accounts` - List of organization accounts including the master account. For a list excluding the master account, see the `non_master_accounts` attribute. All elements have these attributes:\n    * `arn` - ARN of the account\n    * `email` - Email of the account\n    * `id` - Identifier of the account\n    * `name` - Name of the account\n    * `status` - Current status of the account\n* `arn` - ARN of the organization\n* `id` - Identifier of the organization\n* `master_account_arn` - ARN of the master account\n* `master_account_email` - Email address of the master account\n* `master_account_id` - Identifier of the master account\n* `non_master_accounts` - List of organization accounts excluding the master account. For a list including the master account, see the `accounts` attribute. All elements have these attributes:\n    * `arn` - ARN of the account\n    * `email` - Email of the account\n    * `id` - Identifier of the account\n    * `name` - Name of the account\n    * `status` - Current status of the account\n* `roots` - List of organization roots. All elements have these attributes:\n    * `arn` - ARN of the root\n    * `id` - Identifier of the root\n    * `name` - Name of the root\n    * `policy_types` - List of policy types enabled for this root. All elements have these attributes:\n        * `name` - The name of the policy type\n        * `status` - The status of the policy type as it relates to the associated root\n\n## Import\n\nThe AWS organization can be imported by using the `id`, e.g.,\n\n```\n$ terraform import aws_organizations_organization.my_org o-1234567\n```\n",
    "basename": "organizations_organization.html"
  },
  "organizations_organizational_unit.html": {
    "subcategory": "Organizations",
    "layout": "aws",
    "page_title": "AWS: aws_organizations_organizational_unit",
    "description": "Provides a resource to create an organizational unit.",
    "preview": "# Resource: aws_organizations_organizational_unit\n\nProvides a …",
    "content": "\n\n# Resource: aws_organizations_organizational_unit\n\nProvides a resource to create an organizational unit.\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_organizational_unit\" \"example\" {\n  name      = \"example\"\n  parent_id = aws_organizations_organization.example.roots[0].id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - The name for the organizational unit\n* `parent_id` - ID of the parent organizational unit, which may be the root\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `accounts` - List of child accounts for this Organizational Unit. Does not return account information for child Organizational Units. All elements have these attributes:\n    * `arn` - ARN of the account\n    * `email` - Email of the account\n    * `id` - Identifier of the account\n    * `name` - Name of the account\n* `arn` - ARN of the organizational unit\n* `id` - Identifier of the organization unit\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAWS Organizations Organizational Units can be imported by using the `id`, e.g.,\n\n```\n$ terraform import aws_organizations_organizational_unit.example ou-1234567\n```\n",
    "basename": "organizations_organizational_unit.html"
  },
  "organizations_policy.html": {
    "subcategory": "Organizations",
    "layout": "aws",
    "page_title": "AWS: aws_organizations_policy",
    "description": "Provides a resource to manage an AWS Organizations policy.",
    "preview": "# Resource: aws_organizations_policy\n\nProvides a resource to manage …",
    "content": "\n\n# Resource: aws_organizations_policy\n\nProvides a resource to manage an [AWS Organizations policy](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_policy\" \"example\" {\n  name = \"example\"\n\n  content = <<CONTENT\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": {\n    \"Effect\": \"Allow\",\n    \"Action\": \"*\",\n    \"Resource\": \"*\"\n  }\n}\nCONTENT\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `content` - (Required) The policy content to add to the new policy. For example, if you create a [service control policy (SCP)](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html), this string must be JSON text that specifies the permissions that admins in attached accounts can delegate to their users, groups, and roles. For more information about the SCP syntax, see the [Service Control Policy Syntax documentation](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_reference_scp-syntax.html) and for more information on the Tag Policy syntax, see the [Tag Policy Syntax documentation](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_example-tag-policies.html).\n* `name` - (Required) The friendly name to assign to the policy.\n* `description` - (Optional) A description to assign to the policy.\n* `type` - (Optional) The type of policy to create. Valid values are `AISERVICES_OPT_OUT_POLICY`, `BACKUP_POLICY`, `SERVICE_CONTROL_POLICY` (SCP), and `TAG_POLICY`. Defaults to `SERVICE_CONTROL_POLICY`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) of the policy.\n* `arn` - Amazon Resource Name (ARN) of the policy.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_organizations_policy` can be imported by using the policy ID, e.g.,\n\n```\n$ terraform import aws_organizations_policy.example p-12345678\n```\n",
    "basename": "organizations_policy.html"
  },
  "organizations_policy_attachment.html": {
    "subcategory": "Organizations",
    "layout": "aws",
    "page_title": "AWS: aws_organizations_policy_attachment",
    "description": "Provides a resource to attach an AWS Organizations policy to an organization account, root, or unit.",
    "preview": "# Resource: aws_organizations_policy_attachment\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_organizations_policy_attachment\n\nProvides a resource to attach an AWS Organizations policy to an organization account, root, or unit.\n\n## Example Usage\n\n### Organization Account\n\n```terraform\nresource \"aws_organizations_policy_attachment\" \"account\" {\n  policy_id = aws_organizations_policy.example.id\n  target_id = \"123456789012\"\n}\n```\n\n### Organization Root\n\n```terraform\nresource \"aws_organizations_policy_attachment\" \"root\" {\n  policy_id = aws_organizations_policy.example.id\n  target_id = aws_organizations_organization.example.roots[0].id\n}\n```\n\n### Organization Unit\n\n```terraform\nresource \"aws_organizations_policy_attachment\" \"unit\" {\n  policy_id = aws_organizations_policy.example.id\n  target_id = aws_organizations_organizational_unit.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `policy_id` - (Required) The unique identifier (ID) of the policy that you want to attach to the target.\n* `target_id` - (Required) The unique identifier (ID) of the root, organizational unit, or account number that you want to attach the policy to.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\n`aws_organizations_policy_attachment` can be imported by using the target ID and policy ID, e.g., with an account target\n\n```\n$ terraform import aws_organizations_policy_attachment.account 123456789012:p-12345678\n```\n",
    "basename": "organizations_policy_attachment.html"
  },
  "pinpoint_adm_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_adm_channel",
    "description": "Provides a Pinpoint ADM Channel resource.",
    "preview": "# Resource: aws_pinpoint_adm_channel\n\nProvides a Pinpoint ADM …",
    "content": "\n\n# Resource: aws_pinpoint_adm_channel\n\nProvides a Pinpoint ADM (Amazon Device Messaging) Channel resource.\n\n~> **Note:** All arguments including the Client ID and Client Secret will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_app\" \"app\" {}\n\nresource \"aws_pinpoint_adm_channel\" \"channel\" {\n  application_id = aws_pinpoint_app.app.application_id\n  client_id      = \"\"\n  client_secret  = \"\"\n  enabled        = true\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `client_id` - (Required) Client ID (part of OAuth Credentials) obtained via Amazon Developer Account.\n* `client_secret` - (Required) Client Secret (part of OAuth Credentials) obtained via Amazon Developer Account.\n* `enabled` - (Optional) Specifies whether to enable the channel. Defaults to `true`.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint ADM Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_adm_channel.channel application-id\n```\n",
    "basename": "pinpoint_adm_channel"
  },
  "pinpoint_apns_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_apns_channel",
    "description": "Provides a Pinpoint APNs Channel resource.",
    "preview": "# Resource: aws_pinpoint_apns_channel\n\nProvides a Pinpoint APNs …",
    "content": "\n\n# Resource: aws_pinpoint_apns_channel\n\nProvides a Pinpoint APNs Channel resource.\n\n~> **Note:** All arguments, including certificates and tokens, will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_apns_channel\" \"apns\" {\n  application_id = aws_pinpoint_app.app.application_id\n\n  certificate = file(\"./certificate.pem\")\n  private_key = file(\"./private_key.key\")\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `enabled` - (Optional) Whether the channel is enabled or disabled. Defaults to `true`.\n* `default_authentication_method` - (Optional) The default authentication method used for APNs.\n  __NOTE__: Amazon Pinpoint uses this default for every APNs push notification that you send using the console.\n  You can override the default when you send a message programmatically using the Amazon Pinpoint API, the AWS CLI, or an AWS SDK.\n  If your default authentication type fails, Amazon Pinpoint doesn't attempt to use the other authentication type.\n\nOne of the following sets of credentials is also required.\n\nIf you choose to use __Certificate credentials__ you will have to provide:\n\n* `certificate` - (Required) The pem encoded TLS Certificate from Apple.\n* `private_key` - (Required) The Certificate Private Key file (ie. `.key` file).\n\nIf you choose to use __Key credentials__ you will have to provide:\n\n* `bundle_id` - (Required) The ID assigned to your iOS app. To find this value, choose Certificates, IDs & Profiles, choose App IDs in the Identifiers section, and choose your app.\n* `team_id` - (Required) The ID assigned to your Apple developer account team. This value is provided on the Membership page.\n* `token_key` - (Required) The `.p8` file that you download from your Apple developer account when you create an authentication key.\n* `token_key_id` - (Required) The ID assigned to your signing key. To find this value, choose Certificates, IDs & Profiles, and choose your key in the Keys section.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint APNs Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_apns_channel.apns application-id\n```\n",
    "basename": "pinpoint_apns_channel"
  },
  "pinpoint_apns_sandbox_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_apns_sandbox_channel",
    "description": "Provides a Pinpoint APNs Sandbox Channel resource.",
    "preview": "# Resource: aws_pinpoint_apns_sandbox_channel\n\nProvides a Pinpoint …",
    "content": "\n\n# Resource: aws_pinpoint_apns_sandbox_channel\n\nProvides a Pinpoint APNs Sandbox Channel resource.\n\n~> **Note:** All arguments, including certificates and tokens, will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_apns_sandbox_channel\" \"apns_sandbox\" {\n  application_id = aws_pinpoint_app.app.application_id\n\n  certificate = file(\"./certificate.pem\")\n  private_key = file(\"./private_key.key\")\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `enabled` - (Optional) Whether the channel is enabled or disabled. Defaults to `true`.\n* `default_authentication_method` - (Optional) The default authentication method used for APNs Sandbox.\n  __NOTE__: Amazon Pinpoint uses this default for every APNs push notification that you send using the console.\n  You can override the default when you send a message programmatically using the Amazon Pinpoint API, the AWS CLI, or an AWS SDK.\n  If your default authentication type fails, Amazon Pinpoint doesn't attempt to use the other authentication type.\n\nOne of the following sets of credentials is also required.\n\nIf you choose to use __Certificate credentials__ you will have to provide:\n\n* `certificate` - (Required) The pem encoded TLS Certificate from Apple.\n* `private_key` - (Required) The Certificate Private Key file (ie. `.key` file).\n\nIf you choose to use __Key credentials__ you will have to provide:\n\n* `bundle_id` - (Required) The ID assigned to your iOS app. To find this value, choose Certificates, IDs & Profiles, choose App IDs in the Identifiers section, and choose your app.\n* `team_id` - (Required) The ID assigned to your Apple developer account team. This value is provided on the Membership page.\n* `token_key` - (Required) The `.p8` file that you download from your Apple developer account when you create an authentication key.\n* `token_key_id` - (Required) The ID assigned to your signing key. To find this value, choose Certificates, IDs & Profiles, and choose your key in the Keys section.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint APNs Sandbox Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_apns_sandbox_channel.apns_sandbox application-id\n```\n",
    "basename": "pinpoint_apns_sandbox_channel"
  },
  "pinpoint_apns_voip_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_apns_voip_channel",
    "description": "Provides a Pinpoint APNs VoIP Channel resource.",
    "preview": "# Resource: aws_pinpoint_apns_voip_channel\n\nProvides a Pinpoint APNs …",
    "content": "\n\n# Resource: aws_pinpoint_apns_voip_channel\n\nProvides a Pinpoint APNs VoIP Channel resource.\n\n~> **Note:** All arguments, including certificates and tokens, will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_apns_voip_channel\" \"apns_voip\" {\n  application_id = aws_pinpoint_app.app.application_id\n\n  certificate = file(\"./certificate.pem\")\n  private_key = file(\"./private_key.key\")\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `enabled` - (Optional) Whether the channel is enabled or disabled. Defaults to `true`.\n* `default_authentication_method` - (Optional) The default authentication method used for APNs.\n  __NOTE__: Amazon Pinpoint uses this default for every APNs push notification that you send using the console.\n  You can override the default when you send a message programmatically using the Amazon Pinpoint API, the AWS CLI, or an AWS SDK.\n  If your default authentication type fails, Amazon Pinpoint doesn't attempt to use the other authentication type.\n\nOne of the following sets of credentials is also required.\n\nIf you choose to use __Certificate credentials__ you will have to provide:\n\n* `certificate` - (Required) The pem encoded TLS Certificate from Apple.\n* `private_key` - (Required) The Certificate Private Key file (ie. `.key` file).\n\nIf you choose to use __Key credentials__ you will have to provide:\n\n* `bundle_id` - (Required) The ID assigned to your iOS app. To find this value, choose Certificates, IDs & Profiles, choose App IDs in the Identifiers section, and choose your app.\n* `team_id` - (Required) The ID assigned to your Apple developer account team. This value is provided on the Membership page.\n* `token_key` - (Required) The `.p8` file that you download from your Apple developer account when you create an authentication key.\n* `token_key_id` - (Required) The ID assigned to your signing key. To find this value, choose Certificates, IDs & Profiles, and choose your key in the Keys section.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint APNs VoIP Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_apns_voip_channel.apns_voip application-id\n```\n",
    "basename": "pinpoint_apns_voip_channel"
  },
  "pinpoint_apns_voip_sandbox_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_apns_voip_sandbox_channel",
    "description": "Provides a Pinpoint APNs VoIP Sandbox Channel resource.",
    "preview": "# Resource: aws_pinpoint_apns_voip_sandbox_channel\n\nProvides a …",
    "content": "\n\n# Resource: aws_pinpoint_apns_voip_sandbox_channel\n\nProvides a Pinpoint APNs VoIP Sandbox Channel resource.\n\n~> **Note:** All arguments, including certificates and tokens, will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_apns_voip_sandbox_channel\" \"apns_voip_sandbox\" {\n  application_id = aws_pinpoint_app.app.application_id\n\n  certificate = file(\"./certificate.pem\")\n  private_key = file(\"./private_key.key\")\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `enabled` - (Optional) Whether the channel is enabled or disabled. Defaults to `true`.\n* `default_authentication_method` - (Optional) The default authentication method used for APNs.\n  __NOTE__: Amazon Pinpoint uses this default for every APNs push notification that you send using the console.\n  You can override the default when you send a message programmatically using the Amazon Pinpoint API, the AWS CLI, or an AWS SDK.\n  If your default authentication type fails, Amazon Pinpoint doesn't attempt to use the other authentication type.\n\nOne of the following sets of credentials is also required.\n\nIf you choose to use __Certificate credentials__ you will have to provide:\n\n* `certificate` - (Required) The pem encoded TLS Certificate from Apple.\n* `private_key` - (Required) The Certificate Private Key file (ie. `.key` file).\n\nIf you choose to use __Key credentials__ you will have to provide:\n\n* `bundle_id` - (Required) The ID assigned to your iOS app. To find this value, choose Certificates, IDs & Profiles, choose App IDs in the Identifiers section, and choose your app.\n* `team_id` - (Required) The ID assigned to your Apple developer account team. This value is provided on the Membership page.\n* `token_key` - (Required) The `.p8` file that you download from your Apple developer account when you create an authentication key.\n* `token_key_id` - (Required) The ID assigned to your signing key. To find this value, choose Certificates, IDs & Profiles, and choose your key in the Keys section.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint APNs VoIP Sandbox Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_apns_voip_sandbox_channel.apns_voip_sandbox application-id\n```\n",
    "basename": "pinpoint_apns_voip_sandbox_channel"
  },
  "pinpoint_app": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_app",
    "description": "Provides a Pinpoint App resource.",
    "preview": "# Resource: aws_pinpoint_app\n\nProvides a Pinpoint App resource.\n\n## …",
    "content": "\n\n# Resource: aws_pinpoint_app\n\nProvides a Pinpoint App resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_app\" \"example\" {\n  name = \"test-app\"\n\n  limits {\n    maximum_duration = 600\n  }\n\n  quiet_time {\n    start = \"00:00\"\n    end   = \"06:00\"\n  }\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The application name. By default generated by Terraform\n* `name_prefix` - (Optional) The name of the Pinpoint application. Conflicts with `name`\n* `campaign_hook` - (Optional) Specifies settings for invoking an AWS Lambda function that customizes a segment for a campaign\n* `limits` - (Optional) The default campaign limits for the app. These limits apply to each campaign for the app, unless the campaign overrides the default with limits of its own\n* `quiet_time` - (Optional) The default quiet time for the app. Each campaign for this app sends no messages during this time unless the campaign overrides the default with a quiet time of its own\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n`campaign_hook` supports the following:\n\n* `lambda_function_name` - (Optional) Lambda function name or ARN to be called for delivery. Conflicts with `web_url`\n* `mode` - (Required if `lambda_function_name` or `web_url` are provided) What mode Lambda should be invoked in. Valid values for this parameter are `DELIVERY`, `FILTER`.  \n* `web_url` - (Optional) Web URL to call for hook. If the URL has authentication specified it will be added as authentication to the request. Conflicts with `lambda_function_name`\n\n`limits` supports the following:\n\n* `daily` - (Optional) The maximum number of messages that the campaign can send daily.\n* `maximum_duration` - (Optional) The length of time (in seconds) that the campaign can run before it ends and message deliveries stop. This duration begins at the scheduled start time for the campaign. The minimum value is 60.\n* `messages_per_second` - (Optional) The number of messages that the campaign can send per second. The minimum value is 50, and the maximum is 20000.\n* `total` - (Optional) The maximum total number of messages that the campaign can send.\n\n`quiet_time` supports the following:\n\n* `end` - (Optional) The default end time for quiet time in ISO 8601 format. Required if `start` is set\n* `start` - (Optional) The default start time for quiet time in ISO 8601 format. Required if `end` is set\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `application_id` - The Application ID of the Pinpoint App.\n* `arn` - Amazon Resource Name (ARN) of the PinPoint Application\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nPinpoint App can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_app.name application-id\n```\n",
    "basename": "pinpoint_app"
  },
  "pinpoint_baidu_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_baidu_channel",
    "description": "Provides a Pinpoint Baidu Channel resource.",
    "preview": "# Resource: aws_pinpoint_baidu_channel\n\nProvides a Pinpoint Baidu …",
    "content": "\n\n# Resource: aws_pinpoint_baidu_channel\n\nProvides a Pinpoint Baidu Channel resource.\n\n~> **Note:** All arguments including the Api Key and Secret Key will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_app\" \"app\" {}\n\nresource \"aws_pinpoint_baidu_channel\" \"channel\" {\n  application_id = aws_pinpoint_app.app.application_id\n  api_key        = \"\"\n  secret_key     = \"\"\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `enabled` - (Optional) Specifies whether to enable the channel. Defaults to `true`.\n* `api_key` - (Required) Platform credential API key from Baidu.\n* `secret_key` - (Required) Platform credential Secret key from Baidu.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint Baidu Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_baidu_channel.channel application-id\n```\n",
    "basename": "pinpoint_baidu_channel"
  },
  "pinpoint_email_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_email_channel",
    "description": "Provides a Pinpoint Email Channel resource.",
    "preview": "# Resource: aws_pinpoint_email_channel\n\nProvides a Pinpoint Email …",
    "content": "\n\n# Resource: aws_pinpoint_email_channel\n\nProvides a Pinpoint Email Channel resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_email_channel\" \"email\" {\n  application_id = aws_pinpoint_app.app.application_id\n  from_address   = \"user@example.com\"\n  role_arn       = aws_iam_role.role.arn\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n\nresource \"aws_ses_domain_identity\" \"identity\" {\n  domain = \"example.com\"\n}\n\nresource \"aws_iam_role\" \"role\" {\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"pinpoint.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"role_policy\" {\n  name = \"role_policy\"\n  role = aws_iam_role.role.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": {\n    \"Action\": [\n      \"mobileanalytics:PutEvents\",\n      \"mobileanalytics:PutItems\"\n    ],\n    \"Effect\": \"Allow\",\n    \"Resource\": [\n      \"*\"\n    ]\n  }\n}\nEOF\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `enabled` - (Optional) Whether the channel is enabled or disabled. Defaults to `true`.\n* `configuration_set` - (Optional) The ARN of the Amazon SES configuration set that you want to apply to messages that you send through the channel.\n* `from_address` - (Required) The email address used to send emails from. You can use email only (`user@example.com`) or friendly address (`User <user@example.com>`). This field comply with [RFC 5322](https://www.ietf.org/rfc/rfc5322.txt).\n* `identity` - (Required) The ARN of an identity verified with SES.\n* `role_arn` - (Optional) The ARN of an IAM Role used to submit events to Mobile Analytics' event ingestion service.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `messages_per_second` - Messages per second that can be sent.\n\n## Import\n\nPinpoint Email Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_email_channel.email application-id\n```\n",
    "basename": "pinpoint_email_channel"
  },
  "pinpoint_event_stream": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_event_stream",
    "description": "Provides a Pinpoint Event Stream resource.",
    "preview": "# Resource: aws_pinpoint_event_stream\n\nProvides a Pinpoint Event …",
    "content": "\n\n# Resource: aws_pinpoint_event_stream\n\nProvides a Pinpoint Event Stream resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_event_stream\" \"stream\" {\n  application_id         = aws_pinpoint_app.app.application_id\n  destination_stream_arn = aws_kinesis_stream.test_stream.arn\n  role_arn               = aws_iam_role.test_role.arn\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n\nresource \"aws_kinesis_stream\" \"test_stream\" {\n  name        = \"pinpoint-kinesis-test\"\n  shard_count = 1\n}\n\nresource \"aws_iam_role\" \"test_role\" {\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"pinpoint.us-east-1.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"test_role_policy\" {\n  name = \"test_policy\"\n  role = aws_iam_role.test_role.id\n\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": {\n    \"Action\": [\n      \"kinesis:PutRecords\",\n      \"kinesis:DescribeStream\"\n    ],\n    \"Effect\": \"Allow\",\n    \"Resource\": [\n      \"arn:aws:kinesis:us-east-1:*:*/*\"\n    ]\n  }\n}\nEOF\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `destination_stream_arn` - (Required) The Amazon Resource Name (ARN) of the Amazon Kinesis stream or Firehose delivery stream to which you want to publish events.\n* `role_arn` - (Required) The IAM role that authorizes Amazon Pinpoint to publish events to the stream in your account.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint Event Stream can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_event_stream.stream application-id\n```\n",
    "basename": "pinpoint_event_stream"
  },
  "pinpoint_gcm_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_gcm_channel",
    "description": "Provides a Pinpoint GCM Channel resource.",
    "preview": "# Resource: aws_pinpoint_gcm_channel\n\nProvides a Pinpoint GCM …",
    "content": "\n\n# Resource: aws_pinpoint_gcm_channel\n\nProvides a Pinpoint GCM Channel resource.\n\n~> **Note:** Api Key argument will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_gcm_channel\" \"gcm\" {\n  application_id = aws_pinpoint_app.app.application_id\n  api_key        = \"api_key\"\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `api_key` - (Required) Platform credential API key from Google.\n* `enabled` - (Optional) Whether the channel is enabled or disabled. Defaults to `true`.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nPinpoint GCM Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_gcm_channel.gcm application-id\n```\n",
    "basename": "pinpoint_gcm_channel"
  },
  "pinpoint_sms_channel": {
    "subcategory": "Pinpoint",
    "layout": "aws",
    "page_title": "AWS: aws_pinpoint_sms_channel",
    "description": "Provides a Pinpoint SMS Channel resource.",
    "preview": "# Resource: aws_pinpoint_sms_channel\n\nProvides a Pinpoint SMS …",
    "content": "\n\n# Resource: aws_pinpoint_sms_channel\n\nProvides a Pinpoint SMS Channel resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_pinpoint_sms_channel\" \"sms\" {\n  application_id = aws_pinpoint_app.app.application_id\n}\n\nresource \"aws_pinpoint_app\" \"app\" {}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `application_id` - (Required) The application ID.\n* `enabled` - (Optional) Whether the channel is enabled or disabled. Defaults to `true`.\n* `sender_id` - (Optional) Sender identifier of your messages.\n* `short_code` - (Optional) The Short Code registered with the phone provider.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `promotional_messages_per_second` - Promotional messages per second that can be sent.\n* `transactional_messages_per_second` - Transactional messages per second that can be sent.\n\n## Import\n\nPinpoint SMS Channel can be imported using the `application-id`, e.g.,\n\n```\n$ terraform import aws_pinpoint_sms_channel.sms application-id\n```\n",
    "basename": "pinpoint_sms_channel"
  },
  "placement_group.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_placement_group",
    "description": "Provides an EC2 placement group.",
    "preview": "# Resource: aws_placement_group\n\nProvides an EC2 placement group. …",
    "content": "\n\n# Resource: aws_placement_group\n\nProvides an EC2 placement group. Read more about placement groups\nin [AWS Docs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_placement_group\" \"web\" {\n  name     = \"hunky-dory-pg\"\n  strategy = \"cluster\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the placement group.\n* `partition_count` - (Optional) The number of partitions to create in the\n  placement group.  Can only be specified when the `strategy` is set to\n  `\"partition\"`.  Valid values are 1 - 7 (default is `2`).\n* `strategy` - (Required) The placement strategy. Can be `\"cluster\"`, `\"partition\"` or `\"spread\"`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the placement group.\n* `id` - The name of the placement group.\n* `placement_group_id` - The ID of the placement group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nPlacement groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_placement_group.prod_pg production-placement-group\n```\n",
    "basename": "placement_group.html"
  },
  "prometheus_alert_manager_definition.html": {
    "subcategory": "Amazon Managed Service for Prometheus (AMP)",
    "layout": "aws",
    "page_title": "AWS: aws_prometheus_alert_manager_definition",
    "description": "Manages an Amazon Managed Service for Prometheus (AMP) Alert Manager Definition",
    "preview": "# Resource: aws_prometheus_alert_manager_definition\n\nManages an …",
    "content": "\n\n# Resource: aws_prometheus_alert_manager_definition\n\nManages an Amazon Managed Service for Prometheus (AMP) Alert Manager Definition\n\n## Example Usage\n\n```terraform\nresource \"aws_prometheus_workspace\" \"demo\" {\n}\n\nresource \"aws_prometheus_alert_manager_definition\" \"demo\" {\n  workspace_id = aws_prometheus_workspace.demo.id\n  definition   = <<EOF\nalertmanager_config: |\n  route:\n    receiver: 'default'\n  receivers:\n    - name: 'default'\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `workspace_id` - (Required) The id of the prometheus workspace the alert manager definition should be linked to\n* `definition` - (Required) the alert manager definition that you want to be applied. See more [in AWS Docs](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-alert-manager.html).\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nThe prometheus alert manager definition can be imported using the workspace identifier, e.g.,\n\n```\n$ terraform import aws_prometheus_alert_manager_definition.demo ws-C6DCB907-F2D7-4D96-957B-66691F865D8B\n```\n",
    "basename": "prometheus_alert_manager_definition.html"
  },
  "prometheus_rule_group_namespace.html": {
    "subcategory": "Amazon Managed Service for Prometheus (AMP)",
    "layout": "aws",
    "page_title": "AWS: aws_prometheus_rule_group_namespace",
    "description": "Manages an Amazon Managed Service for Prometheus (AMP) Rule Group Namespace",
    "preview": "# Resource: aws_prometheus_rule_group_namespace\n\nManages an Amazon …",
    "content": "\n\n# Resource: aws_prometheus_rule_group_namespace\n\nManages an Amazon Managed Service for Prometheus (AMP) Rule Group Namespace\n\n## Example Usage\n\n```terraform\nresource \"aws_prometheus_workspace\" \"demo\" {\n}\n\nresource \"aws_prometheus_rule_group_namespace\" \"demo\" {\n  name         = \"rules\"\n  workspace_id = aws_prometheus_workspace.demo.id\n  data         = <<EOF\ngroups:\n  - name: test\n    rules:\n    - record: metric:recording_rule\n      expr: avg(rate(container_cpu_usage_seconds_total[5m]))\nEOF\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the rule group namespace\n* `workspace_id` - (Required) The id of the prometheus workspace the rule group namespace should be linked to\n* `data` - (Required) the rule group namespace data that you want to be applied. See more [in AWS Docs](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-Ruler.html).\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nThe prometheus rule group namespace can be imported using the arn, e.g.,\n\n```\n$ terraform import aws_prometheus_rule_group_namespace.demo arn:aws:aps:us-west-2:123456789012:rulegroupsnamespace/IDstring/namespace_name\n```\n",
    "basename": "prometheus_rule_group_namespace.html"
  },
  "prometheus_workspace.html": {
    "subcategory": "Amazon Managed Service for Prometheus (AMP)",
    "layout": "aws",
    "page_title": "AWS: aws_prometheus_workspace",
    "description": "Manages an Amazon Managed Service for Prometheus (AMP) Workspace",
    "preview": "# Resource: aws_prometheus_workspace\n\nManages an Amazon Managed …",
    "content": "\n\n# Resource: aws_prometheus_workspace\n\nManages an Amazon Managed Service for Prometheus (AMP) Workspace.\n\n~> **NOTE:** This AWS functionality is in Preview and may change before General Availability release. Backwards compatibility is not guaranteed between Terraform AWS Provider releases.\n\n## Example Usage\n\n```terraform\nresource \"aws_prometheus_workspace\" \"demo\" {\n  alias = \"prometheus-test\"\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `alias` - (Optional) The alias of the prometheus workspace. See more [in AWS Docs](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-onboard-create-workspace.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the workspace.\n* `id` - Identifier of the workspace\n* `prometheus_endpoint` - Prometheus endpoint available for this workspace.\n\n## Import\n\nAMP Workspaces can be imported using the identifier, e.g.,\n\n```\n$ terraform import aws_prometheus_workspace.demo ws-C6DCB907-F2D7-4D96-957B-66691F865D8B\n```\n",
    "basename": "prometheus_workspace.html"
  },
  "proxy_protocol_policy.html": {
    "subcategory": "Elastic Load Balancing (ELB Classic)",
    "layout": "aws",
    "page_title": "AWS: aws_proxy_protocol_policy",
    "description": "Provides a proxy protocol policy, which allows an ELB to carry a client connection information to a backend.",
    "preview": "# Resource: aws_proxy_protocol_policy\n\nProvides a proxy protocol …",
    "content": "\n\n# Resource: aws_proxy_protocol_policy\n\nProvides a proxy protocol policy, which allows an ELB to carry a client connection information to a backend.\n\n## Example Usage\n\n```terraform\nresource \"aws_elb\" \"lb\" {\n  name               = \"test-lb\"\n  availability_zones = [\"us-east-1a\"]\n\n  listener {\n    instance_port     = 25\n    instance_protocol = \"tcp\"\n    lb_port           = 25\n    lb_protocol       = \"tcp\"\n  }\n\n  listener {\n    instance_port     = 587\n    instance_protocol = \"tcp\"\n    lb_port           = 587\n    lb_protocol       = \"tcp\"\n  }\n}\n\nresource \"aws_proxy_protocol_policy\" \"smtp\" {\n  load_balancer  = aws_elb.lb.name\n  instance_ports = [\"25\", \"587\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `load_balancer` - (Required) The load balancer to which the policy\n  should be attached.\n* `instance_ports` - (Required) List of instance ports to which the policy\n  should be applied. This can be specified if the protocol is SSL or TCP.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the policy.\n* `load_balancer` - The load balancer to which the policy is attached.\n",
    "basename": "proxy_protocol_policy.html"
  },
  "qldb_ledger.html": {
    "subcategory": "Quantum Ledger Database (QLDB)",
    "layout": "aws",
    "page_title": "AWS: aws_qldb_ledger",
    "description": "Provides an QLDB Resource resource.",
    "preview": "# Resource: aws_qldb_ledger\n\nProvides an AWS Quantum Ledger Database …",
    "content": "\n\n# Resource: aws_qldb_ledger\n\nProvides an AWS Quantum Ledger Database (QLDB) resource\n\n~> **NOTE:** Deletion protection is enabled by default. To successfully delete this resource via Terraform, `deletion_protection = false` must be applied before attempting deletion.\n\n## Example Usage\n\n```terraform\nresource \"aws_qldb_ledger\" \"sample-ledger\" {\n  name             = \"sample-ledger\"\n  permissions_mode = \"STANDARD\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The friendly name for the QLDB Ledger instance. By default generated by Terraform.\n* `permissions_mode` - (Required) The permissions mode for the QLDB ledger instance. Specify either `ALLOW_ALL` or `STANDARD`.\n* `deletion_protection` - (Optional) The deletion protection for the QLDB Ledger instance. By default it is `true`. To delete this resource via Terraform, this value must be configured to `false` and applied first before attempting deletion.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Name of the QLDB Ledger\n* `arn` - The ARN of the QLDB Ledger\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nQLDB Ledgers can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_qldb_ledger.sample-ledger sample-ledger\n```\n",
    "basename": "qldb_ledger.html"
  },
  "quicksight_data_source.html": {
    "subcategory": "QuickSight",
    "layout": "aws",
    "page_title": "AWS: aws_quicksight_data_source",
    "description": "Manages a Resource QuickSight Data Source.",
    "preview": "# Resource: aws_quicksight_data_source\n\nResource for managing …",
    "content": "\n\n# Resource: aws_quicksight_data_source\n\nResource for managing QuickSight Data Source\n\n## Example Usage\n\n```terraform\nresource \"aws_quicksight_data_source\" \"default\" {\n  data_source_id = \"example-id\"\n  name           = \"My Cool Data in S3\"\n\n  parameters {\n    s3 {\n      manifest_file_location {\n        bucket = \"my-bucket\"\n        key    = \"path/to/manifest.json\"\n      }\n    }\n  }\n\n  type = \"S3\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `data_source_id` - (Required, Forces new resource) An identifier for the data source.\n* `name` - (Required) A name for the data source, maximum of 128 characters.\n* `parameters` - (Required) The [parameters](#parameters-argument-reference) used to connect to this data source (exactly one).\n* `type` - (Required) The type of the data source. See the [AWS Documentation](https://docs.aws.amazon.com/quicksight/latest/APIReference/API_CreateDataSource.html#QS-CreateDataSource-request-Type) for the complete list of valid values.\n\nThe following arguments are optional:\n\n* `aws_account_id` - (Optional, Forces new resource) The ID for the AWS account that the data source is in. Currently, you use the ID for the AWS account that contains your Amazon QuickSight account.\n* `credentials` - (Optional) The credentials Amazon QuickSight uses to connect to your underlying source. Currently, only credentials based on user name and password are supported. See [Credentials](#credentials-argument-reference) below for more details.\n* `permission` - (Optional) A set of resource permissions on the data source. Maximum of 64 items. See [Permission](#permission-argument-reference) below for more details.\n* `ssl_properties` - (Optional) Secure Socket Layer (SSL) properties that apply when Amazon QuickSight connects to your underlying source. See [SSL Properties](#ssl_properties-argument-reference) below for more details.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_connection_properties`- (Optional) Use this parameter only when you want Amazon QuickSight to use a VPC connection when connecting to your underlying source. See [VPC Connection Properties](#vpc_connection_properties-argument-reference) below for more details.\n\n### credentials Argument Reference\n\n* `copy_source_arn` (Optional, Conflicts with `credential_pair`) - The Amazon Resource Name (ARN) of a data source that has the credential pair that you want to use.\nWhen the value is not null, the `credential_pair` from the data source in the ARN is used.\n* `credential_pair` (Optional, Conflicts with `copy_source_arn`) - Credential pair. See [Credential Pair](#credential_pair-argument-reference) below for more details.\n\n### credential_pair Argument Reference\n\n* `password` - (Required) Password, maximum length of 1024 characters.\n* `username` - (Required) User name, maximum length of 64 characters.\n\n### parameters Argument Reference\n\nTo specify data source connection parameters, exactly one of the following sub-objects must be provided.\n\n* `amazon_elasticsearch` - (Optional) [Parameters](#amazon_elasticsearch-argument-reference) for connecting to Amazon Elasticsearch.\n* `athena` - (Optional) [Parameters](#athena-argument-reference) for connecting to Athena.\n* `aurora` - (Optional) [Parameters](#aurora-argument-reference) for connecting to Aurora MySQL.\n* `aurora_postgresql` - (Optional) [Parameters](#aurora_postgresql-argument-reference) for connecting to Aurora Postgresql.\n* `aws_iot_analytics` - (Optional) [Parameters](#aws_iot_analytics-argument-reference) for connecting to AWS IOT Analytics.\n* `jira` - (Optional) [Parameters](#jira-fargument-reference) for connecting to Jira.\n* `maria_db` - (Optional) [Parameters](#maria_db-argument-reference) for connecting to MariaDB.\n* `mysql` - (Optional) [Parameters](#mysql-argument-reference) for connecting to MySQL.\n* `oracle` - (Optional) [Parameters](#oracle-argument-reference) for connecting to Oracle.\n* `postgresql` - (Optional) [Parameters](#postgresql-argument-reference) for connecting to Postgresql.\n* `presto` - (Optional) [Parameters](#presto-argument-reference) for connecting to Presto.\n* `rds` - (Optional) [Parameters](#rds-argument-reference) for connecting to RDS.\n* `redshift` - (Optional) [Parameters](#redshift-argument-reference) for connecting to Redshift.\n* `s3` - (Optional) [Parameters](#s3-argument-reference) for connecting to S3.\n* `service_now` - (Optional) [Parameters](#service_now-argument-reference) for connecting to ServiceNow.\n* `snowflake` - (Optional) [Parameters](#snowflake-argument-reference) for connecting to Snowflake.\n* `spark` - (Optional) [Parameters](#spark-argument-reference) for connecting to Spark.\n* `sql_server` - (Optional) [Parameters](#sql_server-argument-reference) for connecting to SQL Server.\n* `teradata` - (Optional) [Parameters](#teradata-argument-reference) for connecting to Teradata.\n* `twitter` - (Optional) [Parameters](#twitter-argument-reference) for connecting to Twitter.\n\n### permission Argument Reference\n\n* `actions` - (Required) Set of IAM actions to grant or revoke permissions on. Max of 16 items.\n* `principal` - (Required) The Amazon Resource Name (ARN) of the principal.\n\n### ssl_properties Argument Reference\n\n* `disable_ssl` - (Required) A Boolean option to control whether SSL should be disabled.\n\n### vpc_connection_properties Argument Reference\n\n* `vpc_connection_arn` - (Required) The Amazon Resource Name (ARN) for the VPC connection.\n\n### amazon_elasticsearch Argument Reference\n\n* `domain` - (Required) The OpenSearch domain.\n\n### athena Argument Reference\n\n* `work_group` - (Optional) The work-group to which to connect.\n\n### aurora Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The port to which to connect.\n\n### aurora_postgresql Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The port to which to connect.\n\n### aws_iot_analytics Argument Reference\n\n* `data_set_name` - (Required) The name of the data set to which to connect.\n\n### jira fArgument Reference\n\n* `site_base_url` - (Required) The base URL of the Jira instance's site to which to connect.\n\n### maria_db Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The port to which to connect.\n\n### mysql Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The port to which to connect.\n\n### oracle Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The port to which to connect.\n\n### postgresql Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The port to which to connect.\n\n### presto Argument Reference\n\n* `catalog` - (Required) The catalog to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The port to which to connect.\n\n### rds Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `instance_id` - (Optional) The instance ID to which to connect.\n\n### redshift Argument Reference\n\n* `cluster_id` - (Optional, Required if `host` and `port` are not provided) The ID of the cluster to which to connect.\n* `database` - (Required) The database to which to connect.\n* `host` - (Optional, Required if `cluster_id` is not provided) The host to which to connect.\n* `port` - (Optional, Required if `cluster_id` is not provided) The port to which to connect.\n\n### s3 Argument Reference\n\n* `manifest_file_location` - (Required) An [object containing the S3 location](#manifest_file_location-argument-reference) of the S3 manifest file.\n\n### manifest_file_location Argument Reference\n\n* `bucket` - (Required) The name of the bucket that contains the manifest file.\n* `key` - (Required) The key of the manifest file within the bucket.\n\n### service_now Argument Reference\n\n* `site_base_url` - (Required) The base URL of the Jira instance's site to which to connect.\n\n### snowflake Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `warehouse` - (Required) The warehouse to which to connect.\n\n### spark Argument Reference\n\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The warehouse to which to connect.\n\n### sql_server Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The warehouse to which to connect.\n\n### teradata Argument Reference\n\n* `database` - (Required) The database to which to connect.\n* `host` - (Required) The host to which to connect.\n* `port` - (Required) The warehouse to which to connect.\n\n#### twitter Argument Reference\n\n* `max_rows` - (Required) The maximum number of rows to query.\n* `query` - (Required) The Twitter query to retrieve the data.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the data source\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nA QuickSight data source can be imported using the AWS account ID, and data source ID name separated by a slash (`/`) e.g.,\n\n```\n$ terraform import aws_quicksight_data_source.example 123456789123/my-data-source-id\n```\n",
    "basename": "quicksight_data_source.html"
  },
  "quicksight_group.html": {
    "subcategory": "QuickSight",
    "layout": "aws",
    "page_title": "AWS: aws_quicksight_group",
    "description": "Manages a Resource QuickSight Group.",
    "preview": "# Resource: aws_quicksight_group\n\nResource for managing QuickSight …",
    "content": "\n\n# Resource: aws_quicksight_group\n\nResource for managing QuickSight Group\n\n## Example Usage\n\n```terraform\nresource \"aws_quicksight_group\" \"example\" {\n  group_name = \"tf-example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `group_name` - (Required) A name for the group.\n* `aws_account_id` - (Optional) The ID for the AWS account that the group is in. Currently, you use the ID for the AWS account that contains your Amazon QuickSight account.\n* `description` - (Optional) A description for the group.\n* `namespace` - (Optional) The namespace. Currently, you should set this to `default`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of group\n\n## Import\n\nQuickSight Group can be imported using the aws account id, namespace and group name separated by `/`.\n\n```\n$ terraform import aws_quicksight_group.example 123456789123/default/tf-example\n```\n",
    "basename": "quicksight_group.html"
  },
  "quicksight_group_membership.html": {
    "subcategory": "QuickSight",
    "layout": "aws",
    "page_title": "AWS: aws_quicksight_group_membership",
    "description": "Manages a Resource QuickSight Group Membership.",
    "preview": "# Resource: aws_quicksight_group_membership\n\nResource for managing …",
    "content": "\n\n# Resource: aws_quicksight_group_membership\n\nResource for managing QuickSight Group Membership\n\n## Example Usage\n\n```terraform\nresource \"aws_quicksight_group_membership\" \"example\" {\n  group_name  = \"all-access-users\"\n  member_name = \"john_smith\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `group_name` - (Required) The name of the group in which the member will be added.\n* `member_name` - (Required) The name of the member to add to the group.\n* `aws_account_id` - (Optional) The ID for the AWS account that the group is in. Currently, you use the ID for the AWS account that contains your Amazon QuickSight account.\n* `namespace` - (Required) The namespace. Defaults to `default`. Currently only `default` is supported.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nQuickSight Group membership can be imported using the AWS account ID, namespace, group name and member name separated by `/`.\n\n```\n$ terraform import aws_quicksight_group_membership.example 123456789123/default/all-access-users/john_smith\n```\n",
    "basename": "quicksight_group_membership.html"
  },
  "quicksight_user.html": {
    "subcategory": "QuickSight",
    "layout": "aws",
    "page_title": "AWS: aws_quicksight_user",
    "description": "Manages a Resource QuickSight User.",
    "preview": "# Resource: aws_quicksight_user\n\nResource for managing QuickSight …",
    "content": "\n\n# Resource: aws_quicksight_user\n\nResource for managing QuickSight User\n\n## Example Usage\n\n```terraform\nresource \"aws_quicksight_user\" \"example\" {\n  session_name  = \"an-author\"\n  email         = \"author@example.com\"\n  identity_type = \"IAM\"\n  user_role     = \"AUTHOR\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n\n* `email` - (Required) The email address of the user that you want to register.\n* `identity_type` - (Required) Amazon QuickSight supports several ways of managing the identity of users. This parameter accepts either  `IAM` or `QUICKSIGHT`.\n* `user_role` - (Required) The Amazon QuickSight role of the user. The user role can be one of the following: `READER`, `AUTHOR`, or `ADMIN`\n* `user_name` - (Optional) The Amazon QuickSight user name that you want to create for the user you are registering. Only valid for registering a user with `identity_type` set to `QUICKSIGHT`.\n* `aws_account_id` - (Optional) The ID for the AWS account that the user is in. Currently, you use the ID for the AWS account that contains your Amazon QuickSight account.\n* `iam_arn` - (Optional) The ARN of the IAM user or role that you are registering with Amazon QuickSight.\n* `namespace`  - (Optional) The namespace. Currently, you should set this to `default`.\n* `session_name` - (Optional) The name of the IAM session to use when assuming roles that can embed QuickSight dashboards. Only valid for registering users using an assumed IAM role. Additionally, if registering multiple users using the same IAM role, each user needs to have a unique session name.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the user\n\n## Import\n\nImporting is currently not supported on this resource.\n",
    "basename": "quicksight_user.html"
  },
  "ram_principal_association": {
    "subcategory": "RAM",
    "layout": "aws",
    "page_title": "AWS: aws_ram_principal_association",
    "description": "Provides a Resource Access Manager (RAM) principal association.",
    "preview": "# Resource: aws_ram_principal_association\n\nProvides a Resource …",
    "content": "\n\n# Resource: aws_ram_principal_association\n\nProvides a Resource Access Manager (RAM) principal association. Depending if [RAM Sharing with AWS Organizations is enabled](https://docs.aws.amazon.com/ram/latest/userguide/getting-started-sharing.html#getting-started-sharing-orgs), the RAM behavior with different principal types changes.\n\nWhen RAM Sharing with AWS Organizations is enabled:\n\n- For AWS Account ID, Organization, and Organizational Unit principals within the same AWS Organization, no resource share invitation is sent and resources become available automatically after creating the association.\n- For AWS Account ID principals outside the AWS Organization, a resource share invitation is sent and must be accepted before resources become available. See the [`aws_ram_resource_share_accepter` resource](/docs/providers/aws/r/ram_resource_share_accepter.html) to accept these invitations.\n\nWhen RAM Sharing with AWS Organizations is not enabled:\n\n- Organization and Organizational Unit principals cannot be used.\n- For AWS Account ID principals, a resource share invitation is sent and must be accepted before resources become available. See the [`aws_ram_resource_share_accepter` resource](/docs/providers/aws/r/ram_resource_share_accepter.html) to accept these invitations.\n\n## Example Usage\n\n### AWS Account ID\n\n```terraform\nresource \"aws_ram_resource_share\" \"example\" {\n  # ... other configuration ...\n  allow_external_principals = true\n}\n\nresource \"aws_ram_principal_association\" \"example\" {\n  principal          = \"111111111111\"\n  resource_share_arn = aws_ram_resource_share.example.arn\n}\n```\n\n### AWS Organization\n\n```terraform\nresource \"aws_ram_principal_association\" \"example\" {\n  principal          = aws_organizations_organization.example.arn\n  resource_share_arn = aws_ram_resource_share.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `principal` - (Required) The principal to associate with the resource share. Possible values are an AWS account ID, an AWS Organizations Organization ARN, or an AWS Organizations Organization Unit ARN.\n* `resource_share_arn` - (Required) The Amazon Resource Name (ARN) of the resource share.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the Resource Share and the principal, separated by a comma.\n\n## Import\n\nRAM Principal Associations can be imported using their Resource Share ARN and the `principal` separated by a comma, e.g.,\n\n```\n$ terraform import aws_ram_principal_association.example arn:aws:ram:eu-west-1:123456789012:resource-share/73da1ab9-b94a-4ba3-8eb4-45917f7f4b12,123456789012\n```\n",
    "basename": "ram_principal_association"
  },
  "ram_resource_association.html": {
    "subcategory": "RAM",
    "layout": "aws",
    "page_title": "AWS: aws_ram_resource_association",
    "description": "Manages a Resource Access Manager (RAM) Resource Association.",
    "preview": "# Resource: aws_ram_resource_association\n\nManages a Resource Access …",
    "content": "\n\n# Resource: aws_ram_resource_association\n\nManages a Resource Access Manager (RAM) Resource Association.\n\n~> *NOTE:* Certain AWS resources (e.g., EC2 Subnets) can only be shared in an AWS account that is a member of an AWS Organizations organization with organization-wide Resource Access Manager functionality enabled. See the [Resource Access Manager User Guide](https://docs.aws.amazon.com/ram/latest/userguide/what-is.html) and AWS service specific documentation for additional information.\n\n## Example Usage\n\n```terraform\nresource \"aws_ram_resource_association\" \"example\" {\n  resource_arn       = aws_subnet.example.arn\n  resource_share_arn = aws_ram_resource_share.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resource_arn` - (Required) Amazon Resource Name (ARN) of the resource to associate with the RAM Resource Share.\n* `resource_share_arn` - (Required) Amazon Resource Name (ARN) of the RAM Resource Share.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the resource share.\n\n## Import\n\nRAM Resource Associations can be imported using their Resource Share ARN and Resource ARN separated by a comma, e.g.,\n\n```\n$ terraform import aws_ram_resource_association.example arn:aws:ram:eu-west-1:123456789012:resource-share/73da1ab9-b94a-4ba3-8eb4-45917f7f4b12,arn:aws:ec2:eu-west-1:123456789012:subnet/subnet-12345678\n```\n",
    "basename": "ram_resource_association.html"
  },
  "ram_resource_share": {
    "subcategory": "RAM",
    "layout": "aws",
    "page_title": "AWS: aws_ram_resource_share",
    "description": "Manages a Resource Access Manager (RAM) Resource Share.",
    "preview": "# Resource: aws_ram_resource_share\n\nManages a Resource Access …",
    "content": "\n\n# Resource: aws_ram_resource_share\n\nManages a Resource Access Manager (RAM) Resource Share. To associate principals with the share, see the [`aws_ram_principal_association` resource](/docs/providers/aws/r/ram_principal_association.html). To associate resources with the share, see the [`aws_ram_resource_association` resource](/docs/providers/aws/r/ram_resource_association.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ram_resource_share\" \"example\" {\n  name                      = \"example\"\n  allow_external_principals = true\n\n  tags = {\n    Environment = \"Production\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the resource share.\n* `allow_external_principals` - (Optional) Indicates whether principals outside your organization can be associated with a resource share.\n* `tags` - (Optional) A map of tags to assign to the resource share. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the resource share.\n* `id` - The Amazon Resource Name (ARN) of the resource share.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nResource shares can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_ram_resource_share.example arn:aws:ram:eu-west-1:123456789012:resource-share/73da1ab9-b94a-4ba3-8eb4-45917f7f4b12\n```\n",
    "basename": "ram_resource_share"
  },
  "ram_resource_share_accepter": {
    "subcategory": "RAM",
    "layout": "aws",
    "page_title": "AWS: aws_ram_resource_share_accepter",
    "description": "Manages accepting a Resource Access Manager (RAM) Resource Share invitation.",
    "preview": "# Resource: aws_ram_resource_share_accepter\n\nManage accepting a …",
    "content": "\n\n# Resource: aws_ram_resource_share_accepter\n\nManage accepting a Resource Access Manager (RAM) Resource Share invitation. From a _receiver_ AWS account, accept an invitation to share resources that were shared by a _sender_ AWS account. To create a resource share in the _sender_, see the [`aws_ram_resource_share` resource](/docs/providers/aws/r/ram_resource_share.html).\n\n~> **Note:** If both AWS accounts are in the same Organization and [RAM Sharing with AWS Organizations is enabled](https://docs.aws.amazon.com/ram/latest/userguide/getting-started-sharing.html#getting-started-sharing-orgs), this resource is not necessary as RAM Resource Share invitations are not used.\n\n## Example Usage\n\nThis configuration provides an example of using multiple Terraform AWS providers to configure two different AWS accounts. In the _sender_ account, the configuration creates a `aws_ram_resource_share` and uses a data source in the _receiver_ account to create a `aws_ram_principal_association` resource with the _receiver's_ account ID. In the _receiver_ account, the configuration accepts the invitation to share resources with the `aws_ram_resource_share_accepter`.\n\n```terraform\nprovider \"aws\" {\n  profile = \"profile2\"\n}\n\nprovider \"aws\" {\n  alias   = \"alternate\"\n  profile = \"profile1\"\n}\n\nresource \"aws_ram_resource_share\" \"sender_share\" {\n  provider = aws.alternate\n\n  name                      = \"tf-test-resource-share\"\n  allow_external_principals = true\n\n  tags = {\n    Name = \"tf-test-resource-share\"\n  }\n}\n\nresource \"aws_ram_principal_association\" \"sender_invite\" {\n  provider = aws.alternate\n\n  principal          = data.aws_caller_identity.receiver.account_id\n  resource_share_arn = aws_ram_resource_share.sender_share.arn\n}\n\ndata \"aws_caller_identity\" \"receiver\" {}\n\nresource \"aws_ram_resource_share_accepter\" \"receiver_accept\" {\n  share_arn = aws_ram_principal_association.sender_invite.resource_share_arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `share_arn` - (Required) The ARN of the resource share.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `invitation_arn` - The ARN of the resource share invitation.\n* `share_id` - The ID of the resource share as displayed in the console.\n* `status` - The status of the resource share (ACTIVE, PENDING, FAILED, DELETING, DELETED).\n* `receiver_account_id` - The account ID of the receiver account which accepts the invitation.\n* `sender_account_id` - The account ID of the sender account which submits the invitation.\n* `share_name` - The name of the resource share.\n* `resources` - A list of the resource ARNs shared via the resource share.\n\n## Import\n\nResource share accepters can be imported using the resource share ARN, e.g.,\n\n```\n$ terraform import aws_ram_resource_share_accepter.example arn:aws:ram:us-east-1:123456789012:resource-share/c4b56393-e8d9-89d9-6dc9-883752de4767\n```\n",
    "basename": "ram_resource_share_accepter"
  },
  "rds_cluster.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_rds_cluster",
    "description": "Manages an RDS Aurora Cluster",
    "preview": "# Resource: aws_rds_cluster\n\nManages a [RDS Aurora Cluster][2]. To …",
    "content": "\n\n# Resource: aws_rds_cluster\n\nManages a [RDS Aurora Cluster][2]. To manage cluster instances that inherit configuration from the cluster (when not running the cluster in `serverless` engine mode), see the [`aws_rds_cluster_instance` resource](/docs/providers/aws/r/rds_cluster_instance.html). To manage non-Aurora databases (e.g., MySQL, PostgreSQL, SQL Server, etc.), see the [`aws_db_instance` resource](/docs/providers/aws/r/db_instance.html).\n\nFor information on the difference between the available Aurora MySQL engines\nsee [Comparison between Aurora MySQL 1 and Aurora MySQL 2](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.Updates.20180206.html)\nin the Amazon RDS User Guide.\n\nChanges to an RDS Cluster can occur when you manually change a\nparameter, such as `port`, and are reflected in the next maintenance\nwindow. Because of this, Terraform may report a difference in its planning\nphase because a modification has not yet taken place. You can use the\n`apply_immediately` flag to instruct the service to apply the change immediately\n(see documentation below).\n\n~> **Note:** using `apply_immediately` can result in a\nbrief downtime as the server reboots. See the AWS Docs on [RDS Maintenance][4]\nfor more information.\n\n~> **Note:** All arguments including the username and password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n~> **NOTE on RDS Clusters and RDS Cluster Role Associations:** Terraform provides both a standalone [RDS Cluster Role Association](rds_cluster_role_association.html) - (an association between an RDS Cluster and a single IAM Role) and\nan RDS Cluster resource with `iam_roles` attributes.\nUse one resource or the other to associate IAM Roles and RDS Clusters.\nNot doing so will cause a conflict of associations and will result in the association being overwritten.\n\n## Example Usage\n\n### Aurora MySQL 2.x (MySQL 5.7)\n\n```terraform\nresource \"aws_rds_cluster\" \"default\" {\n  cluster_identifier      = \"aurora-cluster-demo\"\n  engine                  = \"aurora-mysql\"\n  engine_version          = \"5.7.mysql_aurora.2.03.2\"\n  availability_zones      = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n  database_name           = \"mydb\"\n  master_username         = \"foo\"\n  master_password         = \"bar\"\n  backup_retention_period = 5\n  preferred_backup_window = \"07:00-09:00\"\n}\n```\n\n### Aurora MySQL 1.x (MySQL 5.6)\n\n```terraform\nresource \"aws_rds_cluster\" \"default\" {\n  cluster_identifier      = \"aurora-cluster-demo\"\n  availability_zones      = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n  database_name           = \"mydb\"\n  master_username         = \"foo\"\n  master_password         = \"bar\"\n  backup_retention_period = 5\n  preferred_backup_window = \"07:00-09:00\"\n}\n```\n\n### Aurora with PostgreSQL engine\n\n```terraform\nresource \"aws_rds_cluster\" \"postgresql\" {\n  cluster_identifier      = \"aurora-cluster-demo\"\n  engine                  = \"aurora-postgresql\"\n  availability_zones      = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n  database_name           = \"mydb\"\n  master_username         = \"foo\"\n  master_password         = \"bar\"\n  backup_retention_period = 5\n  preferred_backup_window = \"07:00-09:00\"\n}\n```\n\n### Aurora Multi-Master Cluster\n\n-> More information about Aurora Multi-Master Clusters can be found in the [RDS User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-multi-master.html).\n\n```terraform\nresource \"aws_rds_cluster\" \"example\" {\n  cluster_identifier   = \"example\"\n  db_subnet_group_name = aws_db_subnet_group.example.name\n  engine_mode          = \"multimaster\"\n  master_password      = \"barbarbarbar\"\n  master_username      = \"foo\"\n  skip_final_snapshot  = true\n}\n```\n\n## Argument Reference\n\nFor more detailed documentation about each argument, refer to\nthe AWS official documentation :\n\n* [create-db-cluster](https://docs.aws.amazon.com/cli/latest/reference/rds/create-db-cluster.html).\n* [modify-db-cluster](https://docs.aws.amazon.com/cli/latest/reference/rds/modify-db-cluster.html)\n\nThe following arguments are supported:\n\n* `allow_major_version_upgrade` - (Optional) Enable to allow major engine version upgrades when changing engine versions. Defaults to `false`.\n* `apply_immediately` - (Optional) Specifies whether any cluster modifications are applied immediately, or during the next maintenance window. Default is `false`. See [Amazon RDS Documentation for more information.](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html)\n* `availability_zones` - (Optional) A list of EC2 Availability Zones for the DB cluster storage where DB cluster instances can be created. RDS automatically assigns 3 AZs if less than 3 AZs are configured, which will show as a difference requiring resource recreation next Terraform apply. It is recommended to specify 3 AZs or use [the `lifecycle` configuration block `ignore_changes` argument](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) if necessary.\n* `backtrack_window` - (Optional) The target backtrack window, in seconds. Only available for `aurora` and `aurora-mysql` engines currently. To disable backtracking, set this value to `0`. Defaults to `0`. Must be between `0` and `259200` (72 hours)\n* `backup_retention_period` - (Optional) The days to retain backups for. Default `1`\n* `cluster_identifier_prefix` - (Optional, Forces new resource) Creates a unique cluster identifier beginning with the specified prefix. Conflicts with `cluster_identifier`.\n* `cluster_identifier` - (Optional, Forces new resources) The cluster identifier. If omitted, Terraform will assign a random, unique identifier.\n* `copy_tags_to_snapshot` – (Optional, boolean) Copy all Cluster `tags` to snapshots. Default is `false`.\n* `database_name` - (Optional) Name for an automatically created database on cluster creation. There are different naming restrictions per database engine: [RDS Naming Constraints][5]\n* `db_cluster_parameter_group_name` - (Optional) A cluster parameter group to associate with the cluster.\n* `db_instance_parameter_group_name` - (Optional) Instance parameter group to associate with all instances of the DB cluster. The `db_instance_parameter_group_name` parameter is only valid in combination with the `allow_major_version_upgrade` parameter.\n* `db_subnet_group_name` - (Optional) A DB subnet group to associate with this DB instance. **NOTE:** This must match the `db_subnet_group_name` specified on every [`aws_rds_cluster_instance`](/docs/providers/aws/r/rds_cluster_instance.html) in the cluster.\n* `deletion_protection` - (Optional) If the DB instance should have deletion protection enabled. The database can't be deleted when this value is set to `true`. The default is `false`.\n* `enable_http_endpoint` - (Optional) Enable HTTP endpoint (data API). Only valid when `engine_mode` is set to `serverless`.\n* `enabled_cloudwatch_logs_exports` - (Optional) Set of log types to export to cloudwatch. If omitted, no logs will be exported. The following log types are supported: `audit`, `error`, `general`, `slowquery`, `postgresql` (PostgreSQL).\n* `engine` - (Optional) The name of the database engine to be used for this DB cluster. Defaults to `aurora`. Valid Values: `aurora`, `aurora-mysql`, `aurora-postgresql`\n* `engine_mode` - (Optional) The database engine mode. Valid values: `global` (only valid for Aurora MySQL 1.21 and earlier), `multimaster`, `parallelquery`, `provisioned`, `serverless`. Defaults to: `provisioned`. See the [RDS User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/aurora-serverless.html) for limitations when using `serverless`.\n* `engine_version` - (Optional) The database engine version. Updating this argument results in an outage. See the [Aurora MySQL](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.html) and [Aurora Postgres](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.Updates.html) documentation for your configured engine to determine this value. For example with Aurora MySQL 2, a potential value for this argument is `5.7.mysql_aurora.2.03.2`. The value can contain a partial version where supported by the API. The actual engine version used is returned in the attribute `engine_version_actual`, [defined below](#engine_version_actual).\n* `final_snapshot_identifier` - (Optional) The name of your final DB snapshot when this DB cluster is deleted. If omitted, no final snapshot will be made.\n* `global_cluster_identifier` - (Optional) The global cluster identifier specified on [`aws_rds_global_cluster`](/docs/providers/aws/r/rds_global_cluster.html).\n* `enable_global_write_forwarding` - (Optional) Whether cluster should forward writes to an associated global cluster. Applied to secondary clusters to enable them to forward writes to an [`aws_rds_global_cluster`](/docs/providers/aws/r/rds_global_cluster.html)'s primary cluster. See the [Aurora Userguide documentation](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database-write-forwarding.html) for more information.\n* `iam_database_authentication_enabled` - (Optional) Specifies whether or not mappings of AWS Identity and Access Management (IAM) accounts to database accounts is enabled. Please see [AWS Documentation](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.IAMDBAuth.html) for availability and limitations.\n* `iam_roles` - (Optional) A List of ARNs for the IAM roles to associate to the RDS Cluster.\n* `kms_key_id` - (Optional) The ARN for the KMS encryption key. When specifying `kms_key_id`, `storage_encrypted` needs to be set to true.\n* `master_password` - (Required unless a `snapshot_identifier` or `replication_source_identifier` is provided or unless a `global_cluster_identifier` is provided when the cluster is the \"secondary\" cluster of a global database) Password for the master DB user. Note that this may show up in logs, and it will be stored in the state file. Please refer to the [RDS Naming Constraints][5]\n* `master_username` - (Required unless a `snapshot_identifier` or `replication_source_identifier` is provided or unless a `global_cluster_identifier` is provided when the cluster is the \"secondary\" cluster of a global database) Username for the master DB user. Please refer to the [RDS Naming Constraints][5]. This argument does not support in-place updates and cannot be changed during a restore from snapshot.\n* `port` - (Optional) The port on which the DB accepts connections\n* `preferred_backup_window` - (Optional) The daily time range during which automated backups are created if automated backups are enabled using the BackupRetentionPeriod parameter.Time in UTC. Default: A 30-minute window selected at random from an 8-hour block of time per regionE.g., 04:00-09:00\n* `preferred_maintenance_window` - (Optional) The weekly time range during which system maintenance can occur, in (UTC) e.g., wed:04:00-wed:04:30\n* `replication_source_identifier` - (Optional) ARN of a source DB cluster or DB instance if this DB cluster is to be created as a Read Replica. If DB Cluster is part of a Global Cluster, use the [`lifecycle` configuration block `ignore_changes` argument](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to prevent Terraform from showing differences for this argument instead of configuring this value.\n* `restore_to_point_in_time` - (Optional) Nested attribute for [point in time restore](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_PIT.html). More details below.\n* `scaling_configuration` - (Optional) Nested attribute with scaling properties. Only valid when `engine_mode` is set to `serverless`. More details below.\n* `skip_final_snapshot` - (Optional) Determines whether a final DB snapshot is created before the DB cluster is deleted. If true is specified, no DB snapshot is created. If false is specified, a DB snapshot is created before the DB cluster is deleted, using the value from `final_snapshot_identifier`. Default is `false`.\n* `snapshot_identifier` - (Optional) Specifies whether or not to create this cluster from a snapshot. You can use either the name or ARN when specifying a DB cluster snapshot, or the ARN when specifying a DB snapshot.\n* `source_region` - (Optional) The source region for an encrypted replica DB cluster.\n* `storage_encrypted` - (Optional) Specifies whether the DB cluster is encrypted. The default is `false` for `provisioned` `engine_mode` and `true` for `serverless` `engine_mode`. When restoring an unencrypted `snapshot_identifier`, the `kms_key_id` argument must be provided to encrypt the restored cluster. Terraform will only perform drift detection if a configuration value is provided.\n* `tags` - (Optional) A map of tags to assign to the DB cluster. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_security_group_ids` - (Optional) List of VPC security groups to associate with the Cluster\n\n### S3 Import Options\n\nFull details on the core parameters and impacts are in the API Docs: [RestoreDBClusterFromS3](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_RestoreDBClusterFromS3.html). Requires that the S3 bucket be in the same region as the RDS cluster you're trying to create. Sample:\n\n~> **NOTE:** RDS Aurora Serverless does not support loading data from S3, so its not possible to directly use `engine_mode` set to `serverless` with `s3_import`.\n\n```terraform\nresource \"aws_rds_cluster\" \"db\" {\n  engine = \"aurora\"\n\n  s3_import {\n    source_engine         = \"mysql\"\n    source_engine_version = \"5.6\"\n    bucket_name           = \"mybucket\"\n    bucket_prefix         = \"backups\"\n    ingestion_role        = \"arn:aws:iam::1234567890:role/role-xtrabackup-rds-restore\"\n  }\n}\n```\n\n* `bucket_name` - (Required) The bucket name where your backup is stored\n* `bucket_prefix` - (Optional) Can be blank, but is the path to your backup\n* `ingestion_role` - (Required) Role applied to load the data.\n* `source_engine` - (Required) Source engine for the backup\n* `source_engine_version` - (Required) Version of the source engine used to make the backup\n\nThis will not recreate the resource if the S3 object changes in some way. It's only used to initialize the database. This only works currently with the aurora engine. See AWS for currently supported engines and options. See [Aurora S3 Migration Docs](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.Migrating.ExtMySQL.html#AuroraMySQL.Migrating.ExtMySQL.S3).\n\n### restore_to_point_in_time Argument Reference\n\n~> **NOTE:**  The DB cluster is created from the source DB cluster with the same configuration as the original DB cluster, except that the new DB cluster is created with the default DB security group. Thus, the following arguments should only be specified with the source DB cluster's respective values: `database_name`, `master_username`, `storage_encrypted`, `replication_source_identifier`, and `source_region`.\n\nExample:\n\n```terraform\nresource \"aws_rds_cluster\" \"example-clone\" {\n  # ... other configuration ...\n\n  restore_to_point_in_time {\n    source_cluster_identifier  = \"example\"\n    restore_type               = \"copy-on-write\"\n    use_latest_restorable_time = true\n  }\n}\n```\n\n* `source_cluster_identifier` - (Required) The identifier of the source database cluster from which to restore.\n* `restore_type` - (Optional) Type of restore to be performed.\n   Valid options are `full-copy` (default) and `copy-on-write`.\n* `use_latest_restorable_time` - (Optional) Set to true to restore the database cluster to the latest restorable backup time. Defaults to false. Conflicts with `restore_to_time`.\n* `restore_to_time` - (Optional) Date and time in UTC format to restore the database cluster to. Conflicts with `use_latest_restorable_time`.\n\n### scaling_configuration Argument Reference\n\n~> **NOTE:** `scaling_configuration` configuration is only valid when `engine_mode` is set to `serverless`.\n\nExample:\n\n```terraform\nresource \"aws_rds_cluster\" \"example\" {\n  # ... other configuration ...\n\n  engine_mode = \"serverless\"\n\n  scaling_configuration {\n    auto_pause               = true\n    max_capacity             = 256\n    min_capacity             = 2\n    seconds_until_auto_pause = 300\n    timeout_action           = \"ForceApplyCapacityChange\"\n  }\n}\n```\n\n* `auto_pause` - (Optional) Whether to enable automatic pause. A DB cluster can be paused only when it's idle (it has no connections). If a DB cluster is paused for more than seven days, the DB cluster might be backed up with a snapshot. In this case, the DB cluster is restored when there is a request to connect to it. Defaults to `true`.\n* `max_capacity` - (Optional) The maximum capacity for an Aurora DB cluster in `serverless` DB engine mode. The maximum capacity must be greater than or equal to the minimum capacity. Valid Aurora MySQL capacity values are `1`, `2`, `4`, `8`, `16`, `32`, `64`, `128`, `256`. Valid Aurora PostgreSQL capacity values are (`2`, `4`, `8`, `16`, `32`, `64`, `192`, and `384`). Defaults to `16`.\n* `min_capacity` - (Optional) The minimum capacity for an Aurora DB cluster in `serverless` DB engine mode. The minimum capacity must be lesser than or equal to the maximum capacity. Valid Aurora MySQL capacity values are `1`, `2`, `4`, `8`, `16`, `32`, `64`, `128`, `256`. Valid Aurora PostgreSQL capacity values are (`2`, `4`, `8`, `16`, `32`, `64`, `192`, and `384`). Defaults to `1`.\n* `seconds_until_auto_pause` - (Optional) The time, in seconds, before an Aurora DB cluster in serverless mode is paused. Valid values are `300` through `86400`. Defaults to `300`.\n* `timeout_action` - (Optional) The action to take when the timeout is reached. Valid values: `ForceApplyCapacityChange`, `RollbackCapacityChange`. Defaults to `RollbackCapacityChange`. See [documentation](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.how-it-works.html#aurora-serverless.how-it-works.timeout-action).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of cluster\n* `id` - The RDS Cluster Identifier\n* `cluster_identifier` - The RDS Cluster Identifier\n* `cluster_resource_id` - The RDS Cluster Resource ID\n* `cluster_members` – List of RDS Instances that are a part of this cluster\n* `availability_zones` - The availability zone of the instance\n* `backup_retention_period` - The backup retention period\n* `preferred_backup_window` - The daily time range during which the backups happen\n* `preferred_maintenance_window` - The maintenance window\n* `endpoint` - The DNS address of the RDS instance\n* `reader_endpoint` - A read-only endpoint for the Aurora cluster, automatically\nload-balanced across replicas\n* `engine` - The database engine\n* `engine_version_actual` - The running version of the database.\n* `database_name` - The database name\n* `port` - The database port\n* `master_username` - The master username for the database\n* `storage_encrypted` - Specifies whether the DB cluster is encrypted\n* `replication_source_identifier` - ARN of the source DB cluster or DB instance if this DB cluster is created as a Read Replica.\n* `hosted_zone_id` - The Route53 Hosted Zone ID of the endpoint\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[1]: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Replication.html\n[2]: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Aurora.html\n[3]: /docs/providers/aws/r/rds_cluster_instance.html\n[4]: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html\n[5]: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html#RDS_Limits.Constraints\n\n## Timeouts\n\n`aws_rds_cluster` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `120 minutes`) Used for Cluster creation\n- `update` - (Default `120 minutes`) Used for Cluster modifications\n- `delete` - (Default `120 minutes`) Used for destroying cluster. This includes\nany cleanup task during the destroying process.\n\n## Import\n\nRDS Clusters can be imported using the `cluster_identifier`, e.g.,\n\n```\n$ terraform import aws_rds_cluster.aurora_cluster aurora-prod-cluster\n```\n",
    "basename": "rds_cluster.html"
  },
  "rds_cluster_endpoint.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_rds_cluster_endpoint",
    "description": "Manages an RDS Aurora Cluster Endpoint",
    "preview": "# Resource: aws_rds_cluster_endpoint\n\nManages an RDS Aurora Cluster …",
    "content": "\n\n# Resource: aws_rds_cluster_endpoint\n\nManages an RDS Aurora Cluster Endpoint.\nYou can refer to the [User Guide][1].\n\n\n## Example Usage\n\n```terraform\nresource \"aws_rds_cluster\" \"default\" {\n  cluster_identifier      = \"aurora-cluster-demo\"\n  availability_zones      = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n  database_name           = \"mydb\"\n  master_username         = \"foo\"\n  master_password         = \"bar\"\n  backup_retention_period = 5\n  preferred_backup_window = \"07:00-09:00\"\n}\n\nresource \"aws_rds_cluster_instance\" \"test1\" {\n  apply_immediately  = true\n  cluster_identifier = aws_rds_cluster.default.id\n  identifier         = \"test1\"\n  instance_class     = \"db.t2.small\"\n  engine             = aws_rds_cluster.default.engine\n  engine_version     = aws_rds_cluster.default.engine_version\n}\n\nresource \"aws_rds_cluster_instance\" \"test2\" {\n  apply_immediately  = true\n  cluster_identifier = aws_rds_cluster.default.id\n  identifier         = \"test2\"\n  instance_class     = \"db.t2.small\"\n  engine             = aws_rds_cluster.default.engine\n  engine_version     = aws_rds_cluster.default.engine_version\n}\n\nresource \"aws_rds_cluster_instance\" \"test3\" {\n  apply_immediately  = true\n  cluster_identifier = aws_rds_cluster.default.id\n  identifier         = \"test3\"\n  instance_class     = \"db.t2.small\"\n  engine             = aws_rds_cluster.default.engine\n  engine_version     = aws_rds_cluster.default.engine_version\n}\n\nresource \"aws_rds_cluster_endpoint\" \"eligible\" {\n  cluster_identifier          = aws_rds_cluster.default.id\n  cluster_endpoint_identifier = \"reader\"\n  custom_endpoint_type        = \"READER\"\n\n  excluded_members = [\n    aws_rds_cluster_instance.test1.id,\n    aws_rds_cluster_instance.test2.id,\n  ]\n}\n\nresource \"aws_rds_cluster_endpoint\" \"static\" {\n  cluster_identifier          = aws_rds_cluster.default.id\n  cluster_endpoint_identifier = \"static\"\n  custom_endpoint_type        = \"READER\"\n\n  static_members = [\n    aws_rds_cluster_instance.test1.id,\n    aws_rds_cluster_instance.test3.id,\n  ]\n}\n```\n\n## Argument Reference\n\nFor more detailed documentation about each argument, refer to\nthe [AWS official documentation](https://docs.aws.amazon.com/cli/latest/reference/rds/create-db-cluster-endpoint.html).\n\nThe following arguments are supported:\n\n* `cluster_identifier` - (Required, Forces new resources) The cluster identifier.\n* `cluster_endpoint_identifier` - (Required, Forces new resources) The identifier to use for the new endpoint. This parameter is stored as a lowercase string.\n* `custom_endpoint_type` - (Required) The type of the endpoint. One of: READER , ANY .\n* `static_members` - (Optional) List of DB instance identifiers that are part of the custom endpoint group. Conflicts with `excluded_members`.\n* `excluded_members` - (Optional) List of DB instance identifiers that aren't part of the custom endpoint group. All other eligible instances are reachable through the custom endpoint. Only relevant if the list of static members is empty. Conflicts with `static_members`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of cluster\n* `id` - The RDS Cluster Endpoint Identifier\n* `endpoint` - A custom endpoint for the Aurora cluster\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nRDS Clusters Endpoint can be imported using the `cluster_endpoint_identifier`, e.g.,\n\n```\n$ terraform import aws_rds_cluster_endpoint.custom_reader aurora-prod-cluster-custom-reader\n```\n\n[1]: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Endpoints.Cluster\n",
    "basename": "rds_cluster_endpoint.html"
  },
  "rds_cluster_instance.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_rds_cluster_instance",
    "description": "Provides an RDS Cluster Resource Instance",
    "preview": "# Resource: aws_rds_cluster_instance\n\nProvides an RDS Cluster …",
    "content": "\n\n# Resource: aws_rds_cluster_instance\n\nProvides an RDS Cluster Instance Resource. A Cluster Instance Resource defines\nattributes that are specific to a single instance in a [RDS Cluster][3],\nspecifically running Amazon Aurora.\n\nUnlike other RDS resources that support replication, with Amazon Aurora you do\nnot designate a primary and subsequent replicas. Instead, you simply add RDS\nInstances and Aurora manages the replication. You can use the [count][5]\nmeta-parameter to make multiple instances and join them all to the same RDS\nCluster, or you may specify different Cluster Instance resources with various\n`instance_class` sizes.\n\nFor more information on Amazon Aurora, see [Aurora on Amazon RDS][2] in the Amazon RDS User Guide.\n\n~> **NOTE:** Deletion Protection from the RDS service can only be enabled at the cluster level, not for individual cluster instances. You can still add the [`prevent_destroy` lifecycle behavior](https://www.terraform.io/docs/configuration/resources.html#prevent_destroy) to your Terraform resource configuration if you desire protection from accidental deletion.\n\n## Example Usage\n\n```terraform\nresource \"aws_rds_cluster_instance\" \"cluster_instances\" {\n  count              = 2\n  identifier         = \"aurora-cluster-demo-${count.index}\"\n  cluster_identifier = aws_rds_cluster.default.id\n  instance_class     = \"db.r4.large\"\n  engine             = aws_rds_cluster.default.engine\n  engine_version     = aws_rds_cluster.default.engine_version\n}\n\nresource \"aws_rds_cluster\" \"default\" {\n  cluster_identifier = \"aurora-cluster-demo\"\n  availability_zones = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n  database_name      = \"mydb\"\n  master_username    = \"foo\"\n  master_password    = \"barbut8chars\"\n}\n```\n\n## Argument Reference\n\nFor more detailed documentation about each argument, refer to\nthe [AWS official documentation](https://docs.aws.amazon.com/cli/latest/reference/rds/create-db-instance.html).\n\nThe following arguments are supported:\n\n* `identifier` - (Optional, Forces new resource) The identifier for the RDS instance, if omitted, Terraform will assign a random, unique identifier.\n* `identifier_prefix` - (Optional, Forces new resource) Creates a unique identifier beginning with the specified prefix. Conflicts with `identifier`.\n* `cluster_identifier` - (Required, Forces new resource) The identifier of the [`aws_rds_cluster`](/docs/providers/aws/r/rds_cluster.html) in which to launch this instance.\n* `engine` - (Optional, Forces new resource) The name of the database engine to be used for the RDS instance. Defaults to `aurora`. Valid Values: `aurora`, `aurora-mysql`, `aurora-postgresql`.\nFor information on the difference between the available Aurora MySQL engines\nsee [Comparison between Aurora MySQL 1 and Aurora MySQL 2](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.Updates.20180206.html)\nin the Amazon RDS User Guide.\n* `engine_version` - (Optional) The database engine version.\n* `instance_class` - (Required) The instance class to use. For details on CPU\nand memory, see [Scaling Aurora DB Instances][4]. Aurora uses `db.*` instance classes/types. Please see [AWS Documentation][7] for currently available instance classes and complete details.\n* `publicly_accessible` - (Optional) Bool to control if instance is publicly accessible.\nDefault `false`. See the documentation on [Creating DB Instances][6] for more\ndetails on controlling this property.\n* `db_subnet_group_name` - (Required if `publicly_accessible = false`, Optional otherwise, Forces new resource) A DB subnet group to associate with this DB instance. **NOTE:** This must match the `db_subnet_group_name` of the attached [`aws_rds_cluster`](/docs/providers/aws/r/rds_cluster.html).\n* `db_parameter_group_name` - (Optional) The name of the DB parameter group to associate with this instance.\n* `apply_immediately` - (Optional) Specifies whether any database modifications\n     are applied immediately, or during the next maintenance window. Default is`false`.\n* `monitoring_role_arn` - (Optional) The ARN for the IAM role that permits RDS to send\nenhanced monitoring metrics to CloudWatch Logs. You can find more information on the [AWS Documentation](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html)\nwhat IAM permissions are needed to allow Enhanced Monitoring for RDS Instances.\n* `monitoring_interval` - (Optional) The interval, in seconds, between points when Enhanced Monitoring metrics are collected for the DB instance. To disable collecting Enhanced Monitoring metrics, specify 0. The default is 0. Valid Values: 0, 1, 5, 10, 15, 30, 60.\n* `promotion_tier` - (Optional) Default 0. Failover Priority setting on instance level. The reader who has lower tier has higher priority to get promoted to writer.\n* `availability_zone` - (Optional, Computed, Forces new resource) The EC2 Availability Zone that the DB instance is created in. See [docs](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBInstance.html) about the details.\n* `preferred_backup_window` - (Optional) The daily time range during which automated backups are created if automated backups are enabled.\n  Eg: \"04:00-09:00\"\n* `preferred_maintenance_window` - (Optional) The window to perform maintenance in.\n  Syntax: \"ddd:hh24:mi-ddd:hh24:mi\". Eg: \"Mon:00:00-Mon:03:00\".\n* `auto_minor_version_upgrade` - (Optional) Indicates that minor engine upgrades will be applied automatically to the DB instance during the maintenance window. Default `true`.\n* `performance_insights_enabled` - (Optional) Specifies whether Performance Insights is enabled or not.\n* `performance_insights_kms_key_id` - (Optional) ARN for the KMS key to encrypt Performance Insights data. When specifying `performance_insights_kms_key_id`, `performance_insights_enabled` needs to be set to true.\n* `performance_insights_retention_period` - (Optional) Amount of time in days to retain Performance Insights data. Either 7 (7 days) or 731 (2 years). When specifying `performance_insights_retention_period`, `performance_insights_enabled` needs to be set to true. Defaults to '7'.\n* `copy_tags_to_snapshot` – (Optional, boolean) Indicates whether to copy all of the user-defined tags from the DB instance to snapshots of the DB instance. Default `false`.\n* `ca_cert_identifier` - (Optional) The identifier of the CA certificate for the DB instance.\n* `tags` - (Optional) A map of tags to assign to the instance. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of cluster instance\n* `cluster_identifier` - The RDS Cluster Identifier\n* `identifier` - The Instance identifier\n* `id` - The Instance identifier\n* `writer` – Boolean indicating if this instance is writable. `False` indicates this instance is a read replica.\n* `availability_zone` - The availability zone of the instance\n* `endpoint` - The DNS address for this instance. May not be writable\n* `engine` - The database engine\n* `engine_version_actual` - The database engine version\n* `port` - The database port\n* `storage_encrypted` - Specifies whether the DB cluster is encrypted.\n* `kms_key_id` - The ARN for the KMS encryption key if one is set to the cluster.\n* `dbi_resource_id` - The region-unique, immutable identifier for the DB instance.\n* `performance_insights_enabled` - Specifies whether Performance Insights is enabled or not.\n* `performance_insights_kms_key_id` - The ARN for the KMS encryption key used by Performance Insights.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[2]: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Aurora.html\n[3]: /docs/providers/aws/r/rds_cluster.html\n[4]: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Aurora.Managing.html\n[5]: https://www.terraform.io/docs/configuration/meta-arguments/count.html\n[6]: https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBInstance.html\n[7]: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html\n\n## Timeouts\n\n`aws_rds_cluster_instance` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `90 minutes`) Used for Creating Instances, Replicas, and\nrestoring from Snapshots\n- `update` - (Default `90 minutes`) Used for Database modifications\n- `delete` - (Default `90 minutes`) Used for destroying databases. This includes\nthe time required to take snapshots\n\n## Import\n\nRDS Cluster Instances can be imported using the `identifier`, e.g.,\n\n```\n$ terraform import aws_rds_cluster_instance.prod_instance_1 aurora-cluster-instance-1\n```\n",
    "basename": "rds_cluster_instance.html"
  },
  "rds_cluster_parameter_group": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_rds_cluster_parameter_group",
    "description": "Provides an RDS DB cluster parameter group resource.",
    "preview": "# Resource: aws_rds_cluster_parameter_group\n\nProvides an RDS DB …",
    "content": "\n\n# Resource: aws_rds_cluster_parameter_group\n\nProvides an RDS DB cluster parameter group resource. Documentation of the available parameters for various Aurora engines can be found at:\n\n* [Aurora MySQL Parameters](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraMySQL.Reference.html)\n* [Aurora PostgreSQL Parameters](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AuroraPostgreSQL.Reference.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_rds_cluster_parameter_group\" \"default\" {\n  name        = \"rds-cluster-pg\"\n  family      = \"aurora5.6\"\n  description = \"RDS default cluster parameter group\"\n\n  parameter {\n    name  = \"character_set_server\"\n    value = \"utf8\"\n  }\n\n  parameter {\n    name  = \"character_set_client\"\n    value = \"utf8\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the DB cluster parameter group. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `family` - (Required) The family of the DB cluster parameter group.\n* `description` - (Optional) The description of the DB cluster parameter group. Defaults to \"Managed by Terraform\".\n* `parameter` - (Optional) A list of DB parameters to apply. Note that parameters may differ from a family to an other. Full list of all parameters can be discovered via [`aws rds describe-db-cluster-parameters`](https://docs.aws.amazon.com/cli/latest/reference/rds/describe-db-cluster-parameters.html) after initial creation of the group.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nParameter blocks support the following:\n\n* `name` - (Required) The name of the DB parameter.\n* `value` - (Required) The value of the DB parameter.\n* `apply_method` - (Optional) \"immediate\" (default), or \"pending-reboot\". Some\n    engines can't apply some parameters without a reboot, and you will need to\n    specify \"pending-reboot\" here.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The db cluster parameter group name.\n* `arn` - The ARN of the db cluster parameter group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRDS Cluster Parameter Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_rds_cluster_parameter_group.cluster_pg production-pg-1\n```\n",
    "basename": "rds_cluster_parameter_group"
  },
  "rds_cluster_role_association.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_rds_cluster_role_association",
    "description": "Manages a RDS DB Cluster association with an IAM Role.",
    "preview": "# Resource: aws_rds_cluster_role_association\n\nManages a RDS DB …",
    "content": "\n\n# Resource: aws_rds_cluster_role_association\n\nManages a RDS DB Cluster association with an IAM Role. Example use cases:\n\n* [Creating an IAM Role to Allow Amazon Aurora to Access AWS Services](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Integrating.Authorizing.IAM.CreateRole.html)\n* [Importing Amazon S3 Data into an RDS PostgreSQL DB Cluster](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PostgreSQL.S3Import.html)\n\n## Example Usage\n\n```terraform\nresource \"aws_rds_cluster_role_association\" \"example\" {\n  db_cluster_identifier = aws_rds_cluster.example.id\n  feature_name          = \"S3_INTEGRATION\"\n  role_arn              = aws_iam_role.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `db_cluster_identifier` - (Required) DB Cluster Identifier to associate with the IAM Role.\n* `feature_name` - (Required) Name of the feature for association. This can be found in the AWS documentation relevant to the integration or a full list is available in the `SupportedFeatureNames` list returned by [AWS CLI rds describe-db-engine-versions](https://docs.aws.amazon.com/cli/latest/reference/rds/describe-db-engine-versions.html).\n* `role_arn` - (Required) Amazon Resource Name (ARN) of the IAM Role to associate with the DB Cluster.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - DB Cluster Identifier and IAM Role ARN separated by a comma (`,`)\n\n## Import\n\n`aws_rds_cluster_role_association` can be imported using the DB Cluster Identifier and IAM Role ARN separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_rds_cluster_role_association.example my-db-cluster,arn:aws:iam::123456789012:role/my-role\n```\n",
    "basename": "rds_cluster_role_association.html"
  },
  "rds_global_cluster.html": {
    "subcategory": "RDS",
    "layout": "aws",
    "page_title": "AWS: aws_rds_global_cluster",
    "description": "Manages an RDS Global Cluster",
    "preview": "# Resource: aws_rds_global_cluster\n\nManages an RDS Global Cluster, …",
    "content": "\n\n# Resource: aws_rds_global_cluster\n\nManages an RDS Global Cluster, which is an Aurora global database spread across multiple regions. The global database contains a single primary cluster with read-write capability, and a read-only secondary cluster that receives data from the primary cluster through high-speed replication performed by the Aurora storage subsystem.\n\nMore information about Aurora global databases can be found in the [Aurora User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html#aurora-global-database-creating).\n\n## Example Usage\n\n### New MySQL Global Cluster\n\n```terraform\nresource \"aws_rds_global_cluster\" \"example\" {\n  global_cluster_identifier = \"global-test\"\n  engine                    = \"aurora\"\n  engine_version            = \"5.6.mysql_aurora.1.22.2\"\n  database_name             = \"example_db\"\n}\n\nresource \"aws_rds_cluster\" \"primary\" {\n  provider                  = aws.primary\n  engine                    = aws_rds_global_cluster.example.engine\n  engine_version            = aws_rds_global_cluster.example.engine_version\n  cluster_identifier        = \"test-primary-cluster\"\n  master_username           = \"username\"\n  master_password           = \"somepass123\"\n  database_name             = \"example_db\"\n  global_cluster_identifier = aws_rds_global_cluster.example.id\n  db_subnet_group_name      = \"default\"\n}\n\nresource \"aws_rds_cluster_instance\" \"primary\" {\n  provider             = aws.primary\n  engine               = aws_rds_global_cluster.example.engine\n  engine_version       = aws_rds_global_cluster.example.engine_version\n  identifier           = \"test-primary-cluster-instance\"\n  cluster_identifier   = aws_rds_cluster.primary.id\n  instance_class       = \"db.r4.large\"\n  db_subnet_group_name = \"default\"\n}\n\nresource \"aws_rds_cluster\" \"secondary\" {\n  provider                  = aws.secondary\n  engine                    = aws_rds_global_cluster.example.engine\n  engine_version            = aws_rds_global_cluster.example.engine_version\n  cluster_identifier        = \"test-secondary-cluster\"\n  global_cluster_identifier = aws_rds_global_cluster.example.id\n  db_subnet_group_name      = \"default\"\n}\n\nresource \"aws_rds_cluster_instance\" \"secondary\" {\n  provider             = aws.secondary\n  engine               = aws_rds_global_cluster.example.engine\n  engine_version       = aws_rds_global_cluster.example.engine_version\n  identifier           = \"test-secondary-cluster-instance\"\n  cluster_identifier   = aws_rds_cluster.secondary.id\n  instance_class       = \"db.r4.large\"\n  db_subnet_group_name = \"default\"\n\n  depends_on = [\n    aws_rds_cluster_instance.primary\n  ]\n}\n```\n\n### New PostgreSQL Global Cluster\n\n\n```terraform\nprovider \"aws\" {\n  alias  = \"primary\"\n  region = \"us-east-2\"\n}\n\nprovider \"aws\" {\n  alias  = \"secondary\"\n  region = \"us-east-1\"\n}\n\nresource \"aws_rds_global_cluster\" \"example\" {\n  global_cluster_identifier = \"global-test\"\n  engine                    = \"aurora-postgresql\"\n  engine_version            = \"11.9\"\n  database_name             = \"example_db\"\n}\n\nresource \"aws_rds_cluster\" \"primary\" {\n  provider                  = aws.primary\n  engine                    = aws_rds_global_cluster.example.engine\n  engine_version            = aws_rds_global_cluster.example.engine_version\n  cluster_identifier        = \"test-primary-cluster\"\n  master_username           = \"username\"\n  master_password           = \"somepass123\"\n  database_name             = \"example_db\"\n  global_cluster_identifier = aws_rds_global_cluster.example.id\n  db_subnet_group_name      = \"default\"\n}\n\nresource \"aws_rds_cluster_instance\" \"primary\" {\n  provider             = aws.primary\n  engine               = aws_rds_global_cluster.example.engine\n  engine_version       = aws_rds_global_cluster.example.engine_version\n  identifier           = \"test-primary-cluster-instance\"\n  cluster_identifier   = aws_rds_cluster.primary.id\n  instance_class       = \"db.r4.large\"\n  db_subnet_group_name = \"default\"\n}\n\nresource \"aws_rds_cluster\" \"secondary\" {\n  provider                  = aws.secondary\n  engine                    = aws_rds_global_cluster.example.engine\n  engine_version            = aws_rds_global_cluster.example.engine_version\n  cluster_identifier        = \"test-secondary-cluster\"\n  global_cluster_identifier = aws_rds_global_cluster.example.id\n  skip_final_snapshot       = true\n  db_subnet_group_name      = \"default\"\n\n  depends_on = [\n    aws_rds_cluster_instance.primary\n  ]\n}\n\nresource \"aws_rds_cluster_instance\" \"secondary\" {\n  provider             = aws.secondary\n  engine               = aws_rds_global_cluster.example.engine\n  engine_version       = aws_rds_global_cluster.example.engine_version\n  identifier           = \"test-secondary-cluster-instance\"\n  cluster_identifier   = aws_rds_cluster.secondary.id\n  instance_class       = \"db.r4.large\"\n  db_subnet_group_name = \"default\"\n}\n```\n\n\n### New Global Cluster From Existing DB Cluster\n\n```terraform\nresource \"aws_rds_cluster\" \"example\" {\n  # ... other configuration ...\n\n  # NOTE: Using this DB Cluster to create a Global Cluster, the\n  # global_cluster_identifier attribute will become populated and\n  # Terraform will begin showing it as a difference. Do not configure:\n  # global_cluster_identifier = aws_rds_global_cluster.example.id\n  # as it creates a circular reference. Use ignore_changes instead.\n  lifecycle {\n    ignore_changes = [global_cluster_identifier]\n  }\n}\n\nresource \"aws_rds_global_cluster\" \"example\" {\n  force_destroy                = true\n  global_cluster_identifier    = \"example\"\n  source_db_cluster_identifier = aws_rds_cluster.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `global_cluster_identifier` - (Required, Forces new resources) The global cluster identifier.\n* `database_name` - (Optional, Forces new resources) Name for an automatically created database on cluster creation.\n* `deletion_protection` - (Optional) If the Global Cluster should have deletion protection enabled. The database can't be deleted when this value is set to `true`. The default is `false`.\n* `engine` - (Optional, Forces new resources) Name of the database engine to be used for this DB cluster. Terraform will only perform drift detection if a configuration value is provided. Valid values: `aurora`, `aurora-mysql`, `aurora-postgresql`. Defaults to `aurora`. Conflicts with `source_db_cluster_identifier`.\n* `engine_version` - (Optional) Engine version of the Aurora global database. Upgrading the engine version will result in all cluster members being immediately updated.\n    * **NOTE:** When the engine is set to `aurora-mysql`, an engine version compatible with global database is required. The earliest available version is `5.7.mysql_aurora.2.06.0`.\n* `force_destroy` - (Optional) Enable to remove DB Cluster members from Global Cluster on destroy. Required with `source_db_cluster_identifier`.\n* `source_db_cluster_identifier` - (Optional) Amazon Resource Name (ARN) to use as the primary DB Cluster of the Global Cluster on creation. Terraform cannot perform drift detection of this value.\n* `storage_encrypted` - (Optional, Forces new resources) Specifies whether the DB cluster is encrypted. The default is `false` unless `source_db_cluster_identifier` is specified and encrypted. Terraform will only perform drift detection if a configuration value is provided.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - RDS Global Cluster Amazon Resource Name (ARN)\n* `global_cluster_members` - Set of objects containing Global Cluster members.\n    * `db_cluster_arn` - Amazon Resource Name (ARN) of member DB Cluster\n    * `is_writer` - Whether the member is the primary DB Cluster\n* `global_cluster_resource_id` - AWS Region-unique, immutable identifier for the global database cluster. This identifier is found in AWS CloudTrail log entries whenever the AWS KMS key for the DB cluster is accessed\n* `id` - RDS Global Cluster identifier\n\n## Import\n\n`aws_rds_global_cluster` can be imported by using the RDS Global Cluster identifier, e.g.,\n\n```\n$ terraform import aws_rds_global_cluster.example example\n```\n\nCertain resource arguments, like `force_destroy`, only exist within Terraform. If the argument is set in the Terraform configuration on an imported resource, Terraform will show a difference on the first plan after import to update the state value. This change is safe to apply immediately so the state matches the desired configuration.\n\nCertain resource arguments, like `source_db_cluster_identifier`, do not have an API method for reading the information after creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_rds_global_cluster\" \"example\" {\n  # ... other configuration ...\n\n  # There is no API for reading source_db_cluster_identifier\n  lifecycle {\n    ignore_changes = [source_db_cluster_identifier]\n  }\n}\n```\n",
    "basename": "rds_global_cluster.html"
  },
  "redshift_cluster.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_cluster",
    "description": "Provides a Redshift Cluster resource.",
    "preview": "# Resource: aws_redshift_cluster\n\nProvides a Redshift Cluster …",
    "content": "\n\n# Resource: aws_redshift_cluster\n\nProvides a Redshift Cluster Resource.\n\n~> **Note:** All arguments including the username and password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_redshift_cluster\" \"default\" {\n  cluster_identifier = \"tf-redshift-cluster\"\n  database_name      = \"mydb\"\n  master_username    = \"foo\"\n  master_password    = \"Mustbe8characters\"\n  node_type          = \"dc1.large\"\n  cluster_type       = \"single-node\"\n}\n```\n\n## Argument Reference\n\nFor more detailed documentation about each argument, refer to\nthe [AWS official documentation](http://docs.aws.amazon.com/cli/latest/reference/redshift/index.html#cli-aws-redshift).\n\nThe following arguments are supported:\n\n* `cluster_identifier` - (Required) The Cluster Identifier. Must be a lower case\nstring.\n* `database_name` - (Optional) The name of the first database to be created when the cluster is created.\n If you do not provide a name, Amazon Redshift will create a default database called `dev`.\n* `node_type` - (Required) The node type to be provisioned for the cluster.\n* `cluster_type` - (Optional) The cluster type to use. Either `single-node` or `multi-node`.\n* `master_password` - (Required unless a `snapshot_identifier` is provided) Password for the master DB user.\n    Note that this may show up in logs, and it will be stored in the state file. Password must contain at least 8 chars and\n    contain at least one uppercase letter, one lowercase letter, and one number.\n* `master_username` - (Required unless a `snapshot_identifier` is provided) Username for the master DB user.\n\n* `cluster_security_groups` - (Optional) A list of security groups to be associated with this cluster.\n* `vpc_security_group_ids` - (Optional) A list of Virtual Private Cloud (VPC) security groups to be associated with the cluster.\n* `cluster_subnet_group_name` - (Optional) The name of a cluster subnet group to be associated with this cluster. If this parameter is not provided the resulting cluster will be deployed outside virtual private cloud (VPC).\n* `availability_zone` - (Optional) The EC2 Availability Zone (AZ) in which you want Amazon Redshift to provision the cluster. For example, if you have several EC2 instances running in a specific Availability Zone, then you might want the cluster to be provisioned in the same zone in order to decrease network latency.\n* `preferred_maintenance_window` - (Optional) The weekly time range (in UTC) during which automated cluster maintenance can occur.\n                                              Format: ddd:hh24:mi-ddd:hh24:mi\n* `cluster_parameter_group_name` - (Optional) The name of the parameter group to be associated with this cluster.\n* `automated_snapshot_retention_period` - (Optional) The number of days that automated snapshots are retained. If the value is 0, automated snapshots are disabled. Even if automated snapshots are disabled, you can still create manual snapshots when you want with create-cluster-snapshot. Default is 1.\n* `port` - (Optional) The port number on which the cluster accepts incoming connections.\n                      The cluster is accessible only via the JDBC and ODBC connection strings. Part of the connection string requires the port on which the cluster will listen for incoming connections. Default port is 5439.\n* `cluster_version` - (Optional) The version of the Amazon Redshift engine software that you want to deploy on the cluster.\n                                 The version selected runs on all the nodes in the cluster.\n* `allow_version_upgrade` - (Optional) If true , major version upgrades can be applied during the maintenance window to the Amazon Redshift engine that is running on the cluster. Default is true\n* `number_of_nodes` - (Optional) The number of compute nodes in the cluster. This parameter is required when the ClusterType parameter is specified as multi-node. Default is 1.\n* `publicly_accessible` - (Optional) If true, the cluster can be accessed from a public network. Default is `true`.\n* `encrypted` - (Optional) If true , the data in the cluster is encrypted at rest.\n* `enhanced_vpc_routing` - (Optional) If true , enhanced VPC routing is enabled.\n* `kms_key_id` - (Optional) The ARN for the KMS encryption key. When specifying `kms_key_id`, `encrypted` needs to be set to true.\n* `elastic_ip` - (Optional) The Elastic IP (EIP) address for the cluster.\n* `skip_final_snapshot` - (Optional) Determines whether a final snapshot of the cluster is created before Amazon Redshift deletes the cluster. If true , a final cluster snapshot is not created. If false , a final cluster snapshot is created before the cluster is deleted. Default is false.\n* `final_snapshot_identifier` - (Optional) The identifier of the final snapshot that is to be created immediately before deleting the cluster. If this parameter is provided, `skip_final_snapshot` must be false.\n* `snapshot_identifier` - (Optional) The name of the snapshot from which to create the new cluster.\n* `snapshot_cluster_identifier` - (Optional) The name of the cluster the source snapshot was created from.\n* `owner_account` - (Optional) The AWS customer account used to create or copy the snapshot. Required if you are restoring a snapshot you do not own, optional if you own the snapshot.\n* `iam_roles` - (Optional) A list of IAM Role ARNs to associate with the cluster. A Maximum of 10 can be associated to the cluster at any time.\n* `logging` - (Optional) Logging, documented below.\n* `snapshot_copy` - (Optional) Configuration of automatic copy of snapshots from one region to another. Documented below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Timeouts\n\n`aws_redshift_cluster` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `75 minutes`) Used for creating Clusters.\n- `update` - (Default `75 minutes`) Used for updating Clusters.\n- `delete` - (Default `40 minutes`) Used for destroying Clusters.\n\n### Nested Blocks\n\n#### `logging`\n\n* `enable` - (Required) Enables logging information such as queries and connection attempts, for the specified Amazon Redshift cluster.\n* `bucket_name` - (Optional, required when `enable` is `true`) The name of an existing S3 bucket where the log files are to be stored. Must be in the same region as the cluster and the cluster must have read bucket and put object permissions.\nFor more information on the permissions required for the bucket, please read the AWS [documentation](http://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html#db-auditing-enable-logging)\n* `s3_key_prefix` - (Optional) The prefix applied to the log file names.\n\n#### `snapshot_copy`\n\n* `destination_region` - (Required) The destination region that you want to copy snapshots to.\n* `retention_period` - (Optional) The number of days to retain automated snapshots in the destination region after they are copied from the source region. Defaults to `7`.\n* `grant_name` - (Optional) The name of the snapshot copy grant to use when snapshots of an AWS KMS-encrypted cluster are copied to the destination region.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of cluster\n* `id` - The Redshift Cluster ID.\n* `cluster_identifier` - The Cluster Identifier\n* `cluster_type` - The cluster type\n* `node_type` - The type of nodes in the cluster\n* `database_name` - The name of the default database in the Cluster\n* `availability_zone` - The availability zone of the Cluster\n* `automated_snapshot_retention_period` - The backup retention period\n* `preferred_maintenance_window` - The backup window\n* `endpoint` - The connection endpoint\n* `encrypted` - Whether the data in the cluster is encrypted\n* `cluster_security_groups` - The security groups associated with the cluster\n* `vpc_security_group_ids` - The VPC security group Ids associated with the cluster\n* `dns_name` - The DNS name of the cluster\n* `port` - The Port the cluster responds on\n* `cluster_version` - The version of Redshift engine software\n* `cluster_parameter_group_name` - The name of the parameter group to be associated with this cluster\n* `cluster_subnet_group_name` - The name of a cluster subnet group to be associated with this cluster\n* `cluster_public_key` - The public key for the cluster\n* `cluster_revision_number` - The specific revision number of the database in the cluster\n* `cluster_nodes` - The nodes in the cluster. Cluster node blocks are documented below\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\nCluster nodes (for `cluster_nodes`) support the following attributes:\n\n* `node_role` - Whether the node is a leader node or a compute node\n* `private_ip_address` - The private IP address of a node within a cluster\n* `public_ip_address` - The public IP address of a node within a cluster\n\n## Import\n\nRedshift Clusters can be imported using the `cluster_identifier`, e.g.,\n\n```\n$ terraform import aws_redshift_cluster.myprodcluster tf-redshift-cluster-12345\n```\n",
    "basename": "redshift_cluster.html"
  },
  "redshift_event_subscription.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_event_subscription",
    "description": "Provides a Redshift event subscription resource.",
    "preview": "# Resource: aws_redshift_event_subscription\n\nProvides a Redshift …",
    "content": "\n\n# Resource: aws_redshift_event_subscription\n\nProvides a Redshift event subscription resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_redshift_cluster\" \"default\" {\n  cluster_identifier = \"default\"\n  database_name      = \"default\"\n\n  # ...\n}\n\nresource \"aws_sns_topic\" \"default\" {\n  name = \"redshift-events\"\n}\n\nresource \"aws_redshift_event_subscription\" \"default\" {\n  name          = \"redshift-event-sub\"\n  sns_topic_arn = aws_sns_topic.default.arn\n\n  source_type = \"cluster\"\n  source_ids  = [aws_redshift_cluster.default.id]\n\n  severity = \"INFO\"\n\n  event_categories = [\n    \"configuration\",\n    \"management\",\n    \"monitoring\",\n    \"security\",\n  ]\n\n  tags = {\n    Name = \"default\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Redshift event subscription.\n* `sns_topic_arn` - (Required) The ARN of the SNS topic to send events to.\n* `source_ids` - (Optional) A list of identifiers of the event sources for which events will be returned. If not specified, then all sources are included in the response. If specified, a source_type must also be specified.\n* `source_type` - (Optional) The type of source that will be generating the events. Valid options are `cluster`, `cluster-parameter-group`, `cluster-security-group`, or `cluster-snapshot`. If not set, all sources will be subscribed to.\n* `severity` - (Optional) The event severity to be published by the notification subscription. Valid options are `INFO` or `ERROR`.\n* `event_categories` - (Optional) A list of event categories for a SourceType that you want to subscribe to. See https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-event-notifications.html or run `aws redshift describe-event-categories`.\n* `enabled` - (Optional) A boolean flag to enable/disable the subscription. Defaults to true.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the Redshift event notification subscription\n* `id` - The name of the Redshift event notification subscription\n* `customer_aws_id` - The AWS customer account associated with the Redshift event notification subscription\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRedshift Event Subscriptions can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_redshift_event_subscription.default redshift-event-sub\n```\n",
    "basename": "redshift_event_subscription.html"
  },
  "redshift_parameter_group.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_parameter_group",
    "description": "Provides a Redshift Cluster parameter group resource.",
    "preview": "# Resource: aws_redshift_parameter_group\n\nProvides a Redshift …",
    "content": "\n\n# Resource: aws_redshift_parameter_group\n\nProvides a Redshift Cluster parameter group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_redshift_parameter_group\" \"bar\" {\n  name   = \"parameter-group-test-terraform\"\n  family = \"redshift-1.0\"\n\n  parameter {\n    name  = \"require_ssl\"\n    value = \"true\"\n  }\n\n  parameter {\n    name  = \"query_group\"\n    value = \"example\"\n  }\n\n  parameter {\n    name  = \"enable_user_activity_logging\"\n    value = \"true\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Redshift parameter group.\n* `family` - (Required) The family of the Redshift parameter group.\n* `description` - (Optional) The description of the Redshift parameter group. Defaults to \"Managed by Terraform\".\n* `parameter` - (Optional) A list of Redshift parameters to apply.\n\nParameter blocks support the following:\n\n* `name` - (Required) The name of the Redshift parameter.\n* `value` - (Required) The value of the Redshift parameter.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nYou can read more about the parameters that Redshift supports in the [documentation](http://docs.aws.amazon.com/redshift/latest/mgmt/working-with-parameter-groups.html)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of parameter group\n* `id` - The Redshift parameter group name.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRedshift Parameter Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_redshift_parameter_group.paramgroup1 parameter-group-test-terraform\n```\n",
    "basename": "redshift_parameter_group.html"
  },
  "redshift_scheduled_action.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_scheduled_action",
    "description": "Provides a Redshift Scheduled Action resource.",
    "preview": "# Resource: aws_redshift_scheduled_action\n\n## Example Usage\n\n### …",
    "content": "\n\n# Resource: aws_redshift_scheduled_action\n\n## Example Usage\n\n### Pause Cluster Action\n\n```terraform\nresource \"aws_iam_role\" \"example\" {\n  name               = \"redshift_scheduled_action\"\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": [\n          \"scheduler.redshift.amazonaws.com\"\n        ]\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_policy\" \"example\" {\n  name   = \"redshift_scheduled_action\"\n  policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n      {\n          \"Sid\": \"VisualEditor0\",\n          \"Effect\": \"Allow\",\n          \"Action\": [\n              \"redshift:PauseCluster\",\n              \"redshift:ResumeCluster\",\n              \"redshift:ResizeCluster\"\n          ],\n          \"Resource\": \"*\"\n      }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"example\" {\n  policy_arn = aws_iam_policy.example.arn\n  role       = aws_iam_role.example.name\n}\n\nresource \"aws_redshift_scheduled_action\" \"example\" {\n  name     = \"tf-redshift-scheduled-action\"\n  schedule = \"cron(00 23 * * ? *)\"\n  iam_role = aws_iam_role.example.arn\n\n  target_action {\n    pause_cluster {\n      cluster_identifier = \"tf-redshift001\"\n    }\n  }\n}\n```\n\n### Resize Cluster Action\n\n```terraform\nresource \"aws_redshift_scheduled_action\" \"example\" {\n  name     = \"tf-redshift-scheduled-action\"\n  schedule = \"cron(00 23 * * ? *)\"\n  iam_role = aws_iam_role.example.arn\n\n  target_action {\n    resize_cluster {\n      cluster_identifier = \"tf-redshift001\"\n      cluster_type       = \"multi-node\"\n      node_type          = \"dc1.large\"\n      number_of_nodes    = 2\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The scheduled action name.\n* `description` - (Optional) The description of the scheduled action.\n* `enable` - (Optional) Whether to enable the scheduled action. Default is `true` .\n* `start_time` - (Optional) The start time in UTC when the schedule is active, in UTC RFC3339 format(for example, YYYY-MM-DDTHH:MM:SSZ).\n* `end_time` - (Optional) The end time in UTC when the schedule is active, in UTC RFC3339 format(for example, YYYY-MM-DDTHH:MM:SSZ).\n* `schedule` - (Required) The schedule of action. The schedule is defined format of \"at expression\" or \"cron expression\", for example `at(2016-03-04T17:27:00)` or `cron(0 10 ? * MON *)`. See [Scheduled Action](https://docs.aws.amazon.com/redshift/latest/APIReference/API_ScheduledAction.html) for more information.\n* `iam_role` - (Required) The IAM role to assume to run the scheduled action.\n* `target_action` - (Required) Target action. Documented below.\n\n### Nested Blocks\n\n#### `target_action`\n\n* `pause_cluster` - (Optional) An action that runs a `PauseCluster` API operation. Documented below.\n* `resize_cluster` - (Optional) An action that runs a `ResizeCluster` API operation. Documented below.\n* `resume_cluster` - (Optional) An action that runs a `ResumeCluster` API operation. Documented below.\n\n### `pause_cluster`\n\n* `cluster_identifier` - (Required) The identifier of the cluster to be paused.\n\n### `resize_cluster`\n\n* `cluster_identifier` - (Required) The unique identifier for the cluster to resize.\n* `classic` - (Optional) A boolean value indicating whether the resize operation is using the classic resize process. Default: `false`.\n* `cluster_type` - (Optional)　The new cluster type for the specified cluster.\n* `node_type` - (Optional) The new node type for the nodes you are adding.\n* `number_of_nodes` - (Optional) The new number of nodes for the cluster.\n\n### `resume_cluster`\n\n* `cluster_identifier` - (Required) The identifier of the cluster to be resumed.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Redshift Scheduled Action name.\n\n## Import\n\nRedshift Scheduled Action can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_redshift_scheduled_action.example tf-redshift-scheduled-action\n```\n",
    "basename": "redshift_scheduled_action.html"
  },
  "redshift_security_group.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_security_group",
    "description": "Provides a Redshift security group resource.",
    "preview": "# Resource: aws_redshift_security_group\n\nCreates a new Amazon …",
    "content": "\n\n# Resource: aws_redshift_security_group\n\nCreates a new Amazon Redshift security group. You use security groups to control access to non-VPC clusters\n\n## Example Usage\n\n```terraform\nresource \"aws_redshift_security_group\" \"default\" {\n  name = \"redshift-sg\"\n\n  ingress {\n    cidr = \"10.0.0.0/24\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Redshift security group.\n* `description` - (Optional) The description of the Redshift security group. Defaults to \"Managed by Terraform\".\n* `ingress` - (Optional) A list of ingress rules.\n\nIngress blocks support the following:\n\n* `cidr` - The CIDR block to accept\n* `security_group_name` - The name of the security group to authorize\n* `security_group_owner_id` - The owner Id of the security group provided\n  by `security_group_name`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Redshift security group ID.\n\n## Import\n\nRedshift security groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_redshift_security_group.testgroup1 redshift_test_group\n```\n",
    "basename": "redshift_security_group.html"
  },
  "redshift_snapshot_copy_grant.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_snapshot_copy_grant",
    "description": "Creates a snapshot copy grant that allows AWS Redshift to encrypt copied snapshots with a customer master key from AWS KMS in a destination region.",
    "preview": "# Resource: aws_redshift_snapshot_copy_grant\n\nCreates a snapshot …",
    "content": "\n\n# Resource: aws_redshift_snapshot_copy_grant\n\nCreates a snapshot copy grant that allows AWS Redshift to encrypt copied snapshots with a customer master key from AWS KMS in a destination region.\n\nNote that the grant must exist in the destination region, and not in the region of the cluster.\n\n## Example Usage\n\n```terraform\nresource \"aws_redshift_snapshot_copy_grant\" \"test\" {\n  snapshot_copy_grant_name = \"my-grant\"\n}\n\nresource \"aws_redshift_cluster\" \"test\" {\n  # ... other configuration ...\n  snapshot_copy {\n    destination_region = \"us-east-2\"\n    grant_name         = aws_redshift_snapshot_copy_grant.test.snapshot_copy_grant_name\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `snapshot_copy_grant_name` - (Required, Forces new resource) A friendly name for identifying the grant.\n* `kms_key_id` - (Optional, Forces new resource) The unique identifier for the customer master key (CMK) that the grant applies to. Specify the key ID or the Amazon Resource Name (ARN) of the CMK. To specify a CMK in a different AWS account, you must use the key ARN. If not specified, the default key is used.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of snapshot copy grant\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRedshift Snapshot Copy Grants support import by name, e.g.,\n\n```console\n$ terraform import aws_redshift_snapshot_copy_grant.test my-grant\n```\n",
    "basename": "redshift_snapshot_copy_grant.html"
  },
  "redshift_snapshot_schedule.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_snapshot_schedule",
    "description": "Provides an Redshift Snapshot Schedule resource.",
    "preview": "# Resource: aws_redshift_snapshot_schedule\n\n## Example Usage\n …",
    "content": "\n\n# Resource: aws_redshift_snapshot_schedule\n\n## Example Usage\n\n```terraform\nresource \"aws_redshift_snapshot_schedule\" \"default\" {\n  identifier = \"tf-redshift-snapshot-schedule\"\n  definitions = [\n    \"rate(12 hours)\",\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `identifier` - (Optional, Forces new resource) The snapshot schedule identifier. If omitted, Terraform will assign a random, unique identifier.\n* `identifier_prefix` - (Optional, Forces new resource) Creates a unique\nidentifier beginning with the specified prefix. Conflicts with `identifier`.\n* `description` - (Optional) The description of the snapshot schedule.\n* `definitions` - (Optional) The definition of the snapshot schedule. The definition is made up of schedule expressions, for example `cron(30 12 *)` or `rate(12 hours)`.\n* `force_destroy` - (Optional) Whether to destroy all associated clusters with this snapshot schedule on deletion. Must be enabled and applied before attempting deletion.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the Redshift Snapshot Schedule.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRedshift Snapshot Schedule can be imported using the `identifier`, e.g.,\n\n```\n$ terraform import aws_redshift_snapshot_schedule.default tf-redshift-snapshot-schedule\n```\n",
    "basename": "redshift_snapshot_schedule.html"
  },
  "redshift_snapshot_schedule_association.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_snapshot_schedule_association",
    "description": "Provides an Association Redshift Cluster and Snapshot Schedule resource.",
    "preview": "# Resource: aws_redshift_snapshot_schedule_association\n\n## Example …",
    "content": "\n\n# Resource: aws_redshift_snapshot_schedule_association\n\n## Example Usage\n\n```terraform\nresource \"aws_redshift_cluster\" \"default\" {\n  cluster_identifier = \"tf-redshift-cluster\"\n  database_name      = \"mydb\"\n  master_username    = \"foo\"\n  master_password    = \"Mustbe8characters\"\n  node_type          = \"dc1.large\"\n  cluster_type       = \"single-node\"\n}\n\nresource \"aws_redshift_snapshot_schedule\" \"default\" {\n  identifier = \"tf-redshift-snapshot-schedule\"\n  definitions = [\n    \"rate(12 hours)\",\n  ]\n}\n\nresource \"aws_redshift_snapshot_schedule_association\" \"default\" {\n  cluster_identifier  = aws_redshift_cluster.default.id\n  schedule_identifier = aws_redshift_snapshot_schedule.default.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cluster_identifier` - (Required, Forces new resource) The cluster identifier.\n* `schedule_identifier` - (Required, Forces new resource) The snapshot schedule identifier.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nRedshift Snapshot Schedule Association can be imported using the `<cluster-identifier>/<schedule-identifier>`, e.g.,\n\n```\n$ terraform import aws_redshift_snapshot_schedule_association.default tf-redshift-cluster/tf-redshift-snapshot-schedule\n```\n",
    "basename": "redshift_snapshot_schedule_association.html"
  },
  "redshift_subnet_group.html": {
    "subcategory": "Redshift",
    "layout": "aws",
    "page_title": "AWS: aws_redshift_subnet_group",
    "description": "Provides a Redshift Subnet Group resource.",
    "preview": "# Resource: aws_redshift_subnet_group\n\nCreates a new Amazon Redshift …",
    "content": "\n\n# Resource: aws_redshift_subnet_group\n\nCreates a new Amazon Redshift subnet group. You must provide a list of one or more subnets in your existing Amazon Virtual Private Cloud (Amazon VPC) when creating Amazon Redshift subnet group.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"foo\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_subnet\" \"foo\" {\n  cidr_block        = \"10.1.1.0/24\"\n  availability_zone = \"us-west-2a\"\n  vpc_id            = aws_vpc.foo.id\n\n  tags = {\n    Name = \"tf-dbsubnet-test-1\"\n  }\n}\n\nresource \"aws_subnet\" \"bar\" {\n  cidr_block        = \"10.1.2.0/24\"\n  availability_zone = \"us-west-2b\"\n  vpc_id            = aws_vpc.foo.id\n\n  tags = {\n    Name = \"tf-dbsubnet-test-2\"\n  }\n}\n\nresource \"aws_redshift_subnet_group\" \"foo\" {\n  name       = \"foo\"\n  subnet_ids = [aws_subnet.foo.id, aws_subnet.bar.id]\n\n  tags = {\n    environment = \"Production\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the Redshift Subnet group.\n* `description` - (Optional) The description of the Redshift Subnet group. Defaults to \"Managed by Terraform\".\n* `subnet_ids` - (Required) An array of VPC subnet IDs.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the Redshift Subnet group name\n* `id` - The Redshift Subnet group ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRedshift subnet groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_redshift_subnet_group.testgroup1 test-cluster-subnet-group\n```\n",
    "basename": "redshift_subnet_group.html"
  },
  "resourcegroups_group.html": {
    "subcategory": "Resource Groups",
    "layout": "aws",
    "page_title": "AWS: aws_resourcegroups_group",
    "description": "Provides a Resource Group.",
    "preview": "# Resource: aws_resourcegroups_group\n\nProvides a Resource Group.\n\n## …",
    "content": "\n\n# Resource: aws_resourcegroups_group\n\nProvides a Resource Group.\n\n## Example Usage\n\n```terraform\nresource \"aws_resourcegroups_group\" \"test\" {\n  name = \"test-group\"\n\n  resource_query {\n    query = <<JSON\n{\n  \"ResourceTypeFilters\": [\n    \"AWS::EC2::Instance\"\n  ],\n  \"TagFilters\": [\n    {\n      \"Key\": \"Stage\",\n      \"Values\": [\"Test\"]\n    }\n  ]\n}\nJSON\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The resource group's name. A resource group name can have a maximum of 127 characters, including letters, numbers, hyphens, dots, and underscores. The name cannot start with `AWS` or `aws`.\n* `description` - (Optional) A description of the resource group.\n* `resource_query` - (Required) A `resource_query` block. Resource queries are documented below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nAn `resource_query` block supports the following arguments:\n\n* `query` - (Required) The resource query as a JSON string.\n* `type` - (Required) The type of the resource query. Defaults to `TAG_FILTERS_1_0`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN assigned by AWS for this resource group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nResource groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_resourcegroups_group.foo resource-group-name\n```\n",
    "basename": "resourcegroups_group.html"
  },
  "route.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_route",
    "description": "Provides a resource to create a routing entry in a VPC routing table.",
    "preview": "# Resource: aws_route\n\nProvides a resource to create a routing table …",
    "content": "\n\n# Resource: aws_route\n\nProvides a resource to create a routing table entry (a route) in a VPC routing table.\n\n~> **NOTE on Route Tables and Routes:** Terraform currently provides both a standalone Route resource and a [Route Table](route_table.html) resource with routes defined in-line. At this time you cannot use a Route Table with in-line routes in conjunction with any Route resources. Doing so will cause a conflict of rule settings and will overwrite rules.\n\n~> **NOTE on `gateway_id` attribute:** The AWS API is very forgiving with the resource ID passed in the `gateway_id` attribute. For example an `aws_route` resource can be created with an [`aws_nat_gateway`](nat_gateway.html) or [`aws_egress_only_internet_gateway`](egress_only_internet_gateway.html) ID specified for the `gateway_id` attribute. Specifying anything other than an [`aws_internet_gateway`](internet_gateway.html) or [`aws_vpn_gateway`](vpn_gateway.html) ID will lead to Terraform reporting a permanent diff between your configuration and recorded state, as the AWS API returns the more-specific attribute. If you are experiencing constant diffs with an `aws_route` resource, the first thing to check is that the correct attribute is being specified.\n\n## Example Usage\n\n```terraform\nresource \"aws_route\" \"r\" {\n  route_table_id            = \"rtb-4fbb3ac4\"\n  destination_cidr_block    = \"10.0.1.0/22\"\n  vpc_peering_connection_id = \"pcx-45ff3dc1\"\n  depends_on                = [aws_route_table.testing]\n}\n```\n\n## Example IPv6 Usage\n\n```terraform\nresource \"aws_vpc\" \"vpc\" {\n  cidr_block                       = \"10.1.0.0/16\"\n  assign_generated_ipv6_cidr_block = true\n}\n\nresource \"aws_egress_only_internet_gateway\" \"egress\" {\n  vpc_id = aws_vpc.vpc.id\n}\n\nresource \"aws_route\" \"r\" {\n  route_table_id              = \"rtb-4fbb3ac4\"\n  destination_ipv6_cidr_block = \"::/0\"\n  egress_only_gateway_id      = aws_egress_only_internet_gateway.egress.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `route_table_id` - (Required) The ID of the routing table.\n\nOne of the following destination arguments must be supplied:\n\n* `destination_cidr_block` - (Optional) The destination CIDR block.\n* `destination_ipv6_cidr_block` - (Optional) The destination IPv6 CIDR block.\n* `destination_prefix_list_id` - (Optional) The ID of a [managed prefix list](ec2_managed_prefix_list.html) destination.\n\nOne of the following target arguments must be supplied:\n\n* `carrier_gateway_id` - (Optional) Identifier of a carrier gateway. This attribute can only be used when the VPC contains a subnet which is associated with a Wavelength Zone.\n* `egress_only_gateway_id` - (Optional) Identifier of a VPC Egress Only Internet Gateway.\n* `gateway_id` - (Optional) Identifier of a VPC internet gateway or a virtual private gateway.\n* `instance_id` - (Optional) Identifier of an EC2 instance.\n* `nat_gateway_id` - (Optional) Identifier of a VPC NAT gateway.\n* `local_gateway_id` - (Optional) Identifier of a Outpost local gateway.\n* `network_interface_id` - (Optional) Identifier of an EC2 network interface.\n* `transit_gateway_id` - (Optional) Identifier of an EC2 Transit Gateway.\n* `vpc_endpoint_id` - (Optional) Identifier of a VPC Endpoint.\n* `vpc_peering_connection_id` - (Optional) Identifier of a VPC peering connection.\n\nNote that the default route, mapping the VPC's CIDR block to \"local\", is created implicitly and cannot be specified.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n~> **NOTE:** Only the arguments that are configured (one of the above) will be exported as an attribute once the resource is created.\n\n* `id` - Route identifier computed from the routing table identifier and route destination.\n* `instance_owner_id` - The AWS account ID of the owner of the EC2 instance.\n* `origin` - How the route was created - `CreateRouteTable`, `CreateRoute` or `EnableVgwRoutePropagation`.\n* `state` - The state of the route - `active` or `blackhole`.\n\n## Timeouts\n\n`aws_route` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `2 minutes`) Used for route creation\n- `update` - (Default `2 minutes`) Used for route creation\n- `delete` - (Default `5 minutes`) Used for route deletion\n\n## Import\n\nIndividual routes can be imported using `ROUTETABLEID_DESTINATION`.\n\nFor example, import a route in route table `rtb-656C65616E6F72` with an IPv4 destination CIDR of `10.42.0.0/16` like this:\n\n```console\n$ terraform import aws_route.my_route rtb-656C65616E6F72_10.42.0.0/16\n```\n\nImport a route in route table `rtb-656C65616E6F72` with an IPv6 destination CIDR of `2620:0:2d0:200::8/125` similarly:\n\n```console\n$ terraform import aws_route.my_route rtb-656C65616E6F72_2620:0:2d0:200::8/125\n```\n\nImport a route in route table `rtb-656C65616E6F72` with a managed prefix list destination of `pl-0570a1d2d725c16be` similarly:\n\n```console\n$ terraform import aws_route.my_route rtb-656C65616E6F72_pl-0570a1d2d725c16be\n```\n",
    "basename": "route.html"
  },
  "route53_delegation_set.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_delegation_set",
    "description": "Provides a Route53 Delegation Set resource.",
    "preview": "# Resource: aws_route53_delegation_set\n\nProvides a [Route53 …",
    "content": "\n\n# Resource: aws_route53_delegation_set\n\nProvides a [Route53 Delegation Set](https://docs.aws.amazon.com/Route53/latest/APIReference/API-actions-by-function.html#actions-by-function-reusable-delegation-sets) resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_delegation_set\" \"main\" {\n  reference_name = \"DynDNS\"\n}\n\nresource \"aws_route53_zone\" \"primary\" {\n  name              = \"hashicorp.com\"\n  delegation_set_id = aws_route53_delegation_set.main.id\n}\n\nresource \"aws_route53_zone\" \"secondary\" {\n  name              = \"terraform.io\"\n  delegation_set_id = aws_route53_delegation_set.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `reference_name` - (Optional) This is a reference name used in Caller Reference\n  (helpful for identifying single delegation set amongst others)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Delegation Set.\n* `id` - The delegation set ID\n* `name_servers` - A list of authoritative name servers for the hosted zone\n  (effectively a list of NS records).\n\n\n\n## Import\n\nRoute53 Delegation Sets can be imported using the `delegation set id`, e.g.,\n\n```\n$ terraform import aws_route53_delegation_set.set1 N1PA6795SAMPLE\n```\n",
    "basename": "route53_delegation_set.html"
  },
  "route53_health_check.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_health_check",
    "description": "Provides a Route53 health check.",
    "preview": "# Resource: aws_route53_health_check\n\nProvides a Route53 health …",
    "content": "\n# Resource: aws_route53_health_check\n\nProvides a Route53 health check.\n\n## Example Usage\n\n### Connectivity and HTTP Status Code Check\n\n```terraform\nresource \"aws_route53_health_check\" \"example\" {\n  fqdn              = \"example.com\"\n  port              = 80\n  type              = \"HTTP\"\n  resource_path     = \"/\"\n  failure_threshold = \"5\"\n  request_interval  = \"30\"\n\n  tags = {\n    Name = \"tf-test-health-check\"\n  }\n}\n```\n\n### Connectivity and String Matching Check\n\n```terraform\nresource \"aws_route53_health_check\" \"example\" {\n  failure_threshold = \"5\"\n  fqdn              = \"example.com\"\n  port              = 443\n  request_interval  = \"30\"\n  resource_path     = \"/\"\n  search_string     = \"example\"\n  type              = \"HTTPS_STR_MATCH\"\n}\n```\n\n### Aggregate Check\n\n```terraform\nresource \"aws_route53_health_check\" \"parent\" {\n  type                   = \"CALCULATED\"\n  child_health_threshold = 1\n  child_healthchecks     = [aws_route53_health_check.child.id]\n\n  tags = {\n    Name = \"tf-test-calculated-health-check\"\n  }\n}\n```\n\n### CloudWatch Alarm Check\n\n```terraform\nresource \"aws_cloudwatch_metric_alarm\" \"foobar\" {\n  alarm_name          = \"terraform-test-foobar5\"\n  comparison_operator = \"GreaterThanOrEqualToThreshold\"\n  evaluation_periods  = \"2\"\n  metric_name         = \"CPUUtilization\"\n  namespace           = \"AWS/EC2\"\n  period              = \"120\"\n  statistic           = \"Average\"\n  threshold           = \"80\"\n  alarm_description   = \"This metric monitors ec2 cpu utilization\"\n}\n\nresource \"aws_route53_health_check\" \"foo\" {\n  type                            = \"CLOUDWATCH_METRIC\"\n  cloudwatch_alarm_name           = aws_cloudwatch_metric_alarm.foobar.alarm_name\n  cloudwatch_alarm_region         = \"us-west-2\"\n  insufficient_data_health_status = \"Healthy\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n~> **Note:** At least one of either `fqdn` or `ip_address` must be specified.\n\n* `reference_name` - (Optional) This is a reference name used in Caller Reference\n    (helpful for identifying single health_check set amongst others)\n* `fqdn` - (Optional) The fully qualified domain name of the endpoint to be checked.\n* `ip_address` - (Optional) The IP address of the endpoint to be checked.\n* `port` - (Optional) The port of the endpoint to be checked.\n* `type` - (Required) The protocol to use when performing health checks. Valid values are `HTTP`, `HTTPS`, `HTTP_STR_MATCH`, `HTTPS_STR_MATCH`, `TCP`, `CALCULATED`, `CLOUDWATCH_METRIC` and `RECOVERY_CONTROL`.\n* `failure_threshold` - (Required) The number of consecutive health checks that an endpoint must pass or fail.\n* `request_interval` - (Required) The number of seconds between the time that Amazon Route 53 gets a response from your endpoint and the time that it sends the next health-check request.\n* `resource_path` - (Optional) The path that you want Amazon Route 53 to request when performing health checks.\n* `search_string` - (Optional) String searched in the first 5120 bytes of the response body for check to be considered healthy. Only valid with `HTTP_STR_MATCH` and `HTTPS_STR_MATCH`.\n* `measure_latency` - (Optional) A Boolean value that indicates whether you want Route 53 to measure the latency between health checkers in multiple AWS regions and your endpoint and to display CloudWatch latency graphs in the Route 53 console.\n* `invert_healthcheck` - (Optional) A boolean value that indicates whether the status of health check should be inverted. For example, if a health check is healthy but Inverted is True , then Route 53 considers the health check to be unhealthy.\n* `disabled` - (Optional) A boolean value that stops Route 53 from performing health checks. When set to true, Route 53 will do the following depending on the type of health check:\n    * For health checks that check the health of endpoints, Route5 53 stops submitting requests to your application, server, or other resource.\n    * For calculated health checks, Route 53 stops aggregating the status of the referenced health checks.\n    * For health checks that monitor CloudWatch alarms, Route 53 stops monitoring the corresponding CloudWatch metrics.\n\n    ~> **Note:** After you disable a health check, Route 53 considers the status of the health check to always be healthy. If you configured DNS failover, Route 53 continues to route traffic to the corresponding resources. If you want to stop routing traffic to a resource, change the value of `invert_healthcheck`.\n* `enable_sni` - (Optional) A boolean value that indicates whether Route53 should send the `fqdn` to the endpoint when performing the health check. This defaults to AWS' defaults: when the `type` is \"HTTPS\" `enable_sni` defaults to `true`, when `type` is anything else `enable_sni` defaults to `false`.\n* `child_healthchecks` - (Optional) For a specified parent health check, a list of HealthCheckId values for the associated child health checks.\n* `child_health_threshold` - (Optional) The minimum number of child health checks that must be healthy for Route 53 to consider the parent health check to be healthy. Valid values are integers between 0 and 256, inclusive\n* `cloudwatch_alarm_name` - (Optional) The name of the CloudWatch alarm.\n* `cloudwatch_alarm_region` - (Optional) The CloudWatchRegion that the CloudWatch alarm was created in.\n* `insufficient_data_health_status` - (Optional) The status of the health check when CloudWatch has insufficient data about the state of associated alarm. Valid values are `Healthy` , `Unhealthy` and `LastKnownStatus`.\n* `regions` - (Optional) A list of AWS regions that you want Amazon Route 53 health checkers to check the specified endpoint from.\n* `routing_control_arn` - (Optional) The Amazon Resource Name (ARN) for the Route 53 Application Recovery Controller routing control. This is used when health check type is `RECOVERY_CONTROL`\n* `tags` - (Optional) A map of tags to assign to the health check. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Health Check.\n* `id` - The id of the health check\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute53 Health Checks can be imported using the `health check id`, e.g.,\n\n```\n$ terraform import aws_route53_health_check.http_check abcdef11-2222-3333-4444-555555fedcba\n```\n",
    "basename": "route53_health_check.html"
  },
  "route53_hosted_zone_dnssec.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_hosted_zone_dnssec",
    "description": "Manages Route 53 Hosted Zone DNSSEC",
    "preview": "# Resource: aws_route53_hosted_zone_dnssec\n\nManages Route 53 Hosted …",
    "content": "\n\n# Resource: aws_route53_hosted_zone_dnssec\n\nManages Route 53 Hosted Zone Domain Name System Security Extensions (DNSSEC). For more information about managing DNSSEC in Route 53, see the [Route 53 Developer Guide](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-configuring-dnssec.html).\n\n!> **WARNING:** If you disable DNSSEC signing for your hosted zone before the DNS changes have propagated, your domain could become unavailable on the internet. When you remove the DS records, you must wait until the longest TTL for the DS records that you remove has expired before you complete the step to disable DNSSEC signing. Please refer to the [Route 53 Developer Guide - Disable DNSSEC](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-configuring-dnssec-disable.html) for a detailed breakdown on the steps required to disable DNSSEC safely for a hosted zone.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_kms_key\" \"example\" {\n  customer_master_key_spec = \"ECC_NIST_P256\"\n  deletion_window_in_days  = 7\n  key_usage                = \"SIGN_VERIFY\"\n  policy = jsonencode({\n    Statement = [\n      {\n        Action = [\n          \"kms:DescribeKey\",\n          \"kms:GetPublicKey\",\n          \"kms:Sign\",\n        ],\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"dnssec-route53.amazonaws.com\"\n        }\n        Sid      = \"Allow Route 53 DNSSEC Service\",\n        Resource = \"*\"\n      },\n      {\n        Action = \"kms:CreateGrant\",\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"dnssec-route53.amazonaws.com\"\n        }\n        Sid      = \"Allow Route 53 DNSSEC Service to CreateGrant\",\n        Resource = \"*\"\n        Condition = {\n          Bool = {\n            \"kms:GrantIsForAWSResource\" = \"true\"\n          }\n        }\n      },\n      {\n        Action = \"kms:*\"\n        Effect = \"Allow\"\n        Principal = {\n          AWS = \"*\"\n        }\n        Resource = \"*\"\n        Sid      = \"IAM User Permissions\"\n      },\n    ]\n    Version = \"2012-10-17\"\n  })\n}\n\nresource \"aws_route53_zone\" \"example\" {\n  name = \"example.com\"\n}\n\nresource \"aws_route53_key_signing_key\" \"example\" {\n  hosted_zone_id             = aws_route53_zone.example.id\n  key_management_service_arn = aws_kms_key.example.arn\n  name                       = \"example\"\n}\n\nresource \"aws_route53_hosted_zone_dnssec\" \"example\" {\n  depends_on = [\n    aws_route53_key_signing_key.example\n  ]\n  hosted_zone_id = aws_route53_key_signing_key.example.hosted_zone_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `hosted_zone_id` - (Required) Identifier of the Route 53 Hosted Zone.\n\nThe following arguments are optional:\n\n* `signing_status` - (Optional) Hosted Zone signing status. Valid values: `SIGNING`, `NOT_SIGNING`. Defaults to `SIGNING`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Route 53 Hosted Zone identifier.\n\n## Import\n\n`aws_route53_hosted_zone_dnssec` resources can be imported by using the Route 53 Hosted Zone identifier, e.g.,\n\n```\n$ terraform import aws_route53_hosted_zone_dnssec.example Z1D633PJN98FT9\n```\n",
    "basename": "route53_hosted_zone_dnssec.html"
  },
  "route53_key_signing_key.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_key_signing_key",
    "description": "Manages an Route 53 Key Signing Key",
    "preview": "# Resource: aws_route53_key_signing_key\n\nManages a Route 53 Key …",
    "content": "\n\n# Resource: aws_route53_key_signing_key\n\nManages a Route 53 Key Signing Key. To manage Domain Name System Security Extensions (DNSSEC) for a Hosted Zone, see the [`aws_route53_hosted_zone_dnssec` resource](route53_hosted_zone_dnssec.html). For more information about managing DNSSEC in Route 53, see the [Route 53 Developer Guide](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-configuring-dnssec.html).\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_kms_key\" \"example\" {\n  customer_master_key_spec = \"ECC_NIST_P256\"\n  deletion_window_in_days  = 7\n  key_usage                = \"SIGN_VERIFY\"\n  policy = jsonencode({\n    Statement = [\n      {\n        Action = [\n          \"kms:DescribeKey\",\n          \"kms:GetPublicKey\",\n          \"kms:Sign\",\n        ],\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"dnssec-route53.amazonaws.com\"\n        }\n        Sid      = \"Allow Route 53 DNSSEC Service\",\n        Resource = \"*\"\n      },\n      {\n        Action = \"kms:CreateGrant\",\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"dnssec-route53.amazonaws.com\"\n        }\n        Sid      = \"Allow Route 53 DNSSEC Service to CreateGrant\",\n        Resource = \"*\"\n        Condition = {\n          Bool = {\n            \"kms:GrantIsForAWSResource\" = \"true\"\n          }\n        }\n      },\n      {\n        Action = \"kms:*\"\n        Effect = \"Allow\"\n        Principal = {\n          AWS = \"*\"\n        }\n        Resource = \"*\"\n        Sid      = \"IAM User Permissions\"\n      },\n    ]\n    Version = \"2012-10-17\"\n  })\n}\n\nresource \"aws_route53_zone\" \"example\" {\n  name = \"example.com\"\n}\n\nresource \"aws_route53_key_signing_key\" \"example\" {\n  hosted_zone_id             = aws_route53_zone.test.id\n  key_management_service_arn = aws_kms_key.test.arn\n  name                       = \"example\"\n}\n\nresource \"aws_route53_hosted_zone_dnssec\" \"example\" {\n  depends_on = [\n    aws_route53_key_signing_key.example\n  ]\n  hosted_zone_id = aws_route53_key_signing_key.example.hosted_zone_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `hosted_zone_id` - (Required) Identifier of the Route 53 Hosted Zone.\n* `key_management_service_arn` - (Required) Amazon Resource Name (ARN) of the Key Management Service (KMS) Key. This must be unique for each key-signing key (KSK) in a single hosted zone. This key must be in the `us-east-1` Region and meet certain requirements, which are described in the [Route 53 Developer Guide](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-configuring-dnssec-cmk-requirements.html) and [Route 53 API Reference](https://docs.aws.amazon.com/Route53/latest/APIReference/API_CreateKeySigningKey.html).\n* `name` - (Required) Name of the key-signing key (KSK). Must be unique for each key-singing key in the same hosted zone.\n\nThe following arguments are optional:\n\n* `status` - (Optional) Status of the key-signing key (KSK). Valid values: `ACTIVE`, `INACTIVE`. Defaults to `ACTIVE`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `digest_algorithm_mnemonic` - A string used to represent the delegation signer digest algorithm. This value must follow the guidelines provided by [RFC-8624 Section 3.3](https://tools.ietf.org/html/rfc8624#section-3.3).\n* `digest_algorithm_type` - An integer used to represent the delegation signer digest algorithm. This value must follow the guidelines provided by [RFC-8624 Section 3.3](https://tools.ietf.org/html/rfc8624#section-3.3).\n* `digest_value` - A cryptographic digest of a DNSKEY resource record (RR). DNSKEY records are used to publish the public key that resolvers can use to verify DNSSEC signatures that are used to secure certain kinds of information provided by the DNS system.\n* `dnskey_record` - A string that represents a DNSKEY record.\n* `ds_record` - A string that represents a delegation signer (DS) record.\n* `flag` - An integer that specifies how the key is used. For key-signing key (KSK), this value is always 257.\n* `id` - Route 53 Hosted Zone identifier and KMS Key identifier, separated by a comma (`,`).\n* `key_tag` - An integer used to identify the DNSSEC record for the domain name. The process used to calculate the value is described in [RFC-4034 Appendix B](https://tools.ietf.org/rfc/rfc4034.txt).\n* `public_key` - The public key, represented as a Base64 encoding, as required by [RFC-4034 Page 5](https://tools.ietf.org/rfc/rfc4034.txt).\n* `signing_algorithm_mnemonic` - A string used to represent the signing algorithm. This value must follow the guidelines provided by [RFC-8624 Section 3.1](https://tools.ietf.org/html/rfc8624#section-3.1).\n* `signing_algorithm_type` - An integer used to represent the signing algorithm. This value must follow the guidelines provided by [RFC-8624 Section 3.1](https://tools.ietf.org/html/rfc8624#section-3.1).\n\n## Import\n\n`aws_route53_key_signing_key` resources can be imported by using the Route 53 Hosted Zone identifier and KMS Key identifier, separated by a comma (`,`), e.g.,\n\n```\n$ terraform import aws_route53_key_signing_key.example Z1D633PJN98FT9,example\n```\n",
    "basename": "route53_key_signing_key.html"
  },
  "route53_query_log.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_query_log",
    "description": "Provides a Route53 query logging configuration resource.",
    "preview": "# Resource: aws_route53_query_log\n\nProvides a Route53 query logging …",
    "content": "\n\n# Resource: aws_route53_query_log\n\nProvides a Route53 query logging configuration resource.\n\n~> **NOTE:** There are restrictions on the configuration of query logging. Notably,\nthe CloudWatch log group must be in the `us-east-1` region,\na permissive CloudWatch log resource policy must be in place, and\nthe Route53 hosted zone must be public.\nSee [Configuring Logging for DNS Queries](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html?console_help=true#query-logs-configuring) for additional details.\n\n## Example Usage\n\n```terraform\n# Example CloudWatch log group in us-east-1\n\nprovider \"aws\" {\n  alias  = \"us-east-1\"\n  region = \"us-east-1\"\n}\n\nresource \"aws_cloudwatch_log_group\" \"aws_route53_example_com\" {\n  provider = aws.us-east-1\n\n  name              = \"/aws/route53/${aws_route53_zone.example_com.name}\"\n  retention_in_days = 30\n}\n\n# Example CloudWatch log resource policy to allow Route53 to write logs\n# to any log group under /aws/route53/*\n\ndata \"aws_iam_policy_document\" \"route53-query-logging-policy\" {\n  statement {\n    actions = [\n      \"logs:CreateLogStream\",\n      \"logs:PutLogEvents\",\n    ]\n\n    resources = [\"arn:aws:logs:*:*:log-group:/aws/route53/*\"]\n\n    principals {\n      identifiers = [\"route53.amazonaws.com\"]\n      type        = \"Service\"\n    }\n  }\n}\n\nresource \"aws_cloudwatch_log_resource_policy\" \"route53-query-logging-policy\" {\n  provider = aws.us-east-1\n\n  policy_document = data.aws_iam_policy_document.route53-query-logging-policy.json\n  policy_name     = \"route53-query-logging-policy\"\n}\n\n# Example Route53 zone with query logging\n\nresource \"aws_route53_zone\" \"example_com\" {\n  name = \"example.com\"\n}\n\nresource \"aws_route53_query_log\" \"example_com\" {\n  depends_on = [aws_cloudwatch_log_resource_policy.route53-query-logging-policy]\n\n  cloudwatch_log_group_arn = aws_cloudwatch_log_group.aws_route53_example_com.arn\n  zone_id                  = aws_route53_zone.example_com.zone_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cloudwatch_log_group_arn` - (Required) CloudWatch log group ARN to send query logs.\n* `zone_id` - (Required) Route53 hosted zone ID to enable query logs.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Query Logging Config.\n* `id` - The query logging configuration ID\n\n## Import\n\nRoute53 query logging configurations can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_route53_query_log.example_com xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n```\n",
    "basename": "route53_query_log.html"
  },
  "route53_record.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_record",
    "description": "Provides a Route53 record resource.",
    "preview": "# Resource: aws_route53_record\n\nProvides a Route53 record resource.\n …",
    "content": "\n\n# Resource: aws_route53_record\n\nProvides a Route53 record resource.\n\n## Example Usage\n\n### Simple routing policy\n\n```terraform\nresource \"aws_route53_record\" \"www\" {\n  zone_id = aws_route53_zone.primary.zone_id\n  name    = \"www.example.com\"\n  type    = \"A\"\n  ttl     = \"300\"\n  records = [aws_eip.lb.public_ip]\n}\n```\n\n### Weighted routing policy\nOther routing policies are configured similarly. See [Amazon Route 53 Developer Guide](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html) for details.\n\n```terraform\nresource \"aws_route53_record\" \"www-dev\" {\n  zone_id = aws_route53_zone.primary.zone_id\n  name    = \"www\"\n  type    = \"CNAME\"\n  ttl     = \"5\"\n\n  weighted_routing_policy {\n    weight = 10\n  }\n\n  set_identifier = \"dev\"\n  records        = [\"dev.example.com\"]\n}\n\nresource \"aws_route53_record\" \"www-live\" {\n  zone_id = aws_route53_zone.primary.zone_id\n  name    = \"www\"\n  type    = \"CNAME\"\n  ttl     = \"5\"\n\n  weighted_routing_policy {\n    weight = 90\n  }\n\n  set_identifier = \"live\"\n  records        = [\"live.example.com\"]\n}\n```\n\n### Alias record\nSee [related part of Amazon Route 53 Developer Guide](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html)\nto understand differences between alias and non-alias records.\n\nTTL for all alias records is [60 seconds](https://aws.amazon.com/route53/faqs/#dns_failover_do_i_need_to_adjust),\nyou cannot change this, therefore `ttl` has to be omitted in alias records.\n\n```terraform\nresource \"aws_elb\" \"main\" {\n  name               = \"foobar-terraform-elb\"\n  availability_zones = [\"us-east-1c\"]\n\n  listener {\n    instance_port     = 80\n    instance_protocol = \"http\"\n    lb_port           = 80\n    lb_protocol       = \"http\"\n  }\n}\n\nresource \"aws_route53_record\" \"www\" {\n  zone_id = aws_route53_zone.primary.zone_id\n  name    = \"example.com\"\n  type    = \"A\"\n\n  alias {\n    name                   = aws_elb.main.dns_name\n    zone_id                = aws_elb.main.zone_id\n    evaluate_target_health = true\n  }\n}\n```\n\n### NS and SOA Record Management\n\nWhen creating Route 53 zones, the `NS` and `SOA` records for the zone are automatically created. Enabling the `allow_overwrite` argument will allow managing these records in a single Terraform run without the requirement for `terraform import`.\n\n```terraform\nresource \"aws_route53_zone\" \"example\" {\n  name = \"test.example.com\"\n}\n\nresource \"aws_route53_record\" \"example\" {\n  allow_overwrite = true\n  name            = \"test.example.com\"\n  ttl             = 172800\n  type            = \"NS\"\n  zone_id         = aws_route53_zone.example.zone_id\n\n  records = [\n    aws_route53_zone.example.name_servers[0],\n    aws_route53_zone.example.name_servers[1],\n    aws_route53_zone.example.name_servers[2],\n    aws_route53_zone.example.name_servers[3],\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `zone_id` - (Required) The ID of the hosted zone to contain this record.\n* `name` - (Required) The name of the record.\n* `type` - (Required) The record type. Valid values are `A`, `AAAA`, `CAA`, `CNAME`, `DS`, `MX`, `NAPTR`, `NS`, `PTR`, `SOA`, `SPF`, `SRV` and `TXT`.\n* `ttl` - (Required for non-alias records) The TTL of the record.\n* `records` - (Required for non-alias records) A string list of records. To specify a single record value longer than 255 characters such as a TXT record for DKIM, add `\\\"\\\"` inside the Terraform configuration string (e.g., `\"first255characters\\\"\\\"morecharacters\"`).\n* `set_identifier` - (Optional) Unique identifier to differentiate records with routing policies from one another. Required if using `failover`, `geolocation`, `latency`, or `weighted` routing policies documented below.\n* `health_check_id` - (Optional) The health check the record should be associated with.\n* `alias` - (Optional) An alias block. Conflicts with `ttl` & `records`.\n  Alias record documented below.\n* `failover_routing_policy` - (Optional) A block indicating the routing behavior when associated health check fails. Conflicts with any other routing policy. Documented below.\n* `geolocation_routing_policy` - (Optional) A block indicating a routing policy based on the geolocation of the requestor. Conflicts with any other routing policy. Documented below.\n* `latency_routing_policy` - (Optional) A block indicating a routing policy based on the latency between the requestor and an AWS region. Conflicts with any other routing policy. Documented below.\n* `weighted_routing_policy` - (Optional) A block indicating a weighted routing policy. Conflicts with any other routing policy. Documented below.\n* `multivalue_answer_routing_policy` - (Optional) Set to `true` to indicate a multivalue answer routing policy. Conflicts with any other routing policy.\n* `allow_overwrite` - (Optional) Allow creation of this record in Terraform to overwrite an existing record, if any. This does not affect the ability to update the record in Terraform and does not prevent other resources within Terraform or manual Route 53 changes outside Terraform from overwriting this record. `false` by default. This configuration is not recommended for most environments.\n\nExactly one of `records` or `alias` must be specified: this determines whether it's an alias record.\n\nAlias records support the following:\n\n* `name` - (Required) DNS domain name for a CloudFront distribution, S3 bucket, ELB, or another resource record set in this hosted zone.\n* `zone_id` - (Required) Hosted zone ID for a CloudFront distribution, S3 bucket, ELB, or Route 53 hosted zone. See [`resource_elb.zone_id`](/docs/providers/aws/r/elb.html#zone_id) for example.\n* `evaluate_target_health` - (Required) Set to `true` if you want Route 53 to determine whether to respond to DNS queries using this resource record set by checking the health of the resource record set. Some resources have special requirements, see [related part of documentation](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-values.html#rrsets-values-alias-evaluate-target-health).\n\nFailover routing policies support the following:\n\n* `type` - (Required) `PRIMARY` or `SECONDARY`. A `PRIMARY` record will be served if its healthcheck is passing, otherwise the `SECONDARY` will be served. See http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-configuring-options.html#dns-failover-failover-rrsets\n\nGeolocation routing policies support the following:\n\n* `continent` - A two-letter continent code. See http://docs.aws.amazon.com/Route53/latest/APIReference/API_GetGeoLocation.html for code details. Either `continent` or `country` must be specified.\n* `country` - A two-character country code or `*` to indicate a default resource record set.\n* `subdivision` - (Optional) A subdivision code for a country.\n\nLatency routing policies support the following:\n\n* `region` - (Required) An AWS region from which to measure latency. See http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-latency\n\nWeighted routing policies support the following:\n\n* `weight` - (Required) A numeric value indicating the relative weight of the record. See http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-weighted.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `name` - The name of the record.\n* `fqdn` - [FQDN](https://en.wikipedia.org/wiki/Fully_qualified_domain_name) built using the zone domain and `name`.\n\n\n## Import\n\nRoute53 Records can be imported using ID of the record, which is the zone identifier, record name, and record type, separated by underscores (`_`)E.g.,\n\n```\n$ terraform import aws_route53_record.myrecord Z4KAPRWWNC7JR_dev.example.com_NS\n```\n\nIf the record also contains a delegated set identifier, it can be appended:\n\n```\n$ terraform import aws_route53_record.myrecord Z4KAPRWWNC7JR_dev.example.com_NS_dev\n```\n",
    "basename": "route53_record.html"
  },
  "route53_resolver_dnssec_config.html": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_dnssec_config",
    "description": "Provides a Route 53 Resolver DNSSEC config resource.",
    "preview": "# Resource: aws_route53_resolver_dnssec_config\n\nProvides a Route 53 …",
    "content": "\n\n# Resource: aws_route53_resolver_dnssec_config\n\nProvides a Route 53 Resolver DNSSEC config resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"example\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n}\n\nresource \"aws_route53_resolver_dnssec_config\" \"example\" {\n  resource_id = aws_vpc.example.id\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `resource_id` - (Required) The ID of the virtual private cloud (VPC) that you're updating the DNSSEC validation status for.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN for a configuration for DNSSEC validation.\n* `id` - The ID for a configuration for DNSSEC validation.\n* `owner_id` - The owner account ID of the virtual private cloud (VPC) for a configuration for DNSSEC validation.\n* `validation_status` - The validation status for a DNSSEC configuration. The status can be one of the following: `ENABLING`, `ENABLED`, `DISABLING` and `DISABLED`.\n\n## Import\n\n Route 53 Resolver DNSSEC configs can be imported using the Route 53 Resolver DNSSEC config ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_dnssec_config.example rdsc-be1866ecc1683e95\n```\n",
    "basename": "route53_resolver_dnssec_config.html"
  },
  "route53_resolver_endpoint.html": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_endpoint",
    "description": "Provides a Route 53 Resolver endpoint resource.",
    "preview": "# Resource: aws_route53_resolver_endpoint\n\nProvides a Route 53 …",
    "content": "\n\n# Resource: aws_route53_resolver_endpoint\n\nProvides a Route 53 Resolver endpoint resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_endpoint\" \"foo\" {\n  name      = \"foo\"\n  direction = \"INBOUND\"\n\n  security_group_ids = [\n    aws_security_group.sg1.id,\n    aws_security_group.sg2.id,\n  ]\n\n  ip_address {\n    subnet_id = aws_subnet.sn1.id\n  }\n\n  ip_address {\n    subnet_id = aws_subnet.sn2.id\n    ip        = \"10.0.64.4\"\n  }\n\n  tags = {\n    Environment = \"Prod\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `direction` - (Required) The direction of DNS queries to or from the Route 53 Resolver endpoint.\nValid values are `INBOUND` (resolver forwards DNS queries to the DNS service for a VPC from your network or another VPC)\nor `OUTBOUND` (resolver forwards DNS queries from the DNS service for a VPC to your network or another VPC).\n* `ip_address` - (Required) The subnets and IP addresses in your VPC that you want DNS queries to pass through on the way from your VPCs\nto your network (for outbound endpoints) or on the way from your network to your VPCs (for inbound endpoints). Described below.\n* `security_group_ids` - (Required) The ID of one or more security groups that you want to use to control access to this VPC.\n* `name` - (Optional) The friendly name of the Route 53 Resolver endpoint.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `ip_address` object supports the following:\n\n* `subnet_id` - (Required) The ID of the subnet that contains the IP address.\n* `ip` - (Optional) The IP address in the subnet that you want to use for DNS queries.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Route 53 Resolver endpoint.\n* `arn` - The ARN of the Route 53 Resolver endpoint.\n* `host_vpc_id` - The ID of the VPC that you want to create the resolver endpoint in.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_route53_resolver_endpoint` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating Route 53 Resolver endpoint\n- `update` - (Default `10 minutes`) Used for updating Route 53 Resolver endpoint\n- `delete` - (Default `10 minutes`) Used for destroying Route 53 Resolver endpoint\n\n## Import\n\n Route 53 Resolver endpoints can be imported using the Route 53 Resolver endpoint ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_endpoint.foo rslvr-in-abcdef01234567890\n```\n",
    "basename": "route53_resolver_endpoint.html"
  },
  "route53_resolver_firewall_config": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_firewall_config",
    "description": "Provides a Route 53 Resolver DNS Firewall config resource.",
    "preview": "# Resource: aws_route53_resolver_firewall_config\n\nProvides a Route …",
    "content": "\n\n# Resource: aws_route53_resolver_firewall_config\n\nProvides a Route 53 Resolver DNS Firewall config resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"example\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n}\n\nresource \"aws_route53_resolver_firewall_config\" \"example\" {\n  resource_id        = aws_vpc.example.id\n  firewall_fail_open = \"ENABLED\"\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `resource_id` - (Required) The ID of the VPC that the configuration is for.\n* `firewall_fail_open` - (Required) Determines how Route 53 Resolver handles queries during failures, for example when all traffic that is sent to DNS Firewall fails to receive a reply. By default, fail open is disabled, which means the failure mode is closed. This approach favors security over availability. DNS Firewall blocks queries that it is unable to evaluate properly. If you enable this option, the failure mode is open. This approach favors availability over security. DNS Firewall allows queries to proceed if it is unable to properly evaluate them. Valid values: `ENABLED`, `DISABLED`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the firewall configuration.\n* `owner_id` - The AWS account ID of the owner of the VPC that this firewall configuration applies to.\n\n## Import\n\nRoute 53 Resolver DNS Firewall configs can be imported using the Route 53 Resolver DNS Firewall config ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_firewall_config.example rdsc-be1866ecc1683e95\n```\n",
    "basename": "route53_resolver_firewall_config"
  },
  "route53_resolver_firewall_domain_list": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_firewall_domain_list",
    "description": "Provides a Route 53 Resolver DNS Firewall domain list resource.",
    "preview": "# Resource: aws_route53_resolver_firewall_domain_list\n\nProvides a …",
    "content": "\n\n# Resource: aws_route53_resolver_firewall_domain_list\n\nProvides a Route 53 Resolver DNS Firewall domain list resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_firewall_domain_list\" \"example\" {\n  name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `name` - (Required) A name that lets you identify the domain list, to manage and use it.\n* `domains` - (Optional) A array of domains for the firewall domain list.\n* `tags` - (Optional) A map of tags to assign to the resource. f configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN (Amazon Resource Name) of the domain list.\n* `id` - The ID of the domain list.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n Route 53 Resolver DNS Firewall domain lists can be imported using the Route 53 Resolver DNS Firewall domain list ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_firewall_domain_list.example rslvr-fdl-0123456789abcdef\n```\n",
    "basename": "route53_resolver_firewall_domain_list"
  },
  "route53_resolver_firewall_rule": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_firewall_rule",
    "description": "Provides a Route 53 Resolver DNS Firewall rule resource.",
    "preview": "# Resource: aws_route53_resolver_firewall_rule\n\nProvides a Route 53 …",
    "content": "\n\n# Resource: aws_route53_resolver_firewall_rule\n\nProvides a Route 53 Resolver DNS Firewall rule resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_firewall_domain_list\" \"example\" {\n  name    = \"example\"\n  domains = [\"example.com\"]\n  tags    = {}\n}\n\nresource \"aws_route53_resolver_firewall_rule_group\" \"example\" {\n  name = \"example\"\n  tags = {}\n}\n\nresource \"aws_route53_resolver_firewall_rule\" \"example\" {\n  name                    = \"example\"\n  action                  = \"BLOCK\"\n  block_override_dns_type = \"CNAME\"\n  block_override_domain   = \"example.com\"\n  block_override_ttl      = 1\n  block_response          = \"OVERRIDE\"\n  firewall_domain_list_id = aws_route53_resolver_firewall_domain_list.example.id\n  firewall_rule_group_id  = aws_route53_resolver_firewall_rule_group.example.id\n  priority                = 100\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `name` - (Required) A name that lets you identify the rule, to manage and use it.\n* `action` - (Required) The action that DNS Firewall should take on a DNS query when it matches one of the domains in the rule's domain list. Valid values: `ALLOW`, `BLOCK`, `ALERT`.\n* `block_override_dns_type` - (Required if `block_response` is `OVERRIDE`) The DNS record's type. This determines the format of the record value that you provided in BlockOverrideDomain. Value values: `CNAME`.\n* `block_override_domain` - (Required if `block_response` is `OVERRIDE`) The custom DNS record to send back in response to the query.\n* `block_override_ttl` - (Required if `block_response` is `OVERRIDE`) The recommended amount of time, in seconds, for the DNS resolver or web browser to cache the provided override record. Minimum value of 0. Maximum value of 604800.\n* `block_response` - (Required if `action` is `BLOCK`) The way that you want DNS Firewall to block the request. Valid values: `NODATA`, `NXDOMAIN`, `OVERRIDE`.\n* `firewall_domain_list_id` - (Required) The ID of the domain list that you want to use in the rule.\n* `firewall_rule_group_id` - (Required) The unique identifier of the firewall rule group where you want to create the rule.\n* `priority` - (Required) The setting that determines the processing order of the rule in the rule group. DNS Firewall processes the rules in a rule group by order of priority, starting from the lowest setting.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the rule.\n\n## Import\n\n Route 53 Resolver DNS Firewall rules can be imported using the Route 53 Resolver DNS Firewall rule group ID and domain list ID separated by ':', e.g.,\n\n```\n$ terraform import aws_route53_resolver_firewall_rule.example rslvr-frg-0123456789abcdef:rslvr-fdl-0123456789abcdef\n```\n",
    "basename": "route53_resolver_firewall_rule"
  },
  "route53_resolver_firewall_rule_group": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_firewall_rule_group",
    "description": "Provides a Route 53 Resolver DNS Firewall rule group resource.",
    "preview": "# Resource: aws_route53_resolver_firewall_rule_group\n\nProvides a …",
    "content": "\n\n# Resource: aws_route53_resolver_firewall_rule_group\n\nProvides a Route 53 Resolver DNS Firewall rule group resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_firewall_rule_group\" \"example\" {\n  name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `name` - (Required) A name that lets you identify the rule group, to manage and use it.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN (Amazon Resource Name) of the rule group.\n* `id` - The ID of the rule group.\n* `owner_id` - The AWS account ID for the account that created the rule group. When a rule group is shared with your account, this is the account that has shared the rule group with you.\n* `share_status` - Whether the rule group is shared with other AWS accounts, or was shared with the current account by another AWS account. Sharing is configured through AWS Resource Access Manager (AWS RAM). Valid values: `NOT_SHARED`, `SHARED_BY_ME`, `SHARED_WITH_ME`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n Route 53 Resolver DNS Firewall rule groups can be imported using the Route 53 Resolver DNS Firewall rule group ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_firewall_rule_group.example rslvr-frg-0123456789abcdef\n```\n",
    "basename": "route53_resolver_firewall_rule_group"
  },
  "route53_resolver_firewall_rule_group_association": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_firewall_rule_group_association",
    "description": "Provides a Route 53 Resolver DNS Firewall rule group association resource.",
    "preview": "# Resource: aws_route53_resolver_firewall_rule_group_association\n …",
    "content": "\n\n# Resource: aws_route53_resolver_firewall_rule_group_association\n\nProvides a Route 53 Resolver DNS Firewall rule group association resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_firewall_rule_group\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_route53_resolver_firewall_rule_group_association\" \"example\" {\n  name                   = \"example\"\n  firewall_rule_group_id = aws_route53_resolver_firewall_rule_group.example.id\n  priority               = 100\n  vpc_id                 = aws_vpc.example.id\n}\n```\n\n## Argument Reference\n\nThe following argument is supported:\n\n* `name` - (Required) A name that lets you identify the rule group association, to manage and use it.\n* `firewall_rule_group_id` - (Required) The unique identifier of the firewall rule group.\n* `mutation_protection` - (Optional) If enabled, this setting disallows modification or removal of the association, to help prevent against accidentally altering DNS firewall protections. Valid values: `ENABLED`, `DISABLED`.\n* `priority` - (Required) The setting that determines the processing order of the rule group among the rule groups that you associate with the specified VPC. DNS Firewall filters VPC traffic starting from the rule group with the lowest numeric priority setting.\n* `vpc_id` - (Required) The unique identifier of the VPC that you want to associate with the rule group.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN (Amazon Resource Name) of the firewall rule group association.\n* `id` - The identifier for the association.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute 53 Resolver DNS Firewall rule group associations can be imported using the Route 53 Resolver DNS Firewall rule group association ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_firewall_rule_group_association.example rslvr-frgassoc-0123456789abcdef\n```\n",
    "basename": "route53_resolver_firewall_rule_group_association"
  },
  "route53_resolver_query_log_config.html": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_query_log_config",
    "description": "Provides a Route 53 Resolver query logging configuration resource.",
    "preview": "# Resource: aws_route53_resolver_query_log_config\n\nProvides a Route …",
    "content": "\n\n# Resource: aws_route53_resolver_query_log_config\n\nProvides a Route 53 Resolver query logging configuration resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_query_log_config\" \"example\" {\n  name            = \"example\"\n  destination_arn = aws_s3_bucket.example.arn\n\n  tags = {\n    Environment = \"Prod\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `destination_arn` - (Required) The ARN of the resource that you want Route 53 Resolver to send query logs.\nYou can send query logs to an [S3 bucket](s3_bucket.html), a [CloudWatch Logs log group](cloudwatch_log_group.html), or a [Kinesis Data Firehose delivery stream](kinesis_firehose_delivery_stream.html).\n* `name` - (Required) The name of the Route 53 Resolver query logging configuration.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Route 53 Resolver query logging configuration.\n* `arn` - The ARN (Amazon Resource Name) of the Route 53 Resolver query logging configuration.\n* `owner_id` - The AWS account ID of the account that created the query logging configuration.\n* `share_status` - An indication of whether the query logging configuration is shared with other AWS accounts, or was shared with the current account by another AWS account.\nSharing is configured through AWS Resource Access Manager (AWS RAM).\nValues are `NOT_SHARED`, `SHARED_BY_ME` or `SHARED_WITH_ME`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n Route 53 Resolver query logging configurations can be imported using the Route 53 Resolver query logging configuration ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_query_log_config.example rqlc-92edc3b1838248bf\n```\n",
    "basename": "route53_resolver_query_log_config.html"
  },
  "route53_resolver_query_log_config_association.html": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_query_log_config_association",
    "description": "Provides a Route 53 Resolver query logging configuration association resource.",
    "preview": "# Resource: aws_route53_resolver_query_log_config_association\n …",
    "content": "\n\n# Resource: aws_route53_resolver_query_log_config_association\n\nProvides a Route 53 Resolver query logging configuration association resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_query_log_config_association\" \"example\" {\n  resolver_query_log_config_id = aws_route53_resolver_query_log_config.example.id\n  resource_id                  = aws_vpc.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resolver_query_log_config_id` - (Required) The ID of the [Route 53 Resolver query logging configuration](route53_resolver_query_log_config.html) that you want to associate a VPC with.\n* `resource_id` - (Required) The ID of a VPC that you want this query logging configuration to log queries for.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` -The ID of the Route 53 Resolver query logging configuration association.\n\n## Import\n\n Route 53 Resolver query logging configuration associations can be imported using the Route 53 Resolver query logging configuration association ID, e.g.,\n\n```\n$ terraform import aws_route53_resolver_query_log_config_association.example rqlca-b320624fef3c4d70\n```\n",
    "basename": "route53_resolver_query_log_config_association.html"
  },
  "route53_resolver_rule.html": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_rule",
    "description": "Provides a Route53 Resolver rule.",
    "preview": "# Resource: aws_route53_resolver_rule\n\nProvides a Route53 Resolver …",
    "content": "\n\n# Resource: aws_route53_resolver_rule\n\nProvides a Route53 Resolver rule.\n\n## Example Usage\n\n### System rule\n\n```terraform\nresource \"aws_route53_resolver_rule\" \"sys\" {\n  domain_name = \"subdomain.example.com\"\n  rule_type   = \"SYSTEM\"\n}\n```\n\n### Forward rule\n\n```terraform\nresource \"aws_route53_resolver_rule\" \"fwd\" {\n  domain_name          = \"example.com\"\n  name                 = \"example\"\n  rule_type            = \"FORWARD\"\n  resolver_endpoint_id = aws_route53_resolver_endpoint.foo.id\n\n  target_ip {\n    ip = \"123.45.67.89\"\n  }\n\n  tags = {\n    Environment = \"Prod\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Required) DNS queries for this domain name are forwarded to the IP addresses that are specified using `target_ip`.\n* `rule_type` - (Required) The rule type. Valid values are `FORWARD`, `SYSTEM` and `RECURSIVE`.\n* `name` - (Optional) A friendly name that lets you easily find a rule in the Resolver dashboard in the Route 53 console.\n* `resolver_endpoint_id` (Optional) The ID of the outbound resolver endpoint that you want to use to route DNS queries to the IP addresses that you specify using `target_ip`.\nThis argument should only be specified for `FORWARD` type rules.\n* `target_ip` - (Optional) Configuration block(s) indicating the IPs that you want Resolver to forward DNS queries to (documented below).\nThis argument should only be specified for `FORWARD` type rules.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `target_ip` object supports the following:\n\n* `ip` - (Required) One IP address that you want to forward DNS queries to. You can specify only IPv4 addresses.\n* `port` - (Optional) The port at `ip` that you want to forward DNS queries to. Default value is `53`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the resolver rule.\n* `arn` - The ARN (Amazon Resource Name) for the resolver rule.\n* `owner_id` - When a rule is shared with another AWS account, the account ID of the account that the rule is shared with.\n* `share_status` - Whether the rules is shared and, if so, whether the current account is sharing the rule with another account, or another account is sharing the rule with the current account.\nValues are `NOT_SHARED`, `SHARED_BY_ME` or `SHARED_WITH_ME`\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute53 Resolver rules can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_route53_resolver_rule.sys rslvr-rr-0123456789abcdef0\n```\n",
    "basename": "route53_resolver_rule.html"
  },
  "route53_resolver_rule_association.html": {
    "subcategory": "Route53 Resolver",
    "layout": "aws",
    "page_title": "AWS: aws_route53_resolver_rule_association",
    "description": "Provides a Route53 Resolver rule association.",
    "preview": "# Resource: aws_route53_resolver_rule_association\n\nProvides a …",
    "content": "\n\n# Resource: aws_route53_resolver_rule_association\n\nProvides a Route53 Resolver rule association.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53_resolver_rule_association\" \"example\" {\n  resolver_rule_id = aws_route53_resolver_rule.sys.id\n  vpc_id           = aws_vpc.foo.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resolver_rule_id` - (Required) The ID of the resolver rule that you want to associate with the VPC.\n* `vpc_id` - (Required) The ID of the VPC that you want to associate the resolver rule with.\n* `name` - (Optional) A name for the association that you're creating between a resolver rule and a VPC.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the resolver rule association.\n\n## Import\n\nRoute53 Resolver rule associations can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_route53_resolver_rule_association.example rslvr-rrassoc-97242eaf88example\n```\n",
    "basename": "route53_resolver_rule_association.html"
  },
  "route53_vpc_association_authorization.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_vpc_association_authorization",
    "description": "Authorizes a VPC in a different account to be associated with a local Route53 Hosted Zone",
    "preview": "# Resource: aws_route53_vpc_association_authorization\n\nAuthorizes a …",
    "content": "\n\n# Resource: aws_route53_vpc_association_authorization\n\nAuthorizes a VPC in a different account to be associated with a local Route53 Hosted Zone.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n}\n\nprovider \"aws\" {\n  alias = \"alternate\"\n}\n\nresource \"aws_vpc\" \"example\" {\n  cidr_block           = \"10.6.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n}\n\nresource \"aws_route53_zone\" \"example\" {\n  name = \"example.com\"\n\n  vpc {\n    vpc_id = aws_vpc.example.id\n  }\n\n  # Prevent the deletion of associated VPCs after\n  # the initial creation. See documentation on\n  # aws_route53_zone_association for details\n  lifecycle {\n    ignore_changes = [vpc]\n  }\n}\n\nresource \"aws_vpc\" \"alternate\" {\n  provider = \"aws.alternate\"\n\n  cidr_block           = \"10.7.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n}\n\nresource \"aws_route53_vpc_association_authorization\" \"example\" {\n  vpc_id  = aws_vpc.alternate.id\n  zone_id = aws_route53_zone.example.id\n}\n\nresource \"aws_route53_zone_association\" \"example\" {\n  provider = \"aws.alternate\"\n\n  vpc_id  = aws_route53_vpc_association_authorization.example.vpc_id\n  zone_id = aws_route53_vpc_association_authorization.example.zone_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `zone_id` - (Required) The ID of the private hosted zone that you want to authorize associating a VPC with.\n* `vpc_id` - (Required) The VPC to authorize for association with the private hosted zone.\n* `vpc_region` - (Optional) The VPC's region. Defaults to the region of the AWS provider.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The calculated unique identifier for the association.\n\n## Import\n\nRoute 53 VPC Association Authorizations can be imported via the Hosted Zone ID and VPC ID, separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_route53_vpc_association_authorization.example Z123456ABCDEFG:vpc-12345678\n```\n",
    "basename": "route53_vpc_association_authorization.html"
  },
  "route53_zone.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_zone",
    "description": "Manages a Route53 Hosted Zone",
    "preview": "# Resource: aws_route53_zone\n\nManages a Route53 Hosted Zone. For …",
    "content": "\n\n# Resource: aws_route53_zone\n\nManages a Route53 Hosted Zone. For managing Domain Name System Security Extensions (DNSSEC), see the [`aws_route53_key_signing_key`](route53_key_signing_key.html) and [`aws_route53_hosted_zone_dnssec`](route53_hosted_zone_dnssec.html) resources.\n\n## Example Usage\n\n### Public Zone\n\n```terraform\nresource \"aws_route53_zone\" \"primary\" {\n  name = \"example.com\"\n}\n```\n\n### Public Subdomain Zone\n\nFor use in subdomains, note that you need to create a\n`aws_route53_record` of type `NS` as well as the subdomain\nzone.\n\n```terraform\nresource \"aws_route53_zone\" \"main\" {\n  name = \"example.com\"\n}\n\nresource \"aws_route53_zone\" \"dev\" {\n  name = \"dev.example.com\"\n\n  tags = {\n    Environment = \"dev\"\n  }\n}\n\nresource \"aws_route53_record\" \"dev-ns\" {\n  zone_id = aws_route53_zone.main.zone_id\n  name    = \"dev.example.com\"\n  type    = \"NS\"\n  ttl     = \"30\"\n  records = aws_route53_zone.dev.name_servers\n}\n```\n\n### Private Zone\n\n~> **NOTE:** Terraform provides both exclusive VPC associations defined in-line in this resource via `vpc` configuration blocks and a separate [Zone VPC Association](/docs/providers/aws/r/route53_zone_association.html) resource. At this time, you cannot use in-line VPC associations in conjunction with any `aws_route53_zone_association` resources with the same zone ID otherwise it will cause a perpetual difference in plan output. You can optionally use the generic Terraform resource [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` to manage additional associations via the `aws_route53_zone_association` resource.\n\n~> **NOTE:** Private zones require at least one VPC association at all times.\n\n```terraform\nresource \"aws_route53_zone\" \"private\" {\n  name = \"example.com\"\n\n  vpc {\n    vpc_id = aws_vpc.example.id\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) This is the name of the hosted zone.\n* `comment` - (Optional) A comment for the hosted zone. Defaults to 'Managed by Terraform'.\n* `delegation_set_id` - (Optional) The ID of the reusable delegation set whose NS records you want to assign to the hosted zone. Conflicts with `vpc` as delegation sets can only be used for public zones.\n* `force_destroy` - (Optional) Whether to destroy all records (possibly managed outside of Terraform) in the zone when destroying the zone.\n* `tags` - (Optional) A map of tags to assign to the zone. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc` - (Optional) Configuration block(s) specifying VPC(s) to associate with a private hosted zone. Conflicts with the `delegation_set_id` argument in this resource and any [`aws_route53_zone_association` resource](/docs/providers/aws/r/route53_zone_association.html) specifying the same zone ID. Detailed below.\n\n### vpc Argument Reference\n\n* `vpc_id` - (Required) ID of the VPC to associate.\n* `vpc_region` - (Optional) Region of the VPC to associate. Defaults to AWS provider region.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Hosted Zone.\n* `zone_id` - The Hosted Zone ID. This can be referenced by zone records.\n* `name_servers` - A list of name servers in associated (or default) delegation set.\n  Find more about delegation sets in [AWS docs](https://docs.aws.amazon.com/Route53/latest/APIReference/actions-on-reusable-delegation-sets.html).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute53 Zones can be imported using the `zone id`, e.g.,\n\n```\n$ terraform import aws_route53_zone.myzone Z1D633PJN98FT9\n```\n",
    "basename": "route53_zone.html"
  },
  "route53_zone_association.html": {
    "subcategory": "Route53",
    "layout": "aws",
    "page_title": "AWS: aws_route53_zone_association",
    "description": "Manages a Route53 Hosted Zone VPC association",
    "preview": "# Resource: aws_route53_zone_association\n\nManages a Route53 Hosted …",
    "content": "\n\n# Resource: aws_route53_zone_association\n\nManages a Route53 Hosted Zone VPC association. VPC associations can only be made on private zones. See the [`aws_route53_vpc_association_authorization` resource](route53_vpc_association_authorization.html) for setting up cross-account associations.\n\n~> **NOTE:** Unless explicit association ordering is required (e.g., a separate cross-account association authorization), usage of this resource is not recommended. Use the `vpc` configuration blocks available within the [`aws_route53_zone` resource](/docs/providers/aws/r/route53_zone.html) instead.\n\n~> **NOTE:** Terraform provides both this standalone Zone VPC Association resource and exclusive VPC associations defined in-line in the [`aws_route53_zone` resource](/docs/providers/aws/r/route53_zone.html) via `vpc` configuration blocks. At this time, you cannot use those in-line VPC associations in conjunction with this resource and the same zone ID otherwise it will cause a perpetual difference in plan output. You can optionally use the generic Terraform resource [lifecycle configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with `ignore_changes` in the `aws_route53_zone` resource to manage additional associations via this resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"primary\" {\n  cidr_block           = \"10.6.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n}\n\nresource \"aws_vpc\" \"secondary\" {\n  cidr_block           = \"10.7.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n}\n\nresource \"aws_route53_zone\" \"example\" {\n  name = \"example.com\"\n\n  # NOTE: The aws_route53_zone vpc argument accepts multiple configuration\n  #       blocks. The below usage of the single vpc configuration, the\n  #       lifecycle configuration, and the aws_route53_zone_association\n  #       resource is for illustrative purposes (e.g., for a separate\n  #       cross-account authorization process, which is not shown here).\n  vpc {\n    vpc_id = aws_vpc.primary.id\n  }\n\n  lifecycle {\n    ignore_changes = [vpc]\n  }\n}\n\nresource \"aws_route53_zone_association\" \"secondary\" {\n  zone_id = aws_route53_zone.example.zone_id\n  vpc_id  = aws_vpc.secondary.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `zone_id` - (Required) The private hosted zone to associate.\n* `vpc_id` - (Required) The VPC to associate with the private hosted zone.\n* `vpc_region` - (Optional) The VPC's region. Defaults to the region of the AWS provider.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The calculated unique identifier for the association.\n* `owning_account` - The account ID of the account that created the hosted zone.\n\n## Import\n\nRoute 53 Hosted Zone Associations can be imported via the Hosted Zone ID and VPC ID, separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_route53_zone_association.example Z123456ABCDEFG:vpc-12345678\n```\n\nIf the VPC is in a different region than the Terraform AWS Provider region configuration, the VPC Region can be added to the endE.g.,\n\n```\n$ terraform import aws_route53_zone_association.example Z123456ABCDEFG:vpc-12345678:us-east-2\n```\n",
    "basename": "route53_zone_association.html"
  },
  "route53recoverycontrolconfig_cluster.html": {
    "subcategory": "Route53 Recovery Control Config",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoverycontrolconfig_cluster",
    "description": "Provides an AWS Route 53 Recovery Control Config Cluster",
    "preview": "# Resource: aws_route53recoverycontrolconfig_cluster\n\nProvides an …",
    "content": "\n\n# Resource: aws_route53recoverycontrolconfig_cluster\n\nProvides an AWS Route 53 Recovery Control Config Cluster.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoverycontrolconfig_cluster\" \"example\" {\n  name = \"georgefitzgerald\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Unique name describing the cluster.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the cluster\n* `cluster_endpoints` - List of 5 endpoints in 5 regions that can be used to talk to the cluster. See below.\n* `status` - Status of cluster. `PENDING` when it is being created, `PENDING_DELETION` when it is being deleted and `DEPLOYED` otherwise.\n\n### cluster_endpoints\n\n* `endpoint` - Cluster endpoint.\n* `region` - Region of the endpoint.\n\n## Import\n\nRoute53 Recovery Control Config cluster can be imported via the cluster ARN, e.g.,\n\n```\n$ terraform import aws_route53recoverycontrolconfig_cluster.mycluster arn:aws:route53-recovery-control::313517334327:cluster/f9ae13be-a11e-4ec7-8522-94a70468e6ea\n```\n",
    "basename": "route53recoverycontrolconfig_cluster.html"
  },
  "route53recoverycontrolconfig_control_panel.html": {
    "subcategory": "Route53 Recovery Control Config",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoverycontrolconfig_control_panel",
    "description": "Provides an AWS Route 53 Recovery Control Config Control Panel",
    "preview": "# Resource: aws_route53recoverycontrolconfig_control_panel\n\nProvides …",
    "content": "\n\n# Resource: aws_route53recoverycontrolconfig_control_panel\n\nProvides an AWS Route 53 Recovery Control Config Control Panel.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoverycontrolconfig_control_panel\" \"example\" {\n  name        = \"balmorhea\"\n  cluster_arn = \"arn:aws:route53-recovery-control::123456789012:cluster/8d47920e-d789-437d-803a-2dcc4b204393\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `cluster_arn` - (Required) ARN of the cluster in which this control panel will reside.\n* `name` - (Required) Name describing the control panel.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the control panel.\n* `default_control_panel` - Whether a control panel is default.\n* `routing_control_count` - Number routing controls in a control panel.\n* `status` - Status of control panel: `PENDING` when it is being created/updated, `PENDING_DELETION` when it is being deleted, and `DEPLOYED` otherwise.\n\n## Import\n\nRoute53 Recovery Control Config Control Panel can be imported via the control panel arn, e.g.,\n\n```\n$ terraform import aws_route53recoverycontrolconfig_control_panel.mypanel arn:aws:route53-recovery-control::313517334327:controlpanel/1bfba17df8684f5dab0467b71424f7e8\n```\n",
    "basename": "route53recoverycontrolconfig_control_panel.html"
  },
  "route53recoverycontrolconfig_routing_control.html": {
    "subcategory": "Route53 Recovery Control Config",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoverycontrolconfig_routing_control",
    "description": "Provides an AWS Route 53 Recovery Control Config Routing Control",
    "preview": "# Resource: aws_route53recoverycontrolconfig_routing_control\n …",
    "content": "\n\n# Resource: aws_route53recoverycontrolconfig_routing_control\n\nProvides an AWS Route 53 Recovery Control Config Routing Control.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoverycontrolconfig_routing_control\" \"example\" {\n  name        = \"tinlicker\"\n  cluster_arn = \"arn:aws:route53-recovery-control::881188118811:cluster/8d47920e-d789-437d-803a-2dcc4b204393\"\n}\n```\n\n```terraform\nresource \"aws_route53recoverycontrolconfig_routing_control\" \"example\" {\n  name              = \"thomasoliver\"\n  cluster_arn       = \"arn:aws:route53-recovery-control::881188118811:cluster/8d47920e-d789-437d-803a-2dcc4b204393\"\n  control_panel_arn = \"arn:aws:route53-recovery-control::428113431245:controlpanel/abd5fbfc052d4844a082dbf400f61da8\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `cluster_arn` - (Required) ARN of the cluster in which this routing control will reside.\n* `name` - (Required) The name describing the routing control.\n\nThe following arguments are optional:\n\n* `control_panel_arn` - (Optional) ARN of the control panel in which this routing control will reside.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the routing control.\n* `status` - Status of routing control. `PENDING` when it is being created/updated, `PENDING_DELETION` when it is being deleted, and `DEPLOYED` otherwise.\n\n## Import\n\nRoute53 Recovery Control Config Routing Control can be imported via the routing control arn, e.g.,\n\n```\n$ terraform import aws_route53recoverycontrolconfig_routing_control.mycontrol arn:aws:route53-recovery-control::313517334327:controlpanel/abd5fbfc052d4844a082dbf400f61da8/routingcontrol/d5d90e587870494b\n```\n",
    "basename": "route53recoverycontrolconfig_routing_control.html"
  },
  "route53recoverycontrolconfig_safety_rule.html": {
    "subcategory": "Route53 Recovery Control Config",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoverycontrolconfig_safety_rule",
    "description": "Provides an AWS Route 53 Recovery Control Config Safety Rule",
    "preview": "# Resource: aws_route53recoverycontrolconfig_safety_rule\n\nProvides …",
    "content": "\n\n# Resource: aws_route53recoverycontrolconfig_safety_rule\n\nProvides an AWS Route 53 Recovery Control Config Safety Rule\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoverycontrolconfig_safety_rule\" \"example\" {\n  asserted_controls = [aws_route53recoverycontrolconfig_routing_control.example.arn]\n  control_panel_arn = \"arn:aws:route53-recovery-control::313517334327:controlpanel/abd5fbfc052d4844a082dbf400f61da8\"\n  name              = \"daisyguttridge\"\n  wait_period_ms    = 5000\n\n  rule_config {\n    inverted  = false\n    threshold = 1\n    type      = \"ATLEAST\"\n  }\n}\n```\n\n```terraform\nresource \"aws_route53recoverycontrolconfig_safety_rule\" \"example\" {\n  name              = \"i_o\"\n  control_panel_arn = \"arn:aws:route53-recovery-control::313517334327:controlpanel/abd5fbfc052d4844a082dbf400f61da8\"\n  wait_period_ms    = 5000\n  gating_controls   = [aws_route53recoverycontrolconfig_routing_control.example.arn]\n  target_controls   = [aws_route53recoverycontrolconfig_routing_control.example.arn]\n\n  rule_config {\n    inverted  = false\n    threshold = 1\n    type      = \"ATLEAST\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `control_panel_arn` - (Required) ARN of the control panel in which this safety rule will reside.\n* `name` - (Required) Name describing the safety rule.\n* `rule_config` - (Required) Configuration block for safety rule criteria. See below.\n* `wait_period_ms` - (Required) Evaluation period, in milliseconds (ms), during which any request against the target routing controls will fail.\n\nThe following arguments are optional:\n\n* `asserted_controls` - (Optional) Routing controls that are part of transactions that are evaluated to determine if a request to change a routing control state is allowed.\n* `gating_controls` - (Optional) Gating controls for the new gating rule. That is, routing controls that are evaluated by the rule configuration that you specify.\n* `target_controls` - (Optional) Routing controls that can only be set or unset if the specified `rule_config` evaluates to true for the specified `gating_controls`.\n\n### rule_config\n\n* `inverted` - (Required) Logical negation of the rule.\n* `threshold` - (Required) Number of controls that must be set when you specify an `ATLEAST` type rule.\n* `type` - (Required) Rule type. Valid values are `ATLEAST`, `AND`, and `OR`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the safety rule.\n* `status` - Status of the safety rule. `PENDING` when it is being created/updated, `PENDING_DELETION` when it is being deleted, and `DEPLOYED` otherwise.\n\n## Import\n\nRoute53 Recovery Control Config Safety Rule can be imported via the safety rule ARN, e.g.,\n\n```\n$ terraform import aws_route53recoverycontrolconfig_safety_rule.myrule arn:aws:route53-recovery-control::313517334327:controlpanel/1bfba17df8684f5dab0467b71424f7e8/safetyrule/3bacc77003364c0f\n```\n",
    "basename": "route53recoverycontrolconfig_safety_rule.html"
  },
  "route53recoveryreadiness_cell.html": {
    "subcategory": "Route53 Recovery Readiness",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoveryreadiness_cell",
    "description": "Provides an AWS Route 53 Recovery Readiness Cell",
    "preview": "# Resource: aws_route53recoveryreadiness_cell\n\nProvides an AWS Route …",
    "content": "\n\n# Resource: aws_route53recoveryreadiness_cell\n\nProvides an AWS Route 53 Recovery Readiness Cell.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoveryreadiness_cell\" \"example\" {\n  cell_name = \"us-west-2-failover-cell\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `cell_name` - (Required) Unique name describing the cell.\n\nThe following arguments are optional:\n\n* `cells` - (Optional) List of cell arns to add as nested fault domains within this cell.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the cell\n* `parent_readiness_scopes` - List of readiness scopes (recovery groups or cells) that contain this cell.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute53 Recovery Readiness cells can be imported via the cell name, e.g.,\n\n```\n$ terraform import aws_route53recoveryreadiness_cell.us-west-2-failover-cell us-west-2-failover-cell\n```\n\n## Timeouts\n\n`aws_route53recoveryreadiness_cell` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `delete` - (Default `5m`) Used when deleting the Cell\n",
    "basename": "route53recoveryreadiness_cell.html"
  },
  "route53recoveryreadiness_readiness_check.html": {
    "subcategory": "Route53 Recovery Readiness",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoveryreadiness_readiness_check",
    "description": "Provides an AWS Route 53 Recovery Readiness Readiness Check",
    "preview": "# Resource: aws_route53recoveryreadiness_readiness_check\n\nProvides …",
    "content": "\n\n# Resource: aws_route53recoveryreadiness_readiness_check\n\nProvides an AWS Route 53 Recovery Readiness Readiness Check.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoveryreadiness_readiness_check\" \"example\" {\n  readiness_check_name = my-cw-alarm-check\n  resource_set_name    = my-cw-alarm-set\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `readiness_check_name` - (Required) Unique name describing the readiness check.\n* `resource_set_name` - (Required) Name describing the resource set that will be monitored for readiness.\n\nThe following arguments are optional:\n\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the readiness_check\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute53 Recovery Readiness readiness checks can be imported via the readiness check name, e.g.,\n\n```\n$ terraform import aws_route53recoveryreadiness_readiness_check.my-cw-alarm-check\n```\n\n## Timeouts\n\n`aws_route53recoveryreadiness_readiness_check` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `delete` - (Default `5m`) Used when deleting the Readiness Check\n",
    "basename": "route53recoveryreadiness_readiness_check.html"
  },
  "route53recoveryreadiness_recovery_group.html": {
    "subcategory": "Route53 Recovery Readiness",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoveryreadiness_recovery_group",
    "description": "Provides an AWS Route 53 Recovery Readiness Recovery Group",
    "preview": "# Resource: aws_route53recoveryreadiness_recovery_group\n\nProvides an …",
    "content": "\n\n# Resource: aws_route53recoveryreadiness_recovery_group\n\nProvides an AWS Route 53 Recovery Readiness Recovery Group.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoveryreadiness_recovery_group\" \"example\" {\n  recovery_group_name = \"my-high-availability-app\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `recovery_group_name` - (Required) A unique name describing the recovery group.\n\nThe following argument are optional:\n\n* `cells` - (Optional) List of cell arns to add as nested fault domains within this recovery group\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the recovery group\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute53 Recovery Readiness recovery groups can be imported via the recovery group name, e.g.,\n\n```\n$ terraform import aws_route53recoveryreadiness_recovery_group.my-high-availability-app my-high-availability-app\n```\n\n## Timeouts\n\n`aws_route53recoveryreadiness_recovery_group` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `delete` - (Default `5m`) Used when deleting the Recovery Group\n",
    "basename": "route53recoveryreadiness_recovery_group.html"
  },
  "route53recoveryreadiness_resource_set.html": {
    "subcategory": "Route53 Recovery Readiness",
    "layout": "aws",
    "page_title": "AWS: aws_route53recoveryreadiness_resource_set",
    "description": "Provides an AWS Route 53 Recovery Readiness Resource Set",
    "preview": "# Resource: aws_route53recoveryreadiness_resource_set\n\nProvides an …",
    "content": "\n\n# Resource: aws_route53recoveryreadiness_resource_set\n\nProvides an AWS Route 53 Recovery Readiness Resource Set.\n\n## Example Usage\n\n```terraform\nresource \"aws_route53recoveryreadiness_resource_set\" \"example\" {\n  resource_set_name = my-cw-alarm-set\n  resource_set_type = \"AWS::CloudWatch::Alarm\"\n\n  resources {\n    resource_arn = aws_cloudwatch_metric_alarm.example.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resource_set_name` - (Required) Unique name describing the resource set.\n* `resource_set_type` - (Required) Type of the resources in the resource set.\n* `resources` - (Required) List of resources to add to this resource set. See below.\n\nThe following arguments are optional:\n\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### resources\n\n* `dns_target_resource` - (Required if `resource_arn` is not set) Component for DNS/Routing Control Readiness Checks.\n* `readiness_scopes` - (Optional) Recovery group ARN or cell ARN that contains this resource set.\n* `resource_arn` - (Required if `dns_target_resource` is not set) ARN of the resource.\n\n### dns_target_resource\n\n* `domain_name` - (Optional) DNS Name that acts as the ingress point to a portion of application.\n* `hosted_zone_arn` - (Optional) Hosted Zone ARN that contains the DNS record with the provided name of target resource.\n* `record_set_id` - (Optional) Route53 record set id to uniquely identify a record given a `domain_name` and a `record_type`.\n* `record_type` - (Optional) Type of DNS Record of target resource.\n* `target_resource` - (Optional) Target resource the R53 record specified with the above params points to.\n\n### target_resource\n\n* `nlb_resource` - (Optional) NLB resource a DNS Target Resource points to. Required if `r53_resource` is not set.\n* `r53_resource` - (Optional) Route53 resource a DNS Target Resource record points to.\n\n### nlb_resource\n\n* `arn` - (Required) NLB resource ARN.\n\n### r53_resource\n\n* `domain_name` - (Optional) Domain name that is targeted.\n* `record_set_id` - (Optional) Resource record set ID that is targeted.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the resource set\n* `resources.#.component_id` - Unique identified for DNS Target Resources, use for readiness checks.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nRoute53 Recovery Readiness resource set name can be imported via the resource set name, e.g.,\n\n```\n$ terraform import aws_route53recoveryreadiness_resource_set.my-cw-alarm-set\n```\n\n## Timeouts\n\n`aws_route53recoveryreadiness_resource_set` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `delete` - (Default `5m`) Used when deleting the Resource Set\n",
    "basename": "route53recoveryreadiness_resource_set.html"
  },
  "route_table.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_route_table",
    "description": "Provides a resource to create a VPC routing table.",
    "preview": "# Resource: aws_route_table\n\nProvides a resource to create a VPC …",
    "content": "\n\n# Resource: aws_route_table\n\nProvides a resource to create a VPC routing table.\n\n~> **NOTE on Route Tables and Routes:** Terraform currently\nprovides both a standalone [Route resource](route.html) and a Route Table resource with routes\ndefined in-line. At this time you cannot use a Route Table with in-line routes\nin conjunction with any Route resources. Doing so will cause\na conflict of rule settings and will overwrite rules.\n\n~> **NOTE on `gateway_id` and `nat_gateway_id`:** The AWS API is very forgiving with these two\nattributes and the `aws_route_table` resource can be created with a NAT ID specified as a Gateway ID attribute.\nThis _will_ lead to a permanent diff between your configuration and statefile, as the API returns the correct\nparameters in the returned route table. If you're experiencing constant diffs in your `aws_route_table` resources,\nthe first thing to check is whether or not you're specifying a NAT ID instead of a Gateway ID, or vice-versa.\n\n~> **NOTE on `propagating_vgws` and the `aws_vpn_gateway_route_propagation` resource:**\nIf the `propagating_vgws` argument is present, it's not supported to _also_\ndefine route propagations using `aws_vpn_gateway_route_propagation`, since\nthis resource will delete any propagating gateways not explicitly listed in\n`propagating_vgws`. Omit this argument when defining route propagation using\nthe separate resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_route_table\" \"example\" {\n  vpc_id = aws_vpc.example.id\n\n  route {\n    cidr_block = \"10.0.1.0/24\"\n    gateway_id = aws_internet_gateway.example.id\n  }\n\n  route {\n    ipv6_cidr_block        = \"::/0\"\n    egress_only_gateway_id = aws_egress_only_internet_gateway.example.id\n  }\n\n  tags = {\n    Name = \"example\"\n  }\n}\n```\n\nTo subsequently remove all managed routes:\n\n```terraform\nresource \"aws_route_table\" \"example\" {\n  vpc_id = aws_vpc.example.id\n\n  route = []\n\n  tags = {\n    Name = \"example\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Required) The VPC ID.\n* `route` - (Optional) A list of route objects. Their keys are documented below. This argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\nThis means that omitting this argument is interpreted as ignoring any existing routes. To remove all managed routes an empty list should be specified. See the example above.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `propagating_vgws` - (Optional) A list of virtual gateways for propagation.\n\n### route Argument Reference\n\nThis argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\nOne of the following destination arguments must be supplied:\n\n* `cidr_block` - (Required) The CIDR block of the route.\n* `ipv6_cidr_block` - (Optional) The Ipv6 CIDR block of the route.\n* `destination_prefix_list_id` - (Optional) The ID of a [managed prefix list](ec2_managed_prefix_list.html) destination of the route.\n\nOne of the following target arguments must be supplied:\n\n* `carrier_gateway_id` - (Optional) Identifier of a carrier gateway. This attribute can only be used when the VPC contains a subnet which is associated with a Wavelength Zone.\n* `egress_only_gateway_id` - (Optional) Identifier of a VPC Egress Only Internet Gateway.\n* `gateway_id` - (Optional) Identifier of a VPC internet gateway or a virtual private gateway.\n* `instance_id` - (Optional) Identifier of an EC2 instance.\n* `local_gateway_id` - (Optional) Identifier of a Outpost local gateway.\n* `nat_gateway_id` - (Optional) Identifier of a VPC NAT gateway.\n* `network_interface_id` - (Optional) Identifier of an EC2 network interface.\n* `transit_gateway_id` - (Optional) Identifier of an EC2 Transit Gateway.\n* `vpc_endpoint_id` - (Optional) Identifier of a VPC Endpoint.\n* `vpc_peering_connection_id` - (Optional) Identifier of a VPC peering connection.\n\nNote that the default route, mapping the VPC's CIDR block to \"local\", is created implicitly and cannot be specified.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n~> **NOTE:** Only the target that is entered is exported as a readable\nattribute once the route resource is created.\n\n* `id` - The ID of the routing table.\n* `arn` - The ARN of the route table.\n* `owner_id` - The ID of the AWS account that owns the route table.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_default_route_table` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `2 minutes`) Used for route creation\n- `update` - (Default `2 minutes`) Used for route creation\n- `delete` - (Default `5 minutes`) Used for route deletion\n\n## Import\n\nRoute Tables can be imported using the route table `id`. For example, to import\nroute table `rtb-4e616f6d69`, use this command:\n\n```\n$ terraform import aws_route_table.public_rt rtb-4e616f6d69\n```\n",
    "basename": "route_table.html"
  },
  "route_table_association.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_route_table_association",
    "description": "Provides a resource to create an association between a route table and a subnet or a route table and an internet gateway or virtual private gateway.",
    "preview": "# Resource: aws_route_table_association\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_route_table_association\n\nProvides a resource to create an association between a route table and a subnet or a route table and an\ninternet gateway or virtual private gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_route_table_association\" \"a\" {\n  subnet_id      = aws_subnet.foo.id\n  route_table_id = aws_route_table.bar.id\n}\n```\n\n```terraform\nresource \"aws_route_table_association\" \"b\" {\n  gateway_id     = aws_internet_gateway.foo.id\n  route_table_id = aws_route_table.bar.id\n}\n```\n\n## Argument Reference\n\n~> **NOTE:** Please note that one of either `subnet_id` or `gateway_id` is required.\n\nThe following arguments are supported:\n\n* `subnet_id` - (Optional) The subnet ID to create an association. Conflicts with `gateway_id`.\n* `gateway_id` - (Optional) The gateway ID to create an association. Conflicts with `subnet_id`.\n* `route_table_id` - (Required) The ID of the routing table to associate with.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the association\n\n## Import\n\n~> **NOTE:** Attempting to associate a route table with a subnet or gateway, where either\nis already associated, will result in an error (e.g.,\n`Resource.AlreadyAssociated: the specified association for route table\nrtb-4176657279 conflicts with an existing association`) unless you first\nimport the original association.\n\nEC2 Route Table Associations can be imported using the associated resource ID and Route Table ID\nseparated by a forward slash (`/`).\n\nFor example with EC2 Subnets:\n\n```\n$ terraform import aws_route_table_association.assoc subnet-6777656e646f6c796e/rtb-656c65616e6f72\n```\n\nFor example with EC2 Internet Gateways:\n\n```\n$ terraform import aws_route_table_association.assoc igw-01b3a60780f8d034a/rtb-656c65616e6f72\n```\n",
    "basename": "route_table_association.html"
  },
  "s3_access_point.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_access_point",
    "description": "Manages an S3 Access Point.",
    "preview": "# Resource: aws_s3_access_point\n\nProvides a resource to manage an S3 …",
    "content": "\n\n# Resource: aws_s3_access_point\n\nProvides a resource to manage an S3 Access Point.\n\n~> **NOTE on Access Points and Access Point Policies:** Terraform provides both a standalone [Access Point Policy](s3control_access_point_policy.html) resource and an Access Point resource with a resource policy defined in-line. You cannot use an Access Point with in-line resource policy in conjunction with an Access Point Policy resource. Doing so will cause a conflict of policies and will overwrite the access point's resource policy.\n\n-> Advanced usage: To use a custom API endpoint for this Terraform resource, use the [`s3control` endpoint provider configuration](/docs/providers/aws/index.html#s3control), not the `s3` endpoint provider configuration.\n\n## Example Usage\n\n### AWS Partition Bucket\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_access_point\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n  name   = \"example\"\n}\n```\n\n### S3 on Outposts Bucket\n\n```terraform\nresource \"aws_s3control_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_access_point\" \"example\" {\n  bucket = aws_s3control_bucket.example.arn\n  name   = \"example\"\n\n  # VPC must be specified for S3 on Outposts\n  vpc_configuration {\n    vpc_id = aws_vpc.example.id\n  }\n}\n\nresource \"aws_vpc\" \"example\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `bucket` - (Required) The name of an AWS Partition S3 Bucket or the Amazon Resource Name (ARN) of S3 on Outposts Bucket that you want to associate this access point with.\n* `name` - (Required) The name you want to assign to this access point.\n\nThe following arguments are optional:\n\n* `account_id` - (Optional) The AWS account ID for the owner of the bucket for which you want to create an access point. Defaults to automatically determined account ID of the Terraform AWS provider.\n* `policy` - (Optional) A valid JSON document that specifies the policy that you want to apply to this access point.\n* `public_access_block_configuration` - (Optional) Configuration block to manage the `PublicAccessBlock` configuration that you want to apply to this Amazon S3 bucket. You can enable the configuration options in any combination. Detailed below.\n* `vpc_configuration` - (Optional) Configuration block to restrict access to this access point to requests from the specified Virtual Private Cloud (VPC). Required for S3 on Outposts. Detailed below.\n\n### public_access_block_configuration Configuration Block\n\nThe following arguments are optional:\n\n* `block_public_acls` - (Optional) Whether Amazon S3 should block public ACLs for buckets in this account. Defaults to `true`. Enabling this setting does not affect existing policies or ACLs. When set to `true` causes the following behavior:\n    * PUT Bucket acl and PUT Object acl calls fail if the specified ACL is public.\n    * PUT Object calls fail if the request includes a public ACL.\n    * PUT Bucket calls fail if the request includes a public ACL.\n* `block_public_policy` - (Optional) Whether Amazon S3 should block public bucket policies for buckets in this account. Defaults to `true`. Enabling this setting does not affect existing bucket policies. When set to `true` causes Amazon S3 to:\n    * Reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n* `ignore_public_acls` - (Optional) Whether Amazon S3 should ignore public ACLs for buckets in this account. Defaults to `true`. Enabling this setting does not affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set. When set to `true` causes Amazon S3 to:\n    * Ignore all public ACLs on buckets in this account and any objects that they contain.\n* `restrict_public_buckets` - (Optional) Whether Amazon S3 should restrict public bucket policies for buckets in this account. Defaults to `true`. Enabling this setting does not affect previously stored bucket policies, except that public and cross-account access within any public bucket policy, including non-public delegation to specific accounts, is blocked. When set to `true`:\n    * Only the bucket owner and AWS Services can access buckets with public policies.\n\n### vpc_configuration Configuration Block\n\nThe following arguments are required:\n\n* `vpc_id` - (Required)  This access point will only allow connections from the specified VPC ID.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `alias` - The alias of the S3 Access Point.\n* `arn` - Amazon Resource Name (ARN) of the S3 Access Point.\n* `domain_name` - The DNS domain name of the S3 Access Point in the format _`name`_-_`account_id`_.s3-accesspoint._region_.amazonaws.com.\nNote: S3 access points only support secure access by HTTPS. HTTP isn't supported.\n* `endpoints` - The VPC endpoints for the S3 Access Point.\n* `has_public_access_policy` - Indicates whether this access point currently has a policy that allows public access.\n* `id` - For Access Point of an AWS Partition S3 Bucket, the AWS account ID and access point name separated by a colon (`:`). For S3 on Outposts Bucket, the Amazon Resource Name (ARN) of the Access Point.\n* `network_origin` - Indicates whether this access point allows access from the public Internet. Values are `VPC` (the access point doesn't allow access from the public Internet) and `Internet` (the access point allows access from the public Internet, subject to the access point and bucket access policies).\n\n## Import\n\nFor Access Points associated with an AWS Partition S3 Bucket, this resource can be imported using the `account_id` and `name` separated by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_s3_access_point.example 123456789012:example\n```\n\nFor Access Points associated with an S3 on Outposts Bucket, this resource can be imported using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_s3_access_point.example arn:aws:s3-outposts:us-east-1:123456789012:outpost/op-1234567890123456/accesspoint/example\n```\n",
    "basename": "s3_access_point.html"
  },
  "s3_account_public_access_block.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_account_public_access_block",
    "description": "Manages S3 account-level Public Access Block Configuration",
    "preview": "# Resource: aws_s3_account_public_access_block\n\nManages S3 …",
    "content": "\n\n# Resource: aws_s3_account_public_access_block\n\nManages S3 account-level Public Access Block configuration. For more information about these settings, see the [AWS S3 Block Public Access documentation](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html).\n\n~> **NOTE:** Each AWS account may only have one S3 Public Access Block configuration. Multiple configurations of the resource against the same AWS account will cause a perpetual difference.\n\n-> Advanced usage: To use a custom API endpoint for this Terraform resource, use the [`s3control` endpoint provider configuration](/docs/providers/aws/index.html#s3control), not the `s3` endpoint provider configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_account_public_access_block\" \"example\" {\n  block_public_acls   = true\n  block_public_policy = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) AWS account ID to configure. Defaults to automatically determined account ID of the Terraform AWS provider.\n* `block_public_acls` - (Optional) Whether Amazon S3 should block public ACLs for buckets in this account. Defaults to `false`. Enabling this setting does not affect existing policies or ACLs. When set to `true` causes the following behavior:\n    * PUT Bucket acl and PUT Object acl calls will fail if the specified ACL allows public access.\n    * PUT Object calls will fail if the request includes an object ACL.\n* `block_public_policy` - (Optional) Whether Amazon S3 should block public bucket policies for buckets in this account. Defaults to `false`. Enabling this setting does not affect existing bucket policies. When set to `true` causes Amazon S3 to:\n    * Reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n* `ignore_public_acls` - (Optional) Whether Amazon S3 should ignore public ACLs for buckets in this account. Defaults to `false`. Enabling this setting does not affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set. When set to `true` causes Amazon S3 to:\n    * Ignore all public ACLs on buckets in this account and any objects that they contain.\n* `restrict_public_buckets` - (Optional) Whether Amazon S3 should restrict public bucket policies for buckets in this account. Defaults to `false`. Enabling this setting does not affect previously stored bucket policies, except that public and cross-account access within any public bucket policy, including non-public delegation to specific accounts, is blocked. When set to `true`:\n    * Only the bucket owner and AWS Services can access buckets with public policies.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - AWS account ID\n\n## Import\n\n`aws_s3_account_public_access_block` can be imported by using the AWS account ID, e.g.,\n\n```\n$ terraform import aws_s3_account_public_access_block.example 123456789012\n```\n",
    "basename": "s3_account_public_access_block.html"
  },
  "s3_bucket.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket",
    "description": "Provides a S3 bucket resource.",
    "preview": "# Resource: aws_s3_bucket\n\nProvides a S3 bucket resource.\n\n-> This …",
    "content": "\n\n# Resource: aws_s3_bucket\n\nProvides a S3 bucket resource.\n\n-> This functionality is for managing S3 in an AWS Partition. To manage [S3 on Outposts](https://docs.aws.amazon.com/AmazonS3/latest/dev/S3onOutposts.html), see the [`aws_s3control_bucket`](/docs/providers/aws/r/s3control_bucket.html) resource.\n\n## Example Usage\n\n### Private Bucket w/ Tags\n\n```terraform\nresource \"aws_s3_bucket\" \"b\" {\n  bucket = \"my-tf-test-bucket\"\n  acl    = \"private\"\n\n  tags = {\n    Name        = \"My bucket\"\n    Environment = \"Dev\"\n  }\n}\n```\n\n### Static Website Hosting\n\n```terraform\nresource \"aws_s3_bucket\" \"b\" {\n  bucket = \"s3-website-test.hashicorp.com\"\n  acl    = \"public-read\"\n  policy = file(\"policy.json\")\n\n  website {\n    index_document = \"index.html\"\n    error_document = \"error.html\"\n\n    routing_rules = <<EOF\n[{\n    \"Condition\": {\n        \"KeyPrefixEquals\": \"docs/\"\n    },\n    \"Redirect\": {\n        \"ReplaceKeyPrefixWith\": \"documents/\"\n    }\n}]\nEOF\n  }\n}\n```\n\n### Using CORS\n\n```terraform\nresource \"aws_s3_bucket\" \"b\" {\n  bucket = \"s3-website-test.hashicorp.com\"\n  acl    = \"public-read\"\n\n  cors_rule {\n    allowed_headers = [\"*\"]\n    allowed_methods = [\"PUT\", \"POST\"]\n    allowed_origins = [\"https://s3-website-test.hashicorp.com\"]\n    expose_headers  = [\"ETag\"]\n    max_age_seconds = 3000\n  }\n}\n```\n\n### Using versioning\n\n```terraform\nresource \"aws_s3_bucket\" \"b\" {\n  bucket = \"my-tf-test-bucket\"\n  acl    = \"private\"\n\n  versioning {\n    enabled = true\n  }\n}\n```\n\n### Enable Logging\n\n```terraform\nresource \"aws_s3_bucket\" \"log_bucket\" {\n  bucket = \"my-tf-log-bucket\"\n  acl    = \"log-delivery-write\"\n}\n\nresource \"aws_s3_bucket\" \"b\" {\n  bucket = \"my-tf-test-bucket\"\n  acl    = \"private\"\n\n  logging {\n    target_bucket = aws_s3_bucket.log_bucket.id\n    target_prefix = \"log/\"\n  }\n}\n```\n\n### Using object lifecycle\n\n```terraform\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"my-bucket\"\n  acl    = \"private\"\n\n  lifecycle_rule {\n    id      = \"log\"\n    enabled = true\n\n    prefix = \"log/\"\n\n    tags = {\n      rule      = \"log\"\n      autoclean = \"true\"\n    }\n\n    transition {\n      days          = 30\n      storage_class = \"STANDARD_IA\" # or \"ONEZONE_IA\"\n    }\n\n    transition {\n      days          = 60\n      storage_class = \"GLACIER\"\n    }\n\n    expiration {\n      days = 90\n    }\n  }\n\n  lifecycle_rule {\n    id      = \"tmp\"\n    prefix  = \"tmp/\"\n    enabled = true\n\n    expiration {\n      date = \"2016-01-12\"\n    }\n  }\n}\n\nresource \"aws_s3_bucket\" \"versioning_bucket\" {\n  bucket = \"my-versioning-bucket\"\n  acl    = \"private\"\n\n  versioning {\n    enabled = true\n  }\n\n  lifecycle_rule {\n    prefix  = \"config/\"\n    enabled = true\n\n    noncurrent_version_transition {\n      days          = 30\n      storage_class = \"STANDARD_IA\"\n    }\n\n    noncurrent_version_transition {\n      days          = 60\n      storage_class = \"GLACIER\"\n    }\n\n    noncurrent_version_expiration {\n      days = 90\n    }\n  }\n}\n```\n\n### Using replication configuration\n\n~> **NOTE:** See the [`aws_s3_bucket_replication_configuration` resource](/docs/providers/aws/r/s3_bucket_replication_configuration.html) to support bi-directional replication configuration and additional features.\n\n```terraform\nprovider \"aws\" {\n  region = \"eu-west-1\"\n}\n\nprovider \"aws\" {\n  alias  = \"central\"\n  region = \"eu-central-1\"\n}\n\nresource \"aws_iam_role\" \"replication\" {\n  name = \"tf-iam-role-replication-12345\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"s3.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_policy\" \"replication\" {\n  name = \"tf-iam-role-policy-replication-12345\"\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"s3:GetReplicationConfiguration\",\n        \"s3:ListBucket\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"${aws_s3_bucket.source.arn}\"\n      ]\n    },\n    {\n      \"Action\": [\n        \"s3:GetObjectVersionForReplication\",\n        \"s3:GetObjectVersionAcl\",\n         \"s3:GetObjectVersionTagging\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"${aws_s3_bucket.source.arn}/*\"\n      ]\n    },\n    {\n      \"Action\": [\n        \"s3:ReplicateObject\",\n        \"s3:ReplicateDelete\",\n        \"s3:ReplicateTags\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"${aws_s3_bucket.destination.arn}/*\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"replication\" {\n  role       = aws_iam_role.replication.name\n  policy_arn = aws_iam_policy.replication.arn\n}\n\nresource \"aws_s3_bucket\" \"destination\" {\n  bucket = \"tf-test-bucket-destination-12345\"\n\n  versioning {\n    enabled = true\n  }\n}\n\nresource \"aws_s3_bucket\" \"source\" {\n  provider = aws.central\n  bucket   = \"tf-test-bucket-source-12345\"\n  acl      = \"private\"\n\n  versioning {\n    enabled = true\n  }\n\n  replication_configuration {\n    role = aws_iam_role.replication.arn\n\n    rules {\n      id     = \"foobar\"\n      status = \"Enabled\"\n\n      filter {\n        tags = {}\n      }\n      destination {\n        bucket        = aws_s3_bucket.destination.arn\n        storage_class = \"STANDARD\"\n\n        replication_time {\n          status  = \"Enabled\"\n          minutes = 15\n        }\n\n        metrics {\n          status  = \"Enabled\"\n          minutes = 15\n        }\n      }\n    }\n  }\n}\n```\n\n### Enable Default Server Side Encryption\n\n```terraform\nresource \"aws_kms_key\" \"mykey\" {\n  description             = \"This key is used to encrypt bucket objects\"\n  deletion_window_in_days = 10\n}\n\nresource \"aws_s3_bucket\" \"mybucket\" {\n  bucket = \"mybucket\"\n\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        kms_master_key_id = aws_kms_key.mykey.arn\n        sse_algorithm     = \"aws:kms\"\n      }\n    }\n  }\n}\n```\n\n### Using ACL policy grants\n\n```terraform\ndata \"aws_canonical_user_id\" \"current_user\" {}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"mybucket\"\n\n  grant {\n    id          = data.aws_canonical_user_id.current_user.id\n    type        = \"CanonicalUser\"\n    permissions = [\"FULL_CONTROL\"]\n  }\n\n  grant {\n    type        = \"Group\"\n    permissions = [\"READ_ACP\", \"WRITE\"]\n    uri         = \"http://acs.amazonaws.com/groups/s3/LogDelivery\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Optional, Forces new resource) The name of the bucket. If omitted, Terraform will assign a random, unique name. Must be lowercase and less than or equal to 63 characters in length. A full list of bucket naming rules [may be found here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html).\n* `bucket_prefix` - (Optional, Forces new resource) Creates a unique bucket name beginning with the specified prefix. Conflicts with `bucket`. Must be lowercase and less than or equal to 37 characters in length. A full list of bucket naming rules [may be found here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html).\n* `acl` - (Optional) The [canned ACL](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl) to apply. Valid values are `private`, `public-read`, `public-read-write`, `aws-exec-read`, `authenticated-read`, and `log-delivery-write`. Defaults to `private`.  Conflicts with `grant`.\n* `grant` - (Optional) An [ACL policy grant](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#sample-acl) (documented below). Conflicts with `acl`.\n* `policy` - (Optional) A valid [bucket policy](https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html) JSON document. Note that if the policy document is not specific enough (but still valid), Terraform may view the policy as constantly changing in a `terraform plan`. In this case, please make sure you use the verbose/specific version of the policy. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n* `tags` - (Optional) A map of tags to assign to the bucket. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `force_destroy` - (Optional, Default:`false`) A boolean that indicates all objects (including any [locked objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock-overview.html)) should be deleted from the bucket so that the bucket can be destroyed without error. These objects are *not* recoverable.\n* `website` - (Optional) A website object (documented below).\n* `cors_rule` - (Optional) A rule of [Cross-Origin Resource Sharing](https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html) (documented below).\n* `versioning` - (Optional) A state of [versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html) (documented below)\n* `logging` - (Optional) A settings of [bucket logging](https://docs.aws.amazon.com/AmazonS3/latest/UG/ManagingBucketLogging.html) (documented below).\n* `lifecycle_rule` - (Optional) A configuration of [object lifecycle management](http://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html) (documented below).\n* `acceleration_status` - (Optional) Sets the accelerate configuration of an existing bucket. Can be `Enabled` or `Suspended`.\n* `request_payer` - (Optional) Specifies who should bear the cost of Amazon S3 data transfer.\nCan be either `BucketOwner` or `Requester`. By default, the owner of the S3 bucket would incur\nthe costs of any data transfer. See [Requester Pays Buckets](http://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html)\ndeveloper guide for more information.\n* `replication_configuration` - (Optional) A configuration of [replication configuration](http://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html) (documented below).\n* `server_side_encryption_configuration` - (Optional) A configuration of [server-side encryption configuration](http://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html) (documented below)\n* `object_lock_configuration` - (Optional) A configuration of [S3 object locking](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock.html) (documented below)\n\n~> **NOTE:** You cannot use `acceleration_status` in `cn-north-1` or `us-gov-west-1`\n\nThe `website` object supports the following:\n\n* `index_document` - (Required, unless using `redirect_all_requests_to`) Amazon S3 returns this index document when requests are made to the root domain or any of the subfolders.\n* `error_document` - (Optional) An absolute path to the document to return in case of a 4XX error.\n* `redirect_all_requests_to` - (Optional) A hostname to redirect all website requests for this bucket to. Hostname can optionally be prefixed with a protocol (`http://` or `https://`) to use when redirecting requests. The default is the protocol that is used in the original request.\n* `routing_rules` - (Optional) A json array containing [routing rules](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-websiteconfiguration-routingrules.html)\ndescribing redirect behavior and when redirects are applied.\n\nThe `CORS` object supports the following:\n\n* `allowed_headers` (Optional) Specifies which headers are allowed.\n* `allowed_methods` (Required) Specifies which methods are allowed. Can be `GET`, `PUT`, `POST`, `DELETE` or `HEAD`.\n* `allowed_origins` (Required) Specifies which origins are allowed.\n* `expose_headers` (Optional) Specifies expose header in the response.\n* `max_age_seconds` (Optional) Specifies time in seconds that browser can cache the response for a preflight request.\n\nThe `versioning` object supports the following:\n\n* `enabled` - (Optional) Enable versioning. Once you version-enable a bucket, it can never return to an unversioned state. You can, however, suspend versioning on that bucket.\n* `mfa_delete` - (Optional) Enable MFA delete for either `Change the versioning state of your bucket` or `Permanently delete an object version`. Default is `false`. This cannot be used to toggle this setting but is available to allow managed buckets to reflect the state in AWS\n\nThe `logging` object supports the following:\n\n* `target_bucket` - (Required) The name of the bucket that will receive the log objects.\n* `target_prefix` - (Optional) To specify a key prefix for log objects.\n\nThe `lifecycle_rule` object supports the following:\n\n* `id` - (Optional) Unique identifier for the rule. Must be less than or equal to 255 characters in length.\n* `prefix` - (Optional) Object key prefix identifying one or more objects to which the rule applies.\n* `tags` - (Optional) Specifies object tags key and value.\n* `enabled` - (Required) Specifies lifecycle rule status.\n* `abort_incomplete_multipart_upload_days` (Optional) Specifies the number of days after initiating a multipart upload when the multipart upload must be completed.\n* `expiration` - (Optional) Specifies a period in the object's expire (documented below).\n* `transition` - (Optional) Specifies a period in the object's transitions (documented below).\n* `noncurrent_version_expiration` - (Optional) Specifies when noncurrent object versions expire (documented below).\n* `noncurrent_version_transition` - (Optional) Specifies when noncurrent object versions transitions (documented below).\n\nAt least one of `abort_incomplete_multipart_upload_days`, `expiration`, `transition`, `noncurrent_version_expiration`, `noncurrent_version_transition` must be specified.\n\nThe `expiration` object supports the following\n\n* `date` (Optional) Specifies the date after which you want the corresponding action to take effect.\n* `days` (Optional) Specifies the number of days after object creation when the specific rule action takes effect.\n* `expired_object_delete_marker` (Optional) On a versioned bucket (versioning-enabled or versioning-suspended bucket), you can add this element in the lifecycle configuration to direct Amazon S3 to delete expired object delete markers. This cannot be specified with Days or Date in a Lifecycle Expiration Policy.\n\nThe `transition` object supports the following\n\n* `date` (Optional) Specifies the date after which you want the corresponding action to take effect.\n* `days` (Optional) Specifies the number of days after object creation when the specific rule action takes effect.\n* `storage_class` (Required) Specifies the Amazon S3 [storage class](https://docs.aws.amazon.com/AmazonS3/latest/API/API_Transition.html#AmazonS3-Type-Transition-StorageClass) to which you want the object to transition.\n\nThe `noncurrent_version_expiration` object supports the following\n\n* `days` (Required) Specifies the number of days noncurrent object versions expire.\n\nThe `noncurrent_version_transition` object supports the following\n\n* `days` (Required) Specifies the number of days noncurrent object versions transition.\n* `storage_class` (Required) Specifies the Amazon S3 [storage class](https://docs.aws.amazon.com/AmazonS3/latest/API/API_Transition.html#AmazonS3-Type-Transition-StorageClass) to which you want the object to transition.\n\nThe `replication_configuration` object supports the following:\n\n~> **NOTE:** See the [`aws_s3_bucket_replication_configuration` resource documentation](/docs/providers/aws/r/s3_bucket_replication_configuration.html) to avoid conflicts. Replication configuration can only be defined in one resource not both.  When using the independent replication configuration resource the following lifecycle rule is needed on the `aws_s3_bucket` resource.\n\n```\nlifecycle {\n  ignore_changes = [\n    replication_configuration\n  ]\n}\n```\n\n* `role` - (Required) The ARN of the IAM role for Amazon S3 to assume when replicating the objects.\n* `rules` - (Required) Specifies the rules managing the replication (documented below).\n\nThe `rules` object supports the following:\n\n~> **NOTE:** Amazon S3's latest version of the replication configuration is V2, which includes the `filter` attribute for replication rules.\nWith the `filter` attribute, you can specify object filters based on the object key prefix, tags, or both to scope the objects that the rule applies to.\nReplication configuration V1 supports filtering based on only the `prefix` attribute. For backwards compatibility, Amazon S3 continues to support the V1 configuration.\n\n* `delete_marker_replication_status` - (Optional) Whether delete markers are replicated. The only valid value is `Enabled`. To disable, omit this argument. This argument is only valid with V2 replication configurations (i.e., when `filter` is used).\n* `destination` - (Required) Specifies the destination for the rule (documented below).\n* `filter` - (Optional, Conflicts with `prefix`) Filter that identifies subset of objects to which the replication rule applies (documented below).\n* `id` - (Optional) Unique identifier for the rule. Must be less than or equal to 255 characters in length.\n* `prefix` - (Optional, Conflicts with `filter`) Object keyname prefix identifying one or more objects to which the rule applies. Must be less than or equal to 1024 characters in length.\n* `priority` - (Optional) The priority associated with the rule. Priority should only be set if `filter` is configured. If not provided, defaults to `0`. Priority must be unique between multiple rules.\n* `source_selection_criteria` - (Optional) Specifies special object selection criteria (documented below).\n* `status` - (Required) The status of the rule. Either `Enabled` or `Disabled`. The rule is ignored if status is not Enabled.\n\n~> **NOTE:** Replication to multiple destination buckets requires that `priority` is specified in the `rules` object. If the corresponding rule requires no filter, an empty configuration block `filter {}` must be specified.\n\nThe `destination` object supports the following:\n\n* `bucket` - (Required) The ARN of the S3 bucket where you want Amazon S3 to store replicas of the object identified by the rule.\n* `storage_class` - (Optional) The [storage class](https://docs.aws.amazon.com/AmazonS3/latest/API/API_Destination.html#AmazonS3-Type-Destination-StorageClass) used to store the object. By default, Amazon S3 uses the storage class of the source object to create the object replica.\n* `replica_kms_key_id` - (Optional) Destination KMS encryption key ARN for SSE-KMS replication. Must be used in conjunction with\n  `sse_kms_encrypted_objects` source selection criteria.\n* `access_control_translation` - (Optional) Specifies the overrides to use for object owners on replication. Must be used in conjunction with `account_id` owner override configuration.\n* `account_id` - (Optional) The Account ID to use for overriding the object owner on replication. Must be used in conjunction with `access_control_translation` override configuration.\n* `replication_time` - (Optional) Enables S3 Replication Time Control (S3 RTC) (documented below).\n* `metrics` - (Optional) Enables replication metrics (required for S3 RTC) (documented below).\n\nThe `replication_time` object supports the following:\n\n* `status` - (Optional) The status of RTC. Either `Enabled` or `Disabled`.\n* `minutes` - (Optional) Threshold within which objects are to be replicated. The only valid value is `15`.\n\nThe `metrics` object supports the following:\n\n* `status` - (Optional) The status of replication metrics. Either `Enabled` or `Disabled`.\n* `minutes` - (Optional) Threshold within which objects are to be replicated. The only valid value is `15`.\n\nThe `source_selection_criteria` object supports the following:\n\n* `sse_kms_encrypted_objects` - (Optional) Match SSE-KMS encrypted objects (documented below). If specified, `replica_kms_key_id`\n   in `destination` must be specified as well.\n\nThe `sse_kms_encrypted_objects` object supports the following:\n\n* `enabled` - (Required) Boolean which indicates if this criteria is enabled.\n\nThe `filter` object supports the following:\n\n* `prefix` - (Optional) Object keyname prefix that identifies subset of objects to which the rule applies. Must be less than or equal to 1024 characters in length.\n* `tags` - (Optional)  A map of tags that identifies subset of objects to which the rule applies.\nThe rule applies only to objects having all the tags in its tagset.\n\nThe `server_side_encryption_configuration` object supports the following:\n\n* `rule` - (required) A single object for server-side encryption by default configuration. (documented below)\n\nThe `rule` object supports the following:\n\n* `apply_server_side_encryption_by_default` - (required) A single object for setting server-side encryption by default. (documented below)\n* `bucket_key_enabled` - (Optional) Whether or not to use [Amazon S3 Bucket Keys](https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-key.html) for SSE-KMS.\n\nThe `apply_server_side_encryption_by_default` object supports the following:\n\n* `sse_algorithm` - (required) The server-side encryption algorithm to use. Valid values are `AES256` and `aws:kms`\n* `kms_master_key_id` - (optional) The AWS KMS master key ID used for the SSE-KMS encryption. This can only be used when you set the value of `sse_algorithm` as `aws:kms`. The default `aws/s3` AWS KMS master key is used if this element is absent while the `sse_algorithm` is `aws:kms`.\n\nThe `grant` object supports the following:\n\n* `id` - (optional) Canonical user id to grant for. Used only when `type` is `CanonicalUser`.\n* `type` - (required) - Type of grantee to apply for. Valid values are `CanonicalUser` and `Group`. `AmazonCustomerByEmail` is not supported.\n* `permissions` - (required) List of permissions to apply for grantee. Valid values are `READ`, `WRITE`, `READ_ACP`, `WRITE_ACP`, `FULL_CONTROL`.\n* `uri` - (optional) Uri address to grant for. Used only when `type` is `Group`.\n\nThe `access_control_translation` object supports the following:\n\n* `owner` - (Required) The override value for the owner on replicated objects. Currently only `Destination` is supported.\n\nThe `object_lock_configuration` object supports the following:\n\n* `object_lock_enabled` - (Required) Indicates whether this bucket has an Object Lock configuration enabled. Valid value is `Enabled`.\n* `rule` - (Optional) The Object Lock rule in place for this bucket.\n\nThe `rule` object supports the following:\n\n* `default_retention` - (Required) The default retention period that you want to apply to new objects placed in this bucket.\n\nThe `default_retention` object supports the following:\n\n* `mode` - (Required) The default Object Lock retention mode you want to apply to new objects placed in this bucket. Valid values are `GOVERNANCE` and `COMPLIANCE`.\n* `days` - (Optional) The number of days that you want to specify for the default retention period.\n* `years` - (Optional) The number of years that you want to specify for the default retention period.\n\nEither `days` or `years` must be specified, but not both.\n\n~> **NOTE on `object_lock_configuration`:** You can only enable S3 Object Lock for new buckets. If you need to turn on S3 Object Lock for an existing bucket, please contact AWS Support.\nWhen you create a bucket with S3 Object Lock enabled, Amazon S3 automatically enables versioning for the bucket.\nOnce you create a bucket with S3 Object Lock enabled, you can't disable Object Lock or suspend versioning for the bucket.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the bucket.\n* `arn` - The ARN of the bucket. Will be of format `arn:aws:s3:::bucketname`.\n* `bucket_domain_name` - The bucket domain name. Will be of format `bucketname.s3.amazonaws.com`.\n* `bucket_regional_domain_name` - The bucket region-specific domain name. The bucket domain name including the region name, please refer [here](https://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region) for format. Note: The AWS CloudFront allows specifying S3 region-specific endpoint when creating S3 origin, it will prevent [redirect issues](https://forums.aws.amazon.com/thread.jspa?threadID=216814) from CloudFront to S3 Origin URL.\n* `hosted_zone_id` - The [Route 53 Hosted Zone ID](https://docs.aws.amazon.com/general/latest/gr/rande.html#s3_website_region_endpoints) for this bucket's region.\n* `region` - The AWS region this bucket resides in.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `website_endpoint` - The website endpoint, if the bucket is configured with a website. If not, this will be an empty string.\n* `website_domain` - The domain of the website endpoint, if the bucket is configured with a website. If not, this will be an empty string. This is used to create Route 53 alias records.\n\n## Import\n\nS3 bucket can be imported using the `bucket`, e.g.,\n\n```\n$ terraform import aws_s3_bucket.bucket bucket-name\n```\n\nThe `policy` argument is not imported and will be deprecated in a future version 3.x of the Terraform AWS Provider for removal in version 4.0. Use the [`aws_s3_bucket_policy` resource](/docs/providers/aws/r/s3_bucket_policy.html) to manage the S3 Bucket Policy instead.\n",
    "basename": "s3_bucket.html"
  },
  "s3_bucket_analytics_configuration.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_analytics_configuration",
    "description": "Provides a S3 bucket analytics configuration resource.",
    "preview": "# Resource: aws_s3_bucket_analytics_configuration\n\nProvides a S3 …",
    "content": "\n\n# Resource: aws_s3_bucket_analytics_configuration\n\nProvides a S3 bucket [analytics configuration](https://docs.aws.amazon.com/AmazonS3/latest/dev/analytics-storage-class.html) resource.\n\n## Example Usage\n\n### Add analytics configuration for entire S3 bucket and export results to a second S3 bucket\n\n```terraform\nresource \"aws_s3_bucket_analytics_configuration\" \"example-entire-bucket\" {\n  bucket = aws_s3_bucket.example.bucket\n  name   = \"EntireBucket\"\n\n  storage_class_analysis {\n    data_export {\n      destination {\n        s3_bucket_destination {\n          bucket_arn = aws_s3_bucket.analytics.arn\n        }\n      }\n    }\n  }\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_bucket\" \"analytics\" {\n  bucket = \"analytics destination\"\n}\n```\n\n### Add analytics configuration with S3 bucket object filter\n\n```terraform\nresource \"aws_s3_bucket_analytics_configuration\" \"example-filtered\" {\n  bucket = aws_s3_bucket.example.bucket\n  name   = \"ImportantBlueDocuments\"\n\n  filter {\n    prefix = \"documents/\"\n\n    tags = {\n      priority = \"high\"\n      class    = \"blue\"\n    }\n  }\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) The name of the bucket this analytics configuration is associated with.\n* `name` - (Required) Unique identifier of the analytics configuration for the bucket.\n* `filter` - (Optional) Object filtering that accepts a prefix, tags, or a logical AND of prefix and tags (documented below).\n* `storage_class_analysis` - (Optional) Configuration for the analytics data export (documented below).\n\nThe `filter` configuration supports the following:\n\n* `prefix` - (Optional) Object prefix for filtering.\n* `tags` - (Optional) Set of object tags for filtering.\n\nThe `storage_class_analysis` configuration supports the following:\n\n* `data_export` - (Required) Data export configuration (documented below).\n\nThe `data_export` configuration supports the following:\n\n* `output_schema_version` - (Optional) The schema version of exported analytics data. Allowed values: `V_1`. Default value: `V_1`.\n* `destination` - (Required) Specifies the destination for the exported analytics data (documented below).\n\nThe `destination` configuration supports the following:\n\n* `s3_bucket_destination` - (Required) Analytics data export currently only supports an S3 bucket destination (documented below).\n\nThe `s3_bucket_destination` configuration supports the following:\n\n* `bucket_arn` - (Required) The ARN of the destination bucket.\n* `bucket_account_id` - (Optional) The account ID that owns the destination bucket.\n* `format` - (Optional) The output format of exported analytics data. Allowed values: `CSV`. Default value: `CSV`.\n* `prefix` - (Optional) The prefix to append to exported analytics data.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nS3 bucket analytics configurations can be imported using `bucket:analytics`, e.g.,\n\n```\n$ terraform import aws_s3_bucket_analytics_configuration.my-bucket-entire-bucket my-bucket:EntireBucket\n```\n",
    "basename": "s3_bucket_analytics_configuration.html"
  },
  "s3_bucket_intelligent_tiering_configuration.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_intelligent_tiering_configuration",
    "description": "Provides an S3 Intelligent-Tiering configuration resource.",
    "preview": "# Resource: aws_s3_bucket_intelligent_tiering_configuration\n …",
    "content": "\n\n# Resource: aws_s3_bucket_intelligent_tiering_configuration\n\nProvides an [S3 Intelligent-Tiering](https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering.html) configuration resource.\n\n## Example Usage\n\n### Add intelligent tiering configuration for entire S3 bucket\n\n```terraform\nresource \"aws_s3_bucket_intelligent_tiering_configuration\" \"example-entire-bucket\" {\n  bucket = aws_s3_bucket.example.bucket\n  name   = \"EntireBucket\"\n\n  tiering {\n    access_tier = \"DEEP_ARCHIVE_ACCESS\"\n    days        = 180\n  }\n  tiering {\n    access_tier = \"ARCHIVE_ACCESS\"\n    days        = 125\n  }\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n```\n\n### Add intelligent tiering configuration with S3 bucket object filter\n\n```terraform\nresource \"aws_s3_bucket_intelligent_tiering_configuration\" \"example-filtered\" {\n  bucket = aws_s3_bucket.example.bucket\n  name   = \"ImportantBlueDocuments\"\n\n  status = \"Disabled\"\n\n  filter {\n    prefix = \"documents/\"\n\n    tags = {\n      priority = \"high\"\n      class    = \"blue\"\n    }\n  }\n\n  tiering {\n    access_tier = \"ARCHIVE_ACCESS\"\n    days        = 125\n  }\n}\n\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) The name of the bucket this intelligent tiering configuration is associated with.\n* `name` - (Required) The unique name used to identify the S3 Intelligent-Tiering configuration for the bucket.\n* `status` - (Optional) Specifies the status of the configuration. Valid values: `Enabled`, `Disabled`.\n* `filter` - (Optional) A bucket filter. The configuration only includes objects that meet the filter's criteria (documented below).\n* `tiering` - (Required) The S3 Intelligent-Tiering storage class tiers of the configuration (documented below).\n\nThe `filter` configuration supports the following:\n\n* `prefix` - (Optional) An object key name prefix that identifies the subset of objects to which the configuration applies.\n* `tags` - (Optional) All of these tags must exist in the object's tag set in order for the configuration to apply.\n\nThe `tiering` configuration supports the following:\n\n* `access_tier` - (Required) S3 Intelligent-Tiering access tier. Valid values: `ARCHIVE_CONFIGURATION`, `DEEP_ARCHIVE_CONFIGURATION`.\n* `days` - (Required) The number of consecutive days of no access after which an object will be eligible to be transitioned to the corresponding tier.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nS3 bucket intelligent tiering configurations can be imported using `bucket:name`, e.g.\n\n```\n$ terraform import aws_s3_bucket_intelligent_tiering_configuration.my-bucket-entire-bucket my-bucket:EntireBucket\n```\n",
    "basename": "s3_bucket_intelligent_tiering_configuration.html"
  },
  "s3_bucket_inventory.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_inventory",
    "description": "Provides a S3 bucket inventory configuration resource.",
    "preview": "# Resource: aws_s3_bucket_inventory\n\nProvides a S3 bucket [inventory …",
    "content": "\n\n# Resource: aws_s3_bucket_inventory\n\nProvides a S3 bucket [inventory configuration](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-inventory.html) resource.\n\n## Example Usage\n\n### Add inventory configuration\n\n```terraform\nresource \"aws_s3_bucket\" \"test\" {\n  bucket = \"my-tf-test-bucket\"\n}\n\nresource \"aws_s3_bucket\" \"inventory\" {\n  bucket = \"my-tf-inventory-bucket\"\n}\n\nresource \"aws_s3_bucket_inventory\" \"test\" {\n  bucket = aws_s3_bucket.test.id\n  name   = \"EntireBucketDaily\"\n\n  included_object_versions = \"All\"\n\n  schedule {\n    frequency = \"Daily\"\n  }\n\n  destination {\n    bucket {\n      format     = \"ORC\"\n      bucket_arn = aws_s3_bucket.inventory.arn\n    }\n  }\n}\n```\n\n### Add inventory configuration with S3 bucket object prefix\n\n```terraform\nresource \"aws_s3_bucket\" \"test\" {\n  bucket = \"my-tf-test-bucket\"\n}\n\nresource \"aws_s3_bucket\" \"inventory\" {\n  bucket = \"my-tf-inventory-bucket\"\n}\n\nresource \"aws_s3_bucket_inventory\" \"test-prefix\" {\n  bucket = aws_s3_bucket.test.id\n  name   = \"DocumentsWeekly\"\n\n  included_object_versions = \"All\"\n\n  schedule {\n    frequency = \"Daily\"\n  }\n\n  filter {\n    prefix = \"documents/\"\n  }\n\n  destination {\n    bucket {\n      format     = \"ORC\"\n      bucket_arn = aws_s3_bucket.inventory.arn\n      prefix     = \"inventory\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) The name of the source bucket that inventory lists the objects for.\n* `name` - (Required) Unique identifier of the inventory configuration for the bucket.\n* `included_object_versions` - (Required) Object versions to include in the inventory list. Valid values: `All`, `Current`.\n* `schedule` - (Required) Specifies the schedule for generating inventory results (documented below).\n* `destination` - (Required) Contains information about where to publish the inventory results (documented below).\n* `enabled` - (Optional, Default: `true`) Specifies whether the inventory is enabled or disabled.\n* `filter` - (Optional) Specifies an inventory filter. The inventory only includes objects that meet the filter's criteria (documented below).\n* `optional_fields` - (Optional) List of optional fields that are included in the inventory results. Please refer to the S3 [documentation](https://docs.aws.amazon.com/AmazonS3/latest/API/API_InventoryConfiguration.html#AmazonS3-Type-InventoryConfiguration-OptionalFields) for more details.\n\nThe `filter` configuration supports the following:\n\n* `prefix` - (Optional) The prefix that an object must have to be included in the inventory results.\n\nThe `schedule` configuration supports the following:\n\n* `frequency` - (Required) Specifies how frequently inventory results are produced. Valid values: `Daily`, `Weekly`.\n\nThe `destination` configuration supports the following:\n\n* `bucket` - (Required) The S3 bucket configuration where inventory results are published (documented below).\n\nThe `bucket` configuration supports the following:\n\n* `bucket_arn` - (Required) The Amazon S3 bucket ARN of the destination.\n* `format` - (Required) Specifies the output format of the inventory results. Can be `CSV`, [`ORC`](https://orc.apache.org/) or [`Parquet`](https://parquet.apache.org/).\n* `account_id` - (Optional) The ID of the account that owns the destination bucket. Recommended to be set to prevent problems if the destination bucket ownership changes.\n* `prefix` - (Optional) The prefix that is prepended to all inventory results.\n* `encryption` - (Optional) Contains the type of server-side encryption to use to encrypt the inventory (documented below).\n\nThe `encryption` configuration supports the following:\n\n* `sse_kms` - (Optional) Specifies to use server-side encryption with AWS KMS-managed keys to encrypt the inventory file (documented below).\n* `sse_s3` - (Optional) Specifies to use server-side encryption with Amazon S3-managed keys (SSE-S3) to encrypt the inventory file.\n\nThe `sse_kms` configuration supports the following:\n\n* `key_id` - (Required) The ARN of the KMS customer master key (CMK) used to encrypt the inventory file.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nS3 bucket inventory configurations can be imported using `bucket:inventory`, e.g.,\n\n```sh\n$ terraform import aws_s3_bucket_inventory.my-bucket-entire-bucket my-bucket:EntireBucket\n```\n",
    "basename": "s3_bucket_inventory.html"
  },
  "s3_bucket_metric.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_metric",
    "description": "Provides a S3 bucket metrics configuration resource.",
    "preview": "# Resource: aws_s3_bucket_metric\n\nProvides a S3 bucket [metrics …",
    "content": "\n\n# Resource: aws_s3_bucket_metric\n\nProvides a S3 bucket [metrics configuration](http://docs.aws.amazon.com/AmazonS3/latest/dev/metrics-configurations.html) resource.\n\n## Example Usage\n\n### Add metrics configuration for entire S3 bucket\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_bucket_metric\" \"example-entire-bucket\" {\n  bucket = aws_s3_bucket.example.bucket\n  name   = \"EntireBucket\"\n}\n```\n\n### Add metrics configuration with S3 bucket object filter\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_bucket_metric\" \"example-filtered\" {\n  bucket = aws_s3_bucket.example.bucket\n  name   = \"ImportantBlueDocuments\"\n\n  filter {\n    prefix = \"documents/\"\n\n    tags = {\n      priority = \"high\"\n      class    = \"blue\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) The name of the bucket to put metric configuration.\n* `name` - (Required) Unique identifier of the metrics configuration for the bucket.\n* `filter` - (Optional) [Object filtering](http://docs.aws.amazon.com/AmazonS3/latest/dev/metrics-configurations.html#metrics-configurations-filter) that accepts a prefix, tags, or a logical AND of prefix and tags (documented below).\n\nThe `filter` metric configuration supports the following:\n\n~> **NOTE**: At least one of `prefix` or `tags` is required when specifying a `filter`\n\n* `prefix` - (Optional) Object prefix for filtering (singular).\n* `tags` - (Optional) Object tags for filtering (up to 10).\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nS3 bucket metric configurations can be imported using `bucket:metric`, e.g.,\n\n```\n$ terraform import aws_s3_bucket_metric.my-bucket-entire-bucket my-bucket:EntireBucket\n```\n",
    "basename": "s3_bucket_metric.html"
  },
  "s3_bucket_notification.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_notification",
    "description": "Manages a S3 Bucket Notification Configuration",
    "preview": "# Resource: aws_s3_bucket_notification\n\nManages a S3 Bucket …",
    "content": "\n\n# Resource: aws_s3_bucket_notification\n\nManages a S3 Bucket Notification Configuration. For additional information, see the [Configuring S3 Event Notifications section in the Amazon S3 Developer Guide](https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html).\n\n~> **NOTE:** S3 Buckets only support a single notification configuration. Declaring multiple `aws_s3_bucket_notification` resources to the same S3 Bucket will cause a perpetual difference in configuration. See the example \"Trigger multiple Lambda functions\" for an option.\n\n## Example Usage\n\n### Add notification configuration to SNS Topic\n\n```terraform\nresource \"aws_sns_topic\" \"topic\" {\n  name = \"s3-event-notification-topic\"\n\n  policy = <<POLICY\n{\n    \"Version\":\"2012-10-17\",\n    \"Statement\":[{\n        \"Effect\": \"Allow\",\n        \"Principal\": { \"Service\": \"s3.amazonaws.com\" },\n        \"Action\": \"SNS:Publish\",\n        \"Resource\": \"arn:aws:sns:*:*:s3-event-notification-topic\",\n        \"Condition\":{\n            \"ArnLike\":{\"aws:SourceArn\":\"${aws_s3_bucket.bucket.arn}\"}\n        }\n    }]\n}\nPOLICY\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"your-bucket-name\"\n}\n\nresource \"aws_s3_bucket_notification\" \"bucket_notification\" {\n  bucket = aws_s3_bucket.bucket.id\n\n  topic {\n    topic_arn     = aws_sns_topic.topic.arn\n    events        = [\"s3:ObjectCreated:*\"]\n    filter_suffix = \".log\"\n  }\n}\n```\n\n### Add notification configuration to SQS Queue\n\n```terraform\nresource \"aws_sqs_queue\" \"queue\" {\n  name = \"s3-event-notification-queue\"\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": \"*\",\n      \"Action\": \"sqs:SendMessage\",\n\t  \"Resource\": \"arn:aws:sqs:*:*:s3-event-notification-queue\",\n      \"Condition\": {\n        \"ArnEquals\": { \"aws:SourceArn\": \"${aws_s3_bucket.bucket.arn}\" }\n      }\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"your-bucket-name\"\n}\n\nresource \"aws_s3_bucket_notification\" \"bucket_notification\" {\n  bucket = aws_s3_bucket.bucket.id\n\n  queue {\n    queue_arn     = aws_sqs_queue.queue.arn\n    events        = [\"s3:ObjectCreated:*\"]\n    filter_suffix = \".log\"\n  }\n}\n```\n\n### Add notification configuration to Lambda Function\n\n```terraform\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_lambda_permission\" \"allow_bucket\" {\n  statement_id  = \"AllowExecutionFromS3Bucket\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.func.arn\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket.bucket.arn\n}\n\nresource \"aws_lambda_function\" \"func\" {\n  filename      = \"your-function.zip\"\n  function_name = \"example_lambda_name\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"exports.example\"\n  runtime       = \"go1.x\"\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"your-bucket-name\"\n}\n\nresource \"aws_s3_bucket_notification\" \"bucket_notification\" {\n  bucket = aws_s3_bucket.bucket.id\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.func.arn\n    events              = [\"s3:ObjectCreated:*\"]\n    filter_prefix       = \"AWSLogs/\"\n    filter_suffix       = \".log\"\n  }\n\n  depends_on = [aws_lambda_permission.allow_bucket]\n}\n```\n\n### Trigger multiple Lambda functions\n\n```terraform\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  assume_role_policy = <<EOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_lambda_permission\" \"allow_bucket1\" {\n  statement_id  = \"AllowExecutionFromS3Bucket1\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.func1.arn\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket.bucket.arn\n}\n\nresource \"aws_lambda_function\" \"func1\" {\n  filename      = \"your-function1.zip\"\n  function_name = \"example_lambda_name1\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"exports.example\"\n  runtime       = \"go1.x\"\n}\n\nresource \"aws_lambda_permission\" \"allow_bucket2\" {\n  statement_id  = \"AllowExecutionFromS3Bucket2\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.func2.arn\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket.bucket.arn\n}\n\nresource \"aws_lambda_function\" \"func2\" {\n  filename      = \"your-function2.zip\"\n  function_name = \"example_lambda_name2\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"exports.example\"\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"your-bucket-name\"\n}\n\nresource \"aws_s3_bucket_notification\" \"bucket_notification\" {\n  bucket = aws_s3_bucket.bucket.id\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.func1.arn\n    events              = [\"s3:ObjectCreated:*\"]\n    filter_prefix       = \"AWSLogs/\"\n    filter_suffix       = \".log\"\n  }\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.func2.arn\n    events              = [\"s3:ObjectCreated:*\"]\n    filter_prefix       = \"OtherLogs/\"\n    filter_suffix       = \".log\"\n  }\n\n  depends_on = [\n    aws_lambda_permission.allow_bucket1,\n    aws_lambda_permission.allow_bucket2,\n  ]\n}\n```\n\n### Add multiple notification configurations to SQS Queue\n\n```terraform\nresource \"aws_sqs_queue\" \"queue\" {\n  name = \"s3-event-notification-queue\"\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": \"*\",\n      \"Action\": \"sqs:SendMessage\",\n\t  \"Resource\": \"arn:aws:sqs:*:*:s3-event-notification-queue\",\n      \"Condition\": {\n        \"ArnEquals\": { \"aws:SourceArn\": \"${aws_s3_bucket.bucket.arn}\" }\n      }\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"your-bucket-name\"\n}\n\nresource \"aws_s3_bucket_notification\" \"bucket_notification\" {\n  bucket = aws_s3_bucket.bucket.id\n\n  queue {\n    id            = \"image-upload-event\"\n    queue_arn     = aws_sqs_queue.queue.arn\n    events        = [\"s3:ObjectCreated:*\"]\n    filter_prefix = \"images/\"\n  }\n\n  queue {\n    id            = \"video-upload-event\"\n    queue_arn     = aws_sqs_queue.queue.arn\n    events        = [\"s3:ObjectCreated:*\"]\n    filter_prefix = \"videos/\"\n  }\n}\n```\n\nFor Terraform's [JSON syntax](https://www.terraform.io/docs/configuration/syntax.html), use an array instead of defining the `queue` key twice.\n\n```json\n{\n\t\"bucket\": \"${aws_s3_bucket.bucket.id}\",\n\t\"queue\": [\n\t\t{\n\t\t\t\"id\": \"image-upload-event\",\n\t\t\t\"queue_arn\": \"${aws_sqs_queue.queue.arn}\",\n\t\t\t\"events\": [\"s3:ObjectCreated:*\"],\n\t\t\t\"filter_prefix\": \"images/\"\n\t\t},\n\t\t{\n\t\t\t\"id\": \"video-upload-event\",\n\t\t\t\"queue_arn\": \"${aws_sqs_queue.queue.arn}\",\n\t\t\t\"events\": [\"s3:ObjectCreated:*\"],\n\t\t\t\"filter_prefix\": \"videos/\"\n\t\t}\n\t]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) The name of the bucket to put notification configuration.\n* `topic` - (Optional) The notification configuration to SNS Topic (documented below).\n* `queue` - (Optional) The notification configuration to SQS Queue (documented below).\n* `lambda_function` - (Optional, Multiple) Used to configure notifications to a Lambda Function (documented below).\n\nThe `topic` notification configuration supports the following:\n\n* `id` - (Optional) Specifies unique identifier for each of the notification configurations.\n* `topic_arn` - (Required) Specifies Amazon SNS topic ARN.\n* `events` - (Required) Specifies [event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.\n* `filter_prefix` - (Optional) Specifies object key name prefix.\n* `filter_suffix` - (Optional) Specifies object key name suffix.\n\nThe `queue` notification configuration supports the following:\n\n* `id` - (Optional) Specifies unique identifier for each of the notification configurations.\n* `queue_arn` - (Required) Specifies Amazon SQS queue ARN.\n* `events` - (Required) Specifies [event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.\n* `filter_prefix` - (Optional) Specifies object key name prefix.\n* `filter_suffix` - (Optional) Specifies object key name suffix.\n\nThe `lambda_function` notification configuration supports the following:\n\n* `id` - (Optional) Specifies unique identifier for each of the notification configurations.\n* `lambda_function_arn` - (Required) Specifies Amazon Lambda function ARN.\n* `events` - (Required) Specifies [event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.\n* `filter_prefix` - (Optional) Specifies object key name prefix.\n* `filter_suffix` - (Optional) Specifies object key name suffix.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nS3 bucket notification can be imported using the `bucket`, e.g.,\n\n```\n$ terraform import aws_s3_bucket_notification.bucket_notification bucket-name\n```\n",
    "basename": "s3_bucket_notification.html"
  },
  "s3_bucket_object.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_object",
    "description": "Provides a S3 bucket object resource.",
    "preview": "# Resource: aws_s3_bucket_object\n\nProvides a S3 bucket object …",
    "content": "\n\n# Resource: aws_s3_bucket_object\n\nProvides a S3 bucket object resource.\n\n## Example Usage\n\n### Uploading a file to a bucket\n\n```terraform\nresource \"aws_s3_bucket_object\" \"object\" {\n  bucket = \"your_bucket_name\"\n  key    = \"new_object_key\"\n  source = \"path/to/file\"\n\n  # The filemd5() function is available in Terraform 0.11.12 and later\n  # For Terraform 0.11.11 and earlier, use the md5() function and the file() function:\n  # etag = \"${md5(file(\"path/to/file\"))}\"\n  etag = filemd5(\"path/to/file\")\n}\n```\n\n### Encrypting with KMS Key\n\n```terraform\nresource \"aws_kms_key\" \"examplekms\" {\n  description             = \"KMS key 1\"\n  deletion_window_in_days = 7\n}\n\nresource \"aws_s3_bucket\" \"examplebucket\" {\n  bucket = \"examplebuckettftest\"\n  acl    = \"private\"\n}\n\nresource \"aws_s3_bucket_object\" \"examplebucket_object\" {\n  key        = \"someobject\"\n  bucket     = aws_s3_bucket.examplebucket.id\n  source     = \"index.html\"\n  kms_key_id = aws_kms_key.examplekms.arn\n}\n```\n\n### Server Side Encryption with S3 Default Master Key\n\n```terraform\nresource \"aws_s3_bucket\" \"examplebucket\" {\n  bucket = \"examplebuckettftest\"\n  acl    = \"private\"\n}\n\nresource \"aws_s3_bucket_object\" \"examplebucket_object\" {\n  key                    = \"someobject\"\n  bucket                 = aws_s3_bucket.examplebucket.id\n  source                 = \"index.html\"\n  server_side_encryption = \"aws:kms\"\n}\n```\n\n### Server Side Encryption with AWS-Managed Key\n\n```terraform\nresource \"aws_s3_bucket\" \"examplebucket\" {\n  bucket = \"examplebuckettftest\"\n  acl    = \"private\"\n}\n\nresource \"aws_s3_bucket_object\" \"examplebucket_object\" {\n  key                    = \"someobject\"\n  bucket                 = aws_s3_bucket.examplebucket.id\n  source                 = \"index.html\"\n  server_side_encryption = \"AES256\"\n}\n```\n\n### S3 Object Lock\n\n```terraform\nresource \"aws_s3_bucket\" \"examplebucket\" {\n  bucket = \"examplebuckettftest\"\n  acl    = \"private\"\n\n  versioning {\n    enabled = true\n  }\n\n  object_lock_configuration {\n    object_lock_enabled = \"Enabled\"\n  }\n}\n\nresource \"aws_s3_bucket_object\" \"examplebucket_object\" {\n  key    = \"someobject\"\n  bucket = aws_s3_bucket.examplebucket.id\n  source = \"important.txt\"\n\n  object_lock_legal_hold_status = \"ON\"\n  object_lock_mode              = \"GOVERNANCE\"\n  object_lock_retain_until_date = \"2021-12-31T23:59:60Z\"\n\n  force_destroy = true\n}\n```\n\n## Argument Reference\n\n-> **Note:** If you specify `content_encoding` you are responsible for encoding the body appropriately. `source`, `content`, and `content_base64` all expect already encoded/compressed bytes.\n\nThe following arguments are required:\n\n* `bucket` - (Required) Name of the bucket to put the file in. Alternatively, an [S3 access point](https://docs.aws.amazon.com/AmazonS3/latest/dev/using-access-points.html) ARN can be specified.\n* `key` - (Required) Name of the object once it is in the bucket.\n\nThe following arguments are optional:\n\n* `acl` - (Optional) [Canned ACL](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl) to apply. Valid values are `private`, `public-read`, `public-read-write`, `aws-exec-read`, `authenticated-read`, `bucket-owner-read`, and `bucket-owner-full-control`. Defaults to `private`.\n* `bucket_key_enabled` - (Optional) Whether or not to use [Amazon S3 Bucket Keys](https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-key.html) for SSE-KMS.\n* `cache_control` - (Optional) Caching behavior along the request/reply chain Read [w3c cache_control](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9) for further details.\n* `content_base64` - (Optional, conflicts with `source` and `content`) Base64-encoded data that will be decoded and uploaded as raw bytes for the object content. This allows safely uploading non-UTF8 binary data, but is recommended only for small content such as the result of the `gzipbase64` function with small text strings. For larger objects, use `source` to stream the content from a disk file.\n* `content_disposition` - (Optional) Presentational information for the object. Read [w3c content_disposition](http://www.w3.org/Protocols/rfc2616/rfc2616-sec19.html#sec19.5.1) for further information.\n* `content_encoding` - (Optional) Content encodings that have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field. Read [w3c content encoding](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.11) for further information.\n* `content_language` - (Optional) Language the content is in e.g., en-US or en-GB.\n* `content_type` - (Optional) Standard MIME type describing the format of the object data, e.g., application/octet-stream. All Valid MIME Types are valid for this input.\n* `content` - (Optional, conflicts with `source` and `content_base64`) Literal string value to use as the object content, which will be uploaded as UTF-8-encoded text.\n* `etag` - (Optional) Triggers updates when the value changes. The only meaningful value is `filemd5(\"path/to/file\")` (Terraform 0.11.12 or later) or `${md5(file(\"path/to/file\"))}` (Terraform 0.11.11 or earlier). This attribute is not compatible with KMS encryption, `kms_key_id` or `server_side_encryption = \"aws:kms\"` (see `source_hash` instead).\n* `force_destroy` - (Optional) Whether to allow the object to be deleted by removing any legal hold on any object version. Default is `false`. This value should be set to `true` only if the bucket has S3 object lock enabled.\n* `kms_key_id` - (Optional) ARN of the KMS Key to use for object encryption. If the S3 Bucket has server-side encryption enabled, that value will automatically be used. If referencing the `aws_kms_key` resource, use the `arn` attribute. If referencing the `aws_kms_alias` data source or resource, use the `target_key_arn` attribute. Terraform will only perform drift detection if a configuration value is provided.\n* `metadata` - (Optional) Map of keys/values to provision metadata (will be automatically prefixed by `x-amz-meta-`, note that only lowercase label are currently supported by the AWS Go API).\n* `object_lock_legal_hold_status` - (Optional) [Legal hold](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock-overview.html#object-lock-legal-holds) status that you want to apply to the specified object. Valid values are `ON` and `OFF`.\n* `object_lock_mode` - (Optional) Object lock [retention mode](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock-overview.html#object-lock-retention-modes) that you want to apply to this object. Valid values are `GOVERNANCE` and `COMPLIANCE`.\n* `object_lock_retain_until_date` - (Optional) Date and time, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8), when this object's object lock will [expire](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock-overview.html#object-lock-retention-periods).\n* `server_side_encryption` - (Optional) Server-side encryption of the object in S3. Valid values are \"`AES256`\" and \"`aws:kms`\".\n* `source_hash` - (Optional) Triggers updates like `etag` but useful to address `etag` encryption limitations. Set using `filemd5(\"path/to/source\")` (Terraform 0.11.12 or later). (The value is only stored in state and not saved by AWS.)\n* `source` - (Optional, conflicts with `content` and `content_base64`) Path to a file that will be read and uploaded as raw bytes for the object content.\n* `storage_class` - (Optional) [Storage Class](https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html#AmazonS3-PutObject-request-header-StorageClass) for the object. Defaults to \"`STANDARD`\".\n* `tags` - (Optional) Map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `website_redirect` - (Optional) Target URL for [website redirect](http://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-page-redirect.html).\n\nIf no content is provided through `source`, `content` or `content_base64`, then the object will be empty.\n\n-> **Note:** Terraform ignores all leading `/`s in the object's `key` and treats multiple `/`s in the rest of the object's `key` as a single `/`, so values of `/index.html` and `index.html` correspond to the same S3 object as do `first//second///third//` and `first/second/third/`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `etag` - ETag generated for the object (an MD5 sum of the object content). For plaintext objects or objects encrypted with an AWS-managed key, the hash is an MD5 digest of the object data. For objects encrypted with a KMS key or objects created by either the Multipart Upload or Part Copy operation, the hash is not an MD5 digest, regardless of the method of encryption. More information on possible values can be found on [Common Response Headers](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonResponseHeaders.html).\n* `id` - `key` of the resource supplied above\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version_id` - Unique version ID value for the object, if bucket versioning is enabled.\n\n## Import\n\nObjects can be imported using the `id`. The `id` is the bucket name and the key together e.g.,\n\n```\n$ terraform import aws_s3_bucket_object.object some-bucket-name/some/key.txt\n```\n\nAdditionally, s3 url syntax can be used, e.g.,\n\n```\n$ terraform import aws_s3_bucket_object.object s3://some-bucket-name/some/key.txt\n```\n",
    "basename": "s3_bucket_object.html"
  },
  "s3_bucket_ownership_controls.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_ownership_controls",
    "description": "Manages S3 Bucket Ownership Controls.",
    "preview": "# Resource: aws_s3_bucket_ownership_controls\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_s3_bucket_ownership_controls\n\nProvides a resource to manage S3 Bucket Ownership Controls. For more information, see the [S3 Developer Guide](https://docs.aws.amazon.com/AmazonS3/latest/dev/about-object-ownership.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_bucket_ownership_controls\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n\n  rule {\n    object_ownership = \"BucketOwnerPreferred\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `bucket` - (Required) The name of the bucket that you want to associate this access point with.\n* `rule` - (Required) Configuration block(s) with Ownership Controls rules. Detailed below.\n\n### rule Configuration Block\n\nThe following arguments are required:\n\n* `object_ownership` - (Required) Object ownership. Valid values: `BucketOwnerPreferred` or `ObjectWriter`\n    * `BucketOwnerPreferred` - Objects uploaded to the bucket change ownership to the bucket owner if the objects are uploaded with the `bucket-owner-full-control` canned ACL.\n    * `ObjectWriter` - The uploading account will own the object if the object is uploaded with the `bucket-owner-full-control` canned ACL.\n    * `BucketOwnerEnforced` - The bucket owner automatically owns and has full control over every object in the bucket. ACLs no longer affect permissions to data in the S3 bucket.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - S3 Bucket name.\n\n## Import\n\nS3 Bucket Ownership Controls can be imported using S3 Bucket name, e.g.,\n\n```\n$ terraform import aws_s3_bucket_ownership_controls.example my-bucket\n```\n",
    "basename": "s3_bucket_ownership_controls.html"
  },
  "s3_bucket_policy.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_policy",
    "description": "Attaches a policy to an S3 bucket resource.",
    "preview": "# Resource: aws_s3_bucket_policy\n\nAttaches a policy to an S3 bucket …",
    "content": "\n\n# Resource: aws_s3_bucket_policy\n\nAttaches a policy to an S3 bucket resource.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"my-tf-test-bucket\"\n}\n\nresource \"aws_s3_bucket_policy\" \"allow_access_from_another_account\" {\n  bucket = aws_s3_bucket.example.id\n  policy = data.aws_iam_policy_document.allow_access_from_another_account.json\n}\n\ndata \"aws_iam_policy_document\" \"allow_access_from_another_account\" {\n  statement {\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"123456789012\"]\n    }\n\n    actions = [\n      \"s3:GetObject\",\n      \"s3:ListBucket\",\n    ]\n\n    resources = [\n      aws_s3_bucket.example.arn,\n      \"${aws_s3_bucket.example.arn}/*\",\n    ]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) The name of the bucket to which to apply the policy.\n* `policy` - (Required) The text of the policy. Although this is a bucket policy rather than an IAM policy, the [`aws_iam_policy_document`](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/iam_policy_document) data source may be used, so long as it specifies a principal. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy). Note: Bucket policies are limited to 20 KB in size.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nS3 bucket policies can be imported using the bucket name, e.g.,\n\n```\n$ terraform import aws_s3_bucket_policy.example my-bucket-name\n```\n",
    "basename": "s3_bucket_policy.html"
  },
  "s3_bucket_public_access_block.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_public_access_block",
    "description": "Manages S3 bucket-level Public Access Block Configuration",
    "preview": "# Resource: aws_s3_bucket_public_access_block\n\nManages S3 …",
    "content": "\n\n# Resource: aws_s3_bucket_public_access_block\n\nManages S3 bucket-level Public Access Block configuration. For more information about these settings, see the [AWS S3 Block Public Access documentation](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n\n  block_public_acls   = true\n  block_public_policy = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) S3 Bucket to which this Public Access Block configuration should be applied.\n* `block_public_acls` - (Optional) Whether Amazon S3 should block public ACLs for this bucket. Defaults to `false`. Enabling this setting does not affect existing policies or ACLs. When set to `true` causes the following behavior:\n    * PUT Bucket acl and PUT Object acl calls will fail if the specified ACL allows public access.\n    * PUT Object calls will fail if the request includes an object ACL.\n* `block_public_policy` - (Optional) Whether Amazon S3 should block public bucket policies for this bucket. Defaults to `false`. Enabling this setting does not affect the existing bucket policy. When set to `true` causes Amazon S3 to:\n    * Reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n* `ignore_public_acls` - (Optional) Whether Amazon S3 should ignore public ACLs for this bucket. Defaults to `false`. Enabling this setting does not affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set. When set to `true` causes Amazon S3 to:\n    * Ignore public ACLs on this bucket and any objects that it contains.\n* `restrict_public_buckets` - (Optional) Whether Amazon S3 should restrict public bucket policies for this bucket. Defaults to `false`. Enabling this setting does not affect the previously stored bucket policy, except that public and cross-account access within the public bucket policy, including non-public delegation to specific accounts, is blocked. When set to `true`:\n    * Only the bucket owner and AWS Services can access this buckets if it has a public policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Name of the S3 bucket the configuration is attached to\n\n## Import\n\n`aws_s3_bucket_public_access_block` can be imported by using the bucket name, e.g.,\n\n```\n$ terraform import aws_s3_bucket_public_access_block.example my-bucket\n```\n",
    "basename": "s3_bucket_public_access_block.html"
  },
  "s3_bucket_replication_configuration.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_bucket_replication_configuration",
    "description": "Provides a S3 bucket replication configuration resource.",
    "preview": "# Resource: aws_s3_bucket_replication_configuration\n\nProvides an …",
    "content": "\n\n# Resource: aws_s3_bucket_replication_configuration\n\nProvides an independent configuration resource for S3 bucket [replication configuration](http://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html).\n\n## Example Usage\n\n### Using replication configuration\n\n```terraform\nprovider \"aws\" {\n  region = \"eu-west-1\"\n}\n\nprovider \"aws\" {\n  alias  = \"central\"\n  region = \"eu-central-1\"\n}\n\nresource \"aws_iam_role\" \"replication\" {\n  name = \"tf-iam-role-replication-12345\"\n\n  assume_role_policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"s3.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_policy\" \"replication\" {\n  name = \"tf-iam-role-policy-replication-12345\"\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"s3:GetReplicationConfiguration\",\n        \"s3:ListBucket\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"${aws_s3_bucket.source.arn}\"\n      ]\n    },\n    {\n      \"Action\": [\n        \"s3:GetObjectVersionForReplication\",\n        \"s3:GetObjectVersionAcl\",\n         \"s3:GetObjectVersionTagging\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": [\n        \"${aws_s3_bucket.source.arn}/*\"\n      ]\n    },\n    {\n      \"Action\": [\n        \"s3:ReplicateObject\",\n        \"s3:ReplicateDelete\",\n        \"s3:ReplicateTags\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"${aws_s3_bucket.destination.arn}/*\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"replication\" {\n  role       = aws_iam_role.replication.name\n  policy_arn = aws_iam_policy.replication.arn\n}\n\nresource \"aws_s3_bucket\" \"destination\" {\n  bucket = \"tf-test-bucket-destination-12345\"\n\n  versioning {\n    enabled = true\n  }\n}\n\nresource \"aws_s3_bucket\" \"source\" {\n  provider = aws.central\n  bucket   = \"tf-test-bucket-source-12345\"\n  acl      = \"private\"\n\n  versioning {\n    enabled = true\n  }\n\n  lifecycle {\n    ignore_changes = [\n      replication_configuration\n    ]\n  }\n}\n\nresource \"aws_s3_bucket_replication_configuration\" \"replication\" {\n  role   = aws_iam_role.replication.arn\n  bucket = aws_s3_bucket.source.id\n\n  rule {\n    id     = \"foobar\"\n    prefix = \"foo\"\n    status = \"Enabled\"\n\n    destination {\n      bucket        = aws_s3_bucket.destination.arn\n      storage_class = \"STANDARD\"\n    }\n  }\n}\n```\n\n### Bi-Directional Replication\n\n```terraform\n# ... other configuration ...\n\nresource \"aws_s3_bucket\" \"east\" {\n  bucket = \"tf-test-bucket-east-12345\"\n\n  versioning {\n    enabled = true\n  }\n\n  lifecycle {\n    ignore_changes = [\n      replication_configuration\n    ]\n  }\n}\n\nresource \"aws_s3_bucket\" \"west\" {\n  provider = west\n  bucket   = \"tf-test-bucket-west-12345\"\n\n  versioning {\n    enabled = true\n  }\n\n  lifecycle {\n    ignore_changes = [\n      replication_configuration\n    ]\n  }\n}\n\nresource \"aws_s3_bucket_replication_configuration\" \"east_to_west\" {\n  role   = aws_iam_role.east_replication.arn\n  bucket = aws_s3_bucket.east.id\n\n  rule {\n    id     = \"foobar\"\n    prefix = \"foo\"\n    status = \"Enabled\"\n\n    destination {\n      bucket        = aws_s3_bucket.west.arn\n      storage_class = \"STANDARD\"\n    }\n  }\n}\n\nresource \"aws_s3_bucket_replication_configuration\" \"west_to_east\" {\n  role   = aws_iam_role.west_replication.arn\n  bucket = aws_s3_bucket.west.id\n\n  rule {\n    id     = \"foobar\"\n    prefix = \"foo\"\n    status = \"Enabled\"\n\n    destination {\n      bucket        = aws_s3_bucket.east.arn\n      storage_class = \"STANDARD\"\n    }\n  }\n}\n```\n\n## Usage Notes\n\n~> **NOTE:** To avoid conflicts always add the following lifecycle object to the `aws_s3_bucket` resource of the source bucket.\n\nThis resource implements the same features that are provided by the `replication_configuration` object of the [`aws_s3_bucket` resource](/docs/providers/aws/r/s3_bucket.html). To avoid conflicts or unexpected apply results, a lifecycle configuration is needed on the `aws_s3_bucket` to ignore changes to the internal `replication_configuration` object.  Failure to add the `lifecycle` configuration to the `aws_s3_bucket` will result in conflicting state results.\n\n```\nlifecycle {\n  ignore_changes = [\n    replication_configuration\n  ]\n}\n```\n\nThe `aws_s3_bucket_replication_configuration` resource provides the following features that are not available in the [`aws_s3_bucket` resource](/docs/providers/aws/r/s3_bucket.html):\n\n* `replica_modifications` - Added to the `source_selection_criteria` configuration object [documented below](#source_selection_criteria)\n* `metrics` - Added to the `destination` configuration object [documented below](#metrics)\n* `replication_time` - Added to the `destination` configuration object [documented below](#replication_time)\n* `existing_object_replication` - Added to the replication rule object [documented below](#existing_object_replication)\n\nReplication for existing objects requires activation by AWS Support.  See [userguide/replication-what-is-isnot-replicated](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-what-is-isnot-replicated.html#existing-object-replication).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `bucket` - (Required) The name of the source S3 bucket you want Amazon S3 to monitor.\n* `role` - (Required) The ARN of the IAM role for Amazon S3 to assume when replicating the objects.\n* `rule` - (Required) Set of configuration blocks describing the rules managing the replication [documented below](#rule).\n\n### rule\n\n~> **NOTE:** Replication to multiple destination buckets requires that `priority` is specified in the `rule` object. If the corresponding rule requires no filter, an empty configuration block `filter {}` must be specified.\n\n~> **NOTE:** Amazon S3's latest version of the replication configuration is V2, which includes the `filter` attribute for replication rules.\n\nThe `rule` configuration block supports the following arguments:\n\n* `delete_marker_replication` - (Optional) Whether delete markers are replicated. This argument is only valid with V2 replication configurations (i.e., when `filter` is used)[documented below](#delete_marker_replication).\n* `destination` - (Required) Specifies the destination for the rule [documented below](#destination).\n* `existing_object_replication` - (Optional) Replicate existing objects in the source bucket according to the rule configurations [documented below](#existing_object_replication).\n* `filter` - (Optional, Conflicts with `prefix`) Filter that identifies subset of objects to which the replication rule applies [documented below](#filter).\n* `id` - (Optional) Unique identifier for the rule. Must be less than or equal to 255 characters in length.\n* `prefix` - (Optional, Conflicts with `filter`) Object key name prefix identifying one or more objects to which the rule applies. Must be less than or equal to 1024 characters in length.\n* `priority` - (Optional) The priority associated with the rule. Priority should only be set if `filter` is configured. If not provided, defaults to `0`. Priority must be unique between multiple rules.\n* `source_selection_criteria` - (Optional) Specifies special object selection criteria [documented below](#source_selection_criteria).\n* `status` - (Required) The status of the rule. Either `\"Enabled\"` or `\"Disabled\"`. The rule is ignored if status is not \"Enabled\".\n\n### delete_marker_replication\n\n~> **NOTE:** This configuration format differs from that of `aws_s3_bucket`.\n\n~> **NOTE:** This argument is only available with V2 replication configurations.\n\n```\ndelete_marker_replication {\n  status = \"Enabled\"\n}\n```\n\nThe `delete_marker_replication` configuration block supports the following arguments:\n\n* `status` - (Required) Whether delete markers should be replicated. Either `\"Enabled\"` or `\"Disabled\"`.\n\n### destination\n\nThe `destination` configuration block supports the following arguments:\n\n* `access_control_translation` - (Optional) A configuration block that specifies the overrides to use for object owners on replication [documented below](#access_control_translation). Specify this only in a cross-account scenario (where source and destination bucket owners are not the same), and you want to change replica ownership to the AWS account that owns the destination bucket. If this is not specified in the replication configuration, the replicas are owned by same AWS account that owns the source object. Must be used in conjunction with `account` owner override configuration.\n* `account` - (Optional) The Account ID to specify the replica ownership. Must be used in conjunction with `access_control_translation` override configuration.\n* `bucket` - (Required) The ARN of the S3 bucket where you want Amazon S3 to store replicas of the objects identified by the rule.\n* `encryption_configuration` - (Optional) A configuration block that provides information about encryption [documented below](#encryption_configuration). If `source_selection_criteria` is specified, you must specify this element.\n* `metrics` - (Optional) A configuration block that specifies replication metrics-related settings enabling replication metrics and events [documented below](#metrics).\n* `replication_time` - (Optional) A configuration block that specifies S3 Replication Time Control (S3 RTC), including whether S3 RTC is enabled and the time when all objects and operations on objects must be replicated [documented below](#replication_time). Replication Time Control must be used in conjunction with `metrics`.\n* `storage_class` - (Optional) The [storage class](https://docs.aws.amazon.com/AmazonS3/latest/API/API_Destination.html#AmazonS3-Type-Destination-StorageClass) used to store the object. By default, Amazon S3 uses the storage class of the source object to create the object replica.\n\n### access_control_translation\n\n```\naccess_control_translation {\n  owner = \"Destination\"\n}\n```\n\nThe `access_control_translation` configuration block supports the following arguments:\n\n* `owner` - (Required) Specifies the replica ownership. For default and valid values, see [PUT bucket replication](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTreplication.html) in the Amazon S3 API Reference. Valid values: `Destination`.\n\n### encryption_configuration\n\n```\nencryption_configuration {\n  replica_kms_key_id = \"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"\n}\n```\n\nThe `encryption_configuration` configuration block supports the following arguments:\n\n* `replica_kms_key_id` - (Required) The ID (Key ARN or Alias ARN) of the customer managed AWS KMS key stored in AWS Key Management Service (KMS) for the destination bucket.\n\n### metrics\n\n```\nmetrics {\n  event_threshold {\n    minutes = 15\n  }\n  status = \"Enabled\"\n}\n```\n\nThe `metrics` configuration block supports the following arguments:\n\n* `event_threshold` - (Optional) A configuration block that specifies the time threshold for emitting the `s3:Replication:OperationMissedThreshold` event [documented below](#event_threshold).\n* `status` - (Required) The status of the Destination Metrics. Either `\"Enabled\"` or `\"Disabled\"`.\n\n### event_threshold\n\nThe `event_threshold` configuration block supports the following arguments:\n\n* `minutes` - (Required) Time in minutes. Valid values: `15`.\n\n### replication_time\n\n```\nreplication_time {\n  status = \"Enabled\"\n  time {\n    minutes = 15\n  }\n}\n```\n\nThe `replication_time` configuration block supports the following arguments:\n\n* `status` - (Required) The status of the Replication Time Control. Either `\"Enabled\"` or `\"Disabled\"`.\n* `time` - (Required) A configuration block specifying the time by which replication should be complete for all objects and operations on objects [documented below](#time).\n\n### time\n\nThe `time` configuration block supports the following arguments:\n\n* `minutes` - (Required) Time in minutes. Valid values: `15`.\n\n### existing_object_replication\n\n~> **NOTE:** Replication for existing objects requires activation by AWS Support.  See [userguide/replication-what-is-isnot-replicated](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-what-is-isnot-replicated.html#existing-object-replication)\n\n```\nexisting_object_replication {\n  status = \"Enabled\"\n}\n```\n\nThe `existing_object_replication` configuration block supports the following arguments:\n\n* `status` - (Required) Whether the existing objects should be replicated. Either `\"Enabled\"` or `\"Disabled\"`.\n\n### filter\n\n~> **NOTE:** With the `filter` argument, you must specify exactly one of `prefix`, `tag`, or `and`.  Replication configuration V1 supports filtering based on only the `prefix` attribute. For backwards compatibility, Amazon S3 continues to support the V1 configuration.\n\nThe `filter` configuration block supports the following arguments:\n\n* `and` - (Optional) A configuration block for specifying rule filters. This element is required only if you specify more than one filter. See [and](#and) below for more details.\n* `prefix` - (Optional) An object key name prefix that identifies subset of objects to which the rule applies. Must be less than or equal to 1024 characters in length.\n* `tag` - (Optional) A configuration block for specifying a tag key and value [documented below](#tag).\n\n### and\n\nThe `and` configuration block supports the following arguments:\n\n* `prefix` - (Optional) An object key name prefix that identifies subset of objects to which the rule applies. Must be less than or equal to 1024 characters in length.\n* `tags` - (Optional, Required if `prefix` is configured) A map of tags (key and value pairs) that identifies a subset of objects to which the rule applies. The rule applies only to objects having all the tags in its tagset.\n\n### tag\n\nThe `tag` configuration block supports the following arguments:\n\n* `key` - (Required) Name of the object key.\n* `value` - (Required) Value of the tag.\n\n### source_selection_criteria\n\n```\nsource_selection_criteria {\n  replica_modifications {\n    status = \"Enabled\"\n  }\n  sse_kms_encrypted_objects {\n    status = \"Enabled\"\n  }\n}\n```\n\nThe `source_selection_criteria` configuration block supports the following arguments:\n\n~> **NOTE:** `sse_kms_encrypted_objects` configuration format differs here from the configuration in the [`aws_s3_bucket` resource](/docs/providers/aws/r/s3_bucket.html).\n\n* `replica_modifications` - (Optional) A configuration block that you can specify for selections for modifications on replicas. Amazon S3 doesn't replicate replica modifications by default. In the latest version of replication configuration (when `filter` is specified), you can specify this element and set the status to `Enabled` to replicate modifications on replicas.\n\n* `sse_kms_encrypted_objects` - (Optional) A configuration block for filter information for the selection of Amazon S3 objects encrypted with AWS KMS. If specified, `replica_kms_key_id` in `destination` `encryption_configuration` must be specified as well.\n\n### replica_modifications\n\nThe `replica_modifications` configuration block supports the following arguments:\n\n* `status` - (Required) Whether the existing objects should be replicated. Either `\"Enabled\"` or `\"Disabled\"`.\n\n### sse_kms_encrypted_objects\n\nThe `sse_kms_encrypted_objects` configuration block supports the following arguments:\n\n* `status` - (Required) Whether the existing objects should be replicated. Either `\"Enabled\"` or `\"Disabled\"`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The S3 source bucket name.\n\n## Import\n\nS3 bucket replication configuration can be imported using the `bucket`, e.g.\n\n```sh\n$ terraform import aws_s3_bucket_replication_configuration.replication bucket-name\n```\n",
    "basename": "s3_bucket_replication_configuration.html"
  },
  "s3_object_copy.html": {
    "subcategory": "S3",
    "layout": "aws",
    "page_title": "AWS: aws_s3_object_copy",
    "description": "Provides a resource for copying an S3 object.",
    "preview": "# Resource: aws_s3_object_copy\n\nProvides a resource for copying an …",
    "content": "\n\n# Resource: aws_s3_object_copy\n\nProvides a resource for copying an S3 object.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_object_copy\" \"test\" {\n  bucket = \"destination_bucket\"\n  key    = \"destination_key\"\n  source = \"source_bucket/source_key\"\n\n  grant {\n    uri         = \"http://acs.amazonaws.com/groups/global/AllUsers\"\n    type        = \"Group\"\n    permissions = [\"READ\"]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `bucket` - (Required) Name of the bucket to put the file in.\n* `key` - (Required) Name of the object once it is in the bucket.\n* `source` - (Required) Specifies the source object for the copy operation. You specify the value in one of two formats. For objects not accessed through an access point, specify the name of the source bucket and the key of the source object, separated by a slash (`/`). For example, `testbucket/test1.json`. For objects accessed through access points, specify the Amazon Resource Name (ARN) of the object as accessed through the access point, in the format `arn:aws:s3:<Region>:<account-id>:accesspoint/<access-point-name>/object/<key>`. For example, `arn:aws:s3:us-west-2:9999912999:accesspoint/my-access-point/object/testbucket/test1.json`.\n\nThe following arguments are optional:\n\n* `acl` - (Optional) [Canned ACL](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl) to apply. Defaults to `private`. Valid values are `private`, `public-read`, `public-read-write`, `authenticated-read`, `aws-exec-read`, `bucket-owner-read`, and `bucket-owner-full-control`. Conflicts with `grant`.\n* `cache_control` - (Optional) Specifies caching behavior along the request/reply chain Read [w3c cache_control](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9) for further details.\n* `content_disposition` - (Optional) Specifies presentational information for the object. Read [w3c content_disposition](http://www.w3.org/Protocols/rfc2616/rfc2616-sec19.html#sec19.5.1) for further information.\n* `content_encoding` - (Optional) Specifies what content encodings have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field. Read [w3c content encoding](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.11) for further information.\n* `content_language` - (Optional) Language the content is in e.g., en-US or en-GB.\n* `content_type` - (Optional) Standard MIME type describing the format of the object data, e.g., `application/octet-stream`. All Valid MIME Types are valid for this input.\n* `copy_if_match` - (Optional) Copies the object if its entity tag (ETag) matches the specified tag.\n* `copy_if_modified_since` - (Optional) Copies the object if it has been modified since the specified time, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `copy_if_none_match` - (Optional) Copies the object if its entity tag (ETag) is different than the specified ETag.\n* `copy_if_unmodified_since` - (Optional) Copies the object if it hasn't been modified since the specified time, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `customer_algorithm` - (Optional) Specifies the algorithm to use to when encrypting the object (for example, AES256).\n* `customer_key` - (Optional) Specifies the customer-provided encryption key for Amazon S3 to use in encrypting data. This value is used to store the object and then it is discarded; Amazon S3 does not store the encryption key. The key must be appropriate for use with the algorithm specified in the x-amz-server-side-encryption-customer-algorithm header.\n* `customer_key_md5` - (Optional) Specifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses this header for a message integrity check to ensure that the encryption key was transmitted without error.\n* `expected_bucket_owner` - (Optional) Account id of the expected destination bucket owner. If the destination bucket is owned by a different account, the request will fail with an HTTP 403 (Access Denied) error.\n* `expected_source_bucket_owner` - (Optional) Account id of the expected source bucket owner. If the source bucket is owned by a different account, the request will fail with an HTTP 403 (Access Denied) error.\n* `expires` - (Optional) Date and time at which the object is no longer cacheable, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `force_destroy` - (Optional) Allow the object to be deleted by removing any legal hold on any object version. Default is `false`. This value should be set to `true` only if the bucket has S3 object lock enabled.\n* `grant` - (Optional) Configuration block for header grants. Documented below. Conflicts with `acl`.\n* `kms_encryption_context` - (Optional) Specifies the AWS KMS Encryption Context to use for object encryption. The value is a base64-encoded UTF-8 string holding JSON with the encryption context key-value pairs.\n* `kms_key_id` - (Optional) Specifies the AWS KMS Key ARN to use for object encryption. This value is a fully qualified **ARN** of the KMS Key. If using `aws_kms_key`, use the exported `arn` attribute: `kms_key_id = aws_kms_key.foo.arn`\n* `metadata` - (Optional) A map of keys/values to provision metadata (will be automatically prefixed by `x-amz-meta-`, note that only lowercase label are currently supported by the AWS Go API).\n* `metadata_directive` - (Optional) Specifies whether the metadata is copied from the source object or replaced with metadata provided in the request. Valid values are `COPY` and `REPLACE`.\n* `object_lock_legal_hold_status` - (Optional) The [legal hold](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock-overview.html#object-lock-legal-holds) status that you want to apply to the specified object. Valid values are `ON` and `OFF`.\n* `object_lock_mode` - (Optional) The object lock [retention mode](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock-overview.html#object-lock-retention-modes) that you want to apply to this object. Valid values are `GOVERNANCE` and `COMPLIANCE`.\n* `object_lock_retain_until_date` - (Optional) The date and time, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8), when this object's object lock will [expire](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock-overview.html#object-lock-retention-periods).\n* `request_payer` - (Optional) Confirms that the requester knows that they will be charged for the request. Bucket owners need not specify this parameter in their requests. For information about downloading objects from requester pays buckets, see Downloading Objects in Requestor Pays Buckets (https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html) in the Amazon S3 Developer Guide. If included, the only valid value is `requester`.\n* `server_side_encryption` - (Optional) Specifies server-side encryption of the object in S3. Valid values are `AES256` and `aws:kms`.\n* `source_customer_algorithm` - (Optional) Specifies the algorithm to use when decrypting the source object (for example, AES256).\n* `source_customer_key` - (Optional) Specifies the customer-provided encryption key for Amazon S3 to use to decrypt the source object. The encryption key provided in this header must be one that was used when the source object was created.\n* `source_customer_key_md5` - (Optional) Specifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses this header for a message integrity check to ensure that the encryption key was transmitted without error.\n* `storage_class` - (Optional) Specifies the desired [storage class](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html#AmazonS3-CopyObject-request-header-StorageClass) for the object. Defaults to `STANDARD`.\n* `tagging_directive` - (Optional) Specifies whether the object tag-set are copied from the source object or replaced with tag-set provided in the request. Valid values are `COPY` and `REPLACE`.\n* `tags` - (Optional) A map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `website_redirect` - (Optional) Specifies a target URL for [website redirect](http://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-page-redirect.html).\n\n### grant\n\n-> For more information on header grants, see the Amazon Simple Storage Service (S3) [API Reference: PutObjectAcl](https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObjectAcl.html).\n\nThis configuration block has the following required arguments:\n\n* `permissions` - (Required) List of permissions to grant to grantee. Valid values are `READ`, `READ_ACP`, `WRITE_ACP`, `FULL_CONTROL`.\n* `type` - (Required) - Type of grantee. Valid values are `CanonicalUser`, `Group`, and `AmazonCustomerByEmail`.\n\nThis configuration block has the following optional arguments (one of the three is required):\n\n* `email` - (Optional) Email address of the grantee. Used only when `type` is `AmazonCustomerByEmail`.  \n* `id` - (Optional) The canonical user ID of the grantee. Used only when `type` is `CanonicalUser`.  \n* `uri` - (Optional) URI of the grantee group. Used only when `type` is `Group`.\n\n-> **Note:** Terraform ignores all leading `/`s in the object's `key` and treats multiple `/`s in the rest of the object's `key` as a single `/`, so values of `/index.html` and `index.html` correspond to the same S3 object as do `first//second///third//` and `first/second/third/`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `etag` - The ETag generated for the object (an MD5 sum of the object content). For plaintext objects or objects encrypted with an AWS-managed key, the hash is an MD5 digest of the object data. For objects encrypted with a KMS key or objects created by either the Multipart Upload or Part Copy operation, the hash is not an MD5 digest, regardless of the method of encryption. More information on possible values can be found on [Common Response Headers](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonResponseHeaders.html).\n* `expiration` - If the object expiration is configured, this attribute will be set.\n* `id` - The `key` of the resource supplied above.\n* `last_modified` - Returns the date that the object was last modified, in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `request_charged` - If present, indicates that the requester was successfully charged for the request.\n* `source_version_id` - Version of the copied object in the source bucket.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version_id` - Version ID of the newly created copy.\n",
    "basename": "s3_object_copy.html"
  },
  "s3control_access_point_policy.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_access_point_policy",
    "description": "Provides a resource to manage an S3 Access Point resource policy.",
    "preview": "# Resource: aws_s3control_access_point_policy\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_s3control_access_point_policy\n\nProvides a resource to manage an S3 Access Point resource policy.\n\n~> **NOTE on Access Points and Access Point Policies:** Terraform provides both a standalone Access Point Policy resource and an [Access Point](s3_access_point.html) resource with a resource policy defined in-line. You cannot use an Access Point with in-line resource policy in conjunction with an Access Point Policy resource. Doing so will cause a conflict of policies and will overwrite the access point's resource policy.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_access_point\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n  name   = \"example\"\n\n  public_access_block_configuration {\n    block_public_acls       = true\n    block_public_policy     = false\n    ignore_public_acls      = true\n    restrict_public_buckets = false\n  }\n\n  lifecycle {\n    ignore_changes = [policy]\n  }\n}\n\nresource \"aws_s3control_access_point_policy\" \"example\" {\n  access_point_arn = aws_s3_access_point.example.arn\n\n  policy = jsonencode({\n    Version = \"2008-10-17\"\n    Statement = [{\n      Effect = \"Allow\"\n      Action = \"s3:GetObjectTagging\"\n      Principal = {\n        AWS = \"*\"\n      }\n      Resource = \"${aws_s3_access_point.example.arn}/object/*\"\n    }]\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `access_point_arn` - (Required) The ARN of the access point that you want to associate with the specified policy.\n* `policy` - (Required) The policy that you want to apply to the specified access point.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `has_public_access_policy` - Indicates whether this access point currently has a policy that allows public access.\n* `id` - The AWS account ID and access point name separated by a colon (`:`).\n\n## Import\n\nAccess Point policies can be imported using the `access_point_arn`, e.g.\n\n```\n$ terraform import aws_s3control_access_point_policy.example arn:aws:s3:us-west-2:123456789012:accesspoint/example\n```\n",
    "basename": "s3control_access_point_policy.html"
  },
  "s3control_bucket.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_bucket",
    "description": "Manages an S3 Control Bucket.",
    "preview": "# Resource: aws_s3control_bucket\n\nProvides a resource to manage an …",
    "content": "\n\n# Resource: aws_s3control_bucket\n\nProvides a resource to manage an S3 Control Bucket.\n\n-> This functionality is for managing [S3 on Outposts](https://docs.aws.amazon.com/AmazonS3/latest/dev/S3onOutposts.html). To manage S3 Buckets in an AWS Partition, see the [`aws_s3_bucket` resource](/docs/providers/aws/r/s3_bucket.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_s3control_bucket\" \"example\" {\n  bucket     = \"example\"\n  outpost_id = data.aws_outposts_outpost.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `bucket` - (Required) Name of the bucket.\n* `outpost_id` - (Required) Identifier of the Outpost to contain this bucket.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the bucket.\n* `creation_date` - UTC creation date in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `id` - Amazon Resource Name (ARN) of the bucket.\n* `public_access_block_enabled` - Boolean whether Public Access Block is enabled.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nS3 Control Buckets can be imported using Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_s3control_bucket.example arn:aws:s3-outposts:us-east-1:123456789012:outpost/op-12345678/bucket/example\n```",
    "basename": "s3control_bucket.html"
  },
  "s3control_bucket_lifecycle_configuration.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_bucket_lifecycle_configuration",
    "description": "Manages an S3 Control Bucket Lifecycle Configuration.",
    "preview": "# Resource: aws_s3control_bucket_lifecycle_configuration\n\nProvides a …",
    "content": "\n\n# Resource: aws_s3control_bucket_lifecycle_configuration\n\nProvides a resource to manage an S3 Control Bucket Lifecycle Configuration.\n\n~> **NOTE:** Each S3 Control Bucket can only have one Lifecycle Configuration. Using multiple of this resource against the same S3 Control Bucket will result in perpetual differences each Terraform run.\n\n-> This functionality is for managing [S3 on Outposts](https://docs.aws.amazon.com/AmazonS3/latest/dev/S3onOutposts.html). To manage S3 Bucket Lifecycle Configurations in an AWS Partition, see the [`aws_s3_bucket` resource](/docs/providers/aws/r/s3_bucket.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_s3control_bucket_lifecycle_configuration\" \"example\" {\n  bucket = aws_s3control_bucket.example.arn\n\n  rule {\n    expiration {\n      days = 365\n    }\n\n    filter {\n      prefix = \"logs/\"\n    }\n\n    id = \"logs\"\n  }\n\n  rule {\n    expiration {\n      days = 7\n    }\n\n    filter {\n      prefix = \"temp/\"\n    }\n\n    id = \"temp\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `bucket` - (Required) Amazon Resource Name (ARN) of the bucket.\n* `rule` - (Required) Configuration block(s) containing lifecycle rules for the bucket.\n    * `abort_incomplete_multipart_upload` - (Optional) Configuration block containing settings for abort incomplete multipart upload.\n        * `days_after_initiation` - (Required) Number of days after which Amazon S3 aborts an incomplete multipart upload.\n    * `expiration` - (Optional) Configuration block containing settings for expiration of objects.\n        * `date` - (Optional) Date the object is to be deleted. Should be in `YYYY-MM-DD` date format, e.g., `2020-09-30`.\n        * `days` - (Optional) Number of days before the object is to be deleted.\n        * `expired_object_delete_marker` - (Optional) Enable to remove a delete marker with no noncurrent versions. Cannot be specified with `date` or `days`.\n    * `filter` - (Optional) Configuration block containing settings for filtering.\n        * `prefix` - (Optional) Object prefix for rule filtering.\n        * `tags` - (Optional) Key-value map of object tags for rule filtering.\n    * `id` - (Required) Unique identifier for the rule.\n    * `status` - (Optional) Status of the rule. Valid values: `Enabled` and `Disabled`. Defaults to `Enabled`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the bucket.\n\n## Import\n\nS3 Control Bucket Lifecycle Configurations can be imported using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_s3control_bucket_lifecycle_configuration.example arn:aws:s3-outposts:us-east-1:123456789012:outpost/op-12345678/bucket/example\n```\n",
    "basename": "s3control_bucket_lifecycle_configuration.html"
  },
  "s3control_bucket_policy.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_bucket_policy",
    "description": "Manages an S3 Control Bucket Policy.",
    "preview": "# Resource: aws_s3control_bucket_policy\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_s3control_bucket_policy\n\nProvides a resource to manage an S3 Control Bucket Policy.\n\n-> This functionality is for managing [S3 on Outposts](https://docs.aws.amazon.com/AmazonS3/latest/dev/S3onOutposts.html). To manage S3 Bucket Policies in an AWS Partition, see the [`aws_s3_bucket_policy` resource](/docs/providers/aws/r/s3_bucket_policy.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_s3control_bucket_policy\" \"example\" {\n  bucket = aws_s3control_bucket.example.arn\n  policy = jsonencode({\n    Id = \"testBucketPolicy\"\n    Statement = [\n      {\n        Action = \"s3-outposts:PutBucketLifecycleConfiguration\"\n        Effect = \"Deny\"\n        Principal = {\n          AWS = \"*\"\n        }\n        Resource = aws_s3control_bucket.example.arn\n        Sid      = \"statement1\"\n      }\n    ]\n    Version = \"2012-10-17\"\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `bucket` - (Required) Amazon Resource Name (ARN) of the bucket.\n* `policy` - (Required) JSON string of the resource policy. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the bucket.\n\n## Import\n\nS3 Control Bucket Policies can be imported using the Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_s3control_bucket_policy.example arn:aws:s3-outposts:us-east-1:123456789012:outpost/op-12345678/bucket/example\n```\n",
    "basename": "s3control_bucket_policy.html"
  },
  "s3control_multi_region_access_point.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_multi_region_access_point",
    "description": "Provides a resource to manage an S3 Multi-Region Access Point associated with specified buckets.",
    "preview": "# Resource: aws_s3control_multi_region_access_point\n\nProvides a …",
    "content": "\n\n# Resource: aws_s3control_multi_region_access_point\n\nProvides a resource to manage an S3 Multi-Region Access Point associated with specified buckets.\n\n## Example Usage\n\n### Multiple AWS Buckets in Different Regions\n\n```terraform\nprovider \"aws\" {\n  region = \"us-east-1\"\n  alias  = \"primary_region\"\n}\n\nprovider \"aws\" {\n  region = \"us-west-2\"\n  alias  = \"secondary_region\"\n}\n\nresource \"aws_s3_bucket\" \"foo_bucket\" {\n  provider = aws.primary_region\n\n  bucket = \"example-bucket-foo\"\n}\n\nresource \"aws_s3_bucket\" \"bar_bucket\" {\n  provider = aws.secondary_region\n\n  bucket = \"example-bucket-bar\"\n}\n\nresource \"aws_s3control_multi_region_access_point\" \"example\" {\n  details {\n    name = \"example\"\n\n    region {\n      bucket = aws_s3_bucket.foo_bucket.id\n    }\n\n    region {\n      bucket = aws_s3_bucket.bar_bucket.id\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The AWS account ID for the owner of the buckets for which you want to create a Multi-Region Access Point. Defaults to automatically determined account ID of the Terraform AWS provider.\n* `details` - (Required) A configuration block containing details about the Multi-Region Access Point. See [Details Configuration Block](#details-configuration) below for more details\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Default `60 minutes`) Used when creating the Multi-Region Access Point.\n* `delete` - (Default `15 minutes`) Used when deleting the Multi-Region Access Point.\n\n### Details Configuration\n\nThe `details` block supports the following:\n\n* `name` - (Required) The name of the Multi-Region Access Point.\n* `public_access_block` - (Optional) Configuration block to manage the `PublicAccessBlock` configuration that you want to apply to this Multi-Region Access Point. You can enable the configuration options in any combination. See [Public Access Block Configuration](#public-access-block-configuration) below for more details.\n* `region` - (Required) The Region configuration block to specify the bucket associated with the Multi-Region Access Point. See [Region Configuration](#region-configuration) below for more details.\n\nFor more information, see the documentation on [Multi-Region Access Points](https://docs.aws.amazon.com/AmazonS3/latest/userguide/MultiRegionAccessPoints.html).\n\n### Public Access Block Configuration\n\nThe `public_access_block` block supports the following:\n\n* `block_public_acls` - (Optional) Whether Amazon S3 should block public ACLs for buckets in this account. Defaults to `true`. Enabling this setting does not affect existing policies or ACLs. When set to `true` causes the following behavior:\n    * PUT Bucket acl and PUT Object acl calls fail if the specified ACL is public.\n    * PUT Object calls fail if the request includes a public ACL.\n    * PUT Bucket calls fail if the request includes a public ACL.\n* `block_public_policy` - (Optional) Whether Amazon S3 should block public bucket policies for buckets in this account. Defaults to `true`. Enabling this setting does not affect existing bucket policies. When set to `true` causes Amazon S3 to:\n    * Reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n* `ignore_public_acls` - (Optional) Whether Amazon S3 should ignore public ACLs for buckets in this account. Defaults to `true`. Enabling this setting does not affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set. When set to `true` causes Amazon S3 to:\n    * Ignore all public ACLs on buckets in this account and any objects that they contain.\n* `restrict_public_buckets` - (Optional) Whether Amazon S3 should restrict public bucket policies for buckets in this account. Defaults to `true`. Enabling this setting does not affect previously stored bucket policies, except that public and cross-account access within any public bucket policy, including non-public delegation to specific accounts, is blocked. When set to `true`:\n    * Only the bucket owner and AWS Services can access buckets with public policies.\n\n### Region Configuration\n\nThe `region` block supports the following:\n\n* `bucket` - (Required) The name of the associated bucket for the Region.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `alias` - The alias for the Multi-Region Access Point.\n* `arn` - Amazon Resource Name (ARN) of the Multi-Region Access Point.\n* `alias` - The alias for the Multi-Region Access Point.\n* `domain_name` - The DNS domain name of the S3 Multi-Region Access Point in the format _`alias`_.accesspoint.s3-global.amazonaws.com. For more information, see the documentation on [Multi-Region Access Point Requests](https://docs.aws.amazon.com/AmazonS3/latest/userguide/MultiRegionAccessPointRequests.html).\n* `id` - The AWS account ID and access point name separated by a colon (`:`).\n* `status` - The current status of the Multi-Region Access Point. One of: `READY`, `INCONSISTENT_ACROSS_REGIONS`, `CREATING`, `PARTIALLY_CREATED`, `PARTIALLY_DELETED`, `DELETING`.\n\n## Import\n\nMulti-Region Access Points can be imported using the `account_id` and `name` of the Multi-Region Access Point separated by a colon (`:`), e.g.\n\n```\n$ terraform import aws_s3control_multi_region_access_point.example 123456789012:example\n```\n",
    "basename": "s3control_multi_region_access_point.html"
  },
  "s3control_multi_region_access_point_policy.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_multi_region_access_point_policy",
    "description": "Provides a resource to manage an S3 Multi-Region Access Point access control policy.",
    "preview": "# Resource: aws_s3control_multi_region_access_point_policy\n\nProvides …",
    "content": "\n\n# Resource: aws_s3control_multi_region_access_point_policy\n\nProvides a resource to manage an S3 Multi-Region Access Point access control policy.\n\n## Example Usage\n\n### Basic Example\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\ndata \"aws_partition\" \"current\" {}\n\nresource \"aws_s3_bucket\" \"foo_bucket\" {\n  bucket = \"example-bucket-foo\"\n}\n\nresource \"aws_s3control_multi_region_access_point\" \"example\" {\n  details {\n    name = \"example\"\n\n    region {\n      bucket = aws_s3_bucket.foo_bucket.id\n    }\n  }\n}\n\nresource \"aws_s3control_multi_region_access_point_policy\" \"example\" {\n  details {\n    name = element(split(\":\", aws_s3control_multi_region_access_point.example.id), 1)\n    policy = jsonencode({\n      \"Version\" : \"2012-10-17\",\n      \"Statement\" : [\n        {\n          \"Sid\" : \"Example\",\n          \"Effect\" : \"Allow\",\n          \"Principal\" : {\n            \"AWS\" : data.aws_caller_identity.current.account_id\n          },\n          \"Action\" : [\"s3:GetObject\", \"s3:PutObject\"],\n          \"Resource\" : \"arn:${data.aws_partition.current.partition}:s3::${data.aws_caller_identity.current.account_id}:accesspoint/${aws_s3control_multi_region_access_point.example.alias}/object/*\"\n        }\n      ]\n    })\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The AWS account ID for the owner of the Multi-Region Access Point. Defaults to automatically determined account ID of the Terraform AWS provider.\n* `details` - (Required) A configuration block containing details about the policy for the Multi-Region Access Point. See [Details Configuration Block](#details-configuration) below for more details\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Default `15 minutes`) Used when creating the Multi-Region Access Point Policy.\n* `update` - (Default `15 minutes`) Used when updating the Multi-Region Access Point Policy.\n\n### Details Configuration\n\nThe `details` block supports the following:\n\n* `name` - (Required) The name of the Multi-Region Access Point.\n* `policy` - (Required) A valid JSON document that specifies the policy that you want to associate with this Multi-Region Access Point. Once applied, the policy can be edited, but not deleted. For more information, see the documentation on [Multi-Region Access Point Permissions](https://docs.aws.amazon.com/AmazonS3/latest/userguide/MultiRegionAccessPointPermissions.html).\n\n-> **NOTE:** When you update the `policy`, the update is first listed as the proposed policy. After the update is finished and all Regions have been updated, the proposed policy is listed as the established policy. If both policies have the same version number, the proposed policy is the established policy.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `established` - The last established policy for the Multi-Region Access Point.\n* `id` - The AWS account ID and access point name separated by a colon (`:`).\n* `proposed` - The proposed policy for the Multi-Region Access Point.\n\n## Import\n\nMulti-Region Access Point Policies can be imported using the `account_id` and `name` of the Multi-Region Access Point separated by a colon (`:`), e.g.\n\n```\n$ terraform import aws_s3control_multi_region_access_point_policy.example 123456789012:example\n```\n",
    "basename": "s3control_multi_region_access_point_policy.html"
  },
  "s3control_object_lambda_access_point.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_object_lambda_access_point",
    "description": "Provides a resource to manage an S3 Object Lambda Access Point.",
    "preview": "# Resource: aws_s3control_object_lambda_access_point\n\nProvides a …",
    "content": "\n\n# Resource: aws_s3control_object_lambda_access_point\n\nProvides a resource to manage an S3 Object Lambda Access Point.\nAn Object Lambda access point is associated with exactly one [standard access point](s3_access_point.html) and thus one Amazon S3 bucket.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_access_point\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n  name   = \"example\"\n}\n\nresource \"aws_s3control_object_lambda_access_point\" \"example\" {\n  name = \"example\"\n\n  configuration {\n    supporting_access_point = aws_s3_access_point.example.arn\n\n    transformation_configuration {\n      actions = [\"GetObject\"]\n\n      content_transformation {\n        aws_lambda {\n          function_arn = aws_lambda_function.example.arn\n        }\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The AWS account ID for the owner of the bucket for which you want to create an Object Lambda Access Point. Defaults to automatically determined account ID of the Terraform AWS provider.\n* `configuration` - (Required) A configuration block containing details about the Object Lambda Access Point. See [Configuration](#configuration) below for more details.\n* `name` - (Required) The name for this Object Lambda Access Point.\n\n### Configuration\n\nThe `configuration` block supports the following:\n\n* `allowed_features` - (Optional) Allowed features. Valid values: `GetObject-Range`, `GetObject-PartNumber`.\n* `cloud_watch_metrics_enabled` - (Optional) Whether or not the CloudWatch metrics configuration is enabled.\n* `supporting_access_point` - (Required) Standard access point associated with the Object Lambda Access Point.\n* `transformation_configuration` - (Required) List of transformation configurations for the Object Lambda Access Point. See [Transformation Configuration](#transformation-configuration) below for more details.\n\n### Transformation Configuration\n\nThe `transformation_configuration` block supports the following:\n\n* `actions` - (Required) The actions of an Object Lambda Access Point configuration. Valid values: `GetObject`.\n* `content_transformation` - (Required) The content transformation of an Object Lambda Access Point configuration. See [Content Transformation](#content-transformation) below for more details.\n\n### Content Transformation\n\nThe `content_transformation` block supports the following:\n\n* `aws_lambda` - (Required) Configuration for an AWS Lambda function. See [AWS Lambda](#aws-lambda) below for more details.\n\n### AWS Lambda\n\nThe `aws_lambda` block supports the following:\n\n* `function_arn` - (Required) The Amazon Resource Name (ARN) of the AWS Lambda function.\n* `function_payload` - (Optional) Additional JSON that provides supplemental data to the Lambda function used to transform objects.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the Object Lambda Access Point.\n* `id` - The AWS account ID and access point name separated by a colon (`:`).\n\n## Import\n\nObject Lambda Access Points can be imported using the `account_id` and `name`, separated by a colon (`:`), e.g.\n\n```\n$ terraform import aws_s3control_object_lambda_access_point.example 123456789012:example\n```\n",
    "basename": "s3control_object_lambda_access_point.html"
  },
  "s3control_object_lambda_access_point_policy.html": {
    "subcategory": "S3 Control",
    "layout": "aws",
    "page_title": "AWS: aws_s3control_object_lambda_access_point_policy",
    "description": "Provides a resource to manage an S3 Object Lambda Access Point resource policy.",
    "preview": "# Resource: aws_s3control_object_lambda_access_point_policy\n …",
    "content": "\n\n# Resource: aws_s3control_object_lambda_access_point_policy\n\nProvides a resource to manage an S3 Object Lambda Access Point resource policy.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"example\"\n}\n\nresource \"aws_s3_access_point\" \"example\" {\n  bucket = aws_s3_bucket.example.id\n  name   = \"example\"\n}\n\nresource \"aws_s3control_object_lambda_access_point\" \"example\" {\n  name = \"example\"\n\n  configuration {\n    supporting_access_point = aws_s3_access_point.example.arn\n\n    transformation_configuration {\n      actions = [\"GetObject\"]\n\n      content_transformation {\n        aws_lambda {\n          function_arn = aws_lambda_function.example.arn\n        }\n      }\n    }\n  }\n}\n\nresource \"aws_s3control_object_lambda_access_point_policy\" \"example\" {\n  name = aws_s3control_object_lambda_access_point.example.name\n\n  policy = jsonencode({\n    Version = \"2008-10-17\"\n    Statement = [{\n      Effect = \"Allow\"\n      Action = \"s3-object-lambda:GetObject\"\n      Principal = {\n        AWS = data.aws_caller_identity.current.account_id\n      }\n      Resource = aws_s3control_object_lambda_access_point.example.arn\n    }]\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Optional) The AWS account ID for the account that owns the Object Lambda Access Point. Defaults to automatically determined account ID of the Terraform AWS provider.\n* `name` - (Required) The name of the Object Lambda Access Point.\n* `policy` - (Required) The Object Lambda Access Point resource policy document.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `has_public_access_policy` - Indicates whether this access point currently has a policy that allows public access.\n* `id` - The AWS account ID and access point name separated by a colon (`:`).\n\n## Import\n\nObject Lambda Access Point policies can be imported using the `account_id` and `name`, separated by a colon (`:`), e.g.\n\n```\n$ terraform import aws_s3control_object_lambda_access_point_policy.example 123456789012:example\n```\n",
    "basename": "s3control_object_lambda_access_point_policy.html"
  },
  "s3outposts_endpoint.html": {
    "subcategory": "S3 Outposts",
    "layout": "aws",
    "page_title": "AWS: aws_s3outposts_endpoint",
    "description": "Manages an S3 Outposts Endpoint.",
    "preview": "# Resource: aws_s3outposts_endpoint\n\nProvides a resource to manage …",
    "content": "\n\n# Resource: aws_s3outposts_endpoint\n\nProvides a resource to manage an S3 Outposts Endpoint.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3outposts_endpoint\" \"example\" {\n  outpost_id        = data.aws_outposts_outpost.example.id\n  security_group_id = aws_security_group.example.id\n  subnet_id         = aws_subnet.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `outpost_id` - (Required) Identifier of the Outpost to contain this endpoint.\n* `security_group_id` - (Required) Identifier of the EC2 Security Group.\n* `subnet_id` - (Required) Identifier of the EC2 Subnet.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the endpoint.\n* `cidr_block` - VPC CIDR block of the endpoint.\n* `creation_time` - UTC creation time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `id` - Amazon Resource Name (ARN) of the endpoint.\n* `network_interfaces` - Set of nested attributes for associated Elastic Network Interfaces (ENIs).\n    * `network_interface_id` - Identifier of the Elastic Network Interface (ENI).\n\n## Import\n\nS3 Outposts Endpoints can be imported using Amazon Resource Name (ARN), EC2 Security Group identifier, and EC2 Subnet identifier, separated by commas (`,`) e.g.,\n\n```\n$ terraform import aws_s3outposts_endpoint.example arn:aws:s3-outposts:us-east-1:123456789012:outpost/op-12345678/endpoint/0123456789abcdef,sg-12345678,subnet-12345678\n```\n",
    "basename": "s3outposts_endpoint.html"
  },
  "sagemaker_app.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_app",
    "description": "Provides a Sagemaker App resource.",
    "preview": "# Resource: aws_sagemaker_app\n\nProvides a Sagemaker App resource.\n …",
    "content": "\n\n# Resource: aws_sagemaker_app\n\nProvides a Sagemaker App resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_app\" \"example\" {\n  domain_id         = aws_sagemaker_domain.example.id\n  user_profile_name = aws_sagemaker_user_profile.example.user_profile_name\n  app_name          = \"example\"\n  app_type          = \"JupyterServer\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `app_name` - (Required) The name of the app.\n* `app_type` - (Required) The type of app. Valid values are `JupyterServer`, `KernelGateway` and `TensorBoard`.\n* `domain_id` - (Required) The domain ID.\n* `user_profile_name` - (Required) The user profile name.\n* `resource_spec` - (Optional) The instance type and the Amazon Resource Name (ARN) of the SageMaker image created on the instance.See [Resource Spec](#resource-spec) below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Resource Spec\n\n* `instance_type` - (Optional) The instance type that the image version runs on. For valid values see [Sagemaker Instance Types](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html).\n* `sagemaker_image_arn` - (Optional) The ARN of the SageMaker image that the image version belongs to.\n* `sagemaker_image_version_arn` - (Optional) The ARN of the image version created on the instance.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the app.\n* `arn` - The Amazon Resource Name (ARN) of the app.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Code Apps can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_sagemaker_app.example arn:aws:sagemaker:us-west-2:012345678912:app/domain-id/user-profile-name/app-type/app-name\n```\n",
    "basename": "sagemaker_app.html"
  },
  "sagemaker_app_image_config.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_app_image_config",
    "description": "Provides a Sagemaker App Image Config resource.",
    "preview": "# Resource: aws_sagemaker_app_image_config\n\nProvides a Sagemaker App …",
    "content": "\n\n# Resource: aws_sagemaker_app_image_config\n\nProvides a Sagemaker App Image Config resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_app_image_config\" \"test\" {\n  app_image_config_name = \"example\"\n\n  kernel_gateway_image_config {\n    kernel_spec {\n      name = \"example\"\n    }\n  }\n}\n```\n\n### Default File System Config\n\n```terraform\nresource \"aws_sagemaker_app_image_config\" \"test\" {\n  app_image_config_name = \"example\"\n\n  kernel_gateway_image_config {\n    kernel_spec {\n      name = \"example\"\n    }\n\n    file_system_config {}\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `app_image_config_name` - (Required) The name of the App Image Config.\n* `kernel_gateway_image_config` - (Optional) The configuration for the file system and kernels in a SageMaker image running as a KernelGateway app. See [Kernel Gateway Image Config](#kernel-gateway-image-config) details below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Kernel Gateway Image Config\n\n* `file_system_config` - (Optional) The URL where the Git repository is located. See [File System Config](#file-system-config) details below.\n* `kernel_spec` - (Required) The default branch for the Git repository. See [Kernel Spec](#kernel-spec) details below.\n\n#### File System Config\n\n* `default_gid` - (Optional) The default POSIX group ID (GID). If not specified, defaults to `100`. Valid values are `0` and `100`.\n* `default_uid` - (Optional) The default POSIX user ID (UID). If not specified, defaults to `1000`. Valid values are `0` and `1000`.\n* `mount_path` - (Optional) The path within the image to mount the user's EFS home directory. The directory should be empty. If not specified, defaults to `/home/sagemaker-user`.\n\n~> **Note:** When specifying `default_gid` and `default_uid`, Valid value pairs are [`0`, `0`] and [`100`, `1000`].\n\n#### Kernel Spec\n\n* `name` - (Required) The name of the kernel.\n* `display_name` - (Optional) The display name of the kernel.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the App Image Config.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this App Image Config.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker App Image Configs can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_app_image_config.example example\n```\n",
    "basename": "sagemaker_app_image_config.html"
  },
  "sagemaker_code_repository.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_code_repository",
    "description": "Provides a Sagemaker Code Repository resource.",
    "preview": "# Resource: aws_sagemaker_code_repository\n\nProvides a Sagemaker Code …",
    "content": "\n\n# Resource: aws_sagemaker_code_repository\n\nProvides a Sagemaker Code Repository resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_code_repository\" \"example\" {\n  code_repository_name = \"example\"\n\n  git_config {\n    repository_url = \"https://github.com/hashicorp/terraform-provider-aws.git\"\n  }\n}\n```\n\n### Example with Secret\n\n```terraform\nresource \"aws_secretsmanager_secret\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_secretsmanager_secret_version\" \"example\" {\n  secret_id     = aws_secretsmanager_secret.example.id\n  secret_string = jsonencode({ username = \"example\", password = \"example\" })\n}\n\nresource \"aws_sagemaker_code_repository\" \"example\" {\n  code_repository_name = \"example\"\n\n  git_config {\n    repository_url = \"https://github.com/hashicorp/terraform-provider-aws.git\"\n    secret_arn     = aws_secretsmanager_secret.example.arn\n  }\n\n  depends_on = [aws_secretsmanager_secret_version.example]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `code_repository_name` - (Required) The name of the Code Repository (must be unique).\n* `git_config` - (Required) Specifies details about the repository. see [Git Config](#git-config) details below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Git Config\n\n* `repository_url` - (Required) The URL where the Git repository is located.\n* `branch` - (Optional) The default branch for the Git repository.\n* `secret_arn` - (Optional) The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the credentials used to access the git repository. The secret must have a staging label of AWSCURRENT and must be in the following format: `{\"username\": UserName, \"password\": Password}`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Code Repository.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Code Repository.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Code Repositories can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_code_repository.test_code_repository my-code-repo\n```\n",
    "basename": "sagemaker_code_repository.html"
  },
  "sagemaker_device_fleet.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_device_fleet",
    "description": "Provides a Sagemaker Device Fleet resource.",
    "preview": "# Resource: aws_sagemaker_device_fleet\n\nProvides a Sagemaker Device …",
    "content": "\n\n# Resource: aws_sagemaker_device_fleet\n\nProvides a Sagemaker Device Fleet resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_device_fleet\" \"example\" {\n  device_fleet_name = \"example\"\n  role_arn          = aws_iam_role.test.arn\n\n  output_config {\n    s3_output_location = \"s3://${aws_s3_bucket.example.bucket}/prefix/\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `device_fleet_name` - (Required) The name of the Device Fleet (must be unique).\n* `role_arn` - (Required) The Amazon Resource Name (ARN) that has access to AWS Internet of Things (IoT).\n* `output_config` - (Required) Specifies details about the repository. see [Output Config](#output-config) details below.\n* `description` - (Optional) A description of the fleet.\n* `enable_iot_role_alias` - (Optional) Whether to create an AWS IoT Role Alias during device fleet creation. The name of the role alias generated will match this pattern: \"SageMakerEdge-{DeviceFleetName}\".\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Output Config\n\n* `s3_output_location` - (Required) The Amazon Simple Storage (S3) bucker URI.\n* `kms_key_id` - (Optional) The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data on the storage volume after compilation job. If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Device Fleet.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Device Fleet.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Device Fleets can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_device_fleet.example my-fleet\n```\n",
    "basename": "sagemaker_device_fleet.html"
  },
  "sagemaker_domain.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_domain",
    "description": "Provides a Sagemaker Domain resource.",
    "preview": "# Resource: aws_sagemaker_domain\n\nProvides a Sagemaker Domain …",
    "content": "\n\n# Resource: aws_sagemaker_domain\n\nProvides a Sagemaker Domain resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_domain\" \"example\" {\n  domain_name = \"example\"\n  auth_mode   = \"IAM\"\n  vpc_id      = aws_vpc.test.id\n  subnet_ids  = [aws_subnet.test.id]\n\n  default_user_settings {\n    execution_role = aws_iam_role.test.arn\n  }\n}\n\nresource \"aws_iam_role\" \"example\" {\n  name               = \"example\"\n  path               = \"/\"\n  assume_role_policy = data.aws_iam_policy_document.example.json\n}\n\ndata \"aws_iam_policy_document\" \"example\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"sagemaker.amazonaws.com\"]\n    }\n  }\n}\n```\n\n### Using Custom Images\n\n```terraform\nresource \"aws_sagemaker_image\" \"test\" {\n  image_name = \"example\"\n  role_arn   = aws_iam_role.test.arn\n}\n\nresource \"aws_sagemaker_app_image_config\" \"test\" {\n  app_image_config_name = \"example\"\n\n  kernel_gateway_image_config {\n    kernel_spec {\n      name = \"example\"\n    }\n  }\n}\n\nresource \"aws_sagemaker_image_version\" \"test\" {\n  image_name = aws_sagemaker_image.test.id\n  base_image = \"base-image\"\n}\n\nresource \"aws_sagemaker_domain\" \"test\" {\n  domain_name = \"example\"\n  auth_mode   = \"IAM\"\n  vpc_id      = aws_vpc.test.id\n  subnet_ids  = [aws_subnet.test.id]\n\n  default_user_settings {\n    execution_role = aws_iam_role.test.arn\n\n    kernel_gateway_app_settings {\n      custom_image {\n        app_image_config_name = aws_sagemaker_app_image_config.test.app_image_config_name\n        image_name            = aws_sagemaker_image_version.test.image_name\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Required) The domain name.\n* `auth_mode` - (Required) The mode of authentication that members use to access the domain. Valid values are `IAM` and `SSO`.\n* `vpc_id` - (Required) The ID of the Amazon Virtual Private Cloud (VPC) that Studio uses for communication.\n* `subnet_ids` - (Required) The VPC subnets that Studio uses for communication.\n* `default_user_settings` - (Required) The default user settings. See [Default User Settings](#default-user-settings) below.\n* `retention_policy` - (Optional) The retention policy for this domain, which specifies whether resources will be retained after the Domain is deleted. By default, all resources are retained. See [Retention Policy](#retention-policy) below.\n* `kms_key_id` - (Optional) The AWS KMS customer managed CMK used to encrypt the EFS volume attached to the domain.\n* `app_network_access_type` - (Optional) Specifies the VPC used for non-EFS traffic. The default value is `PublicInternetOnly`. Valid values are `PublicInternetOnly` and `VpcOnly`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Default User Settings\n\n* `execution_role` - (Required) The execution role ARN for the user.\n* `security_groups` - (Optional) The security groups.\n* `sharing_settings` - (Optional) The sharing settings. See [Sharing Settings](#sharing-settings) below.\n* `tensor_board_app_settings` - (Optional) The TensorBoard app settings. See [TensorBoard App Settings](#tensorboard-app-settings) below.\n* `jupyter_server_app_settings` - (Optional) The Jupyter server's app settings. See [Jupyter Server App Settings](#jupyter-server-app-settings) below.\n* `kernel_gateway_app_settings` - (Optional) The kernel gateway app settings. See [Kernel Gateway App Settings](#kernal-gateway-app-settings) below.\n\n#### Sharing Settings\n\n* `notebook_output_option` - (Optional) Whether to include the notebook cell output when sharing the notebook. The default is `Disabled`. Valid values are `Allowed` and `Disabled`.\n* `s3_kms_key_id` - (Optional) When `notebook_output_option` is Allowed, the AWS Key Management Service (KMS) encryption key ID used to encrypt the notebook cell output in the Amazon S3 bucket.\n* `s3_output_path` - (Optional) When `notebook_output_option` is Allowed, the Amazon S3 bucket used to save the notebook cell output.\n\n#### TensorBoard App Settings\n\n* `default_resource_spec` - (Optional) The default instance type and the Amazon Resource Name (ARN) of the SageMaker image created on the instance. see [Default Resource Spec](#default-resource-spec) below.\n\n#### Kernel Gateway App Settings\n\n* `default_resource_spec` - (Optional) The default instance type and the Amazon Resource Name (ARN) of the SageMaker image created on the instance. see [Default Resource Spec](#default-resource-spec) below.\n* `custom_image` - (Optional) A list of custom SageMaker images that are configured to run as a KernelGateway app. see [Custom Image](#custom-image) below.\n* `lifecycle_config_arns` - (Optional) The Amazon Resource Name (ARN) of the Lifecycle Configurations.\n\n#### Jupyter Server App Settings\n\n* `default_resource_spec` - (Optional) The default instance type and the Amazon Resource Name (ARN) of the SageMaker image created on the instance. see [Default Resource Spec](#default-resource-spec) below.\n* `lifecycle_config_arns` - (Optional) The Amazon Resource Name (ARN) of the Lifecycle Configurations.\n\n##### Default Resource Spec\n\n* `instance_type` - (Optional) The instance type that the image version runs on.. For valid values see [Sagemaker Instance Types](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html).\n* `sagemaker_image_arn` - (Optional) The ARN of the SageMaker image that the image version belongs to.\n\n##### Custom Image\n\n* `app_image_config_name` - (Required) The name of the App Image Config.\n* `image_name` - (Required) The name of the Custom Image.\n* `image_version_number` - (Optional) The version number of the Custom Image.\n\n### Retention Policy\n\n* `home_efs_file_system` - (Optional) The retention policy for data stored on an Amazon Elastic File System (EFS) volume. Default value is `Retain`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Domain.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Domain.\n* `url` - The domain's URL.\n* `single_sign_on_managed_application_instance_id` - The SSO managed application instance ID.\n* `home_efs_file_system_id` - The ID of the Amazon Elastic File System (EFS) managed by this Domain.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Code Domains can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_sagemaker_domain.test_domain d-8jgsjtilstu8\n```\n",
    "basename": "sagemaker_domain.html"
  },
  "sagemaker_endpoint.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_endpoint",
    "description": "Provides a SageMaker Endpoint resource.",
    "preview": "# Resource: aws_sagemaker_endpoint\n\nProvides a SageMaker Endpoint …",
    "content": "\n\n# Resource: aws_sagemaker_endpoint\n\nProvides a SageMaker Endpoint resource.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_sagemaker_endpoint\" \"e\" {\n  name                 = \"my-endpoint\"\n  endpoint_config_name = aws_sagemaker_endpoint_configuration.ec.name\n\n  tags = {\n    Name = \"foo\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `endpoint_config_name` - (Required) The name of the endpoint configuration to use.\n* `deployment_config` - (Optional) The deployment configuration for an endpoint, which contains the desired deployment strategy and rollback configurations. See [Deployment Config](#deployment-config).\n* `name` - (Optional) The name of the endpoint. If omitted, Terraform will assign a random, unique name.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Deployment Config\n\n* `blue_green_update_policy` - (Required) Update policy for a blue/green deployment. If this update policy is specified, SageMaker creates a new fleet during the deployment while maintaining the old fleet. See [Blue Green Update Config](#blue-green-update-policy).\n* `auto_rollback_configuration` - (Optional) Automatic rollback configuration for handling endpoint deployment failures and recovery. See [Auto Rollback Configuration](#auto-rollback-configuration).\n\n#### Blue Green Update Config\n\n* `traffic_routing_configuration` - (Required) Defines the traffic routing strategy to shift traffic from the old fleet to the new fleet during an endpoint deployment. See [Traffic Routing Configuration](#traffic-routing-configuration).\n* `maximum_execution_timeout_in_seconds` - (Optional) Maximum execution timeout for the deployment. Note that the timeout value should be larger than the total waiting time specified in `termination_wait_in_seconds` and `wait_interval_in_seconds`. Valid values are between `600` and `14400`.\n* `termination_wait_in_seconds` - (Optional) Additional waiting time in seconds after the completion of an endpoint deployment before terminating the old endpoint fleet. Default is `0`. Valid values are between `0` and `3600`.\n\n##### Traffic Routing Configuration\n\n* `type` - (Required) Traffic routing strategy type. Valid values are: `ALL_AT_ONCE`, `CANARY`, and `LINEAR`.\n* `wait_interval_in_seconds` - (Required) The waiting time (in seconds) between incremental steps to turn on traffic on the new endpoint fleet. Valid values are between `0` and `3600`.\n* `canary_size` - (Optional) Batch size for the first step to turn on traffic on the new endpoint fleet. Value must be less than or equal to 50% of the variant's total instance count. See [Canary Size](#canary-size).\n* `linear_step_size` - (Optional) Batch size for each step to turn on traffic on the new endpoint fleet. Value must be 10-50% of the variant's total instance count. See [Linear Step Size](#linear-step-size).\n\n###### Canary Size\n\n* `type` - (Required) Specifies the endpoint capacity type. Valid values are: `INSTANCE_COUNT`, or `CAPACITY_PERCENT`.\n* `value` - (Required) Defines the capacity size, either as a number of instances or a capacity percentage.\n\n###### Linear Step Size\n\n* `type` - (Required) Specifies the endpoint capacity type. Valid values are: `INSTANCE_COUNT`, or `CAPACITY_PERCENT`.\n* `value` - (Required) Defines the capacity size, either as a number of instances or a capacity percentage.\n\n#### Auto Rollback Configuration\n\n* `alarms` - (Required) List of CloudWatch alarms in your account that are configured to monitor metrics on an endpoint. If any alarms are tripped during a deployment, SageMaker rolls back the deployment. See [Alarms](#alarms).\n\n##### Alarms\n\n* `alarm_name` - (Required) The name of a CloudWatch alarm in your account.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this endpoint.\n* `name` - The name of the endpoint.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEndpoints can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_endpoint.test_endpoint my-endpoint\n```\n",
    "basename": "sagemaker_endpoint.html"
  },
  "sagemaker_endpoint_configuration.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_endpoint_configuration",
    "description": "Provides a SageMaker Endpoint Configuration resource.",
    "preview": "# Resource: aws_sagemaker_endpoint_configuration\n\nProvides a …",
    "content": "\n\n# Resource: aws_sagemaker_endpoint_configuration\n\nProvides a SageMaker endpoint configuration resource.\n\n## Example Usage\n\n\nBasic usage:\n\n```terraform\nresource \"aws_sagemaker_endpoint_configuration\" \"ec\" {\n  name = \"my-endpoint-config\"\n\n  production_variants {\n    variant_name           = \"variant-1\"\n    model_name             = aws_sagemaker_model.m.name\n    initial_instance_count = 1\n    instance_type          = \"ml.t2.medium\"\n  }\n\n  tags = {\n    Name = \"foo\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `production_variants` - (Required) Fields are documented below.\n* `kms_key_arn` - (Optional) Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint.\n* `name` - (Optional) The name of the endpoint configuration. If omitted, Terraform will assign a random, unique name.\n* `tags` - (Optional) A mapping of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `data_capture_config` - (Optional) Specifies the parameters to capture input/output of Sagemaker models endpoints. Fields are documented below.\n* `async_inference_config` - (Optional) Specifies configuration for how an endpoint performs asynchronous inference.\n\nThe `production_variants` block supports:\n\n* `initial_instance_count` - (Required) Initial number of instances used for auto-scaling.\n* `instance_type` (Required) - The type of instance to start.\n* `accelerator_type` (Optional) - The size of the Elastic Inference (EI) instance to use for the production variant.\n* `initial_variant_weight` (Optional) - Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to 1.0.\n* `model_name` - (Required) The name of the model to use.\n* `variant_name` - (Optional) The name of the variant. If omitted, Terraform will assign a random, unique name.\n\nThe `data_capture_config` block supports:\n\n* `initial_sampling_percentage` - (Required) Portion of data to capture. Should be between 0 and 100.\n* `destination_s3_uri` - (Required) The URL for S3 location where the captured data is stored.\n* `capture_options` - (Required) Specifies what data to capture. Fields are documented below.\n* `kms_key_id` - (Optional) Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt the captured data on Amazon S3.\n* `enable_capture` - (Optional) Flag to enable data capture. Defaults to `false`.\n* `capture_content_type_header` - (Optional) The content type headers to capture. Fields are documented below.\n\nThe `capture_options` block supports:\n\n* `capture_mode` - (Required) Specifies the data to be captured. Should be one of `Input` or `Output`.\n\nThe `capture_content_type_header` block supports:\n\n* `csv_content_types` - (Optional) The CSV content type headers to capture.\n* `json_content_types` - (Optional) The JSON content type headers to capture.\n\nThe `async_inference_config` block supports:\n\n* `output_config` - (Required) Specifies the configuration for asynchronous inference invocation outputs.\n* `client_config` - (Optional) Configures the behavior of the client used by Amazon SageMaker to interact with the model container during asynchronous inference.\n\nThe `client_config` block supports:\n\n* `max_concurrent_invocations_per_instance` - (Optional) The maximum number of concurrent requests sent by the SageMaker client to the model container. If no value is provided, Amazon SageMaker will choose an optimal value for you.\n\nThe `output_config` block supports:\n\n* `s3_output_path` - (Required) The Amazon S3 location to upload inference responses to.\n* `kms_key_id` - (Optional) The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt the asynchronous inference output in Amazon S3.\n* `notification_config` - (Optional) Specifies the configuration for notifications of inference results for asynchronous inference.\n\nThe `notification_config` block supports:\n\n* `error_topic` - (Optional) Amazon SNS topic to post a notification to when inference fails. If no topic is provided, no notification is sent on failure.\n* `success_topic` - (Optional) Amazon SNS topic to post a notification to when inference completes successfully. If no topic is provided, no notification is sent on success.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this endpoint configuration.\n* `name` - The name of the endpoint configuration.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEndpoint configurations can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_endpoint_configuration.test_endpoint_config endpoint-config-foo\n```\n",
    "basename": "sagemaker_endpoint_configuration.html"
  },
  "sagemaker_feature_group.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_feature_group",
    "description": "Provides a SageMaker Feature Group resource.",
    "preview": "# Resource: aws_sagemaker_feature_group\n\nProvides a SageMaker …",
    "content": "\n\n# Resource: aws_sagemaker_feature_group\n\nProvides a SageMaker Feature Group resource.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_sagemaker_feature_group\" \"example\" {\n  feature_group_name             = \"example\"\n  record_identifier_feature_name = \"example\"\n  event_time_feature_name        = \"example\"\n  role_arn                       = aws_iam_role.test.arn\n\n  feature_definition {\n    feature_name = \"example\"\n    feature_type = \"String\"\n  }\n\n  online_store_config {\n    enable_online_store = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `feature_group_name` - (Required) The name of the Feature Group. The name must be unique within an AWS Region in an AWS account.\n* `record_identifier_feature_name` - (Required) The name of the Feature whose value uniquely identifies a Record defined in the Feature Store. Only the latest record per identifier value will be stored in the Online Store.\n* `event_time_feature_name` - (Required) The name of the feature that stores the EventTime of a Record in a Feature Group.\n* `description` (Optional) - A free-form description of a Feature Group.\n* `role_arn` (Required) - The Amazon Resource Name (ARN) of the IAM execution role used to persist data into the Offline Store if an `offline_store_config` is provided.\n* `feature_definition` (Optional) - A list of Feature names and types. See [Feature Definition](#feature-definition) Below.\n* `offline_store_config` (Optional) - The Offline Feature Store Configuration. See [Offline Store Config](#offline-store-config) Below.\n* `online_store_config` (Optional) - The Online Feature Store Configuration. See [Online Store Config](#online-store-config) Below.\n* `tags` - (Optional) Map of resource tags for the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Feature Definition\n\n* `feature_name` - (Required) The name of a feature. `feature_name` cannot be any of the following: `is_deleted`, `write_time`, `api_invocation_time`.\n* `feature_type` - (Required) The value type of a feature. Valid values are `Integral`, `Fractional`, or `String`.\n\n### Offline Store Config\n\n* `enable_online_store` - (Optional) Set to `true` to disable the automatic creation of an AWS Glue table when configuring an OfflineStore.\n* `s3_storage_config` - (Required) The Amazon Simple Storage (Amazon S3) location of OfflineStore. See [S3 Storage Config](#s3-storage-config) Below.\n* `data_catalog_config` - (Optional) The meta data of the Glue table that is autogenerated when an OfflineStore is created. See [Data Catalog Config](#data-catalog-config) Below.\n\n### Online Store Config\n\n* `disable_glue_table_creation` - (Optional) Set to `true` to turn Online Store On.\n* `security_config` - (Required) Security config for at-rest encryption of your OnlineStore. See [Security Config](#security-config) Below.\n\n#### S3 Storage Config\n\n* `kms_key_id` - (Optional) The AWS Key Management Service (KMS) key ID of the key used to encrypt any objects written into the OfflineStore S3 location.\n* `s3_uri` - (Required) The S3 URI, or location in Amazon S3, of OfflineStore.\n\n#### Data Catalog Config\n\n* `catalog` - (Optional) The name of the Glue table catalog.\n* `database` - (Optional) The name of the Glue table database.\n* `table_name` - (Optional) The name of the Glue table.\n\n#### Security Config\n\n* `kms_key_id` - (Optional) The ID of the AWS Key Management Service (AWS KMS) key that SageMaker Feature Store uses to encrypt the Amazon S3 objects at rest using Amazon S3 server-side encryption.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `name` - The name of the Feature Group.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this feature_group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nFeature Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_feature_group.test_feature_group feature_group-foo\n```\n",
    "basename": "sagemaker_feature_group.html"
  },
  "sagemaker_flow_definition.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_flow_definition",
    "description": "Provides a Sagemaker Flow Definition resource.",
    "preview": "# Resource: aws_sagemaker_flow_definition\n\nProvides a Sagemaker Flow …",
    "content": "\n\n# Resource: aws_sagemaker_flow_definition\n\nProvides a Sagemaker Flow Definition resource.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_sagemaker_flow_definition\" \"example\" {\n  flow_definition_name = \"example\"\n  role_arn             = aws_iam_role.example.arn\n\n  human_loop_config {\n    human_task_ui_arn                     = aws_sagemaker_human_task_ui.example.arn\n    task_availability_lifetime_in_seconds = 1\n    task_count                            = 1\n    task_description                      = \"example\"\n    task_title                            = \"example\"\n    workteam_arn                          = aws_sagemaker_workteam.example.arn\n  }\n\n  output_config {\n    s3_output_path = \"s3://${aws_s3_bucket.example.bucket}/\"\n  }\n}\n```\n\n### Public Workteam Usage\n\n```terraform\nresource \"aws_sagemaker_flow_definition\" \"example\" {\n  flow_definition_name = \"example\"\n  role_arn             = aws_iam_role.example.arn\n\n  human_loop_config {\n    human_task_ui_arn                     = aws_sagemaker_human_task_ui.example.arn\n    task_availability_lifetime_in_seconds = 1\n    task_count                            = 1\n    task_description                      = \"example\"\n    task_title                            = \"example\"\n    workteam_arn                          = \"arn:aws:sagemaker:${data.aws_region.current.name}:394669845002:workteam/public-crowd/default\"\n\n    public_workforce_task_price {\n      amount_in_usd {\n        cents                     = 1\n        tenth_fractions_of_a_cent = 2\n      }\n    }\n  }\n\n  output_config {\n    s3_output_path = \"s3://${aws_s3_bucket.example.bucket}/\"\n  }\n}\n```\n\n### Human Loop Activation Config Usage\n\n```terraform\nresource \"aws_sagemaker_flow_definition\" \"example\" {\n  flow_definition_name = \"example\"\n  role_arn             = aws_iam_role.example.arn\n\n  human_loop_config {\n    human_task_ui_arn                     = aws_sagemaker_human_task_ui.example.arn\n    task_availability_lifetime_in_seconds = 1\n    task_count                            = 1\n    task_description                      = \"example\"\n    task_title                            = \"example\"\n    workteam_arn                          = aws_sagemaker_workteam.example.arn\n  }\n\n  human_loop_request_source {\n    aws_managed_human_loop_request_source = \"AWS/Textract/AnalyzeDocument/Forms/V1\"\n  }\n\n  human_loop_activation_config {\n    human_loop_activation_conditions_config {\n      human_loop_activation_conditions = <<EOF\n        {\n\t\t\t\"Conditions\": [\n\t\t\t  {\n\t\t\t\t\"ConditionType\": \"Sampling\",\n\t\t\t\t\"ConditionParameters\": {\n\t\t\t\t  \"RandomSamplingPercentage\": 5\n\t\t\t\t}\n\t\t\t  }\n\t\t\t]\n\t\t}\n        EOF\n    }\n  }\n\n  output_config {\n    s3_output_path = \"s3://${aws_s3_bucket.example.bucket}/\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `flow_definition_name` - (Required) The name of your flow definition.\n* `human_loop_config` - (Required)  An object containing information about the tasks the human reviewers will perform. See [Human Loop Config](#human-loop-config) details below.\n* `role_arn` - (Required) The Amazon Resource Name (ARN) of the role needed to call other services on your behalf.\n* `output_config` - (Required) An object containing information about where the human review results will be uploaded. See [Output Config](#output-config) details below.\n* `human_loop_activation_config` - (Optional) An object containing information about the events that trigger a human workflow. See [Human Loop Activation Config](#human-loop-activation-config) details below.\n* `human_loop_request_source` - (Optional) Container for configuring the source of human task requests. Use to specify if Amazon Rekognition or Amazon Textract is used as an integration source. See [Human Loop Request Source](#human-loop-request-source) details below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Human Loop Config\n\n* `human_task_ui_arn` - (Required) The Amazon Resource Name (ARN) of the human task user interface.\n* `public_workforce_task_price` - (Optional) Defines the amount of money paid to an Amazon Mechanical Turk worker for each task performed. See [Public Workforce Task Price](#public-workforce-task-price) details below.\n* `task_availability_lifetime_in_seconds` - (Required) The length of time that a task remains available for review by human workers. Valid value range between `1` and `864000`.\n* `task_count` - (Required) The number of distinct workers who will perform the same task on each object. Valid value range between `1` and `3`.\n* `task_description` - (Required) A description for the human worker task.\n* `task_keywords` - (Optional) An array of keywords used to describe the task so that workers can discover the task.\n* `task_time_limit_in_seconds` - (Optional) The amount of time that a worker has to complete a task. The default value is `3600` seconds.\n* `task_title` - (Required) A title for the human worker task.\n* `workteam_arn` - (Required) The Amazon Resource Name (ARN) of the human task user interface. Amazon Resource Name (ARN) of a team of workers. For Public workforces see [AWS Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-management-public.html).\n\n#### Public Workforce Task Price\n\n* `amount_in_usd` - (Optional) Defines the amount of money paid to an Amazon Mechanical Turk worker in United States dollars. See [Amount In Usd](#amount-in-usd) details below.\n\n##### Amount In Usd\n\n* `cents` - (Optional) The fractional portion, in cents, of the amount. Valid value range between `0` and `99`.\n* `dollars` - (Optional) The whole number of dollars in the amount. Valid value range between `0` and `2`.\n* `tenth_fractions_of_a_cent` - (Optional) Fractions of a cent, in tenths. Valid value range between `0` and `9`.\n\n\n### Human Loop Activation Config\n\n* `human_loop_activation_conditions_config` - (Required) defines under what conditions SageMaker creates a human loop. See [Human Loop Activation Conditions Config](#human-loop-activation-conditions-config) details below.\n\n#### Human Loop Activation Conditions Config\n\n* `human_loop_activation_conditions` - (Required) A JSON expressing use-case specific conditions declaratively. If any condition is matched, atomic tasks are created against the configured work team. For more information about how to structure the JSON, see [JSON Schema for Human Loop Activation Conditions in Amazon Augmented AI](https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-human-fallback-conditions-json-schema.html).\n\n### Human Loop Request Source\n\n* `aws_managed_human_loop_request_source` - (Required) Specifies whether Amazon Rekognition or Amazon Textract are used as the integration source. Valid values are: `AWS/Rekognition/DetectModerationLabels/Image/V3` and `AWS/Textract/AnalyzeDocument/Forms/V1`.\n\n### Output Config\n\n* `s3_output_path` - (Required) The Amazon S3 path where the object containing human output will be made available.\n* `kms_key_id` - (Optional) The Amazon Key Management Service (KMS) key ARN for server-side encryption.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Flow Definition.\n* `id` - The name of the Flow Definition.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Flow Definitions can be imported using the `flow_definition_name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_flow_definition.example example\n```\n",
    "basename": "sagemaker_flow_definition.html"
  },
  "sagemaker_human_task_ui.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_human_task_ui",
    "description": "Provides a Sagemaker Human Task UI resource.",
    "preview": "# Resource: aws_sagemaker_human_task_ui\n\nProvides a Sagemaker Human …",
    "content": "\n\n# Resource: aws_sagemaker_human_task_ui\n\nProvides a Sagemaker Human Task UI resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_sagemaker_human_task_ui\" \"example\" {\n  human_task_ui_name = \"example\"\n\n  ui_template {\n    content = file(\"sagemaker-human-task-ui-template.html\")\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `human_task_ui_name` - (Required) The name of the Human Task UI.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `ui_template` - (Required) The Liquid template for the worker user interface. See [UI Template](#ui-template) below.\n\n### UI Template\n\n* `content` - (Required) The content of the Liquid template for the worker user interface.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Human Task UI.\n* `id` - The name of the Human Task UI.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `ui_template` - (Required) The Liquid template for the worker user interface. See [UI Template](#ui-template) below.\n\n### UI Template\n\n* `content_sha256` - The SHA-256 digest of the contents of the template.\n* `url` - The URL for the user interface template.\n\n## Import\n\nSagemaker Human Task UIs can be imported using the `human_task_ui_name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_human_task_ui.example example\n```\n",
    "basename": "sagemaker_human_task_ui.html"
  },
  "sagemaker_image.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_image",
    "description": "Provides a Sagemaker Image resource.",
    "preview": "# Resource: aws_sagemaker_image\n\nProvides a Sagemaker Image …",
    "content": "\n\n# Resource: aws_sagemaker_image\n\nProvides a Sagemaker Image resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_image\" \"example\" {\n  image_name = \"example\"\n  role_arn   = aws_iam_role.test.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `image_name` - (Required) The name of the image. Must be unique to your account.\n* `role_arn` - (Required) The Amazon Resource Name (ARN) of an IAM role that enables Amazon SageMaker to perform tasks on your behalf.\n* `display_name` - (Optional) The display name of the image. When the image is added to a domain (must be unique to the domain).\n* `description` - (Optional) The description of the image.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Image.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Image.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Code Images can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_image.test_image my-code-repo\n```\n",
    "basename": "sagemaker_image.html"
  },
  "sagemaker_image_version.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_image_version",
    "description": "Provides a Sagemaker Image Version resource.",
    "preview": "# Resource: aws_sagemaker_image_version\n\nProvides a Sagemaker Image …",
    "content": "\n\n# Resource: aws_sagemaker_image_version\n\nProvides a Sagemaker Image Version resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_image_version\" \"test\" {\n  image_name = aws_sagemaker_image.test.id\n  base_image = \"012345678912.dkr.ecr.us-west-2.amazonaws.com/image:latest\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `image_name` - (Required) The name of the image. Must be unique to your account.\n* `base_image` - (Required) The registry path of the container image on which this image version is based.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Image.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Image Version.\n* `image_arn`- The Amazon Resource Name (ARN) of the image the version is based on.\n* `container_image` - The registry path of the container image that contains this image version.\n\n## Import\n\nSagemaker Image Versions can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_image_version.test_image my-code-repo\n```\n",
    "basename": "sagemaker_image_version.html"
  },
  "sagemaker_model.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_model",
    "description": "Provides a SageMaker model resource.",
    "preview": "# Resource: aws_sagemaker_model\n\nProvides a SageMaker model …",
    "content": "\n\n# Resource: aws_sagemaker_model\n\nProvides a SageMaker model resource.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_sagemaker_model\" \"example\" {\n  name               = \"my-model\"\n  execution_role_arn = aws_iam_role.example.arn\n\n  primary_container {\n    image = data.aws_sagemaker_prebuilt_ecr_image.test.registry_path\n  }\n}\n\nresource \"aws_iam_role\" \"example\" {\n  assume_role_policy = data.aws_iam_policy_document.assume_role.json\n}\n\ndata \"aws_iam_policy_document\" \"assume_role\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"sagemaker.amazonaws.com\"]\n    }\n  }\n}\n\ndata \"aws_sagemaker_prebuilt_ecr_image\" \"test\" {\n  repository_name = \"kmeans\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the model (must be unique). If omitted, Terraform will assign a random, unique name.\n* `primary_container` - (Optional) The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the `container` argument is required. Fields are documented below.\n* `execution_role_arn` - (Required) A role that SageMaker can assume to access model artifacts and docker images for deployment.\n* `inference_execution_config` - (Optional) Specifies details of how containers in a multi-container endpoint are called. see [Inference Execution Config](#inference-execution-config).\n* `container` (Optional) -  Specifies containers in the inference pipeline. If not specified, the `primary_container` argument is required. Fields are documented below.\n* `enable_network_isolation` (Optional) - Isolates the model container. No inbound or outbound network calls can be made to or from the model container.\n* `vpc_config` (Optional) - Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `primary_container` and `container` block both support:\n\n* `image` - (Required) The registry path where the inference code image is stored in Amazon ECR.\n* `mode` - (Optional) The container hosts value `SingleModel/MultiModel`. The default value is `SingleModel`.\n* `model_data_url` - (Optional) The URL for the S3 location where model artifacts are stored.\n* `container_hostname` - (Optional) The DNS host name for the container.\n* `environment` - (Optional) Environment variables for the Docker container.\n   A list of key value pairs.\n* `image_config` - (Optional) Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see [Using a Private Docker Registry for Real-Time Inference Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-containers-inference-private.html). see [Image Config](#image-config).\n\n### Image Config\n\n* `repository_access_mode` - (Required) Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: `Platform` and `Vpc`.\n\n## Inference Execution Config\n\n* `mode` - (Required) How containers in a multi-container are run. The following values are valid `Serial` and `Direct`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `name` - The name of the model.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this model.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nModels can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_model.test_model model-foo\n```\n",
    "basename": "sagemaker_model.html"
  },
  "sagemaker_model_package_group.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_model_package_group",
    "description": "Provides a Sagemaker Model Package Group resource.",
    "preview": "# Resource: aws_sagemaker_model_package_group\n\nProvides a Sagemaker …",
    "content": "\n\n# Resource: aws_sagemaker_model_package_group\n\nProvides a Sagemaker Model Package Group resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_model_package_group\" \"example\" {\n  model_package_group_name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `model_package_group_name` - (Required) The name of the model group.\n* `model_package_group_description` - (Optional) A description for the model group.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Model Package Group.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Model Package Group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Code Model Package Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_model_package_group.test_model_package_group my-code-repo\n```\n",
    "basename": "sagemaker_model_package_group.html"
  },
  "sagemaker_model_package_group_policy.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_model_package_group_policy",
    "description": "Provides a Sagemaker Model Package Group Policy resource.",
    "preview": "# Resource: aws_sagemaker_model_package_group_policy\n\nProvides a …",
    "content": "\n\n# Resource: aws_sagemaker_model_package_group_policy\n\nProvides a Sagemaker Model Package Group Policy resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_iam_policy_document\" \"example\" {\n  statement {\n    sid       = \"AddPermModelPackageGroup\"\n    actions   = [\"sagemaker:DescribeModelPackage\", \"sagemaker:ListModelPackages\"]\n    resources = [aws_sagemaker_model_package_group.example.arn]\n    principals {\n      identifiers = [data.aws_caller_identity.current.account_id]\n      type        = \"AWS\"\n    }\n  }\n}\n\nresource \"aws_sagemaker_model_package_group\" \"example\" {\n  model_package_group_name = \"example\"\n}\n\nresource \"aws_sagemaker_model_package_group_policy\" \"example\" {\n  model_package_group_name = aws_sagemaker_model_package_group.example.model_package_group_name\n  resource_policy          = jsonencode(jsondecode(data.aws_iam_policy_document.example.json))\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `model_package_group_name` - (Required) The name of the model package group.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Model Package Package Group.\n\n## Import\n\nSagemaker Code Model Package Groups can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_model_package_group_policy.example example\n```\n",
    "basename": "sagemaker_model_package_group_policy.html"
  },
  "sagemaker_notebook_instance.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_notebook_instance",
    "description": "Provides a Sagemaker Notebook Instance resource.",
    "preview": "# Resource: aws_sagemaker_notebook_instance\n\nProvides a Sagemaker …",
    "content": "\n\n# Resource: aws_sagemaker_notebook_instance\n\nProvides a Sagemaker Notebook Instance resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_notebook_instance\" \"ni\" {\n  name          = \"my-notebook-instance\"\n  role_arn      = aws_iam_role.role.arn\n  instance_type = \"ml.t2.medium\"\n\n  tags = {\n    Name = \"foo\"\n  }\n}\n```\n\n### Code repository usage\n\n```terraform\nresource \"aws_sagemaker_code_repository\" \"example\" {\n  code_repository_name = \"my-notebook-instance-code-repo\"\n\n  git_config {\n    repository_url = \"https://github.com/hashicorp/terraform-provider-aws.git\"\n  }\n}\n\nresource \"aws_sagemaker_notebook_instance\" \"ni\" {\n  name                    = \"my-notebook-instance\"\n  role_arn                = aws_iam_role.role.arn\n  instance_type           = \"ml.t2.medium\"\n  default_code_repository = aws_sagemaker_code_repository.example.code_repository_name\n\n  tags = {\n    Name = \"foo\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the notebook instance (must be unique).\n* `role_arn` - (Required) The ARN of the IAM role to be used by the notebook instance which allows SageMaker to call other services on your behalf.\n* `instance_type` - (Required) The name of ML compute instance type.\n* `platform_identifier` - (Optional) The platform identifier of the notebook instance runtime environment. This value can be either `notebook-al1-v1` or `notebook-al2-v1`, depending on which version of Amazon Linux you require.\n* `volume_size` - (Optional) The size, in GB, of the ML storage volume to attach to the notebook instance. The default value is 5 GB.\n* `subnet_id` - (Optional) The VPC subnet ID.\n* `security_groups` - (Optional) The associated security groups.\n* `kms_key_id` - (Optional) The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the model artifacts at rest using Amazon S3 server-side encryption.\n* `lifecycle_config_name` - (Optional) The name of a lifecycle configuration to associate with the notebook instance.\n* `root_access` - (Optional) Whether root access is `Enabled` or `Disabled` for users of the notebook instance. The default value is `Enabled`.\n* `direct_internet_access` - (Optional) Set to `Disabled` to disable internet access to notebook. Requires `security_groups` and `subnet_id` to be set. Supported values: `Enabled` (Default) or `Disabled`. If set to `Disabled`, the notebook instance will be able to access resources only in your VPC, and will not be able to connect to Amazon SageMaker training and endpoint services unless your configure a NAT Gateway in your VPC.\n* `additional_code_repositories` - (Optional) An array of up to three Git repositories to associate with the notebook instance.\n These can be either the names of Git repositories stored as resources in your account, or the URL of Git repositories in [AWS CodeCommit](https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html) or in any other Git repository. These repositories are cloned at the same level as the default repository of your notebook instance.\n* `default_code_repository` - (Optional) The Git repository associated with the notebook instance as its default code repository. This can be either the name of a Git repository stored as a resource in your account, or the URL of a Git repository in [AWS CodeCommit](https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html) or in any other Git repository.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the notebook instance.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this notebook instance.\n* `url` - The URL that you use to connect to the Jupyter notebook that is running in your notebook instance.\n* `network_interface_id` - The network interface ID that Amazon SageMaker created at the time of creating the instance. Only available when setting `subnet_id`.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Notebook Instances can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_notebook_instance.test_notebook_instance my-notebook-instance\n```\n",
    "basename": "sagemaker_notebook_instance.html"
  },
  "sagemaker_notebook_instance_lifecycle_configuration.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_notebook_instance_lifecycle_configuration",
    "description": "Provides a lifecycle configuration for SageMaker Notebook Instances.",
    "preview": "# Resource: aws_sagemaker_notebook_instance_lifecycle_configuration\n …",
    "content": "\n\n# Resource: aws_sagemaker_notebook_instance_lifecycle_configuration\n\nProvides a lifecycle configuration for SageMaker Notebook Instances.\n\n## Example Usage\n\nUsage:\n\n```terraform\nresource \"aws_sagemaker_notebook_instance_lifecycle_configuration\" \"lc\" {\n  name      = \"foo\"\n  on_create = base64encode(\"echo foo\")\n  on_start  = base64encode(\"echo bar\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the lifecycle configuration (must be unique). If omitted, Terraform will assign a random, unique name.\n* `on_create` - (Optional) A shell script (base64-encoded) that runs only once when the SageMaker Notebook Instance is created.\n* `on_start` - (Optional) A shell script (base64-encoded) that runs every time the SageMaker Notebook Instance is started including the time it's created.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this lifecycle configuration.\n\n## Import\n\nModels can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_notebook_instance_lifecycle_configuration.lc foo\n```\n",
    "basename": "sagemaker_notebook_instance_lifecycle_configuration.html"
  },
  "sagemaker_studio_lifecycle_config.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_studio_lifecycle_config",
    "description": "Provides a Sagemaker Studio Lifecycle Config resource.",
    "preview": "# Resource: aws_sagemaker_studio_lifecycle_config\n\nProvides a …",
    "content": "\n\n# Resource: aws_sagemaker_studio_lifecycle_config\n\nProvides a Sagemaker Studio Lifecycle Config resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_studio_lifecycle_config\" \"example\" {\n  studio_lifecycle_config_name     = \"example\"\n  studio_lifecycle_config_app_type = \"JupyterServer\"\n  studio_lifecycle_config_content  = base64encode(\"echo Hello\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `studio_lifecycle_config_name` - (Required) The name of the Studio Lifecycle Configuration to create.\n* `studio_lifecycle_config_app_type` - (Required) The App type that the Lifecycle Configuration is attached to. Valid values are `JupyterServer` and `KernelGateway`.\n* `studio_lifecycle_config_content` - (Required) The content of your Studio Lifecycle Configuration script. This content must be base64 encoded.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Studio Lifecycle Config.\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Studio Lifecycle Config.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Code Studio Lifecycle Configs can be imported using the `studio_lifecycle_config_name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_studio_lifecycle_config.example example\n```\n",
    "basename": "sagemaker_studio_lifecycle_config.html"
  },
  "sagemaker_user_profile.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_user_profile",
    "description": "Provides a Sagemaker User Profile resource.",
    "preview": "# Resource: aws_sagemaker_user_profile\n\nProvides a Sagemaker User …",
    "content": "\n\n# Resource: aws_sagemaker_user_profile\n\nProvides a Sagemaker User Profile resource.\n\n## Example Usage\n\n### Basic usage\n\n```terraform\nresource \"aws_sagemaker_user_profile\" \"example\" {\n  domain_id         = aws_sagemaker_domain.test.id\n  user_profile_name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `user_profile_name` - (Required) The name for the User Profile.\n* `domain_id` - (Required) The ID of the associated Domain.\n* `single_sign_on_user_identifier` - (Optional) A specifier for the type of value specified in `single_sign_on_user_value`. Currently, the only supported value is `UserName`. If the Domain's AuthMode is SSO, this field is required. If the Domain's AuthMode is not SSO, this field cannot be specified.\n* `single_sign_on_user_value` - (Required) The username of the associated AWS Single Sign-On User for this User Profile. If the Domain's AuthMode is SSO, this field is required, and must match a valid username of a user in your directory. If the Domain's AuthMode is not SSO, this field cannot be specified.\n* `user_settings` - (Required) The user settings. See [User Settings](#user-settings) below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### User Settings\n\n* `execution_role` - (Required) The execution role ARN for the user.\n* `security_groups` - (Optional) The security groups.\n* `sharing_settings` - (Optional) The sharing settings. See [Sharing Settings](#sharing-settings) below.\n* `tensor_board_app_settings` - (Optional) The TensorBoard app settings. See [TensorBoard App Settings](#tensorboard-app-settings) below.\n* `jupyter_server_app_settings` - (Optional) The Jupyter server's app settings. See [Jupyter Server App Settings](#jupyter-server-app-settings) below.\n* `kernel_gateway_app_settings` - (Optional) The kernel gateway app settings. See [Kernel Gateway App Settings](#kernal-gateway-app-settings) below.\n\n#### Sharing Settings\n\n* `notebook_output_option` - (Optional) Whether to include the notebook cell output when sharing the notebook. The default is `Disabled`. Valid values are `Allowed` and `Disabled`.\n* `s3_kms_key_id` - (Optional) When `notebook_output_option` is Allowed, the AWS Key Management Service (KMS) encryption key ID used to encrypt the notebook cell output in the Amazon S3 bucket.\n* `s3_output_path` - (Optional) When `notebook_output_option` is Allowed, the Amazon S3 bucket used to save the notebook cell output.\n\n#### TensorBoard App Settings\n\n* `default_resource_spec` - (Optional) The default instance type and the Amazon Resource Name (ARN) of the SageMaker image created on the instance. see [Default Resource Spec](#default-resource-spec) below.\n\n#### Kernel Gateway App Settings\n\n* `default_resource_spec` - (Optional) The default instance type and the Amazon Resource Name (ARN) of the SageMaker image created on the instance. see [Default Resource Spec](#default-resource-spec) below.\n* `custom_image` - (Optional) A list of custom SageMaker images that are configured to run as a KernelGateway app. see [Custom Image](#custom-image) below.\n* `lifecycle_config_arns` - (Optional) The Amazon Resource Name (ARN) of the Lifecycle Configurations.\n\n#### Jupyter Server App Settings\n\n* `default_resource_spec` - (Optional) The default instance type and the Amazon Resource Name (ARN) of the SageMaker image created on the instance. see [Default Resource Spec](#default-resource-spec) below.\n* `lifecycle_config_arns` - (Optional) The Amazon Resource Name (ARN) of the Lifecycle Configurations.\n\n##### Default Resource Spec\n\n* `instance_type` - (Optional) The instance type.\n* `sagemaker_image_arn` - (Optional) The Amazon Resource Name (ARN) of the SageMaker image created on the instance.\n\n##### Custom Image\n\n* `app_image_config_name` - (Required) The name of the App Image Config.\n* `image_name` - (Required) The name of the Custom Image.\n* `image_version_number` - (Optional) The version number of the Custom Image.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The user profile Amazon Resource Name (ARN).\n* `arn` - The user profile Amazon Resource Name (ARN).\n* `home_efs_file_system_uid` - The ID of the user's profile in the Amazon Elastic File System (EFS) volume.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Code User Profiles can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_sagemaker_user_profile.test_user_profile arn:aws:sagemaker:us-west-2:123456789012:user-profile/domain-id/profile-name\n```\n",
    "basename": "sagemaker_user_profile.html"
  },
  "sagemaker_workforce.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_workforce",
    "description": "Provides a Sagemaker Workforce resource.",
    "preview": "# Resource: aws_sagemaker_workforce\n\nProvides a Sagemaker Workforce …",
    "content": "\n\n# Resource: aws_sagemaker_workforce\n\nProvides a Sagemaker Workforce resource.\n\n## Example Usage\n\n### Cognito Usage\n\n```terraform\nresource \"aws_sagemaker_workforce\" \"example\" {\n  workforce_name = \"example\"\n\n  cognito_config {\n    client_id = aws_cognito_user_pool_client.example.id\n    user_pool = aws_cognito_user_pool_domain.example.user_pool_id\n  }\n}\n\nresource \"aws_cognito_user_pool\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_cognito_user_pool_client\" \"example\" {\n  name            = \"example\"\n  generate_secret = true\n  user_pool_id    = aws_cognito_user_pool.example.id\n}\n\nresource \"aws_cognito_user_pool_domain\" \"example\" {\n  domain       = \"example\"\n  user_pool_id = aws_cognito_user_pool.example.id\n}\n```\n\n### Oidc Usage\n\n```terraform\nresource \"aws_sagemaker_workforce\" \"example\" {\n  workforce_name = \"example\"\n\n  oidc_config {\n    authorization_endpoint = \"https://example.com\"\n    client_id              = \"example\"\n    client_secret          = \"example\"\n    issuer                 = \"https://example.com\"\n    jwks_uri               = \"https://example.com\"\n    logout_endpoint        = \"https://example.com\"\n    token_endpoint         = \"https://example.com\"\n    user_info_endpoint     = \"https://example.com\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `workforce_name` - (Required) The name of the Workforce (must be unique).\n* `cognito_config` - (Required) Use this parameter to configure an Amazon Cognito private workforce. A single Cognito workforce is created using and corresponds to a single Amazon Cognito user pool. Conflicts with `oidc_config`. see [Cognito Config](#cognito-config) details below.\n* `oidc_config` - (Required) Use this parameter to configure a private workforce using your own OIDC Identity Provider. Conflicts with `cognito_config`. see [OIDC Config](#oidc-config) details below.\n* `source_ip_config` - (Required) A list of IP address ranges Used to create an allow list of IP addresses for a private workforce. By default, a workforce isn't restricted to specific IP addresses. see [Source Ip Config](#source-ip-config) details below.\n\n### Cognito Config\n\n* `client_id` - (Required) The client ID for your Amazon Cognito user pool.\n* `user_pool` - (Required) The id for your Amazon Cognito user pool.\n\n### Oidc Config\n\n* `authorization_endpoint` - (Required) The OIDC IdP authorization endpoint used to configure your private workforce.\n* `client_id` - (Required) The OIDC IdP client ID used to configure your private workforce.\n* `client_secret` - (Required) The OIDC IdP client secret used to configure your private workforce.\n* `issuer` - (Required) The OIDC IdP issuer used to configure your private workforce.\n* `jwks_uri` - (Required) The OIDC IdP JSON Web Key Set (Jwks) URI used to configure your private workforce.\n* `logout_endpoint` - (Required) The OIDC IdP logout endpoint used to configure your private workforce.\n* `token_endpoint` - (Required) The OIDC IdP token endpoint used to configure your private workforce.\n* `user_info_endpoint` - (Required) The OIDC IdP user information endpoint used to configure your private workforce.\n\n### Source Ip Config\n\n* `cidrs` - (Required) A list of up to 10 CIDR values.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Workforce.\n* `id` - The name of the Workforce.\n* `subdomain` - The subdomain for your OIDC Identity Provider.\n\n## Import\n\nSagemaker Workforces can be imported using the `workforce_name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_workforce.example example\n```\n",
    "basename": "sagemaker_workforce.html"
  },
  "sagemaker_workteam.html": {
    "subcategory": "Sagemaker",
    "layout": "aws",
    "page_title": "AWS: aws_sagemaker_workteam",
    "description": "Provides a Sagemaker Workteam resource.",
    "preview": "# Resource: aws_sagemaker_workteam\n\nProvides a Sagemaker Workteam …",
    "content": "\n\n# Resource: aws_sagemaker_workteam\n\nProvides a Sagemaker Workteam resource.\n\n## Example Usage\n\n### Cognito Usage\n\n```terraform\nresource \"aws_sagemaker_workteam\" \"example\" {\n  workteam_name  = \"example\"\n  workforce_name = aws_sagemaker_workforce.example.id\n  description    = \"example\"\n\n  member_definition {\n    cognito_member_definition {\n      client_id  = aws_cognito_user_pool_client.example.id\n      user_pool  = aws_cognito_user_pool_domain.example.user_pool_id\n      user_group = aws_cognito_user_group.example.id\n    }\n  }\n}\n```\n\n### Oidc Usage\n\n```terraform\nresource \"aws_sagemaker_workteam\" \"example\" {\n  workteam_name  = \"example\"\n  workforce_name = aws_sagemaker_workforce.example.id\n  description    = \"example\"\n\n  member_definition {\n    oidc_member_definition {\n      groups = [\"example\"]\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Required) A description of the work team.\n* `workforce_name` - (Required) The name of the Workteam (must be unique).\n* `workteam_name` - (Required) The name of the workforce.\n* `member_definition` - (Required) A list of Member Definitions that contains objects that identify the workers that make up the work team. Workforces can be created using Amazon Cognito or your own OIDC Identity Provider (IdP). For private workforces created using Amazon Cognito use `cognito_member_definition`. For workforces created using your own OIDC identity provider (IdP) use `oidc_member_definition`. Do not provide input for both of these parameters in a single request. see [Member Definition](#member-definition) details below.\n* `notification_configuration` - (Optional) Configures notification of workers regarding available or expiring work items. see [Notification Configuration](#notification-configuration) details below.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Member Definition\n\n* `cognito_member_definition` - (Optional) The Amazon Cognito user group that is part of the work team. See [Cognito Member Definition](#cognito-member-definition) details below.\n* `oidc_member_definition` - (Optional) A list user groups that exist in your OIDC Identity Provider (IdP). One to ten groups can be used to create a single private work team. See [Cognito Member Definition](#oidc-member-definition) details below.\n\n#### Cognito Member Definition\n\n* `client_id` - (Required) An identifier for an application client. You must create the app client ID using Amazon Cognito.\n* `user_pool` - (Required) An identifier for a user pool. The user pool must be in the same region as the service that you are calling.\n* `user_group` - (Required) An identifier for a user group.\n\n#### Oidc Member Definition\n\n* `groups` - (Required) A list of comma separated strings that identifies user groups in your OIDC IdP. Each user group is made up of a group of private workers.\n\n### Notification Configuration\n\n* `notification_topic_arn` - (Required) The ARN for the SNS topic to which notifications should be published.\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) assigned by AWS to this Workteam.\n* `id` - The name of the Workteam.\n* `subdomain` - The subdomain for your OIDC Identity Provider.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSagemaker Workteams can be imported using the `workteam_name`, e.g.,\n\n```\n$ terraform import aws_sagemaker_workteam.example example\n```\n",
    "basename": "sagemaker_workteam.html"
  },
  "schemas_discoverer.html": {
    "subcategory": "EventBridge Schemas",
    "layout": "aws",
    "page_title": "AWS: aws_schemas_discoverer",
    "description": "Provides an EventBridge Schema Discoverer resource.",
    "preview": "# Resource: aws_schemas_discoverer\n\nProvides an EventBridge Schema …",
    "content": "\n\n# Resource: aws_schemas_discoverer\n\nProvides an EventBridge Schema Discoverer resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n\n## Example Usage\n\n```terraform\nresource \"aws_cloudwatch_event_bus\" \"messenger\" {\n  name = \"chat-messages\"\n}\n\nresource \"aws_schemas_discoverer\" \"test\" {\n  source_arn  = aws_cloudwatch_event_bus.messenger.arn\n  description = \"Auto discover event schemas\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `source_arn` - (Required) The ARN of the event bus to discover event schemas on.\n* `description` - (Optional) The description of the discoverer. Maximum of 256 characters.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the discoverer.\n* `id` - The ID of the discoverer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEventBridge discoverers can be imported using the `id`, e.g.,\n\n```console\n$ terraform import aws_schemas_discoverer.test 123\n```\n",
    "basename": "schemas_discoverer.html"
  },
  "schemas_registry.html": {
    "subcategory": "EventBridge Schemas",
    "layout": "aws",
    "page_title": "AWS: aws_schemas_registry",
    "description": "Provides an EventBridge Custom Schema Registry resource.",
    "preview": "# Resource: aws_schemas_registry\n\nProvides an EventBridge Custom …",
    "content": "\n\n# Resource: aws_schemas_registry\n\nProvides an EventBridge Custom Schema Registry resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n## Example Usage\n\n```terraform\nresource \"aws_schemas_registry\" \"test\" {\n  name        = \"my_own_registry\"\n  description = \"A custom schema registry\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the custom event schema registry. Maximum of 64 characters consisting of lower case letters, upper case letters, 0-9, ., -, _.\n* `description` - (Optional) The description of the discoverer. Maximum of 256 characters.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the discoverer.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nEventBridge schema registries can be imported using the `name`, e.g.,\n\n```console\n$ terraform import aws_schemas_registry.test my_own_registry\n```\n",
    "basename": "schemas_registry.html"
  },
  "schemas_schema.html": {
    "subcategory": "EventBridge Schemas",
    "layout": "aws",
    "page_title": "AWS: aws_schemas_schema",
    "description": "Provides an EventBridge Schema resource.",
    "preview": "# Resource: aws_schemas_schema\n\nProvides an EventBridge Schema …",
    "content": "\n\n# Resource: aws_schemas_schema\n\nProvides an EventBridge Schema resource.\n\n~> **Note:** EventBridge was formerly known as CloudWatch Events. The functionality is identical.\n\n## Example Usage\n\n```terraform\nresource \"aws_schemas_registry\" \"test\" {\n  name = \"my_own_registry\"\n}\n\nresource \"aws_schemas_schema\" \"test\" {\n  name          = \"my_schema\"\n  registry_name = aws_schemas_registry.test.name\n  type          = \"OpenApi3\"\n  description   = \"The schema definition for my event\"\n\n  content = jsonencode({\n    \"openapi\" : \"3.0.0\",\n    \"info\" : {\n      \"version\" : \"1.0.0\",\n      \"title\" : \"Event\"\n    },\n    \"paths\" : {},\n    \"components\" : {\n      \"schemas\" : {\n        \"Event\" : {\n          \"type\" : \"object\",\n          \"properties\" : {\n            \"name\" : {\n              \"type\" : \"string\"\n            }\n          }\n        }\n      }\n    }\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the schema. Maximum of 385 characters consisting of lower case letters, upper case letters, ., -, _, @.\n* `content` - (Required) The schema specification. Must be a valid Open API 3.0 spec.\n* `registry_name` - (Required) The name of the registry in which this schema belongs.\n* `type` - (Required) The type of the schema. Valid values: `OpenApi3`.\n* `description` - (Optional) The description of the schema. Maximum of 256 characters.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the discoverer.\n* `last_modified` - The last modified date of the schema.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version` - The version of the schema.\n* `version_created_date` - The created date of the version of the schema.\n\n## Import\n\nEventBridge schema can be imported using the `name` and `registry_name`, e.g.,\n\n```console\n$ terraform import aws_schemas_schema.test name/registry\n```\n",
    "basename": "schemas_schema.html"
  },
  "secretsmanager_secret.html": {
    "subcategory": "Secrets Manager",
    "layout": "aws",
    "page_title": "AWS: aws_secretsmanager_secret",
    "description": "Provides a resource to manage AWS Secrets Manager secret metadata",
    "preview": "# Resource: aws_secretsmanager_secret\n\nProvides a resource to manage …",
    "content": "\n\n# Resource: aws_secretsmanager_secret\n\nProvides a resource to manage AWS Secrets Manager secret metadata. To manage secret rotation, see the [`aws_secretsmanager_secret_rotation` resource](/docs/providers/aws/r/secretsmanager_secret_rotation.html). To manage a secret value, see the [`aws_secretsmanager_secret_version` resource](/docs/providers/aws/r/secretsmanager_secret_version.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_secretsmanager_secret\" \"example\" {\n  name = \"example\"\n}\n```\n\n### Rotation Configuration\n\nTo enable automatic secret rotation, the Secrets Manager service requires usage of a Lambda function. The [Rotate Secrets section in the Secrets Manager User Guide](https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets_strategies.html) provides additional information about deploying a prebuilt Lambda functions for supported credential rotation (e.g., RDS) or deploying a custom Lambda function.\n\n~> **NOTE:** Configuring rotation causes the secret to rotate once as soon as you store the secret. Before you do this, you must ensure that all of your applications that use the credentials stored in the secret are updated to retrieve the secret from AWS Secrets Manager. The old credentials might no longer be usable after the initial rotation and any applications that you fail to update will break as soon as the old credentials are no longer valid.\n\n~> **NOTE:** If you cancel a rotation that is in progress (by removing the `rotation` configuration), it can leave the VersionStage labels in an unexpected state. Depending on what step of the rotation was in progress, you might need to remove the staging label AWSPENDING from the partially created version, specified by the SecretVersionId response value. You should also evaluate the partially rotated new version to see if it should be deleted, which you can do by removing all staging labels from the new version's VersionStage field.\n\n```terraform\nresource \"aws_secretsmanager_secret\" \"rotation-example\" {\n  name                = \"rotation-example\"\n  rotation_lambda_arn = aws_lambda_function.example.arn\n\n  rotation_rules {\n    automatically_after_days = 7\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) Description of the secret.\n* `kms_key_id` - (Optional) ARN or Id of the AWS KMS customer master key (CMK) to be used to encrypt the secret values in the versions stored in this secret. If you don't specify this value, then Secrets Manager defaults to using the AWS account's default CMK (the one named `aws/secretsmanager`). If the default KMS CMK with that name doesn't yet exist, then AWS Secrets Manager creates it for you automatically the first time.\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `name` - (Optional) Friendly name of the new secret. The secret name can consist of uppercase letters, lowercase letters, digits, and any of the following characters: `/_+=.@-` Conflicts with `name_prefix`.\n* `policy` - (Optional) Valid JSON document representing a [resource policy](https://docs.aws.amazon.com/secretsmanager/latest/userguide/auth-and-access_resource-based-policies.html). For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `recovery_window_in_days` - (Optional) Number of days that AWS Secrets Manager waits before it can delete the secret. This value can be `0` to force deletion without recovery or range from `7` to `30` days. The default value is `30`.\n* `replica` - (Optional) Configuration block to support secret replication. See details below.\n* `rotation_lambda_arn` - (Optional, **DEPRECATED**) ARN of the Lambda function that can rotate the secret. Use the `aws_secretsmanager_secret_rotation` resource to manage this configuration instead. As of version 2.67.0, removal of this configuration will no longer remove rotation due to supporting the new resource. Either import the new resource and remove the configuration or manually remove rotation.\n* `rotation_rules` - (Optional, **DEPRECATED**) Configuration block for the rotation configuration of this secret. Defined below. Use the `aws_secretsmanager_secret_rotation` resource to manage this configuration instead. As of version 2.67.0, removal of this configuration will no longer remove rotation due to supporting the new resource. Either import the new resource and remove the configuration or manually remove rotation.\n* `tags` - (Optional) Key-value map of user-defined tags that are attached to the secret. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### replica\n\n* `kms_key_id` - (Optional) ARN, Key ID, or Alias.\n* `region` - (Required) Region for replicating the secret.\n\n### rotation_rules\n\n* `automatically_after_days` - (Required) Specifies the number of days between automatic scheduled rotations of the secret.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ARN of the secret.\n* `arn` - ARN of the secret.\n* `rotation_enabled` - Whether automatic rotation is enabled for this secret.\n* `replica` - Attributes of a replica are described below.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n### replica\n\n* `last_accessed_date` - Date that you last accessed the secret in the Region.\n* `status` - Status can be `InProgress`, `Failed`, or `InSync`.\n* `status_message` - Message such as `Replication succeeded` or `Secret with this name already exists in this region`.\n\n## Import\n\n`aws_secretsmanager_secret` can be imported by using the secret Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_secretsmanager_secret.example arn:aws:secretsmanager:us-east-1:123456789012:secret:example-123456\n```\n",
    "basename": "secretsmanager_secret.html"
  },
  "secretsmanager_secret_policy.html": {
    "subcategory": "Secrets Manager",
    "layout": "aws",
    "page_title": "AWS: aws_secretsmanager_secret_policy",
    "description": "Provides a resource to manage AWS Secrets Manager secret policy",
    "preview": "# Resource: aws_secretsmanager_secret_policy\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_secretsmanager_secret_policy\n\nProvides a resource to manage AWS Secrets Manager secret policy.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_secretsmanager_secret\" \"example\" {\n  name = \"example\"\n}\n\nresource \"aws_secretsmanager_secret_policy\" \"example\" {\n  secret_arn = aws_secretsmanager_secret.example.arn\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n\t{\n\t  \"Sid\": \"EnableAllPermissions\",\n\t  \"Effect\": \"Allow\",\n\t  \"Principal\": {\n\t\t\"AWS\": \"*\"\n\t  },\n\t  \"Action\": \"secretsmanager:GetSecretValue\",\n\t  \"Resource\": \"*\"\n\t}\n  ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `secret_arn` - (Required) Secret ARN.\n* `policy` - (Required) A valid JSON document representing a [resource policy](https://docs.aws.amazon.com/secretsmanager/latest/userguide/auth-and-access_resource-based-policies.html). For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `block_public_policy` - (Optional) Makes an optional API call to Zelkova to validate the Resource Policy to prevent broad access to your secret.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the secret.\n\n## Import\n\n`aws_secretsmanager_secret_policy` can be imported by using the secret Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_secretsmanager_secret_policy.example arn:aws:secretsmanager:us-east-1:123456789012:secret:example-123456\n```\n",
    "basename": "secretsmanager_secret_policy.html"
  },
  "secretsmanager_secret_rotation.html": {
    "subcategory": "Secrets Manager",
    "layout": "aws",
    "page_title": "AWS: aws_secretsmanager_secret_rotation",
    "description": "Provides a resource to manage AWS Secrets Manager secret rotation",
    "preview": "# Resource: aws_secretsmanager_secret_rotation\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_secretsmanager_secret_rotation\n\nProvides a resource to manage AWS Secrets Manager secret rotation. To manage a secret, see the [`aws_secretsmanager_secret` resource](/docs/providers/aws/r/secretsmanager_secret.html). To manage a secret value, see the [`aws_secretsmanager_secret_version` resource](/docs/providers/aws/r/secretsmanager_secret_version.html).\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_secretsmanager_secret_rotation\" \"example\" {\n  secret_id           = aws_secretsmanager_secret.example.id\n  rotation_lambda_arn = aws_lambda_function.example.arn\n\n  rotation_rules {\n    automatically_after_days = 30\n  }\n}\n```\n\n### Rotation Configuration\n\nTo enable automatic secret rotation, the Secrets Manager service requires usage of a Lambda function. The [Rotate Secrets section in the Secrets Manager User Guide](https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets_strategies.html) provides additional information about deploying a prebuilt Lambda functions for supported credential rotation (e.g., RDS) or deploying a custom Lambda function.\n\n~> **NOTE:** Configuring rotation causes the secret to rotate once as soon as you enable rotation. Before you do this, you must ensure that all of your applications that use the credentials stored in the secret are updated to retrieve the secret from AWS Secrets Manager. The old credentials might no longer be usable after the initial rotation and any applications that you fail to update will break as soon as the old credentials are no longer valid.\n\n~> **NOTE:** If you cancel a rotation that is in progress (by removing the `rotation` configuration), it can leave the VersionStage labels in an unexpected state. Depending on what step of the rotation was in progress, you might need to remove the staging label AWSPENDING from the partially created version, specified by the SecretVersionId response value. You should also evaluate the partially rotated new version to see if it should be deleted, which you can do by removing all staging labels from the new version's VersionStage field.\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `secret_id` - (Required) Specifies the secret to which you want to add a new version. You can specify either the Amazon Resource Name (ARN) or the friendly name of the secret. The secret must already exist.\n* `rotation_lambda_arn` - (Required) Specifies the ARN of the Lambda function that can rotate the secret.\n* `rotation_rules` - (Required) A structure that defines the rotation configuration for this secret. Defined below.\n\n### rotation_rules\n\n* `automatically_after_days` - (Required) Specifies the number of days between automatic scheduled rotations of the secret.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the secret.\n* `arn` - Amazon Resource Name (ARN) of the secret.\n* `rotation_enabled` - Specifies whether automatic rotation is enabled for this secret.\n\n## Import\n\n`aws_secretsmanager_secret_rotation` can be imported by using the secret Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_secretsmanager_secret_rotation.example arn:aws:secretsmanager:us-east-1:123456789012:secret:example-123456\n```\n",
    "basename": "secretsmanager_secret_rotation.html"
  },
  "secretsmanager_secret_version.html": {
    "subcategory": "Secrets Manager",
    "layout": "aws",
    "page_title": "AWS: aws_secretsmanager_secret_version",
    "description": "Provides a resource to manage AWS Secrets Manager secret version including its secret value",
    "preview": "# Resource: aws_secretsmanager_secret_version\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_secretsmanager_secret_version\n\nProvides a resource to manage AWS Secrets Manager secret version including its secret value. To manage secret metadata, see the [`aws_secretsmanager_secret` resource](/docs/providers/aws/r/secretsmanager_secret.html).\n\n~> **NOTE:** If the `AWSCURRENT` staging label is present on this version during resource deletion, that label cannot be removed and will be skipped to prevent errors when fully deleting the secret. That label will leave this secret version active even after the resource is deleted from Terraform unless the secret itself is deleted. Move the `AWSCURRENT` staging label before or after deleting this resource from Terraform to fully trigger version deprecation if necessary.\n\n## Example Usage\n\n### Simple String Value\n\n```terraform\nresource \"aws_secretsmanager_secret_version\" \"example\" {\n  secret_id     = aws_secretsmanager_secret.example.id\n  secret_string = \"example-string-to-protect\"\n}\n```\n\n### Key-Value Pairs\n\nSecrets Manager also accepts key-value pairs in JSON.\n\n```terraform\n# The map here can come from other supported configurations\n# like locals, resource attribute, map() built-in, etc.\nvariable \"example\" {\n  default = {\n    key1 = \"value1\"\n    key2 = \"value2\"\n  }\n\n  type = map(string)\n}\n\nresource \"aws_secretsmanager_secret_version\" \"example\" {\n  secret_id     = aws_secretsmanager_secret.example.id\n  secret_string = jsonencode(var.example)\n}\n```\n\nReading key-value pairs from JSON back into a native Terraform map can be accomplished in Terraform 0.12 and later with the [`jsondecode()` function](https://www.terraform.io/docs/configuration/functions/jsondecode.html):\n\n```terraform\noutput \"example\" {\n  value = jsondecode(aws_secretsmanager_secret_version.example.secret_string)[\"key1\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `secret_id` - (Required) Specifies the secret to which you want to add a new version. You can specify either the Amazon Resource Name (ARN) or the friendly name of the secret. The secret must already exist.\n* `secret_string` - (Optional) Specifies text data that you want to encrypt and store in this version of the secret. This is required if secret_binary is not set.\n* `secret_binary` - (Optional) Specifies binary data that you want to encrypt and store in this version of the secret. This is required if secret_string is not set. Needs to be encoded to base64.\n* `version_stages` - (Optional) Specifies a list of staging labels that are attached to this version of the secret. A staging label must be unique to a single version of the secret. If you specify a staging label that's already associated with a different version of the same secret then that staging label is automatically removed from the other version and attached to this version. If you do not specify a value, then AWS Secrets Manager automatically moves the staging label `AWSCURRENT` to this new version on creation.\n\n~> **NOTE:** If `version_stages` is configured, you must include the `AWSCURRENT` staging label if this secret version is the only version or if the label is currently present on this secret version, otherwise Terraform will show a perpetual difference.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the secret.\n* `id` - A pipe delimited combination of secret ID and version ID.\n* `version_id` - The unique identifier of the version of the secret.\n\n## Import\n\n`aws_secretsmanager_secret_version` can be imported by using the secret ID and version ID, e.g.,\n\n```\n$ terraform import aws_secretsmanager_secret_version.example 'arn:aws:secretsmanager:us-east-1:123456789012:secret:example-123456|xxxxx-xxxxxxx-xxxxxxx-xxxxx'\n```\n",
    "basename": "secretsmanager_secret_version.html"
  },
  "security_group.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_security_group",
    "description": "Provides a security group resource.",
    "preview": "# Resource: aws_security_group\n\nProvides a security group resource.\n …",
    "content": "\n\n# Resource: aws_security_group\n\nProvides a security group resource.\n\n~> **NOTE on Security Groups and Security Group Rules:** Terraform currently\nprovides both a standalone [Security Group Rule resource](security_group_rule.html) (a single `ingress` or\n`egress` rule), and a Security Group resource with `ingress` and `egress` rules\ndefined in-line. At this time you cannot use a Security Group with in-line rules\nin conjunction with any Security Group Rule resources. Doing so will cause\na conflict of rule settings and will overwrite rules.\n\n~> **NOTE:** Referencing Security Groups across VPC peering has certain restrictions. More information is available in the [VPC Peering User Guide](https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html).\n\n~> **NOTE:** Due to [AWS Lambda improved VPC networking changes that began deploying in September 2019](https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/), security groups associated with Lambda Functions can take up to 45 minutes to successfully delete. Terraform AWS Provider version 2.31.0 and later automatically handles this increased timeout, however prior versions require setting the [customizable deletion timeout](#timeouts) to 45 minutes (`delete = \"45m\"`). AWS and HashiCorp are working together to reduce the amount of time required for resource deletion and updates can be tracked in this [GitHub issue](https://github.com/hashicorp/terraform-provider-aws/issues/10329).\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_security_group\" \"allow_tls\" {\n  name        = \"allow_tls\"\n  description = \"Allow TLS inbound traffic\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    description      = \"TLS from VPC\"\n    from_port        = 443\n    to_port          = 443\n    protocol         = \"tcp\"\n    cidr_blocks      = [aws_vpc.main.cidr_block]\n    ipv6_cidr_blocks = [aws_vpc.main.ipv6_cidr_block]\n  }\n\n  egress {\n    from_port        = 0\n    to_port          = 0\n    protocol         = \"-1\"\n    cidr_blocks      = [\"0.0.0.0/0\"]\n    ipv6_cidr_blocks = [\"::/0\"]\n  }\n\n  tags = {\n    Name = \"allow_tls\"\n  }\n}\n```\n\n~> **NOTE on Egress rules:** By default, AWS creates an `ALLOW ALL` egress rule when creating a new Security Group inside of a VPC. When creating a new Security Group inside a VPC, **Terraform will remove this default rule**, and require you specifically re-create it if you desire that rule. We feel this leads to fewer surprises in terms of controlling your egress rules. If you desire this rule to be in place, you can use this `egress` block:\n\n```terraform\nresource \"aws_security_group\" \"example\" {\n  # ... other configuration ...\n\n  egress {\n    from_port        = 0\n    to_port          = 0\n    protocol         = \"-1\"\n    cidr_blocks      = [\"0.0.0.0/0\"]\n    ipv6_cidr_blocks = [\"::/0\"]\n  }\n}\n```\n\n### Usage With Prefix List IDs\n\nPrefix Lists are either managed by AWS internally, or created by the customer using a\n[Prefix List resource](ec2_managed_prefix_list.html). Prefix Lists provided by\nAWS are associated with a prefix list name, or service name, that is linked to a specific region.\nPrefix list IDs are exported on VPC Endpoints, so you can use this format:\n\n```terraform\nresource \"aws_security_group\" \"example\" {\n  # ... other configuration ...\n\n  egress {\n    from_port       = 0\n    to_port         = 0\n    protocol        = \"-1\"\n    prefix_list_ids = [aws_vpc_endpoint.my_endpoint.prefix_list_id]\n  }\n}\n\nresource \"aws_vpc_endpoint\" \"my_endpoint\" {\n  # ... other configuration ...\n}\n```\n\nYou can also find a specific Prefix List using the `aws_prefix_list` data source.\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional, Forces new resource) Security group description. Defaults to `Managed by Terraform`. Cannot be `\"\"`. __NOTE__: This field maps to the AWS `GroupDescription` attribute, for which there is no Update API. If you'd like to classify your security groups in a way that can be updated, use `tags`.\n* `egress` - (Optional, VPC only) Configuration block for egress rules. Can be specified multiple times for each egress rule. Each egress block supports fields documented below. This argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n* `ingress` - (Optional) Configuration block for ingress rules. Can be specified multiple times for each ingress rule. Each ingress block supports fields documented below. This argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `name` - (Optional, Forces new resource) Name of the security group. If omitted, Terraform will assign a random, unique name.\n* `revoke_rules_on_delete` - (Optional) Instruct Terraform to revoke all of the Security Groups attached ingress and egress rules before deleting the rule itself. This is normally not needed, however certain AWS services such as Elastic Map Reduce may automatically add required rules to security groups used with the service, and those rules may contain a cyclic dependency that prevent the security groups from being destroyed without removing the dependency first. Default `false`.\n* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_id` - (Optional, Forces new resource) VPC ID.\n\n### ingress\n\nThis argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\nThe following arguments are required:\n\n* `from_port` - (Required) Start port (or ICMP type number if protocol is `icmp` or `icmpv6`).\n* `to_port` - (Required) End range port (or ICMP code if protocol is `icmp`).\n* `protocol` - (Required) Protocol. If you select a protocol of `-1` (semantically equivalent to `all`, which is not a valid value here), you must specify a `from_port` and `to_port` equal to 0.  The supported values are defined in the `IpProtocol` argument on the [IpPermission](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_IpPermission.html) API reference. This argument is normalized to a lowercase value to match the AWS API requirement when using with Terraform 0.12.x and above, please make sure that the value of the protocol is specified as lowercase when using with older version of Terraform to avoid an issue during upgrade.\n\nThe following arguments are optional:\n\n* `cidr_blocks` - (Optional) List of CIDR blocks.\n* `description` - (Optional) Description of this ingress rule.\n* `ipv6_cidr_blocks` - (Optional) List of IPv6 CIDR blocks.\n* `prefix_list_ids` - (Optional) List of Prefix List IDs.\n* `security_groups` - (Optional) List of security group Group Names if using EC2-Classic, or Group IDs if using a VPC.\n* `self` - (Optional) Whether the security group itself will be added as a source to this ingress rule.\n\n### egress\n\nThis argument is processed in [attribute-as-blocks mode](https://www.terraform.io/docs/configuration/attr-as-blocks.html).\n\nThe following arguments are required:\n\n* `from_port` - (Required) Start port (or ICMP type number if protocol is `icmp`)\n* `to_port` - (Required) End range port (or ICMP code if protocol is `icmp`).\n\nThe following arguments are optional:\n\n* `cidr_blocks` - (Optional) List of CIDR blocks.\n* `description` - (Optional) Description of this egress rule.\n* `ipv6_cidr_blocks` - (Optional) List of IPv6 CIDR blocks.\n* `prefix_list_ids` - (Optional) List of Prefix List IDs.\n* `protocol` - (Required) Protocol. If you select a protocol of `-1` (semantically equivalent to `all`, which is not a valid value here), you must specify a `from_port` and `to_port` equal to 0.  The supported values are defined in the `IpProtocol` argument in the [IpPermission](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_IpPermission.html) API reference. This argument is normalized to a lowercase value to match the AWS API requirement when using Terraform 0.12.x and above. Please make sure that the value of the protocol is specified as lowercase when used with older version of Terraform to avoid issues during upgrade.\n* `security_groups` - (Optional) List of security group Group Names if using EC2-Classic, or Group IDs if using a VPC.\n* `self` - (Optional) Whether the security group itself will be added as a source to this egress rule.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the security group.\n* `id` - ID of the security group.\n* `owner_id` - Owner ID.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_security_group` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `10m`) How long to wait for a security group to be created.\n- `delete` - (Default `15m`) How long to retry on `DependencyViolation` errors during security group deletion from lingering ENIs left by certain AWS services such as Elastic Load Balancing. NOTE: Lambda ENIs can take up to 45 minutes to delete, which is not affected by changing this customizable timeout (in version 2.31.0 and later of the Terraform AWS Provider) unless it is increased above 45 minutes.\n\n## Import\n\nSecurity Groups can be imported using the `security group id`, e.g.,\n\n```\n$ terraform import aws_security_group.elb_sg sg-903004f8\n```\n",
    "basename": "security_group.html"
  },
  "security_group_rule.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_security_group_rule",
    "description": "Provides an security group rule resource.",
    "preview": "# Resource: aws_security_group_rule\n\nProvides a security group rule …",
    "content": "\n\n# Resource: aws_security_group_rule\n\nProvides a security group rule resource. Represents a single `ingress` or\n`egress` group rule, which can be added to external Security Groups.\n\n~> **NOTE on Security Groups and Security Group Rules:** Terraform currently\nprovides both a standalone Security Group Rule resource (a single `ingress` or\n`egress` rule), and a [Security Group resource](security_group.html) with `ingress` and `egress` rules\ndefined in-line. At this time you cannot use a Security Group with in-line rules\nin conjunction with any Security Group Rule resources. Doing so will cause\na conflict of rule settings and will overwrite rules.\n\n~> **NOTE:** Setting `protocol = \"all\"` or `protocol = -1` with `from_port` and `to_port` will result in the EC2 API creating a security group rule with all ports open. This API behavior cannot be controlled by Terraform and may generate warnings in the future.\n\n~> **NOTE:** Referencing Security Groups across VPC peering has certain restrictions. More information is available in the [VPC Peering User Guide](https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html).\n\n## Example Usage\n\nBasic usage\n\n```terraform\nresource \"aws_security_group_rule\" \"example\" {\n  type              = \"ingress\"\n  from_port         = 0\n  to_port           = 65535\n  protocol          = \"tcp\"\n  cidr_blocks       = [aws_vpc.example.cidr_block]\n  ipv6_cidr_blocks  = [aws_vpc.example.ipv6_cidr_block]\n  security_group_id = \"sg-123456\"\n}\n```\n\n### Usage With Prefix List IDs\n\nPrefix Lists are either managed by AWS internally, or created by the customer using a\n[Managed Prefix List resource](ec2_managed_prefix_list.html). Prefix Lists provided by\nAWS are associated with a prefix list name, or service name, that is linked to a specific region.\n\nPrefix list IDs are exported on VPC Endpoints, so you can use this format:\n\n```terraform\nresource \"aws_security_group_rule\" \"allow_all\" {\n  type              = \"egress\"\n  to_port           = 0\n  protocol          = \"-1\"\n  prefix_list_ids   = [aws_vpc_endpoint.my_endpoint.prefix_list_id]\n  from_port         = 0\n  security_group_id = \"sg-123456\"\n}\n\n# ...\nresource \"aws_vpc_endpoint\" \"my_endpoint\" {\n  # ...\n}\n```\n\nYou can also find a specific Prefix List using the `aws_prefix_list` data source.\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `from_port` - (Required) Start port (or ICMP type number if protocol is \"icmp\" or \"icmpv6\").\n* `protocol` - (Required) Protocol. If not icmp, icmpv6, tcp, udp, or all use the [protocol number](https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml)\n* `security_group_id` - (Required) Security group to apply this rule to.\n* `to_port` - (Required) End port (or ICMP code if protocol is \"icmp\").\n* `type` - (Required) Type of rule being created. Valid options are `ingress` (inbound)\nor `egress` (outbound).\n\nThe following arguments are optional:\n\n* `cidr_blocks` - (Optional) List of CIDR blocks. Cannot be specified with `source_security_group_id` or `self`.\n* `description` - (Optional) Description of the rule.\n* `ipv6_cidr_blocks` - (Optional) List of IPv6 CIDR blocks. Cannot be specified with `source_security_group_id` or `self`.\n* `prefix_list_ids` - (Optional) List of Prefix List IDs.\n* `self` - (Optional) Whether the security group itself will be added as a source to this ingress rule. Cannot be specified with `cidr_blocks`, `ipv6_cidr_blocks`, or `source_security_group_id`.\n* `source_security_group_id` - (Optional) Security group id to allow access to/from, depending on the `type`. Cannot be specified with `cidr_blocks`, `ipv6_cidr_blocks`, or `self`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ID of the security group rule.\n\n## Import\n\nSecurity Group Rules can be imported using the `security_group_id`, `type`, `protocol`, `from_port`, `to_port`, and source(s)/destination(s) (e.g., `cidr_block`) separated by underscores (`_`). All parts are required.\n\nNot all rule permissions (e.g., not all of a rule's CIDR blocks) need to be imported for Terraform to manage rule permissions. However, importing some of a rule's permissions but not others, and then making changes to the rule will result in the creation of an additional rule to capture the updated permissions. Rule permissions that were not imported are left intact in the original rule.\n\nImport an ingress rule in security group `sg-6e616f6d69` for TCP port 8000 with an IPv4 destination CIDR of `10.0.3.0/24`:\n\n```console\n$ terraform import aws_security_group_rule.ingress sg-6e616f6d69_ingress_tcp_8000_8000_10.0.3.0/24\n```\n\nImport a rule with various IPv4 and IPv6 source CIDR blocks:\n\n```console\n$ terraform import aws_security_group_rule.ingress sg-4973616163_ingress_tcp_100_121_10.1.0.0/16_2001:db8::/48_10.2.0.0/16_2002:db8::/48\n```\n\nImport a rule, applicable to all ports, with a protocol other than TCP/UDP/ICMP/ICMPV6/ALL, e.g., Multicast Transport Protocol (MTP), using the IANA protocol number, e.g., 92.\n\n```console\n$ terraform import aws_security_group_rule.ingress sg-6777656e646f6c796e_ingress_92_0_65536_10.0.3.0/24_10.0.4.0/24\n```\n\nImport a default any/any egress rule to 0.0.0.0/0:\n\n```console\n$ terraform import aws_security_group_rule.default_egress sg-6777656e646f6c796e_egress_all_0_0_0.0.0.0/0\n```\n\nImport an egress rule with a prefix list ID destination:\n\n```console\n$ terraform import aws_security_group_rule.egress sg-62726f6479_egress_tcp_8000_8000_pl-6469726b\n```\n\nImport a rule applicable to all protocols and ports with a security group source:\n\n```console\n$ terraform import aws_security_group_rule.ingress_rule sg-7472697374616e_ingress_all_0_65536_sg-6176657279\n```\n\nImport a rule that has itself and an IPv6 CIDR block as sources:\n\n```console\n$ terraform import aws_security_group_rule.rule_name sg-656c65616e6f72_ingress_tcp_80_80_self_2001:db8::/48\n```\n",
    "basename": "security_group_rule.html"
  },
  "securityhub_account": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_account",
    "description": "Enables Security Hub for an AWS account.",
    "preview": "# Resource: aws_securityhub_account\n\nEnables Security Hub for this …",
    "content": "\n\n# Resource: aws_securityhub_account\n\nEnables Security Hub for this AWS account.\n\n~> **NOTE:** Destroying this resource will disable Security Hub for this AWS account.\n\n## Example Usage\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n```\n\n## Argument Reference\n\nThe resource does not support any arguments.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - AWS Account ID.\n\n## Import\n\nAn existing Security Hub enabled account can be imported using the AWS account ID, e.g.,\n\n```\n$ terraform import aws_securityhub_account.example 123456789012\n```\n",
    "basename": "securityhub_account"
  },
  "securityhub_action_target.html": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_action_target",
    "description": "Creates Security Hub custom action.",
    "preview": "# Resource: aws_securityhub_action_target\n\nCreates Security Hub …",
    "content": "\n\n# Resource: aws_securityhub_action_target\n\nCreates Security Hub custom action.\n\n## Example Usage\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_action_target\" \"example\" {\n  depends_on  = [aws_securityhub_account.example]\n  name        = \"Send notification to chat\"\n  identifier  = \"SendToChat\"\n  description = \"This is custom action sends selected findings to chat\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The description for the custom action target.\n* `identifier` - (Required) The ID for the custom action target.\n* `description` - (Required) The name of the custom action target.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the Security Hub custom action target.\n\n## Import\n\nSecurity Hub custom action can be imported using the action target ARN e.g.,\n\n```sh\n$ terraform import aws_securityhub_action_target.example arn:aws:securityhub:eu-west-1:312940875350:action/custom/a\n```\n",
    "basename": "securityhub_action_target.html"
  },
  "securityhub_finding_aggregator": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_finding_aggregator",
    "description": "Manages a Security Hub finding aggregator",
    "preview": "# Resource: aws_securityhub_finding_aggregator\n\nManages a Security …",
    "content": "\n\n# Resource: aws_securityhub_finding_aggregator\n\nManages a Security Hub finding aggregator. Security Hub needs to be enabled in a region in order for the aggregator to pull through findings.\n\n## Example Usage\n\n### All Regions Usage\n\nThe following example will enable the aggregator for every region.\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_finding_aggregator\" \"example\" {\n  linking_mode = \"ALL_REGIONS\"\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n### All Regions Except Specified Regions Usage\n\nThe following example will enable the aggregator for every region except those specified in `specified_regions`.\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_finding_aggregator\" \"example\" {\n  linking_mode      = \"ALL_REGIONS_EXCEPT_SPECIFIED\"\n  specified_regions = [\"eu-west-1\", \"eu-west-2\"]\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n### Specified Regions Usage\n\nThe following example will enable the aggregator for every region specified in `specified_regions`.\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_finding_aggregator\" \"example\" {\n  linking_mode      = \"SPECIFIED_REGIONS\"\n  specified_regions = [\"eu-west-1\", \"eu-west-2\"]\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n- `linking_mode` - (Required) Indicates whether to aggregate findings from all of the available Regions or from a specified list. The options are `ALL_REGIONS`, `ALL_REGIONS_EXCEPT_SPECIFIED` or `SPECIFIED_REGIONS`. When `ALL_REGIONS` or `ALL_REGIONS_EXCEPT_SPECIFIED` are used, Security Hub will automatically aggregate findings from new Regions as Security Hub supports them and you opt into them.\n- `specified_regions` - (Optional) List of regions to include or exclude (required if `linking_mode` is set to `ALL_REGIONS_EXCEPT_SPECIFIED` or `SPECIFIED_REGIONS`)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n- `arn` - Amazon Resource Name (ARN) of the Security Hub finding aggregator.\n\n## Import\n\nAn existing Security Hub finding aggregator can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_securityhub_finding_aggregator.example arn:aws:securityhub:eu-west-1:123456789098:finding-aggregator/abcd1234-abcd-1234-1234-abcdef123456\n```\n",
    "basename": "securityhub_finding_aggregator"
  },
  "securityhub_insight.html": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_insight",
    "description": "Provides a Security Hub custom insight resource.",
    "preview": "# Resource: aws_securityhub_insight\n\nProvides a Security Hub custom …",
    "content": "\n\n# Resource: aws_securityhub_insight\n\nProvides a Security Hub custom insight resource. See the [Managing custom insights section](https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-custom-insights.html) of the AWS User Guide for more information.\n\n## Example Usage\n\n### Filter by AWS account ID\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_insight\" \"example\" {\n  filters {\n    aws_account_id {\n      comparison = \"EQUALS\"\n      value      = \"1234567890\"\n    }\n\n    aws_account_id {\n      comparison = \"EQUALS\"\n      value      = \"09876543210\"\n    }\n  }\n\n  group_by_attribute = \"AwsAccountId\"\n\n  name = \"example-insight\"\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n### Filter by date range\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_insight\" \"example\" {\n  filters {\n    created_at {\n      date_range {\n        unit  = \"DAYS\"\n        value = 5\n      }\n    }\n  }\n\n  group_by_attribute = \"CreatedAt\"\n\n  name = \"example-insight\"\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n### Filter by destination IPv4 address\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_insight\" \"example\" {\n  filters {\n    network_destination_ipv4 {\n      cidr = \"10.0.0.0/16\"\n    }\n  }\n\n  group_by_attribute = \"NetworkDestinationIpV4\"\n\n  name = \"example-insight\"\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n### Filter by finding's confidence\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_insight\" \"example\" {\n  filters {\n    confidence {\n      gte = \"80\"\n    }\n  }\n\n  group_by_attribute = \"Confidence\"\n\n  name = \"example-insight\"\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n### Filter by resource tags\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_insight\" \"example\" {\n  filters {\n    resource_tags {\n      comparison = \"EQUALS\"\n      key        = \"Environment\"\n      value      = \"Production\"\n    }\n  }\n\n  group_by_attribute = \"ResourceTags\"\n\n  name = \"example-insight\"\n\n  depends_on = [aws_securityhub_account.example]\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `filters` - (Required) A configuration block including one or more (up to 10 distinct) attributes used to filter the findings included in the insight. The insight only includes findings that match criteria defined in the filters. See [filters](#filters) below for more details.\n* `group_by_attribute` - (Required) The attribute used to group the findings for the insight e.g., if an insight is grouped by `ResourceId`, then the insight produces a list of resource identifiers.\n* `name` - (Required) The name of the custom insight.\n\n### filters\n\nThe `filters` configuration block supports the following arguments:\n\n~> **NOTE:** For each argument below, up to 20 can be provided.\n\n* `aws_account_id` - (Optional) AWS account ID that a finding is generated in. See [String_Filter](#string-filter-argument-reference) below for more details.\n* `company_name` - (Optional) The name of the findings provider (company) that owns the solution (product) that generates findings. See [String_Filter](#string-filter-argument-reference) below for more details.\n* `compliance_status` - (Optional) Exclusive to findings that are generated as the result of a check run against a specific rule in a supported standard, such as CIS AWS Foundations. Contains security standard-related finding details. See [String Filter](#string-filter-argument-reference) below for more details.\n* `confidence` - (Optional) A finding's confidence. Confidence is defined as the likelihood that a finding accurately identifies the behavior or issue that it was intended to identify. Confidence is scored on a 0-100 basis using a ratio scale, where 0 means zero percent confidence and 100 means 100 percent confidence. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `created_at` - (Optional) An ISO8601-formatted timestamp that indicates when the security-findings provider captured the potential security issue that a finding captured. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `criticality` - (Optional) The level of importance assigned to the resources associated with the finding. A score of 0 means that the underlying resources have no criticality, and a score of 100 is reserved for the most critical resources. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `description` - (Optional) A finding's description. See [String Filter](#string-filter-argument-reference) below for more details.\n* `finding_provider_fields_confidence` - (Optional) The finding provider value for the finding confidence. Confidence is defined as the likelihood that a finding accurately identifies the behavior or issue that it was intended to identify. Confidence is scored on a 0-100 basis using a ratio scale, where 0 means zero percent confidence and 100 means 100 percent confidence. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `finding_provider_fields_criticality` - (Optional) The finding provider value for the level of importance assigned to the resources associated with the findings. A score of 0 means that the underlying resources have no criticality, and a score of 100 is reserved for the most critical resources. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `finding_provider_fields_related_findings_id` - (Optional) The finding identifier of a related finding that is identified by the finding provider. See [String Filter](#string-filter-argument-reference) below for more details.\n* `finding_provider_fields_related_findings_product_arn` - (Optional) The ARN of the solution that generated a related finding that is identified by the finding provider. See [String Filter](#string-filter-argument-reference) below for more details.\n* `finding_provider_fields_severity_label` - (Optional) The finding provider value for the severity label. See [String Filter](#string-filter-argument-reference) below for more details.\n* `finding_provider_fields_severity_original` - (Optional) The finding provider's original value for the severity. See [String Filter](#string-filter-argument-reference) below for more details.\n* `finding_provider_fields_types` - (Optional) One or more finding types that the finding provider assigned to the finding. Uses the format of `namespace/category/classifier` that classify a finding. Valid namespace values include: `Software and Configuration Checks`, `TTPs`, `Effects`, `Unusual Behaviors`, and `Sensitive Data Identifications`. See [String Filter](#string-filter-argument-reference) below for more details.\n* `first_observed_at` - (Optional) An ISO8601-formatted timestamp that indicates when the security-findings provider first observed the potential security issue that a finding captured. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `generator_id` - (Optional) The identifier for the solution-specific component (a discrete unit of logic) that generated a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `id` - (Optional) The security findings provider-specific identifier for a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `keyword` - (Optional) A keyword for a finding. See [Keyword Filter](#keyword-filter-argument-reference) below for more details.\n* `last_observed_at` - (Optional) An ISO8601-formatted timestamp that indicates when the security-findings provider most recently observed the potential security issue that a finding captured. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `malware_name` - (Optional) The name of the malware that was observed. See [String Filter](#string-filter-argument-reference) below for more details.\n* `malware_path` - (Optional) The filesystem path of the malware that was observed. See [String Filter](#string-filter-argument-reference) below for more details.\n* `malware_state` - (Optional) The state of the malware that was observed. See [String Filter](#string-filter-argument-reference) below for more details.\n* `malware_type` - (Optional) The type of the malware that was observed. See [String Filter](#string-filter-argument-reference) below for more details.\n* `network_destination_domain` - (Optional) The destination domain of network-related information about a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `network_destination_ipv4` - (Optional) The destination IPv4 address of network-related information about a finding. See [Ip Filter](#ip-filter-argument-reference) below for more details.\n* `network_destination_ipv6` - (Optional) The destination IPv6 address of network-related information about a finding. See [Ip Filter](#ip-filter-argument-reference) below for more details.\n* `network_destination_port` - (Optional) The destination port of network-related information about a finding. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `network_direction` - (Optional) Indicates the direction of network traffic associated with a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `network_protocol` - (Optional) The protocol of network-related information about a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `network_source_domain` - (Optional) The source domain of network-related information about a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `network_source_ipv4` - (Optional) The source IPv4 address of network-related information about a finding. See [Ip Filter](#ip-filter-argument-reference) below for more details.\n* `network_source_ipv6` - (Optional) The source IPv6 address of network-related information about a finding. See [Ip Filter](#ip-filter-argument-reference) below for more details.\n* `network_source_mac` - (Optional) The source media access control (MAC) address of network-related information about a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `network_source_port` - (Optional) The source port of network-related information about a finding. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `note_text` - (Optional) The text of a note. See [String Filter](#string-filter-argument-reference) below for more details.\n* `note_updated_at` - (Optional) The timestamp of when the note was updated. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `note_updated_by` - (Optional) The principal that created a note. See [String Filter](#string-filter-argument-reference) below for more details.\n* `process_launched_at` - (Optional) The date/time that the process was launched. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `process_name` - (Optional) The name of the process. See [String Filter](#string-filter-argument-reference) below for more details.\n* `process_parent_pid` - (Optional) The parent process ID. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `process_path` - (Optional) The path to the process executable. See [String Filter](#string-filter-argument-reference) below for more details.\n* `process_pid` - (Optional) The process ID. See [Number Filter](#number-filter-argument-reference) below for more details.\n* `process_terminated_at` - (Optional) The date/time that the process was terminated. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `product_arn` - (Optional) The ARN generated by Security Hub that uniquely identifies a third-party company (security findings provider) after this provider's product (solution that generates findings) is registered with Security Hub. See [String Filter](#string-filter-argument-reference) below for more details.\n* `product_fields` - (Optional) A data type where security-findings providers can include additional solution-specific details that aren't part of the defined `AwsSecurityFinding` format. See [Map Filter](#map-filter-argument-reference) below for more details.\n* `product_name` - (Optional) The name of the solution (product) that generates findings. See [String Filter](#string-filter-argument-reference) below for more details.\n* `recommendation_text` - (Optional) The recommendation of what to do about the issue described in a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `record_state` - (Optional) The updated record state for the finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `related_findings_id` - (Optional) The solution-generated identifier for a related finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `related_findings_product_arn` - (Optional) The ARN of the solution that generated a related finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_iam_instance_profile_arn` - (Optional) The IAM profile ARN of the instance. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_image_id` - (Optional) The Amazon Machine Image (AMI) ID of the instance. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_ipv4_addresses` - (Optional) The IPv4 addresses associated with the instance. See [Ip Filter](#ip-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_ipv6_addresses` - (Optional) The IPv6 addresses associated with the instance. See [Ip Filter](#ip-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_key_name` - (Optional) The key name associated with the instance. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_launched_at` - (Optional) The date and time the instance was launched. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_subnet_id` - (Optional) The identifier of the subnet that the instance was launched in. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_type` - (Optional) The instance type of the instance. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_ec2_instance_vpc_id` - (Optional) The identifier of the VPC that the instance was launched in. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_iam_access_key_created_at` - (Optional) The creation date/time of the IAM access key related to a finding. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `resource_aws_iam_access_key_status` - (Optional) The status of the IAM access key related to a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_iam_access_key_user_name` - (Optional) The user associated with the IAM access key related to a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_s3_bucket_owner_id` - (Optional) The canonical user ID of the owner of the S3 bucket. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_aws_s3_bucket_owner_name` - (Optional) The display name of the owner of the S3 bucket. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_container_image_id` - (Optional) The identifier of the image related to a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_container_image_name` - (Optional) The name of the image related to a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_container_launched_at` - (Optional) The date/time that the container was started. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `resource_container_name` - (Optional) The name of the container related to a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_details_other` - (Optional) The details of a resource that doesn't have a specific subfield for the resource type defined. See [Map Filter](#map-filter-argument-reference) below for more details.\n* `resource_id` - (Optional) The canonical identifier for the given resource type. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_partition` - (Optional) The canonical AWS partition name that the Region is assigned to. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_region` - (Optional) The canonical AWS external Region name where this resource is located. See [String Filter](#string-filter-argument-reference) below for more details.\n* `resource_tags` - (Optional) A list of AWS tags associated with a resource at the time the finding was processed. See [Map Filter](#map-filter-argument-reference) below for more details.\n* `resource_type` - (Optional) Specifies the type of the resource that details are provided for. See [String Filter](#string-filter-argument-reference) below for more details.\n* `severity_label` - (Optional) The label of a finding's severity. See [String Filter](#string-filter-argument-reference) below for more details.\n* `source_url` - (Optional) A URL that links to a page about the current finding in the security-findings provider's solution. See [String Filter](#string-filter-argument-reference) below for more details.\n* `threat_intel_indicator_category` - (Optional) The category of a threat intelligence indicator. See [String Filter](#string-filter-argument-reference) below for more details.\n* `threat_intel_indicator_last_observed_at` - (Optional) The date/time of the last observation of a threat intelligence indicator. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `threat_intel_indicator_source` - (Optional) The source of the threat intelligence. See [String Filter](#string-filter-argument-reference) below for more details.\n* `threat_intel_indicator_source_url` - (Optional) The URL for more details from the source of the threat intelligence. See [String Filter](#string-filter-argument-reference) below for more details.\n* `threat_intel_indicator_type` - (Optional) The type of a threat intelligence indicator. See [String Filter](#string-filter-argument-reference) below for more details.\n* `threat_intel_indicator_value` - (Optional) The value of a threat intelligence indicator. See [String Filter](#string-filter-argument-reference) below for more details.\n* `title` - (Optional) A finding's title. See [String Filter](#string-filter-argument-reference) below for more details.\n* `type` - (Optional) A finding type in the format of `namespace/category/classifier` that classifies a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `updated_at` - (Optional) An ISO8601-formatted timestamp that indicates when the security-findings provider last updated the finding record. See [Date Filter](#date-filter-argument-reference) below for more details.\n* `user_defined_values` - (Optional) A list of name/value string pairs associated with the finding. These are custom, user-defined fields added to a finding. See [Map Filter](#map-filter-argument-reference) below for more details.\n* `verification_state` - (Optional) The veracity of a finding. See [String Filter](#string-filter-argument-reference) below for more details.\n* `workflow_status` - (Optional) The status of the investigation into a finding. See [Workflow Status Filter](#workflow-status-filter-argument-reference) below for more details.\n\n### Date Filter Argument reference\n\nThe date filter configuration block supports the following arguments:\n\n* `date_range` - (Optional) A configuration block of the date range for the date filter. See [date_range](#date_range-argument-reference) below for more details.\n* `end` - (Optional) An end date for the date filter. Required with `start` if `date_range` is not specified.\n* `start` - (Optional) A start date for the date filter. Required with `end` if `date_range` is not specified.\n\n### date_range Argument reference\n\nThe `date_range` configuration block supports the following arguments:\n\n* `unit` - (Required) A date range unit for the date filter. Valid values: `DAYS`.\n* `value` - (Required) A date range value for the date filter, provided as an Integer.\n\n### Ip Filter Argument Reference\n\nThe Ip filter configuration block supports the following arguments:\n\n* `cidr` - (Required) A finding's CIDR value.\n\n### Keyword Filter Argument Reference\n\nThe keyword filter configuration block supports the following arguments:\n\n* `value` - (Required) A value for the keyword.\n\n### Map Filter Argument reference\n\nThe map filter configuration block supports the following arguments:\n\n* `comparison` - (Required) The condition to apply to a string value when querying for findings. Valid values include: `EQUALS` and `NOT_EQUALS`.\n* `key` - (Required) The key of the map filter. For example, for `ResourceTags`, `Key` identifies the name of the tag. For `UserDefinedFields`, `Key` is the name of the field.\n* `value` - (Required) The value for the key in the map filter. Filter values are case sensitive. For example, one of the values for a tag called `Department` might be `Security`. If you provide `security` as the filter value, then there is no match.\n\n### Number Filter Argument reference\n\nThe number filter configuration block supports the following arguments:\n\n~> **NOTE:** Only one of `eg`, `gte`, or `lte` must be specified.\n\n* `eq` - (Optional) The equal-to condition to be applied to a single field when querying for findings, provided as a String.\n* `gte` - (Optional) The greater-than-equal condition to be applied to a single field when querying for findings, provided as a String.\n* `lte` - (Optional) The less-than-equal condition to be applied to a single field when querying for findings, provided as a String.\n\n### String Filter Argument reference\n\nThe string filter configuration block supports the following arguments:\n\n* `comparison` - (Required) The condition to apply to a string value when querying for findings. Valid values include: `EQUALS`, `PREFIX`, `NOT_EQUALS`, `PREFIX_NOT_EQUALS`.\n* `value` - (Required) The string filter value. Filter values are case sensitive.\n\n### Workflow Status Filter Argument reference\n\nThe workflow status filter configuration block supports the following arguments:\n\n* `comparison` - (Required) The condition to apply to a string value when querying for findings. Valid values include: `EQUALS`, `PREFIX`, `NOT_EQUALS`, `PREFIX_NOT_EQUALS`.\n* `value` - (Required) The string filter value. Valid values include: `NEW`, `NOTIFIED`, `SUPPRESSED`, and `RESOLVED`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - ARN of the insight.\n* `arn` - ARN of the insight.\n\n## Import\n\nSecurity Hub insights can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_securityhub_insight.example arn:aws:securityhub:us-west-2:1234567890:insight/1234567890/custom/91299ed7-abd0-4e44-a858-d0b15e37141a\n```\n",
    "basename": "securityhub_insight.html"
  },
  "securityhub_invite_accepter": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_invite_accepter",
    "description": "Accepts a Security Hub invitation.",
    "preview": "# Resource: aws_securityhub_invite_accepter\n\n-> **Note:** AWS …",
    "content": "\n\n# Resource: aws_securityhub_invite_accepter\n\n-> **Note:** AWS accounts can only be associated with a single Security Hub master account. Destroying this resource will disassociate the member account from the master account.\n\nAccepts a Security Hub invitation.\n\n## Example Usage\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_member\" \"example\" {\n  account_id = \"123456789012\"\n  email      = \"example@example.com\"\n  invite     = true\n}\n\nresource \"aws_securityhub_account\" \"invitee\" {\n  provider = \"aws.invitee\"\n}\n\nresource \"aws_securityhub_invite_accepter\" \"invitee\" {\n  provider   = \"aws.invitee\"\n  depends_on = [aws_securityhub_account.invitee]\n  master_id  = aws_securityhub_member.example.master_id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `master_id` - (Required) The account ID of the master Security Hub account whose invitation you're accepting.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `invitation_id` - The ID of the invitation.\n\n## Import\n\nSecurity Hub invite acceptance can be imported using the account ID, e.g.,\n\n```\n$ terraform import aws_securityhub_invite_accepter.example 123456789012\n```\n",
    "basename": "securityhub_invite_accepter"
  },
  "securityhub_member": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_member",
    "description": "Provides a Security Hub member resource.",
    "preview": "# Resource: aws_securityhub_member\n\nProvides a Security Hub member …",
    "content": "\n\n# Resource: aws_securityhub_member\n\nProvides a Security Hub member resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_member\" \"example\" {\n  depends_on = [aws_securityhub_account.example]\n  account_id = \"123456789012\"\n  email      = \"example@example.com\"\n  invite     = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `account_id` - (Required) The ID of the member AWS account.\n* `email` - (Required) The email of the member AWS account.\n* `invite` - (Optional) Boolean whether to invite the account to Security Hub as a member. Defaults to `false`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the member AWS account (matches `account_id`).\n* `master_id` - The ID of the master Security Hub AWS account.\n* `member_status` - The status of the member account relationship.\n\n## Import\n\nSecurity Hub members can be imported using their account ID, e.g.,\n\n```\n$ terraform import aws_securityhub_member.example 123456789012\n```\n",
    "basename": "securityhub_member"
  },
  "securityhub_organization_admin_account.html": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_organization_admin_account",
    "description": "Manages a Security Hub administrator account for an organization.",
    "preview": "# Resource: aws_securityhub_organization_admin_account\n\nManages a …",
    "content": "\n\n# Resource: aws_securityhub_organization_admin_account\n\nManages a Security Hub administrator account for an organization. The AWS account utilizing this resource must be an Organizations primary account. More information about Organizations support in Security Hub can be found in the [Security Hub User Guide](https://docs.aws.amazon.com/securityhub/latest/userguide/designate-orgs-admin-account.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"securityhub.amazonaws.com\"]\n  feature_set                   = \"ALL\"\n}\n\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_organization_admin_account\" \"example\" {\n  depends_on = [aws_organizations_organization.example]\n\n  admin_account_id = \"123456789012\"\n}\n\n# Auto enable security hub in organization member accounts\nresource \"aws_securityhub_organization_configuration\" \"example\" {\n  auto_enable = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `admin_account_id` - (Required) The AWS account identifier of the account to designate as the Security Hub administrator account.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - AWS account identifier.\n\n## Import\n\nSecurity Hub Organization Admin Accounts can be imported using the AWS account ID, e.g.,\n\n```\n$ terraform import aws_securityhub_organization_admin_account.example 123456789012\n```\n",
    "basename": "securityhub_organization_admin_account.html"
  },
  "securityhub_organization_configuration": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_organization_configuration",
    "description": "Manages the Security Hub Organization Configuration",
    "preview": "# Resource: aws_securityhub_organization_configuration\n\nManages the …",
    "content": "\n\n# Resource: aws_securityhub_organization_configuration\n\nManages the Security Hub Organization Configuration.\n\n~> **NOTE:** This resource requires an [`aws_securityhub_organization_admin_account`](/docs/providers/aws/r/securityhub_organization_admin_account.html) to be configured (not necessarily with Terraform). More information about managing Security Hub in an organization can be found in the [Managing administrator and member accounts](https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-accounts.html) documentation\n\n~> **NOTE:** This is an advanced Terraform resource. Terraform will automatically assume management of the Security Hub Organization Configuration without import and perform no actions on removal from the Terraform configuration.\n\n## Example Usage\n\n```terraform\nresource \"aws_organizations_organization\" \"example\" {\n  aws_service_access_principals = [\"securityhub.amazonaws.com\"]\n  feature_set                   = \"ALL\"\n}\n\nresource \"aws_securityhub_organization_admin_account\" \"example\" {\n  depends_on = [aws_organizations_organization.example]\n\n  admin_account_id = \"123456789012\"\n}\n\nresource \"aws_securityhub_organization_configuration\" \"example\" {\n  auto_enable = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `auto_enable` - (Required) Whether to automatically enable Security Hub for new accounts in the organization.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - AWS Account ID.\n\n## Import\n\nAn existing Security Hub enabled account can be imported using the AWS account ID, e.g.,\n\n```\n$ terraform import aws_securityhub_organization_configuration.example 123456789012\n```\n",
    "basename": "securityhub_organization_configuration"
  },
  "securityhub_product_subscription": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_product_subscription",
    "description": "Subscribes to a Security Hub product.",
    "preview": "# Resource: aws_securityhub_product_subscription\n\nSubscribes to a …",
    "content": "\n\n# Resource: aws_securityhub_product_subscription\n\nSubscribes to a Security Hub product.\n\n## Example Usage\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_securityhub_product_subscription\" \"example\" {\n  depends_on  = [aws_securityhub_account.example]\n  product_arn = \"arn:aws:securityhub:${data.aws_region.current.name}:733251395267:product/alertlogic/althreatmanagement\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `product_arn` - (Required) The ARN of the product that generates findings that you want to import into Security Hub - see below.\n\nCurrently available products (remember to replace `${var.region}` as appropriate):\n\n* `arn:aws:securityhub:${var.region}::product/aws/guardduty`\n* `arn:aws:securityhub:${var.region}::product/aws/inspector`\n* `arn:aws:securityhub:${var.region}::product/aws/macie`\n* `arn:aws:securityhub:${var.region}:733251395267:product/alertlogic/althreatmanagement`\n* `arn:aws:securityhub:${var.region}:679703615338:product/armordefense/armoranywhere`\n* `arn:aws:securityhub:${var.region}:151784055945:product/barracuda/cloudsecurityguardian`\n* `arn:aws:securityhub:${var.region}:758245563457:product/checkpoint/cloudguard-iaas`\n* `arn:aws:securityhub:${var.region}:634729597623:product/checkpoint/dome9-arc`\n* `arn:aws:securityhub:${var.region}:517716713836:product/crowdstrike/crowdstrike-falcon`\n* `arn:aws:securityhub:${var.region}:749430749651:product/cyberark/cyberark-pta`\n* `arn:aws:securityhub:${var.region}:250871914685:product/f5networks/f5-advanced-waf`\n* `arn:aws:securityhub:${var.region}:123073262904:product/fortinet/fortigate`\n* `arn:aws:securityhub:${var.region}:324264561773:product/guardicore/aws-infection-monkey`\n* `arn:aws:securityhub:${var.region}:324264561773:product/guardicore/guardicore`\n* `arn:aws:securityhub:${var.region}:949680696695:product/ibm/qradar-siem`\n* `arn:aws:securityhub:${var.region}:955745153808:product/imperva/imperva-attack-analytics`\n* `arn:aws:securityhub:${var.region}:297986523463:product/mcafee-skyhigh/mcafee-mvision-cloud-aws`\n* `arn:aws:securityhub:${var.region}:188619942792:product/paloaltonetworks/redlock`\n* `arn:aws:securityhub:${var.region}:122442690527:product/paloaltonetworks/vm-series`\n* `arn:aws:securityhub:${var.region}:805950163170:product/qualys/qualys-pc`\n* `arn:aws:securityhub:${var.region}:805950163170:product/qualys/qualys-vm`\n* `arn:aws:securityhub:${var.region}:336818582268:product/rapid7/insightvm`\n* `arn:aws:securityhub:${var.region}:062897671886:product/sophos/sophos-server-protection`\n* `arn:aws:securityhub:${var.region}:112543817624:product/splunk/splunk-enterprise`\n* `arn:aws:securityhub:${var.region}:112543817624:product/splunk/splunk-phantom`\n* `arn:aws:securityhub:${var.region}:956882708938:product/sumologicinc/sumologic-mda`\n* `arn:aws:securityhub:${var.region}:754237914691:product/symantec-corp/symantec-cwp`\n* `arn:aws:securityhub:${var.region}:422820575223:product/tenable/tenable-io`\n* `arn:aws:securityhub:${var.region}:679593333241:product/trend-micro/deep-security`\n* `arn:aws:securityhub:${var.region}:453761072151:product/turbot/turbot`\n* `arn:aws:securityhub:${var.region}:496947949261:product/twistlock/twistlock-enterprise`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of a resource that represents your subscription to the product that generates the findings that you want to import into Security Hub.\n\n## Import\n\nSecurity Hub product subscriptions can be imported in the form `product_arn,arn`, e.g.,\n\n```sh\n$ terraform import aws_securityhub_product_subscription.example arn:aws:securityhub:eu-west-1:733251395267:product/alertlogic/althreatmanagement,arn:aws:securityhub:eu-west-1:123456789012:product-subscription/alertlogic/althreatmanagement\n```\n",
    "basename": "securityhub_product_subscription"
  },
  "securityhub_standards_control": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_standards_control",
    "description": "Enable/disable Security Hub standards controls.",
    "preview": "# Resource: aws_securityhub_standards_control\n\nDisable/enable …",
    "content": "\n\n# Resource: aws_securityhub_standards_control\n\nDisable/enable Security Hub standards control in the current region.\n\nThe `aws_securityhub_standards_control` behaves differently from normal resources, in that\nTerraform does not _create_ this resource, but instead \"adopts\" it\ninto management. When you _delete_ this resource configuration, Terraform \"abandons\" resource as is and just removes it from the state.\n\n## Example Usage\n\n```terraform\nresource aws_securityhub_account example {}\n\nresource aws_securityhub_standards_subscription cis_aws_foundations_benchmark {\n  standards_arn = \"arn:aws:securityhub:::ruleset/cis-aws-foundations-benchmark/v/1.2.0\"\n  depends_on    = [aws_securityhub_account.example]\n}\n\nresource aws_securityhub_standards_control ensure_iam_password_policy_prevents_password_reuse {\n  standards_control_arn = \"arn:aws:securityhub:us-east-1:111111111111:control/cis-aws-foundations-benchmark/v/1.2.0/1.10\"\n  control_status        = \"DISABLED\"\n  disabled_reason       = \"We handle password policies within Okta\"\n\n  depends_on = [aws_securityhub_standards_subscription.cis_aws_foundations_benchmark]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `standards_control_arn` - (Required) The standards control ARN.\n* `control_status` – (Required) The control status could be `ENABLED` or `DISABLED`. You have to specify `disabled_reason` argument for `DISABLED` control status.\n* `disabled_reason` – (Optional) A description of the reason why you are disabling a security standard control. If you specify this attribute, `control_status` will be set to `DISABLED` automatically.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The standard control ARN.\n* `control_id` – The identifier of the security standard control.\n* `control_status_updated_at` – The date and time that the status of the security standard control was most recently updated.\n* `description` – The standard control longer description. Provides information about what the control is checking for.\n* `related_requirements` – The list of requirements that are related to this control.\n* `remediation_url` – A link to remediation information for the control in the Security Hub user documentation.\n* `severity_rating` – The severity of findings generated from this security standard control.\n* `title` – The standard control title.\n",
    "basename": "securityhub_standards_control"
  },
  "securityhub_standards_subscription": {
    "subcategory": "Security Hub",
    "layout": "aws",
    "page_title": "AWS: aws_securityhub_standards_subscription",
    "description": "Subscribes to a Security Hub standard.",
    "preview": "# Resource: aws_securityhub_standards_subscription\n\nSubscribes to a …",
    "content": "\n\n# Resource: aws_securityhub_standards_subscription\n\nSubscribes to a Security Hub standard.\n\n## Example Usage\n\n```terraform\nresource \"aws_securityhub_account\" \"example\" {}\n\nresource \"aws_securityhub_standards_subscription\" \"cis\" {\n  depends_on    = [aws_securityhub_account.example]\n  standards_arn = \"arn:aws:securityhub:::ruleset/cis-aws-foundations-benchmark/v/1.2.0\"\n}\n\nresource \"aws_securityhub_standards_subscription\" \"pci_321\" {\n  depends_on    = [aws_securityhub_account.example]\n  standards_arn = \"arn:aws:securityhub:us-east-1::standards/pci-dss/v/3.2.1\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `standards_arn` - (Required) The ARN of a standard - see below.\n\nCurrently available standards:\n\n| Name                                     | ARN                                                                                         |\n|------------------------------------------|---------------------------------------------------------------------------------------------|\n| AWS Foundational Security Best Practices | `arn:aws:securityhub:us-east-1::standards/aws-foundational-security-best-practices/v/1.0.0` |\n| CIS AWS Foundations                      | `arn:aws:securityhub:::ruleset/cis-aws-foundations-benchmark/v/1.2.0`                       |\n| PCI DSS                                  | `arn:aws:securityhub:us-east-1::standards/pci-dss/v/3.2.1`                                  |\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of a resource that represents your subscription to a supported standard.\n\n## Import\n\nSecurity Hub standards subscriptions can be imported using the standards subscription ARN, e.g.,\n\n```\n$ terraform import aws_securityhub_standards_subscription.cis arn:aws:securityhub:eu-west-1:123456789012:subscription/cis-aws-foundations-benchmark/v/1.2.0\n$ terraform import aws_securityhub_standards_subscription.pci_321 arn:aws:securityhub:eu-west-1:123456789012:subscription/pci-dss/v/3.2.1\n```\n",
    "basename": "securityhub_standards_subscription"
  },
  "serverlessapplicationrepository_cloudformation_stack.html": {
    "subcategory": "Serverless Application Repository",
    "layout": "aws",
    "page_title": "AWS: aws_serverlessapplicationrepository_cloudformation_stack",
    "description": "Deploys an Application CloudFormation Stack from the Serverless Application Repository.",
    "preview": "# Resource: aws_serverlessapplicationrepository_cloudformation_stack …",
    "content": "\n\n# Resource: aws_serverlessapplicationrepository_cloudformation_stack\n\nDeploys an Application CloudFormation Stack from the Serverless Application Repository.\n\n## Example Usage\n\n```terraform\nresource \"aws_serverlessapplicationrepository_cloudformation_stack\" \"postgres-rotator\" {\n  name           = \"postgres-rotator\"\n  application_id = \"arn:aws:serverlessrepo:us-east-1:297356227824:applications/SecretsManagerRDSPostgreSQLRotationSingleUser\"\n  capabilities = [\n    \"CAPABILITY_IAM\",\n    \"CAPABILITY_RESOURCE_POLICY\",\n  ]\n  parameters = {\n    functionName = \"func-postgres-rotator\"\n    endpoint     = \"secretsmanager.${data.aws_region.current.name}.${data.aws_partition.current.dns_suffix}\"\n  }\n}\n\ndata \"aws_partition\" \"current\" {}\ndata \"aws_region\" \"current\" {}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the stack to create. The resource deployed in AWS will be prefixed with `serverlessrepo-`\n* `application_id` - (Required) The ARN of the application from the Serverless Application Repository.\n* `capabilities` - (Required) A list of capabilities. Valid values are `CAPABILITY_IAM`, `CAPABILITY_NAMED_IAM`, `CAPABILITY_RESOURCE_POLICY`, or `CAPABILITY_AUTO_EXPAND`\n* `parameters` - (Optional) A map of Parameter structures that specify input parameters for the stack.\n* `semantic_version` - (Optional) The version of the application to deploy. If not supplied, deploys the latest version.\n* `tags` - (Optional) A list of tags to associate with this stack. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A unique identifier of the stack.\n* `outputs` - A map of outputs from the stack.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nServerless Application Repository Stack can be imported using the CloudFormation Stack name (with or without the `serverlessrepo-` prefix) or the CloudFormation Stack ID, e.g.,\n\n```\n$ terraform import aws_serverlessapplicationrepository_cloudformation_stack.example serverlessrepo-postgres-rotator\n```\n",
    "basename": "serverlessapplicationrepository_cloudformation_stack.html"
  },
  "service_discovery_http_namespace.html": {
    "subcategory": "Service Discovery",
    "layout": "aws",
    "page_title": "AWS: aws_service_discovery_http_namespace",
    "description": "Provides a Service Discovery HTTP Namespace resource.",
    "preview": "# Resource: aws_service_discovery_http_namespace\n\n\n## Example Usage\n …",
    "content": "\n\n# Resource: aws_service_discovery_http_namespace\n\n\n## Example Usage\n\n```terraform\nresource \"aws_service_discovery_http_namespace\" \"example\" {\n  name        = \"development\"\n  description = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the http namespace.\n* `description` - (Optional) The description that you specify for the namespace when you create it.\n* `tags` - (Optional) A map of tags to assign to the namespace. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of a namespace.\n* `arn` - The ARN that Amazon Route 53 assigns to the namespace when you create it.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nService Discovery HTTP Namespace can be imported using the namespace ID, e.g.,\n\n```\n$ terraform import aws_service_discovery_http_namespace.example ns-1234567890\n```\n",
    "basename": "service_discovery_http_namespace.html"
  },
  "service_discovery_instance.html": {
    "subcategory": "Service Discovery",
    "layout": "aws",
    "page_title": "AWS: aws_service_discovery_instance",
    "description": "Provides a Service Discovery Instance resource.",
    "preview": "# Resource: aws_service_discovery_instance\n\nProvides a Service …",
    "content": "\n\n# Resource: aws_service_discovery_instance\n\nProvides a Service Discovery Instance resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"example\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n}\n\nresource \"aws_service_discovery_private_dns_namespace\" \"example\" {\n  name        = \"example.terraform.local\"\n  description = \"example\"\n  vpc         = aws_vpc.example.id\n}\n\nresource \"aws_service_discovery_service\" \"example\" {\n  name = \"example\"\n\n  dns_config {\n    namespace_id = aws_service_discovery_private_dns_namespace.example.id\n\n    dns_records {\n      ttl  = 10\n      type = \"A\"\n    }\n\n    routing_policy = \"MULTIVALUE\"\n  }\n\n  health_check_custom_config {\n    failure_threshold = 1\n  }\n}\n\nresource \"aws_service_discovery_instance\" \"example\" {\n  instance_id = \"example-instance-id\"\n  service_id  = aws_service_discovery_service.example.id\n\n  attributes = {\n    AWS_INSTANCE_IPV4 = \"172.18.0.1\"\n    custom_attribute  = \"custom\"\n  }\n}\n```\n\n```terraform\nresource \"aws_service_discovery_http_namespace\" \"example\" {\n  name        = \"example.terraform.com\"\n  description = \"example\"\n}\n\nresource \"aws_service_discovery_service\" \"example\" {\n  name         = \"example\"\n  namespace_id = aws_service_discovery_http_namespace.example.id\n}\n\nresource \"aws_service_discovery_instance\" \"example\" {\n  instance_id = \"example-instance-id\"\n  service_id  = aws_service_discovery_service.example.id\n\n  attributes = {\n    AWS_EC2_INSTANCE_ID = \"i-0abdg374kd892cj6dl\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `instance_id` - (Required, ForceNew) The ID of the service instance.\n* `service_id` - (Required, ForceNew) The ID of the service that you want to use to create the instance.\n* `attributes` - (Required) A map contains the attributes of the instance. Check the [doc](https://docs.aws.amazon.com/cloud-map/latest/api/API_RegisterInstance.html#API_RegisterInstance_RequestSyntax) for the supported attributes and syntax.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the instance.\n\n## Import\n\nService Discovery Instance can be imported using the service ID and instance ID, e.g.,\n\n```\n$ terraform import aws_service_discovery_instance.example 0123456789/i-0123\n```\n",
    "basename": "service_discovery_instance.html"
  },
  "service_discovery_private_dns_namespace.html": {
    "subcategory": "Service Discovery",
    "layout": "aws",
    "page_title": "AWS: aws_service_discovery_private_dns_namespace",
    "description": "Provides a Service Discovery Private DNS Namespace resource.",
    "preview": "# Resource: aws_service_discovery_private_dns_namespace\n\nProvides a …",
    "content": "\n\n# Resource: aws_service_discovery_private_dns_namespace\n\nProvides a Service Discovery Private DNS Namespace resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"example\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_service_discovery_private_dns_namespace\" \"example\" {\n  name        = \"hoge.example.local\"\n  description = \"example\"\n  vpc         = aws_vpc.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the namespace.\n* `vpc` - (Required) The ID of VPC that you want to associate the namespace with.\n* `description` - (Optional) The description that you specify for the namespace when you create it.\n* `tags` - (Optional) A map of tags to assign to the namespace. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of a namespace.\n* `arn` - The ARN that Amazon Route 53 assigns to the namespace when you create it.\n* `hosted_zone` - The ID for the hosted zone that Amazon Route 53 creates when you create a namespace.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nService Discovery Private DNS Namespace can be imported using the namespace ID and VPC ID, e.g.,\n\n```\n$ terraform import aws_service_discovery_private_dns_namespace.example 0123456789:vpc-123345\n```\n",
    "basename": "service_discovery_private_dns_namespace.html"
  },
  "service_discovery_public_dns_namespace.html": {
    "subcategory": "Service Discovery",
    "layout": "aws",
    "page_title": "AWS: aws_service_discovery_public_dns_namespace",
    "description": "Provides a Service Discovery Public DNS Namespace resource.",
    "preview": "# Resource: aws_service_discovery_public_dns_namespace\n\nProvides a …",
    "content": "\n\n# Resource: aws_service_discovery_public_dns_namespace\n\nProvides a Service Discovery Public DNS Namespace resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_service_discovery_public_dns_namespace\" \"example\" {\n  name        = \"hoge.example.com\"\n  description = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the namespace.\n* `description` - (Optional) The description that you specify for the namespace when you create it.\n* `tags` - (Optional) A map of tags to assign to the namespace. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of a namespace.\n* `arn` - The ARN that Amazon Route 53 assigns to the namespace when you create it.\n* `hosted_zone` - The ID for the hosted zone that Amazon Route 53 creates when you create a namespace.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nService Discovery Public DNS Namespace can be imported using the namespace ID, e.g.,\n\n```\n$ terraform import aws_service_discovery_public_dns_namespace.example 0123456789\n```\n",
    "basename": "service_discovery_public_dns_namespace.html"
  },
  "service_discovery_service.html": {
    "subcategory": "Service Discovery",
    "layout": "aws",
    "page_title": "AWS: aws_service_discovery_service",
    "description": "Provides a Service Discovery Service resource.",
    "preview": "# Resource: aws_service_discovery_service\n\nProvides a Service …",
    "content": "\n\n# Resource: aws_service_discovery_service\n\nProvides a Service Discovery Service resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"example\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n}\n\nresource \"aws_service_discovery_private_dns_namespace\" \"example\" {\n  name        = \"example.terraform.local\"\n  description = \"example\"\n  vpc         = aws_vpc.example.id\n}\n\nresource \"aws_service_discovery_service\" \"example\" {\n  name = \"example\"\n\n  dns_config {\n    namespace_id = aws_service_discovery_private_dns_namespace.example.id\n\n    dns_records {\n      ttl  = 10\n      type = \"A\"\n    }\n\n    routing_policy = \"MULTIVALUE\"\n  }\n\n  health_check_custom_config {\n    failure_threshold = 1\n  }\n}\n```\n\n```terraform\nresource \"aws_service_discovery_public_dns_namespace\" \"example\" {\n  name        = \"example.terraform.com\"\n  description = \"example\"\n}\n\nresource \"aws_service_discovery_service\" \"example\" {\n  name = \"example\"\n\n  dns_config {\n    namespace_id = aws_service_discovery_public_dns_namespace.example.id\n\n    dns_records {\n      ttl  = 10\n      type = \"A\"\n    }\n  }\n\n  health_check_config {\n    failure_threshold = 10\n    resource_path     = \"path\"\n    type              = \"HTTP\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required, ForceNew) The name of the service.\n* `description` - (Optional) The description of the service.\n* `dns_config` - (Optional) A complex type that contains information about the resource record sets that you want Amazon Route 53 to create when you register an instance.\n* `health_check_config` - (Optional) A complex type that contains settings for an optional health check. Only for Public DNS namespaces.\n* `force_destroy` - (Optional, Default:false ) A boolean that indicates all instances should be deleted from the service so that the service can be destroyed without error. These instances are not recoverable.\n* `health_check_custom_config` - (Optional, ForceNew) A complex type that contains settings for ECS managed health checks.\n* `namespace_id` - (Optional) The ID of the namespace that you want to use to create the service.\n* `tags` - (Optional) A map of tags to assign to the service. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### dns_config\n\nThe following arguments are supported:\n\n* `namespace_id` - (Required, ForceNew) The ID of the namespace to use for DNS configuration.\n* `dns_records` - (Required) An array that contains one DnsRecord object for each resource record set.\n* `routing_policy` - (Optional) The routing policy that you want to apply to all records that Route 53 creates when you register an instance and specify the service. Valid Values: MULTIVALUE, WEIGHTED\n\n#### dns_records\n\nThe following arguments are supported:\n\n* `ttl` - (Required) The amount of time, in seconds, that you want DNS resolvers to cache the settings for this resource record set.\n* `type` - (Required, ForceNew) The type of the resource, which indicates the value that Amazon Route 53 returns in response to DNS queries. Valid Values: A, AAAA, SRV, CNAME\n\n### health_check_config\n\nThe following arguments are supported:\n\n* `failure_threshold` - (Optional) The number of consecutive health checks. Maximum value of 10.\n* `resource_path` - (Optional) The path that you want Route 53 to request when performing health checks. Route 53 automatically adds the DNS name for the service. If you don't specify a value, the default value is /.\n* `type` - (Optional, ForceNew) The type of health check that you want to create, which indicates how Route 53 determines whether an endpoint is healthy. Valid Values: HTTP, HTTPS, TCP\n\n### health_check_custom_config\n\nThe following arguments are supported:\n\n* `failure_threshold` - (Optional, ForceNew) The number of 30-second intervals that you want service discovery to wait before it changes the health status of a service instance.  Maximum value of 10.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the service.\n* `arn` - The ARN of the service.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nService Discovery Service can be imported using the service ID, e.g.,\n\n```\n$ terraform import aws_service_discovery_service.example 0123456789\n```\n",
    "basename": "service_discovery_service.html"
  },
  "servicecatalog_budget_resource_association.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_budget_resource_association",
    "description": "Manages a Service Catalog Budget Resource Association",
    "preview": "# Resource: aws_servicecatalog_budget_resource_association\n\nManages …",
    "content": "\n\n# Resource: aws_servicecatalog_budget_resource_association\n\nManages a Service Catalog Budget Resource Association.\n\n-> **Tip:** A \"resource\" is either a Service Catalog portfolio or product.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_budget_resource_association\" \"example\" {\n  budget_name = \"budget-pjtvyakdlyo3m\"\n  resource_id = \"prod-dnigbtea24ste\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `budget_name` - (Required) Budget name.\n* `resource_id` - (Required) Resource identifier.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier of the association.\n\n## Import\n\n`aws_servicecatalog_budget_resource_association` can be imported using the budget name and resource ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_budget_resource_association.example budget-pjtvyakdlyo3m:prod-dnigbtea24ste\n```\n",
    "basename": "servicecatalog_budget_resource_association.html"
  },
  "servicecatalog_constraint.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_constraint",
    "description": "Manages a Service Catalog Constraint",
    "preview": "# Resource: aws_servicecatalog_constraint\n\nManages a Service Catalog …",
    "content": "\n\n# Resource: aws_servicecatalog_constraint\n\nManages a Service Catalog Constraint.\n\n~> **NOTE:** This resource does not associate a Service Catalog product and portfolio. However, the product and portfolio must be associated (see the `aws_servicecatalog_product_portfolio_association` resource) prior to creating a constraint or you will receive an error.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_constraint\" \"example\" {\n  description  = \"Back off, man. I'm a scientist.\"\n  portfolio_id = aws_servicecatalog_portfolio.example.id\n  product_id   = aws_servicecatalog_product.example.id\n  type         = \"LAUNCH\"\n\n  parameters = jsonencode({\n    \"RoleArn\" : \"arn:aws:iam::123456789012:role/LaunchRole\"\n  })\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `parameters` - (Required) Constraint parameters in JSON format. The syntax depends on the constraint type. See details below.\n* `portfolio_id` - (Required) Portfolio identifier.\n* `product_id` - (Required) Product identifier.\n* `type` - (Required) Type of constraint. Valid values are `LAUNCH`, `NOTIFICATION`, `RESOURCE_UPDATE`, `STACKSET`, and `TEMPLATE`.\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values: `en` (English), `jp` (Japanese), `zh` (Chinese). Default value is `en`.\n* `description` - (Optional) Description of the constraint.\n\n### `parameters`\n\nThe `type` you specify determines what must be included in the `parameters` JSON:\n\n* `LAUNCH`: You are required to specify either the RoleArn or the LocalRoleName but can't use both. If you specify the `LocalRoleName` property, when an account uses the launch constraint, the IAM role with that name in the account will be used. This allows launch-role constraints to be account-agnostic so the administrator can create fewer resources per shared account. The given role name must exist in the account used to create the launch constraint and the account of the user who launches a product with this launch constraint. You cannot have both a `LAUNCH` and a `STACKSET` constraint. You also cannot have more than one `LAUNCH` constraint on an `aws_servicecatalog_product` and `aws_servicecatalog_portfolio`. Specify the `RoleArn` and `LocalRoleName` properties as follows:\n\n```json\n{ \"RoleArn\" : \"arn:aws:iam::123456789012:role/LaunchRole\" }\n```\n\n```json\n{ \"LocalRoleName\" : \"SCBasicLaunchRole\" }\n```\n\n* `NOTIFICATION`: Specify the `NotificationArns` property as follows:\n\n```json\n{ \"NotificationArns\" : [\"arn:aws:sns:us-east-1:123456789012:Topic\"] }\n```\n\n* `RESOURCE_UPDATE`: Specify the `TagUpdatesOnProvisionedProduct` property as follows. The `TagUpdatesOnProvisionedProduct` property accepts a string value of `ALLOWED` or `NOT_ALLOWED`.\n\n```json\n{ \"Version\" : \"2.0\",\"Properties\" :{ \"TagUpdateOnProvisionedProduct\" : \"String\" }}\n```\n\n* `STACKSET`: Specify the Parameters property as follows. You cannot have both a `LAUNCH` and a `STACKSET` constraint. You also cannot have more than one `STACKSET` constraint on on an `aws_servicecatalog_product` and `aws_servicecatalog_portfolio`. Products with a `STACKSET` constraint will launch an AWS CloudFormation stack set.\n\n```json\n{ \"Version\" : \"String\", \"Properties\" : { \"AccountList\" : [ \"String\" ], \"RegionList\" : [ \"String\" ], \"AdminRole\" : \"String\", \"ExecutionRole\" : \"String\" }}\n```\n\n* `TEMPLATE`: Specify the Rules property. For more information, see [Template Constraint Rules](http://docs.aws.amazon.com/servicecatalog/latest/adminguide/reference-template_constraint_rules.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Constraint identifier.\n* `owner` - Owner of the constraint.\n\n## Import\n\n`aws_servicecatalog_constraint` can be imported using the constraint ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_constraint.example cons-nmdkb6cgxfcrs\n```\n",
    "basename": "servicecatalog_constraint.html"
  },
  "servicecatalog_organizations_access.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_organizations_access",
    "description": "Manages Service Catalog Organizations Access",
    "preview": "# Resource: aws_servicecatalog_organizations_access\n\nManages Service …",
    "content": "\n\n# Resource: aws_servicecatalog_organizations_access\n\nManages Service Catalog AWS Organizations Access, a portfolio sharing feature through AWS Organizations. This allows Service Catalog to receive updates on your organization in order to sync your shares with the current structure. This resource will prompt AWS to set `organizations:EnableAWSServiceAccess` on your behalf so that your shares can be in sync with any changes in your AWS Organizations structure.\n\n~> **NOTE:** This resource can only be used by the management account in the organization. In other words, a delegated administrator is not authorized to use the resource.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_organizations_access\" \"example\" {\n  enabled = \"true\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `enabled` - (Required) Whether to enable AWS Organizations access.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Account ID for the account using the resource.\n",
    "basename": "servicecatalog_organizations_access.html"
  },
  "servicecatalog_portfolio.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_portfolio",
    "description": "Provides a resource to create a Service Catalog portfolio",
    "preview": "# Resource: aws_servicecatalog_portfolio\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_servicecatalog_portfolio\n\nProvides a resource to create a Service Catalog Portfolio.\n\n## Example Usage\n\n```terraform\nresource \"aws_servicecatalog_portfolio\" \"portfolio\" {\n  name          = \"My App Portfolio\"\n  description   = \"List of my organizations apps\"\n  provider_name = \"Brett\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the portfolio.\n* `description` - (Required) Description of the portfolio\n* `provider_name` - (Required) Name of the person or organization who owns the portfolio.\n* `tags` - (Optional) Tags to apply to the connection. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Service Catalog Portfolio.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nService Catalog Portfolios can be imported using the `service catalog portfolio id`, e.g.,\n\n```\n$ terraform import aws_servicecatalog_portfolio.testfolio port-12344321\n```\n",
    "basename": "servicecatalog_portfolio.html"
  },
  "servicecatalog_portfolio_share.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_portfolio_share",
    "description": "Manages a Service Catalog Portfolio Share",
    "preview": "# Resource: aws_servicecatalog_portfolio_share\n\nManages a Service …",
    "content": "\n\n# Resource: aws_servicecatalog_portfolio_share\n\nManages a Service Catalog Portfolio Share. Shares the specified portfolio with the specified account or organization node. You can share portfolios to an organization, an organizational unit, or a specific account.\n\nIf the portfolio share with the specified account or organization node already exists, using this resource to re-create the share will have no effect and will not return an error. You can then use this resource to update the share.\n\n~> **NOTE:** Shares to an organization node can only be created by the management account of an organization or by a delegated administrator. If a delegated admin is de-registered, they can no longer create portfolio shares.\n\n~> **NOTE:** AWSOrganizationsAccess must be enabled in order to create a portfolio share to an organization node.\n\n~> **NOTE:** You can't share a shared resource, including portfolios that contain a shared product.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_portfolio_share\" \"example\" {\n  principal_id = \"012128675309\"\n  portfolio_id = aws_servicecatalog_portfolio.example.id\n  type         = \"ACCOUNT\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `portfolio_id` - (Required) Portfolio identifier.\n* `principal_id` - (Required) Identifier of the principal with whom you will share the portfolio. Valid values AWS account IDs and ARNs of AWS Organizations and organizational units.\n* `type` - (Required) Type of portfolio share. Valid values are `ACCOUNT` (an external account), `ORGANIZATION` (a share to every account in an organization), `ORGANIZATIONAL_UNIT`, `ORGANIZATION_MEMBER_ACCOUNT` (a share to an account in an organization).\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values: `en` (English), `jp` (Japanese), `zh` (Chinese). Default value is `en`.\n* `share_tag_options` - (Optional) Whether to enable sharing of `aws_servicecatalog_tag_option` resources when creating the portfolio share.\n* `wait_for_acceptance` - (Optional) Whether to wait (up to the timeout) for the share to be accepted. Organizational shares are automatically accepted.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `accepted` - Whether the shared portfolio is imported by the recipient account. If the recipient is organizational, the share is automatically imported, and the field is always set to true.\n\n## Import\n\n`aws_servicecatalog_portfolio_share` can be imported using the portfolio share ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_portfolio_share.example port-12344321:ACCOUNT:123456789012\n```\n",
    "basename": "servicecatalog_portfolio_share.html"
  },
  "servicecatalog_principal_portfolio_association.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_principal_portfolio_association",
    "description": "Manages a Service Catalog Principal Portfolio Association",
    "preview": "# Resource: aws_servicecatalog_principal_portfolio_association\n …",
    "content": "\n\n# Resource: aws_servicecatalog_principal_portfolio_association\n\nManages a Service Catalog Principal Portfolio Association.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_principal_portfolio_association\" \"example\" {\n  portfolio_id  = \"port-68656c6c6f\"\n  principal_arn = \"arn:aws:iam::123456789012:user/Eleanor\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `portfolio_id` - (Required) Portfolio identifier.\n* `principal_arn` - (Required) Principal ARN.\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values: `en` (English), `jp` (Japanese), `zh` (Chinese). Default value is `en`.\n* `principal_type` - (Optional) Principal type. Setting this argument empty (e.g., `principal_type = \"\"`) will result in an error. Valid value is `IAM`. Default is `IAM`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier of the association.\n\n## Import\n\n`aws_servicecatalog_principal_portfolio_association` can be imported using the accept language, principal ARN, and portfolio ID, separated by a comma, e.g.,\n\n```\n$ terraform import aws_servicecatalog_principal_portfolio_association.example en,arn:aws:iam::123456789012:user/Eleanor,port-68656c6c6f\n```\n",
    "basename": "servicecatalog_principal_portfolio_association.html"
  },
  "servicecatalog_product.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_product",
    "description": "Manages a Service Catalog Product",
    "preview": "# Resource: aws_servicecatalog_product\n\nManages a Service Catalog …",
    "content": "\n\n# Resource: aws_servicecatalog_product\n\nManages a Service Catalog Product.\n\n~> **NOTE:** The user or role that uses this resources must have the `cloudformation:GetTemplate` IAM policy permission. This policy permission is required when using the `template_physical_id` argument.\n\n-> A \"provisioning artifact\" is also referred to as a \"version.\" A \"distributor\" is also referred to as a \"vendor.\"\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_product\" \"example\" {\n  name  = \"example\"\n  owner = [aws_security_group.example.id]\n  type  = aws_subnet.main.id\n\n  provisioning_artifact_parameters {\n    template_url = \"https://s3.amazonaws.com/cf-templates-ozkq9d3hgiq2-us-east-1/temp1.json\"\n  }\n\n  tags = {\n    foo = \"bar\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) Name of the product.\n* `owner` - (Required) Owner of the product.\n* `provisioning_artifact_parameters` - (Required) Configuration block for provisioning artifact (i.e., version) parameters. Detailed below.\n* `type` - (Required) Type of product. Valid values are `CLOUD_FORMATION_TEMPLATE`, `MARKETPLACE`.\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values: `en` (English), `jp` (Japanese), `zh` (Chinese). Default value is `en`.\n* `description` - (Optional) Description of the product.\n* `distributor` - (Optional) Distributor (i.e., vendor) of the product.\n* `support_description` - (Optional) Support information about the product.\n* `support_email` - (Optional) Contact email for product support.\n* `support_url` - (Optional) Contact URL for product support.\n* `tags` - (Optional) Tags to apply to the product. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### provisioning_artifact_parameters\n\nThe following arguments are supported:\n\n* `description` - (Optional) Description of the provisioning artifact (i.e., version), including how it differs from the previous provisioning artifact.\n* `disable_template_validation` - (Optional) Whether AWS Service Catalog stops validating the specified provisioning artifact template even if it is invalid.\n* `name` - (Optional) Name of the provisioning artifact (for example, `v1`, `v2beta`). No spaces are allowed.\n* `template_physical_id` - (Required if `template_url` is not provided) Template source as the physical ID of the resource that contains the template. Currently only supports CloudFormation stack ARN. Specify the physical ID as `arn:[partition]:cloudformation:[region]:[account ID]:stack/[stack name]/[resource ID]`.\n* `template_url` - (Required if `template_physical_id` is not provided) Template source as URL of the CloudFormation template in Amazon S3.\n* `type` - (Optional) Type of provisioning artifact. Valid values: `CLOUD_FORMATION_TEMPLATE`, `MARKETPLACE_AMI`, `MARKETPLACE_CAR` (Marketplace Clusters and AWS Resources).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the product.\n* `created_time` - Time when the product was created.\n* `has_default_path` - Whether the product has a default path. If the product does not have a default path, call `ListLaunchPaths` to disambiguate between paths.  Otherwise, `ListLaunchPaths` is not required, and the output of ProductViewSummary can be used directly with `DescribeProvisioningParameters`.\n* `id` - Product ID. For example, `prod-dnigbtea24ste`.\n* `status` - Status of the product.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_servicecatalog_product` can be imported using the product ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_product.example prod-dnigbtea24ste\n```\n",
    "basename": "servicecatalog_product.html"
  },
  "servicecatalog_product_portfolio_association.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_product_portfolio_association",
    "description": "Manages a Service Catalog Product Portfolio Association",
    "preview": "# Resource: aws_servicecatalog_product_portfolio_association\n …",
    "content": "\n\n# Resource: aws_servicecatalog_product_portfolio_association\n\nManages a Service Catalog Product Portfolio Association.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_product_portfolio_association\" \"example\" {\n  portfolio_id = \"port-68656c6c6f\"\n  product_id   = \"prod-dnigbtea24ste\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `portfolio_id` - (Required) Portfolio identifier.\n* `product_id` - (Required) Product identifier.\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values: `en` (English), `jp` (Japanese), `zh` (Chinese). Default value is `en`.\n* `source_portfolio_id` - (Optional) Identifier of the source portfolio.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier of the association.\n\n## Import\n\n`aws_servicecatalog_product_portfolio_association` can be imported using the accept language, portfolio ID, and product ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_product_portfolio_association.example en:port-68656c6c6f:prod-dnigbtea24ste\n```\n",
    "basename": "servicecatalog_product_portfolio_association.html"
  },
  "servicecatalog_provisioned_product.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_provisioned_product",
    "description": "Manages a Service Catalog Provisioned Product",
    "preview": "# Resource: aws_servicecatalog_provisioned_product\n\nThis resource …",
    "content": "\n\n# Resource: aws_servicecatalog_provisioned_product\n\nThis resource provisions and manages a Service Catalog provisioned product.\n\nA provisioned product is a resourced instance of a product. For example, provisioning a product based on a CloudFormation template launches a CloudFormation stack and its underlying resources.\n\nLike this resource, the `aws_servicecatalog_record` data source also provides information about a provisioned product. Although a Service Catalog record provides some overlapping information with this resource, a record is tied to a provisioned product event, such as provisioning, termination, and updating.\n\n-> **Tip:** If you include conflicted keys as tags, AWS will report an error, \"Parameter validation failed: Missing required parameter in Tags[N]:Value\".\n\n-> **Tip:** A \"provisioning artifact\" is also referred to as a \"version.\" A \"distributor\" is also referred to as a \"vendor.\"\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_provisioned_product\" \"example\" {\n  name                       = \"example\"\n  product_name               = \"Example product\"\n  provisioning_artifact_name = \"Example version\"\n\n  provisioning_parameters {\n    key   = \"foo\"\n    value = \"bar\"\n  }\n\n  tags = {\n    foo = \"bar\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `name` - (Required) User-friendly name of the provisioned product.\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values: `en` (English), `jp` (Japanese), `zh` (Chinese). Default value is `en`.\n* `ignore_errors` - (Optional) _Only applies to deleting._ If set to `true`, AWS Service Catalog stops managing the specified provisioned product even if it cannot delete the underlying resources. The default value is `false`.\n* `notification_arns` - (Optional) Passed to CloudFormation. The SNS topic ARNs to which to publish stack-related events.\n* `path_id` - (Optional) Path identifier of the product. This value is optional if the product has a default path, and required if the product has more than one path. To list the paths for a product, use `aws_servicecatalog_launch_paths`. When required, you must provide `path_id` or `path_name`, but not both.\n* `path_name` - (Optional) Name of the path. You must provide `path_id` or `path_name`, but not both.\n* `product_id` - (Optional) Product identifier. For example, `prod-abcdzk7xy33qa`. You must provide `product_id` or `product_name`, but not both.\n* `product_name` - (Optional) Name of the product. You must provide `product_id` or `product_name`, but not both.\n* `provisioning_artifact_id` - (Optional) Identifier of the provisioning artifact. For example, `pa-4abcdjnxjj6ne`. You must provide the `provisioning_artifact_id` or `provisioning_artifact_name`, but not both.\n* `provisioning_artifact_name` - (Optional) Name of the provisioning artifact. You must provide the `provisioning_artifact_id` or `provisioning_artifact_name`, but not both.\n* `provisioning_parameters` - (Optional) Configuration block with parameters specified by the administrator that are required for provisioning the product. See details below.\n* `retain_physical_resources` - (Optional) _Only applies to deleting._ Whether to delete the Service Catalog provisioned product but leave the CloudFormation stack, stack set, or the underlying resources of the deleted provisioned product. The default value is `false`.\n* `stack_set_provisioning_preferences` - (Optional) Configuration block with information about the provisioning preferences for a stack set. See details below.\n* `tags` - (Optional) Tags to apply to the provisioned product. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### provisioning_parameters\n\nThe following arguments are supported:\n\n* `key` - (Required) Parameter key.\n* `use_previous_value` - (Optional) Whether to ignore `value` and keep the previous parameter value. Ignored when initially provisioning a product.\n* `value` - (Optional) Parameter value.\n\n### stack_set_provisioning_preferences\n\nAll of the `stack_set_provisioning_preferences` are only applicable to a `CFN_STACKSET` provisioned product type.\n\nThe following arguments are supported:\n\n* `accounts` - (Optional) One or more AWS accounts that will have access to the provisioned product. The AWS accounts specified should be within the list of accounts in the STACKSET constraint. To get the list of accounts in the STACKSET constraint, use the `aws_servicecatalog_provisioning_parameters` data source. If no values are specified, the default value is all accounts from the STACKSET constraint.\n* `failure_tolerance_count` - (Optional) Number of accounts, per region, for which this operation can fail before AWS Service Catalog stops the operation in that region. If the operation is stopped in a region, AWS Service Catalog doesn't attempt the operation in any subsequent regions. You must specify either `failure_tolerance_count` or `failure_tolerance_percentage`, but not both. The default value is 0 if no value is specified.\n* `failure_tolerance_percentage` - (Optional) Percentage of accounts, per region, for which this stack operation can fail before AWS Service Catalog stops the operation in that region. If the operation is stopped in a region, AWS Service Catalog doesn't attempt the operation in any subsequent regions. When calculating the number of accounts based on the specified percentage, AWS Service Catalog rounds down to the next whole number. You must specify either `failure_tolerance_count` or `failure_tolerance_percentage`, but not both.\n* `max_concurrency_count` - (Optional) Maximum number of accounts in which to perform this operation at one time. This is dependent on the value of `failure_tolerance_count`. `max_concurrency_count` is at most one more than the `failure_tolerance_count`. Note that this setting lets you specify the maximum for operations. For large deployments, under certain circumstances the actual number of accounts acted upon concurrently may be lower due to service throttling. You must specify either `max_concurrency_count` or `max_concurrency_percentage`, but not both.\n* `max_concurrency_percentage` - (Optional) Maximum percentage of accounts in which to perform this operation at one time. When calculating the number of accounts based on the specified percentage, AWS Service Catalog rounds down to the next whole number. This is true except in cases where rounding down would result is zero. In this case, AWS Service Catalog sets the number as 1 instead. Note that this setting lets you specify the maximum for operations. For large deployments, under certain circumstances the actual number of accounts acted upon concurrently may be lower due to service throttling. You must specify either `max_concurrency_count` or `max_concurrency_percentage`, but not both.\n* `regions` - (Optional) One or more AWS Regions where the provisioned product will be available. The specified regions should be within the list of regions from the STACKSET constraint. To get the list of regions in the STACKSET constraint, use the `aws_servicecatalog_provisioning_parameters` data source. If no values are specified, the default value is all regions from the STACKSET constraint.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the provisioned product.\n* `cloudwatch_dashboard_names` - Set of CloudWatch dashboards that were created when provisioning the product.\n* `created_time` - Time when the provisioned product was created.\n* `id` - Provisioned Product ID.\n* `last_provisioning_record_id` - Record identifier of the last request performed on this provisioned product of the following types: `ProvisionedProduct`, `UpdateProvisionedProduct`, `ExecuteProvisionedProductPlan`, `TerminateProvisionedProduct`.\n* `last_record_id` - Record identifier of the last request performed on this provisioned product.\n* `last_successful_provisioning_record_id` - Record identifier of the last successful request performed on this provisioned product of the following types: `ProvisionedProduct`, `UpdateProvisionedProduct`, `ExecuteProvisionedProductPlan`, `TerminateProvisionedProduct`.\n* `launch_role_arn` - ARN of the launch role associated with the provisioned product.\n* `status` - Current status of the provisioned product. See meanings below.\n* `status_message` - Current status message of the provisioned product.\n* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `type` - Type of provisioned product. Valid values are `CFN_STACK` and `CFN_STACKSET`.\n\n### status Meanings\n\n* `AVAILABLE` - Stable state, ready to perform any operation. The most recent operation succeeded and completed.\n* `UNDER_CHANGE` - Transitive state. Operations performed might not have\nvalid results. Wait for an `AVAILABLE` status before performing operations.\n* `TAINTED` - Stable state, ready to perform any operation. The stack has completed the requested operation but is not exactly what was requested. For example, a request to update to a new version failed and the stack rolled back to the current version.\n* `ERROR` - An unexpected error occurred. The provisioned product exists but the stack is not running. For example, CloudFormation received a parameter value that was not valid and could not launch the stack.\n* `PLAN_IN_PROGRESS` - Transitive state. The plan operations were performed to provision a new product, but resources have not yet been created. After reviewing the list of resources to be created, execute the plan. Wait for an `AVAILABLE` status before performing operations.\n\n## Import\n\n`aws_servicecatalog_provisioned_product` can be imported using the provisioned product ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_provisioned_product.example pp-dnigbtea24ste\n```\n",
    "basename": "servicecatalog_provisioned_product.html"
  },
  "servicecatalog_provisioning_artifact.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_provisioning_artifact",
    "description": "Manages a Service Catalog Provisioning Artifact",
    "preview": "# Resource: aws_servicecatalog_provisioning_artifact\n\nManages a …",
    "content": "\n\n# Resource: aws_servicecatalog_provisioning_artifact\n\nManages a Service Catalog Provisioning Artifact for a specified product.\n\n-> A \"provisioning artifact\" is also referred to as a \"version.\"\n\n~> **NOTE:** You cannot create a provisioning artifact for a product that was shared with you.\n\n~> **NOTE:** The user or role that use this resource must have the `cloudformation:GetTemplate` IAM policy permission. This policy permission is required when using the `template_physical_id` argument.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_provisioning_artifact\" \"example\" {\n  name         = \"example\"\n  product_id   = aws_servicecatalog_product.example.id\n  type         = \"CLOUD_FORMATION_TEMPLATE\"\n  template_url = \"https://${aws_s3_bucket.example.bucket_regional_domain_name}/${aws_s3_bucket_object.example.key}\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `product_id` - (Required) Identifier of the product.\n* `template_physical_id` - (Required if `template_url` is not provided) Template source as the physical ID of the resource that contains the template. Currently only supports CloudFormation stack ARN. Specify the physical ID as `arn:[partition]:cloudformation:[region]:[account ID]:stack/[stack name]/[resource ID]`.\n* `template_url` - (Required if `template_physical_id` is not provided) Template source as URL of the CloudFormation template in Amazon S3.\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values: `en` (English), `jp` (Japanese), `zh` (Chinese). The default value is `en`.\n* `active` - (Optional) Whether the product version is active. Inactive provisioning artifacts are invisible to end users. End users cannot launch or update a provisioned product from an inactive provisioning artifact. Default is `true`.\n* `description` - (Optional) Description of the provisioning artifact (i.e., version), including how it differs from the previous provisioning artifact.\n* `disable_template_validation` - (Optional) Whether AWS Service Catalog stops validating the specified provisioning artifact template even if it is invalid.\n* `guidance` - (Optional) Information set by the administrator to provide guidance to end users about which provisioning artifacts to use. Valid values are `DEFAULT` and `DEPRECATED`. The default is `DEFAULT`. Users are able to make updates to a provisioned product of a deprecated version but cannot launch new provisioned products using a deprecated version.\n* `name` - (Optional) Name of the provisioning artifact (for example, `v1`, `v2beta`). No spaces are allowed.\n* `type` - (Optional) Type of provisioning artifact. Valid values: `CLOUD_FORMATION_TEMPLATE`, `MARKETPLACE_AMI`, `MARKETPLACE_CAR` (Marketplace Clusters and AWS Resources).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `created_time` - Time when the provisioning artifact was created.\n* `id` - Provisioning Artifact identifier and product identifier separated by a colon.\n* `status` - Status of the provisioning artifact.\n\n## Import\n\n`aws_servicecatalog_provisioning_artifact` can be imported using the provisioning artifact ID and product ID separated by a colon, e.g.,\n\n```\n$ terraform import aws_servicecatalog_provisioning_artifact.example pa-ij2b6lusy6dec:prod-el3an0rma3\n```\n",
    "basename": "servicecatalog_provisioning_artifact.html"
  },
  "servicecatalog_service_action.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_service_action",
    "description": "Manages a Service Catalog Service Action",
    "preview": "# Resource: aws_servicecatalog_service_action\n\nManages a Service …",
    "content": "\n\n# Resource: aws_servicecatalog_service_action\n\nManages a Service Catalog self-service action.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_service_action\" \"example\" {\n  description = \"Motor generator unit\"\n  name        = \"MGU\"\n\n  definition {\n    name = \"AWS-RestartEC2Instance\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `definition` - (Required) Self-service action definition configuration block. Detailed below.\n* `name` - (Required) Self-service action name.\n\nThe following arguments are optional:\n\n* `accept_language` - (Optional) Language code. Valid values are `en` (English), `jp` (Japanese), and `zh` (Chinese). Default is `en`.\n* `description` - (Optional) Self-service action description.\n\n### `definition`\n\nThe `definition` configuration block supports the following attributes:\n\n* `assume_role` - (Optional) ARN of the role that performs the self-service actions on your behalf. For example, `arn:aws:iam::12345678910:role/ActionRole`. To reuse the provisioned product launch role, set to `LAUNCH_ROLE`.\n* `name` - (Required) Name of the SSM document. For example, `AWS-RestartEC2Instance`. If you are using a shared SSM document, you must provide the ARN instead of the name.\n* `parameters` - (Optional) List of parameters in JSON format. For example: `[{\\\"Name\\\":\\\"InstanceId\\\",\\\"Type\\\":\\\"TARGET\\\"}]` or `[{\\\"Name\\\":\\\"InstanceId\\\",\\\"Type\\\":\\\"TEXT_VALUE\\\"}]`.\n* `type` - (Optional) Service action definition type. Valid value is `SSM_AUTOMATION`. Default is `SSM_AUTOMATION`.\n* `version` - (Required) SSM document version. For example, `1`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier of the service action.\n\n## Import\n\n`aws_servicecatalog_service_action` can be imported using the service action ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_service_action.example act-f1w12eperfslh\n```\n",
    "basename": "servicecatalog_service_action.html"
  },
  "servicecatalog_tag_option.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_tag_option",
    "description": "Manages a Service Catalog Tag Option",
    "preview": "# Resource: aws_servicecatalog_tag_option\n\nManages a Service Catalog …",
    "content": "\n\n# Resource: aws_servicecatalog_tag_option\n\nManages a Service Catalog Tag Option.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_tag_option\" \"example\" {\n  key   = \"nyckel\"\n  value = \"värde\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `key` - (Required) Tag option key.\n* `value` - (Required) Tag option value.\n\nThe following arguments are optional:\n\n* `active` - (Optional) Whether tag option is active. Default is `true`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier (e.g., `tag-pjtvagohlyo3m`).\n* `owner_id` - AWS account ID of the owner account that created the tag option.\n\n## Import\n\n`aws_servicecatalog_tag_option` can be imported using the tag option ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_tag_option.example tag-pjtvagohlyo3m\n```\n",
    "basename": "servicecatalog_tag_option.html"
  },
  "servicecatalog_tag_option_resource_association.html": {
    "subcategory": "Service Catalog",
    "layout": "aws",
    "page_title": "AWS: aws_servicecatalog_tag_option_resource_association",
    "description": "Manages a Service Catalog Tag Option Resource Association",
    "preview": "# Resource: aws_servicecatalog_tag_option_resource_association\n …",
    "content": "\n\n# Resource: aws_servicecatalog_tag_option_resource_association\n\nManages a Service Catalog Tag Option Resource Association.\n\n-> **Tip:** A \"resource\" is either a Service Catalog portfolio or product.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_servicecatalog_tag_option_resource_association\" \"example\" {\n  resource_id   = \"prod-dnigbtea24ste\"\n  tag_option_id = \"tag-pjtvyakdlyo3m\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `resource_id` - (Required) Resource identifier.\n* `tag_option_id` - (Required) Tag Option identifier.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Identifier of the association.\n* `resource_arn` - ARN of the resource.\n* `resource_created_time` - Creation time of the resource.\n* `resource_description` - Description of the resource.\n* `resource_name` - Description of the resource.\n\n## Import\n\n`aws_servicecatalog_tag_option_resource_association` can be imported using the tag option ID and resource ID, e.g.,\n\n```\n$ terraform import aws_servicecatalog_tag_option_resource_association.example tag-pjtvyakdlyo3m:prod-dnigbtea24ste\n```\n",
    "basename": "servicecatalog_tag_option_resource_association.html"
  },
  "servicequotas_service_quota.html": {
    "subcategory": "Service Quotas",
    "layout": "aws",
    "page_title": "AWS: aws_servicequotas_service_quota",
    "description": "Manages an individual Service Quota",
    "preview": "# Resource: aws_servicequotas_service_quota\n\nManages an individual …",
    "content": "\n\n# Resource: aws_servicequotas_service_quota\n\nManages an individual Service Quota.\n\n~> **NOTE:** Global quotas apply to all AWS regions, but can only be accessed in `us-east-1` in the Commercial partition or `us-gov-west-1` in the GovCloud partition. In other regions, the AWS API will return the error `The request failed because the specified service does not exist.`\n\n## Example Usage\n\n```terraform\nresource \"aws_servicequotas_service_quota\" \"example\" {\n  quota_code   = \"L-F678F1CE\"\n  service_code = \"vpc\"\n  value        = 75\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `quota_code` - (Required) Code of the service quota to track. For example: `L-F678F1CE`. Available values can be found with the [AWS CLI service-quotas list-service-quotas command](https://docs.aws.amazon.com/cli/latest/reference/service-quotas/list-service-quotas.html).\n* `service_code` - (Required) Code of the service to track. For example: `vpc`. Available values can be found with the [AWS CLI service-quotas list-services command](https://docs.aws.amazon.com/cli/latest/reference/service-quotas/list-services.html).\n* `value` - (Required) Float specifying the desired value for the service quota. If the desired value is higher than the current value, a quota increase request is submitted. When a known request is submitted and pending, the value reflects the desired value of the pending request.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `adjustable` - Whether the service quota can be increased.\n* `arn` - Amazon Resource Name (ARN) of the service quota.\n* `default_value` - Default value of the service quota.\n* `id` - Service code and quota code, separated by a front slash (`/`)\n* `quota_name` - Name of the quota.\n* `service_name` - Name of the service.\n\n## Import\n\n~> *NOTE* This resource does not require explicit import and will assume management of an existing service quota on Terraform resource creation.\n\n`aws_servicequotas_service_quota` can be imported by using the service code and quota code, separated by a front slash (`/`), e.g.,\n\n```\n$ terraform import aws_servicequotas_service_quota.example vpc/L-F678F1CE\n```\n",
    "basename": "servicequotas_service_quota.html"
  },
  "ses_active_receipt_rule_set.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_active_receipt_rule_set",
    "description": "Provides a resource to designate the active SES receipt rule set",
    "preview": "# Resource: aws_ses_active_receipt_rule_set\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_ses_active_receipt_rule_set\n\nProvides a resource to designate the active SES receipt rule set\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_active_receipt_rule_set\" \"main\" {\n  rule_set_name = \"primary-rules\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rule_set_name` - (Required) The name of the rule set\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The SES receipt rule set name.\n* `arn` - The SES receipt rule set ARN.\n",
    "basename": "ses_active_receipt_rule_set.html"
  },
  "ses_configuration_set.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_configuration_set",
    "description": "Provides an SES configuration set",
    "preview": "# Resource: aws_ses_configuration_set\n\nProvides an SES configuration …",
    "content": "\n\n# Resource: aws_ses_configuration_set\n\nProvides an SES configuration set resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_configuration_set\" \"test\" {\n  name = \"some-configuration-set-test\"\n}\n```\n\n### Require TLS Connections\n\n```terraform\nresource \"aws_ses_configuration_set\" \"test\" {\n  name = \"some-configuration-set-test\"\n\n  delivery_options {\n    tls_policy = \"Require\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following argument is required:\n\n* `name` - (Required) Name of the configuration set.\n\nThe following argument is optional:\n\n* `delivery_options` - (Optional) Configuration block. Detailed below.\n* `reputation_metrics_enabled` - (Optional) Whether or not Amazon SES publishes reputation metrics for the configuration set, such as bounce and complaint rates, to Amazon CloudWatch. The default value is `false`.\n* `sending_enabled` - (Optional) Whether email sending is enabled or disabled for the configuration set. The default value is `true`.\n\n### delivery_options\n\n* `tls_policy` - (Optional) Specifies whether messages that use the configuration set are required to use Transport Layer Security (TLS). If the value is `Require`, messages are only delivered if a TLS connection can be established. If the value is `Optional`, messages can be delivered in plain text if a TLS connection can't be established. Valid values: `Require` or `Optional`. Defaults to `Optional`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - SES configuration set ARN.\n* `id` - SES configuration set name.\n* `last_fresh_start` - The date and time at which the reputation metrics for the configuration set were last reset. Resetting these metrics is known as a fresh start.\n\n## Import\n\nSES Configuration Sets can be imported using their `name`, e.g.,\n\n```\n$ terraform import aws_ses_configuration_set.test some-configuration-set-test\n```\n",
    "basename": "ses_configuration_set.html"
  },
  "ses_domain_dkim.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_domain_dkim",
    "description": "Provides an SES domain DKIM generation resource",
    "preview": "# Resource: aws_ses_domain_dkim\n\nProvides an SES domain DKIM …",
    "content": "\n\n# Resource: aws_ses_domain_dkim\n\nProvides an SES domain DKIM generation resource.\n\nDomain ownership needs to be confirmed first using [ses_domain_identity Resource](/docs/providers/aws/r/ses_domain_identity.html)\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain` - (Required) Verified domain name to generate DKIM tokens for.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `dkim_tokens` - DKIM tokens generated by SES.\n  These tokens should be used to create CNAME records used to verify SES Easy DKIM.\n  See below for an example of how this might be achieved\n  when the domain is hosted in Route 53 and managed by Terraform.\n  Find out more about verifying domains in Amazon SES\n  in the [AWS SES docs](http://docs.aws.amazon.com/ses/latest/DeveloperGuide/easy-dkim-dns-records.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_domain_identity\" \"example\" {\n  domain = \"example.com\"\n}\n\nresource \"aws_ses_domain_dkim\" \"example\" {\n  domain = aws_ses_domain_identity.example.domain\n}\n\nresource \"aws_route53_record\" \"example_amazonses_dkim_record\" {\n  count   = 3\n  zone_id = \"ABCDEFGHIJ123\"\n  name    = \"${element(aws_ses_domain_dkim.example.dkim_tokens, count.index)}._domainkey\"\n  type    = \"CNAME\"\n  ttl     = \"600\"\n  records = [\"${element(aws_ses_domain_dkim.example.dkim_tokens, count.index)}.dkim.amazonses.com\"]\n}\n```\n\n## Import\n\nDKIM tokens can be imported using the `domain` attribute, e.g.,\n\n```\n$ terraform import aws_ses_domain_dkim.example example.com\n```\n",
    "basename": "ses_domain_dkim.html"
  },
  "ses_domain_identity.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_domain_identity",
    "description": "Provides an SES domain identity resource",
    "preview": "# Resource: aws_ses_domain_identity\n\nProvides an SES domain identity …",
    "content": "\n\n# Resource: aws_ses_domain_identity\n\nProvides an SES domain identity resource\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain` - (Required) The domain name to assign to SES\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the domain identity.\n\n* `verification_token` - A code which when added to the domain as a TXT record\n  will signal to SES that the owner of the domain has authorised SES to act on\n  their behalf. The domain identity will be in state \"verification pending\"\n  until this is done. See below for an example of how this might be achieved\n  when the domain is hosted in Route 53 and managed by Terraform.  Find out\n  more about verifying domains in Amazon SES in the [AWS SES\n  docs](http://docs.aws.amazon.com/ses/latest/DeveloperGuide/verify-domains.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_domain_identity\" \"example\" {\n  domain = \"example.com\"\n}\n\nresource \"aws_route53_record\" \"example_amazonses_verification_record\" {\n  zone_id = \"ABCDEFGHIJ123\"\n  name    = \"_amazonses.example.com\"\n  type    = \"TXT\"\n  ttl     = \"600\"\n  records = [aws_ses_domain_identity.example.verification_token]\n}\n```\n\n## Import\n\nSES domain identities can be imported using the domain name.\n\n```\n$ terraform import aws_ses_domain_identity.example example.com\n```\n",
    "basename": "ses_domain_identity.html"
  },
  "ses_domain_identity_verification.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_domain_identity_verification",
    "description": "Waits for and checks successful verification of an SES domain identity.",
    "preview": "# Resource: aws_ses_domain_identity_verification\n\nRepresents a …",
    "content": "\n\n# Resource: aws_ses_domain_identity_verification\n\nRepresents a successful verification of an SES domain identity.\n\nMost commonly, this resource is used together with [`aws_route53_record`](route53_record.html) and\n[`aws_ses_domain_identity`](ses_domain_identity.html) to request an SES domain identity,\ndeploy the required DNS verification records, and wait for verification to complete.\n\n~> **WARNING:** This resource implements a part of the verification workflow. It does not represent a real-world entity in AWS, therefore changing or deleting this resource on its own has no immediate effect.\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_domain_identity\" \"example\" {\n  domain = \"example.com\"\n}\n\nresource \"aws_route53_record\" \"example_amazonses_verification_record\" {\n  zone_id = aws_route53_zone.example.zone_id\n  name    = \"_amazonses.${aws_ses_domain_identity.example.id}\"\n  type    = \"TXT\"\n  ttl     = \"600\"\n  records = [aws_ses_domain_identity.example.verification_token]\n}\n\nresource \"aws_ses_domain_identity_verification\" \"example_verification\" {\n  domain = aws_ses_domain_identity.example.id\n\n  depends_on = [aws_route53_record.example_amazonses_verification_record]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain` - (Required) The domain name of the SES domain identity to verify.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The domain name of the domain identity.\n* `arn` - The ARN of the domain identity.\n\n## Timeouts\n\n`acm_ses_domain_identity_verification` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `45m`) How long to wait for a domain identity to be verified.\n",
    "basename": "ses_domain_identity_verification.html"
  },
  "ses_domain_mail_from.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_domain_mail_from",
    "description": "Provides an SES domain MAIL FROM resource",
    "preview": "# Resource: aws_ses_domain_mail_from\n\nProvides an SES domain MAIL …",
    "content": "\n\n# Resource: aws_ses_domain_mail_from\n\nProvides an SES domain MAIL FROM resource.\n\n~> **NOTE:** For the MAIL FROM domain to be fully usable, this resource should be paired with the [aws_ses_domain_identity resource](/docs/providers/aws/r/ses_domain_identity.html). To validate the MAIL FROM domain, a DNS MX record is required. To pass SPF checks, a DNS TXT record may also be required. See the [Amazon SES MAIL FROM documentation](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/mail-from-set.html) for more information.\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_domain_mail_from\" \"example\" {\n  domain           = aws_ses_domain_identity.example.domain\n  mail_from_domain = \"bounce.${aws_ses_domain_identity.example.domain}\"\n}\n\n# Example SES Domain Identity\nresource \"aws_ses_domain_identity\" \"example\" {\n  domain = \"example.com\"\n}\n\n# Example Route53 MX record\nresource \"aws_route53_record\" \"example_ses_domain_mail_from_mx\" {\n  zone_id = aws_route53_zone.example.id\n  name    = aws_ses_domain_mail_from.example.mail_from_domain\n  type    = \"MX\"\n  ttl     = \"600\"\n  records = [\"10 feedback-smtp.us-east-1.amazonses.com\"] # Change to the region in which `aws_ses_domain_identity.example` is created\n}\n\n# Example Route53 TXT record for SPF\nresource \"aws_route53_record\" \"example_ses_domain_mail_from_txt\" {\n  zone_id = aws_route53_zone.example.id\n  name    = aws_ses_domain_mail_from.example.mail_from_domain\n  type    = \"TXT\"\n  ttl     = \"600\"\n  records = [\"v=spf1 include:amazonses.com -all\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `domain` - (Required) Verified domain name to generate DKIM tokens for.\n* `mail_from_domain` - (Required) Subdomain (of above domain) which is to be used as MAIL FROM address (Required for DMARC validation)\n\nThe following arguments are optional:\n\n* `behavior_on_mx_failure` - (Optional) The action that you want Amazon SES to take if it cannot successfully read the required MX record when you send an email. Defaults to `UseDefaultValue`. See the [SES API documentation](https://docs.aws.amazon.com/ses/latest/APIReference/API_SetIdentityMailFromDomain.html) for more information.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The domain name.\n\n## Import\n\nMAIL FROM domain can be imported using the `domain` attribute, e.g.,\n\n```\n$ terraform import aws_ses_domain_mail_from.example example.com\n```\n",
    "basename": "ses_domain_mail_from.html"
  },
  "ses_email_identity.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_email_identity",
    "description": "Provides an SES email identity resource",
    "preview": "# Resource: aws_ses_email_identity\n\nProvides an SES email identity …",
    "content": "\n\n# Resource: aws_ses_email_identity\n\nProvides an SES email identity resource\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `email` - (Required) The email address to assign to SES\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the email identity.\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_email_identity\" \"example\" {\n  email = \"email@example.com\"\n}\n```\n\n## Import\n\nSES email identities can be imported using the email address.\n\n```\n$ terraform import aws_ses_email_identity.example email@example.com\n```\n",
    "basename": "ses_email_identity.html"
  },
  "ses_event_destination.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_event_destination",
    "description": "Provides an SES event destination",
    "preview": "# Resource: aws_ses_event_destination\n\nProvides an SES event …",
    "content": "\n\n# Resource: aws_ses_event_destination\n\nProvides an SES event destination\n\n## Example Usage\n\n### CloudWatch Destination\n\n```terraform\nresource \"aws_ses_event_destination\" \"cloudwatch\" {\n  name                   = \"event-destination-cloudwatch\"\n  configuration_set_name = aws_ses_configuration_set.example.name\n  enabled                = true\n  matching_types         = [\"bounce\", \"send\"]\n\n  cloudwatch_destination {\n    default_value  = \"default\"\n    dimension_name = \"dimension\"\n    value_source   = \"emailHeader\"\n  }\n}\n```\n\n### Kinesis Destination\n\n```terraform\nresource \"aws_ses_event_destination\" \"kinesis\" {\n  name                   = \"event-destination-kinesis\"\n  configuration_set_name = aws_ses_configuration_set.example.name\n  enabled                = true\n  matching_types         = [\"bounce\", \"send\"]\n\n  kinesis_destination {\n    stream_arn = aws_kinesis_firehose_delivery_stream.example.arn\n    role_arn   = aws_iam_role.example.arn\n  }\n}\n```\n\n### SNS Destination\n\n```terraform\nresource \"aws_ses_event_destination\" \"sns\" {\n  name                   = \"event-destination-sns\"\n  configuration_set_name = aws_ses_configuration_set.example.name\n  enabled                = true\n  matching_types         = [\"bounce\", \"send\"]\n\n  sns_destination {\n    topic_arn = aws_sns_topic.example.arn\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the event destination\n* `configuration_set_name` - (Required) The name of the configuration set\n* `enabled` - (Optional) If true, the event destination will be enabled\n* `matching_types` - (Required) A list of matching types. May be any of `\"send\"`, `\"reject\"`, `\"bounce\"`, `\"complaint\"`, `\"delivery\"`, `\"open\"`, `\"click\"`, or `\"renderingFailure\"`.\n* `cloudwatch_destination` - (Optional) CloudWatch destination for the events\n* `kinesis_destination` - (Optional) Send the events to a kinesis firehose destination\n* `sns_destination` - (Optional) Send the events to an SNS Topic destination\n\n~> **NOTE:** You can specify `\"cloudwatch_destination\"` or `\"kinesis_destination\"` but not both\n\n### cloudwatch_destination Argument Reference\n\n* `default_value` - (Required) The default value for the event\n* `dimension_name` - (Required) The name for the dimension\n* `value_source` - (Required) The source for the value. May be any of `\"messageTag\"`, `\"emailHeader\"` or `\"linkTag\"`.\n\n### kinesis_destination Argument Reference\n\n* `stream_arn` - (Required) The ARN of the Kinesis Stream\n* `role_arn` - (Required) The ARN of the role that has permissions to access the Kinesis Stream\n\n### sns_destination Argument Reference\n\n* `topic_arn` - (Required) The ARN of the SNS topic\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The SES event destination name.\n* `arn` - The SES event destination ARN.\n\n## Import\n\nSES event destinations can be imported using `configuration_set_name` together with the event destination's `name`,\ne.g.,\n\n```\n$ terraform import aws_ses_event_destination.sns some-configuration-set-test/event-destination-sns\n```\n",
    "basename": "ses_event_destination.html"
  },
  "ses_identity_notification_topic": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_identity_notification_topic",
    "description": "Setting AWS SES Identity Notification Topic",
    "preview": "# Resource: aws_ses_identity_notification_topic\n\nResource for …",
    "content": "\n\n# Resource: aws_ses_identity_notification_topic\n\nResource for managing SES Identity Notification Topics\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_identity_notification_topic\" \"test\" {\n  topic_arn                = aws_sns_topic.example.arn\n  notification_type        = \"Bounce\"\n  identity                 = aws_ses_domain_identity.example.domain\n  include_original_headers = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `topic_arn` - (Optional) The Amazon Resource Name (ARN) of the Amazon SNS topic. Can be set to \"\" (an empty string) to disable publishing.\n* `notification_type` - (Required) The type of notifications that will be published to the specified Amazon SNS topic. Valid Values: *Bounce*, *Complaint* or *Delivery*.\n* `identity` - (Required) The identity for which the Amazon SNS topic will be set. You can specify an identity by using its name or by using its Amazon Resource Name (ARN).\n* `include_original_headers` - (Optional) Whether SES should include original email headers in SNS notifications of this type. *false* by default.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nIdentity Notification Topics can be imported using ID of the record. The ID is made up as IDENTITY|TYPE where IDENTITY is the SES Identity and TYPE is the Notification Type.\n\n```\n$ terraform import aws_ses_identity_notification_topic.test 'example.com|Bounce'\n```\n",
    "basename": "ses_identity_notification_topic"
  },
  "ses_identity_policy.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_identity_policy",
    "description": "Manages a SES Identity Policy",
    "preview": "# Resource: aws_ses_identity_policy\n\nManages a SES Identity Policy. …",
    "content": "\n\n# Resource: aws_ses_identity_policy\n\nManages a SES Identity Policy. More information about SES Sending Authorization Policies can be found in the [SES Developer Guide](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/sending-authorization-policies.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_domain_identity\" \"example\" {\n  domain = \"example.com\"\n}\n\ndata \"aws_iam_policy_document\" \"example\" {\n  statement {\n    actions   = [\"SES:SendEmail\", \"SES:SendRawEmail\"]\n    resources = [aws_ses_domain_identity.example.arn]\n\n    principals {\n      identifiers = [\"*\"]\n      type        = \"AWS\"\n    }\n  }\n}\n\nresource \"aws_ses_identity_policy\" \"example\" {\n  identity = aws_ses_domain_identity.example.arn\n  name     = \"example\"\n  policy   = data.aws_iam_policy_document.example.json\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `identity` - (Required) Name or Amazon Resource Name (ARN) of the SES Identity.\n* `name` - (Required) Name of the policy.\n* `policy` - (Required) JSON string of the policy. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nSES Identity Policies can be imported using the identity and policy name, separated by a pipe character (`|`), e.g.,\n\n```\n$ terraform import aws_ses_identity_policy.example 'example.com|example'\n```\n",
    "basename": "ses_identity_policy.html"
  },
  "ses_receipt_filter.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_receipt_filter",
    "description": "Provides an SES receipt filter",
    "preview": "# Resource: aws_ses_receipt_filter\n\nProvides an SES receipt filter …",
    "content": "\n\n# Resource: aws_ses_receipt_filter\n\nProvides an SES receipt filter resource\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_receipt_filter\" \"filter\" {\n  name   = \"block-spammer\"\n  cidr   = \"10.10.10.10\"\n  policy = \"Block\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the filter\n* `cidr` - (Required) The IP address or address range to filter, in CIDR notation\n* `policy` - (Required) Block or Allow\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The SES receipt filter name.\n* `arn` - The SES receipt filter ARN.\n\n## Import\n\nSES Receipt Filter can be imported using their `name`, e.g.,\n\n```\n$ terraform import aws_ses_receipt_filter.test some-filter\n```\n",
    "basename": "ses_receipt_filter.html"
  },
  "ses_receipt_rule.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_receipt_rule",
    "description": "Provides an SES receipt rule resource",
    "preview": "# Resource: aws_ses_receipt_rule\n\nProvides an SES receipt rule …",
    "content": "\n\n# Resource: aws_ses_receipt_rule\n\nProvides an SES receipt rule resource\n\n## Example Usage\n\n```terraform\n# Add a header to the email and store it in S3\nresource \"aws_ses_receipt_rule\" \"store\" {\n  name          = \"store\"\n  rule_set_name = \"default-rule-set\"\n  recipients    = [\"karen@example.com\"]\n  enabled       = true\n  scan_enabled  = true\n\n  add_header_action {\n    header_name  = \"Custom-Header\"\n    header_value = \"Added by SES\"\n    position     = 1\n  }\n\n  s3_action {\n    bucket_name = \"emails\"\n    position    = 2\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the rule\n* `rule_set_name` - (Required) The name of the rule set\n* `after` - (Optional) The name of the rule to place this rule after\n* `enabled` - (Optional) If true, the rule will be enabled\n* `recipients` - (Optional) A list of email addresses\n* `scan_enabled` - (Optional) If true, incoming emails will be scanned for spam and viruses\n* `tls_policy` - (Optional) `Require` or `Optional`\n* `add_header_action` - (Optional) A list of Add Header Action blocks. Documented below.\n* `bounce_action` - (Optional) A list of Bounce Action blocks. Documented below.\n* `lambda_action` - (Optional) A list of Lambda Action blocks. Documented below.\n* `s3_action` - (Optional) A list of S3 Action blocks. Documented below.\n* `sns_action` - (Optional) A list of SNS Action blocks. Documented below.\n* `stop_action` - (Optional) A list of Stop Action blocks. Documented below.\n* `workmail_action` - (Optional) A list of WorkMail Action blocks. Documented below.\n\nAdd header actions support the following:\n\n* `header_name` - (Required) The name of the header to add\n* `header_value` - (Required) The value of the header to add\n* `position` - (Required) The position of the action in the receipt rule\n\nBounce actions support the following:\n\n* `message` - (Required) The message to send\n* `sender` - (Required) The email address of the sender\n* `smtp_reply_code` - (Required) The RFC 5321 SMTP reply code\n* `status_code` - (Optional) The RFC 3463 SMTP enhanced status code\n* `topic_arn` - (Optional) The ARN of an SNS topic to notify\n* `position` - (Required) The position of the action in the receipt rule\n\nLambda actions support the following:\n\n* `function_arn` - (Required) The ARN of the Lambda function to invoke\n* `invocation_type` - (Optional) `Event` or `RequestResponse`\n* `topic_arn` - (Optional) The ARN of an SNS topic to notify\n* `position` - (Required) The position of the action in the receipt rule\n\nS3 actions support the following:\n\n* `bucket_name` - (Required) The name of the S3 bucket\n* `kms_key_arn` - (Optional) The ARN of the KMS key\n* `object_key_prefix` - (Optional) The key prefix of the S3 bucket\n* `topic_arn` - (Optional) The ARN of an SNS topic to notify\n* `position` - (Required) The position of the action in the receipt rule\n\nSNS actions support the following:\n\n* `topic_arn` - (Required) The ARN of an SNS topic to notify\n* `position` - (Required) The position of the action in the receipt rule\n* `encoding` - (Optional) The encoding to use for the email within the Amazon SNS notification. Default value is `UTF-8`.\n\nStop actions support the following:\n\n* `scope` - (Required) The scope to apply\n* `topic_arn` - (Optional) The ARN of an SNS topic to notify\n* `position` - (Required) The position of the action in the receipt rule\n\nWorkMail actions support the following:\n\n* `organization_arn` - (Required) The ARN of the WorkMail organization\n* `topic_arn` - (Optional) The ARN of an SNS topic to notify\n* `position` - (Required) The position of the action in the receipt rule\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The SES receipt rule name.\n* `arn` - The SES receipt rule ARN.\n\n## Import\n\nSES receipt rules can be imported using the ruleset name and rule name separated by `:`.\n\n```\n$ terraform import aws_ses_receipt_rule.my_rule my_rule_set:my_rule\n```\n",
    "basename": "ses_receipt_rule.html"
  },
  "ses_receipt_rule_set.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_receipt_rule_set",
    "description": "Provides an SES receipt rule set resource",
    "preview": "# Resource: aws_ses_receipt_rule_set\n\nProvides an SES receipt rule …",
    "content": "\n\n# Resource: aws_ses_receipt_rule_set\n\nProvides an SES receipt rule set resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_receipt_rule_set\" \"main\" {\n  rule_set_name = \"primary-rules\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `rule_set_name` - (Required) Name of the rule set.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - SES receipt rule set ARN.\n* `id` - SES receipt rule set name.\n\n## Import\n\nSES receipt rule sets can be imported using the rule set name.\n\n```\n$ terraform import aws_ses_receipt_rule_set.my_rule_set my_rule_set_name\n```\n",
    "basename": "ses_receipt_rule_set.html"
  },
  "ses_template.html": {
    "subcategory": "SES",
    "layout": "aws",
    "page_title": "AWS: aws_ses_template",
    "description": "Provides a resource to create a SES template",
    "preview": "# Resource: aws_ses_template\n\nProvides a resource to create a SES …",
    "content": "\n\n# Resource: aws_ses_template\n\nProvides a resource to create a SES template.\n\n## Example Usage\n\n```terraform\nresource \"aws_ses_template\" \"MyTemplate\" {\n  name    = \"MyTemplate\"\n  subject = \"Greetings, {{name}}!\"\n  html    = \"<h1>Hello {{name}},</h1><p>Your favorite animal is {{favoriteanimal}}.</p>\"\n  text    = \"Hello {{name}},\\r\\nYour favorite animal is {{favoriteanimal}}.\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the template. Cannot exceed 64 characters. You will refer to this name when you send email.\n* `html` - (Optional) The HTML body of the email. Must be less than 500KB in size, including both the text and HTML parts.\n* `subject` - (Optional) The subject line of the email.\n* `text` - (Optional) The email body that will be visible to recipients whose email clients do not display HTML. Must be less than 500KB in size, including both the text and HTML parts.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the SES template\n* `id` - The name of the SES template\n\n## Import\n\nSES templates can be imported using the template name, e.g.,\n\n```\n$ terraform import aws_ses_template.MyTemplate MyTemplate\n```\n",
    "basename": "ses_template.html"
  },
  "sfn_activity.html": {
    "subcategory": "Step Function (SFN)",
    "layout": "aws",
    "page_title": "AWS: aws_sfn_activity",
    "description": "Provides a Step Function Activity resource.",
    "preview": "# Resource: aws_sfn_activity\n\nProvides a Step Function Activity …",
    "content": "\n\n# Resource: aws_sfn_activity\n\nProvides a Step Function Activity resource\n\n## Example Usage\n\n```terraform\nresource \"aws_sfn_activity\" \"sfn_activity\" {\n  name = \"my-activity\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the activity to create.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) that identifies the created activity.\n* `name` - The name of the activity.\n* `creation_date` - The date the activity was created.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nActivities can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_sfn_activity.foo arn:aws:states:eu-west-1:123456789098:activity:bar\n```\n",
    "basename": "sfn_activity.html"
  },
  "sfn_state_machine.html": {
    "subcategory": "Step Function (SFN)",
    "layout": "aws",
    "page_title": "AWS: aws_sfn_state_machine",
    "description": "Provides a Step Function State Machine resource.",
    "preview": "# Resource: aws_sfn_state_machine\n\nProvides a Step Function State …",
    "content": "\n\n# Resource: aws_sfn_state_machine\n\nProvides a Step Function State Machine resource\n\n## Example Usage\n### Basic (Standard Workflow)\n\n```terraform\n# ...\n\nresource \"aws_sfn_state_machine\" \"sfn_state_machine\" {\n  name     = \"my-state-machine\"\n  role_arn = aws_iam_role.iam_for_sfn.arn\n\n  definition = <<EOF\n{\n  \"Comment\": \"A Hello World example of the Amazon States Language using an AWS Lambda Function\",\n  \"StartAt\": \"HelloWorld\",\n  \"States\": {\n    \"HelloWorld\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"${aws_lambda_function.lambda.arn}\",\n      \"End\": true\n    }\n  }\n}\nEOF\n}\n```\n\n### Basic (Express Workflow)\n\n```terraform\n# ...\n\nresource \"aws_sfn_state_machine\" \"sfn_state_machine\" {\n  name     = \"my-state-machine\"\n  role_arn = aws_iam_role.iam_for_sfn.arn\n  type     = \"EXPRESS\"\n\n  definition = <<EOF\n{\n  \"Comment\": \"A Hello World example of the Amazon States Language using an AWS Lambda Function\",\n  \"StartAt\": \"HelloWorld\",\n  \"States\": {\n    \"HelloWorld\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"${aws_lambda_function.lambda.arn}\",\n      \"End\": true\n    }\n  }\n}\nEOF\n}\n```\n\n### Logging\n\n~> *NOTE:* See the [AWS Step Functions Developer Guide](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html) for more information about enabling Step Function logging.\n\n```terraform\n# ...\n\nresource \"aws_sfn_state_machine\" \"sfn_state_machine\" {\n  name     = \"my-state-machine\"\n  role_arn = aws_iam_role.iam_for_sfn.arn\n\n  definition = <<EOF\n{\n  \"Comment\": \"A Hello World example of the Amazon States Language using an AWS Lambda Function\",\n  \"StartAt\": \"HelloWorld\",\n  \"States\": {\n    \"HelloWorld\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"${aws_lambda_function.lambda.arn}\",\n      \"End\": true\n    }\n  }\n}\nEOF\n\n  logging_configuration {\n    log_destination        = \"${aws_cloudwatch_log_group.log_group_for_sfn.arn}:*\"\n    include_execution_data = true\n    level                  = \"ERROR\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `definition` - (Required) The [Amazon States Language](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html) definition of the state machine.\n* `logging_configuration` - (Optional) Defines what execution history events are logged and where they are logged. The `logging_configuration` parameter is only valid when `type` is set to `EXPRESS`. Defaults to `OFF`. For more information see [Logging Express Workflows](https://docs.aws.amazon.com/step-functions/latest/dg/cw-logs.html) and [Log Levels](https://docs.aws.amazon.com/step-functions/latest/dg/cloudwatch-log-level.html) in the AWS Step Functions User Guide.\n* `name` - (Required) The name of the state machine. To enable logging with CloudWatch Logs, the name should only contain `0`-`9`, `A`-`Z`, `a`-`z`, `-` and `_`.\n* `role_arn` - (Required) The Amazon Resource Name (ARN) of the IAM role to use for this state machine.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `tracing_configuration` - (Optional) Selects whether AWS X-Ray tracing is enabled.\n* `type` - (Optional) Determines whether a Standard or Express state machine is created. The default is `STANDARD`. You cannot update the type of a state machine once it has been created. Valid values: `STANDARD`, `EXPRESS`.\n\n### `logging_configuration` Configuration Block\n\n* `include_execution_data` - (Optional) Determines whether execution data is included in your log. When set to `false`, data is excluded.\n* `level` - (Optional) Defines which category of execution history events are logged. Valid values: `ALL`, `ERROR`, `FATAL`, `OFF`\n* `log_destination` - (Optional) Amazon Resource Name (ARN) of a CloudWatch log group. Make sure the State Machine has the correct IAM policies for logging. The ARN must end with `:*`\n\n### `tracing_configuration` Configuration Block\n\n* `enabled` - (Optional) When set to `true`, AWS X-Ray tracing is enabled. Make sure the State Machine has the correct IAM policies for logging. See the [AWS Step Functions Developer Guide](https://docs.aws.amazon.com/step-functions/latest/dg/xray-iam.html) for details.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the state machine.\n* `arn` - The ARN of the state machine.\n* `creation_date` - The date the state machine was created.\n* `status` - The current status of the state machine. Either `ACTIVE` or `DELETING`.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nState Machines can be imported using the `arn`, e.g.,\n\n```\n$ terraform import aws_sfn_state_machine.foo arn:aws:states:eu-west-1:123456789098:stateMachine:bar\n```\n",
    "basename": "sfn_state_machine.html"
  },
  "shield_protection.html": {
    "subcategory": "Shield",
    "layout": "aws",
    "page_title": "AWS: aws_shield_protection",
    "description": "Enables AWS Shield Advanced for a specific AWS resource.",
    "preview": "# Resource: aws_shield_protection\n\nEnables AWS Shield Advanced for a …",
    "content": "\n\n# Resource: aws_shield_protection\n\nEnables AWS Shield Advanced for a specific AWS resource.\nThe resource can be an Amazon CloudFront distribution, Elastic Load Balancing load balancer, AWS Global Accelerator accelerator, Elastic IP Address, or an Amazon Route 53 hosted zone.\n\n## Example Usage\n\n### Create protection\n\n```terraform\ndata \"aws_availability_zones\" \"available\" {}\ndata \"aws_region\" \"current\" {}\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_eip\" \"example\" {\n  vpc = true\n}\n\nresource \"aws_shield_protection\" \"example\" {\n  name         = \"example\"\n  resource_arn = \"arn:aws:ec2:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:eip-allocation/${aws_eip.example.id}\"\n\n  tags = {\n    Environment = \"Dev\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A friendly name for the Protection you are creating.\n* `resource_arn` - (Required) The ARN (Amazon Resource Name) of the resource to be protected.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The unique identifier (ID) for the Protection object that is created.\n* `arn` - The ARN of the Protection.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nShield protection resources can be imported by specifying their ID e.g.,\n\n```\n$ terraform import aws_shield_protection.example ff9592dc-22f3-4e88-afa1-7b29fde9669a\n```\n",
    "basename": "shield_protection.html"
  },
  "shield_protection_group.html": {
    "subcategory": "Shield",
    "layout": "aws",
    "page_title": "AWS: aws_shield_protection_group",
    "description": "Creates a grouping of protected resources so they can be handled as a collective.",
    "preview": "# Resource: aws_shield_protection_group\n\nCreates a grouping of …",
    "content": "\n\n# Resource: aws_shield_protection_group\n\nCreates a grouping of protected resources so they can be handled as a collective.\nThis resource grouping improves the accuracy of detection and reduces false positives. For more information see\n[Managing AWS Shield Advanced protection groups](https://docs.aws.amazon.com/waf/latest/developerguide/manage-protection-group.html)\n\n## Example Usage\n\n### Create protection group for all resources\n\n```terraform\nresource \"aws_shield_protection_group\" \"example\" {\n  protection_group_id = \"example\"\n  aggregation         = \"MAX\"\n  pattern             = \"ALL\"\n}\n```\n\n### Create protection group for arbitrary number of resources\n\n```terraform\ndata \"aws_region\" \"current\" {}\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_eip\" \"example\" {\n  vpc = true\n}\n\nresource \"aws_shield_protection\" \"example\" {\n  name         = \"example\"\n  resource_arn = \"arn:aws:ec2:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:eip-allocation/${aws_eip.example.id}\"\n}\n\nresource \"aws_shield_protection_group\" \"example\" {\n  depends_on = [aws_shield_protection.example]\n\n  protection_group_id = \"example\"\n  aggregation         = \"MEAN\"\n  pattern             = \"ARBITRARY\"\n  members             = [\"arn:aws:ec2:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:eip-allocation/${aws_eip.example.id}\"]\n}\n```\n\n### Create protection group for a type of resource\n\n```terraform\nresource \"aws_shield_protection_group\" \"example\" {\n  protection_group_id = \"example\"\n  aggregation         = \"SUM\"\n  pattern             = \"BY_RESOURCE_TYPE\"\n  resource_type       = \"ELASTIC_IP_ALLOCATION\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `aggregation` - (Required) Defines how AWS Shield combines resource data for the group in order to detect, mitigate, and report events.\n* `members` - (Optional) The Amazon Resource Names (ARNs) of the resources to include in the protection group. You must set this when you set `pattern` to ARBITRARY and you must not set it for any other `pattern` setting.\n* `pattern` - (Required) The criteria to use to choose the protected resources for inclusion in the group.\n* `protection_group_id` - (Required) The name of the protection group.\n* `resource_type` - (Optional) The resource type to include in the protection group. You must set this when you set `pattern` to BY_RESOURCE_TYPE and you must not set it for any other `pattern` setting.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `protection_group_arn` - The ARN (Amazon Resource Name) of the protection group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nShield protection group resources can be imported by specifying their protection group id.\n\n```\n$ terraform import aws_shield_protection_group.example example\n```\n",
    "basename": "shield_protection_group.html"
  },
  "signer_signing_job.html": {
    "subcategory": "Signer",
    "layout": "aws",
    "page_title": "AWS: aws_signer_signing_job",
    "description": "Creates a Signer Signing Job.",
    "preview": "# Resource: aws_signer_signing_job\n\nCreates a Signer Signing Job.\n …",
    "content": "\n\n# Resource: aws_signer_signing_job\n\nCreates a Signer Signing Job.\n\n## Example Usage\n\n```terraform\nresource \"aws_signer_signing_profile\" \"test_sp\" {\n  platform_id = \"AWSLambda-SHA384-ECDSA\"\n}\n\nresource \"aws_signer_signing_job\" \"build_signing_job\" {\n  profile_name = aws_signer_signing_profile.test_sp.name\n\n  source {\n    s3 {\n      bucket  = \"s3-bucket-name\"\n      key     = \"object-to-be-signed.zip\"\n      version = \"jADjFYYYEXAMPLETszPjOmCMFDzd9dN1\"\n    }\n  }\n\n  destination {\n    s3 {\n      bucket = \"s3-bucket-name\"\n      prefix = \"signed/\"\n    }\n  }\n\n  ignore_signing_job_failure = true\n}\n```\n\n## Argument Reference\n\n* `profile_name` - (Required) The name of the profile to initiate the signing operation.\n* `source` - (Required) The S3 bucket that contains the object to sign. See [Source](#source) below for details.\n* `destination` - (Required) The S3 bucket in which to save your signed object. See [Destination](#destination) below for details.\n* `ignore_signing_job_failure` - (Optional) Set this argument to `true` to ignore signing job failures and retrieve failed status and reason. Default `false`.\n\n### Source\n\nThe source configuration block supports the following arguments:\n\n* `s3` - (Required) A configuration block describing the S3 Source object: See [S3 Source](#s3-source) below for details.\n\n### S3 Source\n\nThe configuration block supports the following arguments:\n\n* `bucket` - (Required) Name of the S3 bucket.\n* `key` - (Required) Key name of the bucket object that contains your unsigned code.\n* `version` - (Required) Version of your source image in your version enabled S3 bucket.\n\n### Destination\n\nThe destination configuration block supports the following arguments:\n\n* `s3` - (Required) A configuration block describing the S3 Destination object: See [S3 Destination](#s3-destination) below for details.\n\n### S3 Destination\n\nThe configuration block supports the following arguments:\n\n* `bucket` - (Required) Name of the S3 bucket.\n* `prefix` - (Optional) An Amazon S3 object key prefix that you can use to limit signed objects keys to begin with the specified prefix.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `completed_at` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) that the signing job was completed.\n* `created_at` - Date and time in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) that the signing job was created.\n* `job_id` - The ID of the signing job on output.\n* `job_invoker` - The IAM entity that initiated the signing job.\n* `job_owner` - The AWS account ID of the job owner.\n* `platform_display_name` - A human-readable name for the signing platform associated with the signing job.\n* `platform_id` - The platform to which your signed code image will be distributed.\n* `profile_version` - The version of the signing profile used to initiate the signing job.\n* `requested_by` - The IAM principal that requested the signing job.\n* `revocation_record` - A revocation record if the signature generated by the signing job has been revoked. Contains a timestamp and the ID of the IAM entity that revoked the signature.\n* `signature_expires_at` - The time when the signature of a signing job expires.\n* `signed_object` - Name of the S3 bucket where the signed code image is saved by code signing.\n* `status` - Status of the signing job.\n* `status_reason` - String value that contains the status reason.\n\n## Import\n\nSigner signing jobs can be imported using the `job_id`, e.g.,\n\n```\n$ terraform import aws_signer_signing_job.test_signer_signing_job 9ed7e5c3-b8d4-4da0-8459-44e0b068f7ee\n```\n",
    "basename": "signer_signing_job.html"
  },
  "signer_signing_profile.html": {
    "subcategory": "Signer",
    "layout": "aws",
    "page_title": "AWS: aws_signer_signing_profile",
    "description": "Creates a Signer Signing Profile.",
    "preview": "# Resource: aws_signer_signing_profile\n\nCreates a Signer Signing …",
    "content": "\n\n# Resource: aws_signer_signing_profile\n\nCreates a Signer Signing Profile. A signing profile contains information about the code signing configuration parameters that can be used by a given code signing user.\n\n## Example Usage\n\n```terraform\nresource \"aws_signer_signing_profile\" \"test_sp\" {\n  platform_id = \"AWSLambda-SHA384-ECDSA\"\n}\n\nresource \"aws_signer_signing_profile\" \"prod_sp\" {\n  platform_id = \"AWSLambda-SHA384-ECDSA\"\n  name_prefix = \"prod_sp_\"\n\n  signature_validity_period {\n    value = 5\n    type  = \"YEARS\"\n  }\n\n  tags = {\n    tag1 = \"value1\"\n    tag2 = \"value2\"\n  }\n}\n```\n\n## Argument Reference\n\n* `platform_id` - (Required) The ID of the platform that is used by the target signing profile.\n* `name` - (Optional) A unique signing profile name. By default generated by Terraform. Signing profile names are immutable and cannot be reused after canceled.\n* `name_prefix` - (Optional) A signing profile name prefix. Terraform will generate a unique suffix. Conflicts with `name`.\n* `signature_validity_period` - (Optional) The validity period for a signing job.\n* `tags` - (Optional) A list of tags associated with the signing profile. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) for the signing profile.\n* `name` - The name of the target signing profile.\n* `platform_display_name` - A human-readable name for the signing platform associated with the signing profile.\n* `revocation_record` - Revocation information for a signing profile.\n* `status` - The status of the target signing profile.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `version` - The current version of the signing profile.\n* `version_arn` - The signing profile ARN, including the profile version.\n\n## Import\n\nSigner signing profiles can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_signer_signing_profile.test_signer_signing_profile test_sp_DdW3Mk1foYL88fajut4mTVFGpuwfd4ACO6ANL0D1uIj7lrn8adK\n```\n",
    "basename": "signer_signing_profile.html"
  },
  "signer_signing_profile_permission.html": {
    "subcategory": "Signer",
    "layout": "aws",
    "page_title": "AWS: aws_signer_signing_profile_permission",
    "description": "Creates a Signer Signing Profile Permission.",
    "preview": "# Resource: aws_signer_signing_profile_permission\n\nCreates a Signer …",
    "content": "\n\n# Resource: aws_signer_signing_profile_permission\n\nCreates a Signer Signing Profile Permission. That is, a cross-account permission for a signing profile.\n\n## Example Usage\n\n```terraform\nresource \"aws_signer_signing_profile\" \"prod_sp\" {\n  platform_id = \"AWSLambda-SHA384-ECDSA\"\n  name_prefix = \"prod_sp_\"\n\n  signature_validity_period {\n    value = 5\n    type  = \"YEARS\"\n  }\n\n  tags = {\n    tag1 = \"value1\"\n    tag2 = \"value2\"\n  }\n}\n\nresource \"aws_signer_signing_profile_permission\" \"sp_permission_1\" {\n  profile_name = aws_signer_signing_profile.prod_sp.name\n  action       = \"signer:StartSigningJob\"\n  principal    = var.aws_account\n}\n\nresource \"aws_signer_signing_profile_permission\" \"sp_permission_2\" {\n  profile_name = aws_signer_signing_profile.prod_sp.name\n  action       = \"signer:GetSigningProfile\"\n  principal    = var.aws_team_role_arn\n  statement_id = \"ProdAccountStartSigningJob_StatementId\"\n}\n\nresource \"aws_signer_signing_profile_permission\" \"sp_permission_3\" {\n  profile_name        = aws_signer_signing_profile.prod_sp.name\n  action              = \"signer:RevokeSignature\"\n  principal           = \"123456789012\"\n  profile_version     = aws_signer_signing_profile.prod_sp.version\n  statement_id_prefix = \"version-permission-\"\n}\n```\n\n## Argument Reference\n\n* `profile_name` - (Required) Name of the signing profile to add the cross-account permissions.\n* `action` - (Required) An AWS Signer action permitted as part of cross-account permissions. Valid values: `signer:StartSigningJob`, `signer:GetSigningProfile`, or `signer:RevokeSignature`.\n* `principal` - (Required) The AWS principal to be granted a cross-account permission.\n* `profile_version` - (Optional) The signing profile version that a permission applies to.\n* `statement_id` - (Optional) A unique statement identifier. By default generated by Terraform.\n* `statement_id_prefix` - (Optional) A statement identifier prefix. Terraform will generate a unique suffix. Conflicts with `statement_id`.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nSigner signing profile permission statements can be imported using profile_name/statement_id, e.g.,\n\n```\n$ terraform import aws_signer_signing_profile_permission.test_signer_signing_profile_permission prod_profile_DdW3Mk1foYL88fajut4mTVFGpuwfd4ACO6ANL0D1uIj7lrn8adK/ProdAccountStartSigningJobStatementId\n```\n",
    "basename": "signer_signing_profile_permission.html"
  },
  "simpledb_domain.html": {
    "subcategory": "SimpleDB",
    "layout": "aws",
    "page_title": "AWS: aws_simpledb_domain",
    "description": "Provides a SimpleDB domain resource.",
    "preview": "# Resource: aws_simpledb_domain\n\nProvides a SimpleDB domain resource …",
    "content": "\n\n# Resource: aws_simpledb_domain\n\nProvides a SimpleDB domain resource\n\n## Example Usage\n\n```terraform\nresource \"aws_simpledb_domain\" \"users\" {\n  name = \"users\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the SimpleDB domain\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the SimpleDB domain\n\n## Import\n\nSimpleDB Domains can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_simpledb_domain.users users\n```\n",
    "basename": "simpledb_domain.html"
  },
  "snapshot_create_volume_permission.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_snapshot_create_volume_permission",
    "description": "Adds create volume permission to an EBS Snapshot",
    "preview": "# Resource: aws_snapshot_create_volume_permission\n\nAdds permission …",
    "content": "\n\n# Resource: aws_snapshot_create_volume_permission\n\nAdds permission to create volumes off of a given EBS Snapshot.\n\n## Example Usage\n\n```terraform\nresource \"aws_snapshot_create_volume_permission\" \"example_perm\" {\n  snapshot_id = aws_ebs_snapshot.example_snapshot.id\n  account_id  = \"12345678\"\n}\n\nresource \"aws_ebs_volume\" \"example\" {\n  availability_zone = \"us-west-2a\"\n  size              = 40\n}\n\nresource \"aws_ebs_snapshot\" \"example_snapshot\" {\n  volume_id = aws_ebs_volume.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `snapshot_id` - (required) A snapshot ID\n* `account_id` - (required) An AWS Account ID to add create volume permissions\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A combination of \"`snapshot_id`-`account_id`\".\n",
    "basename": "snapshot_create_volume_permission.html"
  },
  "sns_platform_application.html": {
    "subcategory": "SNS",
    "layout": "aws",
    "page_title": "AWS: aws_sns_platform_application",
    "description": "Provides an SNS platform application resource.",
    "preview": "# Resource: aws_sns_platform_application\n\nProvides an SNS platform …",
    "content": "\n\n# Resource: aws_sns_platform_application\n\nProvides an SNS platform application resource\n\n## Example Usage\n\n### Apple Push Notification Service (APNS)\n\n```terraform\nresource \"aws_sns_platform_application\" \"apns_application\" {\n  name                = \"apns_application\"\n  platform            = \"APNS\"\n  platform_credential = \"<APNS PRIVATE KEY>\"\n  platform_principal  = \"<APNS CERTIFICATE>\"\n}\n```\n\n### Google Cloud Messaging (GCM)\n\n```terraform\nresource \"aws_sns_platform_application\" \"gcm_application\" {\n  name                = \"gcm_application\"\n  platform            = \"GCM\"\n  platform_credential = \"<GCM API KEY>\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The friendly name for the SNS platform application\n* `platform` - (Required) The platform that the app is registered with. See [Platform][1] for supported platforms.\n* `platform_credential` - (Required) Application Platform credential. See [Credential][1] for type of credential required for platform. The value of this attribute when stored into the Terraform state is only a hash of the real value, so therefore it is not practical to use this as an attribute for other resources.\n* `event_delivery_failure_topic_arn` - (Optional) SNS Topic triggered when a delivery to any of the platform endpoints associated with your platform application encounters a permanent failure.\n* `event_endpoint_created_topic_arn` - (Optional) SNS Topic triggered when a new platform endpoint is added to your platform application.\n* `event_endpoint_deleted_topic_arn` - (Optional) SNS Topic triggered when an existing platform endpoint is deleted from your platform application.\n* `event_endpoint_updated_topic_arn` - (Optional) SNS Topic triggered when an existing platform endpoint is changed from your platform application.\n* `failure_feedback_role_arn` - (Optional) The IAM role permitted to receive failure feedback for this application.\n* `platform_principal` - (Optional) Application Platform principal. See [Principal][2] for type of principal required for platform. The value of this attribute when stored into the Terraform state is only a hash of the real value, so therefore it is not practical to use this as an attribute for other resources.\n* `success_feedback_role_arn` - (Optional) The IAM role permitted to receive success feedback for this application.\n* `success_feedback_sample_rate` - (Optional) The percentage of success to sample (0-100)\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the SNS platform application\n* `arn` - The ARN of the SNS platform application\n\n[1]: http://docs.aws.amazon.com/sns/latest/dg/mobile-push-send-register.html\n[2]: http://docs.aws.amazon.com/sns/latest/api/API_CreatePlatformApplication.html\n\n## Import\n\nSNS platform applications can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_sns_platform_application.gcm_application arn:aws:sns:us-west-2:0123456789012:app/GCM/gcm_application\n```\n",
    "basename": "sns_platform_application.html"
  },
  "sns_sms_preferences.html": {
    "subcategory": "SNS",
    "layout": "aws",
    "page_title": "AWS: aws_sns_sms_preferences",
    "description": "Provides a way to set SNS SMS preferences.",
    "preview": "# Resource: aws_sns_sms_preferences\n\nProvides a way to set SNS SMS …",
    "content": "\n\n# Resource: aws_sns_sms_preferences\n\nProvides a way to set SNS SMS preferences.\n\n## Example Usage\n\n```terraform\nresource \"aws_sns_sms_preferences\" \"update_sms_prefs\" {}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `monthly_spend_limit` - (Optional) The maximum amount in USD that you are willing to spend each month to send SMS messages.\n* `delivery_status_iam_role_arn` - (Optional) The ARN of the IAM role that allows Amazon SNS to write logs about SMS deliveries in CloudWatch Logs.\n* `delivery_status_success_sampling_rate` - (Optional) The percentage of successful SMS deliveries for which Amazon SNS will write logs in CloudWatch Logs. The value must be between 0 and 100.\n* `default_sender_id` - (Optional) A string, such as your business brand, that is displayed as the sender on the receiving device.\n* `default_sms_type` - (Optional) The type of SMS message that you will send by default. Possible values are: Promotional, Transactional\n* `usage_report_s3_bucket` - (Optional) The name of the Amazon S3 bucket to receive daily SMS usage reports from Amazon SNS.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n",
    "basename": "sns_sms_preferences.html"
  },
  "sns_topic.html": {
    "subcategory": "SNS",
    "layout": "aws",
    "page_title": "AWS: aws_sns_topic",
    "description": "Provides an SNS topic resource.",
    "preview": "# Resource: aws_sns_topic\n\nProvides an SNS topic resource\n\n## …",
    "content": "\n\n# Resource: aws_sns_topic\n\nProvides an SNS topic resource\n\n## Example Usage\n\n```terraform\nresource \"aws_sns_topic\" \"user_updates\" {\n  name = \"user-updates-topic\"\n}\n```\n\n## Example with Delivery Policy\n\n```hcl\nresource \"aws_sns_topic\" \"user_updates\" {\n  name            = \"user-updates-topic\"\n  delivery_policy = <<EOF\n{\n  \"http\": {\n    \"defaultHealthyRetryPolicy\": {\n      \"minDelayTarget\": 20,\n      \"maxDelayTarget\": 20,\n      \"numRetries\": 3,\n      \"numMaxDelayRetries\": 0,\n      \"numNoDelayRetries\": 0,\n      \"numMinDelayRetries\": 0,\n      \"backoffFunction\": \"linear\"\n    },\n    \"disableSubscriptionOverrides\": false,\n    \"defaultThrottlePolicy\": {\n      \"maxReceivesPerSecond\": 1\n    }\n  }\n}\nEOF\n}\n```\n\n## Example with Server-side encryption (SSE)\n\n```terraform\nresource \"aws_sns_topic\" \"user_updates\" {\n  name              = \"user-updates-topic\"\n  kms_master_key_id = \"alias/aws/sns\"\n}\n```\n\n## Example with First-In-First-Out (FIFO)\n\n```hcl\nresource \"aws_sns_topic\" \"user_updates\" {\n  name                        = \"user-updates-topic.fifo\"\n  fifo_topic                  = true\n  content_based_deduplication = true\n}\n```\n\n## Message Delivery Status Arguments\n\nThe `<endpoint>_success_feedback_role_arn` and `<endpoint>_failure_feedback_role_arn` arguments are used to give Amazon SNS write access to use CloudWatch Logs on your behalf. The `<endpoint>_success_feedback_sample_rate` argument is for specifying the sample rate percentage (0-100) of successfully delivered messages. After you configure the  `<endpoint>_failure_feedback_role_arn` argument, then all failed message deliveries generate CloudWatch Logs.\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the topic. Topic names must be made up of only uppercase and lowercase ASCII letters, numbers, underscores, and hyphens, and must be between 1 and 256 characters long. For a FIFO (first-in-first-out) topic, the name must end with the `.fifo` suffix. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`\n* `display_name` - (Optional) The display name for the topic\n* `policy` - (Optional) The fully-formed AWS policy as JSON. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `delivery_policy` - (Optional) The SNS delivery policy. More on [AWS documentation](https://docs.aws.amazon.com/sns/latest/dg/DeliveryPolicies.html)\n* `application_success_feedback_role_arn` - (Optional) The IAM role permitted to receive success feedback for this topic\n* `application_success_feedback_sample_rate` - (Optional) Percentage of success to sample\n* `application_failure_feedback_role_arn` - (Optional) IAM role for failure feedback\n* `http_success_feedback_role_arn` - (Optional) The IAM role permitted to receive success feedback for this topic\n* `http_success_feedback_sample_rate` - (Optional) Percentage of success to sample\n* `http_failure_feedback_role_arn` - (Optional) IAM role for failure feedback\n* `kms_master_key_id` - (Optional) The ID of an AWS-managed customer master key (CMK) for Amazon SNS or a custom CMK. For more information, see [Key Terms](https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html#sse-key-terms)\n* `fifo_topic` - (Optional) Boolean indicating whether or not to create a FIFO (first-in-first-out) topic (default is `false`).\n* `content_based_deduplication` - (Optional) Enables content-based deduplication for FIFO topics. For more information, see the [related documentation](https://docs.aws.amazon.com/sns/latest/dg/fifo-message-dedup.html)\n* `lambda_success_feedback_role_arn` - (Optional) The IAM role permitted to receive success feedback for this topic\n* `lambda_success_feedback_sample_rate` - (Optional) Percentage of success to sample\n* `lambda_failure_feedback_role_arn` - (Optional) IAM role for failure feedback\n* `sqs_success_feedback_role_arn` - (Optional) The IAM role permitted to receive success feedback for this topic\n* `sqs_success_feedback_sample_rate` - (Optional) Percentage of success to sample\n* `sqs_failure_feedback_role_arn` - (Optional) IAM role for failure feedback\n* `firehose_success_feedback_role_arn` - (Optional) The IAM role permitted to receive success feedback for this topic\n* `firehose_success_feedback_sample_rate` - (Optional) Percentage of success to sample\n* `firehose_failure_feedback_role_arn` - (Optional) IAM role for failure feedback\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the SNS topic\n* `arn` - The ARN of the SNS topic, as a more obvious property (clone of id)\n* `owner` - The AWS Account ID of the SNS topic owner\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSNS Topics can be imported using the `topic arn`, e.g.,\n\n```\n$ terraform import aws_sns_topic.user_updates arn:aws:sns:us-west-2:0123456789012:my-topic\n```\n",
    "basename": "sns_topic.html"
  },
  "sns_topic_policy.html": {
    "subcategory": "SNS",
    "layout": "aws",
    "page_title": "AWS: aws_sns_topic_policy",
    "description": "Provides an SNS topic policy resource.",
    "preview": "# Resource: aws_sns_topic_policy\n\nProvides an SNS topic policy …",
    "content": "\n\n# Resource: aws_sns_topic_policy\n\nProvides an SNS topic policy resource\n\n~> **NOTE:** If a Principal is specified as just an AWS account ID rather than an ARN, AWS silently converts it to the ARN for the root user, causing future terraform plans to differ. To avoid this problem, just specify the full ARN, e.g., `arn:aws:iam::123456789012:root`\n\n## Example Usage\n\n```terraform\nresource \"aws_sns_topic\" \"test\" {\n  name = \"my-topic-with-policy\"\n}\n\nresource \"aws_sns_topic_policy\" \"default\" {\n  arn = aws_sns_topic.test.arn\n\n  policy = data.aws_iam_policy_document.sns_topic_policy.json\n}\n\ndata \"aws_iam_policy_document\" \"sns_topic_policy\" {\n  policy_id = \"__default_policy_ID\"\n\n  statement {\n    actions = [\n      \"SNS:Subscribe\",\n      \"SNS:SetTopicAttributes\",\n      \"SNS:RemovePermission\",\n      \"SNS:Receive\",\n      \"SNS:Publish\",\n      \"SNS:ListSubscriptionsByTopic\",\n      \"SNS:GetTopicAttributes\",\n      \"SNS:DeleteTopic\",\n      \"SNS:AddPermission\",\n    ]\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"AWS:SourceOwner\"\n\n      values = [\n        var.account-id,\n      ]\n    }\n\n    effect = \"Allow\"\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"*\"]\n    }\n\n    resources = [\n      aws_sns_topic.test.arn,\n    ]\n\n    sid = \"__default_statement_ID\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `arn` - (Required) The ARN of the SNS topic\n* `policy` - (Required) The fully-formed AWS policy as JSON. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `owner` - The AWS Account ID of the SNS topic owner\n\n## Import\n\nSNS Topic Policy can be imported using the topic ARN, e.g.,\n\n```\n$ terraform import aws_sns_topic_policy.user_updates arn:aws:sns:us-west-2:0123456789012:my-topic\n```\n\n",
    "basename": "sns_topic_policy.html"
  },
  "sns_topic_subscription.html": {
    "subcategory": "SNS",
    "layout": "aws",
    "page_title": "AWS: aws_sns_topic_subscription",
    "description": "Provides a resource for subscribing to SNS topics.",
    "preview": "# Resource: aws_sns_topic_subscription\n\nProvides a resource for …",
    "content": "\n\n# Resource: aws_sns_topic_subscription\n\nProvides a resource for subscribing to SNS topics. Requires that an SNS topic exist for the subscription to attach to. This resource allows you to automatically place messages sent to SNS topics in SQS queues, send them as HTTP(S) POST requests to a given endpoint, send SMS messages, or notify devices / applications. The most likely use case for Terraform users will probably be SQS queues.\n\n~> **NOTE:** If the SNS topic and SQS queue are in different AWS regions, the `aws_sns_topic_subscription` must use an AWS provider that is in the same region as the SNS topic. If the `aws_sns_topic_subscription` uses a provider with a different region than the SNS topic, Terraform will fail to create the subscription.\n\n~> **NOTE:** Setup of cross-account subscriptions from SNS topics to SQS queues requires Terraform to have access to BOTH accounts.\n\n~> **NOTE:** If an SNS topic and SQS queue are in different AWS accounts but the same region, the `aws_sns_topic_subscription` must use the AWS provider for the account with the SQS queue. If `aws_sns_topic_subscription` uses a Provider with a different account than the SQS queue, Terraform creates the subscription but does not keep state and tries to re-create the subscription at every `apply`.\n\n~> **NOTE:** If an SNS topic and SQS queue are in different AWS accounts and different AWS regions, the subscription needs to be initiated from the account with the SQS queue but in the region of the SNS topic.\n\n~> **NOTE:** You cannot unsubscribe to a subscription that is pending confirmation. If you use `email`, `email-json`, or `http`/`https` (without auto-confirmation enabled), until the subscription is confirmed (e.g., outside of Terraform), AWS does not allow Terraform to delete / unsubscribe the subscription. If you `destroy` an unconfirmed subscription, Terraform will remove the subscription from its state but the subscription will still exist in AWS. However, if you delete an SNS topic, SNS [deletes all the subscriptions](https://docs.aws.amazon.com/sns/latest/dg/sns-delete-subscription-topic.html) associated with the topic. Also, you can import a subscription after confirmation and then have the capability to delete it.\n\n## Example Usage\n\nYou can directly supply a topic and ARN by hand in the `topic_arn` property along with the queue ARN:\n\n```terraform\nresource \"aws_sns_topic_subscription\" \"user_updates_sqs_target\" {\n  topic_arn = \"arn:aws:sns:us-west-2:432981146916:user-updates-topic\"\n  protocol  = \"sqs\"\n  endpoint  = \"arn:aws:sqs:us-west-2:432981146916:terraform-queue-too\"\n}\n```\n\nAlternatively you can use the ARN properties of a managed SNS topic and SQS queue:\n\n```terraform\nresource \"aws_sns_topic\" \"user_updates\" {\n  name = \"user-updates-topic\"\n}\n\nresource \"aws_sqs_queue\" \"user_updates_queue\" {\n  name = \"user-updates-queue\"\n}\n\nresource \"aws_sns_topic_subscription\" \"user_updates_sqs_target\" {\n  topic_arn = aws_sns_topic.user_updates.arn\n  protocol  = \"sqs\"\n  endpoint  = aws_sqs_queue.user_updates_queue.arn\n}\n```\n\nYou can subscribe SNS topics to SQS queues in different Amazon accounts and regions:\n\n```terraform\nvariable \"sns\" {\n  default = {\n    account-id   = \"111111111111\"\n    role-name    = \"service/service-hashicorp-terraform\"\n    name         = \"example-sns-topic\"\n    display_name = \"example\"\n    region       = \"us-west-1\"\n  }\n}\n\nvariable \"sqs\" {\n  default = {\n    account-id = \"222222222222\"\n    role-name  = \"service/service-hashicorp-terraform\"\n    name       = \"example-sqs-queue\"\n    region     = \"us-east-1\"\n  }\n}\n\ndata \"aws_iam_policy_document\" \"sns-topic-policy\" {\n  policy_id = \"__default_policy_ID\"\n\n  statement {\n    actions = [\n      \"SNS:Subscribe\",\n      \"SNS:SetTopicAttributes\",\n      \"SNS:RemovePermission\",\n      \"SNS:Publish\",\n      \"SNS:ListSubscriptionsByTopic\",\n      \"SNS:GetTopicAttributes\",\n      \"SNS:DeleteTopic\",\n      \"SNS:AddPermission\",\n    ]\n\n    condition {\n      test     = \"StringEquals\"\n      variable = \"AWS:SourceOwner\"\n\n      values = [\n        var.sns[\"account-id\"],\n      ]\n    }\n\n    effect = \"Allow\"\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"*\"]\n    }\n\n    resources = [\n      \"arn:aws:sns:${var.sns[\"region\"]}:${var.sns[\"account-id\"]}:${var.sns[\"name\"]}\",\n    ]\n\n    sid = \"__default_statement_ID\"\n  }\n\n  statement {\n    actions = [\n      \"SNS:Subscribe\",\n      \"SNS:Receive\",\n    ]\n\n    condition {\n      test     = \"StringLike\"\n      variable = \"SNS:Endpoint\"\n\n      values = [\n        \"arn:aws:sqs:${var.sqs[\"region\"]}:${var.sqs[\"account-id\"]}:${var.sqs[\"name\"]}\",\n      ]\n    }\n\n    effect = \"Allow\"\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"*\"]\n    }\n\n    resources = [\n      \"arn:aws:sns:${var.sns[\"region\"]}:${var.sns[\"account-id\"]}:${var.sns[\"name\"]}\",\n    ]\n\n    sid = \"__console_sub_0\"\n  }\n}\n\ndata \"aws_iam_policy_document\" \"sqs-queue-policy\" {\n  policy_id = \"arn:aws:sqs:${var.sqs[\"region\"]}:${var.sqs[\"account-id\"]}:${var.sqs[\"name\"]}/SQSDefaultPolicy\"\n\n  statement {\n    sid    = \"example-sns-topic\"\n    effect = \"Allow\"\n\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"*\"]\n    }\n\n    actions = [\n      \"SQS:SendMessage\",\n    ]\n\n    resources = [\n      \"arn:aws:sqs:${var.sqs[\"region\"]}:${var.sqs[\"account-id\"]}:${var.sqs[\"name\"]}\",\n    ]\n\n    condition {\n      test     = \"ArnEquals\"\n      variable = \"aws:SourceArn\"\n\n      values = [\n        \"arn:aws:sns:${var.sns[\"region\"]}:${var.sns[\"account-id\"]}:${var.sns[\"name\"]}\",\n      ]\n    }\n  }\n}\n\n# provider to manage SNS topics\nprovider \"aws\" {\n  alias  = \"sns\"\n  region = var.sns[\"region\"]\n\n  assume_role {\n    role_arn     = \"arn:aws:iam::${var.sns[\"account-id\"]}:role/${var.sns[\"role-name\"]}\"\n    session_name = \"sns-${var.sns[\"region\"]}\"\n  }\n}\n\n# provider to manage SQS queues\nprovider \"aws\" {\n  alias  = \"sqs\"\n  region = var.sqs[\"region\"]\n\n  assume_role {\n    role_arn     = \"arn:aws:iam::${var.sqs[\"account-id\"]}:role/${var.sqs[\"role-name\"]}\"\n    session_name = \"sqs-${var.sqs[\"region\"]}\"\n  }\n}\n\n# provider to subscribe SQS to SNS (using the SQS account but the SNS region)\nprovider \"aws\" {\n  alias  = \"sns2sqs\"\n  region = var.sns[\"region\"]\n\n  assume_role {\n    role_arn     = \"arn:aws:iam::${var.sqs[\"account-id\"]}:role/${var.sqs[\"role-name\"]}\"\n    session_name = \"sns2sqs-${var.sns[\"region\"]}\"\n  }\n}\n\nresource \"aws_sns_topic\" \"sns-topic\" {\n  provider     = \"aws.sns\"\n  name         = var.sns[\"name\"]\n  display_name = var.sns[\"display_name\"]\n  policy       = data.aws_iam_policy_document.sns-topic-policy.json\n}\n\nresource \"aws_sqs_queue\" \"sqs-queue\" {\n  provider = \"aws.sqs\"\n  name     = var.sqs[\"name\"]\n  policy   = data.aws_iam_policy_document.sqs-queue-policy.json\n}\n\nresource \"aws_sns_topic_subscription\" \"sns-topic\" {\n  provider  = \"aws.sns2sqs\"\n  topic_arn = aws_sns_topic.sns-topic.arn\n  protocol  = \"sqs\"\n  endpoint  = aws_sqs_queue.sqs-queue.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `endpoint` - (Required) Endpoint to send data to. The contents vary with the protocol. See details below.\n* `protocol` - (Required) Protocol to use. Valid values are: `sqs`, `sms`, `lambda`, `firehose`, and `application`. Protocols `email`, `email-json`, `http` and `https` are also valid but partially supported. See details below.\n* `subscription_role_arn` - (Required if `protocol` is `firehose`) ARN of the IAM role to publish to Kinesis Data Firehose delivery stream. Refer to [SNS docs](https://docs.aws.amazon.com/sns/latest/dg/sns-firehose-as-subscriber.html).\n* `topic_arn` - (Required) ARN of the SNS topic to subscribe to.\n\nThe following arguments are optional:\n\n* `confirmation_timeout_in_minutes` - (Optional) Integer indicating number of minutes to wait in retrying mode for fetching subscription arn before marking it as failure. Only applicable for http and https protocols. Default is `1`.\n* `delivery_policy` - (Optional) JSON String with the delivery policy (retries, backoff, etc.) that will be used in the subscription - this only applies to HTTP/S subscriptions. Refer to the [SNS docs](https://docs.aws.amazon.com/sns/latest/dg/DeliveryPolicies.html) for more details.\n* `endpoint_auto_confirms` - (Optional) Whether the endpoint is capable of [auto confirming subscription](http://docs.aws.amazon.com/sns/latest/dg/SendMessageToHttp.html#SendMessageToHttp.prepare) (e.g., PagerDuty). Default is `false`.\n* `filter_policy` - (Optional) JSON String with the filter policy that will be used in the subscription to filter messages seen by the target resource. Refer to the [SNS docs](https://docs.aws.amazon.com/sns/latest/dg/message-filtering.html) for more details.\n* `raw_message_delivery` - (Optional) Whether to enable raw message delivery (the original message is directly passed, not wrapped in JSON with the original message in the message property). Default is `false`.\n* `redrive_policy` - (Optional) JSON String with the redrive policy that will be used in the subscription. Refer to the [SNS docs](https://docs.aws.amazon.com/sns/latest/dg/sns-dead-letter-queues.html#how-messages-moved-into-dead-letter-queue) for more details.\n\n### Protocol support\n\nSupported values for `protocol` include:\n\n* `application` - Delivers JSON-encoded messages. `endpoint` is the endpoint ARN of a mobile app and device.\n* `firehose` - Delivers JSON-encoded messages. `endpoint` is the ARN of an Amazon Kinesis Data Firehose delivery stream (e.g.,\n`arn:aws:firehose:us-east-1:123456789012:deliverystream/ticketUploadStream`).\n* `lambda` - Delivers JSON-encoded messages. `endpoint` is the ARN of an AWS Lambda function.\n* `sms` - Delivers text messages via SMS. `endpoint` is the phone number of an SMS-enabled device.\n* `sqs` - Delivers JSON-encoded messages. `endpoint` is the ARN of an Amazon SQS queue (e.g., `arn:aws:sqs:us-west-2:123456789012:terraform-queue-too`).\n\nPartially supported values for `protocol` include:\n\n~> **NOTE:** If an `aws_sns_topic_subscription` uses a partially-supported protocol and the subscription is not confirmed, either through automatic confirmation or means outside of Terraform (e.g., clicking on a \"Confirm Subscription\" link in an email), Terraform cannot delete / unsubscribe the subscription. Attempting to `destroy` an unconfirmed subscription will remove the `aws_sns_topic_subscription` from Terraform's state but **_will not_** remove the subscription from AWS. The `pending_confirmation` attribute provides confirmation status.\n\n* `email` - Delivers messages via SMTP. `endpoint` is an email address.\n* `email-json` - Delivers JSON-encoded messages via SMTP. `endpoint` is an email address.\n* `http` -- Delivers JSON-encoded messages via HTTP POST. `endpoint` is a URL beginning with `http://`.\n* `https` -- Delivers JSON-encoded messages via HTTPS POST. `endpoint` is a URL beginning with `https://`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - ARN of the subscription.\n* `confirmation_was_authenticated` - Whether the subscription confirmation request was authenticated.\n* `id` - ARN of the subscription.\n* `owner_id` - AWS account ID of the subscription's owner.\n* `pending_confirmation` - Whether the subscription has not been confirmed.\n\n## Import\n\nSNS Topic Subscriptions can be imported using the `subscription arn`, e.g.,\n\n```\n$ terraform import aws_sns_topic_subscription.user_updates_sqs_target arn:aws:sns:us-west-2:0123456789012:my-topic:8a21d249-4329-4871-acc6-7be709c6ea7f\n```\n",
    "basename": "sns_topic_subscription.html"
  },
  "spot_datafeed_subscription.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_spot_datafeed_subscription",
    "description": "Provides a Spot Datafeed Subscription resource.",
    "preview": "# Resource: aws_spot_datafeed_subscription\n\n-> **Note:** There is …",
    "content": "\n\n# Resource: aws_spot_datafeed_subscription\n\n-> **Note:** There is only a single subscription allowed per account.\n\nTo help you understand the charges for your Spot instances, Amazon EC2 provides a data feed that describes your Spot instance usage and pricing.\nThis data feed is sent to an Amazon S3 bucket that you specify when you subscribe to the data feed.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"default\" {\n  bucket = \"tf-spot-datafeed\"\n}\n\nresource \"aws_spot_datafeed_subscription\" \"default\" {\n  bucket = aws_s3_bucket.default.bucket\n  prefix = \"my_subdirectory\"\n}\n```\n\n## Argument Reference\n\n* `bucket` - (Required) The Amazon S3 bucket in which to store the Spot instance data feed.\n* `prefix` - (Optional) Path of folder inside bucket to place spot pricing data.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nA Spot Datafeed Subscription can be imported using the word `spot-datafeed-subscription`, e.g.,\n\n```\n$ terraform import aws_spot_datafeed_subscription.mysubscription spot-datafeed-subscription\n```\n",
    "basename": "spot_datafeed_subscription.html"
  },
  "spot_fleet_request.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_spot_fleet_request",
    "description": "Provides a Spot Fleet Request resource.",
    "preview": "# Resource: aws_spot_fleet_request\n\nProvides an EC2 Spot Fleet …",
    "content": "\n\n# Resource: aws_spot_fleet_request\n\nProvides an EC2 Spot Fleet Request resource. This allows a fleet of Spot\ninstances to be requested on the Spot market.\n\n## Example Usage\n\n### Using launch specifications\n\n```terraform\n# Request a Spot fleet\nresource \"aws_spot_fleet_request\" \"cheap_compute\" {\n  iam_fleet_role      = \"arn:aws:iam::12345678:role/spot-fleet\"\n  spot_price          = \"0.03\"\n  allocation_strategy = \"diversified\"\n  target_capacity     = 6\n  valid_until         = \"2019-11-04T20:44:20Z\"\n\n  launch_specification {\n    instance_type            = \"m4.10xlarge\"\n    ami                      = \"ami-1234\"\n    spot_price               = \"2.793\"\n    placement_tenancy        = \"dedicated\"\n    iam_instance_profile_arn = aws_iam_instance_profile.example.arn\n  }\n\n  launch_specification {\n    instance_type            = \"m4.4xlarge\"\n    ami                      = \"ami-5678\"\n    key_name                 = \"my-key\"\n    spot_price               = \"1.117\"\n    iam_instance_profile_arn = aws_iam_instance_profile.example.arn\n    availability_zone        = \"us-west-1a\"\n    subnet_id                = \"subnet-1234\"\n    weighted_capacity        = 35\n\n    root_block_device {\n      volume_size = \"300\"\n      volume_type = \"gp2\"\n    }\n\n    tags = {\n      Name = \"spot-fleet-example\"\n    }\n  }\n}\n```\n\n### Using launch templates\n\n```terraform\nresource \"aws_launch_template\" \"foo\" {\n  name          = \"launch-template\"\n  image_id      = \"ami-516b9131\"\n  instance_type = \"m1.small\"\n  key_name      = \"some-key\"\n}\n\nresource \"aws_spot_fleet_request\" \"foo\" {\n  iam_fleet_role  = \"arn:aws:iam::12345678:role/spot-fleet\"\n  spot_price      = \"0.005\"\n  target_capacity = 2\n  valid_until     = \"2019-11-04T20:44:20Z\"\n\n  launch_template_config {\n    launch_template_specification {\n      id      = aws_launch_template.foo.id\n      version = aws_launch_template.foo.latest_version\n    }\n  }\n\n  depends_on = [aws_iam_policy_attachment.test-attach]\n}\n```\n\n~> **NOTE:** Terraform does not support the functionality where multiple `subnet_id` or `availability_zone` parameters can be specified in the same\nlaunch configuration block. If you want to specify multiple values, then separate launch configuration blocks should be used or launch template overrides should be configured, one per subnet:\n\n### Using multiple launch specifications\n\n```terraform\nresource \"aws_spot_fleet_request\" \"foo\" {\n  iam_fleet_role  = \"arn:aws:iam::12345678:role/spot-fleet\"\n  spot_price      = \"0.005\"\n  target_capacity = 2\n  valid_until     = \"2019-11-04T20:44:20Z\"\n\n  launch_specification {\n    instance_type     = \"m1.small\"\n    ami               = \"ami-d06a90b0\"\n    key_name          = \"my-key\"\n    availability_zone = \"us-west-2a\"\n  }\n\n  launch_specification {\n    instance_type     = \"m5.large\"\n    ami               = \"ami-d06a90b0\"\n    key_name          = \"my-key\"\n    availability_zone = \"us-west-2a\"\n  }\n}\n```\n\n\n### Using multiple launch configurations\n\n```terraform\ndata \"aws_subnet_ids\" \"example\" {\n  vpc_id = var.vpc_id\n}\n\nresource \"aws_launch_template\" \"foo\" {\n  name          = \"launch-template\"\n  image_id      = \"ami-516b9131\"\n  instance_type = \"m1.small\"\n  key_name      = \"some-key\"\n}\n\nresource \"aws_spot_fleet_request\" \"foo\" {\n  iam_fleet_role  = \"arn:aws:iam::12345678:role/spot-fleet\"\n  spot_price      = \"0.005\"\n  target_capacity = 2\n  valid_until     = \"2019-11-04T20:44:20Z\"\n\n  launch_template_config {\n    launch_template_specification {\n      id      = aws_launch_template.foo.id\n      version = aws_launch_template.foo.latest_version\n    }\n    overrides {\n      subnet_id = data.aws_subnets.example.ids[0]\n    }\n    overrides {\n      subnet_id = data.aws_subnets.example.ids[1]\n    }\n    overrides {\n      subnet_id = data.aws_subnets.example.ids[2]\n    }\n  }\n\n  depends_on = [aws_iam_policy_attachment.test-attach]\n}\n```\n\n## Argument Reference\n\nMost of these arguments directly correspond to the\n[official API](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_SpotFleetRequestConfigData.html).\n\n* `iam_fleet_role` - (Required) Grants the Spot fleet permission to terminate\n  Spot instances on your behalf when you cancel its Spot fleet request using\nCancelSpotFleetRequests or when the Spot fleet request expires, if you set\nterminateInstancesWithExpiration.\n* `replace_unhealthy_instances` - (Optional) Indicates whether Spot fleet should replace unhealthy instances. Default `false`.\n* `launch_specification` - (Optional) Used to define the launch configuration of the\n  spot-fleet request. Can be specified multiple times to define different bids\nacross different markets and instance types. Conflicts with `launch_template_config`. At least one of `launch_specification` or `launch_template_config` is required.\n\n    **Note:** This takes in similar but not\n    identical inputs as [`aws_instance`](instance.html).  There are limitations on\n    what you can specify. See the list of officially supported inputs in the\n    [reference documentation](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_SpotFleetLaunchSpecification.html). Any normal [`aws_instance`](instance.html) parameter that corresponds to those inputs may be used and it have\n    a additional parameter `iam_instance_profile_arn` takes `aws_iam_instance_profile` attribute `arn` as input.\n\n* `launch_template_config` - (Optional) Launch template configuration block. See [Launch Template Configs](#launch-template-configs) below for more details. Conflicts with `launch_specification`. At least one of `launch_specification` or `launch_template_config` is required.\n* `spot_maintenance_strategies` - (Optional) Nested argument containing maintenance strategies for managing your Spot Instances that are at an elevated risk of being interrupted. Defined below.\n* `spot_price` - (Optional; Default: On-demand price) The maximum bid price per unit hour.\n* `wait_for_fulfillment` - (Optional; Default: false) If set, Terraform will\n  wait for the Spot Request to be fulfilled, and will throw an error if the\n  timeout of 10m is reached.\n* `target_capacity` - The number of units to request. You can choose to set the\n  target capacity in terms of instances or a performance characteristic that is\n  important to your application workload, such as vCPUs, memory, or I/O.\n* `allocation_strategy` - Indicates how to allocate the target capacity across\n  the Spot pools specified by the Spot fleet request. The default is\n  `lowestPrice`.\n* `instance_pools_to_use_count` - (Optional; Default: 1)\n  The number of Spot pools across which to allocate your target Spot capacity.\n  Valid only when `allocation_strategy` is set to `lowestPrice`. Spot Fleet selects\n  the cheapest Spot pools and evenly allocates your target Spot capacity across\n  the number of Spot pools that you specify.\n* `excess_capacity_termination_policy` - Indicates whether running Spot\n  instances should be terminated if the target capacity of the Spot fleet\n  request is decreased below the current size of the Spot fleet.\n* `terminate_instances_with_expiration` - Indicates whether running Spot\n  instances should be terminated when the Spot fleet request expires.\n* `instance_interruption_behaviour` - (Optional) Indicates whether a Spot\n  instance stops or terminates when it is interrupted. Default is\n  `terminate`.\n* `fleet_type` - (Optional) The type of fleet request. Indicates whether the Spot Fleet only requests the target\n  capacity or also attempts to maintain it. Default is `maintain`.\n* `valid_until` - (Optional) The end date and time of the request, in UTC [RFC3339](https://tools.ietf.org/html/rfc3339#section-5.8) format(for example, YYYY-MM-DDTHH:MM:SSZ). At this point, no new Spot instance requests are placed or enabled to fulfill the request.\n* `valid_from` - (Optional) The start date and time of the request, in UTC [RFC3339](https://tools.ietf.org/html/rfc3339#section-5.8) format(for example, YYYY-MM-DDTHH:MM:SSZ). The default is to start fulfilling the request immediately.\n* `load_balancers` (Optional) A list of elastic load balancer names to add to the Spot fleet.\n* `target_group_arns` (Optional) A list of `aws_alb_target_group` ARNs, for use with Application Load Balancing.\n* `on_demand_allocation_strategy` - The order of the launch template overrides to use in fulfilling On-Demand capacity. the possible values are: `lowestPrice` and `prioritized`. the default is `lowestPrice`.\n* `on_demand_max_total_price` - The maximum amount per hour for On-Demand Instances that you're willing to pay. When the maximum amount you're willing to pay is reached, the fleet stops launching instances even if it hasn’t met the target capacity.\n* `on_demand_target_capacity` - The number of On-Demand units to request. If the request type is `maintain`, you can specify a target capacity of 0 and add capacity later.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Launch Template Configs\n\nThe `launch_template_config` block supports the following:\n\n* `launch_template_specification` - (Required) Launch template specification. See [Launch Template Specification](#launch-template-specification) below for more details.\n* `overrides` - (Optional) One or more override configurations. See [Overrides](#overrides) below for more details.\n\n### Launch Template Specification\n\n* `id` - The ID of the launch template. Conflicts with `name`.\n* `name` - The name of the launch template. Conflicts with `id`.\n* `version` - (Optional) Template version. Unlike the autoscaling equivalent, does not support `$Latest` or `$Default`, so use the launch_template resource's attribute, e.g., `\"${aws_launch_template.foo.latest_version}\"`. It will use the default version if omitted.\n\n    **Note:** The specified launch template can specify only a subset of the\n    inputs of [`aws_launch_template`](launch_template.html).  There are limitations on\n    what you can specify as spot fleet does not support all the attributes that are supported by autoscaling groups. [AWS documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html#launch-templates-spot-fleet) is currently sparse, but at least `instance_initiated_shutdown_behavior` is confirmed unsupported.\n\n### spot_maintenance_strategies\n\n* `capacity_rebalance` - (Optional) Nested argument containing the capacity rebalance for your fleet request. Defined below.\n\n### capacity_rebalance\n\n* `replacement_strategy` - (Optional) The replacement strategy to use. Only available for spot fleets with `fleet_type` set to `maintain`. Valid values: `launch`.\n\n\n### Overrides\n\n* `availability_zone` - (Optional) The availability zone in which to place the request.\n* `instance_type` - (Optional) The type of instance to request.\n* `priority` - (Optional) The priority for the launch template override. The lower the number, the higher the priority. If no number is set, the launch template override has the lowest priority.\n* `spot_price` - (Optional) The maximum spot bid for this override request.\n* `subnet_id` - (Optional) The subnet in which to launch the requested instance.\n* `weighted_capacity` - (Optional) The capacity added to the fleet by a fulfilled request.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 10 mins) Used when requesting the spot instance (only valid if `wait_for_fulfillment = true`)\n* `delete` - (Defaults to 15 mins) Used when destroying the spot instance\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Spot fleet request ID\n* `spot_request_state` - The state of the Spot fleet request.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSpot Fleet Requests can be imported using `id`, e.g.,\n\n```\n$ terraform import aws_spot_fleet_request.fleet sfr-005e9ec8-5546-4c31-b317-31a62325411e\n```\n",
    "basename": "spot_fleet_request.html"
  },
  "spot_instance_request.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_spot_instance_request",
    "description": "Provides a Spot Instance Request resource.",
    "preview": "# Resource: aws_spot_instance_request\n\nProvides an EC2 Spot Instance …",
    "content": "\n\n# Resource: aws_spot_instance_request\n\nProvides an EC2 Spot Instance Request resource. This allows instances to be\nrequested on the spot market.\n\nBy default Terraform creates Spot Instance Requests with a `persistent` type,\nwhich means that for the duration of their lifetime, AWS will launch an\ninstance with the configured details if and when the spot market will accept\nthe requested price.\n\nOn destruction, Terraform will make an attempt to terminate the associated Spot\nInstance if there is one present.\n\nSpot Instances requests with a `one-time` type will close the spot request\nwhen the instance is terminated either by the request being below the current spot\nprice availability or by a user.\n\n~> **NOTE:** Because their behavior depends on the live status of the spot\nmarket, Spot Instance Requests have a unique lifecycle that makes them behave\ndifferently than other Terraform resources. Most importantly: there is __no\nguarantee__ that a Spot Instance exists to fulfill the request at any given\npoint in time. See the [AWS Spot Instance\ndocumentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html)\nfor more information.\n\n\n## Example Usage\n\n```terraform\n# Request a spot instance at $0.03\nresource \"aws_spot_instance_request\" \"cheap_worker\" {\n  ami           = \"ami-1234\"\n  spot_price    = \"0.03\"\n  instance_type = \"c4.xlarge\"\n\n  tags = {\n    Name = \"CheapWorker\"\n  }\n}\n```\n\n## Argument Reference\n\nSpot Instance Requests support all the same arguments as\n[`aws_instance`](instance.html), with the addition of:\n\n* `spot_price` - (Optional; Default: On-demand price) The maximum price to request on the spot market.\n* `wait_for_fulfillment` - (Optional; Default: false) If set, Terraform will\n  wait for the Spot Request to be fulfilled, and will throw an error if the\n  timeout of 10m is reached.\n* `spot_type` - (Optional; Default: `persistent`) If set to `one-time`, after\n  the instance is terminated, the spot request will be closed.\n* `launch_group` - (Optional) A launch group is a group of spot instances that launch together and terminate together.\n  If left empty instances are launched and terminated individually.\n* `block_duration_minutes` - (Optional) The required duration for the Spot instances, in minutes. This value must be a multiple of 60 (60, 120, 180, 240, 300, or 360).\n  The duration period starts as soon as your Spot instance receives its instance ID. At the end of the duration period, Amazon EC2 marks the Spot instance for termination and provides a Spot instance termination notice, which gives the instance a two-minute warning before it terminates.\n  Note that you can't specify an Availability Zone group or a launch group if you specify a duration.\n* `instance_interruption_behavior` - (Optional) Indicates Spot instance behavior when it is interrupted. Valid values are `terminate`, `stop`, or `hibernate`. Default value is `terminate`.\n* `instance_interruption_behaviour` - (Optional, **Deprecated**) Indicates Spot instance behavior when it is interrupted. Valid values are `terminate`, `stop`, or `hibernate`. Default value is `terminate`. Use the argument `instance_interruption_behavior` instead.\n* `valid_until` - (Optional) The end date and time of the request, in UTC [RFC3339](https://tools.ietf.org/html/rfc3339#section-5.8) format(for example, YYYY-MM-DDTHH:MM:SSZ). At this point, no new Spot instance requests are placed or enabled to fulfill the request. The default end date is 7 days from the current date.\n* `valid_from` - (Optional) The start date and time of the request, in UTC [RFC3339](https://tools.ietf.org/html/rfc3339#section-5.8) format(for example, YYYY-MM-DDTHH:MM:SSZ). The default is to start fulfilling the request immediately.\n* `tags` - (Optional) A map of tags to assign to the Spot Instance Request. These tags are not automatically applied to the launched Instance. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 10 mins) Used when requesting the spot instance (only valid if `wait_for_fulfillment = true`)\n* `delete` - (Defaults to 20 mins) Used when terminating all instances launched via the given spot instance request\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Spot Instance Request ID.\n\nThese attributes are exported, but they are expected to change over time and so\nshould only be used for informational purposes, not for resource dependencies:\n\n* `spot_bid_status` - The current [bid\n  status](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-bid-status.html)\n  of the Spot Instance Request.\n* `spot_request_state` The current [request\n  state](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-requests.html#creating-spot-request-status)\n  of the Spot Instance Request.\n* `spot_instance_id` - The Instance ID (if any) that is currently fulfilling\n  the Spot Instance request.\n* `public_dns` - The public DNS name assigned to the instance. For EC2-VPC, this\n  is only available if you've enabled DNS hostnames for your VPC\n* `public_ip` - The public IP address assigned to the instance, if applicable.\n* `private_dns` - The private DNS name assigned to the instance. Can only be\n  used inside the Amazon EC2, and only available if you've enabled DNS hostnames\n  for your VPC\n* `private_ip` - The private IP address assigned to the instance\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n",
    "basename": "spot_instance_request.html"
  },
  "sqs_queue.html": {
    "subcategory": "SQS",
    "layout": "aws",
    "page_title": "AWS: aws_sqs_queue",
    "description": "Provides a SQS resource.",
    "preview": "# Resource: aws_sqs_queue\n\n## Example Usage\n\n```terraform\nresource …",
    "content": "\n\n# Resource: aws_sqs_queue\n\n## Example Usage\n\n```terraform\nresource \"aws_sqs_queue\" \"terraform_queue\" {\n  name                      = \"terraform-example-queue\"\n  delay_seconds             = 90\n  max_message_size          = 2048\n  message_retention_seconds = 86400\n  receive_wait_time_seconds = 10\n  redrive_policy = jsonencode({\n    deadLetterTargetArn = aws_sqs_queue.terraform_queue_deadletter.arn\n    maxReceiveCount     = 4\n  })\n\n  tags = {\n    Environment = \"production\"\n  }\n}\n```\n\n## FIFO queue\n\n```terraform\nresource \"aws_sqs_queue\" \"terraform_queue\" {\n  name                        = \"terraform-example-queue.fifo\"\n  fifo_queue                  = true\n  content_based_deduplication = true\n}\n```\n\n## High-throughput FIFO queue\n\n```terraform\nresource \"aws_sqs_queue\" \"terraform_queue\" {\n  name                  = \"terraform-example-queue.fifo\"\n  fifo_queue            = true\n  deduplication_scope   = \"messageGroup\"\n  fifo_throughput_limit = \"perMessageGroupId\"\n}\n```\n\n## Server-side encryption (SSE)\n\nUsing [SSE-SQS](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-sqs-sse-queue.html):\n\n```terraform\nresource \"aws_sqs_queue\" \"terraform_queue\" {\n  name                    = \"terraform-example-queue\"\n  sqs_managed_sse_enabled = true\n}\n```\n\nUsing [SSE-KMS](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-sse-existing-queue.html):\n\n```terraform\nresource \"aws_sqs_queue\" \"terraform_queue\" {\n  name                              = \"terraform-example-queue\"\n  kms_master_key_id                 = \"alias/aws/sqs\"\n  kms_data_key_reuse_period_seconds = 300\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The name of the queue. Queue names must be made up of only uppercase and lowercase ASCII letters, numbers, underscores, and hyphens, and must be between 1 and 80 characters long. For a FIFO (first-in-first-out) queue, the name must end with the `.fifo` suffix. If omitted, Terraform will assign a random, unique name. Conflicts with `name_prefix`\n* `name_prefix` - (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`\n* `visibility_timeout_seconds` - (Optional) The visibility timeout for the queue. An integer from 0 to 43200 (12 hours). The default for this attribute is 30. For more information about visibility timeout, see [AWS docs](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/AboutVT.html).\n* `message_retention_seconds` - (Optional) The number of seconds Amazon SQS retains a message. Integer representing seconds, from 60 (1 minute) to 1209600 (14 days). The default for this attribute is 345600 (4 days).\n* `max_message_size` - (Optional) The limit of how many bytes a message can contain before Amazon SQS rejects it. An integer from 1024 bytes (1 KiB) up to 262144 bytes (256 KiB). The default for this attribute is 262144 (256 KiB).\n* `delay_seconds` - (Optional) The time in seconds that the delivery of all messages in the queue will be delayed. An integer from 0 to 900 (15 minutes). The default for this attribute is 0 seconds.\n* `receive_wait_time_seconds` - (Optional) The time for which a ReceiveMessage call will wait for a message to arrive (long polling) before returning. An integer from 0 to 20 (seconds). The default for this attribute is 0, meaning that the call will return immediately.\n* `policy` - (Optional) The JSON policy for the SQS queue. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `redrive_policy` - (Optional) The JSON policy to set up the Dead Letter Queue, see [AWS docs](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSDeadLetterQueue.html). **Note:** when specifying `maxReceiveCount`, you must specify it as an integer (`5`), and not a string (`\"5\"`).\n* `fifo_queue` - (Optional) Boolean designating a FIFO queue. If not set, it defaults to `false` making it standard.\n* `content_based_deduplication` - (Optional) Enables content-based deduplication for FIFO queues. For more information, see the [related documentation](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing)\n* `sqs_managed_sse_enabled` - (Optional) Boolean to enable server-side encryption (SSE) of message content with SQS-owned encryption keys. Defaults to `false`. See [Encryption at rest](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html).\n* `kms_master_key_id` - (Optional) The ID of an AWS-managed customer master key (CMK) for Amazon SQS or a custom CMK. For more information, see [Key Terms](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html#sqs-sse-key-terms).\n* `kms_data_key_reuse_period_seconds` - (Optional) The length of time, in seconds, for which Amazon SQS can reuse a data key to encrypt or decrypt messages before calling AWS KMS again. An integer representing seconds, between 60 seconds (1 minute) and 86,400 seconds (24 hours). The default is 300 (5 minutes).\n* `deduplication_scope` - (Optional) Specifies whether message deduplication occurs at the message group or queue level. Valid values are `messageGroup` and `queue` (default).\n* `fifo_throughput_limit` - (Optional) Specifies whether the FIFO queue throughput quota applies to the entire queue or per message group. Valid values are `perQueue` (default) and `perMessageGroupId`.\n* `tags` - (Optional) A map of tags to assign to the queue. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The URL for the created Amazon SQS queue.\n* `arn` - The ARN of the SQS queue\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `url` - Same as `id`: The URL for the created Amazon SQS queue.\n\n## Import\n\nSQS Queues can be imported using the `queue url`, e.g.,\n\n```\n$ terraform import aws_sqs_queue.public_queue https://queue.amazonaws.com/80398EXAMPLE/MyQueue\n```\n",
    "basename": "sqs_queue.html"
  },
  "sqs_queue_policy.html": {
    "subcategory": "SQS",
    "layout": "aws",
    "page_title": "AWS: aws_sqs_queue_policy",
    "description": "Provides a SQS Queue Policy resource.",
    "preview": "# Resource: aws_sqs_queue_policy\n\nAllows you to set a policy of an …",
    "content": "\n\n# Resource: aws_sqs_queue_policy\n\nAllows you to set a policy of an SQS Queue\nwhile referencing ARN of the queue within the policy.\n\n## Example Usage\n\n```terraform\nresource \"aws_sqs_queue\" \"q\" {\n  name = \"examplequeue\"\n}\n\nresource \"aws_sqs_queue_policy\" \"test\" {\n  queue_url = aws_sqs_queue.q.id\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Id\": \"sqspolicy\",\n  \"Statement\": [\n    {\n      \"Sid\": \"First\",\n      \"Effect\": \"Allow\",\n      \"Principal\": \"*\",\n      \"Action\": \"sqs:SendMessage\",\n      \"Resource\": \"${aws_sqs_queue.q.arn}\",\n      \"Condition\": {\n        \"ArnEquals\": {\n          \"aws:SourceArn\": \"${aws_sns_topic.example.arn}\"\n        }\n      }\n    }\n  ]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `queue_url` - (Required) The URL of the SQS Queue to which to attach the policy\n* `policy` - (Required) The JSON policy for the SQS queue. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nSQS Queue Policies can be imported using the queue URL, e.g.,\n\n```\n$ terraform import aws_sqs_queue_policy.test https://queue.amazonaws.com/0123456789012/myqueue\n```\n",
    "basename": "sqs_queue_policy.html"
  },
  "ssm_activation.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_activation",
    "description": "Registers an on-premises server or virtual machine with Amazon EC2 so that it can be managed using Run Command.",
    "preview": "# Resource: aws_ssm_activation\n\nRegisters an on-premises server or …",
    "content": "\n\n# Resource: aws_ssm_activation\n\nRegisters an on-premises server or virtual machine with Amazon EC2 so that it can be managed using Run Command.\n\n## Example Usage\n\n```terraform\nresource \"aws_iam_role\" \"test_role\" {\n  name = \"test_role\"\n\n  assume_role_policy = <<EOF\n  {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"ssm.amazonaws.com\"},\n      \"Action\": \"sts:AssumeRole\"\n    }\n  }\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"test_attach\" {\n  role       = aws_iam_role.test_role.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n}\n\nresource \"aws_ssm_activation\" \"foo\" {\n  name               = \"test_ssm_activation\"\n  description        = \"Test\"\n  iam_role           = aws_iam_role.test_role.id\n  registration_limit = \"5\"\n  depends_on         = [aws_iam_role_policy_attachment.test_attach]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional) The default name of the registered managed instance.\n* `description` - (Optional) The description of the resource that you want to register.\n* `expiration_date` - (Optional) UTC timestamp in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) by which this activation request should expire. The default value is 24 hours from resource creation time. Terraform will only perform drift detection of its value when present in a configuration.\n* `iam_role` - (Required) The IAM Role to attach to the managed instance.\n* `registration_limit` - (Optional) The maximum number of managed instances you want to register. The default value is 1 instance.\n* `tags` - (Optional) A map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The activation ID.\n* `activation_code` - The code the system generates when it processes the activation.\n* `name` - The default name of the registered managed instance.\n* `description` - The description of the resource that was registered.\n* `expired` - If the current activation has expired.\n* `expiration_date` - The date by which this activation request should expire. The default value is 24 hours.\n* `iam_role` - The IAM Role attached to the managed instance.\n* `registration_limit` - The maximum number of managed instances you want to be registered. The default value is 1 instance.\n* `registration_count` - The number of managed instances that are currently registered using this activation.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nAWS SSM Activation can be imported using the `id`, e.g.,\n\n```sh\n$ terraform import aws_ssm_activation.example e488f2f6-e686-4afb-8a04-ef6dfEXAMPLE\n```\n\n-> **Note:** The `activation_code` attribute cannot be imported.\n",
    "basename": "ssm_activation.html"
  },
  "ssm_association.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_association",
    "description": "Associates an SSM Document to an instance or EC2 tag.",
    "preview": "# Resource: aws_ssm_association\n\nAssociates an SSM Document to an …",
    "content": "\n\n# Resource: aws_ssm_association\n\nAssociates an SSM Document to an instance or EC2 tag.\n\n## Example Usage\n\n### Create an association for a specific instance\n\n```terraform\nresource \"aws_ssm_association\" \"example\" {\n  name = aws_ssm_document.example.name\n\n  targets {\n    key    = \"InstanceIds\"\n    values = [aws_instance.example.id]\n  }\n}\n```\n\n### Create an association for all managed instances in an AWS account\n\nTo target all managed instances in an AWS account, set the `key` as `\"InstanceIds\"` with `values` set as `[\"*\"]`. This example also illustrates how to use an Amazon owned SSM document named `AmazonCloudWatch-ManageAgent`.\n\n```terraform\nresource \"aws_ssm_association\" \"example\" {\n  name = \"AmazonCloudWatch-ManageAgent\"\n\n  targets {\n    key    = \"InstanceIds\"\n    values = [\"*\"]\n  }\n}\n```\n\n### Create an association for a specific tag\n\nThis example shows how to target all managed instances that are assigned a tag key of `Environment` and value of `Development`.\n\n```terraform\nresource \"aws_ssm_association\" \"example\" {\n  name = \"AmazonCloudWatch-ManageAgent\"\n\n  targets {\n    key    = \"tag:Environment\"\n    values = [\"Development\"]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the SSM document to apply.\n* `apply_only_at_cron_interval` - (Optional) By default, when you create a new or update associations, the system runs it immediately and then according to the schedule you specified. Enable this option if you do not want an association to run immediately after you create or update it. This parameter is not supported for rate expressions. Default: `false`.\n* `association_name` - (Optional) The descriptive name for the association.\n* `document_version` - (Optional) The document version you want to associate with the target(s). Can be a specific version or the default version.\n* `instance_id` - (Optional) The instance ID to apply an SSM document to. Use `targets` with key `InstanceIds` for document schema versions 2.0 and above.\n* `output_location` - (Optional) An output location block. Output Location is documented below.\n* `parameters` - (Optional) A block of arbitrary string parameters to pass to the SSM document.\n* `schedule_expression` - (Optional) A cron expression when the association will be applied to the target(s).\n* `targets` - (Optional) A block containing the targets of the SSM association. Targets are documented below. AWS currently supports a maximum of 5 targets.\n* `compliance_severity` - (Optional) The compliance severity for the association. Can be one of the following: `UNSPECIFIED`, `LOW`, `MEDIUM`, `HIGH` or `CRITICAL`\n* `max_concurrency` - (Optional) The maximum number of targets allowed to run the association at the same time. You can specify a number, for example 10, or a percentage of the target set, for example 10%.\n* `max_errors` - (Optional) The number of errors that are allowed before the system stops sending requests to run the association on additional targets. You can specify a number, for example 10, or a percentage of the target set, for example 10%.\n* `automation_target_parameter_name` - (Optional) Specify the target for the association. This target is required for associations that use an `Automation` document and target resources by using rate controls. This should be set to the SSM document `parameter` that will define how your automation will branch out.\n\nOutput Location (`output_location`) is an S3 bucket where you want to store the results of this association:\n\n* `s3_bucket_name` - (Required) The S3 bucket name.\n* `s3_key_prefix` - (Optional) The S3 bucket prefix. Results stored in the root if not configured.\n* `s3_region` - (Optional) The S3 bucket region.\n\nTargets specify what instance IDs or tags to apply the document to and has these keys:\n\n* `key` - (Required) Either `InstanceIds` or `tag:Tag Name` to specify an EC2 tag.\n* `values` - (Required) A list of instance IDs or tag values. AWS currently limits this list size to one value.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `association_id` - The ID of the SSM association.\n* `instance_id` - The instance id that the SSM document was applied to.\n* `name` - The name of the SSM document to apply.\n* `parameters` - Additional parameters passed to the SSM document.\n\n## Import\n\nSSM associations can be imported using the `association_id`, e.g.,\n\n```\n$ terraform import aws_ssm_association.test-association 10abcdef-0abc-1234-5678-90abcdef123456\n```\n",
    "basename": "ssm_association.html"
  },
  "ssm_document.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_document",
    "description": "Provides an SSM Document resource",
    "preview": "# Resource: aws_ssm_document\n\nProvides an SSM Document resource\n\n~> …",
    "content": "\n\n# Resource: aws_ssm_document\n\nProvides an SSM Document resource\n\n~> **NOTE on updating SSM documents:** Only documents with a schema version of 2.0\nor greater can update their content once created, see [SSM Schema Features][1]. To update a document with an older schema version you must recreate the resource. Not all document types support a schema version of 2.0 or greater. Refer to [SSM document schema features and examples][2] for information about which schema versions are supported for the respective `document_type`.\n\n## Example Usage\n\n### Create an ssm document in JSON format\n\n```terraform\nresource \"aws_ssm_document\" \"foo\" {\n  name          = \"test_document\"\n  document_type = \"Command\"\n\n  content = <<DOC\n  {\n    \"schemaVersion\": \"1.2\",\n    \"description\": \"Check ip configuration of a Linux instance.\",\n    \"parameters\": {\n\n    },\n    \"runtimeConfig\": {\n      \"aws:runShellScript\": {\n        \"properties\": [\n          {\n            \"id\": \"0.aws:runShellScript\",\n            \"runCommand\": [\"ifconfig\"]\n          }\n        ]\n      }\n    }\n  }\nDOC\n}\n```\n\n### Create an ssm document in YAML format\n\n```terraform\nresource \"aws_ssm_document\" \"foo\" {\n  name            = \"test_document\"\n  document_format = \"YAML\"\n  document_type   = \"Command\"\n\n  content = <<DOC\nschemaVersion: '1.2'\ndescription: Check ip configuration of a Linux instance.\nparameters: {}\nruntimeConfig:\n  'aws:runShellScript':\n    properties:\n      - id: '0.aws:runShellScript'\n        runCommand:\n          - ifconfig\nDOC\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the document.\n* `attachments_source` - (Optional) One or more configuration blocks describing attachments sources to a version of a document. Defined below.\n* `content` - (Required) The JSON or YAML content of the document.\n* `document_format` - (Optional, defaults to JSON) The format of the document. Valid document types include: `JSON` and `YAML`\n* `document_type` - (Required) The type of the document. Valid document types include: `Automation`, `Command`, `Package`, `Policy`, and `Session`\n* `permissions` - (Optional) Additional Permissions to attach to the document. See [Permissions](#permissions) below for details.\n* `target_type` - (Optional) The target type which defines the kinds of resources the document can run on. For example, /AWS::EC2::Instance. For a list of valid resource types, see AWS Resource Types Reference (http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html)\n* `tags` - (Optional) A map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `version_name` - (Optional) A field specifying the version of the artifact you are creating with the document. For example, \"Release 12, Update 6\". This value is unique across all versions of a document and cannot be changed for an existing document version.\n\n## attachments_source\n\nThe `attachments_source` block supports the following:\n\n* `key` - (Required) The key describing the location of an attachment to a document. Valid key types include: `SourceUrl` and `S3FileUrl`\n* `values` - (Required) The value describing the location of an attachment to a document\n* `name` - (Optional) The name of the document attachment file\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `created_date` - The date the document was created.\n* `description` - The description of the document.\n* `schema_version` - The schema version of the document.\n* `default_version` - The default version of the document.\n* `document_version` - The document version.\n* `hash` - The sha1 or sha256 of the document content\n* `hash_type` - \"Sha1\" \"Sha256\". The hashing algorithm used when hashing the content.\n* `latest_version` - The latest version of the document.\n* `owner` - The AWS user account of the person who created the document.\n* `status` - \"Creating\", \"Active\" or \"Deleting\". The current status of the document.\n* `parameter` - The parameters that are available to this document.\n* `platform_types` - A list of OS platforms compatible with this SSM document, either \"Windows\" or \"Linux\".\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[1]: http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-ssm-docs.html#document-schemas-features\n[2]: https://docs.aws.amazon.com/systems-manager/latest/userguide/document-schemas-features.html\n\n## Permissions\n\nThe permissions attribute specifies how you want to share the document. If you share a document privately,\nyou must specify the AWS user account IDs for those people who can use the document. If you share a document\npublicly, you must specify All as the account ID.\n\nThe permissions mapping supports the following:\n\n* `type` - The permission type for the document. The permission type can be `Share`.\n* `account_ids` - The AWS user accounts that should have access to the document. The account IDs can either be a group of account IDs or `All`.\n\n## Import\n\nSSM Documents can be imported using the name, e.g.,\n\n```\n$ terraform import aws_ssm_document.example example\n```\n\nThe `attachments_source` argument does not have an SSM API method for reading the attachment information detail after creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_ssm_document\" \"test\" {\n  name          = \"test_document\"\n  document_type = \"Package\"\n\n  attachments_source {\n    key    = \"SourceUrl\"\n    values = [\"s3://${aws_s3_bucket.object_bucket.bucket}/test.zip\"]\n  }\n\n  # There is no AWS SSM API for reading attachments_source info directly\n  lifecycle {\n    ignore_changes = [attachments_source]\n  }\n}\n```\n",
    "basename": "ssm_document.html"
  },
  "ssm_maintenance_window.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_maintenance_window",
    "description": "Provides an SSM Maintenance Window resource",
    "preview": "# Resource: aws_ssm_maintenance_window\n\nProvides an SSM Maintenance …",
    "content": "\n\n# Resource: aws_ssm_maintenance_window\n\nProvides an SSM Maintenance Window resource\n\n## Example Usage\n\n```terraform\nresource \"aws_ssm_maintenance_window\" \"production\" {\n  name     = \"maintenance-window-application\"\n  schedule = \"cron(0 16 ? * TUE *)\"\n  duration = 3\n  cutoff   = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the maintenance window.\n* `schedule` - (Required) The schedule of the Maintenance Window in the form of a [cron](https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-maintenance-cron.html) or rate expression.\n* `cutoff` - (Required) The number of hours before the end of the Maintenance Window that Systems Manager stops scheduling new tasks for execution.\n* `duration` - (Required) The duration of the Maintenance Window in hours.\n* `description` - (Optional) A description for the maintenance window.\n* `allow_unassociated_targets` - (Optional) Whether targets must be registered with the Maintenance Window before tasks can be defined for those targets.\n* `enabled` - (Optional) Whether the maintenance window is enabled. Default: `true`.\n* `end_date` - (Optional) Timestamp in [ISO-8601 extended format](https://www.iso.org/iso-8601-date-and-time-format.html) when to no longer run the maintenance window.\n* `schedule_timezone` - (Optional) Timezone for schedule in [Internet Assigned Numbers Authority (IANA) Time Zone Database format](https://www.iana.org/time-zones). For example: `America/Los_Angeles`, `etc/UTC`, or `Asia/Seoul`.\n* `schedule_offset` - (Optional) The number of days to wait after the date and time specified by a CRON expression before running the maintenance window.\n* `start_date` - (Optional) Timestamp in [ISO-8601 extended format](https://www.iso.org/iso-8601-date-and-time-format.html) when to begin the maintenance window.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the maintenance window.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSSM  Maintenance Windows can be imported using the `maintenance window id`, e.g.,\n\n```\n$ terraform import aws_ssm_maintenance_window.imported-window mw-0123456789\n```\n",
    "basename": "ssm_maintenance_window.html"
  },
  "ssm_maintenance_window_target.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_maintenance_window_target",
    "description": "Provides an SSM Maintenance Window Target resource",
    "preview": "# Resource: aws_ssm_maintenance_window_target\n\nProvides an SSM …",
    "content": "\n\n# Resource: aws_ssm_maintenance_window_target\n\nProvides an SSM Maintenance Window Target resource\n\n## Example Usage\n\n### Instance Target\n\n```terraform\nresource \"aws_ssm_maintenance_window\" \"window\" {\n  name     = \"maintenance-window-webapp\"\n  schedule = \"cron(0 16 ? * TUE *)\"\n  duration = 3\n  cutoff   = 1\n}\n\nresource \"aws_ssm_maintenance_window_target\" \"target1\" {\n  window_id     = aws_ssm_maintenance_window.window.id\n  name          = \"maintenance-window-target\"\n  description   = \"This is a maintenance window target\"\n  resource_type = \"INSTANCE\"\n\n  targets {\n    key    = \"tag:Name\"\n    values = [\"acceptance_test\"]\n  }\n}\n```\n\n### Resource Group Target\n\n```terraform\nresource \"aws_ssm_maintenance_window\" \"window\" {\n  name     = \"maintenance-window-webapp\"\n  schedule = \"cron(0 16 ? * TUE *)\"\n  duration = 3\n  cutoff   = 1\n}\n\nresource \"aws_ssm_maintenance_window_target\" \"target1\" {\n  window_id     = aws_ssm_maintenance_window.window.id\n  name          = \"maintenance-window-target\"\n  description   = \"This is a maintenance window target\"\n  resource_type = \"RESOURCE_GROUP\"\n\n  targets {\n    key    = \"resource-groups:ResourceTypeFilters\"\n    values = [\"AWS::EC2::Instance\"]\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `window_id` - (Required) The Id of the maintenance window to register the target with.\n* `name` - (Optional) The name of the maintenance window target.\n* `description` - (Optional) The description of the maintenance window target.\n* `resource_type` - (Required) The type of target being registered with the Maintenance Window. Possible values are `INSTANCE` and `RESOURCE_GROUP`.\n* `targets` - (Required) The targets to register with the maintenance window. In other words, the instances to run commands on when the maintenance window runs. You can specify targets using instance IDs, resource group names, or tags that have been applied to instances. For more information about these examples formats see\n (https://docs.aws.amazon.com/systems-manager/latest/userguide/mw-cli-tutorial-targets-examples.html)\n* `owner_information` - (Optional) User-provided value that will be included in any CloudWatch events raised while running tasks for these targets in this Maintenance Window.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the maintenance window target.\n\n## Import\n\nSSM Maintenance Window targets can be imported using `WINDOW_ID/WINDOW_TARGET_ID`, e.g.,\n\n```\n$ terraform import aws_ssm_maintenance_window_target.example mw-0c50858d01EXAMPLE/23639a0b-ddbc-4bca-9e72-78d96EXAMPLE\n```\n",
    "basename": "ssm_maintenance_window_target.html"
  },
  "ssm_maintenance_window_task.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_maintenance_window_task",
    "description": "Provides an SSM Maintenance Window Task resource",
    "preview": "# Resource: aws_ssm_maintenance_window_task\n\nProvides an SSM …",
    "content": "\n\n# Resource: aws_ssm_maintenance_window_task\n\nProvides an SSM Maintenance Window Task resource\n\n## Example Usage\n\n### Automation Tasks\n\n```terraform\nresource \"aws_ssm_maintenance_window_task\" \"example\" {\n  max_concurrency = 2\n  max_errors      = 1\n  priority        = 1\n  task_arn        = \"AWS-RestartEC2Instance\"\n  task_type       = \"AUTOMATION\"\n  window_id       = aws_ssm_maintenance_window.example.id\n\n  targets {\n    key    = \"InstanceIds\"\n    values = [aws_instance.example.id]\n  }\n\n  task_invocation_parameters {\n    automation_parameters {\n      document_version = \"$LATEST\"\n\n      parameter {\n        name   = \"InstanceId\"\n        values = [aws_instance.example.id]\n      }\n    }\n  }\n}\n```\n\n### Lambda Tasks\n\n```terraform\nresource \"aws_ssm_maintenance_window_task\" \"example\" {\n  max_concurrency = 2\n  max_errors      = 1\n  priority        = 1\n  task_arn        = aws_lambda_function.example.arn\n  task_type       = \"LAMBDA\"\n  window_id       = aws_ssm_maintenance_window.example.id\n\n  targets {\n    key    = \"InstanceIds\"\n    values = [aws_instance.example.id]\n  }\n\n  task_invocation_parameters {\n    lambda_parameters {\n      client_context = base64encode(\"{\\\"key1\\\":\\\"value1\\\"}\")\n      payload        = \"{\\\"key1\\\":\\\"value1\\\"}\"\n    }\n  }\n}\n```\n\n### Run Command Tasks\n\n```terraform\nresource \"aws_ssm_maintenance_window_task\" \"example\" {\n  max_concurrency = 2\n  max_errors      = 1\n  priority        = 1\n  task_arn        = \"AWS-RunShellScript\"\n  task_type       = \"RUN_COMMAND\"\n  window_id       = aws_ssm_maintenance_window.example.id\n\n  targets {\n    key    = \"InstanceIds\"\n    values = [aws_instance.example.id]\n  }\n\n  task_invocation_parameters {\n    run_command_parameters {\n      output_s3_bucket     = aws_s3_bucket.example.bucket\n      output_s3_key_prefix = \"output\"\n      service_role_arn     = aws_iam_role.example.arn\n      timeout_seconds      = 600\n\n      notification_config {\n        notification_arn    = aws_sns_topic.example.arn\n        notification_events = [\"All\"]\n        notification_type   = \"Command\"\n      }\n\n      parameter {\n        name   = \"commands\"\n        values = [\"date\"]\n      }\n    }\n  }\n}\n```\n\n### Step Function Tasks\n\n```terraform\nresource \"aws_ssm_maintenance_window_task\" \"example\" {\n  max_concurrency = 2\n  max_errors      = 1\n  priority        = 1\n  task_arn        = aws_sfn_activity.example.id\n  task_type       = \"STEP_FUNCTIONS\"\n  window_id       = aws_ssm_maintenance_window.example.id\n\n  targets {\n    key    = \"InstanceIds\"\n    values = [aws_instance.example.id]\n  }\n\n  task_invocation_parameters {\n    step_functions_parameters {\n      input = \"{\\\"key1\\\":\\\"value1\\\"}\"\n      name  = \"example\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `window_id` - (Required) The Id of the maintenance window to register the task with.\n* `max_concurrency` - (Required) The maximum number of targets this task can be run for in parallel.\n* `max_errors` - (Required) The maximum number of errors allowed before this task stops being scheduled.\n* `task_type` - (Required) The type of task being registered. Valid values: `AUTOMATION`, `LAMBDA`, `RUN_COMMAND` or `STEP_FUNCTIONS`.\n* `task_arn` - (Required) The ARN of the task to execute.\n* `service_role_arn` - (Optional) The role that should be assumed when executing the task. If a role is not provided, Systems Manager uses your account's service-linked role. If no service-linked role for Systems Manager exists in your account, it is created for you.\n* `name` - (Optional) The name of the maintenance window task.\n* `description` - (Optional) The description of the maintenance window task.\n* `targets` - (Required) The targets (either instances or window target ids). Instances are specified using Key=InstanceIds,Values=instanceid1,instanceid2. Window target ids are specified using Key=WindowTargetIds,Values=window target id1, window target id2.\n* `priority` - (Optional) The priority of the task in the Maintenance Window, the lower the number the higher the priority. Tasks in a Maintenance Window are scheduled in priority order with tasks that have the same priority scheduled in parallel.\n* `task_invocation_parameters` - (Optional) Configuration block with parameters for task execution.\n\n`task_invocation_parameters` supports the following:\n\n* `automation_parameters` - (Optional) The parameters for an AUTOMATION task type. Documented below.\n* `lambda_parameters` - (Optional) The parameters for a LAMBDA task type. Documented below.\n* `run_command_parameters` - (Optional) The parameters for a RUN_COMMAND task type. Documented below.\n* `step_functions_parameters` - (Optional) The parameters for a STEP_FUNCTIONS task type. Documented below.\n\n`automation_parameters` supports the following:\n\n* `document_version` - (Optional) The version of an Automation document to use during task execution.\n* `parameter` - (Optional) The parameters for the RUN_COMMAND task execution. Documented below.\n\n`lambda_parameters` supports the following:\n\n* `client_context` - (Optional) Pass client-specific information to the Lambda function that you are invoking.\n* `payload` - (Optional) JSON to provide to your Lambda function as input.\n* `qualifier` - (Optional) Specify a Lambda function version or alias name.\n\n`run_command_parameters` supports the following:\n\n* `comment` - (Optional) Information about the command(s) to execute.\n* `document_hash` - (Optional) The SHA-256 or SHA-1 hash created by the system when the document was created. SHA-1 hashes have been deprecated.\n* `document_hash_type` - (Optional) SHA-256 or SHA-1. SHA-1 hashes have been deprecated. Valid values: `Sha256` and `Sha1`\n* `notification_config` - (Optional) Configurations for sending notifications about command status changes on a per-instance basis. Documented below.\n* `output_s3_bucket` - (Optional) The name of the Amazon S3 bucket.\n* `output_s3_key_prefix` - (Optional) The Amazon S3 bucket subfolder.\n* `parameter` - (Optional) The parameters for the RUN_COMMAND task execution. Documented below.\n* `service_role_arn` - (Optional) The IAM service role to assume during task execution.\n* `timeout_seconds` - (Optional) If this time is reached and the command has not already started executing, it doesn't run.\n* `cloudwatch_config` - (Optional) Configuration options for sending command output to CloudWatch Logs. Documented below.\n\n`step_functions_parameters` supports the following:\n\n* `input` - (Optional) The inputs for the STEP_FUNCTION task.\n* `name` - (Optional) The name of the STEP_FUNCTION task.\n\n`notification_config` supports the following:\n\n* `notification_arn` - (Optional) An Amazon Resource Name (ARN) for a Simple Notification Service (SNS) topic. Run Command pushes notifications about command status changes to this topic.\n* `notification_events` - (Optional) The different events for which you can receive notifications. Valid values: `All`, `InProgress`, `Success`, `TimedOut`, `Cancelled`, and `Failed`\n* `notification_type` - (Optional) When specified with `Command`, receive notification when the status of a command changes. When specified with `Invocation`, for commands sent to multiple instances, receive notification on a per-instance basis when the status of a command changes. Valid values: `Command` and `Invocation`\n\n`cloudwatch_config` supports the following:\n\n* `cloudwatch_log_group_name` - (Optional) The name of the CloudWatch log group where you want to send command output. If you don't specify a group name, Systems Manager automatically creates a log group for you. The log group uses the following naming format: aws/ssm/SystemsManagerDocumentName.\n* `cloudwatch_output_enabled` - (Optional) Enables Systems Manager to send command output to CloudWatch Logs.\n\n`parameter` supports the following:\n\n* `name` - (Required) The parameter name.\n* `values` - (Required) The array of strings.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the maintenance window task.\n\n## Import\n\nAWS Maintenance Window Task can be imported using the `window_id` and `window_task_id` separated by `/`.\n\n```sh\n$ terraform import aws_ssm_maintenance_window_task.task <window_id>/<window_task_id>\n```\n",
    "basename": "ssm_maintenance_window_task.html"
  },
  "ssm_parameter.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_parameter",
    "description": "Provides a SSM Parameter resource",
    "preview": "# Resource: aws_ssm_parameter\n\nProvides an SSM Parameter resource.\n …",
    "content": "\n\n# Resource: aws_ssm_parameter\n\nProvides an SSM Parameter resource.\n\n## Example Usage\n\nTo store a basic string parameter:\n\n```terraform\nresource \"aws_ssm_parameter\" \"foo\" {\n  name  = \"foo\"\n  type  = \"String\"\n  value = \"bar\"\n}\n```\n\nTo store an encrypted string using the default SSM KMS key:\n\n```terraform\nresource \"aws_db_instance\" \"default\" {\n  allocated_storage    = 10\n  storage_type         = \"gp2\"\n  engine               = \"mysql\"\n  engine_version       = \"5.7.16\"\n  instance_class       = \"db.t2.micro\"\n  name                 = \"mydb\"\n  username             = \"foo\"\n  password             = var.database_master_password\n  db_subnet_group_name = \"my_database_subnet_group\"\n  parameter_group_name = \"default.mysql5.7\"\n}\n\nresource \"aws_ssm_parameter\" \"secret\" {\n  name        = \"/production/database/password/master\"\n  description = \"The parameter description\"\n  type        = \"SecureString\"\n  value       = var.database_master_password\n\n  tags = {\n    environment = \"production\"\n  }\n}\n```\n\n~> **Note:** The unencrypted value of a SecureString will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the parameter. If the name contains a path (e.g., any forward slashes (`/`)), it must be fully qualified with a leading forward slash (`/`). For additional requirements and constraints, see the [AWS SSM User Guide](https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-parameter-name-constraints.html).\n* `type` - (Required) The type of the parameter. Valid types are `String`, `StringList` and `SecureString`.\n* `value` - (Required) The value of the parameter. This value is always marked as sensitive in the Terraform plan output, regardless of `type`. In Terraform CLI version 0.15 and later, this may require additional configuration handling for certain scenarios. For more information, see the [Terraform v0.15 Upgrade Guide](https://www.terraform.io/upgrade-guides/0-15.html#sensitive-output-values).\n* `description` - (Optional) The description of the parameter.\n* `tier` - (Optional) The tier of the parameter. If not specified, will default to `Standard`. Valid tiers are `Standard`, `Advanced`, and `Intelligent-Tiering`. For more information on parameter tiers, see the [AWS SSM Parameter tier comparison and guide](https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-advanced-parameters.html).\n* `key_id` - (Optional) The KMS key id or arn for encrypting a SecureString.\n* `overwrite` - (Optional) Overwrite an existing parameter. If not specified, will default to `false` if the resource has not been created by terraform to avoid overwrite of existing resource and will default to `true` otherwise (terraform lifecycle rules should then be used to manage the update behavior).\n* `allowed_pattern` - (Optional) A regular expression used to validate the parameter value.\n* `data_type` - (Optional) The data_type of the parameter. Valid values: text and aws:ec2:image for AMI format, see the [Native parameter support for Amazon Machine Image IDs\n](https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-ec2-aliases.html)\n* `tags` - (Optional) A map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the parameter.\n* `name` - (Required) The name of the parameter.\n* `description` - (Required) The description of the parameter.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `type` - (Required) The type of the parameter. Valid types are `String`, `StringList` and `SecureString`.\n* `value` - (Required) The value of the parameter.\n* `version` - The version of the parameter.\n\n## Import\n\nSSM Parameters can be imported using the `parameter store name`, e.g.,\n\n```\n$ terraform import aws_ssm_parameter.my_param /my_path/my_paramname\n```\n",
    "basename": "ssm_parameter.html"
  },
  "ssm_patch_baseline.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_patch_baseline",
    "description": "Provides an SSM Patch Baseline resource",
    "preview": "# Resource: aws_ssm_patch_baseline\n\nProvides an SSM Patch Baseline …",
    "content": "\n\n# Resource: aws_ssm_patch_baseline\n\nProvides an SSM Patch Baseline resource\n\n~> **NOTE on Patch Baselines:** The `approved_patches` and `approval_rule` are\nboth marked as optional fields, but the Patch Baseline requires that at least one\nof them is specified.\n\n## Example Usage\n\nBasic usage using `approved_patches` only\n\n```terraform\nresource \"aws_ssm_patch_baseline\" \"production\" {\n  name             = \"patch-baseline\"\n  approved_patches = [\"KB123456\"]\n}\n```\n\nAdvanced usage, specifying patch filters\n\n```terraform\nresource \"aws_ssm_patch_baseline\" \"production\" {\n  name             = \"patch-baseline\"\n  description      = \"Patch Baseline Description\"\n  approved_patches = [\"KB123456\", \"KB456789\"]\n  rejected_patches = [\"KB987654\"]\n\n  global_filter {\n    key    = \"PRODUCT\"\n    values = [\"WindowsServer2008\"]\n  }\n\n  global_filter {\n    key    = \"CLASSIFICATION\"\n    values = [\"ServicePacks\"]\n  }\n\n  global_filter {\n    key    = \"MSRC_SEVERITY\"\n    values = [\"Low\"]\n  }\n\n  approval_rule {\n    approve_after_days = 7\n    compliance_level   = \"HIGH\"\n\n    patch_filter {\n      key    = \"PRODUCT\"\n      values = [\"WindowsServer2016\"]\n    }\n\n    patch_filter {\n      key    = \"CLASSIFICATION\"\n      values = [\"CriticalUpdates\", \"SecurityUpdates\", \"Updates\"]\n    }\n\n    patch_filter {\n      key    = \"MSRC_SEVERITY\"\n      values = [\"Critical\", \"Important\", \"Moderate\"]\n    }\n  }\n\n  approval_rule {\n    approve_after_days = 7\n\n    patch_filter {\n      key    = \"PRODUCT\"\n      values = [\"WindowsServer2012\"]\n    }\n  }\n}\n```\n\nAdvanced usage, specifying Microsoft application and Windows patch rules\n\n```terraform\nresource \"aws_ssm_patch_baseline\" \"windows_os_apps\" {\n  name             = \"WindowsOSAndMicrosoftApps\"\n  description      = \"Patch both Windows and Microsoft apps\"\n  operating_system = \"WINDOWS\"\n\n  approval_rule {\n    approve_after_days = 7\n\n    patch_filter {\n      key    = \"CLASSIFICATION\"\n      values = [\"CriticalUpdates\", \"SecurityUpdates\"]\n    }\n\n    patch_filter {\n      key    = \"MSRC_SEVERITY\"\n      values = [\"Critical\", \"Important\"]\n    }\n  }\n\n  approval_rule {\n    approve_after_days = 7\n\n    patch_filter {\n      key    = \"PATCH_SET\"\n      values = [\"APPLICATION\"]\n    }\n\n    # Filter on Microsoft product if necessary\n    patch_filter {\n      key    = \"PRODUCT\"\n      values = [\"Office 2013\", \"Office 2016\"]\n    }\n  }\n}\n```\n\nAdvanced usage, specifying alternate patch source repository\n\n```terraform\nresource \"aws_ssm_patch_baseline\" \"al_2017_09\" {\n  name             = \"Amazon-Linux-2017.09\"\n  description      = \"My patch repository for Amazon Linux 2017.09\"\n  operating_system = \"AMAZON_LINUX\"\n\n  approval_rule {\n    # ...\n  }\n\n  source {\n    name          = \"My-AL2017.09\"\n    products      = [\"AmazonLinux2017.09\"]\n    configuration = <<EOF\n[amzn-main]\nname=amzn-main-Base\nmirrorlist=http://repo./$awsregion./$awsdomain//$releasever/main/mirror.list\nmirrorlist_expire=300\nmetadata_expire=300\npriority=10\nfailovermethod=priority\nfastestmirror_enabled=0\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-amazon-ga\nenabled=1\nretries=3\ntimeout=5\nreport_instanceid=yes\nEOF\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the patch baseline.\n* `description` - (Optional) The description of the patch baseline.\n* `operating_system` - (Optional) Defines the operating system the patch baseline applies to. Supported operating systems include `WINDOWS`, `AMAZON_LINUX`, `AMAZON_LINUX_2`, `SUSE`, `UBUNTU`, `CENTOS`, and `REDHAT_ENTERPRISE_LINUX`. The Default value is `WINDOWS`.\n* `approved_patches_compliance_level` - (Optional) Defines the compliance level for approved patches. This means that if an approved patch is reported as missing, this is the severity of the compliance violation. Valid compliance levels include the following: `CRITICAL`, `HIGH`, `MEDIUM`, `LOW`, `INFORMATIONAL`, `UNSPECIFIED`. The default value is `UNSPECIFIED`.\n* `approved_patches` - (Optional) A list of explicitly approved patches for the baseline.\n* `rejected_patches` - (Optional) A list of rejected patches.\n* `global_filter` - (Optional) A set of global filters used to exclude patches from the baseline. Up to 4 global filters can be specified using Key/Value pairs. Valid Keys are `PRODUCT | CLASSIFICATION | MSRC_SEVERITY | PATCH_ID`.\n* `approval_rule` - (Optional) A set of rules used to include patches in the baseline. up to 10 approval rules can be specified. Each approval_rule block requires the fields documented below.\n* `source` - (Optional) Configuration block(s) with alternate sources for patches. Applies to Linux instances only. Documented below.\n* `rejected_patches_action` - (Optional) The action for Patch Manager to take on patches included in the `rejected_patches` list. Allow values are `ALLOW_AS_DEPENDENCY` and `BLOCK`.\n* `approved_patches_enable_non_security` - (Optional) Indicates whether the list of approved patches includes non-security updates that should be applied to the instances. Applies to Linux instances only.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\nThe `approval_rule` block supports:\n\n* `approve_after_days` - (Optional) The number of days after the release date of each patch matched by the rule the patch is marked as approved in the patch baseline. Valid Range: 0 to 100. Conflicts with `approve_until_date`\n* `approve_until_date` - (Optional) The cutoff date for auto approval of released patches. Any patches released on or before this date are installed automatically. Date is formatted as `YYYY-MM-DD`. Conflicts with `approve_after_days`\n* `patch_filter` - (Required) The patch filter group that defines the criteria for the rule. Up to 5 patch filters can be specified per approval rule using Key/Value pairs. Valid Keys are `PATCH_SET | PRODUCT | CLASSIFICATION | MSRC_SEVERITY | PATCH_ID`. Valid combinations of these Keys and the `operating_system` value can be found in the [SSM DescribePatchProperties API Reference](https://docs.aws.amazon.com/systems-manager/latest/APIReference/API_DescribePatchProperties.html). Valid Values are exact values for the patch property given as the key, or a wildcard `*`, which matches all values.\n    * `PATCH_SET` defaults to `OS` if unspecified\n* `compliance_level` - (Optional) Defines the compliance level for patches approved by this rule. Valid compliance levels include the following: `CRITICAL`, `HIGH`, `MEDIUM`, `LOW`, `INFORMATIONAL`, `UNSPECIFIED`. The default value is `UNSPECIFIED`.\n* `enable_non_security` - (Optional) Boolean enabling the application of non-security updates. The default value is 'false'. Valid for Linux instances only.\n\nThe `source` block supports:\n\n* `name` - (Required) The name specified to identify the patch source.\n* `configuration` - (Required) The value of the yum repo configuration. For information about other options available for your yum repository configuration, see the [`dnf.conf` documentation](https://man7.org/linux/man-pages/man5/dnf.conf.5.html)\n* `products` - (Required) The specific operating system versions a patch repository applies to, such as `\"Ubuntu16.04\"`, `\"AmazonLinux2016.09\"`, `\"RedhatEnterpriseLinux7.2\"` or `\"Suse12.7\"`. For lists of supported product values, see [PatchFilter](https://docs.aws.amazon.com/systems-manager/latest/APIReference/API_PatchFilter.html).\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the patch baseline.\n* `arn` - The ARN of the patch baseline.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSSM Patch Baselines can be imported by their baseline ID, e.g.,\n\n```\n$ terraform import aws_ssm_patch_baseline.example pb-12345678\n```\n",
    "basename": "ssm_patch_baseline.html"
  },
  "ssm_patch_group.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_patch_group",
    "description": "Provides an SSM Patch Group resource",
    "preview": "# Resource: aws_ssm_patch_group\n\nProvides an SSM Patch Group …",
    "content": "\n\n# Resource: aws_ssm_patch_group\n\nProvides an SSM Patch Group resource\n\n## Example Usage\n\n```terraform\nresource \"aws_ssm_patch_baseline\" \"production\" {\n  name             = \"patch-baseline\"\n  approved_patches = [\"KB123456\"]\n}\n\nresource \"aws_ssm_patch_group\" \"patchgroup\" {\n  baseline_id = aws_ssm_patch_baseline.production.id\n  patch_group = \"patch-group-name\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `baseline_id` - (Required) The ID of the patch baseline to register the patch group with.\n* `patch_group` - (Required) The name of the patch group that should be registered with the patch baseline.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the patch group and ID of the patch baseline separated by a comma (`,`).\n",
    "basename": "ssm_patch_group.html"
  },
  "ssm_resource_data_sync.html": {
    "subcategory": "SSM",
    "layout": "aws",
    "page_title": "AWS: aws_ssm_resource_data_sync",
    "description": "Provides a SSM resource data sync.",
    "preview": "# Resource: aws_ssm_resource_data_sync\n\nProvides a SSM resource data …",
    "content": "\n\n# Resource: aws_ssm_resource_data_sync\n\nProvides a SSM resource data sync.\n\n## Example Usage\n\n```terraform\nresource \"aws_s3_bucket\" \"hoge\" {\n  bucket = \"tf-test-bucket-1234\"\n}\n\nresource \"aws_s3_bucket_policy\" \"hoge\" {\n  bucket = aws_s3_bucket.hoge.bucket\n\n  policy = <<EOF\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"SSMBucketPermissionsCheck\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"ssm.amazonaws.com\"\n            },\n            \"Action\": \"s3:GetBucketAcl\",\n            \"Resource\": \"arn:aws:s3:::tf-test-bucket-1234\"\n        },\n        {\n            \"Sid\": \" SSMBucketDelivery\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"ssm.amazonaws.com\"\n            },\n            \"Action\": \"s3:PutObject\",\n            \"Resource\": [\"arn:aws:s3:::tf-test-bucket-1234/*\"],\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"s3:x-amz-acl\": \"bucket-owner-full-control\"\n                }\n            }\n        }\n    ]\n}\nEOF\n}\n\nresource \"aws_ssm_resource_data_sync\" \"foo\" {\n  name = \"foo\"\n\n  s3_destination {\n    bucket_name = aws_s3_bucket.hoge.bucket\n    region      = aws_s3_bucket.hoge.region\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) Name for the configuration.\n* `s3_destination` - (Required) Amazon S3 configuration details for the sync.\n\n## s3_destination\n\n`s3_destination` supports the following:\n\n* `bucket_name` - (Required) Name of S3 bucket where the aggregated data is stored.\n* `region` - (Required) Region with the bucket targeted by the Resource Data Sync.\n* `kms_key_arn` - (Optional) ARN of an encryption key for a destination in Amazon S3.\n* `prefix` - (Optional) Prefix for the bucket.\n* `sync_format` - (Optional) A supported sync format. Only JsonSerDe is currently supported. Defaults to JsonSerDe.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nSSM resource data sync can be imported using the `name`, e.g.,\n\n```sh\n$ terraform import aws_ssm_resource_data_sync.example example-name\n```\n",
    "basename": "ssm_resource_data_sync.html"
  },
  "ssoadmin_account_assignment.html": {
    "subcategory": "SSO Admin",
    "layout": "aws",
    "page_title": "AWS: aws_ssoadmin_account_assignment",
    "description": "Manages a Single Sign-On (SSO) Account Assignment",
    "preview": "# Resource: aws_ssoadmin_account_assignment\n\nProvides a Single …",
    "content": "\n\n# Resource: aws_ssoadmin_account_assignment\n\nProvides a Single Sign-On (SSO) Account Assignment resource\n\n## Example Usage\n\n```terraform\ndata \"aws_ssoadmin_instances\" \"example\" {}\n\ndata \"aws_ssoadmin_permission_set\" \"example\" {\n  instance_arn = tolist(data.aws_ssoadmin_instances.example.arns)[0]\n  name         = \"AWSReadOnlyAccess\"\n}\n\ndata \"aws_identitystore_group\" \"example\" {\n  identity_store_id = tolist(data.aws_ssoadmin_instances.example.identity_store_ids)[0]\n\n  filter {\n    attribute_path  = \"DisplayName\"\n    attribute_value = \"ExampleGroup\"\n  }\n}\n\nresource \"aws_ssoadmin_account_assignment\" \"example\" {\n  instance_arn       = data.aws_ssoadmin_permission_set.example.instance_arn\n  permission_set_arn = data.aws_ssoadmin_permission_set.example.arn\n\n  principal_id   = data.aws_identitystore_group.example.group_id\n  principal_type = \"GROUP\"\n\n  target_id   = \"012347678910\"\n  target_type = \"AWS_ACCOUNT\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `instance_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the SSO Instance.\n* `permission_set_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the Permission Set that the admin wants to grant the principal access to.\n* `principal_id` - (Required, Forces new resource) An identifier for an object in SSO, such as a user or group. PrincipalIds are GUIDs (For example, `f81d4fae-7dec-11d0-a765-00a0c91e6bf6`).\n* `principal_type` - (Required, Forces new resource) The entity type for which the assignment will be created. Valid values: `USER`, `GROUP`.\n* `target_id` - (Required, Forces new resource) An AWS account identifier, typically a 10-12 digit string.\n* `target_type` - (Optional, Forces new resource) The entity type for which the assignment will be created. Valid values: `AWS_ACCOUNT`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The identifier of the Account Assignment i.e., `principal_id`, `principal_type`, `target_id`, `target_type`, `permission_set_arn`, `instance_arn` separated by commas (`,`).\n\n## Import\n\nSSO Account Assignments can be imported using the `principal_id`, `principal_type`, `target_id`, `target_type`, `permission_set_arn`, `instance_arn` separated by commas (`,`) e.g.,\n\n```\n$ terraform import aws_ssoadmin_account_assignment.example f81d4fae-7dec-11d0-a765-00a0c91e6bf6,GROUP,1234567890,AWS_ACCOUNT,arn:aws:sso:::permissionSet/ssoins-0123456789abcdef/ps-0123456789abcdef,arn:aws:sso:::instance/ssoins-0123456789abcdef\n```\n",
    "basename": "ssoadmin_account_assignment.html"
  },
  "ssoadmin_managed_policy_attachment.html": {
    "subcategory": "SSO Admin",
    "layout": "aws",
    "page_title": "AWS: aws_ssoadmin_managed_policy_attachment",
    "description": "Manages an IAM managed policy for a Single Sign-On (SSO) Permission Set",
    "preview": "# Resource: aws_ssoadmin_managed_policy_attachment\n\nProvides an IAM …",
    "content": "\n\n# Resource: aws_ssoadmin_managed_policy_attachment\n\nProvides an IAM managed policy for a Single Sign-On (SSO) Permission Set resource\n\n~> **NOTE:** Creating this resource will automatically [Provision the Permission Set](https://docs.aws.amazon.com/singlesignon/latest/APIReference/API_ProvisionPermissionSet.html) to apply the corresponding updates to all assigned accounts.\n\n## Example Usage\n\n```terraform\ndata \"aws_ssoadmin_instances\" \"example\" {}\n\nresource \"aws_ssoadmin_permission_set\" \"example\" {\n  name         = \"Example\"\n  instance_arn = tolist(data.aws_ssoadmin_instances.example.arns)[0]\n}\n\nresource \"aws_ssoadmin_managed_policy_attachment\" \"example\" {\n  instance_arn       = tolist(data.aws_ssoadmin_instances.example.arns)[0]\n  managed_policy_arn = \"arn:aws:iam::aws:policy/AlexaForBusinessDeviceSetup\"\n  permission_set_arn = aws_ssoadmin_permission_set.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `instance_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the SSO Instance under which the operation will be executed.\n* `managed_policy_arn` - (Required, Forces new resource) The IAM managed policy Amazon Resource Name (ARN) to be attached to the Permission Set.\n* `permission_set_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the Permission Set.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Names (ARNs) of the Managed Policy, Permission Set, and SSO Instance, separated by a comma (`,`).\n* `managed_policy_name` - The name of the IAM Managed Policy.\n\n## Import\n\nSSO Managed Policy Attachments can be imported using the `managed_policy_arn`, `permission_set_arn`, and `instance_arn` separated by a comma (`,`) e.g.,\n\n```\n$ terraform import aws_ssoadmin_managed_policy_attachment.example arn:aws:iam::aws:policy/AlexaForBusinessDeviceSetup,arn:aws:sso:::permissionSet/ssoins-2938j0x8920sbj72/ps-80383020jr9302rk,arn:aws:sso:::instance/ssoins-2938j0x8920sbj72\n```\n",
    "basename": "ssoadmin_managed_policy_attachment.html"
  },
  "ssoadmin_permission_set.html": {
    "subcategory": "SSO Admin",
    "layout": "aws",
    "page_title": "AWS: aws_ssoadmin_permission_set",
    "description": "Manages a Single Sign-On (SSO) Permission Set",
    "preview": "# Resource: aws_ssoadmin_permission_set\n\nProvides a Single Sign-On …",
    "content": "\n\n# Resource: aws_ssoadmin_permission_set\n\nProvides a Single Sign-On (SSO) Permission Set resource\n\n~> **NOTE:** Updating this resource will automatically [Provision the Permission Set](https://docs.aws.amazon.com/singlesignon/latest/APIReference/API_ProvisionPermissionSet.html) to apply the corresponding updates to all assigned accounts.\n\n## Example Usage\n\n```terraform\ndata \"aws_ssoadmin_instances\" \"example\" {}\n\nresource \"aws_ssoadmin_permission_set\" \"example\" {\n  name             = \"Example\"\n  description      = \"An example\"\n  instance_arn     = tolist(data.aws_ssoadmin_instances.example.arns)[0]\n  relay_state      = \"https://s3.console.aws.amazon.com/s3/home?region=us-east-1#\"\n  session_duration = \"PT2H\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) The description of the Permission Set.\n* `instance_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the SSO Instance under which the operation will be executed.\n* `name` - (Required, Forces new resource) The name of the Permission Set.\n* `relay_state` - (Optional) The relay state URL used to redirect users within the application during the federation authentication process.\n* `session_duration` - (Optional) The length of time that the application user sessions are valid in the ISO-8601 standard. Default: `PT1H`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The Amazon Resource Name (ARN) of the Permission Set.\n* `id` - The Amazon Resource Names (ARNs) of the Permission Set and SSO Instance, separated by a comma (`,`).\n* `created_date` - The date the Permission Set was created in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSSO Permission Sets can be imported using the `arn` and `instance_arn` separated by a comma (`,`) e.g.,\n\n```\n$ terraform import aws_ssoadmin_permission_set.example arn:aws:sso:::permissionSet/ssoins-2938j0x8920sbj72/ps-80383020jr9302rk,arn:aws:sso:::instance/ssoins-2938j0x8920sbj72\n```\n",
    "basename": "ssoadmin_permission_set.html"
  },
  "ssoadmin_permission_set_inline_policy.html": {
    "subcategory": "SSO Admin",
    "layout": "aws",
    "page_title": "AWS: aws_ssoadmin_permission_set_inline_policy",
    "description": "Manages an IAM inline policy for a Single Sign-On (SSO) Permission Set",
    "preview": "# Resource: aws_ssoadmin_permission_set_inline_policy\n\nProvides an …",
    "content": "\n\n# Resource: aws_ssoadmin_permission_set_inline_policy\n\nProvides an IAM inline policy for a Single Sign-On (SSO) Permission Set resource\n\n~> **NOTE:** AWS Single Sign-On (SSO) only supports one IAM inline policy per [`aws_ssoadmin_permission_set`](ssoadmin_permission_set.html) resource.\nCreating or updating this resource will automatically [Provision the Permission Set](https://docs.aws.amazon.com/singlesignon/latest/APIReference/API_ProvisionPermissionSet.html) to apply the corresponding updates to all assigned accounts.\n\n## Example Usage\n\n```terraform\ndata \"aws_ssoadmin_instances\" \"example\" {}\n\nresource \"aws_ssoadmin_permission_set\" \"example\" {\n  name         = \"Example\"\n  instance_arn = tolist(data.aws_ssoadmin_instances.example.arns)[0]\n}\n\ndata \"aws_iam_policy_document\" \"example\" {\n  statement {\n    sid = \"1\"\n\n    actions = [\n      \"s3:ListAllMyBuckets\",\n      \"s3:GetBucketLocation\",\n    ]\n\n    resources = [\n      \"arn:aws:s3:::*\",\n    ]\n  }\n}\n\nresource \"aws_ssoadmin_permission_set_inline_policy\" \"example\" {\n  inline_policy      = data.aws_iam_policy_document.example.json\n  instance_arn       = aws_ssoadmin_permission_set.example.instance_arn\n  permission_set_arn = aws_ssoadmin_permission_set.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `inline_policy` - (Required) The IAM inline policy to attach to a Permission Set.\n* `instance_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the SSO Instance under which the operation will be executed.\n* `permission_set_arn` - (Required, Forces new resource) The Amazon Resource Name (ARN) of the Permission Set.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Names (ARNs) of the Permission Set and SSO Instance, separated by a comma (`,`).\n\n## Import\n\nSSO Permission Set Inline Policies can be imported using the `permission_set_arn` and `instance_arn` separated by a comma (`,`) e.g.,\n\n```\n$ terraform import aws_ssoadmin_permission_set_inline_policy.example arn:aws:sso:::permissionSet/ssoins-2938j0x8920sbj72/ps-80383020jr9302rk,arn:aws:sso:::instance/ssoins-2938j0x8920sbj72\n```\n",
    "basename": "ssoadmin_permission_set_inline_policy.html"
  },
  "storagegateway_cache.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_cache",
    "description": "Manages an AWS Storage Gateway cache",
    "preview": "# Resource: aws_storagegateway_cache\n\nManages an AWS Storage Gateway …",
    "content": "\n\n# Resource: aws_storagegateway_cache\n\nManages an AWS Storage Gateway cache.\n\n~> **NOTE:** The Storage Gateway API provides no method to remove a cache disk. Destroying this Terraform resource does not perform any Storage Gateway actions.\n\n## Example Usage\n\n```terraform\nresource \"aws_storagegateway_cache\" \"example\" {\n  disk_id     = data.aws_storagegateway_local_disk.example.id\n  gateway_arn = aws_storagegateway_gateway.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `disk_id` - (Required) Local disk identifier. For example, `pci-0000:03:00.0-scsi-0:0:0:0`.\n* `gateway_arn` - (Required) The Amazon Resource Name (ARN) of the gateway.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Combined gateway Amazon Resource Name (ARN) and local disk identifier.\n\n## Import\n\n`aws_storagegateway_cache` can be imported by using the gateway Amazon Resource Name (ARN) and local disk identifier separated with a colon (`:`), e.g.,\n\n```\n$ terraform import aws_storagegateway_cache.example arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678:pci-0000:03:00.0-scsi-0:0:0:0\n```\n",
    "basename": "storagegateway_cache.html"
  },
  "storagegateway_cached_iscsi_volume.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_cached_iscsi_volume",
    "description": "Manages an AWS Storage Gateway cached iSCSI volume",
    "preview": "# Resource: aws_storagegateway_cached_iscsi_volume\n\nManages an AWS …",
    "content": "\n\n# Resource: aws_storagegateway_cached_iscsi_volume\n\nManages an AWS Storage Gateway cached iSCSI volume.\n\n~> **NOTE:** The gateway must have cache added (e.g., via the [`aws_storagegateway_cache`](/docs/providers/aws/r/storagegateway_cache.html) resource) before creating volumes otherwise the Storage Gateway API will return an error.\n\n~> **NOTE:** The gateway must have an upload buffer added (e.g., via the [`aws_storagegateway_upload_buffer`](/docs/providers/aws/r/storagegateway_upload_buffer.html) resource) before the volume is operational to clients, however the Storage Gateway API will allow volume creation without error in that case and return volume status as `UPLOAD BUFFER NOT CONFIGURED`.\n\n## Example Usage\n\n~> **NOTE:** These examples are referencing the [`aws_storagegateway_cache`](/docs/providers/aws/r/storagegateway_cache.html) resource `gateway_arn` attribute to ensure Terraform properly adds cache before creating the volume. If you are not using this method, you may need to declare an expicit dependency (e.g., via `depends_on = [aws_storagegateway_cache.example]`) to ensure proper ordering.\n\n### Create Empty Cached iSCSI Volume\n\n```terraform\nresource \"aws_storagegateway_cached_iscsi_volume\" \"example\" {\n  gateway_arn          = aws_storagegateway_cache.example.gateway_arn\n  network_interface_id = aws_instance.example.private_ip\n  target_name          = \"example\"\n  volume_size_in_bytes = 5368709120 # 5 GB\n}\n```\n\n### Create Cached iSCSI Volume From Snapshot\n\n```terraform\nresource \"aws_storagegateway_cached_iscsi_volume\" \"example\" {\n  gateway_arn          = aws_storagegateway_cache.example.gateway_arn\n  network_interface_id = aws_instance.example.private_ip\n  snapshot_id          = aws_ebs_snapshot.example.id\n  target_name          = \"example\"\n  volume_size_in_bytes = aws_ebs_snapshot.example.volume_size * 1024 * 1024 * 1024\n}\n```\n\n### Create Cached iSCSI Volume From Source Volume\n\n```terraform\nresource \"aws_storagegateway_cached_iscsi_volume\" \"example\" {\n  gateway_arn          = aws_storagegateway_cache.example.gateway_arn\n  network_interface_id = aws_instance.example.private_ip\n  source_volume_arn    = aws_storagegateway_cached_iscsi_volume.existing.arn\n  target_name          = \"example\"\n  volume_size_in_bytes = aws_storagegateway_cached_iscsi_volume.existing.volume_size_in_bytes\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `gateway_arn` - (Required) The Amazon Resource Name (ARN) of the gateway.\n* `network_interface_id` - (Required) The network interface of the gateway on which to expose the iSCSI target. Only IPv4 addresses are accepted.\n* `target_name` - (Required) The name of the iSCSI target used by initiators to connect to the target and as a suffix for the target ARN. The target name must be unique across all volumes of a gateway.\n* `volume_size_in_bytes` - (Required) The size of the volume in bytes.\n* `snapshot_id` - (Optional) The snapshot ID of the snapshot to restore as the new cached volumeE.g., `snap-1122aabb`.\n* `source_volume_arn` - (Optional) The ARN for an existing volume. Specifying this ARN makes the new volume into an exact copy of the specified existing volume's latest recovery point. The `volume_size_in_bytes` value for this new volume must be equal to or larger than the size of the existing volume, in bytes.\n* `kms_encrypted` - (Optional) Set to `true` to use Amazon S3 server side encryption with your own AWS KMS key, or `false` to use a key managed by Amazon S3.\n* `kms_key` - (Optional) The Amazon Resource Name (ARN) of the AWS KMS key used for Amazon S3 server side encryption. Is required when `kms_encrypted` is set.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Volume Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678`.\n* `chap_enabled` - Whether mutual CHAP is enabled for the iSCSI target.\n* `id` - Volume Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678`.\n* `lun_number` - Logical disk number.\n* `network_interface_port` - The port used to communicate with iSCSI targets.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `target_arn` - Target Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/target/iqn.1997-05.com.amazon:TargetName`.\n* `volume_arn` - Volume Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678`.\n* `volume_id` - Volume ID, e.g., `vol-12345678`.\n\n## Import\n\n`aws_storagegateway_cached_iscsi_volume` can be imported by using the volume Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_storagegateway_cached_iscsi_volume.example arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678\n```\n",
    "basename": "storagegateway_cached_iscsi_volume.html"
  },
  "storagegateway_file_system_association.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_file_system_association",
    "description": "Mananges an association between an Amazon FSx file system and an Amazon FSx File Gateway.",
    "preview": "# Resource: aws_storagegateway_file_system_association\n\nAssociate an …",
    "content": "\n\n# Resource: aws_storagegateway_file_system_association\n\nAssociate an Amazon FSx file system with the FSx File Gateway. After the association process is complete, the file shares on the Amazon FSx file system are available for access through the gateway. This operation only supports the FSx File Gateway type.\n\n[FSx File Gateway requirements](https://docs.aws.amazon.com/filegateway/latest/filefsxw/Requirements.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_storagegateway_file_system_association\" \"example\" {\n  gateway_arn           = aws_storagegateway_gateway.example.arn\n  location_arn          = aws_fsx_windows_file_system.example.arn\n  username              = \"Admin\"\n  password              = \"avoid-plaintext-passwords\"\n  audit_destination_arn = aws_s3_bucket.example.arn\n}\n```\n\n## Required Services Example\n\n```terraform\ndata \"aws_ssm_parameter\" \"aws_service_storagegateway_ami_FILE_S3_latest\" {\n  name = \"/aws/service/storagegateway/ami/FILE_S3/latest\"\n}\n\nresource \"aws_instance\" \"test\" {\n  # If using a single root module to build full gateway stack\n  # you must include the dependencies below\n  depends_on = [aws_route.test, aws_vpc_dhcp_options_association.test]\n\n  ami                         = data.aws_ssm_parameter.aws_service_storagegateway_ami_FILE_S3_latest.value\n  associate_public_ip_address = true\n  instance_type               = data.aws_ec2_instance_type_offering.available.instance_type\n  vpc_security_group_ids      = [aws_security_group.test.id]\n  subnet_id                   = aws_subnet.test[0].id\n}\n\nresource \"aws_storagegateway_gateway\" \"test\" {\n  gateway_ip_address = aws_instance.test.public_ip\n  gateway_name       = \"test-sgw\"\n  gateway_timezone   = \"GMT\"\n  gateway_type       = \"FILE_FSX_SMB\"\n\n  smb_active_directory_settings {\n    domain_name = aws_directory_service_directory.test.name\n    password    = aws_directory_service_directory.test.password\n    username    = \"Admin\"\n  }\n}\n\nresource \"aws_fsx_windows_file_system\" \"test\" {\n  active_directory_id = aws_directory_service_directory.test.id\n  security_group_ids  = [aws_security_group.test.id]\n  skip_final_backup   = true\n  storage_capacity    = 32\n  subnet_ids          = [aws_subnet.test[0].id]\n  throughput_capacity = 8\n}\n\nresource \"aws_storagegateway_file_system_association\" \"fsx\" {\n\n  gateway_arn  = aws_storagegateway_gateway.test.arn\n  location_arn = aws_fsx_windows_file_system.test.arn\n  username     = \"Admin\"\n  password     = aws_directory_service_directory.test.password\n  cache_attributes {\n    cache_stale_timeout_in_seconds = 400\n  }\n  audit_destination_arn = aws_cloudwatch_log_group.test.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `gateway_arn` - (Required) The Amazon Resource Name (ARN) of the gateway.\n* `location_arn` - (Required) The Amazon Resource Name (ARN) of the Amazon FSx file system to associate with the FSx File Gateway.\n* `username` - (Required) The user name of the user credential that has permission to access the root share of the Amazon FSx file system. The user account must belong to the Amazon FSx delegated admin user group.\n* `password` - (Required, sensitive) The password of the user credential.\n* `audit_destination_arn` - (Optional) The Amazon Resource Name (ARN) of the storage used for the audit logs.\n* `cache_attributes` - (Optional) Refresh cache information. see [Cache Attributes](#cache_attributes) for more details.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### cache_attributes\n\n* `cache_stale_timeout_in_seconds` - (Optional) Refreshes a file share's cache by using Time To Live (TTL).\n TTL is the length of time since the last refresh after which access to the directory would cause the file gateway\n  to first refresh that directory's contents from the Amazon S3 bucket. Valid Values: `0` or `300` to `2592000` seconds (5 minutes to 30 days). Defaults to `0`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the FSx file system association\n* `arn` - Amazon Resource Name (ARN) of the newly created file system association.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_storagegateway_file_system_association` can be imported by using the FSx file system association Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_storagegateway_file_system_association.example arn:aws:storagegateway:us-east-1:123456789012:fs-association/fsa-0DA347732FDB40125\n```\n",
    "basename": "storagegateway_file_system_association.html"
  },
  "storagegateway_gateway.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_gateway",
    "description": "Manages an AWS Storage Gateway file, tape, or volume gateway in the provider region",
    "preview": "# Resource: aws_storagegateway_gateway\n\nManages an AWS Storage …",
    "content": "\n\n# Resource: aws_storagegateway_gateway\n\nManages an AWS Storage Gateway file, tape, or volume gateway in the provider region.\n\n~> **NOTE:** The Storage Gateway API requires the gateway to be connected to properly return information after activation. If you are receiving `The specified gateway is not connected` errors during resource creation (gateway activation), ensure your gateway instance meets the [Storage Gateway requirements](https://docs.aws.amazon.com/storagegateway/latest/userguide/Requirements.html).\n\n\n## Example Usage\n\n### Local Cache\n\n```terraform\nresource \"aws_volume_attachment\" \"test\" {\n  device_name = \"/dev/xvdb\"\n  volume_id   = aws_ebs_volume.test.id\n  instance_id = aws_instance.test.id\n}\n\ndata \"aws_storagegateway_local_disk\" \"test\" {\n  disk_node   = data.aws_volume_attachment.test.device_name\n  gateway_arn = aws_storagegateway_gateway.test.arn\n}\n\nresource \"aws_storagegateway_cache\" \"test\" {\n  disk_id     = data.aws_storagegateway_local_disk.test.disk_id\n  gateway_arn = aws_storagegateway_gateway.test.arn\n}\n```\n\n### FSx File Gateway\n\n```terraform\nresource \"aws_storagegateway_gateway\" \"example\" {\n  gateway_ip_address = \"1.2.3.4\"\n  gateway_name       = \"example\"\n  gateway_timezone   = \"GMT\"\n  gateway_type       = \"FILE_FSX_SMB\"\n  smb_active_directory_settings {\n    domain_name = \"corp.example.com\"\n    password    = \"avoid-plaintext-passwords\"\n    username    = \"Admin\"\n  }\n}\n```\n\n### S3 File Gateway\n\n```terraform\nresource \"aws_storagegateway_gateway\" \"example\" {\n  gateway_ip_address = \"1.2.3.4\"\n  gateway_name       = \"example\"\n  gateway_timezone   = \"GMT\"\n  gateway_type       = \"FILE_S3\"\n}\n```\n\n\n### Tape Gateway\n\n```terraform\nresource \"aws_storagegateway_gateway\" \"example\" {\n  gateway_ip_address  = \"1.2.3.4\"\n  gateway_name        = \"example\"\n  gateway_timezone    = \"GMT\"\n  gateway_type        = \"VTL\"\n  medium_changer_type = \"AWS-Gateway-VTL\"\n  tape_drive_type     = \"IBM-ULT3580-TD5\"\n}\n```\n\n### Volume Gateway (Cached)\n\n```terraform\nresource \"aws_storagegateway_gateway\" \"example\" {\n  gateway_ip_address = \"1.2.3.4\"\n  gateway_name       = \"example\"\n  gateway_timezone   = \"GMT\"\n  gateway_type       = \"CACHED\"\n}\n```\n\n### Volume Gateway (Stored)\n\n```terraform\nresource \"aws_storagegateway_gateway\" \"example\" {\n  gateway_ip_address = \"1.2.3.4\"\n  gateway_name       = \"example\"\n  gateway_timezone   = \"GMT\"\n  gateway_type       = \"STORED\"\n}\n```\n\n## Argument Reference\n\n~> **NOTE:** One of `activation_key` or `gateway_ip_address` must be provided for resource creation (gateway activation). Neither is required for resource import. If using `gateway_ip_address`, Terraform must be able to make an HTTP (port 80) GET request to the specified IP address from where it is running.\n\nThe following arguments are supported:\n\n* `gateway_name` - (Required) Name of the gateway.\n* `gateway_timezone` - (Required) Time zone for the gateway. The time zone is of the format \"GMT\", \"GMT-hr:mm\", or \"GMT+hr:mm\". For example, `GMT-4:00` indicates the time is 4 hours behind GMT. The time zone is used, for example, for scheduling snapshots and your gateway's maintenance schedule.\n* `activation_key` - (Optional) Gateway activation key during resource creation. Conflicts with `gateway_ip_address`. Additional information is available in the [Storage Gateway User Guide](https://docs.aws.amazon.com/storagegateway/latest/userguide/get-activation-key.html).\n* `average_download_rate_limit_in_bits_per_sec` - (Optional) The average download bandwidth rate limit in bits per second. This is supported for the `CACHED`, `STORED`, and `VTL` gateway types.\n* `average_upload_rate_limit_in_bits_per_sec` - (Optional) The average upload bandwidth rate limit in bits per second. This is supported for the `CACHED`, `STORED`, and `VTL` gateway types.\n* `gateway_ip_address` - (Optional) Gateway IP address to retrieve activation key during resource creation. Conflicts with `activation_key`. Gateway must be accessible on port 80 from where Terraform is running. Additional information is available in the [Storage Gateway User Guide](https://docs.aws.amazon.com/storagegateway/latest/userguide/get-activation-key.html).\n* `gateway_type` - (Optional) Type of the gateway. The default value is `STORED`. Valid values: `CACHED`, `FILE_FSX_SMB`, `FILE_S3`, `STORED`, `VTL`.\n* `gateway_vpc_endpoint` - (Optional) VPC endpoint address to be used when activating your gateway. This should be used when your instance is in a private subnet. Requires HTTP access from client computer running terraform. More info on what ports are required by your VPC Endpoint Security group in [Activating a Gateway in a Virtual Private Cloud](https://docs.aws.amazon.com/storagegateway/latest/userguide/gateway-private-link.html).\n* `cloudwatch_log_group_arn` - (Optional) The Amazon Resource Name (ARN) of the Amazon CloudWatch log group to use to monitor and log events in the gateway.\n* `medium_changer_type` - (Optional) Type of medium changer to use for tape gateway. Terraform cannot detect drift of this argument. Valid values: `STK-L700`, `AWS-Gateway-VTL`, `IBM-03584L32-0402`.\n* `smb_active_directory_settings` - (Optional) Nested argument with Active Directory domain join information for Server Message Block (SMB) file shares. Only valid for `FILE_S3` and `FILE_FSX_SMB` gateway types. Must be set before creating `ActiveDirectory` authentication SMB file shares. More details below.\n* `smb_guest_password` - (Optional) Guest password for Server Message Block (SMB) file shares. Only valid for `FILE_S3` and `FILE_FSX_SMB` gateway types. Must be set before creating `GuestAccess` authentication SMB file shares. Terraform can only detect drift of the existence of a guest password, not its actual value from the gateway. Terraform can however update the password with changing the argument.\n* `smb_security_strategy` - (Optional) Specifies the type of security strategy. Valid values are: `ClientSpecified`, `MandatorySigning`, and `MandatoryEncryption`. See [Setting a Security Level for Your Gateway](https://docs.aws.amazon.com/storagegateway/latest/userguide/managing-gateway-file.html#security-strategy) for more information.\n* `smb_file_share_visibility` - (Optional) Specifies whether the shares on this gateway appear when listing shares.\n* `tape_drive_type` - (Optional) Type of tape drive to use for tape gateway. Terraform cannot detect drift of this argument. Valid values: `IBM-ULT3580-TD5`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### smb_active_directory_settings\n\nInformation to join the gateway to an Active Directory domain for Server Message Block (SMB) file shares.\n\n~> **NOTE** It is not possible to unconfigure this setting without recreating the gateway. Also, Terraform can only detect drift of the `domain_name` argument from the gateway.\n\n~> **NOTE:** The Storage Gateway needs to be able to resolve the name of your Active Directory Domain Controller. If the gateway is hosted on EC2, ensure that DNS/DHCP is configured prior to creating the EC2 instance. If you are receiving `NETWORK_ERROR` errors during resource creation (gateway joining the domain), ensure your gateway instance meets the [FSx File Gateway requirements](https://docs.aws.amazon.com/filegateway/latest/filefsxw/Requirements.html).\n\n* `domain_name` - (Required) The name of the domain that you want the gateway to join.\n* `password` - (Required) The password of the user who has permission to add the gateway to the Active Directory domain.\n* `username` - (Required) The user name of user who has permission to add the gateway to the Active Directory domain.\n* `timeout_in_seconds` - (Optional) Specifies the time in seconds, in which the JoinDomain operation must complete. The default is `20` seconds.\n* `organizational_unit` - (Optional) The organizational unit (OU) is a container in an Active Directory that can hold users, groups,\n computers, and other OUs and this parameter specifies the OU that the gateway will join within the AD domain.\n* `domain_controllers` - (Optional) List of IPv4 addresses, NetBIOS names, or host names of your domain server.\n If you need to specify the port number include it after the colon (“:”). For example, `mydc.mydomain.com:389`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the gateway.\n* `arn` - Amazon Resource Name (ARN) of the gateway.\n* `gateway_id` - Identifier of the gateway.\n* `ec2_instance_id` - The ID of the Amazon EC2 instance that was used to launch the gateway.\n* `endpoint_type` - The type of endpoint for your gateway.\n* `host_environment` - The type of hypervisor environment used by the host.\n* `gateway_network_interface` - An array that contains descriptions of the gateway network interfaces. See [Gateway Network Interface](#gateway-network-interface).\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n### Gateway Network Interface\n\n* `ipv4_address` - The Internet Protocol version 4 (IPv4) address of the interface.\n\n## Timeouts\n\n`aws_storagegateway_gateway` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `10m`) How long to wait for gateway activation and connection to Storage Gateway.\n\n## Import\n\n`aws_storagegateway_gateway` can be imported by using the gateway Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_storagegateway_gateway.example arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678\n```\n\nCertain resource arguments, like `gateway_ip_address` do not have a Storage Gateway API method for reading the information after creation, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n\n```terraform\nresource \"aws_storagegateway_gateway\" \"example\" {\n  # ... other configuration ...\n\n  gateway_ip_address = aws_instance.sgw.private_ip\n  # There is no Storage Gateway API for reading gateway_ip_address\n  lifecycle {\n    ignore_changes = [\"gateway_ip_address\"]\n  }\n}\n```\n",
    "basename": "storagegateway_gateway.html"
  },
  "storagegateway_nfs_file_share.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_nfs_file_share",
    "description": "Manages an AWS Storage Gateway NFS File Share",
    "preview": "# Resource: aws_storagegateway_nfs_file_share\n\nManages an AWS …",
    "content": "\n\n# Resource: aws_storagegateway_nfs_file_share\n\nManages an AWS Storage Gateway NFS File Share.\n\n## Example Usage\n\n```terraform\nresource \"aws_storagegateway_nfs_file_share\" \"example\" {\n  client_list  = [\"0.0.0.0/0\"]\n  gateway_arn  = aws_storagegateway_gateway.example.arn\n  location_arn = aws_s3_bucket.example.arn\n  role_arn     = aws_iam_role.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `client_list` - (Required) The list of clients that are allowed to access the file gateway. The list must contain either valid IP addresses or valid CIDR blocks. Set to `[\"0.0.0.0/0\"]` to not limit access. Minimum 1 item. Maximum 100 items.\n* `gateway_arn` - (Required) Amazon Resource Name (ARN) of the file gateway.\n* `location_arn` - (Required) The ARN of the backed storage used for storing file data.\n* `role_arn` - (Required) The ARN of the AWS Identity and Access Management (IAM) role that a file gateway assumes when it accesses the underlying storage.\n* `audit_destination_arn` - (Optional) The Amazon Resource Name (ARN) of the storage used for audit logs.\n* `default_storage_class` - (Optional) The default [storage class](https://docs.aws.amazon.com/storagegateway/latest/APIReference/API_CreateNFSFileShare.html#StorageGateway-CreateNFSFileShare-request-DefaultStorageClass) for objects put into an Amazon S3 bucket by the file gateway. Defaults to `S3_STANDARD`.\n* `guess_mime_type_enabled` - (Optional) Boolean value that enables guessing of the MIME type for uploaded objects based on file extensions. Defaults to `true`.\n* `kms_encrypted` - (Optional) Boolean value if `true` to use Amazon S3 server side encryption with your own AWS KMS key, or `false` to use a key managed by Amazon S3. Defaults to `false`.\n* `kms_key_arn` - (Optional) Amazon Resource Name (ARN) for KMS key used for Amazon S3 server side encryption. This value can only be set when `kms_encrypted` is true.\n* `nfs_file_share_defaults` - (Optional) Nested argument with file share default values. More information below. see [NFS File Share Defaults](#nfs_file_share_defaults) for more details.\n* `cache_attributes` - (Optional) Refresh cache information. see [Cache Attributes](#cache_attributes) for more details.\n* `object_acl` - (Optional) Access Control List permission for S3 bucket objects. Defaults to `private`.\n* `read_only` - (Optional) Boolean to indicate write status of file share. File share does not accept writes if `true`. Defaults to `false`.\n* `requester_pays` - (Optional) Boolean who pays the cost of the request and the data download from the Amazon S3 bucket. Set this value to `true` if you want the requester to pay instead of the bucket owner. Defaults to `false`.\n* `squash` - (Optional) Maps a user to anonymous user. Defaults to `RootSquash`. Valid values: `RootSquash` (only root is mapped to anonymous user), `NoSquash` (no one is mapped to anonymous user), `AllSquash` (everyone is mapped to anonymous user)\n* `file_share_name` - (Optional) The name of the file share. Must be set if an S3 prefix name is set in `location_arn`.\n* `notification_policy` - (Optional) The notification policy of the file share. For more information see the [AWS Documentation](https://docs.aws.amazon.com/storagegateway/latest/APIReference/API_CreateNFSFileShare.html#StorageGateway-CreateNFSFileShare-request-NotificationPolicy). Default value is `{}`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### nfs_file_share_defaults\n\nFiles and folders stored as Amazon S3 objects in S3 buckets don't, by default, have Unix file permissions assigned to them. Upon discovery in an S3 bucket by Storage Gateway, the S3 objects that represent files and folders are assigned these default Unix permissions.\n\n* `directory_mode` - (Optional) The Unix directory mode in the string form \"nnnn\". Defaults to `\"0777\"`.\n* `file_mode` - (Optional) The Unix file mode in the string form \"nnnn\". Defaults to `\"0666\"`.\n* `group_id` - (Optional) The default group ID for the file share (unless the files have another group ID specified). Defaults to `65534` (`nfsnobody`). Valid values: `0` through `4294967294`.\n* `owner_id` - (Optional) The default owner ID for the file share (unless the files have another owner ID specified). Defaults to `65534` (`nfsnobody`). Valid values: `0` through `4294967294`.\n\n### cache_attributes\n\n* `cache_stale_timeout_in_seconds` - (Optional) Refreshes a file share's cache by using Time To Live (TTL).\n TTL is the length of time since the last refresh after which access to the directory would cause the file gateway\n  to first refresh that directory's contents from the Amazon S3 bucket. Valid Values: 300 to 2,592,000 seconds (5 minutes to 30 days)\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the NFS File Share.\n* `arn` - Amazon Resource Name (ARN) of the NFS File Share.\n* `fileshare_id` - ID of the NFS File Share.\n* `path` - File share path used by the NFS client to identify the mount point.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_storagegateway_nfs_file_share` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `10m`) How long to wait for file share creation.\n* `update` - (Default `10m`) How long to wait for file share updates.\n* `delete` - (Default `10m`) How long to wait for file share deletion.\n\n## Import\n\n`aws_storagegateway_nfs_file_share` can be imported by using the NFS File Share Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_storagegateway_nfs_file_share.example arn:aws:storagegateway:us-east-1:123456789012:share/share-12345678\n```\n",
    "basename": "storagegateway_nfs_file_share.html"
  },
  "storagegateway_smb_file_share.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_smb_file_share",
    "description": "Manages an AWS Storage Gateway SMB File Share",
    "preview": "# Resource: aws_storagegateway_smb_file_share\n\nManages an AWS …",
    "content": "\n\n# Resource: aws_storagegateway_smb_file_share\n\nManages an AWS Storage Gateway SMB File Share.\n\n## Example Usage\n\n### Active Directory Authentication\n\n~> **NOTE:** The gateway must have already joined the Active Directory domain prior to SMB file share creationE.g., via \"SMB Settings\" in the AWS Storage Gateway console or `smb_active_directory_settings` in the [`aws_storagegateway_gateway` resource](/docs/providers/aws/r/storagegateway_gateway.html).\n\n```terraform\nresource \"aws_storagegateway_smb_file_share\" \"example\" {\n  authentication = \"ActiveDirectory\"\n  gateway_arn    = aws_storagegateway_gateway.example.arn\n  location_arn   = aws_s3_bucket.example.arn\n  role_arn       = aws_iam_role.example.arn\n}\n```\n\n### Guest Authentication\n\n~> **NOTE:** The gateway must have already had the SMB guest password set prior to SMB file share creationE.g., via \"SMB Settings\" in the AWS Storage Gateway console or `smb_guest_password` in the [`aws_storagegateway_gateway` resource](/docs/providers/aws/r/storagegateway_gateway.html).\n\n```terraform\nresource \"aws_storagegateway_smb_file_share\" \"example\" {\n  authentication = \"GuestAccess\"\n  gateway_arn    = aws_storagegateway_gateway.example.arn\n  location_arn   = aws_s3_bucket.example.arn\n  role_arn       = aws_iam_role.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `gateway_arn` - (Required) Amazon Resource Name (ARN) of the file gateway.\n* `location_arn` - (Required) The ARN of the backed storage used for storing file data.\n* `vpc_endpoint_dns_name` - (Optional) The DNS name of the VPC endpoint for S3 private link.\n* `bucket_region` - (Optional) The region of the S3 buck used by the file share. Required when specifying a `vpc_endpoint_dns_name`.\n* `role_arn` - (Required) The ARN of the AWS Identity and Access Management (IAM) role that a file gateway assumes when it accesses the underlying storage.\n* `admin_user_list` - (Optional) A list of users in the Active Directory that have admin access to the file share. Only valid if `authentication` is set to `ActiveDirectory`.\n* `authentication` - (Optional) The authentication method that users use to access the file share. Defaults to `ActiveDirectory`. Valid values: `ActiveDirectory`, `GuestAccess`.\n* `audit_destination_arn` - (Optional) The Amazon Resource Name (ARN) of the CloudWatch Log Group used for the audit logs.\n* `default_storage_class` - (Optional) The default [storage class](https://docs.aws.amazon.com/storagegateway/latest/APIReference/API_CreateNFSFileShare.html#StorageGateway-CreateNFSFileShare-request-DefaultStorageClass) for objects put into an Amazon S3 bucket by the file gateway. Defaults to `S3_STANDARD`.\n* `file_share_name` - (Optional) The name of the file share. Must be set if an S3 prefix name is set in `location_arn`.\n* `guess_mime_type_enabled` - (Optional) Boolean value that enables guessing of the MIME type for uploaded objects based on file extensions. Defaults to `true`.\n* `invalid_user_list` - (Optional) A list of users in the Active Directory that are not allowed to access the file share. Only valid if `authentication` is set to `ActiveDirectory`.\n* `kms_encrypted` - (Optional) Boolean value if `true` to use Amazon S3 server side encryption with your own AWS KMS key, or `false` to use a key managed by Amazon S3. Defaults to `false`.\n* `kms_key_arn` - (Optional) Amazon Resource Name (ARN) for KMS key used for Amazon S3 server side encryption. This value can only be set when `kms_encrypted` is true.\n* `object_acl` - (Optional) Access Control List permission for S3 bucket objects. Defaults to `private`.\n* `oplocks_enabled` - (Optional) Boolean to indicate Opportunistic lock (oplock) status. Defaults to `true`.\n* `cache_attributes` - (Optional) Refresh cache information. see [Cache Attributes](#cache_attributes) for more details.\n* `read_only` - (Optional) Boolean to indicate write status of file share. File share does not accept writes if `true`. Defaults to `false`.\n* `requester_pays` - (Optional) Boolean who pays the cost of the request and the data download from the Amazon S3 bucket. Set this value to `true` if you want the requester to pay instead of the bucket owner. Defaults to `false`.\n* `smb_acl_enabled` - (Optional) Set this value to `true` to enable ACL (access control list) on the SMB fileshare. Set it to `false` to map file and directory permissions to the POSIX permissions. This setting applies only to `ActiveDirectory` authentication type.\n* `case_sensitivity` - (Optional) The case of an object name in an Amazon S3 bucket. For `ClientSpecified`, the client determines the case sensitivity. For `CaseSensitive`, the gateway determines the case sensitivity. The default value is `ClientSpecified`.\n* `valid_user_list` - (Optional) A list of users in the Active Directory that are allowed to access the file share. If you need to specify an Active directory group, add '@' before the name of the group. It will be set on Allowed group in AWS console. Only valid if `authentication` is set to `ActiveDirectory`.\n* `access_based_enumeration` - (Optional) The files and folders on this share will only be visible to users with read access. Default value is `false`.\n* `notification_policy` - (Optional) The notification policy of the file share. For more information see the [AWS Documentation](https://docs.aws.amazon.com/storagegateway/latest/APIReference/API_CreateNFSFileShare.html#StorageGateway-CreateNFSFileShare-request-NotificationPolicy). Default value is `{}`.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### cache_attributes\n\n* `cache_stale_timeout_in_seconds` - (Optional) Refreshes a file share's cache by using Time To Live (TTL).\n TTL is the length of time since the last refresh after which access to the directory would cause the file gateway\n  to first refresh that directory's contents from the Amazon S3 bucket. Valid Values: 300 to 2,592,000 seconds (5 minutes to 30 days)\n\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Amazon Resource Name (ARN) of the SMB File Share.\n* `arn` - Amazon Resource Name (ARN) of the SMB File Share.\n* `fileshare_id` - ID of the SMB File Share.\n* `path` - File share path used by the NFS client to identify the mount point.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_storagegateway_smb_file_share` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n* `create` - (Default `10m`) How long to wait for file share creation.\n* `update` - (Default `10m`) How long to wait for file share updates.\n* `delete` - (Default `15m`) How long to wait for file share deletion.\n\n## Import\n\n`aws_storagegateway_smb_file_share` can be imported by using the SMB File Share Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_storagegateway_smb_file_share.example arn:aws:storagegateway:us-east-1:123456789012:share/share-12345678\n```\n",
    "basename": "storagegateway_smb_file_share.html"
  },
  "storagegateway_stored_iscsi_volume.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_stored_iscsi_volume",
    "description": "Manages an AWS Storage Gateway stored iSCSI volume",
    "preview": "# Resource: aws_storagegateway_stored_iscsi_volume\n\nManages an AWS …",
    "content": "\n\n# Resource: aws_storagegateway_stored_iscsi_volume\n\nManages an AWS Storage Gateway stored iSCSI volume.\n\n~> **NOTE:** The gateway must have a working storage added (e.g., via the [`aws_storagegateway_working_storage`](/docs/providers/aws/r/storagegateway_working_storage.html) resource) before the volume is operational to clients, however the Storage Gateway API will allow volume creation without error in that case and return volume status as `WORKING STORAGE NOT CONFIGURED`.\n\n## Example Usage\n\n### Create Empty Stored iSCSI Volume\n\n```terraform\nresource \"aws_storagegateway_stored_iscsi_volume\" \"example\" {\n  gateway_arn            = aws_storagegateway_cache.example.gateway_arn\n  network_interface_id   = aws_instance.example.private_ip\n  target_name            = \"example\"\n  preserve_existing_data = false\n  disk_id                = data.aws_storagegateway_local_disk.test.id\n}\n```\n\n### Create Stored iSCSI Volume From Snapshot\n\n```terraform\nresource \"aws_storagegateway_stored_iscsi_volume\" \"example\" {\n  gateway_arn            = aws_storagegateway_cache.example.gateway_arn\n  network_interface_id   = aws_instance.example.private_ip\n  snapshot_id            = aws_ebs_snapshot.example.id\n  target_name            = \"example\"\n  preserve_existing_data = false\n  disk_id                = data.aws_storagegateway_local_disk.test.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `gateway_arn` - (Required) The Amazon Resource Name (ARN) of the gateway.\n* `network_interface_id` - (Required) The network interface of the gateway on which to expose the iSCSI target. Only IPv4 addresses are accepted.\n* `target_name` - (Required) The name of the iSCSI target used by initiators to connect to the target and as a suffix for the target ARN. The target name must be unique across all volumes of a gateway.\n* `disk_id` - (Required) The unique identifier for the gateway local disk that is configured as a stored volume.\n* `preserve_existing_data` - (Required) Specify this field as `true` if you want to preserve the data on the local disk. Otherwise, specifying this field as false creates an empty volume.\n* `snapshot_id` - (Optional) The snapshot ID of the snapshot to restore as the new stored volumeE.g., `snap-1122aabb`.\n* `kms_encrypted` - (Optional) `true` to use Amazon S3 server side encryption with your own AWS KMS key, or `false` to use a key managed by Amazon S3. Optional.\n* `kms_key` - (Optional) The Amazon Resource Name (ARN) of the AWS KMS key used for Amazon S3 server side encryption. This value can only be set when `kms_encrypted` is `true`.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Volume Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678`.\n* `chap_enabled` - Whether mutual CHAP is enabled for the iSCSI target.\n* `id` - Volume Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678`.\n* `lun_number` - Logical disk number.\n* `network_interface_port` - The port used to communicate with iSCSI targets.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `target_arn` - Target Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/target/iqn.1997-05.com.amazon:TargetName`.\n* `volume_arn` - Volume Amazon Resource Name (ARN), e.g., `arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678`.\n* `volume_id` - Volume ID, e.g., `vol-12345678`.\n* `volume_status` - indicates the state of the storage volume.\n* `volume_type` - indicates the type of the volume.\n* `volume_size_in_bytes` - The size of the data stored on the volume in bytes.\n* `volume_attachment_status` - A value that indicates whether a storage volume is attached to, detached from, or is in the process of detaching from a gateway.\n\n## Import\n\n`aws_storagegateway_stored_iscsi_volume` can be imported by using the volume Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_storagegateway_stored_iscsi_volume.example arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678/volume/vol-12345678\n```\n",
    "basename": "storagegateway_stored_iscsi_volume.html"
  },
  "storagegateway_tape_pool.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_tape_pool",
    "description": "Manages an AWS Storage Gateway Tape Pool",
    "preview": "# Resource: aws_storagegateway_tape_pool\n\nManages an AWS Storage …",
    "content": "\n\n# Resource: aws_storagegateway_tape_pool\n\nManages an AWS Storage Gateway Tape Pool.\n\n## Example Usage\n\n```terraform\nresource \"aws_storagegateway_tape_pool\" \"example\" {\n  pool_name     = \"example\"\n  storage_class = \"GLACIER\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `pool_name` - (Required) The name of the new custom tape pool.\n* `storage_class` - (Required) The storage class that is associated with the new custom pool. When you use your backup application to eject the tape, the tape is archived directly into the storage class that corresponds to the pool. Possible values are `DEEP_ARCHIVE` or `GLACIER`.\n* `retention_lock_type` - (Required) Tape retention lock can be configured in two modes. When configured in governance mode, AWS accounts with specific IAM permissions are authorized to remove the tape retention lock from archived virtual tapes. When configured in compliance mode, the tape retention lock cannot be removed by any user, including the root AWS account. Possible values are `COMPLIANCE`, `GOVERNANCE`, and `NONE`. Default value is `NONE`.\n* `retention_lock_time_in_days` - (Optional) Tape retention lock time is set in days. Tape retention lock can be enabled for up to 100 years (36,500 days). Default value is 0.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Volume Amazon Resource Name (ARN), e.g., `aws_storagegateway_tape_pool.example arn:aws:storagegateway:us-east-1:123456789012:tapepool/pool-12345678`.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\n`aws_storagegateway_tape_pool` can be imported by using the volume Amazon Resource Name (ARN), e.g.,\n\n```\n$ terraform import aws_storagegateway_tape_pool.example arn:aws:storagegateway:us-east-1:123456789012:tapepool/pool-12345678\n```\n",
    "basename": "storagegateway_tape_pool.html"
  },
  "storagegateway_upload_buffer.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_upload_buffer",
    "description": "Manages an AWS Storage Gateway upload buffer",
    "preview": "# Resource: aws_storagegateway_upload_buffer\n\nManages an AWS Storage …",
    "content": "\n\n# Resource: aws_storagegateway_upload_buffer\n\nManages an AWS Storage Gateway upload buffer.\n\n~> **NOTE:** The Storage Gateway API provides no method to remove an upload buffer disk. Destroying this Terraform resource does not perform any Storage Gateway actions.\n\n## Example Usage\n\n### Cached and VTL Gateway Type\n\n```terraform\ndata \"aws_storagegateway_local_disk\" \"test\" {\n  disk_node   = aws_volume_attachment.test.device_name\n  gateway_arn = aws_storagegateway_gateway.test.arn\n}\n\nresource \"aws_storagegateway_upload_buffer\" \"test\" {\n  disk_path   = data.aws_storagegateway_local_disk.test.disk_path\n  gateway_arn = aws_storagegateway_gateway.test.arn\n}\n```\n\n### Stored Gateway Type\n\n```terraform\ndata \"aws_storagegateway_local_disk\" \"test\" {\n  disk_node   = aws_volume_attachment.test.device_name\n  gateway_arn = aws_storagegateway_gateway.test.arn\n}\n\nresource \"aws_storagegateway_upload_buffer\" \"example\" {\n  disk_id     = data.aws_storagegateway_local_disk.example.id\n  gateway_arn = aws_storagegateway_gateway.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `disk_id` - (Optional) Local disk identifier. For example, `pci-0000:03:00.0-scsi-0:0:0:0`.\n* `disk_path` - (Optional) Local disk path. For example, `/dev/nvme1n1`.\n* `gateway_arn` - (Required) The Amazon Resource Name (ARN) of the gateway.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Combined gateway Amazon Resource Name (ARN) and local disk identifier.\n\n## Import\n\n`aws_storagegateway_upload_buffer` can be imported by using the gateway Amazon Resource Name (ARN) and local disk identifier separated with a colon (`:`), e.g.,\n\n```\n$ terraform import aws_storagegateway_upload_buffer.example arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678:pci-0000:03:00.0-scsi-0:0:0:0\n```\n",
    "basename": "storagegateway_upload_buffer.html"
  },
  "storagegateway_working_storage.html": {
    "subcategory": "Storage Gateway",
    "layout": "aws",
    "page_title": "AWS: aws_storagegateway_working_storage",
    "description": "Manages an AWS Storage Gateway working storage",
    "preview": "# Resource: aws_storagegateway_working_storage\n\nManages an AWS …",
    "content": "\n\n# Resource: aws_storagegateway_working_storage\n\nManages an AWS Storage Gateway working storage.\n\n~> **NOTE:** The Storage Gateway API provides no method to remove a working storage disk. Destroying this Terraform resource does not perform any Storage Gateway actions.\n\n## Example Usage\n\n```terraform\nresource \"aws_storagegateway_working_storage\" \"example\" {\n  disk_id     = data.aws_storagegateway_local_disk.example.id\n  gateway_arn = aws_storagegateway_gateway.example.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `disk_id` - (Required) Local disk identifier. For example, `pci-0000:03:00.0-scsi-0:0:0:0`.\n* `gateway_arn` - (Required) The Amazon Resource Name (ARN) of the gateway.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Combined gateway Amazon Resource Name (ARN) and local disk identifier.\n\n## Import\n\n`aws_storagegateway_working_storage` can be imported by using the gateway Amazon Resource Name (ARN) and local disk identifier separated with a colon (`:`), e.g.,\n\n```\n$ terraform import aws_storagegateway_working_storage.example arn:aws:storagegateway:us-east-1:123456789012:gateway/sgw-12345678:pci-0000:03:00.0-scsi-0:0:0:0\n```\n",
    "basename": "storagegateway_working_storage.html"
  },
  "subnet.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_subnet",
    "description": "Provides an VPC subnet resource.",
    "preview": "# Resource: aws_subnet\n\nProvides an VPC subnet resource.\n\n~> …",
    "content": "\n\n# Resource: aws_subnet\n\nProvides an VPC subnet resource.\n\n~> **NOTE:** Due to [AWS Lambda improved VPC networking changes that began deploying in September 2019](https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/), subnets associated with Lambda Functions can take up to 45 minutes to successfully delete. Terraform AWS Provider version 2.31.0 and later automatically handles this increased timeout, however prior versions require setting the [customizable deletion timeout](#timeouts) to 45 minutes (`delete = \"45m\"`). AWS and HashiCorp are working together to reduce the amount of time required for resource deletion and updates can be tracked in this [GitHub issue](https://github.com/hashicorp/terraform-provider-aws/issues/10329).\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_subnet\" \"main\" {\n  vpc_id     = aws_vpc.main.id\n  cidr_block = \"10.0.1.0/24\"\n\n  tags = {\n    Name = \"Main\"\n  }\n}\n```\n\n### Subnets In Secondary VPC CIDR Blocks\n\nWhen managing subnets in one of a VPC's secondary CIDR blocks created using a [`aws_vpc_ipv4_cidr_block_association`](vpc_ipv4_cidr_block_association.html)\nresource, it is recommended to reference that resource's `vpc_id` attribute to ensure correct dependency ordering.\n\n```terraform\nresource \"aws_vpc_ipv4_cidr_block_association\" \"secondary_cidr\" {\n  vpc_id     = aws_vpc.main.id\n  cidr_block = \"172.2.0.0/16\"\n}\n\nresource \"aws_subnet\" \"in_secondary_cidr\" {\n  vpc_id     = aws_vpc_ipv4_cidr_block_association.secondary_cidr.vpc_id\n  cidr_block = \"172.2.0.0/24\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `availability_zone` - (Optional) The AZ for the subnet.\n* `availability_zone_id` - (Optional) The AZ ID of the subnet.\n* `cidr_block` - (Required) The CIDR block for the subnet.\n* `customer_owned_ipv4_pool` - (Optional) The customer owned IPv4 address pool. Typically used with the `map_customer_owned_ip_on_launch` argument. The `outpost_arn` argument must be specified when configured.\n* `ipv6_cidr_block` - (Optional) The IPv6 network range for the subnet,\n    in CIDR notation. The subnet size must use a /64 prefix length.\n* `map_customer_owned_ip_on_launch` -  (Optional) Specify `true` to indicate that network interfaces created in the subnet should be assigned a customer owned IP address. The `customer_owned_ipv4_pool` and `outpost_arn` arguments must be specified when set to `true`. Default is `false`.\n* `map_public_ip_on_launch` -  (Optional) Specify true to indicate\n    that instances launched into the subnet should be assigned\n    a public IP address. Default is `false`.\n* `outpost_arn` - (Optional) The Amazon Resource Name (ARN) of the Outpost.\n* `assign_ipv6_address_on_creation` - (Optional) Specify true to indicate\n    that network interfaces created in the specified subnet should be\n    assigned an IPv6 address. Default is `false`\n* `vpc_id` - (Required) The VPC ID.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the subnet\n* `arn` - The ARN of the subnet.\n* `ipv6_cidr_block_association_id` - The association ID for the IPv6 CIDR block.\n* `owner_id` - The ID of the AWS account that owns the subnet.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Timeouts\n\n`aws_subnet` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts)\nconfiguration options:\n\n- `create` - (Default `10m`) How long to wait for a subnet to be created.\n- `delete` - (Default `20m`) How long to retry on `DependencyViolation` errors during subnet deletion from lingering ENIs left by certain AWS services such as Elastic Load Balancing. NOTE: Lambda ENIs can take up to 45 minutes to delete, which is not affected by changing this customizable timeout (in version 2.31.0 and later of the Terraform AWS Provider) unless it is increased above 45 minutes.\n\n## Import\n\nSubnets can be imported using the `subnet id`, e.g.,\n\n```\n$ terraform import aws_subnet.public_subnet subnet-9d4a7b6c\n```\n",
    "basename": "subnet.html"
  },
  "swf_domain.html": {
    "subcategory": "SWF",
    "layout": "aws",
    "page_title": "AWS: aws_swf_domain",
    "description": "Provides an SWF Domain resource",
    "preview": "# Resource: aws_swf_domain\n\nProvides an SWF Domain resource.\n\n## …",
    "content": "\n\n# Resource: aws_swf_domain\n\nProvides an SWF Domain resource.\n\n## Example Usage\n\nTo register a basic SWF domain:\n\n```terraform\nresource \"aws_swf_domain\" \"foo\" {\n  name                                        = \"foo\"\n  description                                 = \"Terraform SWF Domain\"\n  workflow_execution_retention_period_in_days = 30\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Optional, Forces new resource) The name of the domain. If omitted, Terraform will assign a random, unique name.\n* `name_prefix` - (Optional, Forces new resource) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n* `description` - (Optional, Forces new resource) The domain description.\n* `workflow_execution_retention_period_in_days` - (Required, Forces new resource) Length of time that SWF will continue to retain information about the workflow execution after the workflow execution is complete, must be between 0 and 90 days.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the domain.\n* `arn` - Amazon Resource Name (ARN)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nSWF Domains can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_swf_domain.foo test-domain\n```\n",
    "basename": "swf_domain.html"
  },
  "synthetics_canary.html": {
    "subcategory": "Synthetics",
    "layout": "aws",
    "page_title": "AWS: aws_synthetics_canary",
    "description": "Provides a Synthetics Canary resource",
    "preview": "# Resource: aws_synthetics_canary\n\nProvides a Synthetics Canary …",
    "content": "\n\n# Resource: aws_synthetics_canary\n\nProvides a Synthetics Canary resource.\n\n~> **NOTE:** When you create a canary, AWS creates supporting implicit resources. See the Amazon CloudWatch Synthetics documentation on [DeleteCanary](https://docs.aws.amazon.com/AmazonSynthetics/latest/APIReference/API_DeleteCanary.html) for a full list. Neither AWS nor Terraform deletes these implicit resources automatically when the canary is deleted. Before deleting a canary, ensure you have all the information about the canary that you need to delete the implicit resources using Terraform shell commands, the AWS Console, or AWS CLI.\n\n## Example Usage\n\n```terraform\nresource \"aws_synthetics_canary\" \"some\" {\n  name                 = \"some-canary\"\n  artifact_s3_location = \"s3://some-bucket/\"\n  execution_role_arn   = \"some-role\"\n  handler              = \"exports.handler\"\n  zip_file             = \"test-fixtures/lambdatest.zip\"\n  runtime_version      = \"syn-1.0\"\n\n  schedule {\n    expression = \"rate(0 minute)\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `artifact_s3_location` - (Required) Location in Amazon S3 where Synthetics stores artifacts from the test runs of this canary.\n* `execution_role_arn` - (Required) ARN of the IAM role to be used to run the canary. see [AWS Docs](https://docs.aws.amazon.com/AmazonSynthetics/latest/APIReference/API_CreateCanary.html#API_CreateCanary_RequestSyntax) for permissions needs for IAM Role.\n* `handler` - (Required) Entry point to use for the source code when running the canary. This value must end with the string `.handler` .\n* `name` - (Required) Name for this canary. Has a maximum length of 21 characters. Valid characters are lowercase alphanumeric, hyphen, or underscore.\n* `runtime_version` - (Required) Runtime version to use for the canary. Versions change often so consult the [Amazon CloudWatch documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Synthetics_Canaries_Library.html) for the latest valid versions. Values include `syn-python-selenium-1.0`, `syn-nodejs-puppeteer-3.0`, `syn-nodejs-2.2`, `syn-nodejs-2.1`, `syn-nodejs-2.0`, and `syn-1.0`.\n* `schedule` -  (Required) Configuration block providing how often the canary is to run and when these test runs are to stop. Detailed below.\n\nThe following arguments are optional:\n\n* `vpc_config` - (Optional) Configuration block. Detailed below.\n* `failure_retention_period` - (Optional) Number of days to retain data about failed runs of this canary. If you omit this field, the default of 31 days is used. The valid range is 1 to 455 days.\n* `run_config` - (Optional) Configuration block for individual canary runs. Detailed below.\n* `s3_bucket` - (Optional) Full bucket name which is used if your canary script is located in S3. The bucket must already exist. Specify the full bucket name including s3:// as the start of the bucket name. **Conflicts with `zip_file`.**\n* `s3_key` - (Optional) S3 key of your script. **Conflicts with `zip_file`.**\n* `s3_version` - (Optional) S3 version ID of your script. **Conflicts with `zip_file`.**\n* `start_canary` - (Optional) Whether to run or stop the canary.\n* `success_retention_period` - (Optional) Number of days to retain data about successful runs of this canary. If you omit this field, the default of 31 days is used. The valid range is 1 to 455 days.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `artifact_config` - (Optional) configuration for canary artifacts, including the encryption-at-rest settings for artifacts that the canary uploads to Amazon S3. See [Artifact Config](#artifact_config).\n* `zip_file` - (Optional) ZIP file that contains the script, if you input your canary script directly into the canary instead of referring to an S3 location. It can be up to 5 MB. **Conflicts with `s3_bucket`, `s3_key`, and `s3_version`.**\n\n### artifact_config\n\n* `s3_encryption` - (Optional) Configuration of the encryption-at-rest settings for artifacts that the canary uploads to Amazon S3. See [S3 Encryption](#s3_encryption).\n\n### s3_encryption\n\n* `encryption_mode` - (Optional) The encryption method to use for artifacts created by this canary. Valid values are: `SSE-S3` and `SSE-KMS`.\n* `kms_key_arn` - (Optional) The ARN of the customer-managed KMS key to use, if you specify `SSE-KMS` for `encryption_mode`.\n\n### schedule\n\n* `expression` - (Required) Rate expression that defines how often the canary is to run. The syntax is rate(number unit). unit can be minute, minutes, or hour.\n* `duration_in_seconds` - (Optional) Duration in seconds, for the canary to continue making regular runs according to the schedule in the Expression value.\n\n### run_config\n\n* `timeout_in_seconds` - (Optional) Number of seconds the canary is allowed to run before it must stop. If you omit this field, the frequency of the canary is used, up to a maximum of 840 (14 minutes).\n* `memory_in_mb` - (Optional) Maximum amount of memory available to the canary while it is running, in MB. The value you specify must be a multiple of 64.\n* `active_tracing` - (Optional) Whether this canary is to use active AWS X-Ray tracing when it runs. You can enable active tracing only for canaries that use version syn-nodejs-2.0 or later for their canary runtime.\n\n### vpc_config\n\nIf this canary tests an endpoint in a VPC, this structure contains information about the subnet and security groups of the VPC endpoint. For more information, see [Running a Canary in a VPC](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Synthetics_Canaries_VPC.html).\n\n* `subnet_ids` - (Required) IDs of the subnets where this canary is to run.\n* `security_group_ids` - (Required) IDs of the security groups for this canary.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the Canary.\n* `engine_arn` - ARN of the Lambda function that is used as your canary's engine.\n* `id` - Name for this canary.\n* `source_location_arn` - ARN of the Lambda layer where Synthetics stores the canary script code.\n* `status` - Canary status.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `timeline` - Structure that contains information about when the canary was created, modified, and most recently run. see [Timeline](#timeline).\n\n### vpc_config\n\n* `vpc_id` - ID of the VPC where this canary is to run.\n\n### timeline\n\n* `created` - Date and time the canary was created.\n* `last_modified` - Date and time the canary was most recently modified.\n* `last_started` - Date and time that the canary's most recent run started.\n* `last_stopped` - Date and time that the canary's most recent run ended.\n\n## Import\n\nSynthetics Canaries can be imported using the `name`, e.g.,\n\n```\n$ terraform import aws_synthetics_canary.some some-canary\n```\n",
    "basename": "synthetics_canary.html"
  },
  "timestreamwrite_database.html": {
    "subcategory": "Timestream Write",
    "layout": "aws",
    "page_title": "AWS: aws_timestreamwrite_database",
    "description": "Provides a Timestream database resource.",
    "preview": "# Resource: aws_timestreamwrite_database\n\nProvides a Timestream …",
    "content": "\n\n# Resource: aws_timestreamwrite_database\n\nProvides a Timestream database resource.\n\n## Example Usage\n\n### Basic usage\n\n```hcl\nresource \"aws_timestreamwrite_database\" \"example\" {\n  database_name = \"database-example\"\n}\n```\n\n### Full usage\n\n```hcl\nresource \"aws_timestreamwrite_database\" \"example\" {\n  database_name = \"database-example\"\n  kms_key_id    = aws_kms_key.example.arn\n\n  tags = {\n    Name = \"value\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `database_name` – (Required) The name of the Timestream database. Minimum length of 3. Maximum length of 64.\n* `kms_key_id` - (Optional) The ARN (not Alias ARN) of the KMS key to be used to encrypt the data stored in the database. If the KMS key is not specified, the database will be encrypted with a Timestream managed KMS key located in your account. Refer to [AWS managed KMS keys](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#aws-managed-cmk) for more info.\n* `tags` - (Optional) Map of tags to assign to this resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the Timestream database.\n* `arn` - The ARN that uniquely identifies this database.\n* `kms_key_id` - The ARN of the KMS key used to encrypt the data stored in the database.\n* `table_count` - The total number of tables found within the Timestream database.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nTimestream databases can be imported using the `database_name`, e.g.,\n\n```\n$ terraform import aws_timestreamwrite_database.example example\n```\n",
    "basename": "timestreamwrite_database.html"
  },
  "timestreamwrite_table.html": {
    "subcategory": "Timestream Write",
    "layout": "aws",
    "page_title": "AWS: aws_timestreamwrite_table",
    "description": "Provides a Timestream table resource.",
    "preview": "# Resource: aws_timestreamwrite_table\n\nProvides a Timestream table …",
    "content": "\n\n# Resource: aws_timestreamwrite_table\n\nProvides a Timestream table resource.\n\n## Example Usage\n\n### Basic usage\n\n```hcl\nresource \"aws_timestreamwrite_table\" \"example\" {\n  database_name = aws_timestreamwrite_database.example.database_name\n  table_name    = \"example\"\n}\n```\n\n### Full usage\n\n```hcl\nresource \"aws_timestreamwrite_table\" \"example\" {\n  database_name = aws_timestreamwrite_database.example.database_name\n  table_name    = \"example\"\n\n  retention_properties {\n    magnetic_store_retention_period_in_days = 30\n    memory_store_retention_period_in_hours  = 8\n  }\n\n  tags = {\n    Name = \"example-timestream-table\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `database_name` – (Required) The name of the Timestream database.\n* `retention_properties` - (Optional) The retention duration for the memory store and magnetic store. See [Retention Properties](#retention-properties) below for more details. If not provided, `magnetic_store_retention_period_in_days` default to 73000 and `memory_store_retention_period_in_hours` defaults to 6.\n* `table_name` - (Required) The name of the Timestream table.\n* `tags` - (Optional) Map of tags to assign to this resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Retention Properties\n\nThe `retention_properties` block supports the following arguments:\n\n* `magnetic_store_retention_period_in_days` - (Required) The duration for which data must be stored in the magnetic store. Minimum value of 1. Maximum value of 73000.\n* `memory_store_retention_period_in_hours` - (Required) The duration for which data must be stored in the memory store. Minimum value of 1. Maximum value of 8766.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The `table_name` and `database_name` separated by a colon (`:`).\n* `arn` - The ARN that uniquely identifies this table.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nTimestream tables can be imported using the `table_name` and `database_name` separate by a colon (`:`), e.g.,\n\n```\n$ terraform import aws_timestreamwrite_table.example ExampleTable:ExampleDatabase\n```\n",
    "basename": "timestreamwrite_table.html"
  },
  "transfer_access.html": {
    "subcategory": "Transfer",
    "layout": "aws",
    "page_title": "AWS: aws_transfer_access",
    "description": "Provides a AWS Transfer Access resource.",
    "preview": "# Resource: aws_transfer_access\n\nProvides a AWS Transfer Access …",
    "content": "\n\n# Resource: aws_transfer_access\n\nProvides a AWS Transfer Access resource.\n\n## Example Usage\n\n### Basic S3\n\n```terraform\nresource \"aws_transfer_access\" \"example\" {\n  external_id    = \"S-1-1-12-1234567890-123456789-1234567890-1234\"\n  server_id      = aws_transfer_server.example.id\n  role           = aws_iam_role.example.arn\n  home_directory = \"/${aws_s3_bucket.example.id}/\"\n}\n```\n\n### Basic EFS\n\n```terraform\nresource \"aws_transfer_access\" \"test\" {\n  external_id    = \"S-1-1-12-1234567890-123456789-1234567890-1234\"\n  server_id      = aws_transfer_server.test.id\n  role           = aws_iam_role.test.arn\n  home_directory = \"/${aws_efs_file_system.test.id}/\"\n  posix_profile {\n    gid = 1000\n    uid = 1000\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `external_id` - (Required) The SID of a group in the directory connected to the Transfer Server (e.g., `S-1-1-12-1234567890-123456789-1234567890-1234`)\n* `server_id` - (Required) The Server ID of the Transfer Server (e.g., `s-12345678`)\n* `home_directory` - (Optional) The landing directory (folder) for a user when they log in to the server using their SFTP client.  It should begin with a `/`.  The first item in the path is the name of the home bucket (accessible as `${Transfer:HomeBucket}` in the policy) and the rest is the home directory (accessible as `${Transfer:HomeDirectory}` in the policy). For example, `/example-bucket-1234/username` would set the home bucket to `example-bucket-1234` and the home directory to `username`.\n* `home_directory_mappings` - (Optional) Logical directory mappings that specify what S3 paths and keys should be visible to your user and how you want to make them visible. See [Home Directory Mappings](#home-directory-mappings) below.\n* `home_directory_type` - (Optional) The type of landing directory (folder) you mapped for your users' home directory. Valid values are `PATH` and `LOGICAL`.\n* `policy` - (Optional) An IAM JSON policy document that scopes down user access to portions of their Amazon S3 bucket. IAM variables you can use inside this policy include `${Transfer:UserName}`, `${Transfer:HomeDirectory}`, and `${Transfer:HomeBucket}`. Since the IAM variable syntax matches Terraform's interpolation syntax, they must be escaped inside Terraform configuration strings (`$${Transfer:UserName}`).  These are evaluated on-the-fly when navigating the bucket.\n* `posix_profile` - (Optional) Specifies the full POSIX identity, including user ID (Uid), group ID (Gid), and any secondary groups IDs (SecondaryGids), that controls your users' access to your Amazon EFS file systems. See [Posix Profile](#posix-profile) below.\n* `role` - (Required) Amazon Resource Name (ARN) of an IAM role that allows the service to controls your user’s access to your Amazon S3 bucket.\n\n### Home Directory Mappings\n\n* `entry` - (Required) Represents an entry and a target.\n* `target` - (Required) Represents the map target.\n\n### Posix Profile\n\n* `gid` - (Required) The POSIX group ID used for all EFS operations by this user.\n* `uid` - (Required) The POSIX user ID used for all EFS operations by this user.\n* `secondary_gids` - (Optional) The secondary POSIX group IDs used for all EFS operations by this user.\n\n## Attributes Reference\nIn addition to all arguments above, the following attributes are exported:\n\n* `id`  - The ID of the resource\n\n## Import\n\nTransfer Accesses can be imported using the `server_id` and `external_id`, e.g.,\n\n```\n$ terraform import aws_transfer_access.example s-12345678/S-1-1-12-1234567890-123456789-1234567890-1234\n```\n\n",
    "basename": "transfer_access.html"
  },
  "transfer_server.html": {
    "subcategory": "Transfer",
    "layout": "aws",
    "page_title": "AWS: aws_transfer_server",
    "description": "Provides a AWS Transfer Server resource.",
    "preview": "# Resource: aws_transfer_server\n\nProvides a AWS Transfer Server …",
    "content": "\n\n# Resource: aws_transfer_server\n\nProvides a AWS Transfer Server resource.\n\n~> **NOTE on AWS IAM permissions:** If the `endpoint_type` is set to `VPC`, the `ec2:DescribeVpcEndpoints` and `ec2:ModifyVpcEndpoint` [actions](https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonec2.html#amazonec2-actions-as-permissions) are used.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_transfer_server\" \"example\" {\n  tags = {\n    Name = \"Example\"\n  }\n}\n```\n\n### Security Policy Name\n\n```terraform\nresource \"aws_transfer_server\" \"example\" {\n  security_policy_name = \"TransferSecurityPolicy-2020-06\"\n}\n```\n\n### VPC Endpoint\n\n```terraform\nresource \"aws_transfer_server\" \"example\" {\n  endpoint_type = \"VPC\"\n\n  endpoint_details {\n    address_allocation_ids = [aws_eip.example.id]\n    subnet_ids             = [aws_subnet.example.id]\n    vpc_id                 = aws_vpc.example.id\n  }\n}\n```\n\n### AWS Directory authentication\n\n```terraform\nresource \"aws_transfer_server\" \"example\" {\n  identity_provider_type = \"AWS_DIRECTORY_SERVICE\"\n  directory_id           = aws_directory_service_directory.example.id\n}\n```\n\n### AWS Lambda authentication\n\n```terraform\nresource \"aws_transfer_server\" \"example\" {\n  identity_provider_type = \"AWS_LAMBDA\"\n  function               = aws_lambda_identity_provider.example.arn\n}\n```\n\n### Protocols\n\n```terraform\nresource \"aws_transfer_server\" \"example\" {\n  endpoint_type = \"VPC\"\n\n  endpoint_details {\n    subnet_ids = [aws_subnet.example.id]\n    vpc_id     = aws_vpc.example.id\n  }\n\n  protocols   = [\"FTP\", \"FTPS\"]\n  certificate = aws_acm_certificate.example.arn\n\n  identity_provider_type = \"API_GATEWAY\"\n  url                    = \"${aws_api_gateway_deployment.example.invoke_url}${aws_api_gateway_resource.example.path}\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `certificate` - (Optional) The Amazon Resource Name (ARN) of the AWS Certificate Manager (ACM) certificate. This is required when `protocols` is set to `FTPS`\n* `domain` - (Optional) The domain of the storage system that is used for file transfers. Valid values are: `S3` and `EFS`. The default value is `S3`.\n* `protocols` - (Optional) Specifies the file transfer protocol or protocols over which your file transfer protocol client can connect to your server's endpoint. This defaults to `SFTP` . The available protocols are:\n    * `SFTP`: File transfer over SSH\n    * `FTPS`: File transfer with TLS encryption\n    * `FTP`: Unencrypted file transfer\n* `endpoint_details` - (Optional) The virtual private cloud (VPC) endpoint settings that you want to configure for your SFTP server. Fields documented below.\n* `endpoint_type` - (Optional) The type of endpoint that you want your SFTP server connect to. If you connect to a `VPC` (or `VPC_ENDPOINT`), your SFTP server isn't accessible over the public internet. If you want to connect your SFTP server via public internet, set `PUBLIC`.  Defaults to `PUBLIC`.\n* `invocation_role` - (Optional) Amazon Resource Name (ARN) of the IAM role used to authenticate the user account with an `identity_provider_type` of `API_GATEWAY`.\n* `host_key` - (Optional) RSA private key (e.g., as generated by the `ssh-keygen -N \"\" -m PEM -f my-new-server-key` command).\n* `url` - (Optional) - URL of the service endpoint used to authenticate users with an `identity_provider_type` of `API_GATEWAY`.\n* `identity_provider_type` - (Optional) The mode of authentication enabled for this service. The default value is `SERVICE_MANAGED`, which allows you to store and access SFTP user credentials within the service. `API_GATEWAY` indicates that user authentication requires a call to an API Gateway endpoint URL provided by you to integrate an identity provider of your choice. Using `AWS_DIRECTORY_SERVICE` will allow for authentication against AWS Managed Active Directory or Microsoft Active Directory in your on-premises environment, or in AWS using AD Connectors. Use the `AWS_LAMBDA` value to directly use a Lambda function as your identity provider. If you choose this value, you must specify the ARN for the lambda function in the `function` argument.\n* `directory_id` - (Optional) The directory service ID of the directory service you want to connect to with an `identity_provider_type` of `AWS_DIRECTORY_SERVICE`.\n* `function` - (Optional) The ARN for a lambda function to use for the Identity provider.\n* `logging_role` - (Optional) Amazon Resource Name (ARN) of an IAM role that allows the service to write your SFTP users’ activity to your Amazon CloudWatch logs for monitoring and auditing purposes.\n* `force_destroy` - (Optional) A boolean that indicates all users associated with the server should be deleted so that the Server can be destroyed without error. The default value is `false`. This option only applies to servers configured with a `SERVICE_MANAGED` `identity_provider_type`.\n* `security_policy_name` - (Optional) Specifies the name of the security policy that is attached to the server. Possible values are `TransferSecurityPolicy-2018-11`, `TransferSecurityPolicy-2020-06`, and  `TransferSecurityPolicy-FIPS-2020-06`. Default value is: `TransferSecurityPolicy-2018-11`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n**endpoint_details** requires the following:\n\n* `address_allocation_ids` - (Optional) A list of address allocation IDs that are required to attach an Elastic IP address to your SFTP server's endpoint. This property can only be used when `endpoint_type` is set to `VPC`.\n* `security_group_ids` - (Optional) A list of security groups IDs that are available to attach to your server's endpoint. If no security groups are specified, the VPC's default security groups are automatically assigned to your endpoint. This property can only be used when `endpoint_type` is set to `VPC`.\n* `subnet_ids` - (Optional) A list of subnet IDs that are required to host your SFTP server endpoint in your VPC. This property can only be used when `endpoint_type` is set to `VPC`.\n* `vpc_endpoint_id` - (Optional) The ID of the VPC endpoint. This property can only be used when `endpoint_type` is set to `VPC_ENDPOINT`\n* `vpc_id` - (Optional) The VPC ID of the virtual private cloud in which the SFTP server's endpoint will be hosted. This property can only be used when `endpoint_type` is set to `VPC`.\n\n## Attributes Reference\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of Transfer Server\n* `id`  - The Server ID of the Transfer Server (e.g., `s-12345678`)\n* `endpoint` - The endpoint of the Transfer Server (e.g., `s-12345678.server.transfer.REGION.amazonaws.com`)\n* `host_key_fingerprint` - This value contains the message-digest algorithm (MD5) hash of the server's host key. This value is equivalent to the output of the `ssh-keygen -l -E md5 -f my-new-server-key` command.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nTransfer Servers can be imported using the `server id`, e.g.,\n\n```\n$ terraform import aws_transfer_server.example s-12345678\n```\n\nCertain resource arguments, such as `host_key`, cannot be read via the API and imported into Terraform. Terraform will display a difference for these arguments the first run after import if declared in the Terraform configuration for an imported resource.\n",
    "basename": "transfer_server.html"
  },
  "transfer_ssh_key.html": {
    "subcategory": "Transfer",
    "layout": "aws",
    "page_title": "AWS: aws_transfer_ssh_key",
    "description": "Provides a AWS Transfer SSH Public Key resource.",
    "preview": "# Resource: aws_transfer_ssh_key\n\nProvides a AWS Transfer User SSH …",
    "content": "\n\n# Resource: aws_transfer_ssh_key\n\nProvides a AWS Transfer User SSH Key resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_transfer_ssh_key\" \"example\" {\n  server_id = aws_transfer_server.example.id\n  user_name = aws_transfer_user.example.user_name\n  body      = \"... SSH key ...\"\n}\n\nresource \"aws_transfer_server\" \"example\" {\n  identity_provider_type = \"SERVICE_MANAGED\"\n\n  tags = {\n    NAME = \"tf-acc-test-transfer-server\"\n  }\n}\n\nresource \"aws_transfer_user\" \"example\" {\n  server_id = aws_transfer_server.example.id\n  user_name = \"tftestuser\"\n  role      = aws_iam_role.example.arn\n\n  tags = {\n    NAME = \"tftestuser\"\n  }\n}\n\nresource \"aws_iam_role\" \"example\" {\n  name = \"tf-test-transfer-user-iam-role\"\n\n  assume_role_policy = <<EOF\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\"Effect\": \"Allow\",\n\t\t\"Principal\": {\n\t\t\t\"Service\": \"transfer.amazonaws.com\"\n\t\t},\n\t\t\"Action\": \"sts:AssumeRole\"\n\t\t}\n\t]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"example\" {\n  name = \"tf-test-transfer-user-iam-policy\"\n  role = aws_iam_role.example.id\n\n  policy = <<POLICY\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\t\"Sid\": \"AllowFullAccesstoS3\",\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Action\": [\n\t\t\t\t\"s3:*\"\n\t\t\t],\n\t\t\t\"Resource\": \"*\"\n\t\t}\n\t]\n}\nPOLICY\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `server_id` - (Requirement) The Server ID of the Transfer Server (e.g., `s-12345678`)\n* `user_name` - (Requirement) The name of the user account that is assigned to one or more servers.\n* `body` - (Requirement) The public key portion of an SSH key pair.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nTransfer SSH Public Key can be imported using the `server_id` and `user_name` and `ssh_public_key_id` separated by `/`.\n\n```\n$ terraform import aws_transfer_ssh_key.bar s-12345678/test-username/key-12345\n```\n",
    "basename": "transfer_ssh_key.html"
  },
  "transfer_user.html": {
    "subcategory": "Transfer",
    "layout": "aws",
    "page_title": "AWS: aws_transfer_user",
    "description": "Provides a AWS Transfer User resource.",
    "preview": "# Resource: aws_transfer_user\n\nProvides a AWS Transfer User …",
    "content": "\n\n# Resource: aws_transfer_user\n\nProvides a AWS Transfer User resource. Managing SSH keys can be accomplished with the [`aws_transfer_ssh_key` resource](/docs/providers/aws/r/transfer_ssh_key.html).\n\n## Example Usage\n\n```terraform\nresource \"aws_transfer_server\" \"foo\" {\n  identity_provider_type = \"SERVICE_MANAGED\"\n\n  tags = {\n    NAME = \"tf-acc-test-transfer-server\"\n  }\n}\n\nresource \"aws_iam_role\" \"foo\" {\n  name = \"tf-test-transfer-user-iam-role\"\n\n  assume_role_policy = <<EOF\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\"Effect\": \"Allow\",\n\t\t\"Principal\": {\n\t\t\t\"Service\": \"transfer.amazonaws.com\"\n\t\t},\n\t\t\"Action\": \"sts:AssumeRole\"\n\t\t}\n\t]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"foo\" {\n  name = \"tf-test-transfer-user-iam-policy\"\n  role = aws_iam_role.foo.id\n\n  policy = <<POLICY\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\t\"Sid\": \"AllowFullAccesstoS3\",\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Action\": [\n\t\t\t\t\"s3:*\"\n\t\t\t],\n\t\t\t\"Resource\": \"*\"\n\t\t}\n\t]\n}\nPOLICY\n}\n\nresource \"aws_transfer_user\" \"foo\" {\n  server_id = aws_transfer_server.foo.id\n  user_name = \"tftestuser\"\n  role      = aws_iam_role.foo.arn\n\n  home_directory_type = \"LOGICAL\"\n  home_directory_mappings {\n    entry  = \"/test.pdf\"\n    target = \"/bucket3/test-path/tftestuser.pdf\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `server_id` - (Required) The Server ID of the Transfer Server (e.g., `s-12345678`)\n* `user_name` - (Required) The name used for log in to your SFTP server.\n* `home_directory` - (Optional) The landing directory (folder) for a user when they log in to the server using their SFTP client.  It should begin with a `/`.  The first item in the path is the name of the home bucket (accessible as `${Transfer:HomeBucket}` in the policy) and the rest is the home directory (accessible as `${Transfer:HomeDirectory}` in the policy). For example, `/example-bucket-1234/username` would set the home bucket to `example-bucket-1234` and the home directory to `username`.\n* `home_directory_mappings` - (Optional) Logical directory mappings that specify what S3 paths and keys should be visible to your user and how you want to make them visible. See [Home Directory Mappings](#home-directory-mappings) below.\n* `home_directory_type` - (Optional) The type of landing directory (folder) you mapped for your users' home directory. Valid values are `PATH` and `LOGICAL`.\n* `policy` - (Optional) An IAM JSON policy document that scopes down user access to portions of their Amazon S3 bucket. IAM variables you can use inside this policy include `${Transfer:UserName}`, `${Transfer:HomeDirectory}`, and `${Transfer:HomeBucket}`. Since the IAM variable syntax matches Terraform's interpolation syntax, they must be escaped inside Terraform configuration strings (`$${Transfer:UserName}`).  These are evaluated on-the-fly when navigating the bucket.\n* `posix_profile` - (Optional) Specifies the full POSIX identity, including user ID (Uid), group ID (Gid), and any secondary groups IDs (SecondaryGids), that controls your users' access to your Amazon EFS file systems. See [Posix Profile](#posix-profile) below.\n* `role` - (Required) Amazon Resource Name (ARN) of an IAM role that allows the service to controls your user’s access to your Amazon S3 bucket.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n\n### Home Directory Mappings\n\n* `entry` - (Required) Represents an entry and a target.\n* `target` - (Required) Represents the map target.\n\nThe `Restricted` option is achieved using the following mapping:\n\n```\nhome_directory_mappings {\n\tentry  = \"/\"\n\ttarget = \"/${aws_s3_bucket.foo.id}/$${Transfer:UserName}\"\n}\n```\n\n### Posix Profile\n\n* `gid` - (Required) The POSIX group ID used for all EFS operations by this user.\n* `uid` - (Required) The POSIX user ID used for all EFS operations by this user.\n* `secondary_gids` - (Optional) The secondary POSIX group IDs used for all EFS operations by this user.\n\n## Attributes Reference\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of Transfer User\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nTransfer Users can be imported using the `server_id` and `user_name` separated by `/`.\n\n```\n$ terraform import aws_transfer_user.bar s-12345678/test-username\n```\n",
    "basename": "transfer_user.html"
  },
  "volume_attachment.html": {
    "subcategory": "EC2",
    "layout": "aws",
    "page_title": "AWS: aws_volume_attachment",
    "description": "Provides an AWS EBS Volume Attachment",
    "preview": "# Resource: aws_volume_attachment\n\nProvides an AWS EBS Volume …",
    "content": "\n\n# Resource: aws_volume_attachment\n\nProvides an AWS EBS Volume Attachment as a top level resource, to attach and\ndetach volumes from AWS Instances.\n\n~> **NOTE on EBS block devices:** If you use `ebs_block_device` on an `aws_instance`, Terraform will assume management over the full set of non-root EBS block devices for the instance, and treats additional block devices as drift. For this reason, `ebs_block_device` cannot be mixed with external `aws_ebs_volume` + `aws_ebs_volume_attachment` resources for a given instance.\n\n## Example Usage\n\n```terraform\nresource \"aws_volume_attachment\" \"ebs_att\" {\n  device_name = \"/dev/sdh\"\n  volume_id   = aws_ebs_volume.example.id\n  instance_id = aws_instance.web.id\n}\n\nresource \"aws_instance\" \"web\" {\n  ami               = \"ami-21f78e11\"\n  availability_zone = \"us-west-2a\"\n  instance_type     = \"t2.micro\"\n\n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n\nresource \"aws_ebs_volume\" \"example\" {\n  availability_zone = \"us-west-2a\"\n  size              = 1\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `device_name` - (Required) The device name to expose to the instance (for\nexample, `/dev/sdh` or `xvdh`).  See [Device Naming on Linux Instances][1] and [Device Naming on Windows Instances][2] for more information.\n* `instance_id` - (Required) ID of the Instance to attach to\n* `volume_id` - (Required) ID of the Volume to be attached\n* `force_detach` - (Optional, Boolean) Set to `true` if you want to force the\nvolume to detach. Useful if previous attempts failed, but use this option only\nas a last resort, as this can result in **data loss**. See\n[Detaching an Amazon EBS Volume from an Instance][3] for more information.\n* `skip_destroy` - (Optional, Boolean) Set this to true if you do not wish\nto detach the volume from the instance to which it is attached at destroy\ntime, and instead just remove the attachment from Terraform state. This is\nuseful when destroying an instance which has volumes created by some other\nmeans attached.\n* `stop_instance_before_detaching` - (Optional, Boolean) Set this to true to ensure that the target instance is stopped\nbefore trying to detach the volume. Stops the instance, if it is not already stopped.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `device_name` - The device name exposed to the instance\n* `instance_id` - ID of the Instance\n* `volume_id` - ID of the Volume\n\n## Import\n\nEBS Volume Attachments can be imported using `DEVICE_NAME:VOLUME_ID:INSTANCE_ID`, e.g.,\n\n```\n$ terraform import aws_volume_attachment.example /dev/sdh:vol-049df61146c4d7901:i-12345678\n```\n\n\n[1]: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/device_naming.html#available-ec2-device-names\n[2]: https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/device_naming.html#available-ec2-device-names\n[3]: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-detaching-volume.html\n",
    "basename": "volume_attachment.html"
  },
  "vpc.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc",
    "description": "Provides a VPC resource.",
    "preview": "# Resource: aws_vpc\n\nProvides a VPC resource.\n\n## Example Usage\n …",
    "content": "\n\n# Resource: aws_vpc\n\nProvides a VPC resource.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n```\n\nBasic usage with tags:\n\n```terraform\nresource \"aws_vpc\" \"main\" {\n  cidr_block       = \"10.0.0.0/16\"\n  instance_tenancy = \"default\"\n\n  tags = {\n    Name = \"main\"\n  }\n}\n```\n\nVPC with CIDR from AWS IPAM:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam\" \"test\" {\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n}\n\nresource \"aws_vpc_ipam_pool\" \"test\" {\n  address_family = \"ipv4\"\n  ipam_scope_id  = aws_vpc_ipam.test.private_default_scope_id\n  locale         = data.aws_region.current.name\n}\n\nresource \"aws_vpc_ipam_pool_cidr\" \"test\" {\n  ipam_pool_id = aws_vpc_ipam_pool.test.id\n  cidr         = \"172.2.0.0/16\"\n}\n\nresource \"aws_vpc\" \"test\" {\n  ipv4_ipam_pool_id   = aws_vpc_ipam_pool.test.id\n  ipv4_netmask_length = 28\n  depends_on = [\n    aws_vpc_ipam_pool_cidr.test\n  ]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cidr_block` - (Optional) The IPv4 CIDR block for the VPC. CIDR can be explicitly set or it can be derived from IPAM using `ipv4_netmask_length`.\n* `instance_tenancy` - (Optional) A tenancy option for instances launched into the VPC. Default is `default`, which makes your instances shared on the host. Using either of the other options (`dedicated` or `host`) costs at least $2/hr.\n* `ipv4_ipam_pool_id` - (Optional) The ID of an IPv4 IPAM pool you want to use for allocating this VPC's CIDR. IPAM is a VPC feature that you can use to automate your IP address management workflows including assigning, tracking, troubleshooting, and auditing IP addresses across AWS Regions and accounts. Using IPAM you can monitor IP address usage throughout your AWS Organization.\n* `ipv4_netmask_length` - (Optional) The netmask length of the IPv4 CIDR you want to allocate to this VPC. Requires specifying a `ipv4_ipam_pool_id`.\n* `ipv6_cidr_block` - (Optional) IPv6 CIDR block to request from an IPAM Pool. Can be set explicitly or derived from IPAM using `ipv6_netmask_length`.\n* `ipv6_ipam_pool_id` - (Optional) IPAM Pool ID for a IPv6 pool. Conflicts with `assign_generated_ipv6_cidr_block`.\n* `ipv6_netmask_length` - (Optional) Netmask length to request from IPAM Pool. Conflicts with `ipv6_cidr_block`. This can be omitted if IPAM pool as a `allocation_default_netmask_length` set. Valid values: `56`.\n* `enable_dns_support` - (Optional) A boolean flag to enable/disable DNS support in the VPC. Defaults true.\n* `enable_dns_hostnames` - (Optional) A boolean flag to enable/disable DNS hostnames in the VPC. Defaults false.\n* `enable_classiclink` - (Optional) A boolean flag to enable/disable ClassicLink\n  for the VPC. Only valid in regions and accounts that support EC2 Classic.\n  See the [ClassicLink documentation][1] for more information. Defaults false.\n* `enable_classiclink_dns_support` - (Optional) A boolean flag to enable/disable ClassicLink DNS Support for the VPC.\n  Only valid in regions and accounts that support EC2 Classic.\n* `assign_generated_ipv6_cidr_block` - (Optional) Requests an Amazon-provided IPv6 CIDR block with a /56 prefix length for the VPC. You cannot specify the range of IP addresses, or the size of the CIDR block. Default is `false`. Conflicts with `ipv6_ipam_pool_id`\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of VPC\n* `id` - The ID of the VPC\n* `instance_tenancy` - Tenancy of instances spin up within VPC.\n* `enable_dns_support` - Whether or not the VPC has DNS support\n* `enable_dns_hostnames` - Whether or not the VPC has DNS hostname support\n* `enable_classiclink` - Whether or not the VPC has Classiclink enabled\n* `main_route_table_id` - The ID of the main route table associated with\n     this VPC. Note that you can change a VPC's main route table by using an\n     [`aws_main_route_table_association`](/docs/providers/aws/r/main_route_table_association.html).\n* `default_network_acl_id` - The ID of the network ACL created by default on VPC creation\n* `default_security_group_id` - The ID of the security group created by default on VPC creation\n* `default_route_table_id` - The ID of the route table created by default on VPC creation\n* `ipv6_association_id` - The association ID for the IPv6 CIDR block.\n* `owner_id` - The ID of the AWS account that owns the VPC.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n[1]: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html\n\n## Import\n\nVPCs can be imported using the `vpc id`, e.g.,\n\n```\n$ terraform import aws_vpc.test_vpc vpc-a01106c2\n```\n",
    "basename": "vpc.html"
  },
  "vpc_dhcp_options.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_dhcp_options",
    "description": "Provides a VPC DHCP Options resource.",
    "preview": "# Resource: aws_vpc_dhcp_options\n\nProvides a VPC DHCP Options …",
    "content": "\n\n# Resource: aws_vpc_dhcp_options\n\nProvides a VPC DHCP Options resource.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_vpc_dhcp_options\" \"dns_resolver\" {\n  domain_name_servers = [\"8.8.8.8\", \"8.8.4.4\"]\n}\n```\n\nFull usage:\n\n```terraform\nresource \"aws_vpc_dhcp_options\" \"foo\" {\n  domain_name          = \"service.consul\"\n  domain_name_servers  = [\"127.0.0.1\", \"10.0.0.2\"]\n  ntp_servers          = [\"127.0.0.1\"]\n  netbios_name_servers = [\"127.0.0.1\"]\n  netbios_node_type    = 2\n\n  tags = {\n    Name = \"foo-name\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `domain_name` - (Optional) the suffix domain name to use by default when resolving non Fully Qualified Domain Names. In other words, this is what ends up being the `search` value in the `/etc/resolv.conf` file.\n* `domain_name_servers` - (Optional) List of name servers to configure in `/etc/resolv.conf`. If you want to use the default AWS nameservers you should set this to `AmazonProvidedDNS`.\n* `ntp_servers` - (Optional) List of NTP servers to configure.\n* `netbios_name_servers` - (Optional) List of NETBIOS name servers.\n* `netbios_node_type` - (Optional) The NetBIOS node type (1, 2, 4, or 8). AWS recommends to specify 2 since broadcast and multicast are not supported in their network. For more information about these node types, see [RFC 2132](http://www.ietf.org/rfc/rfc2132.txt).\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Remarks\n\n* Notice that all arguments are optional but you have to specify at least one argument.\n* `domain_name_servers`, `netbios_name_servers`, `ntp_servers` are limited by AWS to maximum four servers only.\n* To actually use the DHCP Options Set you need to associate it to a VPC using [`aws_vpc_dhcp_options_association`](/docs/providers/aws/r/vpc_dhcp_options_association.html).\n* If you delete a DHCP Options Set, all VPCs using it will be associated to AWS's `default` DHCP Option Set.\n* In most cases unless you're configuring your own DNS you'll want to set `domain_name_servers` to `AmazonProvidedDNS`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the DHCP Options Set.\n* `arn` - The ARN of the DHCP Options Set.\n* `owner_id` - The ID of the AWS account that owns the DHCP options set.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\nYou can find more technical documentation about DHCP Options Set in the\nofficial [AWS User Guide](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_DHCP_Options.html).\n\n\n## Import\n\nVPC DHCP Options can be imported using the `dhcp options id`, e.g.,\n\n```\n$ terraform import aws_vpc_dhcp_options.my_options dopt-d9070ebb\n```\n",
    "basename": "vpc_dhcp_options.html"
  },
  "vpc_dhcp_options_association.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_dhcp_options_association",
    "description": "Provides a VPC DHCP Options Association resource.",
    "preview": "# Resource: aws_vpc_dhcp_options_association\n\nProvides a VPC DHCP …",
    "content": "\n\n# Resource: aws_vpc_dhcp_options_association\n\nProvides a VPC DHCP Options Association resource.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc_dhcp_options_association\" \"dns_resolver\" {\n  vpc_id          = aws_vpc.foo.id\n  dhcp_options_id = aws_vpc_dhcp_options.foo.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Required) The ID of the VPC to which we would like to associate a DHCP Options Set.\n* `dhcp_options_id` - (Required) The ID of the DHCP Options Set to associate to the VPC.\n\n## Remarks\n\n* You can only associate one DHCP Options Set to a given VPC ID.\n* Removing the DHCP Options Association automatically sets AWS's `default` DHCP Options Set to the VPC.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the DHCP Options Set Association.\n\n## Import\n\nDHCP associations can be imported by providing the VPC ID associated with the options:\n\n```\n$ terraform import aws_vpc_dhcp_options_association.imported vpc-0f001273ec18911b1\n```\n",
    "basename": "vpc_dhcp_options_association.html"
  },
  "vpc_endpoint.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_endpoint",
    "description": "Provides a VPC Endpoint resource.",
    "preview": "# Resource: aws_vpc_endpoint\n\nProvides a VPC Endpoint resource.\n\n~> …",
    "content": "\n\n# Resource: aws_vpc_endpoint\n\nProvides a VPC Endpoint resource.\n\n~> **NOTE on VPC Endpoints and VPC Endpoint Associations:** Terraform provides both standalone VPC Endpoint Associations for\n[Route Tables](vpc_endpoint_route_table_association.html) - (an association between a VPC endpoint and a single `route_table_id`) and\n[Subnets](vpc_endpoint_subnet_association.html) - (an association between a VPC endpoint and a single `subnet_id`) and\na VPC Endpoint resource with `route_table_ids` and `subnet_ids` attributes.\nDo not use the same resource ID in both a VPC Endpoint resource and a VPC Endpoint Association resource.\nDoing so will cause a conflict of associations and will overwrite the association.\n\n## Example Usage\n\n### Basic\n\n```terraform\nresource \"aws_vpc_endpoint\" \"s3\" {\n  vpc_id       = aws_vpc.main.id\n  service_name = \"com.amazonaws.us-west-2.s3\"\n}\n```\n\n### Basic w/ Tags\n\n```terraform\nresource \"aws_vpc_endpoint\" \"s3\" {\n  vpc_id       = aws_vpc.main.id\n  service_name = \"com.amazonaws.us-west-2.s3\"\n\n  tags = {\n    Environment = \"test\"\n  }\n}\n```\n\n### Interface Endpoint Type\n\n```terraform\nresource \"aws_vpc_endpoint\" \"ec2\" {\n  vpc_id            = aws_vpc.main.id\n  service_name      = \"com.amazonaws.us-west-2.ec2\"\n  vpc_endpoint_type = \"Interface\"\n\n  security_group_ids = [\n    aws_security_group.sg1.id,\n  ]\n\n  private_dns_enabled = true\n}\n```\n\n### Gateway Load Balancer Endpoint Type\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_vpc_endpoint_service\" \"example\" {\n  acceptance_required        = false\n  allowed_principals         = [data.aws_caller_identity.current.arn]\n  gateway_load_balancer_arns = [aws_lb.example.arn]\n}\n\nresource \"aws_vpc_endpoint\" \"example\" {\n  service_name      = aws_vpc_endpoint_service.example.service_name\n  subnet_ids        = [aws_subnet.example.id]\n  vpc_endpoint_type = aws_vpc_endpoint_service.example.service_type\n  vpc_id            = aws_vpc.example.id\n}\n```\n\n### Non-AWS Service\n\n```terraform\nresource \"aws_vpc_endpoint\" \"ptfe_service\" {\n  vpc_id            = var.vpc_id\n  service_name      = var.ptfe_service\n  vpc_endpoint_type = \"Interface\"\n\n  security_group_ids = [\n    aws_security_group.ptfe_service.id,\n  ]\n\n  subnet_ids          = [local.subnet_ids]\n  private_dns_enabled = false\n}\n\ndata \"aws_route53_zone\" \"internal\" {\n  name         = \"vpc.internal.\"\n  private_zone = true\n  vpc_id       = var.vpc_id\n}\n\nresource \"aws_route53_record\" \"ptfe_service\" {\n  zone_id = data.aws_route53_zone.internal.zone_id\n  name    = \"ptfe.${data.aws_route53_zone.internal.name}\"\n  type    = \"CNAME\"\n  ttl     = \"300\"\n  records = [aws_vpc_endpoint.ptfe_service.dns_entry[0][\"dns_name\"]]\n}\n```\n\n~> **NOTE The `dns_entry` output is a list of maps:** Terraform interpolation support for lists of maps requires the `lookup` and `[]` until full support of lists of maps is available\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `service_name` - (Required) The service name. For AWS services the service name is usually in the form `com.amazonaws.<region>.<service>` (the SageMaker Notebook service is an exception to this rule, the service name is in the form `aws.sagemaker.<region>.notebook`).\n* `vpc_id` - (Required) The ID of the VPC in which the endpoint will be used.\n* `auto_accept` - (Optional) Accept the VPC endpoint (the VPC endpoint and service need to be in the same AWS account).\n* `policy` - (Optional) A policy to attach to the endpoint that controls access to the service. This is a JSON formatted string. Defaults to full access. All `Gateway` and some `Interface` endpoints support policies - see the [relevant AWS documentation](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-access.html) for more details. For more information about building AWS IAM policy documents with Terraform, see the [AWS IAM Policy Document Guide](https://learn.hashicorp.com/terraform/aws/iam-policy).\n* `private_dns_enabled` - (Optional; AWS services and AWS Marketplace partner services only) Whether or not to associate a private hosted zone with the specified VPC. Applicable for endpoints of type `Interface`.\nDefaults to `false`.\n* `route_table_ids` - (Optional) One or more route table IDs. Applicable for endpoints of type `Gateway`.\n* `subnet_ids` - (Optional) The ID of one or more subnets in which to create a network interface for the endpoint. Applicable for endpoints of type `GatewayLoadBalancer` and `Interface`.\n* `security_group_ids` - (Optional) The ID of one or more security groups to associate with the network interface. Required for endpoints of type `Interface`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `vpc_endpoint_type` - (Optional) The VPC endpoint type, `Gateway`, `GatewayLoadBalancer`, or `Interface`. Defaults to `Gateway`.\n\n### Timeouts\n\n`aws_vpc_endpoint` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating a VPC endpoint\n- `update` - (Default `10 minutes`) Used for VPC endpoint modifications\n- `delete` - (Default `10 minutes`) Used for destroying VPC endpoints\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC endpoint.\n* `arn` - The Amazon Resource Name (ARN) of the VPC endpoint.\n* `cidr_blocks` - The list of CIDR blocks for the exposed AWS service. Applicable for endpoints of type `Gateway`.\n* `dns_entry` - The DNS entries for the VPC Endpoint. Applicable for endpoints of type `Interface`. DNS blocks are documented below.\n* `network_interface_ids` - One or more network interfaces for the VPC Endpoint. Applicable for endpoints of type `Interface`.\n* `owner_id` - The ID of the AWS account that owns the VPC endpoint.\n* `prefix_list_id` - The prefix list ID of the exposed AWS service. Applicable for endpoints of type `Gateway`.\n* `requester_managed` -  Whether or not the VPC Endpoint is being managed by its service - `true` or `false`.\n* `state` - The state of the VPC endpoint.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\nDNS blocks (for `dns_entry`) support the following attributes:\n\n* `dns_name` - The DNS name.\n* `hosted_zone_id` - The ID of the private hosted zone.\n\n## Import\n\nVPC Endpoints can be imported using the `vpc endpoint id`, e.g.,\n\n```\n$ terraform import aws_vpc_endpoint.endpoint1 vpce-3ecf2a57\n```\n",
    "basename": "vpc_endpoint.html"
  },
  "vpc_endpoint_connection_notification.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_endpoint_connection_notification",
    "description": "Provides a VPC Endpoint connection notification resource.",
    "preview": "# Resource: aws_vpc_endpoint_connection_notification\n\nProvides a VPC …",
    "content": "\n\n# Resource: aws_vpc_endpoint_connection_notification\n\nProvides a VPC Endpoint connection notification resource.\nConnection notifications notify subscribers of VPC Endpoint events.\n\n## Example Usage\n\n```terraform\nresource \"aws_sns_topic\" \"topic\" {\n  name = \"vpce-notification-topic\"\n\n  policy = <<POLICY\n{\n    \"Version\":\"2012-10-17\",\n    \"Statement\":[{\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"vpce.amazonaws.com\"\n        },\n        \"Action\": \"SNS:Publish\",\n        \"Resource\": \"arn:aws:sns:*:*:vpce-notification-topic\"\n    }]\n}\nPOLICY\n}\n\nresource \"aws_vpc_endpoint_service\" \"foo\" {\n  acceptance_required        = false\n  network_load_balancer_arns = [aws_lb.test.arn]\n}\n\nresource \"aws_vpc_endpoint_connection_notification\" \"foo\" {\n  vpc_endpoint_service_id     = aws_vpc_endpoint_service.foo.id\n  connection_notification_arn = aws_sns_topic.topic.arn\n  connection_events           = [\"Accept\", \"Reject\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_endpoint_service_id` - (Optional) The ID of the VPC Endpoint Service to receive notifications for.\n* `vpc_endpoint_id` - (Optional) The ID of the VPC Endpoint to receive notifications for.\n* `connection_notification_arn` - (Required) The ARN of the SNS topic for the notifications.\n* `connection_events` - (Required) One or more endpoint [events](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVpcEndpointConnectionNotification.html#API_CreateVpcEndpointConnectionNotification_RequestParameters) for which to receive notifications.\n\n~> **NOTE:** One of `vpc_endpoint_service_id` or `vpc_endpoint_id` must be specified.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC connection notification.\n* `state` - The state of the notification.\n* `notification_type` - The type of notification.\n\n## Import\n\nVPC Endpoint connection notifications can be imported using the `VPC endpoint connection notification id`, e.g.,\n\n```\n$ terraform import aws_vpc_endpoint_connection_notification.foo vpce-nfn-09e6ed3b4efba2263\n```\n",
    "basename": "vpc_endpoint_connection_notification.html"
  },
  "vpc_endpoint_route_table_association.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_endpoint_route_table_association",
    "description": "Manages a VPC Endpoint Route Table Association",
    "preview": "# Resource: aws_vpc_endpoint_route_table_association\n\nManages a VPC …",
    "content": "\n\n# Resource: aws_vpc_endpoint_route_table_association\n\nManages a VPC Endpoint Route Table Association\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc_endpoint_route_table_association\" \"example\" {\n  route_table_id  = aws_route_table.example.id\n  vpc_endpoint_id = aws_vpc_endpoint.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `route_table_id` - (Required) Identifier of the EC2 Route Table to be associated with the VPC Endpoint.\n* `vpc_endpoint_id` - (Required) Identifier of the VPC Endpoint with which the EC2 Route Table will be associated.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A hash of the EC2 Route Table and VPC Endpoint identifiers.\n\n\n## Import\n\nVPC Endpoint Route Table Associations can be imported using `vpc_endpoint_id` together with `route_table_id`,\ne.g.,\n\n```\n$ terraform import aws_vpc_endpoint_route_table_association.example vpce-aaaaaaaa/rtb-bbbbbbbb\n```\n",
    "basename": "vpc_endpoint_route_table_association.html"
  },
  "vpc_endpoint_service.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_endpoint_service",
    "description": "Provides a VPC Endpoint Service resource.",
    "preview": "# Resource: aws_vpc_endpoint_service\n\nProvides a VPC Endpoint …",
    "content": "\n\n# Resource: aws_vpc_endpoint_service\n\nProvides a VPC Endpoint Service resource.\nService consumers can create an _Interface_ [VPC Endpoint](vpc_endpoint.html) to connect to the service.\n\n~> **NOTE on VPC Endpoint Services and VPC Endpoint Service Allowed Principals:** Terraform provides\nboth a standalone [VPC Endpoint Service Allowed Principal](vpc_endpoint_service_allowed_principal.html) resource\nand a VPC Endpoint Service resource with an `allowed_principals` attribute. Do not use the same principal ARN in both\na VPC Endpoint Service resource and a VPC Endpoint Service Allowed Principal resource. Doing so will cause a conflict\nand will overwrite the association.\n\n## Example Usage\n\n### Network Load Balancers\n\n```terraform\nresource \"aws_vpc_endpoint_service\" \"example\" {\n  acceptance_required        = false\n  network_load_balancer_arns = [aws_lb.example.arn]\n}\n```\n\n### Gateway Load Balancers\n\n```terraform\nresource \"aws_vpc_endpoint_service\" \"example\" {\n  acceptance_required        = false\n  gateway_load_balancer_arns = [aws_lb.example.arn]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `acceptance_required` - (Required) Whether or not VPC endpoint connection requests to the service must be accepted by the service owner - `true` or `false`.\n* `allowed_principals` - (Optional) The ARNs of one or more principals allowed to discover the endpoint service.\n* `gateway_load_balancer_arns` - (Optional) Amazon Resource Names (ARNs) of one or more Gateway Load Balancers for the endpoint service.\n* `network_load_balancer_arns` - (Optional) Amazon Resource Names (ARNs) of one or more Network Load Balancers for the endpoint service.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `private_dns_name` - (Optional) The private DNS name for the service.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC endpoint service.\n* `availability_zones` - The Availability Zones in which the service is available.\n* `arn` - The Amazon Resource Name (ARN) of the VPC endpoint service.\n* `base_endpoint_dns_names` - The DNS names for the service.\n* `manages_vpc_endpoints` - Whether or not the service manages its VPC endpoints - `true` or `false`.\n* `service_name` - The service name.\n* `service_type` - The service type, `Gateway` or `Interface`.\n* `state` - The state of the VPC endpoint service.\n* `private_dns_name_configuration` - List of objects containing information about the endpoint service private DNS name configuration.\n    * `name` - Name of the record subdomain the service provider needs to create.\n    * `state` - Verification state of the VPC endpoint service. Consumers of the endpoint service can use the private name only when the state is `verified`.\n    * `type` - Endpoint service verification type, for example `TXT`.\n    * `value` - Value the service provider adds to the private DNS name domain record before verification.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nVPC Endpoint Services can be imported using the `VPC endpoint service id`, e.g.,\n\n```\n$ terraform import aws_vpc_endpoint_service.foo vpce-svc-0f97a19d3fa8220bc\n```\n",
    "basename": "vpc_endpoint_service.html"
  },
  "vpc_endpoint_service_allowed_principal.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_endpoint_service_allowed_principal",
    "description": "Provides a resource to allow a principal to discover a VPC endpoint service.",
    "preview": "# Resource: aws_vpc_endpoint_service_allowed_principal\n\nProvides a …",
    "content": "\n\n# Resource: aws_vpc_endpoint_service_allowed_principal\n\nProvides a resource to allow a principal to discover a VPC endpoint service.\n\n~> **NOTE on VPC Endpoint Services and VPC Endpoint Service Allowed Principals:** Terraform provides\nboth a standalone [VPC Endpoint Service Allowed Principal](vpc_endpoint_service_allowed_principal.html) resource\nand a VPC Endpoint Service resource with an `allowed_principals` attribute. Do not use the same principal ARN in both\na VPC Endpoint Service resource and a VPC Endpoint Service Allowed Principal resource. Doing so will cause a conflict\nand will overwrite the association.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\ndata \"aws_caller_identity\" \"current\" {}\n\nresource \"aws_vpc_endpoint_service_allowed_principal\" \"allow_me_to_foo\" {\n  vpc_endpoint_service_id = aws_vpc_endpoint_service.foo.id\n  principal_arn           = data.aws_caller_identity.current.arn\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_endpoint_service_id` - (Required) The ID of the VPC endpoint service to allow permission.\n* `principal_arn` - (Required) The ARN of the principal to allow permissions.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the association.\n",
    "basename": "vpc_endpoint_service_allowed_principal.html"
  },
  "vpc_endpoint_subnet_association.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_endpoint_subnet_association",
    "description": "Provides a resource to create an association between a VPC endpoint and a subnet.",
    "preview": "# Resource: aws_vpc_endpoint_subnet_association\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_vpc_endpoint_subnet_association\n\nProvides a resource to create an association between a VPC endpoint and a subnet.\n\n~> **NOTE on VPC Endpoints and VPC Endpoint Subnet Associations:** Terraform provides\nboth a standalone VPC Endpoint Subnet Association (an association between a VPC endpoint\nand a single `subnet_id`) and a [VPC Endpoint](vpc_endpoint.html) resource with a `subnet_ids`\nattribute. Do not use the same subnet ID in both a VPC Endpoint resource and a VPC Endpoint Subnet\nAssociation resource. Doing so will cause a conflict of associations and will overwrite the association.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_vpc_endpoint_subnet_association\" \"sn_ec2\" {\n  vpc_endpoint_id = aws_vpc_endpoint.ec2.id\n  subnet_id       = aws_subnet.sn.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_endpoint_id` - (Required) The ID of the VPC endpoint with which the subnet will be associated.\n* `subnet_id` - (Required) The ID of the subnet to be associated with the VPC endpoint.\n\n### Timeouts\n\n`aws_vpc_endpoint_subnet_association` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating the association\n- `delete` - (Default `10 minutes`) Used for destroying the association\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the association.\n",
    "basename": "vpc_endpoint_subnet_association.html"
  },
  "vpc_ipam.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_ipam",
    "description": "Provides a IPAM resource.",
    "preview": "# Resource: aws_vpc_ipam\n\nProvides a IPAM resource.\n\n## Example …",
    "content": "\n\n# Resource: aws_vpc_ipam\n\nProvides a IPAM resource.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam\" \"main\" {\n  description = \"My IPAM\"\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n\n  tags = {\n    Test = \"Main\"\n  }\n}\n```\n\nShared with multiple operating_regions:\n\n```terraform\nvariable \"ipam_regions\" {\n  type    = list\n  default = [\"us-east-1\", \"us-west-2\"]\n}\n\nresource \"aws_vpc_ipam\" \"example\" {\n  description = \"test4\"\n  dynamic operating_regions {\n    for_each = var.ipam_regions\n    content {\n      region_name = operating_regions.value\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `description` - (Optional) A description for the IPAM.\n* `operating_regions` - (Required) Determines which locales can be chosen when you create pools. Locale is the Region where you want to make an IPAM pool available for allocations. You can only create pools with locales that match the operating Regions of the IPAM. You can only create VPCs from a pool whose locale matches the VPC's Region. You specify a region using the [region_name](#operating_regions) parameter. You **must** set your provider block region as an operating_region.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### operating_regions\n\n* `region_name` - (Required) The name of the Region you want to add to the IPAM.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of IPAM\n* `id` - The ID of the IPAM\n* `private_default_scope_id` - The ID of the IPAM's private scope. A scope is a top-level container in IPAM. Each scope represents an IP-independent network. Scopes enable you to represent networks where you have overlapping IP space. When you create an IPAM, IPAM automatically creates two scopes: public and private. The private scope is intended for private IP space. The public scope is intended for all internet-routable IP space.\n* `public_default_scope_id` - The ID of the IPAM's public scope. A scope is a top-level container in IPAM. Each scope represents an IP-independent network. Scopes enable you to represent networks where you have overlapping IP space. When you create an IPAM, IPAM automatically creates two scopes: public and private. The private scope is intended for private\nIP space. The public scope is intended for all internet-routable IP space.\n* `scope_count` - The number of scopes in the IPAM.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nIPAMs can be imported using the `ipam id`, e.g.\n\n```\n$ terraform import aws_vpc_ipam.example ipam-0178368ad2146a492\n```\n",
    "basename": "vpc_ipam.html"
  },
  "vpc_ipam_pool.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_ipam_pool",
    "description": "Provides a IP address pool resource for IPAM.",
    "preview": "# Resource: aws_vpc_ipam_pool\n\nProvides an IP address pool resource …",
    "content": "\n\n# Resource: aws_vpc_ipam_pool\n\nProvides an IP address pool resource for IPAM.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam\" \"example\" {\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n}\n\nresource \"aws_vpc_ipam_pool\" \"example\" {\n  address_family = \"ipv4\"\n  ipam_scope_id  = aws_vpc_ipam.example.private_default_scope_id\n  locale         = data.aws_region.current.name\n}\n```\n\nNested Pools:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam\" \"example\" {\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n}\n\nresource \"aws_vpc_ipam_pool\" \"parent\" {\n  address_family = \"ipv4\"\n  ipam_scope_id  = aws_vpc_ipam.example.private_default_scope_id\n}\n\nresource \"aws_vpc_ipam_pool_cidr\" \"parent_test\" {\n  ipam_pool_id = aws_vpc_ipam_pool.parent.id\n  cidr         = \"172.2.0.0/16\"\n}\n\nresource \"aws_vpc_ipam_pool\" \"child\" {\n  address_family      = \"ipv4\"\n  ipam_scope_id       = aws_vpc_ipam.example.private_default_scope_id\n  locale              = data.aws_region.current.name\n  source_ipam_pool_id = aws_vpc_ipam_pool.parent.id\n}\n\n\nresource \"aws_vpc_ipam_pool_cidr\" \"child_test\" {\n  ipam_pool_id = aws_vpc_ipam_pool.child.id\n  cidr         = \"172.2.0.0/24\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `address_family` - (Optional) The IP protocol assigned to this pool. You must choose either IPv4 or IPv6 protocol for a pool.\n* `publicly_advertisable` - (Required) Defines whether or not IPv6 pool space is publicly advertisable over the internet. This option is not available for IPv4 pool space.\n* `allocation_default_netmask_length` - (Optional) A default netmask length for allocations added to this pool. If, for example, the CIDR assigned to this pool is 10.0.0.0/8 and you enter 16 here, new allocations will default to 10.0.0.0/16 (unless you provide a different netmask value when you create the new allocation).\n* `allocation_max_netmask_length` - (Optional) The maximum netmask length that will be required for CIDR allocations in this pool.\n* `allocation_min_netmask_length` - (Optional) The minimum netmask length that will be required for CIDR allocations in this pool.\n* `allocation_resource_tags` - (Optional) Tags that are required for resources that use CIDRs from this IPAM pool. Resources that do not have these tags will not be allowed to allocate space from the pool. If the resources have their tags changed after they have allocated space or if the allocation tagging requirements are changed on the pool, the resource may be marked as noncompliant.\n* `auto_import` - (Optional) If you include this argument, IPAM automatically imports any VPCs you have in your scope that fall\nwithin the CIDR range in the pool.\n* `aws_service` - (Optional) Limits which AWS service the pool can be used in. Only useable on public scopes. Valid Values: `ec2`.\n* `description` - (Optional) A description for the IPAM pool.\n* `ipam_scope_id` - (Optional) The ID of the scope in which you would like to create the IPAM pool.\n* `locale` - (Optional) The locale in which you would like to create the IPAM pool. Locale is the Region where you want to make an IPAM pool available for allocations. You can only create pools with locales that match the operating Regions of the IPAM. You can only create VPCs from a pool whose locale matches the VPC's Region. Possible values: Any AWS region, such as `us-east-1`.\n* `source_ipam_pool_id` - (Optional) The ID of the source IPAM pool. Use this argument to create a child pool within an existing pool.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of IPAM\n* `id` - The ID of the IPAM\n* `state` - The ID of the IPAM\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n\n## Import\n\nIPAMs can be imported using the `ipam pool id`, e.g.\n\n```\n$ terraform import aws_vpc_ipam_pool.example ipam-pool-0958f95207d978e1e\n```\n",
    "basename": "vpc_ipam_pool.html"
  },
  "vpc_ipam_pool_cidr.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_ipam_pool_cidr",
    "description": "Provisions a CIDR from an IPAM address pool.",
    "preview": "# Resource: aws_vpc_ipam_pool_cidr\n\nProvisions a CIDR from an IPAM …",
    "content": "\n\n# Resource: aws_vpc_ipam_pool_cidr\n\nProvisions a CIDR from an IPAM address pool.\n\n~> **NOTE:** Provisioning Public IPv4 or Public IPv6 require [steps outside the scope of this resource](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-byoip.html#prepare-for-byoip). The resource accepts `message` and `signature` as part of the `cidr_authorization_context` attribute but those must be generated ahead of time. Public IPv6 CIDRs that are provisioned into a Pool with `publicly_advertisable = true` and all public IPv4 CIDRs also require creating a Route Origin Authorization (ROA) object in your Regional Internet Registry (RIR).\n\n## Example Usage\n\nBasic usage:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam\" \"example\" {\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n}\n\nresource \"aws_vpc_ipam_pool\" \"example\" {\n  address_family = \"ipv4\"\n  ipam_scope_id  = aws_vpc_ipam.example.private_default_scope_id\n  locale         = data.aws_region.current.name\n}\n\nresource \"aws_vpc_ipam_pool_cidr\" \"example\" {\n  ipam_pool_id = aws_vpc_ipam_pool.example.id\n  cidr         = \"172.2.0.0/16\"\n}\n```\n\nProvision Public IPv6 Pool CIDRs:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam\" \"example\" {\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n}\n\nresource \"aws_vpc_ipam_pool\" \"ipv6_test_public\" {\n  address_family = \"ipv6\"\n  ipam_scope_id  = aws_vpc_ipam.example.public_default_scope_id\n  locale         = \"us-east-1\"\n  description    = \"public ipv6\"\n  advertisable   = false\n}\n\nresource \"aws_vpc_ipam_pool_cidr\" \"ipv6_test_public\" {\n  ipam_pool_id = aws_vpc_ipam_pool.ipv6_test_public.id\n  cidr         = var.ipv6_cidr\n  cidr_authorization_context {\n    message   = var.message\n    signature = var.signature\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cidr` - (Optional) The CIDR you want to assign to the pool.\n* `cidr_authorization_context` - (Optional) A signed document that proves that you are authorized to bring the specified IP address range to Amazon using BYOIP. This is not stored in the state file. See [cidr_authorization_context](#cidr_authorization_context) for more information.\n* `ipam_pool_id` - (Required) The ID of the pool to which you want to assign a CIDR.\n\n### cidr_authorization_context\n\n* `message` - (Optional) The plain-text authorization message for the prefix and account.\n* `signature` - (Optional) The signed authorization message for the prefix and account.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the IPAM Pool Cidr concatenated with the IPAM Pool ID.\n\n## Import\n\nIPAMs can be imported using the `<cidr>_<ipam-pool-id>`, e.g.\n\n```\n$ terraform import aws_vpc_ipam_pool_cidr.example 172.2.0.0/24_ipam-pool-0e634f5a1517cccdc\n```\n",
    "basename": "vpc_ipam_pool_cidr.html"
  },
  "vpc_ipam_pool_cidr_allocation.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_ipam_pool_cidr_allocation",
    "description": "Allocates (reserves) a CIDR from an IPAM address pool, preventing usage by IPAM.",
    "preview": "# Resource: aws_vpc_ipam_pool_cidr_allocation\n\nAllocates (reserves) …",
    "content": "\n\n# Resource: aws_vpc_ipam_pool_cidr_allocation\n\nAllocates (reserves) a CIDR from an IPAM address pool, preventing usage by IPAM. Only works for private IPv4.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam_pool_cidr_allocation\" \"example\" {\n  ipam_pool_id = aws_vpc_ipam_pool.example.id\n  cidr         = \"172.2.0.0/24\"\n  depends_on = [\n    aws_vpc_ipam_pool_cidr.example\n  ]\n}\n\nresource \"aws_vpc_ipam_pool_cidr\" \"example\" {\n  ipam_pool_id = aws_vpc_ipam_pool.example.id\n  cidr         = \"172.2.0.0/16\"\n}\n\nresource \"aws_vpc_ipam_pool\" \"example\" {\n  address_family = \"ipv4\"\n  ipam_scope_id  = aws_vpc_ipam.example.private_default_scope_id\n  locale         = data.aws_region.current.name\n}\n\nresource \"aws_vpc_ipam\" \"example\" {\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cidr` - (Optional) The CIDR you want to assign to the pool.\n* `description` - (Optional) The description for the allocation.\n* `ipam_pool_id` - (Required) The ID of the pool to which you want to assign a CIDR.\n* `netmask_length` - (Optional) The netmask length of the CIDR you would like to allocate to the IPAM pool.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the allocation.\n* `resource_id` - The ID of the resource.\n* `resource_owner` - The owner of the resource.\n* `resource_type` - The type of the resource.\n\n## Import\n\nIPAMs can be imported using the `allocation id`, e.g.\n\n```\n$ terraform import aws_vpc_ipam_pool_cidr_allocation.example\n```\n",
    "basename": "vpc_ipam_pool_cidr_allocation.html"
  },
  "vpc_ipam_scope.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_ipam_scope",
    "description": "Creates a scope for AWS IPAM.",
    "preview": "# Resource: aws_vpc_ipam_scope\n\nCreates a scope for AWS IPAM.\n\n## …",
    "content": "\n\n# Resource: aws_vpc_ipam_scope\n\nCreates a scope for AWS IPAM.\n\n## Example Usage\n\nBasic usage:\n\n```terraform\ndata \"aws_region\" \"current\" {}\n\nresource \"aws_vpc_ipam\" \"example\" {\n  operating_regions {\n    region_name = data.aws_region.current.name\n  }\n}\n\nresource \"aws_vpc_ipam_scope\" \"example\" {\n  ipam_id     = aws_vpc_ipam.example.id\n  description = \"Another Scope\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `ipam_id` - The ID of the IPAM for which you're creating this scope.\n* `description` - (Optional) A description for the scope you're creating.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the IPAM Scope.\n* `ipam_arn` - The ARN of the IPAM for which you're creating this scope.\n* `is_default` - Defines if the scope is the default scope or not.\n* `pool_count` - Count of pools under this scope\n\n## Import\n\nIPAMs can be imported using the `scope_id`, e.g.\n\n```\n$ terraform import aws_vpc_ipam_scope.example ipam-scope-0513c69f283d11dfb\n```\n",
    "basename": "vpc_ipam_scope.html"
  },
  "vpc_ipv4_cidr_block_association.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_ipv4_cidr_block_association",
    "description": "Associate additional IPv4 CIDR blocks with a VPC",
    "preview": "# Resource: aws_vpc_ipv4_cidr_block_association\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_vpc_ipv4_cidr_block_association\n\nProvides a resource to associate additional IPv4 CIDR blocks with a VPC.\n\nWhen a VPC is created, a primary IPv4 CIDR block for the VPC must be specified.\nThe `aws_vpc_ipv4_cidr_block_association` resource allows further IPv4 CIDR blocks to be added to the VPC.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpc_ipv4_cidr_block_association\" \"secondary_cidr\" {\n  vpc_id     = aws_vpc.main.id\n  cidr_block = \"172.2.0.0/16\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `cidr_block` - (Optional) The IPv4 CIDR block for the VPC. CIDR can be explicitly set or it can be derived from IPAM using `ipv4_netmask_length`.\n* `ipv4_ipam_pool_id` - (Optional) The ID of an IPv4 IPAM pool you want to use for allocating this VPC's CIDR. IPAM is a VPC feature that you can use to automate your IP address management workflows including assigning, tracking, troubleshooting, and auditing IP addresses across AWS Regions and accounts. Using IPAM you can monitor IP address usage throughout your AWS Organization.\n* `ipv4_netmask_length` - (Optional) The netmask length of the IPv4 CIDR you want to allocate to this VPC. Requires specifying a `ipv4_ipam_pool_id`.\n* `vpc_id` - (Required) The ID of the VPC to make the association with.\n\n## Timeouts\n\n`aws_vpc_ipv4_cidr_block_association` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating the association\n- `delete` - (Default `10 minutes`) Used for destroying the association\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC CIDR association\n\n## Import\n\n`aws_vpc_ipv4_cidr_block_association` can be imported by using the VPC CIDR Association ID, e.g.,\n\n```\n$ terraform import aws_vpc_ipv4_cidr_block_association.example vpc-cidr-assoc-xxxxxxxx\n```\n",
    "basename": "vpc_ipv4_cidr_block_association.html"
  },
  "vpc_ipv6_cidr_block_association.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_ipv6_cidr_block_association",
    "description": "Associate additional IPv6 CIDR blocks with a VPC",
    "preview": "# Resource: aws_vpc_ipv6_cidr_block_association\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_vpc_ipv6_cidr_block_association\n\nProvides a resource to associate additional IPv6 CIDR blocks with a VPC.\n\nThe `aws_vpc_ipv6_cidr_block_association` resource allows IPv6 CIDR blocks to be added to the VPC.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"test\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpc_ipv6_cidr_block_association\" \"test\" {\n  ipv6_ipam_pool_id = aws_vpc_ipam_pool.test.id\n  vpc_id            = aws_vpc.test.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `ipv6_cidr_block` - (Optional) The IPv6 CIDR block for the VPC. CIDR can be explicitly set or it can be derived from IPAM using `ipv6_netmask_length`. This parameter is required if `ipv6_netmask_length` is not set and he IPAM pool does not have `allocation_default_netmask` set.\n* `ipv6_ipam_pool_id` - (Required) The ID of an IPv6 IPAM pool you want to use for allocating this VPC's CIDR. IPAM is a VPC feature that you can use to automate your IP address management workflows including assigning, tracking, troubleshooting, and auditing IP addresses across AWS Regions and accounts.\n* `ipv6_netmask_length` - (Optional) The netmask length of the IPv6 CIDR you want to allocate to this VPC. Requires specifying a `ipv6_ipam_pool_id`. This parameter is optional if the IPAM pool has `allocation_default_netmask` set, otherwise it or `cidr_block` are required\n* `vpc_id` - (Required) The ID of the VPC to make the association with.\n\n## Timeouts\n\n`aws_vpc_ipv6_cidr_block_association` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `10 minutes`) Used for creating the association\n- `delete` - (Default `10 minutes`) Used for destroying the association\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC CIDR association\n\n## Import\n\n`aws_vpc_ipv6_cidr_block_association` can be imported by using the VPC CIDR Association ID, e.g.,\n\n```\n$ terraform import aws_vpc_ipv6_cidr_block_association.example vpc-cidr-assoc-xxxxxxxx\n```\n",
    "basename": "vpc_ipv6_cidr_block_association.html"
  },
  "vpc_peering_connection.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_peering_connection",
    "description": "Provides a resource to manage a VPC peering connection.",
    "preview": "# Resource: aws_vpc_peering_connection\n\nProvides a resource to …",
    "content": "\n\n# Resource: aws_vpc_peering_connection\n\nProvides a resource to manage a VPC peering connection.\n\n~> **NOTE on VPC Peering Connections and VPC Peering Connection Options:** Terraform provides\nboth a standalone [VPC Peering Connection Options](vpc_peering_connection_options.html) and a VPC Peering Connection\nresource with `accepter` and `requester` attributes. Do not manage options for the same VPC peering\nconnection in both a VPC Peering Connection resource and a VPC Peering Connection Options resource.\nDoing so will cause a conflict of options and will overwrite the options.\nUsing a VPC Peering Connection Options resource decouples management of the connection options from\nmanagement of the VPC Peering Connection and allows options to be set correctly in cross-account scenarios.\n\n-> **Note:** For cross-account (requester's AWS account differs from the accepter's AWS account) or inter-region\nVPC Peering Connections use the `aws_vpc_peering_connection` resource to manage the requester's side of the\nconnection and use the `aws_vpc_peering_connection_accepter` resource to manage the accepter's side of the connection.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc_peering_connection\" \"foo\" {\n  peer_owner_id = var.peer_owner_id\n  peer_vpc_id   = aws_vpc.bar.id\n  vpc_id        = aws_vpc.foo.id\n}\n```\n\nBasic usage with connection options:\n\n```terraform\nresource \"aws_vpc_peering_connection\" \"foo\" {\n  peer_owner_id = var.peer_owner_id\n  peer_vpc_id   = aws_vpc.bar.id\n  vpc_id        = aws_vpc.foo.id\n\n  accepter {\n    allow_remote_vpc_dns_resolution = true\n  }\n\n  requester {\n    allow_remote_vpc_dns_resolution = true\n  }\n}\n```\n\nBasic usage with tags:\n\n```terraform\nresource \"aws_vpc_peering_connection\" \"foo\" {\n  peer_owner_id = var.peer_owner_id\n  peer_vpc_id   = aws_vpc.bar.id\n  vpc_id        = aws_vpc.foo.id\n  auto_accept   = true\n\n  tags = {\n    Name = \"VPC Peering between foo and bar\"\n  }\n}\n\nresource \"aws_vpc\" \"foo\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_vpc\" \"bar\" {\n  cidr_block = \"10.2.0.0/16\"\n}\n```\n\nBasic usage with region:\n\n\n```terraform\nresource \"aws_vpc_peering_connection\" \"foo\" {\n  peer_owner_id = var.peer_owner_id\n  peer_vpc_id   = aws_vpc.bar.id\n  vpc_id        = aws_vpc.foo.id\n  peer_region   = \"us-east-1\"\n}\n\nresource \"aws_vpc\" \"foo\" {\n  provider   = aws.us-west-2\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_vpc\" \"bar\" {\n  provider   = aws.us-east-1\n  cidr_block = \"10.2.0.0/16\"\n}\n```\n\n## Argument Reference\n\n-> **Note:** Modifying the VPC Peering Connection options requires peering to be active. An automatic activation\ncan be done using the [`auto_accept`](vpc_peering_connection.html#auto_accept) attribute. Alternatively, the VPC Peering\nConnection has to be made active manually using other means. See [notes](vpc_peering_connection.html#notes) below for\nmore information.\n\nThe following arguments are supported:\n\n* `peer_owner_id` - (Optional) The AWS account ID of the owner of the peer VPC.\n   Defaults to the account ID the [AWS provider][1] is currently connected to.\n* `peer_vpc_id` - (Required) The ID of the VPC with which you are creating the VPC Peering Connection.\n* `vpc_id` - (Required) The ID of the requester VPC.\n* `auto_accept` - (Optional) Accept the peering (both VPCs need to be in the same AWS account).\n* `peer_region` - (Optional) The region of the accepter VPC of the VPC Peering Connection. `auto_accept` must be `false`,\nand use the `aws_vpc_peering_connection_accepter` to manage the accepter side.\n* `accepter` (Optional) - An optional configuration block that allows for [VPC Peering Connection](https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html) options to be set for the VPC that accepts\nthe peering connection (a maximum of one).\n* `requester` (Optional) - A optional configuration block that allows for [VPC Peering Connection](https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html) options to be set for the VPC that requests\nthe peering connection (a maximum of one).\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n#### Accepter and Requester Arguments\n\n-> **Note:** When enabled, the DNS resolution feature requires that VPCs participating in the peering\nmust have support for the DNS hostnames enabled. This can be done using the [`enable_dns_hostnames`](vpc.html#enable_dns_hostnames) attribute in the [`aws_vpc`](vpc.html) resource. See [Using DNS with Your VPC](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-dns.html) user guide for more information.\n\n* `allow_remote_vpc_dns_resolution` - (Optional) Allow a local VPC to resolve public DNS hostnames to\nprivate IP addresses when queried from instances in the peer VPC.\n* `allow_classic_link_to_remote_vpc` - (Optional) Allow a local linked EC2-Classic instance to communicate\nwith instances in a peer VPC. This enables an outbound communication from the local ClassicLink connection\nto the remote VPC.\n* `allow_vpc_to_remote_classic_link` - (Optional) Allow a local VPC to communicate with a linked EC2-Classic\ninstance in a peer VPC. This enables an outbound communication from the local VPC to the remote ClassicLink\nconnection.\n\n### Timeouts\n\n`aws_vpc_peering_connection` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `1 minute`) Used for creating a peering connection\n- `update` - (Default `1 minute`) Used for peering connection modifications\n- `delete` - (Default `1 minute`) Used for destroying peering connections\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC Peering Connection.\n* `accept_status` - The status of the VPC Peering Connection request.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Notes\n\nIf both VPCs are not in the same AWS account do not enable the `auto_accept` attribute.\nThe accepter can manage its side of the connection using the `aws_vpc_peering_connection_accepter` resource\nor accept the connection manually using the AWS Management Console, AWS CLI, through SDKs, etc.\n\n## Import\n\nVPC Peering resources can be imported using the `vpc peering id`, e.g.,\n\n```sh\n$ terraform import aws_vpc_peering_connection.test_connection pcx-111aaa111\n```\n\n[1]: /docs/providers/aws/index.html\n",
    "basename": "vpc_peering_connection.html"
  },
  "vpc_peering_connection_accepter.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_peering_connection_accepter",
    "description": "Manage the accepter's side of a VPC Peering Connection.",
    "preview": "# Resource: aws_vpc_peering_connection_accepter\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_vpc_peering_connection_accepter\n\nProvides a resource to manage the accepter's side of a VPC Peering Connection.\n\nWhen a cross-account (requester's AWS account differs from the accepter's AWS account) or an inter-region\nVPC Peering Connection is created, a VPC Peering Connection resource is automatically created in the\naccepter's account.\nThe requester can use the `aws_vpc_peering_connection` resource to manage its side of the connection\nand the accepter can use the `aws_vpc_peering_connection_accepter` resource to \"adopt\" its side of the\nconnection into management.\n\n## Example Usage\n\n```terraform\nprovider \"aws\" {\n  region = \"us-east-1\"\n\n  # Requester's credentials.\n}\n\nprovider \"aws\" {\n  alias  = \"peer\"\n  region = \"us-west-2\"\n\n  # Accepter's credentials.\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpc\" \"peer\" {\n  provider   = aws.peer\n  cidr_block = \"10.1.0.0/16\"\n}\n\ndata \"aws_caller_identity\" \"peer\" {\n  provider = aws.peer\n}\n\n# Requester's side of the connection.\nresource \"aws_vpc_peering_connection\" \"peer\" {\n  vpc_id        = aws_vpc.main.id\n  peer_vpc_id   = aws_vpc.peer.id\n  peer_owner_id = data.aws_caller_identity.peer.account_id\n  peer_region   = \"us-west-2\"\n  auto_accept   = false\n\n  tags = {\n    Side = \"Requester\"\n  }\n}\n\n# Accepter's side of the connection.\nresource \"aws_vpc_peering_connection_accepter\" \"peer\" {\n  provider                  = aws.peer\n  vpc_peering_connection_id = aws_vpc_peering_connection.peer.id\n  auto_accept               = true\n\n  tags = {\n    Side = \"Accepter\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_peering_connection_id` - (Required) The VPC Peering Connection ID to manage.\n* `auto_accept` - (Optional) Whether or not to accept the peering request. Defaults to `false`.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Removing `aws_vpc_peering_connection_accepter` from your configuration\n\nAWS allows a cross-account VPC Peering Connection to be deleted from either the requester's or accepter's side.\nHowever, Terraform only allows the VPC Peering Connection to be deleted from the requester's side\nby removing the corresponding `aws_vpc_peering_connection` resource from your configuration.\nRemoving a `aws_vpc_peering_connection_accepter` resource from your configuration will remove it\nfrom your statefile and management, **but will not destroy the VPC Peering Connection.**\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC Peering Connection.\n* `accept_status` - The status of the VPC Peering Connection request.\n* `vpc_id` - The ID of the accepter VPC.\n* `peer_vpc_id` - The ID of the requester VPC.\n* `peer_owner_id` - The AWS account ID of the owner of the requester VPC.\n* `peer_region` - The region of the accepter VPC.\n* `accepter` - A configuration block that describes [VPC Peering Connection]\n(https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html) options set for the accepter VPC.\n* `requester` - A configuration block that describes [VPC Peering Connection]\n(https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html) options set for the requester VPC.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n#### Accepter and Requester Attributes Reference\n\n* `allow_remote_vpc_dns_resolution` - Indicates whether a local VPC can resolve public DNS hostnames to\nprivate IP addresses when queried from instances in a peer VPC.\n* `allow_classic_link_to_remote_vpc` - Indicates whether a local ClassicLink connection can communicate\nwith the peer VPC over the VPC Peering Connection.\n* `allow_vpc_to_remote_classic_link` - Indicates whether a local VPC can communicate with a ClassicLink\nconnection in the peer VPC over the VPC Peering Connection.\n\n## Import\n\nVPC Peering Connection Accepters can be imported by using the Peering Connection ID, e.g.,\n\n```sh\n$ terraform import aws_vpc_peering_connection_accepter.example pcx-12345678\n```\n\nCertain resource arguments, like `auto_accept`, do not have an EC2 API method for reading the information after peering connection creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference, e.g.,\n\n```terraform\nresource \"aws_vpc_peering_connection_accepter\" \"example\" {\n  # ... other configuration ...\n\n  # There is no AWS EC2 API for reading auto_accept\n  lifecycle {\n    ignore_changes = [auto_accept]\n  }\n}\n```\n",
    "basename": "vpc_peering_connection_accepter.html"
  },
  "vpc_peering_connection_options.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpc_peering_connection_options",
    "description": "Provides a resource to manage VPC peering connection options.",
    "preview": "# Resource: aws_vpc_peering_connection_options\n\nProvides a resource …",
    "content": "\n\n# Resource: aws_vpc_peering_connection_options\n\nProvides a resource to manage VPC peering connection options.\n\n~> **NOTE on VPC Peering Connections and VPC Peering Connection Options:** Terraform provides\nboth a standalone VPC Peering Connection Options and a [VPC Peering Connection](vpc_peering_connection.html)\nresource with `accepter` and `requester` attributes. Do not manage options for the same VPC peering\nconnection in both a VPC Peering Connection resource and a VPC Peering Connection Options resource.\nDoing so will cause a conflict of options and will overwrite the options.\nUsing a VPC Peering Connection Options resource decouples management of the connection options from\nmanagement of the VPC Peering Connection and allows options to be set correctly in cross-region and\ncross-account scenarios.\n\n## Example Usage\n\n### Basic Usage\n\n```terraform\nresource \"aws_vpc\" \"foo\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpc\" \"bar\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\nresource \"aws_vpc_peering_connection\" \"foo\" {\n  vpc_id      = aws_vpc.foo.id\n  peer_vpc_id = aws_vpc.bar.id\n  auto_accept = true\n}\n\nresource \"aws_vpc_peering_connection_options\" \"foo\" {\n  vpc_peering_connection_id = aws_vpc_peering_connection.foo.id\n\n  accepter {\n    allow_remote_vpc_dns_resolution = true\n  }\n\n  requester {\n    allow_vpc_to_remote_classic_link = true\n    allow_classic_link_to_remote_vpc = true\n  }\n}\n```\n\n### Cross-Account Usage\n\n```terraform\nprovider \"aws\" {\n  alias = \"requester\"\n\n  # Requester's credentials.\n}\n\nprovider \"aws\" {\n  alias = \"accepter\"\n\n  # Accepter's credentials.\n}\n\nresource \"aws_vpc\" \"main\" {\n  provider = aws.requester\n\n  cidr_block = \"10.0.0.0/16\"\n\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n}\n\nresource \"aws_vpc\" \"peer\" {\n  provider = aws.accepter\n\n  cidr_block = \"10.1.0.0/16\"\n\n  enable_dns_support   = true\n  enable_dns_hostnames = true\n}\n\ndata \"aws_caller_identity\" \"peer\" {\n  provider = aws.accepter\n}\n\n# Requester's side of the connection.\nresource \"aws_vpc_peering_connection\" \"peer\" {\n  provider = aws.requester\n\n  vpc_id        = aws_vpc.main.id\n  peer_vpc_id   = aws_vpc.peer.id\n  peer_owner_id = data.aws_caller_identity.peer.account_id\n  auto_accept   = false\n\n  tags = {\n    Side = \"Requester\"\n  }\n}\n\n# Accepter's side of the connection.\nresource \"aws_vpc_peering_connection_accepter\" \"peer\" {\n  provider = aws.accepter\n\n  vpc_peering_connection_id = aws_vpc_peering_connection.peer.id\n  auto_accept               = true\n\n  tags = {\n    Side = \"Accepter\"\n  }\n}\n\nresource \"aws_vpc_peering_connection_options\" \"requester\" {\n  provider = aws.requester\n\n  # As options can't be set until the connection has been accepted\n  # create an explicit dependency on the accepter.\n  vpc_peering_connection_id = aws_vpc_peering_connection_accepter.peer.id\n\n  requester {\n    allow_remote_vpc_dns_resolution = true\n  }\n}\n\nresource \"aws_vpc_peering_connection_options\" \"accepter\" {\n  provider = aws.accepter\n\n  vpc_peering_connection_id = aws_vpc_peering_connection_accepter.peer.id\n\n  accepter {\n    allow_remote_vpc_dns_resolution = true\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_peering_connection_id` - (Required) The ID of the requester VPC peering connection.\n* `accepter` (Optional) - An optional configuration block that allows for [VPC Peering Connection]\n(https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html) options to be set for the VPC that accepts\nthe peering connection (a maximum of one).\n* `requester` (Optional) - A optional configuration block that allows for [VPC Peering Connection]\n(https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html) options to be set for the VPC that requests\nthe peering connection (a maximum of one).\n\n#### Accepter and Requester Arguments\n\n-> **Note:** When enabled, the DNS resolution feature requires that VPCs participating in the peering\nmust have support for the DNS hostnames enabled. This can be done using the [`enable_dns_hostnames`]\n(vpc.html#enable_dns_hostnames) attribute in the [`aws_vpc`](vpc.html) resource. See [Using DNS with Your VPC]\n(http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-dns.html) user guide for more information.\n\n* `allow_remote_vpc_dns_resolution` - (Optional) Allow a local VPC to resolve public DNS hostnames to\nprivate IP addresses when queried from instances in the peer VPC.\n* `allow_classic_link_to_remote_vpc` - (Optional) Allow a local linked EC2-Classic instance to communicate\nwith instances in a peer VPC. This enables an outbound communication from the local ClassicLink connection\nto the remote VPC. This option is not supported for inter-region VPC peering.\n* `allow_vpc_to_remote_classic_link` - (Optional) Allow a local VPC to communicate with a linked EC2-Classic\ninstance in a peer VPC. This enables an outbound communication from the local VPC to the remote ClassicLink\nconnection. This option is not supported for inter-region VPC peering.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the VPC Peering Connection Options.\n\n## Import\n\nVPC Peering Connection Options can be imported using the `vpc peering id`, e.g.,\n\n```\n$ terraform import aws_vpc_peering_connection_options.foo pcx-111aaa111\n```\n",
    "basename": "vpc_peering_connection_options.html"
  },
  "vpn_connection.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpn_connection",
    "description": "Manages an EC2 VPN connection. These objects can be connected to customer gateways, and allow you to establish tunnels between your network and Amazon.",
    "preview": "# Resource: aws_vpn_connection\n\nManages an EC2 VPN connection. These …",
    "content": "\n\n# Resource: aws_vpn_connection\n\nManages an EC2 VPN connection. These objects can be connected to customer gateways, and allow you to establish tunnels between your network and Amazon.\n\n~> **Note:** All arguments including `tunnel1_preshared_key` and `tunnel2_preshared_key` will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](https://www.terraform.io/docs/state/sensitive-data.html).\n\n~> **Note:** The CIDR blocks in the arguments `tunnel1_inside_cidr` and `tunnel2_inside_cidr` must have a prefix of /30 and be a part of a specific range.\n[Read more about this in the AWS documentation](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_VpnTunnelOptionsSpecification.html).\n\n## Example Usage\n\n### EC2 Transit Gateway\n\n```terraform\nresource \"aws_ec2_transit_gateway\" \"example\" {}\n\nresource \"aws_customer_gateway\" \"example\" {\n  bgp_asn    = 65000\n  ip_address = \"172.0.0.1\"\n  type       = \"ipsec.1\"\n}\n\nresource \"aws_vpn_connection\" \"example\" {\n  customer_gateway_id = aws_customer_gateway.example.id\n  transit_gateway_id  = aws_ec2_transit_gateway.example.id\n  type                = aws_customer_gateway.example.type\n}\n```\n\n### Virtual Private Gateway\n\n```terraform\nresource \"aws_vpc\" \"vpc\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpn_gateway\" \"vpn_gateway\" {\n  vpc_id = aws_vpc.vpc.id\n}\n\nresource \"aws_customer_gateway\" \"customer_gateway\" {\n  bgp_asn    = 65000\n  ip_address = \"172.0.0.1\"\n  type       = \"ipsec.1\"\n}\n\nresource \"aws_vpn_connection\" \"main\" {\n  vpn_gateway_id      = aws_vpn_gateway.vpn_gateway.id\n  customer_gateway_id = aws_customer_gateway.customer_gateway.id\n  type                = \"ipsec.1\"\n  static_routes_only  = true\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `customer_gateway_id` - (Required) The ID of the customer gateway.\n* `type` - (Required) The type of VPN connection. The only type AWS supports at this time is \"ipsec.1\".\n\nOne of the following arguments is required:\n\n* `transit_gateway_id` - (Optional) The ID of the EC2 Transit Gateway.\n* `vpn_gateway_id` - (Optional) The ID of the Virtual Private Gateway.\n\nOther arguments:\n\n* `static_routes_only` - (Optional, Default `false`) Whether the VPN connection uses static routes exclusively. Static routes must be used for devices that don't support BGP.\n* `enable_acceleration` - (Optional, Default `false`) Indicate whether to enable acceleration for the VPN connection. Supports only EC2 Transit Gateway.\n* `tags` - (Optional) Tags to apply to the connection. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `local_ipv4_network_cidr` - (Optional, Default `0.0.0.0/0`) The IPv4 CIDR on the customer gateway (on-premises) side of the VPN connection.\n* `local_ipv6_network_cidr` - (Optional, Default `::/0`) The IPv6 CIDR on the customer gateway (on-premises) side of the VPN connection.\n* `remote_ipv4_network_cidr` - (Optional, Default `0.0.0.0/0`) The IPv4 CIDR on the AWS side of the VPN connection.\n* `remote_ipv6_network_cidr` - (Optional, Default `::/0`) The IPv6 CIDR on the customer gateway (on-premises) side of the VPN connection.\n* `tunnel_inside_ip_version` - (Optional, Default `ipv4`) Indicate whether the VPN tunnels process IPv4 or IPv6 traffic. Valid values are `ipv4 | ipv6`. `ipv6` Supports only EC2 Transit Gateway.\n* `tunnel1_inside_cidr` - (Optional) The CIDR block of the inside IP addresses for the first VPN tunnel. Valid value is a size /30 CIDR block from the 169.254.0.0/16 range.\n* `tunnel2_inside_cidr` - (Optional) The CIDR block of the inside IP addresses for the second VPN tunnel. Valid value is a size /30 CIDR block from the 169.254.0.0/16 range.\n* `tunnel1_inside_ipv6_cidr` - (Optional) The range of inside IPv6 addresses for the first VPN tunnel. Supports only EC2 Transit Gateway. Valid value is a size /126 CIDR block from the local fd00::/8 range.\n* `tunnel2_inside_ipv6_cidr` - (Optional) The range of inside IPv6 addresses for the second VPN tunnel. Supports only EC2 Transit Gateway. Valid value is a size /126 CIDR block from the local fd00::/8 range.\n* `tunnel1_preshared_key` - (Optional) The preshared key of the first VPN tunnel. The preshared key must be between 8 and 64 characters in length and cannot start with zero(0). Allowed characters are alphanumeric characters, periods(.) and underscores(_).\n* `tunnel2_preshared_key` - (Optional) The preshared key of the second VPN tunnel. The preshared key must be between 8 and 64 characters in length and cannot start with zero(0). Allowed characters are alphanumeric characters, periods(.) and underscores(_).\n* `tunnel1_dpd_timeout_action` - (Optional, Default `clear`) The action to take after DPD timeout occurs for the first VPN tunnel. Specify restart to restart the IKE initiation. Specify clear to end the IKE session. Valid values are `clear | none | restart`.\n* `tunnel2_dpd_timeout_action` - (Optional, Default `clear`) The action to take after DPD timeout occurs for the second VPN tunnel. Specify restart to restart the IKE initiation. Specify clear to end the IKE session. Valid values are `clear | none | restart`.\n* `tunnel1_dpd_timeout_seconds` - (Optional, Default `30`) The number of seconds after which a DPD timeout occurs for the first VPN tunnel. Valid value is equal or higher than `30`.\n* `tunnel2_dpd_timeout_seconds` - (Optional, Default `30`) The number of seconds after which a DPD timeout occurs for the second VPN tunnel. Valid value is equal or higher than `30`.\n* `tunnel1_ike_versions` - (Optional) The IKE versions that are permitted for the first VPN tunnel. Valid values are `ikev1 | ikev2`.\n* `tunnel2_ike_versions` - (Optional) The IKE versions that are permitted for the second VPN tunnel. Valid values are `ikev1 | ikev2`.\n* `tunnel1_phase1_dh_group_numbers` - (Optional) List of one or more Diffie-Hellman group numbers that are permitted for the first VPN tunnel for phase 1 IKE negotiations. Valid values are ` 2 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24`.\n* `tunnel2_phase1_dh_group_numbers` - (Optional) List of one or more Diffie-Hellman group numbers that are permitted for the second VPN tunnel for phase 1 IKE negotiations. Valid values are ` 2 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24`.\n* `tunnel1_phase1_encryption_algorithms` - (Optional) List of one or more encryption algorithms that are permitted for the first VPN tunnel for phase 1 IKE negotiations. Valid values are `AES128 | AES256 | AES128-GCM-16 | AES256-GCM-16`.\n* `tunnel2_phase1_encryption_algorithms` - (Optional) List of one or more encryption algorithms that are permitted for the second VPN tunnel for phase 1 IKE negotiations. Valid values are `AES128 | AES256 | AES128-GCM-16 | AES256-GCM-16`.\n* `tunnel1_phase1_integrity_algorithms` - (Optional) One or more integrity algorithms that are permitted for the first VPN tunnel for phase 1 IKE negotiations. Valid values are `SHA1 | SHA2-256 | SHA2-384 | SHA2-512`.\n* `tunnel2_phase1_integrity_algorithms` - (Optional) One or more integrity algorithms that are permitted for the second VPN tunnel for phase 1 IKE negotiations. Valid values are `SHA1 | SHA2-256 | SHA2-384 | SHA2-512`.\n* `tunnel1_phase1_lifetime_seconds` - (Optional, Default `28800`) The lifetime for phase 1 of the IKE negotiation for the first VPN tunnel, in seconds. Valid value is between `900` and `28800`.\n* `tunnel2_phase1_lifetime_seconds` - (Optional, Default `28800`) The lifetime for phase 1 of the IKE negotiation for the second VPN tunnel, in seconds. Valid value is between `900` and `28800`.\n* `tunnel1_phase2_dh_group_numbers` - (Optional) List of one or more Diffie-Hellman group numbers that are permitted for the first VPN tunnel for phase 2 IKE negotiations. Valid values are `2 | 5 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24`.\n* `tunnel2_phase2_dh_group_numbers` - (Optional) List of one or more Diffie-Hellman group numbers that are permitted for the second VPN tunnel for phase 2 IKE negotiations. Valid values are `2 | 5 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24`.\n* `tunnel1_phase2_encryption_algorithms` - (Optional) List of one or more encryption algorithms that are permitted for the first VPN tunnel for phase 2 IKE negotiations. Valid values are `AES128 | AES256 | AES128-GCM-16 | AES256-GCM-16`.\n* `tunnel2_phase2_encryption_algorithms` - (Optional) List of one or more encryption algorithms that are permitted for the second VPN tunnel for phase 2 IKE negotiations. Valid values are `AES128 | AES256 | AES128-GCM-16 | AES256-GCM-16`.\n* `tunnel1_phase2_integrity_algorithms` - (Optional) List of one or more integrity algorithms that are permitted for the first VPN tunnel for phase 2 IKE negotiations. Valid values are `SHA1 | SHA2-256 | SHA2-384 | SHA2-512`.\n* `tunnel2_phase2_integrity_algorithms` - (Optional) List of one or more integrity algorithms that are permitted for the second VPN tunnel for phase 2 IKE negotiations. Valid values are `SHA1 | SHA2-256 | SHA2-384 | SHA2-512`.\n* `tunnel1_phase2_lifetime_seconds` - (Optional, Default `3600`) The lifetime for phase 2 of the IKE negotiation for the first VPN tunnel, in seconds. Valid value is between `900` and `3600`.\n* `tunnel2_phase2_lifetime_seconds` - (Optional, Default `3600`) The lifetime for phase 2 of the IKE negotiation for the second VPN tunnel, in seconds. Valid value is between `900` and `3600`.\n* `tunnel1_rekey_fuzz_percentage` - (Optional, Default `100`) The percentage of the rekey window for the first VPN tunnel (determined by `tunnel1_rekey_margin_time_seconds`) during which the rekey time is randomly selected. Valid value is between `0` and `100`.\n* `tunnel2_rekey_fuzz_percentage` - (Optional, Default `100`) The percentage of the rekey window for the second VPN tunnel (determined by `tunnel2_rekey_margin_time_seconds`) during which the rekey time is randomly selected. Valid value is between `0` and `100`.\n* `tunnel1_rekey_margin_time_seconds` - (Optional, Default `540`) The margin time, in seconds, before the phase 2 lifetime expires, during which the AWS side of the first VPN connection performs an IKE rekey. The exact time of the rekey is randomly selected based on the value for `tunnel1_rekey_fuzz_percentage`. Valid value is between `60` and half of `tunnel1_phase2_lifetime_seconds`.\n* `tunnel2_rekey_margin_time_seconds` - (Optional, Default `540`) The margin time, in seconds, before the phase 2 lifetime expires, during which the AWS side of the second VPN connection performs an IKE rekey. The exact time of the rekey is randomly selected based on the value for `tunnel2_rekey_fuzz_percentage`. Valid value is between `60` and half of `tunnel2_phase2_lifetime_seconds`.\n* `tunnel1_replay_window_size` - (Optional, Default `1024`) The number of packets in an IKE replay window for the first VPN tunnel. Valid value is between `64` and `2048`.\n* `tunnel2_replay_window_size` - (Optional, Default `1024`) The number of packets in an IKE replay window for the second VPN tunnel. Valid value is between `64` and `2048`.\n* `tunnel1_startup_action` - (Optional, Default `add`) The action to take when the establishing the tunnel for the first VPN connection. By default, your customer gateway device must initiate the IKE negotiation and bring up the tunnel. Specify start for AWS to initiate the IKE negotiation. Valid values are `add | start`.\n* `tunnel2_startup_action` - (Optional, Default `add`) The action to take when the establishing the tunnel for the second VPN connection. By default, your customer gateway device must initiate the IKE negotiation and bring up the tunnel. Specify start for AWS to initiate the IKE negotiation. Valid values are `add | start`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the VPN Connection.\n* `id` - The amazon-assigned ID of the VPN connection.\n* `customer_gateway_configuration` - The configuration information for the VPN connection's customer gateway (in the native XML format).\n* `customer_gateway_id` - The ID of the customer gateway to which the connection is attached.\n* `static_routes_only` - Whether the VPN connection uses static routes exclusively.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `transit_gateway_attachment_id` - When associated with an EC2 Transit Gateway (`transit_gateway_id` argument), the attachment ID. See also the [`aws_ec2_tag` resource](/docs/providers/aws/r/ec2_tag.html) for tagging the EC2 Transit Gateway VPN Attachment.\n* `tunnel1_address` - The public IP address of the first VPN tunnel.\n* `tunnel1_cgw_inside_address` - The RFC 6890 link-local address of the first VPN tunnel (Customer Gateway Side).\n* `tunnel1_vgw_inside_address` - The RFC 6890 link-local address of the first VPN tunnel (VPN Gateway Side).\n* `tunnel1_preshared_key` - The preshared key of the first VPN tunnel.\n* `tunnel1_bgp_asn` - The bgp asn number of the first VPN tunnel.\n* `tunnel1_bgp_holdtime` - The bgp holdtime of the first VPN tunnel.\n* `tunnel2_address` - The public IP address of the second VPN tunnel.\n* `tunnel2_cgw_inside_address` - The RFC 6890 link-local address of the second VPN tunnel (Customer Gateway Side).\n* `tunnel2_vgw_inside_address` - The RFC 6890 link-local address of the second VPN tunnel (VPN Gateway Side).\n* `tunnel2_preshared_key` - The preshared key of the second VPN tunnel.\n* `tunnel2_bgp_asn` - The bgp asn number of the second VPN tunnel.\n* `tunnel2_bgp_holdtime` - The bgp holdtime of the second VPN tunnel.\n* `vpn_gateway_id` - The ID of the virtual private gateway to which the connection is attached.\n\n\n## Import\n\nVPN Connections can be imported using the `vpn connection id`, e.g.,\n\n```\n$ terraform import aws_vpn_connection.testvpnconnection vpn-40f41529\n```\n",
    "basename": "vpn_connection.html"
  },
  "vpn_connection_route.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpn_connection_route",
    "description": "Provides a static route between a VPN connection and a customer gateway.",
    "preview": "# Resource: aws_vpn_connection_route\n\nProvides a static route …",
    "content": "\n\n# Resource: aws_vpn_connection_route\n\nProvides a static route between a VPN connection and a customer gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"vpc\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpn_gateway\" \"vpn_gateway\" {\n  vpc_id = aws_vpc.vpc.id\n}\n\nresource \"aws_customer_gateway\" \"customer_gateway\" {\n  bgp_asn    = 65000\n  ip_address = \"172.0.0.1\"\n  type       = \"ipsec.1\"\n}\n\nresource \"aws_vpn_connection\" \"main\" {\n  vpn_gateway_id      = aws_vpn_gateway.vpn_gateway.id\n  customer_gateway_id = aws_customer_gateway.customer_gateway.id\n  type                = \"ipsec.1\"\n  static_routes_only  = true\n}\n\nresource \"aws_vpn_connection_route\" \"office\" {\n  destination_cidr_block = \"192.168.10.0/24\"\n  vpn_connection_id      = aws_vpn_connection.main.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `destination_cidr_block` - (Required) The CIDR block associated with the local subnet of the customer network.\n* `vpn_connection_id` - (Required) The ID of the VPN connection.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `destination_cidr_block` - The CIDR block associated with the local subnet of the customer network.\n* `vpn_connection_id` - The ID of the VPN connection.\n",
    "basename": "vpn_connection_route.html"
  },
  "vpn_gateway.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpn_gateway",
    "description": "Provides a resource to create a VPC VPN Gateway.",
    "preview": "# Resource: aws_vpn_gateway\n\nProvides a resource to create a VPC VPN …",
    "content": "\n\n# Resource: aws_vpn_gateway\n\nProvides a resource to create a VPC VPN Gateway.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpn_gateway\" \"vpn_gw\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = {\n    Name = \"main\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Optional) The VPC ID to create in.\n* `availability_zone` - (Optional) The Availability Zone for the virtual private gateway.\n* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `amazon_side_asn` - (Optional) The Autonomous System Number (ASN) for the Amazon side of the gateway. If you don't specify an ASN, the virtual private gateway is created with the default ASN.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the VPN Gateway.\n* `id` - The ID of the VPN Gateway.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nVPN Gateways can be imported using the `vpn gateway id`, e.g.,\n\n```\n$ terraform import aws_vpn_gateway.testvpngateway vgw-9a4cacf3\n```\n",
    "basename": "vpn_gateway.html"
  },
  "vpn_gateway_attachment.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpn_gateway_attachment",
    "description": "Provides a Virtual Private Gateway attachment resource.",
    "preview": "# Resource: aws_vpn_gateway_attachment\n\nProvides a Virtual Private …",
    "content": "\n\n# Resource: aws_vpn_gateway_attachment\n\nProvides a Virtual Private Gateway attachment resource, allowing for an existing\nhardware VPN gateway to be attached and/or detached from a VPC.\n\n-> **Note:** The [`aws_vpn_gateway`](vpn_gateway.html)\nresource can also automatically attach the Virtual Private Gateway it creates\nto an existing VPC by setting the [`vpc_id`](vpn_gateway.html#vpc_id) attribute accordingly.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpc\" \"network\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpn_gateway\" \"vpn\" {\n  tags = {\n    Name = \"example-vpn-gateway\"\n  }\n}\n\nresource \"aws_vpn_gateway_attachment\" \"vpn_attachment\" {\n  vpc_id         = aws_vpc.network.id\n  vpn_gateway_id = aws_vpn_gateway.vpn.id\n}\n```\n\nSee [Virtual Private Cloud](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html)\nand [Virtual Private Gateway](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html) user\nguides for more information.\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `vpc_id` - (Required) The ID of the VPC.\n* `vpn_gateway_id` - (Required) The ID of the Virtual Private Gateway.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `vpc_id` - The ID of the VPC that Virtual Private Gateway is attached to.\n* `vpn_gateway_id` - The ID of the Virtual Private Gateway.\n\n## Import\n\nThis resource does not support importing.\n",
    "basename": "vpn_gateway_attachment.html"
  },
  "vpn_gateway_route_propagation.html": {
    "subcategory": "VPC",
    "layout": "aws",
    "page_title": "AWS: aws_vpn_gateway_route_propagation",
    "description": "Requests automatic route propagation between a VPN gateway and a route table.",
    "preview": "# Resource: aws_vpn_gateway_route_propagation\n\nRequests automatic …",
    "content": "\n\n# Resource: aws_vpn_gateway_route_propagation\n\nRequests automatic route propagation between a VPN gateway and a route table.\n\n~> **Note:** This resource should not be used with a route table that has\nthe `propagating_vgws` argument set. If that argument is set, any route\npropagation not explicitly listed in its value will be removed.\n\n## Example Usage\n\n```terraform\nresource \"aws_vpn_gateway_route_propagation\" \"example\" {\n  vpn_gateway_id = aws_vpn_gateway.example.id\n  route_table_id = aws_route_table.example.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are required:\n\n* `vpn_gateway_id` - The id of the `aws_vpn_gateway` to propagate routes from.\n* `route_table_id` - The id of the `aws_route_table` to propagate routes into.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Timeouts\n\n`aws_vpn_gateway_route_propagation` provides the following [Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `2 minutes`) Used for propagation creation\n- `delete` - (Default `2 minutes`) Used for propagation deletion",
    "basename": "vpn_gateway_route_propagation.html"
  },
  "waf_byte_match_set.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_byte_match_set",
    "description": "Provides a AWS WAF Byte Match Set resource.",
    "preview": "# Resource: aws_waf_byte_match_set\n\nProvides a WAF Byte Match Set …",
    "content": "\n\n# Resource: aws_waf_byte_match_set\n\nProvides a WAF Byte Match Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_byte_match_set\" \"byte_set\" {\n  name = \"tf_waf_byte_match_set\"\n\n  byte_match_tuples {\n    text_transformation   = \"NONE\"\n    target_string         = \"badrefer1\"\n    positional_constraint = \"CONTAINS\"\n\n    field_to_match {\n      type = \"HEADER\"\n      data = \"referer\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Byte Match Set.\n* `byte_match_tuples` - Specifies the bytes (typically a string that corresponds\n  with ASCII characters) that you want to search for in web requests,\n  the location in requests that you want to search, and other settings.\n\n## Nested blocks\n\n### `byte_match_tuples`\n\n#### Arguments\n\n* `field_to_match` - (Required) The part of a web request that you want to search, such as a specified header or a query string.\n* `positional_constraint` - (Required) Within the portion of a web request that you want to search\n  (for example, in the query string, if any), specify where you want to search.\n  e.g., `CONTAINS`, `CONTAINS_WORD` or `EXACTLY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_ByteMatchTuple.html#WAF-Type-ByteMatchTuple-PositionalConstraint)\n  for all supported values.\n* `target_string` - (Optional) The value that you want to search forE.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_ByteMatchTuple.html#WAF-Type-ByteMatchTuple-TargetString)\n  for all supported values.\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  If you specify a transformation, AWS WAF performs the transformation on `target_string` before inspecting a request for a match.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_ByteMatchTuple.html#WAF-Type-ByteMatchTuple-TextTransformation)\n  for all supported values.\n\n### `field_to_match`\n\n#### Arguments\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_FieldToMatch.html)\n  for all supported values.\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Byte Match Set.\n\n## Import\n\nWAF Byte Match Set can be imported using the id, e.g.,\n\n```\n$ terraform import aws_waf_byte_match_set.byte_set a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_byte_match_set.html"
  },
  "waf_geo_match_set.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_geo_match_set",
    "description": "Provides a AWS WAF GeoMatchSet resource.",
    "preview": "# Resource: aws_waf_geo_match_set\n\nProvides a WAF Geo Match Set …",
    "content": "\n\n# Resource: aws_waf_geo_match_set\n\nProvides a WAF Geo Match Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_geo_match_set\" \"geo_match_set\" {\n  name = \"geo_match_set\"\n\n  geo_match_constraint {\n    type  = \"Country\"\n    value = \"US\"\n  }\n\n  geo_match_constraint {\n    type  = \"Country\"\n    value = \"CA\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the GeoMatchSet.\n* `geo_match_constraint` - (Optional) The GeoMatchConstraint objects which contain the country that you want AWS WAF to search for.\n\n## Nested Blocks\n\n### `geo_match_constraint`\n\n#### Arguments\n\n* `type` - (Required) The type of geographical area you want AWS WAF to search for. Currently Country is the only valid value.\n* `value` - (Required) The country that you want AWS WAF to search for.\n  This is the two-letter country code, e.g., `US`, `CA`, `RU`, `CN`, etc.\n  See [docs](https://docs.aws.amazon.com/waf/latest/APIReference/API_GeoMatchConstraint.html) for all supported values.\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF GeoMatchSet.\n* `arn` - Amazon Resource Name (ARN)\n\n## Import\n\nWAF Geo Match Set can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_waf_geo_match_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_geo_match_set.html"
  },
  "waf_ipset.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_ipset",
    "description": "Provides a AWS WAF IPSet resource.",
    "preview": "# Resource: aws_waf_ipset\n\nProvides a WAF IPSet Resource\n\n## Example …",
    "content": "\n\n# Resource: aws_waf_ipset\n\nProvides a WAF IPSet Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptors {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n\n  ip_set_descriptors {\n    type  = \"IPV4\"\n    value = \"10.16.16.0/16\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the IPSet.\n* `ip_set_descriptors` - (Optional) One or more pairs specifying the IP address type (IPV4 or IPV6) and the IP address range (in CIDR format) from which web requests originate.\n\n## Nested Blocks\n\n### `ip_set_descriptors`\n\n#### Arguments\n\n* `type` - (Required) Type of the IP address - `IPV4` or `IPV6`.\n* `value` - (Required) An IPv4 or IPv6 address specified via CIDR notationE.g., `192.0.2.44/32` or `1111:0000:0000:0000:0000:0000:0000:0000/64`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF IPSet.\n* `arn` - The ARN of the WAF IPSet.\n\n## Import\n\nWAF IPSets can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_waf_ipset.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_ipset.html"
  },
  "waf_rate_based_rule.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_rate_based_rule",
    "description": "Provides a AWS WAF rule resource.",
    "preview": "# Resource: aws_waf_rate_based_rule\n\nProvides a WAF Rate Based Rule …",
    "content": "\n\n# Resource: aws_waf_rate_based_rule\n\nProvides a WAF Rate Based Rule Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptors {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_waf_rate_based_rule\" \"wafrule\" {\n  depends_on  = [aws_waf_ipset.ipset]\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  rate_key   = \"IP\"\n  rate_limit = 100\n\n  predicates {\n    data_id = aws_waf_ipset.ipset.id\n    negated = false\n    type    = \"IPMatch\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `metric_name` - (Required) The name or description for the Amazon CloudWatch metric of this rule.\n* `name` - (Required) The name or description of the rule.\n* `rate_key` - (Required) Valid value is IP.\n* `rate_limit` - (Required) The maximum number of requests, which have an identical value in the field specified by the RateKey, allowed in a five-minute period. Minimum value is 100.\n* `predicates` - (Optional) The objects to include in a rule (documented below).\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Nested Blocks\n\n### `predicates`\n\nSee the [WAF Documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_Predicate.html) for more information.\n\n#### Arguments\n\n* `negated` - (Required) Set this to `false` if you want to allow, block, or count requests\n  based on the settings in the specified `ByteMatchSet`, `IPSet`, `SqlInjectionMatchSet`, `XssMatchSet`, or `SizeConstraintSet`.\n  For example, if an IPSet includes the IP address `192.0.2.44`, AWS WAF will allow or block requests based on that IP address.\n  If set to `true`, AWS WAF will allow, block, or count requests based on all IP addresses _except_ `192.0.2.44`.\n* `data_id` - (Required) A unique identifier for a predicate in the rule, such as Byte Match Set ID or IPSet ID.\n* `type` - (Required) The type of predicate in a rule. Valid values: `ByteMatch`, `GeoMatch`, `IPMatch`, `RegexMatch`, `SizeConstraint`, `SqlInjectionMatch`, or `XssMatch`.\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF rule.\n* `arn` - Amazon Resource Name (ARN)\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF Rated Based Rule can be imported using the id, e.g.,\n\n```\n$ terraform import aws_waf_rate_based_rule.wafrule a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_rate_based_rule.html"
  },
  "waf_regex_match_set.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_regex_match_set",
    "description": "Provides a AWS WAF Regex Match Set resource.",
    "preview": "# Resource: aws_waf_regex_match_set\n\nProvides a WAF Regex Match Set …",
    "content": "\n\n# Resource: aws_waf_regex_match_set\n\nProvides a WAF Regex Match Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_regex_match_set\" \"example\" {\n  name = \"example\"\n\n  regex_match_tuple {\n    field_to_match {\n      data = \"User-Agent\"\n      type = \"HEADER\"\n    }\n\n    regex_pattern_set_id = aws_waf_regex_pattern_set.example.id\n    text_transformation  = \"NONE\"\n  }\n}\n\nresource \"aws_waf_regex_pattern_set\" \"example\" {\n  name                  = \"example\"\n  regex_pattern_strings = [\"one\", \"two\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Regex Match Set.\n* `regex_match_tuple` - (Required) The regular expression pattern that you want AWS WAF to search for in web requests, the location in requests that you want AWS WAF to search, and other settings. See below.\n\n### Nested Arguments\n\n#### `regex_match_tuple`\n\n* `field_to_match` - (Required) The part of a web request that you want to search, such as a specified header or a query string.\n* `regex_pattern_set_id` - (Required) The ID of a [Regex Pattern Set](/docs/providers/aws/r/waf_regex_pattern_set.html).\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_ByteMatchTuple.html#WAF-Type-ByteMatchTuple-TextTransformation)\n  for all supported values.\n\n#### `field_to_match`\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_FieldToMatch.html)\n  for all supported values.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regex Match Set.\n* `arn` - Amazon Resource Name (ARN)\n\n## Import\n\nWAF Regex Match Set can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_waf_regex_match_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_regex_match_set.html"
  },
  "waf_regex_pattern_set.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_regex_pattern_set",
    "description": "Provides a AWS WAF Regex Pattern Set resource.",
    "preview": "# Resource: aws_waf_regex_pattern_set\n\nProvides a WAF Regex Pattern …",
    "content": "\n\n# Resource: aws_waf_regex_pattern_set\n\nProvides a WAF Regex Pattern Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_regex_pattern_set\" \"example\" {\n  name                  = \"tf_waf_regex_pattern_set\"\n  regex_pattern_strings = [\"one\", \"two\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Regex Pattern Set.\n* `regex_pattern_strings` - (Optional) A list of regular expression (regex) patterns that you want AWS WAF to search for, such as `B[a@]dB[o0]t`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regex Pattern Set.\n* `arn` - Amazon Resource Name (ARN)\n\n## Import\n\nAWS WAF Regex Pattern Set can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_waf_regex_pattern_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_regex_pattern_set.html"
  },
  "waf_rule.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_rule",
    "description": "Provides a AWS WAF rule resource.",
    "preview": "# Resource: aws_waf_rule\n\nProvides a WAF Rule Resource\n\n## Example …",
    "content": "\n\n# Resource: aws_waf_rule\n\nProvides a WAF Rule Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptors {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_waf_rule\" \"wafrule\" {\n  depends_on  = [aws_waf_ipset.ipset]\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  predicates {\n    data_id = aws_waf_ipset.ipset.id\n    negated = false\n    type    = \"IPMatch\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `metric_name` - (Required) The name or description for the Amazon CloudWatch metric of this rule. The name can contain only alphanumeric characters (A-Z, a-z, 0-9); the name can't contain whitespace.\n* `name` - (Required) The name or description of the rule.\n* `predicates` - (Optional) The objects to include in a rule (documented below).\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Nested Blocks\n\n### `predicates`\n\nSee the [WAF Documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_Predicate.html) for more information.\n\n#### Arguments\n\n* `negated` - (Required) Set this to `false` if you want to allow, block, or count requests\n  based on the settings in the specified [waf_byte_match_set](/docs/providers/aws/r/waf_byte_match_set.html), [waf_ipset](/docs/providers/aws/r/waf_ipset.html), [aws_waf_size_constraint_set](/docs/providers/aws/r/waf_size_constraint_set.html), [aws_waf_sql_injection_match_set](/docs/providers/aws/r/waf_sql_injection_match_set.html) or [aws_waf_xss_match_set](/docs/providers/aws/r/waf_xss_match_set.html).\n  For example, if an IPSet includes the IP address `192.0.2.44`, AWS WAF will allow or block requests based on that IP address.\n  If set to `true`, AWS WAF will allow, block, or count requests based on all IP addresses except `192.0.2.44`.\n* `data_id` - (Required) A unique identifier for a predicate in the rule, such as Byte Match Set ID or IPSet ID.\n* `type` - (Required) The type of predicate in a rule. Valid values: `ByteMatch`, `GeoMatch`, `IPMatch`, `RegexMatch`, `SizeConstraint`, `SqlInjectionMatch`, or `XssMatch`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF rule.\n* `arn` - The ARN of the WAF rule.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF rules can be imported using the id, e.g.,\n\n```\n$ terraform import aws_waf_rule.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_rule.html"
  },
  "waf_rule_group.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_rule_group",
    "description": "Provides a AWS WAF rule group resource.",
    "preview": "# Resource: aws_waf_rule_group\n\nProvides a WAF Rule Group Resource\n …",
    "content": "\n\n# Resource: aws_waf_rule_group\n\nProvides a WAF Rule Group Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_rule\" \"example\" {\n  name        = \"example\"\n  metric_name = \"example\"\n}\n\nresource \"aws_waf_rule_group\" \"example\" {\n  name        = \"example\"\n  metric_name = \"example\"\n\n  activated_rule {\n    action {\n      type = \"COUNT\"\n    }\n\n    priority = 50\n    rule_id  = aws_waf_rule.example.id\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A friendly name of the rule group\n* `metric_name` - (Required) A friendly name for the metrics from the rule group\n* `activated_rule` - (Optional) A list of activated rules, see below\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Nested Blocks\n\n### `activated_rule`\n\n#### Arguments\n\n* `action` - (Required) Specifies the action that CloudFront or AWS WAF takes when a web request matches the conditions in the rule.\n    * `type` - (Required) e.g., `BLOCK`, `ALLOW`, or `COUNT`\n* `priority` - (Required) Specifies the order in which the rules are evaluated. Rules with a lower value are evaluated before rules with a higher value.\n* `rule_id` - (Required) The ID of a [rule](/docs/providers/aws/r/waf_rule.html)\n* `type` - (Optional) The rule type, either [`REGULAR`](/docs/providers/aws/r/waf_rule.html), [`RATE_BASED`](/docs/providers/aws/r/waf_rate_based_rule.html), or `GROUP`. Defaults to `REGULAR`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF rule group.\n* `arn` - The ARN of the WAF rule group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF Rule Group can be imported using the id, e.g.,\n\n```\n$ terraform import aws_waf_rule_group.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_rule_group.html"
  },
  "waf_size_constraint_set.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_size_constraint_set",
    "description": "Provides a AWS WAF Size Constraint Set resource.",
    "preview": "# Resource: aws_waf_size_constraint_set\n\nProvides a WAF Size …",
    "content": "\n\n# Resource: aws_waf_size_constraint_set\n\nProvides a WAF Size Constraint Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_size_constraint_set\" \"size_constraint_set\" {\n  name = \"tfsize_constraints\"\n\n  size_constraints {\n    text_transformation = \"NONE\"\n    comparison_operator = \"EQ\"\n    size                = \"4096\"\n\n    field_to_match {\n      type = \"BODY\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Size Constraint Set.\n* `size_constraints` - (Optional) Specifies the parts of web requests that you want to inspect the size of.\n\n## Nested Blocks\n\n### `size_constraints`\n\n#### Arguments\n\n* `field_to_match` - (Required) Specifies where in a web request to look for the size constraint.\n* `comparison_operator` - (Required) The type of comparison you want to perform.\n  e.g., `EQ`, `NE`, `LT`, `GT`.\n  See [docs](https://docs.aws.amazon.com/waf/latest/APIReference/API_wafRegional_SizeConstraint.html) for all supported values.\n* `size` - (Required) The size in bytes that you want to compare against the size of the specified `field_to_match`.\n  Valid values are between 0 - 21474836480 bytes (0 - 20 GB).\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  If you specify a transformation, AWS WAF performs the transformation on `field_to_match` before inspecting a request for a match.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_SizeConstraint.html#WAF-Type-SizeConstraint-TextTransformation)\n  for all supported values.\n  **Note:** if you choose `BODY` as `type`, you must choose `NONE` because CloudFront forwards only the first 8192 bytes for inspection.\n\n### `field_to_match`\n\n#### Arguments\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_FieldToMatch.html)\n  for all supported values.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Size Constraint Set.\n* `arn` - Amazon Resource Name (ARN)\n\n## Import\n\nAWS WAF Size Constraint Set can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_waf_size_constraint_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_size_constraint_set.html"
  },
  "waf_sql_injection_match_set.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_sql_injection_match_set",
    "description": "Provides a AWS WAF SQL Injection Match Set resource.",
    "preview": "# Resource: aws_waf_sql_injection_match_set\n\nProvides a WAF SQL …",
    "content": "\n\n# Resource: aws_waf_sql_injection_match_set\n\nProvides a WAF SQL Injection Match Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_sql_injection_match_set\" \"sql_injection_match_set\" {\n  name = \"tf-sql_injection_match_set\"\n\n  sql_injection_match_tuples {\n    text_transformation = \"URL_DECODE\"\n\n    field_to_match {\n      type = \"QUERY_STRING\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the SQL Injection Match Set.\n* `sql_injection_match_tuples` - (Optional) The parts of web requests that you want AWS WAF to inspect for malicious SQL code and, if you want AWS WAF to inspect a header, the name of the header.\n\n## Nested Blocks\n\n### `sql_injection_match_tuples`\n\n* `field_to_match` - (Required) Specifies where in a web request to look for snippets of malicious SQL code.\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  If you specify a transformation, AWS WAF performs the transformation on `field_to_match` before inspecting a request for a match.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_SqlInjectionMatchTuple.html#WAF-Type-SqlInjectionMatchTuple-TextTransformation)\n  for all supported values.\n\n### `field_to_match`\n\n#### Arguments\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_FieldToMatch.html)\n  for all supported values.\n\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF SQL Injection Match Set.\n\n## Import\n\nAWS WAF SQL Injection Match Set can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_waf_sql_injection_match_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_sql_injection_match_set.html"
  },
  "waf_web_acl.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_web_acl",
    "description": "Provides a AWS WAF web access control group (ACL) resource.",
    "preview": "# Resource: aws_waf_web_acl\n\nProvides a WAF Web ACL Resource\n\n## …",
    "content": "\n\n# Resource: aws_waf_web_acl\n\nProvides a WAF Web ACL Resource\n\n## Example Usage\n\nThis example blocks requests coming from `192.0.7.0/24` and allows everything else.\n\n```terraform\nresource \"aws_waf_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptors {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_waf_rule\" \"wafrule\" {\n  depends_on  = [aws_waf_ipset.ipset]\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  predicates {\n    data_id = aws_waf_ipset.ipset.id\n    negated = false\n    type    = \"IPMatch\"\n  }\n}\n\nresource \"aws_waf_web_acl\" \"waf_acl\" {\n  depends_on = [\n    aws_waf_ipset.ipset,\n    aws_waf_rule.wafrule,\n  ]\n  name        = \"tfWebACL\"\n  metric_name = \"tfWebACL\"\n\n  default_action {\n    type = \"ALLOW\"\n  }\n\n  rules {\n    action {\n      type = \"BLOCK\"\n    }\n\n    priority = 1\n    rule_id  = aws_waf_rule.wafrule.id\n    type     = \"REGULAR\"\n  }\n}\n```\n\n### Logging\n\n~> *NOTE:* The Kinesis Firehose Delivery Stream name must begin with `aws-waf-logs-` and be located in `us-east-1` region. See the [AWS WAF Developer Guide](https://docs.aws.amazon.com/waf/latest/developerguide/logging.html) for more information about enabling WAF logging.\n\n```terraform\nresource \"aws_waf_web_acl\" \"example\" {\n  # ... other configuration ...\n  logging_configuration {\n    log_destination = aws_kinesis_firehose_delivery_stream.example.arn\n\n    redacted_fields {\n      field_to_match {\n        type = \"URI\"\n      }\n\n      field_to_match {\n        data = \"referer\"\n        type = \"HEADER\"\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `default_action` - (Required) Configuration block with action that you want AWS WAF to take when a request doesn't match the criteria in any of the rules that are associated with the web ACL. Detailed below.\n* `metric_name` - (Required) The name or description for the Amazon CloudWatch metric of this web ACL.\n* `name` - (Required) The name or description of the web ACL.\n* `rules` - (Optional) Configuration blocks containing rules to associate with the web ACL and the settings for each rule. Detailed below.\n* `logging_configuration` - (Optional) Configuration block to enable WAF logging. Detailed below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `default_action` Configuration Block\n\n* `type` - (Required) Specifies how you want AWS WAF to respond to requests that don't match the criteria in any of the `rules`.\n  e.g., `ALLOW`, `BLOCK` or `COUNT`\n\n### `logging_configuration` Configuration Block\n\n* `log_destination` - (Required) Amazon Resource Name (ARN) of Kinesis Firehose Delivery Stream\n* `redacted_fields` - (Optional) Configuration block containing parts of the request that you want redacted from the logs. Detailed below.\n\n#### `redacted_fields` Configuration Block\n\n* `field_to_match` - (Required) Set of configuration blocks for fields to redact. Detailed below.\n\n##### `field_to_match` Configuration Block\n\n-> Additional information about this configuration can be found in the [AWS WAF Regional API Reference](https://docs.aws.amazon.com/waf/latest/APIReference/API_regional_FieldToMatch.html).\n\n* `data` - (Optional) When the value of `type` is `HEADER`, enter the name of the header that you want the WAF to search, for example, `User-Agent` or `Referer`. If the value of `type` is any other value, omit `data`.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified stringE.g., `HEADER` or `METHOD`\n\n### `rules` Configuration Block\n\nSee [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_ActivatedRule.html) for all details and supported values.\n\n* `action` - (Optional) The action that CloudFront or AWS WAF takes when a web request matches the conditions in the rule. Not used if `type` is `GROUP`.\n    * `type` - (Required) valid values are: `BLOCK`, `ALLOW`, or `COUNT`\n* `override_action` - (Optional) Override the action that a group requests CloudFront or AWS WAF takes when a web request matches the conditions in the rule. Only used if `type` is `GROUP`.\n    * `type` - (Required) valid values are: `NONE` or `COUNT`\n* `priority` - (Required) Specifies the order in which the rules in a WebACL are evaluated.\n  Rules with a lower value are evaluated before rules with a higher value.\n* `rule_id` - (Required) ID of the associated WAF (Global) rule (e.g., [`aws_waf_rule`](/docs/providers/aws/r/waf_rule.html)). WAF (Regional) rules cannot be used.\n* `type` - (Optional) The rule type, either `REGULAR`, as defined by [Rule](http://docs.aws.amazon.com/waf/latest/APIReference/API_Rule.html), `RATE_BASED`, as defined by [RateBasedRule](http://docs.aws.amazon.com/waf/latest/APIReference/API_RateBasedRule.html), or `GROUP`, as defined by [RuleGroup](https://docs.aws.amazon.com/waf/latest/APIReference/API_RuleGroup.html). The default is REGULAR. If you add a RATE_BASED rule, you need to set `type` as `RATE_BASED`. If you add a GROUP rule, you need to set `type` as `GROUP`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF WebACL.\n* `arn` - The ARN of the WAF WebACL.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF Web ACL can be imported using the `id`, e.g.,\n\n```\n$ terraform import aws_waf_web_acl.main 0c8e583e-18f3-4c13-9e2a-67c4805d2f94\n```\n",
    "basename": "waf_web_acl.html"
  },
  "waf_xss_match_set.html": {
    "subcategory": "WAF",
    "layout": "aws",
    "page_title": "AWS: aws_waf_xss_match_set",
    "description": "Provides a AWS WAF XssMatchSet resource.",
    "preview": "# Resource: aws_waf_xss_match_set\n\nProvides a WAF XSS Match Set …",
    "content": "\n\n# Resource: aws_waf_xss_match_set\n\nProvides a WAF XSS Match Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_waf_xss_match_set\" \"xss_match_set\" {\n  name = \"xss_match_set\"\n\n  xss_match_tuples {\n    text_transformation = \"NONE\"\n\n    field_to_match {\n      type = \"URI\"\n    }\n  }\n\n  xss_match_tuples {\n    text_transformation = \"NONE\"\n\n    field_to_match {\n      type = \"QUERY_STRING\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the SizeConstraintSet.\n* `xss_match_tuples` - (Optional) The parts of web requests that you want to inspect for cross-site scripting attacks.\n\n## Nested Blocks\n\n### `xss_match_tuples`\n\n* `field_to_match` - (Required) Specifies where in a web request to look for cross-site scripting attacks.\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  If you specify a transformation, AWS WAF performs the transformation on `target_string` before inspecting a request for a match.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_XssMatchTuple.html#WAF-Type-XssMatchTuple-TextTransformation)\n  for all supported values.\n\n### `field_to_match`\n\n#### Arguments\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_FieldToMatch.html)\n  for all supported values.\n\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF XssMatchSet.\n* `arn` - Amazon Resource Name (ARN)\n\n## Import\n\nWAF XSS Match Set can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_waf_xss_match_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "waf_xss_match_set.html"
  },
  "wafregional_byte_match_set.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_byte_match_set",
    "description": "Provides a AWS WAF Regional ByteMatchSet resource for use with ALB.",
    "preview": "# Resource: aws_wafregional_byte_match_set\n\nProvides a WAF Regional …",
    "content": "\n\n# Resource: aws_wafregional_byte_match_set\n\nProvides a WAF Regional Byte Match Set Resource for use with Application Load Balancer.\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_byte_match_set\" \"byte_set\" {\n  name = \"tf_waf_byte_match_set\"\n\n  byte_match_tuples {\n    text_transformation   = \"NONE\"\n    target_string         = \"badrefer1\"\n    positional_constraint = \"CONTAINS\"\n\n    field_to_match {\n      type = \"HEADER\"\n      data = \"referer\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the ByteMatchSet.\n* `byte_match_tuples` - (Optional)Settings for the ByteMatchSet, such as the bytes (typically a string that corresponds with ASCII characters) that you want AWS WAF to search for in web requests. ByteMatchTuple documented below.\n\n\nByteMatchTuples(byte_match_tuples) support the following:\n\n* `field_to_match` - (Required) Settings for the ByteMatchTuple. FieldToMatch documented below.\n* `positional_constraint` - (Required) Within the portion of a web request that you want to search.\n* `target_string` - (Required) The value that you want AWS WAF to search for. The maximum length of the value is 50 bytes.\n* `text_transformation` - (Required) The formatting way for web request.\n\nFieldToMatch(field_to_match) support following:\n\n* `data` - (Optional) When the value of Type is HEADER, enter the name of the header that you want AWS WAF to search, for example, User-Agent or Referer. If the value of Type is any other value, omit Data.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF ByteMatchSet.\n\n## Import\n\nWAF Regional Byte Match Set can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_byte_match_set.byte_set a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_byte_match_set.html"
  },
  "wafregional_geo_match_set.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_geo_match_set",
    "description": "Provides a AWS WAF Regional Geo Match Set resource.",
    "preview": "# Resource: aws_wafregional_geo_match_set\n\nProvides a WAF Regional …",
    "content": "\n\n# Resource: aws_wafregional_geo_match_set\n\nProvides a WAF Regional Geo Match Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_geo_match_set\" \"geo_match_set\" {\n  name = \"geo_match_set\"\n\n  geo_match_constraint {\n    type  = \"Country\"\n    value = \"US\"\n  }\n\n  geo_match_constraint {\n    type  = \"Country\"\n    value = \"CA\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Geo Match Set.\n* `geo_match_constraint` - (Optional) The Geo Match Constraint objects which contain the country that you want AWS WAF to search for.\n\n## Nested Blocks\n\n### `geo_match_constraint`\n\n#### Arguments\n\n* `type` - (Required) The type of geographical area you want AWS WAF to search for. Currently Country is the only valid value.\n* `value` - (Required) The country that you want AWS WAF to search for.\n  This is the two-letter country code, e.g., `US`, `CA`, `RU`, `CN`, etc.\n  See [docs](https://docs.aws.amazon.com/waf/latest/APIReference/API_GeoMatchConstraint.html) for all supported values.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regional Geo Match Set.\n\n## Import\n\nWAF Regional Geo Match Set can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_geo_match_set.geo_match_set a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_geo_match_set.html"
  },
  "wafregional_ipset.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_ipset",
    "description": "Provides a AWS WAF Regional IPSet resource for use with ALB.",
    "preview": "# Resource: aws_wafregional_ipset\n\nProvides a WAF Regional IPSet …",
    "content": "\n\n# Resource: aws_wafregional_ipset\n\nProvides a WAF Regional IPSet Resource for use with Application Load Balancer.\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptor {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n\n  ip_set_descriptor {\n    type  = \"IPV4\"\n    value = \"10.16.16.0/16\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the IPSet.\n* `ip_set_descriptor` - (Optional) One or more pairs specifying the IP address type (IPV4 or IPV6) and the IP address range (in CIDR notation) from which web requests originate.\n\n## Nested Blocks\n\n### `ip_set_descriptor`\n\n#### Arguments\n\n* `type` - (Required) The string like IPV4 or IPV6.\n* `value` - (Required) The CIDR notation.\n\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF IPSet.\n* `arn` - The ARN of the WAF IPSet.\n\n## Import\n\nWAF Regional IPSets can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_wafregional_ipset.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_ipset.html"
  },
  "wafregional_rate_based_rule.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_rate_based_rule",
    "description": "Provides a AWS WAF Regional rate based rule resource.",
    "preview": "# Resource: aws_wafregional_rate_based_rule\n\nProvides a WAF Rate …",
    "content": "\n\n# Resource: aws_wafregional_rate_based_rule\n\nProvides a WAF Rate Based Rule Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptor {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_wafregional_rate_based_rule\" \"wafrule\" {\n  depends_on  = [aws_wafregional_ipset.ipset]\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  rate_key   = \"IP\"\n  rate_limit = 100\n\n  predicate {\n    data_id = aws_wafregional_ipset.ipset.id\n    negated = false\n    type    = \"IPMatch\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `metric_name` - (Required) The name or description for the Amazon CloudWatch metric of this rule.\n* `name` - (Required) The name or description of the rule.\n* `rate_key` - (Required) Valid value is IP.\n* `rate_limit` - (Required) The maximum number of requests, which have an identical value in the field specified by the RateKey, allowed in a five-minute period. Minimum value is 100.\n* `predicate` - (Optional) The objects to include in a rule (documented below).\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Nested Blocks\n\n### `predicate`\n\nSee the [WAF Documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_Predicate.html) for more information.\n\n#### Arguments\n\n* `negated` - (Required) Set this to `false` if you want to allow, block, or count requests\n  based on the settings in the specified `ByteMatchSet`, `IPSet`, `SqlInjectionMatchSet`, `XssMatchSet`, or `SizeConstraintSet`.\n  For example, if an IPSet includes the IP address `192.0.2.44`, AWS WAF will allow or block requests based on that IP address.\n  If set to `true`, AWS WAF will allow, block, or count requests based on all IP addresses _except_ `192.0.2.44`.\n* `data_id` - (Required) A unique identifier for a predicate in the rule, such as Byte Match Set ID or IPSet ID.\n* `type` - (Required) The type of predicate in a rule. Valid values: `ByteMatch`, `GeoMatch`, `IPMatch`, `RegexMatch`, `SizeConstraint`, `SqlInjectionMatch`, or `XssMatch`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regional Rate Based Rule.\n* `arn` - The ARN of the WAF Regional Rate Based Rule.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF Regional Rate Based Rule can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_rate_based_rule.wafrule a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_rate_based_rule.html"
  },
  "wafregional_regex_match_set.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_regex_match_set",
    "description": "Provides a AWS WAF Regional Regex Match Set resource.",
    "preview": "# Resource: aws_wafregional_regex_match_set\n\nProvides a WAF Regional …",
    "content": "\n\n# Resource: aws_wafregional_regex_match_set\n\nProvides a WAF Regional Regex Match Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_regex_match_set\" \"example\" {\n  name = \"example\"\n\n  regex_match_tuple {\n    field_to_match {\n      data = \"User-Agent\"\n      type = \"HEADER\"\n    }\n\n    regex_pattern_set_id = aws_wafregional_regex_pattern_set.example.id\n    text_transformation  = \"NONE\"\n  }\n}\n\nresource \"aws_wafregional_regex_pattern_set\" \"example\" {\n  name                  = \"example\"\n  regex_pattern_strings = [\"one\", \"two\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Regex Match Set.\n* `regex_match_tuple` - (Required) The regular expression pattern that you want AWS WAF to search for in web requests, the location in requests that you want AWS WAF to search, and other settings. See below.\n\n### Nested Arguments\n\n#### `regex_match_tuple`\n\n* `field_to_match` - (Required) The part of a web request that you want to search, such as a specified header or a query string.\n* `regex_pattern_set_id` - (Required) The ID of a [Regex Pattern Set](/docs/providers/aws/r/waf_regex_pattern_set.html).\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_ByteMatchTuple.html#WAF-Type-ByteMatchTuple-TextTransformation)\n  for all supported values.\n\n#### `field_to_match`\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_FieldToMatch.html)\n  for all supported values.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regional Regex Match Set.\n\n## Import\n\nWAF Regional Regex Match Set can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_regex_match_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_regex_match_set.html"
  },
  "wafregional_regex_pattern_set.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_regex_pattern_set",
    "description": "Provides a AWS WAF Regional Regex Pattern Set resource.",
    "preview": "# Resource: aws_wafregional_regex_pattern_set\n\nProvides a WAF …",
    "content": "\n\n# Resource: aws_wafregional_regex_pattern_set\n\nProvides a WAF Regional Regex Pattern Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_regex_pattern_set\" \"example\" {\n  name                  = \"example\"\n  regex_pattern_strings = [\"one\", \"two\"]\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Regex Pattern Set.\n* `regex_pattern_strings` - (Optional) A list of regular expression (regex) patterns that you want AWS WAF to search for, such as `B[a@]dB[o0]t`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regional Regex Pattern Set.\n\n## Import\n\nWAF Regional Regex Pattern Set can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_regex_pattern_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_regex_pattern_set.html"
  },
  "wafregional_rule.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_rule",
    "description": "Provides an AWS WAF Regional rule resource for use with ALB.",
    "preview": "# Resource: aws_wafregional_rule\n\nProvides an WAF Regional Rule …",
    "content": "\n\n# Resource: aws_wafregional_rule\n\nProvides an WAF Regional Rule Resource for use with Application Load Balancer.\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptor {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_wafregional_rule\" \"wafrule\" {\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  predicate {\n    type    = \"IPMatch\"\n    data_id = aws_wafregional_ipset.ipset.id\n    negated = false\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the rule.\n* `metric_name` - (Required) The name or description for the Amazon CloudWatch metric of this rule.\n* `predicate` - (Optional) The objects to include in a rule (documented below).\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Nested Fields\n\n### `predicate`\n\nSee the [WAF Documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_Predicate.html) for more information.\n\n#### Arguments\n\n* `type` - (Required) The type of predicate in a rule. Valid values: `ByteMatch`, `GeoMatch`, `IPMatch`, `RegexMatch`, `SizeConstraint`, `SqlInjectionMatch`, or `XssMatch`\n* `data_id` - (Required) The unique identifier of a predicate, such as the ID of a `ByteMatchSet` or `IPSet`.\n* `negated` - (Required) Whether to use the settings or the negated settings that you specified in the objects.\n\n## Remarks\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regional Rule.\n* `arn` - The ARN of the WAF Regional Rule.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF Regional Rule can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_rule.wafrule a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_rule.html"
  },
  "wafregional_rule_group.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_rule_group",
    "description": "Provides a AWS WAF Regional Rule Group resource.",
    "preview": "# Resource: aws_wafregional_rule_group\n\nProvides a WAF Regional Rule …",
    "content": "\n\n# Resource: aws_wafregional_rule_group\n\nProvides a WAF Regional Rule Group Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_rule\" \"example\" {\n  name        = \"example\"\n  metric_name = \"example\"\n}\n\nresource \"aws_wafregional_rule_group\" \"example\" {\n  name        = \"example\"\n  metric_name = \"example\"\n\n  activated_rule {\n    action {\n      type = \"COUNT\"\n    }\n\n    priority = 50\n    rule_id  = aws_wafregional_rule.example.id\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A friendly name of the rule group\n* `metric_name` - (Required) A friendly name for the metrics from the rule group\n* `activated_rule` - (Optional) A list of activated rules, see below\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Nested Blocks\n\n### `activated_rule`\n\n#### Arguments\n\n* `action` - (Required) Specifies the action that CloudFront or AWS WAF takes when a web request matches the conditions in the rule.\n    * `type` - (Required) e.g., `BLOCK`, `ALLOW`, or `COUNT`\n* `priority` - (Required) Specifies the order in which the rules are evaluated. Rules with a lower value are evaluated before rules with a higher value.\n* `rule_id` - (Required) The ID of a [rule](/docs/providers/aws/r/wafregional_rule.html)\n* `type` - (Optional) The rule type, either [`REGULAR`](/docs/providers/aws/r/wafregional_rule.html), [`RATE_BASED`](/docs/providers/aws/r/wafregional_rate_based_rule.html), or `GROUP`. Defaults to `REGULAR`.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Regional Rule Group.\n* `arn` - The ARN of the WAF Regional Rule Group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF Regional Rule Group can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_rule_group.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_rule_group.html"
  },
  "wafregional_size_constraint_set.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_size_constraint_set",
    "description": "Provides an AWS WAF Regional Size Constraint Set resource for use with ALB.",
    "preview": "# Resource: aws_wafregional_size_constraint_set\n\nProvides a WAF …",
    "content": "\n\n# Resource: aws_wafregional_size_constraint_set\n\nProvides a WAF Regional Size Constraint Set Resource for use with Application Load Balancer.\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_size_constraint_set\" \"size_constraint_set\" {\n  name = \"tfsize_constraints\"\n\n  size_constraints {\n    text_transformation = \"NONE\"\n    comparison_operator = \"EQ\"\n    size                = \"4096\"\n\n    field_to_match {\n      type = \"BODY\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the Size Constraint Set.\n* `size_constraints` - (Optional) Specifies the parts of web requests that you want to inspect the size of.\n\n## Nested Blocks\n\n### `size_constraints`\n\n#### Arguments\n\n* `field_to_match` - (Required) Specifies where in a web request to look for the size constraint.\n* `comparison_operator` - (Required) The type of comparison you want to perform.\n  e.g., `EQ`, `NE`, `LT`, `GT`.\n  See [docs](https://docs.aws.amazon.com/waf/latest/APIReference/API_wafRegional_SizeConstraint.html) for all supported values.\n* `size` - (Required) The size in bytes that you want to compare against the size of the specified `field_to_match`.\n  Valid values are between 0 - 21474836480 bytes (0 - 20 GB).\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  If you specify a transformation, AWS WAF performs the transformation on `field_to_match` before inspecting a request for a match.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_SizeConstraint.html#WAF-Type-SizeConstraint-TextTransformation)\n  for all supported values.\n  **Note:** if you choose `BODY` as `type`, you must choose `NONE` because CloudFront forwards only the first 8192 bytes for inspection.\n\n### `field_to_match`\n\n#### Arguments\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](http://docs.aws.amazon.com/waf/latest/APIReference/API_FieldToMatch.html)\n  for all supported values.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF Size Constraint Set.\n\n## Import\n\nWAF Size Constraint Set can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_size_constraint_set.size_constraint_set a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_size_constraint_set.html"
  },
  "wafregional_sql_injection_match_set.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_sql_injection_match_set",
    "description": "Provides a AWS WAF Regional SqlInjectionMatchSet resource for use with ALB.",
    "preview": "# Resource: aws_wafregional_sql_injection_match_set\n\nProvides a WAF …",
    "content": "\n\n# Resource: aws_wafregional_sql_injection_match_set\n\nProvides a WAF Regional SQL Injection Match Set Resource for use with Application Load Balancer.\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_sql_injection_match_set\" \"sql_injection_match_set\" {\n  name = \"tf-sql_injection_match_set\"\n\n  sql_injection_match_tuple {\n    text_transformation = \"URL_DECODE\"\n\n    field_to_match {\n      type = \"QUERY_STRING\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name or description of the SizeConstraintSet.\n* `sql_injection_match_tuple` - (Optional) The parts of web requests that you want AWS WAF to inspect for malicious SQL code and, if you want AWS WAF to inspect a header, the name of the header.\n\n### Nested fields\n\n### `sql_injection_match_tuple`\n\n* `field_to_match` - (Required) Specifies where in a web request to look for snippets of malicious SQL code.\n* `text_transformation` - (Required) Text transformations used to eliminate unusual formatting that attackers use in web requests in an effort to bypass AWS WAF.\n  If you specify a transformation, AWS WAF performs the transformation on `field_to_match` before inspecting a request for a match.\n  e.g., `CMD_LINE`, `HTML_ENTITY_DECODE` or `NONE`.\n  See [docs](https://docs.aws.amazon.com/waf/latest/APIReference/API_regional_SqlInjectionMatchTuple.html#WAF-Type-regional_SqlInjectionMatchTuple-TextTransformation)\n  for all supported values.\n\n### `field_to_match`\n\n* `data` - (Optional) When `type` is `HEADER`, enter the name of the header that you want to search, e.g., `User-Agent` or `Referer`.\n  If `type` is any other value, omit this field.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified string.\n  e.g., `HEADER`, `METHOD` or `BODY`.\n  See [docs](https://docs.aws.amazon.com/waf/latest/APIReference/API_regional_FieldToMatch.html)\n  for all supported values.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF SqlInjectionMatchSet.\n\n## Import\n\nWAF Regional Sql Injection Match Set can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_sql_injection_match_set.sql_injection_match_set a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_sql_injection_match_set.html"
  },
  "wafregional_web_acl.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_web_acl",
    "description": "Provides a AWS WAF Regional web access control group (ACL) resource for use with ALB.",
    "preview": "# Resource: aws_wafregional_web_acl\n\nProvides a WAF Regional Web ACL …",
    "content": "\n\n# Resource: aws_wafregional_web_acl\n\nProvides a WAF Regional Web ACL Resource for use with Application Load Balancer.\n\n## Example Usage\n\n### Regular Rule\n\n```terraform\nresource \"aws_wafregional_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptor {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_wafregional_rule\" \"wafrule\" {\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  predicate {\n    data_id = aws_wafregional_ipset.ipset.id\n    negated = false\n    type    = \"IPMatch\"\n  }\n}\n\nresource \"aws_wafregional_web_acl\" \"wafacl\" {\n  name        = \"tfWebACL\"\n  metric_name = \"tfWebACL\"\n\n  default_action {\n    type = \"ALLOW\"\n  }\n\n  rule {\n    action {\n      type = \"BLOCK\"\n    }\n\n    priority = 1\n    rule_id  = aws_wafregional_rule.wafrule.id\n    type     = \"REGULAR\"\n  }\n}\n```\n\n### Group Rule\n\n```terraform\nresource \"aws_wafregional_web_acl\" \"example\" {\n  name        = \"example\"\n  metric_name = \"example\"\n\n  default_action {\n    type = \"ALLOW\"\n  }\n\n  rule {\n    priority = 1\n    rule_id  = aws_wafregional_rule_group.example.id\n    type     = \"GROUP\"\n\n    override_action {\n      type = \"NONE\"\n    }\n  }\n}\n```\n\n### Logging\n\n~> *NOTE:* The Kinesis Firehose Delivery Stream name must begin with `aws-waf-logs-`. See the [AWS WAF Developer Guide](https://docs.aws.amazon.com/waf/latest/developerguide/logging.html) for more information about enabling WAF logging.\n\n```terraform\nresource \"aws_wafregional_web_acl\" \"example\" {\n  # ... other configuration ...\n\n  logging_configuration {\n    log_destination = aws_kinesis_firehose_delivery_stream.example.arn\n\n    redacted_fields {\n      field_to_match {\n        type = \"URI\"\n      }\n\n      field_to_match {\n        data = \"referer\"\n        type = \"HEADER\"\n      }\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `default_action` - (Required) The action that you want AWS WAF Regional to take when a request doesn't match the criteria in any of the rules that are associated with the web ACL.\n* `metric_name` - (Required) The name or description for the Amazon CloudWatch metric of this web ACL.\n* `name` - (Required) The name or description of the web ACL.\n* `logging_configuration` - (Optional) Configuration block to enable WAF logging. Detailed below.\n* `rule` - (Optional) Set of configuration blocks containing rules for the web ACL. Detailed below.\n* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### `default_action` Configuration Block\n\n* `type` - (Required) Specifies how you want AWS WAF Regional to respond to requests that match the settings in a ruleE.g., `ALLOW`, `BLOCK` or `COUNT`\n\n### `logging_configuration` Configuration Block\n\n* `log_destination` - (Required) Amazon Resource Name (ARN) of Kinesis Firehose Delivery Stream\n* `redacted_fields` - (Optional) Configuration block containing parts of the request that you want redacted from the logs. Detailed below.\n\n#### `redacted_fields` Configuration Block\n\n* `field_to_match` - (Required) Set of configuration blocks for fields to redact. Detailed below.\n\n##### `field_to_match` Configuration Block\n\n-> Additional information about this configuration can be found in the [AWS WAF Regional API Reference](https://docs.aws.amazon.com/waf/latest/APIReference/API_regional_FieldToMatch.html).\n\n* `data` - (Optional) When the value of `type` is `HEADER`, enter the name of the header that you want the WAF to search, for example, `User-Agent` or `Referer`. If the value of `type` is any other value, omit `data`.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified stringE.g., `HEADER` or `METHOD`\n\n### `rule` Configuration Block\n\n-> Additional information about this configuration can be found in the [AWS WAF Regional API Reference](https://docs.aws.amazon.com/waf/latest/APIReference/API_regional_ActivatedRule.html).\n\n* `priority` - (Required) Specifies the order in which the rules in a WebACL are evaluated.\n  Rules with a lower value are evaluated before rules with a higher value.\n* `rule_id` - (Required) ID of the associated WAF (Regional) rule (e.g., [`aws_wafregional_rule`](/docs/providers/aws/r/wafregional_rule.html)). WAF (Global) rules cannot be used.\n* `action` - (Optional) Configuration block of the action that CloudFront or AWS WAF takes when a web request matches the conditions in the rule.  Not used if `type` is `GROUP`. Detailed below.\n* `override_action` - (Optional) Configuration block of the override the action that a group requests CloudFront or AWS WAF takes when a web request matches the conditions in the rule.  Only used if `type` is `GROUP`. Detailed below.\n* `type` - (Optional) The rule type, either `REGULAR`, as defined by [Rule](http://docs.aws.amazon.com/waf/latest/APIReference/API_Rule.html), `RATE_BASED`, as defined by [RateBasedRule](http://docs.aws.amazon.com/waf/latest/APIReference/API_RateBasedRule.html), or `GROUP`, as defined by [RuleGroup](https://docs.aws.amazon.com/waf/latest/APIReference/API_RuleGroup.html). The default is REGULAR. If you add a RATE_BASED rule, you need to set `type` as `RATE_BASED`. If you add a GROUP rule, you need to set `type` as `GROUP`.\n\n#### `action` / `override_action` Configuration Block\n\n* `type` - (Required) Specifies how you want AWS WAF Regional to respond to requests that match the settings in a ruleE.g., `ALLOW`, `BLOCK` or `COUNT`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - Amazon Resource Name (ARN) of the WAF Regional WebACL.\n* `id` - The ID of the WAF Regional WebACL.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAF Regional Web ACL can be imported using the id, e.g.,\n\n```\n$ terraform import aws_wafregional_web_acl.wafacl a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc\n```\n",
    "basename": "wafregional_web_acl.html"
  },
  "wafregional_web_acl_association.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_web_acl_association",
    "description": "Manages an association with WAF Regional Web ACL",
    "preview": "# Resource: aws_wafregional_web_acl_association\n\nManages an …",
    "content": "\n\n# Resource: aws_wafregional_web_acl_association\n\nManages an association with WAF Regional Web ACL.\n\n-> **Note:** An Application Load Balancer can only be associated with one WAF Regional WebACL.\n\n## Example Usage\n\n### Application Load Balancer Association\n\n```terraform\nresource \"aws_wafregional_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptor {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_wafregional_rule\" \"foo\" {\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  predicate {\n    data_id = aws_wafregional_ipset.ipset.id\n    negated = false\n    type    = \"IPMatch\"\n  }\n}\n\nresource \"aws_wafregional_web_acl\" \"foo\" {\n  name        = \"foo\"\n  metric_name = \"foo\"\n\n  default_action {\n    type = \"ALLOW\"\n  }\n\n  rule {\n    action {\n      type = \"BLOCK\"\n    }\n\n    priority = 1\n    rule_id  = aws_wafregional_rule.foo.id\n  }\n}\n\nresource \"aws_vpc\" \"foo\" {\n  cidr_block = \"10.1.0.0/16\"\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nresource \"aws_subnet\" \"foo\" {\n  vpc_id            = aws_vpc.foo.id\n  cidr_block        = \"10.1.1.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[0]\n}\n\nresource \"aws_subnet\" \"bar\" {\n  vpc_id            = aws_vpc.foo.id\n  cidr_block        = \"10.1.2.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[1]\n}\n\nresource \"aws_alb\" \"foo\" {\n  internal = true\n  subnets  = [aws_subnet.foo.id, aws_subnet.bar.id]\n}\n\nresource \"aws_wafregional_web_acl_association\" \"foo\" {\n  resource_arn = aws_alb.foo.arn\n  web_acl_id   = aws_wafregional_web_acl.foo.id\n}\n```\n\n### API Gateway Association\n\n```terraform\nresource \"aws_wafregional_ipset\" \"ipset\" {\n  name = \"tfIPSet\"\n\n  ip_set_descriptor {\n    type  = \"IPV4\"\n    value = \"192.0.7.0/24\"\n  }\n}\n\nresource \"aws_wafregional_rule\" \"foo\" {\n  name        = \"tfWAFRule\"\n  metric_name = \"tfWAFRule\"\n\n  predicate {\n    data_id = aws_wafregional_ipset.ipset.id\n    negated = false\n    type    = \"IPMatch\"\n  }\n}\n\nresource \"aws_wafregional_web_acl\" \"foo\" {\n  name        = \"foo\"\n  metric_name = \"foo\"\n\n  default_action {\n    type = \"ALLOW\"\n  }\n\n  rule {\n    action {\n      type = \"BLOCK\"\n    }\n\n    priority = 1\n    rule_id  = aws_wafregional_rule.foo.id\n  }\n}\n\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = \"example\"\n      version = \"1.0\"\n    }\n    paths = {\n      \"/path1\" = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n\nresource \"aws_wafregional_web_acl_association\" \"association\" {\n  resource_arn = aws_api_gateway_stage.example.arn\n  web_acl_id   = aws_wafregional_web_acl.foo.id\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `web_acl_id` - (Required) The ID of the WAF Regional WebACL to create an association.\n* `resource_arn` - (Required) ARN of the resource to associate with. For example, an Application Load Balancer or API Gateway Stage.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the association\n\n## Import\n\nWAF Regional Web ACL Association can be imported using their `web_acl_id:resource_arn`, e.g.,\n\n```\n$ terraform import aws_wafregional_web_acl_association.foo web_acl_id:resource_arn\n```\n",
    "basename": "wafregional_web_acl_association.html"
  },
  "wafregional_xss_match_set.html": {
    "subcategory": "WAF Regional",
    "layout": "aws",
    "page_title": "AWS: aws_wafregional_xss_match_set",
    "description": "Provides an AWS WAF Regional XSS Match Set resource for use with ALB.",
    "preview": "# Resource: aws_wafregional_xss_match_set\n\nProvides a WAF Regional …",
    "content": "\n\n# Resource: aws_wafregional_xss_match_set\n\nProvides a WAF Regional XSS Match Set Resource for use with Application Load Balancer.\n\n## Example Usage\n\n```terraform\nresource \"aws_wafregional_xss_match_set\" \"xss_match_set\" {\n  name = \"xss_match_set\"\n\n  xss_match_tuple {\n    text_transformation = \"NONE\"\n\n    field_to_match {\n      type = \"URI\"\n    }\n  }\n\n  xss_match_tuple {\n    text_transformation = \"NONE\"\n\n    field_to_match {\n      type = \"QUERY_STRING\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the set\n* `xss_match_tuple` - (Optional) The parts of web requests that you want to inspect for cross-site scripting attacks.\n\n### Nested fields\n\n#### `xss_match_tuple`\n\n* `field_to_match` - (Required) Specifies where in a web request to look for cross-site scripting attacks.\n* `text_transformation` - (Required) Which text transformation, if any, to perform on the web request before inspecting the request for cross-site scripting attacks.\n\n#### `field_to_match`\n\n* `data` - (Optional) When the value of `type` is `HEADER`, enter the name of the header that you want the WAF to search, for example, `User-Agent` or `Referer`. If the value of `type` is any other value, omit `data`.\n* `type` - (Required) The part of the web request that you want AWS WAF to search for a specified stringE.g., `HEADER` or `METHOD`\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the Regional WAF XSS Match Set.\n\n## Import\n\nAWS WAF Regional XSS Match can be imported using the `id`, e.g.,\n\n```sh\n$ terraform import aws_wafregional_xss_match_set.example 12345abcde\n```\n",
    "basename": "wafregional_xss_match_set.html"
  },
  "wafv2_ip_set.html": {
    "subcategory": "WAFv2",
    "layout": "aws",
    "page_title": "AWS: aws_wafv2_ip_set",
    "description": "Provides an AWS WAFv2 IP Set resource.",
    "preview": "# Resource: aws_wafv2_ip_set\n\nProvides a WAFv2 IP Set Resource\n\n## …",
    "content": "\n\n# Resource: aws_wafv2_ip_set\n\nProvides a WAFv2 IP Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_wafv2_ip_set\" \"example\" {\n  name               = \"example\"\n  description        = \"Example IP set\"\n  scope              = \"REGIONAL\"\n  ip_address_version = \"IPV4\"\n  addresses          = [\"1.2.3.4/32\", \"5.6.7.8/32\"]\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A friendly name of the IP set.\n* `description` - (Optional) A friendly description of the IP set.\n* `scope` - (Required) Specifies whether this is for an AWS CloudFront distribution or for a regional application. Valid values are `CLOUDFRONT` or `REGIONAL`. To work with CloudFront, you must also specify the Region US East (N. Virginia).\n* `ip_address_version` - (Required) Specify IPV4 or IPV6. Valid values are `IPV4` or `IPV6`.\n* `addresses` - (Required) Contains an array of strings that specify one or more IP addresses or blocks of IP addresses in Classless Inter-Domain Routing (CIDR) notation. AWS WAF supports all address ranges for IP versions IPv4 and IPv6.\n* `tags` - (Optional) An array of key:value pairs to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A unique identifier for the set.\n* `arn` - The Amazon Resource Name (ARN) that identifies the cluster.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAFv2 IP Sets can be imported using `ID/name/scope`\n\n```\n$ terraform import aws_wafv2_ip_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc/example/REGIONAL\n```\n",
    "basename": "wafv2_ip_set.html"
  },
  "wafv2_regex_pattern_set.html": {
    "subcategory": "WAFv2",
    "layout": "aws",
    "page_title": "AWS: aws_wafv2_regex_pattern_set",
    "description": "Provides an AWS WAFv2 Regex Pattern Set resource.",
    "preview": "# Resource: aws_wafv2_regex_pattern_set\n\nProvides an AWS WAFv2 Regex …",
    "content": "\n\n# Resource: aws_wafv2_regex_pattern_set\n\nProvides an AWS WAFv2 Regex Pattern Set Resource\n\n## Example Usage\n\n```terraform\nresource \"aws_wafv2_regex_pattern_set\" \"example\" {\n  name        = \"example\"\n  description = \"Example regex pattern set\"\n  scope       = \"REGIONAL\"\n\n  regular_expression {\n    regex_string = \"one\"\n  }\n\n  regular_expression {\n    regex_string = \"two\"\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A friendly name of the regular expression pattern set.\n* `description` - (Optional) A friendly description of the regular expression pattern set.\n* `scope` - (Required) Specifies whether this is for an AWS CloudFront distribution or for a regional application. Valid values are `CLOUDFRONT` or `REGIONAL`. To work with CloudFront, you must also specify the region `us-east-1` (N. Virginia) on the AWS provider.\n* `regular_expression` - (Optional) One or more blocks of regular expression patterns that you want AWS WAF to search for, such as `B[a@]dB[o0]t`. See [Regular Expression](#regular-expression) below for details.\n* `tags` - (Optional) An array of key:value pairs to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n### Regular Expression\n\n* `regex_string` - (Required) The string representing the regular expression, see the AWS WAF [documentation](https://docs.aws.amazon.com/waf/latest/developerguide/waf-regex-pattern-set-creating.html) for more information.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - A unique identifier for the set.\n* `arn` - The Amazon Resource Name (ARN) that identifies the cluster.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAFv2 Regex Pattern Sets can be imported using `ID/name/scope` e.g.,\n\n```\n$ terraform import aws_wafv2_regex_pattern_set.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc/example/REGIONAL\n```\n",
    "basename": "wafv2_regex_pattern_set.html"
  },
  "wafv2_rule_group.html": {
    "subcategory": "WAFv2",
    "layout": "aws",
    "page_title": "AWS: aws_wafv2_rule_group",
    "description": "Creates a WAFv2 rule group resource.",
    "preview": "# Resource: aws_wafv2_rule_group\n\nCreates a WAFv2 Rule Group …",
    "content": "\n\n# Resource: aws_wafv2_rule_group\n\nCreates a WAFv2 Rule Group resource.\n\n## Example Usage\n\n### Simple\n\n```terraform\nresource \"aws_wafv2_rule_group\" \"example\" {\n  name     = \"example-rule\"\n  scope    = \"REGIONAL\"\n  capacity = 2\n\n  rule {\n    name     = \"rule-1\"\n    priority = 1\n\n    action {\n      allow {}\n    }\n\n    statement {\n\n      geo_match_statement {\n        country_codes = [\"US\", \"NL\"]\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n}\n```\n\n### Complex\n\n```terraform\nresource \"aws_wafv2_ip_set\" \"test\" {\n  name               = \"test\"\n  scope              = \"REGIONAL\"\n  ip_address_version = \"IPV4\"\n  addresses          = [\"1.1.1.1/32\", \"2.2.2.2/32\"]\n}\n\nresource \"aws_wafv2_regex_pattern_set\" \"test\" {\n  name  = \"test\"\n  scope = \"REGIONAL\"\n\n  regular_expression {\n    regex_string = \"one\"\n  }\n}\n\nresource \"aws_wafv2_rule_group\" \"example\" {\n  name        = \"complex-example\"\n  description = \"An rule group containing all statements\"\n  scope       = \"REGIONAL\"\n  capacity    = 500\n\n  rule {\n    name     = \"rule-1\"\n    priority = 1\n\n    action {\n      block {}\n    }\n\n    statement {\n\n      not_statement {\n        statement {\n\n          and_statement {\n            statement {\n\n              geo_match_statement {\n                country_codes = [\"US\"]\n              }\n            }\n\n            statement {\n\n              byte_match_statement {\n                positional_constraint = \"CONTAINS\"\n                search_string         = \"word\"\n\n                field_to_match {\n                  all_query_arguments {}\n                }\n\n                text_transformation {\n                  priority = 5\n                  type     = \"CMD_LINE\"\n                }\n\n                text_transformation {\n                  priority = 2\n                  type     = \"LOWERCASE\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"rule-1\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  rule {\n    name     = \"rule-2\"\n    priority = 2\n\n    action {\n      count {}\n    }\n\n    statement {\n\n      or_statement {\n        statement {\n\n          sqli_match_statement {\n\n            field_to_match {\n              body {}\n            }\n\n            text_transformation {\n              priority = 5\n              type     = \"URL_DECODE\"\n            }\n\n            text_transformation {\n              priority = 4\n              type     = \"HTML_ENTITY_DECODE\"\n            }\n\n            text_transformation {\n              priority = 3\n              type     = \"COMPRESS_WHITE_SPACE\"\n            }\n          }\n        }\n\n        statement {\n\n          xss_match_statement {\n\n            field_to_match {\n              method {}\n            }\n\n            text_transformation {\n              priority = 2\n              type     = \"NONE\"\n            }\n          }\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"rule-2\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  rule {\n    name     = \"rule-3\"\n    priority = 3\n\n    action {\n      block {}\n    }\n\n    statement {\n\n      size_constraint_statement {\n        comparison_operator = \"GT\"\n        size                = 100\n\n        field_to_match {\n          single_query_argument {\n            name = \"username\"\n          }\n        }\n\n        text_transformation {\n          priority = 5\n          type     = \"NONE\"\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"rule-3\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  rule {\n    name     = \"rule-4\"\n    priority = 4\n\n    action {\n      block {}\n    }\n\n    statement {\n\n      or_statement {\n        statement {\n\n          ip_set_reference_statement {\n            arn = aws_wafv2_ip_set.test.arn\n          }\n        }\n\n        statement {\n\n          regex_pattern_set_reference_statement {\n            arn = aws_wafv2_regex_pattern_set.test.arn\n\n            field_to_match {\n              single_header {\n                name = \"referer\"\n              }\n            }\n\n            text_transformation {\n              priority = 2\n              type     = \"NONE\"\n            }\n          }\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"rule-4\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n\n  tags = {\n    Name = \"example-and-statement\"\n    Code = \"123456\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `capacity` - (Required, Forces new resource) The web ACL capacity units (WCUs) required for this rule group. See [here](https://docs.aws.amazon.com/waf/latest/APIReference/API_CreateRuleGroup.html#API_CreateRuleGroup_RequestSyntax) for general information and [here](https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statements-list.html) for capacity specific information.\n* `custom_response_body` - (Optional) Defines custom response bodies that can be referenced by `custom_response` actions. See [Custom Response Body](#custom-response-body) below for details.\n* `description` - (Optional) A friendly description of the rule group.\n* `name` - (Required, Forces new resource) A friendly name of the rule group.\n* `rule` - (Optional) The rule blocks used to identify the web requests that you want to `allow`, `block`, or `count`. See [Rules](#rules) below for details.\n* `scope` - (Required, Forces new resource) Specifies whether this is for an AWS CloudFront distribution or for a regional application. Valid values are `CLOUDFRONT` or `REGIONAL`. To work with CloudFront, you must also specify the region `us-east-1` (N. Virginia) on the AWS provider.\n* `tags` - (Optional) An array of key:value pairs to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `visibility_config` - (Required) Defines and enables Amazon CloudWatch metrics and web request sample collection. See [Visibility Configuration](#visibility-configuration) below for details.\n\n### Custom Response Body\n\nEach `custom_response_body` block supports the following arguments:\n\n* `key` - (Required) A unique key identifying the custom response body. This is referenced by the `custom_response_body_key` argument in the [Custom Response](#custom-response) block.\n* `content` - (Required) The payload of the custom response.\n* `content_type` - (Required) The type of content in the payload that you are defining in the `content` argument. Valid values are `TEXT_PLAIN`, `TEXT_HTML`, or `APPLICATION_JSON`.\n\n### Rules\n\nEach `rule` supports the following arguments:\n\n* `action` - (Required) The action that AWS WAF should take on a web request when it matches the rule's statement. Settings at the `aws_wafv2_web_acl` level can override the rule action setting. See [Action](#action) below for details.\n* `name` - (Required, Forces new resource) A friendly name of the rule.\n* `priority` - (Required) If you define more than one Rule in a WebACL, AWS WAF evaluates each request against the `rules` in order based on the value of `priority`. AWS WAF processes rules with lower priority first.\n* `rule_label` - (Optional) Labels to apply to web requests that match the rule match statement. See [Rule Label](#rule-label) below for details.\n* `statement` - (Required) The AWS WAF processing statement for the rule, for example `byte_match_statement` or `geo_match_statement`. See [Statement](#statement) below for details.\n* `visibility_config` - (Required) Defines and enables Amazon CloudWatch metrics and web request sample collection. See [Visibility Configuration](#visibility-configuration) below for details.\n\n### Action\n\nThe `action` block supports the following arguments:\n\n~> **NOTE:** One of `allow`, `block`, or `count`, is required when specifying an `action`.\n\n* `allow` - (Optional) Instructs AWS WAF to allow the web request. See [Allow](#action) below for details.\n* `block` - (Optional) Instructs AWS WAF to block the web request. See [Block](#block) below for details.\n* `count` - (Optional) Instructs AWS WAF to count the web request and allow it. See [Count](#count) below for details.\n\n### Allow\n\nThe `allow` block supports the following arguments:\n\n* `custom_request_handling` - (Optional) Defines custom handling for the web request. See [Custom Request Handling](#custom-request-handling) below for details.\n\n### Block\n\nThe `block` block supports the following arguments:\n\n* `custom_response` - (Optional) Defines a custom response for the web request. See [Custom Response](#custom-response) below for details.\n\n### Count\n\nThe `count` block supports the following arguments:\n\n* `custom_request_handling` - (Optional) Defines custom handling for the web request. See [Custom Request Handling](#custom-request-handling) below for details.\n\n### Custom Request Handling\n\nThe `custom_request_handling` block supports the following arguments:\n\n* `insert_header` - (Required) The `insert_header` blocks used to define HTTP headers added to the request. See [Custom HTTP Header](#custom-http-header) below for details.\n\n### Custom Response\n\nThe `custom_response` block supports the following arguments:\n\n* `custom_response_body_key` - (Optional) References the response body that you want AWS WAF to return to the web request client. This must reference a `key` defined in a `custom_response_body` block of this resource.\n* `response_code` - (Required) The HTTP status code to return to the client.\n* `response_header` - (Optional) The `response_header` blocks used to define the HTTP response headers added to the response. See [Custom HTTP Header](#custom-http-header) below for details.\n\n### Custom HTTP Header\n\nEach block supports the following arguments. Duplicate header names are not allowed:\n\n* `name` - The name of the custom header. For custom request header insertion, when AWS WAF inserts the header into the request, it prefixes this name `x-amzn-waf-`, to avoid confusion with the headers that are already in the request. For example, for the header name `sample`, AWS WAF inserts the header `x-amzn-waf-sample`.\n* `value` - The value of the custom header.\n\n### Rule Label\n\nEach block supports the following arguments:\n\n* `name` - The label string.\n\n### Statement\n\nThe processing guidance for a Rule, used by AWS WAF to determine whether a web request matches the rule. See the [documentation](https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statements-list.html) for more information.\n\n-> **NOTE:** Although the `statement` block is recursive, currently only 3 levels are supported.\n\nThe `statement` block supports the following arguments:\n\n* `and_statement` - (Optional) A logical rule statement used to combine other rule statements with AND logic. See [AND Statement](#and-statement) below for details.\n* `byte_match_statement` - (Optional) A rule statement that defines a string match search for AWS WAF to apply to web requests. See [Byte Match Statement](#byte-match-statement) below for details.\n* `geo_match_statement` - (Optional) A rule statement used to identify web requests based on country of origin. See [GEO Match Statement](#geo-match-statement) below for details.\n* `label_match_statement` - (Optional) A rule statement that defines a string match search against labels that have been added to the web request by rules that have already run in the web ACL. See [Label Match Statement](#label-match-statement) below for details.\n* `ip_set_reference_statement` - (Optional) A rule statement used to detect web requests coming from particular IP addresses or address ranges. See [IP Set Reference Statement](#ip-set-reference-statement) below for details.\n* `not_statement` - (Optional) A logical rule statement used to negate the results of another rule statement. See [NOT Statement](#not-statement) below for details.\n* `or_statement` - (Optional) A logical rule statement used to combine other rule statements with OR logic. See [OR Statement](#or-statement) below for details.\n* `regex_pattern_set_reference_statement` - (Optional) A rule statement used to search web request components for matches with regular expressions. See [Regex Pattern Set Reference Statement](#regex-pattern-set-reference-statement) below for details.\n* `size_constraint_statement` - (Optional) A rule statement that compares a number of bytes against the size of a request component, using a comparison operator, such as greater than (>) or less than (<). See [Size Constraint Statement](#size-constraint-statement) below for more details.\n* `sqli_match_statement` - (Optional) An SQL injection match condition identifies the part of web requests, such as the URI or the query string, that you want AWS WAF to inspect. See [SQL Injection Match Statement](#sql-injection-match-statement) below for details.\n* `xss_match_statement` - (Optional) A rule statement that defines a cross-site scripting (XSS) match search for AWS WAF to apply to web requests. See [XSS Match Statement](#xss-match-statement) below for details.\n\n### AND Statement\n\nA logical rule statement used to combine other rule statements with `AND` logic. You provide more than one `statement` within the `and_statement`.\n\nThe `and_statement` block supports the following arguments:\n\n* `statement` - (Required) The statements to combine with `AND` logic. You can use any statements that can be nested. See [Statement](#statement) above for details.\n\n### Byte Match Statement\n\nThe byte match statement provides the bytes to search for, the location in requests that you want AWS WAF to search, and other settings. The bytes to search for are typically a string that corresponds with ASCII characters.\n\nThe `byte_match_statement` block supports the following arguments:\n\n* `field_to_match` - (Required) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `positional_constraint` - (Required) The area within the portion of a web request that you want AWS WAF to search for `search_string`. Valid values include the following: `EXACTLY`, `STARTS_WITH`, `ENDS_WITH`, `CONTAINS`, `CONTAINS_WORD`. See the AWS [documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_ByteMatchStatement.html) for more information.\n* `search_string` - (Required) A string value that you want AWS WAF to search for. AWS WAF searches only in the part of web requests that you designate for inspection in `field_to_match`. The maximum length of the value is 50 bytes.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### GEO Match Statement\n\nThe `geo_match_statement` block supports the following arguments:\n\n* `country_codes` - (Required) An array of two-character country codes, for example, [ \"US\", \"CN\" ], from the alpha-2 country ISO codes of the `ISO 3166` international standard. See the [documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_GeoMatchStatement.html) for valid values.\n* `forwarded_ip_config` - (Optional) The configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. See [Forwarded IP Config](#forwarded-ip-config) below for details.\n\n### Label Match Statement\n\nThe `label_match_statement` block supports the following arguments:\n\n* `scope` - (Required) Specify whether you want to match using the label name or just the namespace. Valid values are `LABEL` or `NAMESPACE`.\n* `key` - (Required) The string to match against.\n\n### IP Set Reference Statement\n\nA rule statement used to detect web requests coming from particular IP addresses or address ranges. To use this, create an `aws_wafv2_ip_set` that specifies the addresses you want to detect, then use the `ARN` of that set in this statement.\n\nThe `ip_set_reference_statement` block supports the following arguments:\n\n* `arn` - (Required) The Amazon Resource Name (ARN) of the IP Set that this statement references.\n* `ip_set_forwarded_ip_config` - (Optional) The configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. See [IPSet Forwarded IP Config](#ipset-forwarded-ip-config) below for more details.\n\n### NOT Statement\n\nA logical rule statement used to negate the results of another rule statement. You provide one `statement` within the `not_statement`.\n\nThe `not_statement` block supports the following arguments:\n\n* `statement` - (Required) The statement to negate. You can use any statement that can be nested. See [Statement](#statement) above for details.\n\n### OR Statement\n\nA logical rule statement used to combine other rule statements with `OR` logic. You provide more than one `statement` within the `or_statement`.\n\nThe `or_statement` block supports the following arguments:\n\n* `statement` - (Required) The statements to combine with `OR` logic. You can use any statements that can be nested. See [Statement](#statement) above for details.\n\n### Regex Pattern Set Reference Statement\n\nA rule statement used to search web request components for matches with regular expressions. To use this, create a `aws_wafv2_regex_pattern_set` that specifies the expressions that you want to detect, then use the `ARN` of that set in this statement. A web request matches the pattern set rule statement if the request component matches any of the patterns in the set.\n\nThe `regex_pattern_set_reference_statement` block supports the following arguments:\n\n* `arn` - (Required) The Amazon Resource Name (ARN) of the Regex Pattern Set that this statement references.\n* `field_to_match` - (Required) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### Size Constraint Statement\n\nA rule statement that uses a comparison operator to compare a number of bytes against the size of a request component. AWS WAFv2 inspects up to the first 8192 bytes (8 KB) of a request body, and when inspecting the request URI Path, the slash `/` in\nthe URI counts as one character.\n\nThe `size_constraint_statement` block supports the following arguments:\n\n* `comparison_operator` - (Required) The operator to use to compare the request part to the size setting. Valid values include: `EQ`, `NE`, `LE`, `LT`, `GE`, or `GT`.\n* `field_to_match` - (Optional) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `size` - (Required) The size, in bytes, to compare to the request part, after any transformations. Valid values are integers between 0 and 21474836480, inclusive.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### SQL Injection Match Statement\n\nAn SQL injection match condition identifies the part of web requests, such as the URI or the query string, that you want AWS WAF to inspect. Later in the process, when you create a web ACL, you specify whether to allow or block requests that appear to contain malicious SQL code.\n\nThe `sqli_match_statement` block supports the following arguments:\n\n* `field_to_match` - (Required) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### XSS Match Statement\n\nThe XSS match statement provides the location in requests that you want AWS WAF to search and text transformations to use on the search area before AWS WAF searches for character sequences that are likely to be malicious strings.\n\nThe `xss_match_statement` block supports the following arguments:\n\n* `field_to_match` - (Required) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### Field to Match\n\nThe part of a web request that you want AWS WAF to inspect. Include the single `field_to_match` type that you want to inspect, with additional specifications as needed, according to the type. You specify a single request component in `field_to_match` for each rule statement that requires it. To inspect more than one component of a web request, create a separate rule statement for each component. See the [documentation](https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-fields.html#waf-rule-statement-request-component) for more details.\n\nThe `field_to_match` block supports the following arguments:\n\n~> **NOTE:** Only one of `all_query_arguments`, `body`, `method`, `query_string`, `single_header`, `single_query_argument`, or `uri_path` can be specified.\nAn empty configuration block `{}` should be used when specifying `all_query_arguments`, `body`, `method`, or `query_string` attributes.\n\n* `all_query_arguments` - (Optional) Inspect all query arguments.\n* `body` - (Optional) Inspect the request body, which immediately follows the request headers.\n* `method` - (Optional) Inspect the HTTP method. The method indicates the type of operation that the request is asking the origin to perform.\n* `query_string` - (Optional) Inspect the query string. This is the part of a URL that appears after a `?` character, if any.\n* `single_header` - (Optional) Inspect a single header. See [Single Header](#single-header) below for details.\n* `single_query_argument` - (Optional) Inspect a single query argument. See [Single Query Argument](#single-query-argument) below for details.\n* `uri_path` - (Optional) Inspect the request URI path. This is the part of a web request that identifies a resource, for example, `/images/daily-ad.jpg`.\n\n### Forwarded IP Config\n\nThe configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. Commonly, this is the X-Forwarded-For (XFF) header, but you can specify\nany header name. If the specified header isn't present in the request, AWS WAFv2 doesn't apply the rule to the web request at all.\nAWS WAFv2 only evaluates the first IP address found in the specified HTTP header.\n\nThe `forwarded_ip_config` block supports the following arguments:\n\n* `fallback_behavior` - (Required) - The match status to assign to the web request if the request doesn't have a valid IP address in the specified position. Valid values include: `MATCH` or `NO_MATCH`.\n* `header_name` - (Required) - The name of the HTTP header to use for the IP address.\n\n### IPSet Forwarded IP Config\n\nThe configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. Commonly, this is the X-Forwarded-For (XFF) header, but you can specify any header name.\n\nThe `ip_set_forwarded_ip_config` block supports the following arguments:\n\n* `fallback_behavior` - (Required) - The match status to assign to the web request if the request doesn't have a valid IP address in the specified position. Valid values include: `MATCH` or `NO_MATCH`.\n* `header_name` - (Required) - The name of the HTTP header to use for the IP address.\n* `position` - (Required) - The position in the header to search for the IP address. Valid values include: `FIRST`, `LAST`, or `ANY`. If `ANY` is specified and the header contains more than 10 IP addresses, AWS WAFv2 inspects the last 10.\n\n### Single Header\n\nInspect a single header. Provide the name of the header to inspect, for example, `User-Agent` or `Referer` (provided as lowercase strings).\n\nThe `single_header` block supports the following arguments:\n\n* `name` - (Optional) The name of the query header to inspect. This setting must be provided as lower case characters.\n\n### Single Query Argument\n\nInspect a single query argument. Provide the name of the query argument to inspect, such as `UserName` or `SalesRegion` (provided as lowercase strings).\n\nThe `single_query_argument` block supports the following arguments:\n\n* `name` - (Optional) The name of the query header to inspect. This setting must be provided as lower case characters.\n\n### Text Transformation\n\nThe `text_transformation` block supports the following arguments:\n\n* `priority` - (Required) The relative processing order for multiple transformations that are defined for a rule statement. AWS WAF processes all transformations, from lowest priority to highest, before inspecting the transformed content.\n* `type` - (Required) The transformation to apply, please refer to the Text Transformation [documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_TextTransformation.html) for more details.\n\n### Visibility Configuration\n\nThe `visibility_config` block supports the following arguments:\n\n* `cloudwatch_metrics_enabled` - (Required) A boolean indicating whether the associated resource sends metrics to CloudWatch. For the list of available metrics, see [AWS WAF Metrics](https://docs.aws.amazon.com/waf/latest/developerguide/monitoring-cloudwatch.html#waf-metrics).\n* `metric_name` - (Required, Forces new resource) A friendly name of the CloudWatch metric. The name can contain only alphanumeric characters (A-Z, a-z, 0-9) hyphen(-) and underscore (_), with length from one to 128 characters. It can't contain whitespace or metric names reserved for AWS WAF, for example `All` and `Default_Action`.\n* `sampled_requests_enabled` - (Required) A boolean indicating whether AWS WAF should store a sampling of the web requests that match the rules. You can view the sampled requests through the AWS WAF console.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ID of the WAF rule group.\n* `arn` - The ARN of the WAF rule group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAFv2 Rule Group can be imported using `ID/name/scope` e.g.,\n\n```\n$ terraform import aws_wafv2_rule_group.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc/example/REGIONAL\n```\n",
    "basename": "wafv2_rule_group.html"
  },
  "wafv2_web_acl.html": {
    "subcategory": "WAFv2",
    "layout": "aws",
    "page_title": "AWS: aws_wafv2_web_acl",
    "description": "Creates a WAFv2 Web ACL resource.",
    "preview": "# Resource: aws_wafv2_web_acl\n\nCreates a WAFv2 Web ACL resource.\n\n## …",
    "content": "\n\n# Resource: aws_wafv2_web_acl\n\nCreates a WAFv2 Web ACL resource.\n\n## Example Usage\n\nThis resource is based on `aws_wafv2_rule_group`, check the documentation of the `aws_wafv2_rule_group` resource to see examples of the various available statements.\n\n\n### Managed Rule\n\n```terraform\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"managed-rule-example\"\n  description = \"Example of a managed rule.\"\n  scope       = \"REGIONAL\"\n\n  default_action {\n    allow {}\n  }\n\n  rule {\n    name     = \"rule-1\"\n    priority = 1\n\n    override_action {\n      count {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesCommonRuleSet\"\n        vendor_name = \"AWS\"\n\n        excluded_rule {\n          name = \"SizeRestrictions_QUERYSTRING\"\n        }\n\n        excluded_rule {\n          name = \"NoUserAgent_HEADER\"\n        }\n\n        scope_down_statement {\n          geo_match_statement {\n            country_codes = [\"US\", \"NL\"]\n          }\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n}\n```\n\n### Rate Based\nRate-limit US and NL-based clients to 10,000 requests for every 5 minutes.\n\n```terraform\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"rate-based-example\"\n  description = \"Example of a Cloudfront rate based statement.\"\n  scope       = \"CLOUDFRONT\"\n\n  default_action {\n    allow {}\n  }\n\n  rule {\n    name     = \"rule-1\"\n    priority = 1\n\n    action {\n      block {}\n    }\n\n    statement {\n      rate_based_statement {\n        limit              = 10000\n        aggregate_key_type = \"IP\"\n\n        scope_down_statement {\n          geo_match_statement {\n            country_codes = [\"US\", \"NL\"]\n          }\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n}\n```\n\n### Rule Group Reference\n\n```terraform\nresource \"aws_wafv2_rule_group\" \"example\" {\n  capacity = 10\n  name     = \"example-rule-group\"\n  scope    = \"REGIONAL\"\n\n  rule {\n    name     = \"rule-1\"\n    priority = 1\n\n    action {\n      count {}\n    }\n\n    statement {\n      geo_match_statement {\n        country_codes = [\"NL\"]\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  rule {\n    name     = \"rule-to-exclude-a\"\n    priority = 10\n\n    action {\n      allow {}\n    }\n\n    statement {\n      geo_match_statement {\n        country_codes = [\"US\"]\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  rule {\n    name     = \"rule-to-exclude-b\"\n    priority = 15\n\n    action {\n      allow {}\n    }\n\n    statement {\n      geo_match_statement {\n        country_codes = [\"GB\"]\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n}\n\nresource \"aws_wafv2_web_acl\" \"test\" {\n  name  = \"rule-group-example\"\n  scope = \"REGIONAL\"\n\n  default_action {\n    block {}\n  }\n\n  rule {\n    name     = \"rule-1\"\n    priority = 1\n\n    override_action {\n      count {}\n    }\n\n    statement {\n      rule_group_reference_statement {\n        arn = aws_wafv2_rule_group.example.arn\n\n        excluded_rule {\n          name = \"rule-to-exclude-b\"\n        }\n\n        excluded_rule {\n          name = \"rule-to-exclude-a\"\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n  tags = {\n    Tag1 = \"Value1\"\n    Tag2 = \"Value2\"\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `custom_response_body` - (Optional) Defines custom response bodies that can be referenced by `custom_response` actions. See [Custom Response Body](#custom-response-body) below for details.\n* `default_action` - (Required) The action to perform if none of the `rules` contained in the WebACL match. See [Default Action](#default-action) below for details.\n* `description` - (Optional) A friendly description of the WebACL.\n* `name` - (Required) A friendly name of the WebACL.\n* `rule` - (Optional) The rule blocks used to identify the web requests that you want to `allow`, `block`, or `count`. See [Rules](#rules) below for details.\n* `scope` - (Required) Specifies whether this is for an AWS CloudFront distribution or for a regional application. Valid values are `CLOUDFRONT` or `REGIONAL`. To work with CloudFront, you must also specify the region `us-east-1` (N. Virginia) on the AWS provider.\n* `tags` - (Optional) An map of key:value pairs to associate with the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `visibility_config` - (Required) Defines and enables Amazon CloudWatch metrics and web request sample collection. See [Visibility Configuration](#visibility-configuration) below for details.\n\n### Custom Response Body\n\nEach `custom_response_body` block supports the following arguments:\n\n* `key` - (Required) A unique key identifying the custom response body. This is referenced by the `custom_response_body_key` argument in the [Custom Response](#custom-response) block.\n* `content` - (Required) The payload of the custom response.\n* `content_type` - (Required) The type of content in the payload that you are defining in the `content` argument. Valid values are `TEXT_PLAIN`, `TEXT_HTML`, or `APPLICATION_JSON`.\n\n### Default Action\n\nThe `default_action` block supports the following arguments:\n\n~> **NOTE:** One of `allow` or `block`, expressed as an empty configuration block `{}`, is required when specifying a `default_action`\n\n* `allow` - (Optional) Specifies that AWS WAF should allow requests by default. See [Allow](#action) below for details.\n* `block` - (Optional) Specifies that AWS WAF should block requests by default. See [Block](#block) below for details.\n\n### Rules\n\n~> **NOTE:** One of `action` or `override_action` is required when specifying a rule\n\nEach `rule` supports the following arguments:\n\n* `action` - (Optional) The action that AWS WAF should take on a web request when it matches the rule's statement. This is used only for rules whose **statements do not reference a rule group**. See [Action](#action) below for details.\n* `name` - (Required) A friendly name of the rule.\n* `override_action` - (Optional) The override action to apply to the rules in a rule group. Used only for rule **statements that reference a rule group**, like `rule_group_reference_statement` and `managed_rule_group_statement`. See [Override Action](#override-action) below for details.\n* `priority` - (Required) If you define more than one Rule in a WebACL, AWS WAF evaluates each request against the `rules` in order based on the value of `priority`. AWS WAF processes rules with lower priority first.\n* `rule_label` - (Optional) Labels to apply to web requests that match the rule match statement. See [Rule Label](#rule-label) below for details.\n* `statement` - (Required) The AWS WAF processing statement for the rule, for example `byte_match_statement` or `geo_match_statement`. See [Statement](#statement) below for details.\n* `visibility_config` - (Required) Defines and enables Amazon CloudWatch metrics and web request sample collection. See [Visibility Configuration](#visibility-configuration) below for details.\n\n### Action\n\nThe `action` block supports the following arguments:\n\n~> **NOTE:** One of `allow`, `block`, or `count`, is required when specifying an `action`.\n\n* `allow` - (Optional) Instructs AWS WAF to allow the web request. See [Allow](#action) below for details.\n* `block` - (Optional) Instructs AWS WAF to block the web request. See [Block](#block) below for details.\n* `count` - (Optional) Instructs AWS WAF to count the web request and allow it. See [Count](#count) below for details.\n\n### Override Action\n\nThe `override_action` block supports the following arguments:\n\n~> **NOTE:** One of `count` or `none`, expressed as an empty configuration block `{}`, is required when specifying an `override_action`\n\n* `count` - (Optional) Override the rule action setting to count (i.e., only count matches). Configured as an empty block `{}`.\n* `none` - (Optional) Don't override the rule action setting. Configured as an empty block `{}`.\n\n### Allow\n\nThe `allow` block supports the following arguments:\n\n* `custom_request_handling` - (Optional) Defines custom handling for the web request. See [Custom Request Handling](#custom-request-handling) below for details.\n\n### Block\n\nThe `block` block supports the following arguments:\n\n* `custom_response` - (Optional) Defines a custom response for the web request. See [Custom Response](#custom-response) below for details.\n\n### Count\n\nThe `count` block supports the following arguments:\n\n* `custom_request_handling` - (Optional) Defines custom handling for the web request. See [Custom Request Handling](#custom-request-handling) below for details.\n\n### Custom Request Handling\n\nThe `custom_request_handling` block supports the following arguments:\n\n* `insert_header` - (Required) The `insert_header` blocks used to define HTTP headers added to the request. See [Custom HTTP Header](#custom-http-header) below for details.\n\n### Custom Response\n\nThe `custom_response` block supports the following arguments:\n\n* `custom_response_body_key` - (Optional) References the response body that you want AWS WAF to return to the web request client. This must reference a `key` defined in a `custom_response_body` block of this resource.\n* `response_code` - (Required) The HTTP status code to return to the client.\n* `response_header` - (Optional) The `response_header` blocks used to define the HTTP response headers added to the response. See [Custom HTTP Header](#custom-http-header) below for details.\n\n### Custom HTTP Header\n\nEach block supports the following arguments. Duplicate header names are not allowed:\n\n* `name` - The name of the custom header. For custom request header insertion, when AWS WAF inserts the header into the request, it prefixes this name `x-amzn-waf-`, to avoid confusion with the headers that are already in the request. For example, for the header name `sample`, AWS WAF inserts the header `x-amzn-waf-sample`.\n* `value` - The value of the custom header.\n\n### Rule Label\n\nEach block supports the following arguments:\n\n* `name` - The label string.\n\n### Statement\n\nThe processing guidance for a Rule, used by AWS WAF to determine whether a web request matches the rule. See the [documentation](https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statements-list.html) for more information.\n\n-> **NOTE:** Although the `statement` block is recursive, currently only 3 levels are supported.\n\nThe `statement` block supports the following arguments:\n\n* `and_statement` - (Optional) A logical rule statement used to combine other rule statements with AND logic. See [AND Statement](#and-statement) below for details.\n* `byte_match_statement` - (Optional) A rule statement that defines a string match search for AWS WAF to apply to web requests. See [Byte Match Statement](#byte-match-statement) below for details.\n* `geo_match_statement` - (Optional) A rule statement used to identify web requests based on country of origin. See [GEO Match Statement](#geo-match-statement) below for details.\n* `ip_set_reference_statement` - (Optional) A rule statement used to detect web requests coming from particular IP addresses or address ranges. See [IP Set Reference Statement](#ip-set-reference-statement) below for details.\n* `label_match_statement` - (Optional) A rule statement that defines a string match search against labels that have been added to the web request by rules that have already run in the web ACL. See [Label Match Statement](#label-match-statement) below for details.  \n* `managed_rule_group_statement` - (Optional) A rule statement used to run the rules that are defined in a managed rule group.  This statement can not be nested. See [Managed Rule Group Statement](#managed-rule-group-statement) below for details.\n* `not_statement` - (Optional) A logical rule statement used to negate the results of another rule statement. See [NOT Statement](#not-statement) below for details.\n* `or_statement` - (Optional) A logical rule statement used to combine other rule statements with OR logic. See [OR Statement](#or-statement) below for details.\n* `rate_based_statement` - (Optional) A rate-based rule tracks the rate of requests for each originating `IP address`, and triggers the rule action when the rate exceeds a limit that you specify on the number of requests in any `5-minute` time span. This statement can not be nested. See [Rate Based Statement](#rate-based-statement) below for details.\n* `regex_pattern_set_reference_statement` - (Optional) A rule statement used to search web request components for matches with regular expressions. See [Regex Pattern Set Reference Statement](#regex-pattern-set-reference-statement) below for details.\n* `rule_group_reference_statement` - (Optional) A rule statement used to run the rules that are defined in an WAFv2 Rule Group. See [Rule Group Reference Statement](#rule-group-reference-statement) below for details.\n* `size_constraint_statement` - (Optional) A rule statement that compares a number of bytes against the size of a request component, using a comparison operator, such as greater than (>) or less than (<). See [Size Constraint Statement](#size-constraint-statement) below for more details.\n* `sqli_match_statement` - (Optional) An SQL injection match condition identifies the part of web requests, such as the URI or the query string, that you want AWS WAF to inspect. See [SQL Injection Match Statement](#sql-injection-match-statement) below for details.\n* `xss_match_statement` - (Optional) A rule statement that defines a cross-site scripting (XSS) match search for AWS WAF to apply to web requests. See [XSS Match Statement](#xss-match-statement) below for details.\n\n### AND Statement\n\nA logical rule statement used to combine other rule statements with `AND` logic. You provide more than one `statement` within the `and_statement`.\n\nThe `and_statement` block supports the following arguments:\n\n* `statement` - (Required) The statements to combine with `AND` logic. You can use any statements that can be nested. See [Statement](#statement) above for details.\n\n### Byte Match Statement\n\nThe byte match statement provides the bytes to search for, the location in requests that you want AWS WAF to search, and other settings. The bytes to search for are typically a string that corresponds with ASCII characters.\n\nThe `byte_match_statement` block supports the following arguments:\n\n* `field_to_match` - (Optional) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `positional_constraint` - (Required) The area within the portion of a web request that you want AWS WAF to search for `search_string`. Valid values include the following: `EXACTLY`, `STARTS_WITH`, `ENDS_WITH`, `CONTAINS`, `CONTAINS_WORD`. See the AWS [documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_ByteMatchStatement.html) for more information.\n* `search_string` - (Required) A string value that you want AWS WAF to search for. AWS WAF searches only in the part of web requests that you designate for inspection in `field_to_match`. The maximum length of the value is 50 bytes.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n\n### GEO Match Statement\n\nThe `geo_match_statement` block supports the following arguments:\n\n* `country_codes` - (Required) An array of two-character country codes, for example, [ \"US\", \"CN\" ], from the alpha-2 country ISO codes of the `ISO 3166` international standard. See the [documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_GeoMatchStatement.html) for valid values.\n* `forwarded_ip_config` - (Optional) The configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. See [Forwarded IP Config](#forwarded-ip-config) below for details.\n\n### IP Set Reference Statement\n\nA rule statement used to detect web requests coming from particular IP addresses or address ranges. To use this, create an `aws_wafv2_ip_set` that specifies the addresses you want to detect, then use the `ARN` of that set in this statement.\n\nThe `ip_set_reference_statement` block supports the following arguments:\n\n* `arn` - (Required) The Amazon Resource Name (ARN) of the IP Set that this statement references.\n* `ip_set_forwarded_ip_config` - (Optional) The configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. See [IPSet Forwarded IP Config](#ipset-forwarded-ip-config) below for more details.\n\n### Label Match Statement\n\nThe `label_match_statement` block supports the following arguments:\n\n* `scope` - (Required) Specify whether you want to match using the label name or just the namespace. Valid values are `LABEL` or `NAMESPACE`.\n* `key` - (Required) The string to match against.\n\n### Managed Rule Group Statement\n\nA rule statement used to run the rules that are defined in a managed rule group.\n\nYou can't nest a `managed_rule_group_statement`, for example for use inside a `not_statement` or `or_statement`. It can only be referenced as a `top-level` statement within a `rule`.\n\nThe `managed_rule_group_statement` block supports the following arguments:\n\n* `excluded_rule` - (Optional) The `rules` whose actions are set to `COUNT` by the web ACL, regardless of the action that is set on the rule. See [Excluded Rule](#excluded-rule) below for details.\n* `name` - (Required) The name of the managed rule group.\n* `scope_down_statement` - Narrows the scope of the statement to matching web requests. This can be any nestable statement, and you can nest statements at any level below this scope-down statement. See [Statement](#statement) above for details.\n* `vendor_name` - (Required) The name of the managed rule group vendor.\n\n### NOT Statement\n\nA logical rule statement used to negate the results of another rule statement. You provide one `statement` within the `not_statement`.\n\nThe `not_statement` block supports the following arguments:\n\n* `statement` - (Required) The statement to negate. You can use any statement that can be nested. See [Statement](#statement) above for details.\n\n### OR Statement\n\nA logical rule statement used to combine other rule statements with `OR` logic. You provide more than one `statement` within the `or_statement`.\n\nThe `or_statement` block supports the following arguments:\n\n* `statement` - (Required) The statements to combine with `OR` logic. You can use any statements that can be nested. See [Statement](#statement) above for details.\n\n### Rate Based Statement\n\nA rate-based rule tracks the rate of requests for each originating IP address, and triggers the rule action when the rate exceeds a limit that you specify on the number of requests in any 5-minute time span. You can use this to put a temporary block on requests from an IP address that is sending excessive requests. See the [documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_RateBasedStatement.html) for more information.\n\nYou can't nest a `rate_based_statement`, for example for use inside a `not_statement` or `or_statement`. It can only be referenced as a `top-level` statement within a `rule`.\n\nThe `rate_based_statement` block supports the following arguments:\n\n* `aggregate_key_type` - (Optional) Setting that indicates how to aggregate the request counts. Valid values include: `FORWARDED_IP` or `IP`. Default: `IP`.\n* `forwarded_ip_config` - (Optional) The configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. If `aggregate_key_type` is set to `FORWARDED_IP`, this block is required. See [Forwarded IP Config](#forwarded-ip-config) below for details.\n* `limit` - (Required) The limit on requests per 5-minute period for a single originating IP address.\n* `scope_down_statement` - (Optional) An optional nested statement that narrows the scope of the rate-based statement to matching web requests. This can be any nestable statement, and you can nest statements at any level below this scope-down statement. See [Statement](#statement) above for details.\n\n### Regex Pattern Set Reference Statement\n\nA rule statement used to search web request components for matches with regular expressions. To use this, create a `aws_wafv2_regex_pattern_set` that specifies the expressions that you want to detect, then use the `ARN` of that set in this statement. A web request matches the pattern set rule statement if the request component matches any of the patterns in the set.\n\nThe `regex_pattern_set_reference_statement` block supports the following arguments:\n\n* `arn` - (Required) The Amazon Resource Name (ARN) of the Regex Pattern Set that this statement references.\n* `field_to_match` - (Optional) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### Rule Group Reference Statement\n\nA rule statement used to run the rules that are defined in an WAFv2 Rule Group or `aws_wafv2_rule_group` resource.\n\nYou can't nest a `rule_group_reference_statement`, for example for use inside a `not_statement` or `or_statement`. It can only be referenced as a `top-level` statement within a `rule`.\n\nThe `rule_group_reference_statement` block supports the following arguments:\n\n* `arn` - (Required) The Amazon Resource Name (ARN) of the `aws_wafv2_rule_group` resource.\n* `excluded_rule` - (Optional) The `rules` whose actions are set to `COUNT` by the web ACL, regardless of the action that is set on the rule. See [Excluded Rule](#excluded-rule) below for details.\n\n### Size Constraint Statement\n\nA rule statement that uses a comparison operator to compare a number of bytes against the size of a request component. AWS WAFv2 inspects up to the first 8192 bytes (8 KB) of a request body, and when inspecting the request URI Path, the slash `/` in\nthe URI counts as one character.\n\nThe `size_constraint_statement` block supports the following arguments:\n\n* `comparison_operator` - (Required) The operator to use to compare the request part to the size setting. Valid values include: `EQ`, `NE`, `LE`, `LT`, `GE`, or `GT`.\n* `field_to_match` - (Optional) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `size` - (Required) The size, in bytes, to compare to the request part, after any transformations. Valid values are integers between 0 and 21474836480, inclusive.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### SQL Injection Match Statement\n\nAn SQL injection match condition identifies the part of web requests, such as the URI or the query string, that you want AWS WAF to inspect. Later in the process, when you create a web ACL, you specify whether to allow or block requests that appear to contain malicious SQL code.\n\nThe `sqli_match_statement` block supports the following arguments:\n\n* `field_to_match` - (Optional) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### XSS Match Statement\n\nThe XSS match statement provides the location in requests that you want AWS WAF to search and text transformations to use on the search area before AWS WAF searches for character sequences that are likely to be malicious strings.\n\nThe `xss_match_statement` block supports the following arguments:\n\n* `field_to_match` - (Optional) The part of a web request that you want AWS WAF to inspect. See [Field to Match](#field-to-match) below for details.\n* `text_transformation` - (Required) Text transformations eliminate some of the unusual formatting that attackers use in web requests in an effort to bypass detection. See [Text Transformation](#text-transformation) below for details.\n\n### Excluded Rule\n\nThe `excluded_rule` block supports the following arguments:\n\n* `name` - (Required) The name of the rule to exclude. If the rule group is managed by AWS, see the [documentation](https://docs.aws.amazon.com/waf/latest/developerguide/aws-managed-rule-groups-list.html) for a list of names in the appropriate rule group in use.\n\n### Field to Match\n\nThe part of a web request that you want AWS WAF to inspect. Include the single `field_to_match` type that you want to inspect, with additional specifications as needed, according to the type. You specify a single request component in `field_to_match` for each rule statement that requires it. To inspect more than one component of a web request, create a separate rule statement for each component. See the [documentation](https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-fields.html#waf-rule-statement-request-component) for more details.\n\nThe `field_to_match` block supports the following arguments:\n\n~> **NOTE:** Only one of `all_query_arguments`, `body`, `method`, `query_string`, `single_header`, `single_query_argument`, or `uri_path` can be specified.\nAn empty configuration block `{}` should be used when specifying `all_query_arguments`, `body`, `method`, or `query_string` attributes.\n\n* `all_query_arguments` - (Optional) Inspect all query arguments.\n* `body` - (Optional) Inspect the request body, which immediately follows the request headers.\n* `method` - (Optional) Inspect the HTTP method. The method indicates the type of operation that the request is asking the origin to perform.\n* `query_string` - (Optional) Inspect the query string. This is the part of a URL that appears after a `?` character, if any.\n* `single_header` - (Optional) Inspect a single header. See [Single Header](#single-header) below for details.\n* `single_query_argument` - (Optional) Inspect a single query argument. See [Single Query Argument](#single-query-argument) below for details.\n* `uri_path` - (Optional) Inspect the request URI path. This is the part of a web request that identifies a resource, for example, `/images/daily-ad.jpg`.\n\n### Forwarded IP Config\n\nThe configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. Commonly, this is the X-Forwarded-For (XFF) header, but you can specify\nany header name. If the specified header isn't present in the request, AWS WAFv2 doesn't apply the rule to the web request at all.\nAWS WAFv2 only evaluates the first IP address found in the specified HTTP header.\n\nThe `forwarded_ip_config` block supports the following arguments:\n\n* `fallback_behavior` - (Required) - The match status to assign to the web request if the request doesn't have a valid IP address in the specified position. Valid values include: `MATCH` or `NO_MATCH`.\n* `header_name` - (Required) - The name of the HTTP header to use for the IP address.\n\n### IPSet Forwarded IP Config\n\nThe configuration for inspecting IP addresses in an HTTP header that you specify, instead of using the IP address that's reported by the web request origin. Commonly, this is the X-Forwarded-For (XFF) header, but you can specify any header name.\n\nThe `ip_set_forwarded_ip_config` block supports the following arguments:\n\n* `fallback_behavior` - (Required) - The match status to assign to the web request if the request doesn't have a valid IP address in the specified position. Valid values include: `MATCH` or `NO_MATCH`.\n* `header_name` - (Required) - The name of the HTTP header to use for the IP address.\n* `position` - (Required) - The position in the header to search for the IP address. Valid values include: `FIRST`, `LAST`, or `ANY`. If `ANY` is specified and the header contains more than 10 IP addresses, AWS WAFv2 inspects the last 10.\n\n### Single Header\n\nInspect a single header. Provide the name of the header to inspect, for example, `User-Agent` or `Referer` (provided as lowercase strings).\n\nThe `single_header` block supports the following arguments:\n\n* `name` - (Optional) The name of the query header to inspect. This setting must be provided as lower case characters.\n\n### Single Query Argument\n\nInspect a single query argument. Provide the name of the query argument to inspect, such as `UserName` or `SalesRegion` (provided as lowercase strings).\n\nThe `single_query_argument` block supports the following arguments:\n\n* `name` - (Optional) The name of the query header to inspect. This setting must be provided as lower case characters.\n\n### Text Transformation\n\nThe `text_transformation` block supports the following arguments:\n\n* `priority` - (Required) The relative processing order for multiple transformations that are defined for a rule statement. AWS WAF processes all transformations, from lowest priority to highest, before inspecting the transformed content.\n* `type` - (Required) The transformation to apply, please refer to the Text Transformation [documentation](https://docs.aws.amazon.com/waf/latest/APIReference/API_TextTransformation.html) for more details.\n\n\n### Visibility Configuration\n\nThe `visibility_config` block supports the following arguments:\n\n* `cloudwatch_metrics_enabled` - (Required) A boolean indicating whether the associated resource sends metrics to CloudWatch. For the list of available metrics, see [AWS WAF Metrics](https://docs.aws.amazon.com/waf/latest/developerguide/monitoring-cloudwatch.html#waf-metrics).\n* `metric_name` - (Required) A friendly name of the CloudWatch metric. The name can contain only alphanumeric characters (A-Z, a-z, 0-9) hyphen(-) and underscore (\\_), with length from one to 128 characters. It can't contain whitespace or metric names reserved for AWS WAF, for example `All` and `Default_Action`.\n* `sampled_requests_enabled` - (Required) A boolean indicating whether AWS WAF should store a sampling of the web requests that match the rules. You can view the sampled requests through the AWS WAF console.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `arn` - The ARN of the WAF WebACL.\n* `capacity` - The web ACL capacity units (WCUs) currently being used by this web ACL.\n* `id` - The ID of the WAF WebACL.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWAFv2 Web ACLs can be imported using `ID/Name/Scope` e.g.,\n\n```\n$ terraform import aws_wafv2_web_acl.example a1b2c3d4-d5f6-7777-8888-9999aaaabbbbcccc/example/REGIONAL\n```\n",
    "basename": "wafv2_web_acl.html"
  },
  "wafv2_web_acl_association.html": {
    "subcategory": "WAFv2",
    "layout": "aws",
    "page_title": "AWS: aws_wafv2_web_acl_association",
    "description": "Creates a WAFv2 Web ACL Association.",
    "preview": "# Resource: aws_wafv2_web_acl_association\n\nCreates a WAFv2 Web ACL …",
    "content": "\n\n# Resource: aws_wafv2_web_acl_association\n\nCreates a WAFv2 Web ACL Association.\n\n~> **NOTE on associating a WAFv2 Web ACL with a Cloudfront distribution:** Do not use this resource to associate a WAFv2 Web ACL with a Cloudfront Distribution. The [AWS API call backing this resource][1] notes that you should use the [`web_acl_id`][2] property on the [`cloudfront_distribution`][2] instead.\n\n[1]: https://docs.aws.amazon.com/waf/latest/APIReference/API_AssociateWebACL.html\n[2]: /docs/providers/aws/r/cloudfront_distribution.html#web_acl_id\n\n## Example Usage\n\n```terraform\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = \"example\"\n      version = \"1.0\"\n    }\n    paths = {\n      \"/path1\" = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = \"example\"\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name  = \"web-acl-association-example\"\n  scope = \"REGIONAL\"\n\n  default_action {\n    allow {}\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = false\n    metric_name                = \"friendly-metric-name\"\n    sampled_requests_enabled   = false\n  }\n}\n\nresource \"aws_wafv2_web_acl_association\" \"example\" {\n  resource_arn = aws_api_gateway_stage.example.arn\n  web_acl_arn  = aws_wafv2_web_acl.example.arn\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `resource_arn` - (Required) The Amazon Resource Name (ARN) of the resource to associate with the web ACL. This must be an ARN of an Application Load Balancer or an Amazon API Gateway stage.\n* `web_acl_arn` - (Required) The Amazon Resource Name (ARN) of the Web ACL that you want to associate with the resource.\n\n## Attributes Reference\n\nNo additional attributes are exported.\n\n## Import\n\nWAFv2 Web ACL Association can be imported using `WEB_ACL_ARN,RESOURCE_ARN` e.g.,\n\n```\n$ terraform import aws_wafv2_web_acl_association.example arn:aws:wafv2:...7ce849ea,arn:aws:apigateway:...ages/name\n```\n",
    "basename": "wafv2_web_acl_association.html"
  },
  "wafv2_web_acl_logging_configuration.html": {
    "subcategory": "WAFv2",
    "layout": "aws",
    "page_title": "AWS: aws_wafv2_web_acl_logging_configuration",
    "description": "Creates a WAFv2 Web ACL Logging Configuration resource.",
    "preview": "# Resource: aws_wafv2_web_acl_logging_configuration\n\nCreates a WAFv2 …",
    "content": "\n\n# Resource: aws_wafv2_web_acl_logging_configuration\n\nCreates a WAFv2 Web ACL Logging Configuration resource.\n\n-> **Note:** To start logging from a WAFv2 Web ACL, an Amazon Kinesis Data Firehose (e.g., [`aws_kinesis_firehose_delivery_stream` resource](/docs/providers/aws/r/kinesis_firehose_delivery_stream.html) must also be created with a PUT source (not a stream) and in the region that you are operating.\nIf you are capturing logs for Amazon CloudFront, always create the firehose in US East (N. Virginia).\nBe sure to give the data firehose a name that starts with the prefix `aws-waf-logs-`.\n\n## Example Usage\n\n### With Redacted Fields\n\n```terraform\nresource \"aws_wafv2_web_acl_logging_configuration\" \"example\" {\n  log_destination_configs = [aws_kinesis_firehose_delivery_stream.example.arn]\n  resource_arn            = aws_wafv2_web_acl.example.arn\n  redacted_fields {\n    single_header {\n      name = \"user-agent\"\n    }\n  }\n}\n```\n\n### With Logging Filter\n\n```terraform\nresource \"aws_wafv2_web_acl_logging_configuration\" \"example\" {\n  log_destination_configs = [aws_kinesis_firehose_delivery_stream.example.arn]\n  resource_arn            = aws_wafv2_web_acl.example.arn\n\n  logging_filter {\n    default_behavior = \"KEEP\"\n\n    filter {\n      behavior = \"DROP\"\n\n      condition {\n        action_condition {\n          action = \"COUNT\"\n        }\n      }\n\n      condition {\n        label_name_condition {\n          label_name = \"awswaf:111122223333:rulegroup:testRules:LabelNameZ\"\n        }\n      }\n\n      requirement = \"MEETS_ALL\"\n    }\n\n    filter {\n      behavior = \"KEEP\"\n\n      condition {\n        action_condition {\n          action = \"ALLOW\"\n        }\n      }\n\n      requirement = \"MEETS_ANY\"\n    }\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `log_destination_configs` - (Required) The Amazon Kinesis Data Firehose Amazon Resource Name (ARNs) that you want to associate with the web ACL. Currently, only 1 ARN is supported.\n* `logging_filter` - (Optional) A configuration block that specifies which web requests are kept in the logs and which are dropped. You can filter on the rule action and on the web request labels that were applied by matching rules during web ACL evaluation. See [Logging Filter](#logging-filter) below for more details.\n* `redacted_fields` - (Optional) The parts of the request that you want to keep out of the logs. Up to 100 `redacted_fields` blocks are supported. See [Redacted Fields](#redacted-fields) below for more details.\n* `resource_arn` - (Required) The Amazon Resource Name (ARN) of the web ACL that you want to associate with `log_destination_configs`.\n\n### Logging Filter\n\nThe `logging_filter` block supports the following arguments:\n\n* `default_behavior` - (Required) Default handling for logs that don't match any of the specified filtering conditions. Valid values: `KEEP` or `DROP`.\n* `filter` - (Required) Filter(s) that you want to apply to the logs. See [Filter](#filter) below for more details.\n\n### Filter\n\nThe `filter` block supports the following arguments:\n\n* `behavior` - (Required) How to handle logs that satisfy the filter's conditions and requirement. Valid values: `KEEP` or `DROP`.\n* `condition` - (Required) Match condition(s) for the filter. See [Condition](#condition) below for more details.\n* `requirement` - (Required) Logic to apply to the filtering conditions. You can specify that, in order to satisfy the filter, a log must match all conditions or must match at least one condition. Valid values: `MEETS_ALL` or `MEETS_ANY`.\n\n### Condition\n\nThe `condition` block supports the following arguments:\n\n~> **Note:** Either `action_condition` or `label_name_condition` must be specified.  \n\n* `action_condition` - (Optional) A single action condition. See [Action Condition](#action-condition) below for more details.\n* `label_name_condition` - (Optional) A single label name condition. See [Label Name Condition](#label-name-condition) below for more details.\n\n### Action Condition\n\nThe `action_condition` block supports the following argument:\n\n* `action` - (Required) The action setting that a log record must contain in order to meet the condition. Valid values: `ALLOW`, `BLOCK`, `COUNT`.\n\n### Label Name Condition\n\nThe `label_name_condition` block supports the following argument:\n\n* `label_name` - (Required) The label name that a log record must contain in order to meet the condition. This must be a fully qualified label name. Fully qualified labels have a prefix, optional namespaces, and label name. The prefix identifies the rule group or web ACL context of the rule that added the label.\n\n### Redacted Fields\n\nThe `redacted_fields` block supports the following arguments:\n\n~> **NOTE:** Only one of `method`, `query_string`, `single_header` or `uri_path` can be specified.\n\n* `all_query_arguments` - (Optional, **DEPRECATED**) Redact all query arguments.\n* `body` - (Optional, **DEPRECATED**) Redact the request body, which immediately follows the request headers.\n* `method` - (Optional) Redact the HTTP method. Must be specified as an empty configuration block `{}`. The method indicates the type of operation that the request is asking the origin to perform.\n* `query_string` - (Optional) Redact the query string. Must be specified as an empty configuration block `{}`. This is the part of a URL that appears after a `?` character, if any.\n* `single_header` - (Optional) Redact a single header. See [Single Header](#single-header) below for details.\n* `single_query_argument` - (Optional, **DEPRECATED**) Redact a single query argument. See [Single Query Argument](#single-query-argument) below for details.\n* `uri_path` - (Optional) Redact the request URI path. Must be specified as an empty configuration block `{}`. This is the part of a web request that identifies a resource, for example, `/images/daily-ad.jpg`.\n\n### Single Header\n\nRedact a single header. Provide the name of the header to redact, for example, `User-Agent` or `Referer` (provided as lowercase strings).\n\nThe `single_header` block supports the following arguments:\n\n* `name` - (Optional) The name of the query header to redact. This setting must be provided as lower case characters.\n\n### Single Query Argument (**DEPRECATED**)\n\nRedact a single query argument. Provide the name of the query argument to redact, such as `UserName` or `SalesRegion` (provided as lowercase strings).\n\nThe `single_query_argument` block supports the following arguments:\n\n* `name` - (Optional) The name of the query header to redact. This setting must be provided as lower case characters.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The Amazon Resource Name (ARN) of the WAFv2 Web ACL.\n\n## Import\n\nWAFv2 Web ACL Logging Configurations can be imported using the WAFv2 Web ACL ARN e.g.,\n\n```\n$ terraform import aws_wafv2_web_acl_logging_configuration.example arn:aws:wafv2:us-west-2:123456789012:regional/webacl/test-logs/a1b2c3d4-5678-90ab-cdef\n```\n",
    "basename": "wafv2_web_acl_logging_configuration.html"
  },
  "worklink_fleet.html": {
    "subcategory": "WorkLink",
    "layout": "aws",
    "page_title": "AWS: aws_worklink_fleet",
    "description": "Provides a AWS WorkLink Fleet resource.",
    "preview": "# Resource: aws_worklink_fleet\n\n## Example Usage\n\nBasic usage:\n …",
    "content": "\n\n# Resource: aws_worklink_fleet\n\n## Example Usage\n\nBasic usage:\n\n```terraform\nresource \"aws_worklink_fleet\" \"example\" {\n  name = \"terraform-example\"\n}\n```\n\nNetwork Configuration Usage:\n\n```terraform\nresource \"aws_worklink_fleet\" \"example\" {\n  name = \"terraform-example\"\n\n  network {\n    vpc_id             = aws_vpc.test.id\n    subnet_ids         = [aws_subnet.test.*.id]\n    security_group_ids = [aws_security_group.test.id]\n  }\n}\n```\n\nIdentity Provider Configuration Usage:\n\n```terraform\nresource \"aws_worklink_fleet\" \"test\" {\n  name = \"tf-worklink-fleet\"\n\n  identity_provider {\n    type          = \"SAML\"\n    saml_metadata = file(\"saml-metadata.xml\")\n  }\n}\n```\n\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) A region-unique name for the AMI.\n* `audit_stream_arn` - (Optional) The ARN of the Amazon Kinesis data stream that receives the audit events. Kinesis data stream name must begin with `\"AmazonWorkLink-\"`.\n* `device_ca_certificate` - (Optional) The certificate chain, including intermediate certificates and the root certificate authority certificate used to issue device certificates.\n* `identity_provider` - (Optional) Provide this to allow manage the identity provider configuration for the fleet. Fields documented below.\n* `display_name` - (Optional) The name of the fleet.\n* `network` - (Optional) Provide this to allow manage the company network configuration for the fleet. Fields documented below.\n* `optimize_for_end_user_location` - (Optional) The option to optimize for better performance by routing traffic through the closest AWS Region to users, which may be outside of your home Region. Defaults to `true`.\n\n**network** requires the following:\n\n~> **NOTE:** `network` cannot be removed without force recreating by `terraform taint`.\n\n* `vpc_id` - (Required) The VPC ID with connectivity to associated websites.\n* `subnet_ids` - (Required) A list of subnet IDs used for X-ENI connections from Amazon WorkLink rendering containers.\n* `security_group_ids` - (Required) A list of security group IDs associated with access to the provided subnets.\n\n**identity_provider** requires the following:\n\n~> **NOTE:** `identity_provider` cannot be removed without force recreating by `terraform taint`.\n\n* `type` - (Required) The type of identity provider.\n* `saml_metadata` - (Required) The SAML metadata document provided by the customer’s identity provider.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the created WorkLink Fleet.\n* `arn` - The ARN of the created WorkLink Fleet.\n* `company_code` - The identifier used by users to sign in to the Amazon WorkLink app.\n* `created_time` - The time that the fleet was created.\n* `last_updated_time` - The time that the fleet was last updated.\n\n## Import\n\nWorkLink can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_worklink_fleet.test arn:aws:worklink::123456789012:fleet/example\n```\n",
    "basename": "worklink_fleet.html"
  },
  "worklink_website_certificate_authority_association.html": {
    "subcategory": "WorkLink",
    "layout": "aws",
    "page_title": "AWS: aws_worklink_website_certificate_authority_association",
    "description": "Provides a AWS WorkLink Website Certificate Authority Association resource.",
    "preview": "# Resource: aws_worklink_website_certificate_authority_association\n …",
    "content": "\n\n# Resource: aws_worklink_website_certificate_authority_association\n\n## Example Usage\n\n```terraform\nresource \"aws_worklink_fleet\" \"example\" {\n  name = \"terraform-example\"\n}\n\nresource \"aws_worklink_website_certificate_authority_association\" \"test\" {\n  fleet_arn   = aws_worklink_fleet.test.arn\n  certificate = file(\"certificate.pem\")\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `fleet_arn` - (Required, ForceNew) The ARN of the fleet.\n* `certificate` - (Required, ForceNew) The root certificate of the Certificate Authority.\n* `display_name` - (Optional, ForceNew) The certificate name to display.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `website_ca_id` - A unique identifier for the Certificate Authority.\n\n\n## Import\n\nWorkLink Website Certificate Authority can be imported using `FLEET-ARN,WEBSITE-CA-ID`, e.g.,\n\n```\n$ terraform import aws_worklink_website_certificate_authority_association.example arn:aws:worklink::123456789012:fleet/example,abcdefghijk\n```\n",
    "basename": "worklink_website_certificate_authority_association.html"
  },
  "workspaces_directory.html": {
    "subcategory": "WorkSpaces",
    "layout": "aws",
    "page_title": "AWS: aws_workspaces_directory",
    "description": "Provides a WorkSpaces directory in AWS WorkSpaces Service.",
    "preview": "# Resource: aws_workspaces_directory\n\nProvides a WorkSpaces …",
    "content": "\n\n# Resource: aws_workspaces_directory\n\nProvides a WorkSpaces directory in AWS WorkSpaces Service.\n\n~> **NOTE:** AWS WorkSpaces service requires [`workspaces_DefaultRole`](https://docs.aws.amazon.com/workspaces/latest/adminguide/workspaces-access-control.html#create-default-role) IAM role to operate normally.\n\n## Example Usage\n\n```terraform\nresource \"aws_workspaces_directory\" \"example\" {\n  directory_id = aws_directory_service_directory.example.id\n  subnet_ids = [\n    aws_subnet.example_c.id,\n    aws_subnet.example_d.id\n  ]\n\n  tags = {\n    Example = true\n  }\n\n  self_service_permissions {\n    change_compute_type  = true\n    increase_volume_size = true\n    rebuild_workspace    = true\n    restart_workspace    = true\n    switch_running_mode  = true\n  }\n\n  workspace_access_properties {\n    device_type_android    = \"ALLOW\"\n    device_type_chromeos   = \"ALLOW\"\n    device_type_ios        = \"ALLOW\"\n    device_type_linux      = \"DENY\"\n    device_type_osx        = \"ALLOW\"\n    device_type_web        = \"DENY\"\n    device_type_windows    = \"DENY\"\n    device_type_zeroclient = \"DENY\"\n  }\n\n  workspace_creation_properties {\n    custom_security_group_id            = aws_security_group.example.id\n    default_ou                          = \"OU=AWS,DC=Workgroup,DC=Example,DC=com\"\n    enable_internet_access              = true\n    enable_maintenance_mode             = true\n    user_enabled_as_local_administrator = true\n  }\n\n  depends_on = [\n    aws_iam_role_policy_attachment.workspaces_default_service_access,\n    aws_iam_role_policy_attachment.workspaces_default_self_service_access\n  ]\n}\n\nresource \"aws_directory_service_directory\" \"example\" {\n  name     = \"corp.example.com\"\n  password = \"#S1ncerely\"\n  size     = \"Small\"\n\n  vpc_settings {\n    vpc_id = aws_vpc.example.id\n    subnet_ids = [\n      aws_subnet.example_a.id,\n      aws_subnet.example_b.id\n    ]\n  }\n}\n\ndata \"aws_iam_policy_document\" \"workspaces\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"workspaces.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"workspaces_default\" {\n  name               = \"workspaces_DefaultRole\"\n  assume_role_policy = data.aws_iam_policy_document.workspaces.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"workspaces_default_service_access\" {\n  role       = aws_iam_role.workspaces_default.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonWorkSpacesServiceAccess\"\n}\n\nresource \"aws_iam_role_policy_attachment\" \"workspaces_default_self_service_access\" {\n  role       = aws_iam_role.workspaces_default.name\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonWorkSpacesSelfServiceAccess\"\n}\n\nresource \"aws_vpc\" \"example\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_subnet\" \"example_a\" {\n  vpc_id            = aws_vpc.example.id\n  availability_zone = \"us-east-1a\"\n  cidr_block        = \"10.0.0.0/24\"\n}\n\nresource \"aws_subnet\" \"example_b\" {\n  vpc_id            = aws_vpc.example.id\n  availability_zone = \"us-east-1b\"\n  cidr_block        = \"10.0.1.0/24\"\n}\nresource \"aws_subnet\" \"example_c\" {\n  vpc_id            = aws_vpc.example.id\n  availability_zone = \"us-east-1c\"\n  cidr_block        = \"10.0.2.0/24\"\n}\n\nresource \"aws_subnet\" \"example_d\" {\n  vpc_id            = aws_vpc.example.id\n  availability_zone = \"us-east-1d\"\n  cidr_block        = \"10.0.3.0/24\"\n}\n```\n\n### IP Groups\n\n```terraform\nresource \"aws_workspaces_directory\" \"example\" {\n  directory_id = aws_directory_service_directory.example.id\n\n  ip_group_ids = [\n    aws_workspaces_ip_group.example.id,\n  ]\n}\n\nresource \"aws_workspaces_ip_group\" \"example\" {\n  name = \"example\"\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `directory_id` - (Required) The directory identifier for registration in WorkSpaces service.\n* `subnet_ids` - (Optional) The identifiers of the subnets where the directory resides.\n* `ip_group_ids` - The identifiers of the IP access control groups associated with the directory.\n* `tags` – (Optional) A map of tags assigned to the WorkSpaces directory. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `self_service_permissions` – (Optional) Permissions to enable or disable self-service capabilities. Defined below.\n* `workspace_access_properties` – (Optional) Specifies which devices and operating systems users can use to access their WorkSpaces. Defined below.\n* `workspace_creation_properties` – (Optional) Default properties that are used for creating WorkSpaces. Defined below.\n\n### self_service_permissions\n\n* `change_compute_type` – (Optional) Whether WorkSpaces directory users can change the compute type (bundle) for their workspace. Default `false`.\n* `increase_volume_size` – (Optional) Whether WorkSpaces directory users can increase the volume size of the drives on their workspace. Default `false`.\n* `rebuild_workspace` – (Optional) Whether WorkSpaces directory users can rebuild the operating system of a workspace to its original state. Default `false`.\n* `restart_workspace` – (Optional) Whether WorkSpaces directory users can restart their workspace. Default `true`.\n* `switch_running_mode` – (Optional) Whether WorkSpaces directory users can switch the running mode of their workspace. Default `false`.\n\n### workspace_access_properties\n\n* `device_type_android` – (Optional) Indicates whether users can use Android devices to access their WorkSpaces.\n* `device_type_chromeos` – (Optional) Indicates whether users can use Chromebooks to access their WorkSpaces.\n* `device_type_ios` – (Optional) Indicates whether users can use iOS devices to access their WorkSpaces.\n* `device_type_linux` – (Optional) Indicates whether users can use Linux clients to access their WorkSpaces.\n* `device_type_osx` – (Optional) Indicates whether users can use macOS clients to access their WorkSpaces.\n* `device_type_web` – (Optional) Indicates whether users can access their WorkSpaces through a web browser.\n* `device_type_windows` – (Optional) Indicates whether users can use Windows clients to access their WorkSpaces.\n* `device_type_zeroclient` – (Optional) Indicates whether users can use zero client devices to access their WorkSpaces.\n\n### workspace_creation_properties\n\n-> **Note:** Once you specified `custom_security_group_id` or `default_ou`, there is no way to delete these attributes. If you cleanup them from the configuration, they still be present in state.\n\n* `custom_security_group_id` – (Optional) The identifier of your custom security group. Should relate to the same VPC, where workspaces reside in.\n* `default_ou` – (Optional) The default organizational unit (OU) for your WorkSpace directories. Should conform `\"OU=<value>,DC=<value>,...,DC=<value>\"` pattern.\n* `enable_internet_access` – (Optional) Indicates whether internet access is enabled for your WorkSpaces.\n* `enable_maintenance_mode` – (Optional) Indicates whether maintenance mode is enabled for your WorkSpaces. For more information, see [WorkSpace Maintenance](https://docs.aws.amazon.com/workspaces/latest/adminguide/workspace-maintenance.html)..\n* `user_enabled_as_local_administrator` – (Optional) Indicates whether users are local administrators of their WorkSpaces.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The WorkSpaces directory identifier.\n* `alias` - The directory alias.\n* `customer_user_name` - The user name for the service account.\n* `directory_name` - The name of the directory.\n* `directory_type` - The directory type.\n* `dns_ip_addresses` - The IP addresses of the DNS servers for the directory.\n* `iam_role_id` - The identifier of the IAM role. This is the role that allows Amazon WorkSpaces to make calls to other services, such as Amazon EC2, on your behalf.\n* `ip_group_ids` - The identifiers of the IP access control groups associated with the directory.\n* `registration_code` - The registration code for the directory. This is the code that users enter in their Amazon WorkSpaces client application to connect to the directory.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n* `workspace_security_group_id` - The identifier of the security group that is assigned to new WorkSpaces.\n\n## Import\n\nWorkspaces directory can be imported using the directory ID, e.g.,\n\n```\n$ terraform import aws_workspaces_directory.main d-4444444444\n```\n",
    "basename": "workspaces_directory.html"
  },
  "workspaces_ip_group.html": {
    "subcategory": "WorkSpaces",
    "layout": "aws",
    "page_title": "AWS: aws_workspaces_ip_group",
    "description": "Provides an IP access control group in AWS WorkSpaces Service.",
    "preview": "# Resource: aws_workspaces_ip_group\n\nProvides an IP access control …",
    "content": "\n\n# Resource: aws_workspaces_ip_group\n\nProvides an IP access control group in AWS WorkSpaces Service\n\n## Example Usage\n\n```terraform\nresource \"aws_workspaces_ip_group\" \"contractors\" {\n  name        = \"Contractors\"\n  description = \"Contractors IP access control group\"\n  rules {\n    source      = \"150.24.14.0/24\"\n    description = \"NY\"\n  }\n  rules {\n    source      = \"125.191.14.85/32\"\n    description = \"LA\"\n  }\n  rules {\n    source      = \"44.98.100.0/24\"\n    description = \"STL\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The name of the IP group.\n* `description` - (Optional) The description of the IP group.\n* `rules` - (Optional) One or more pairs specifying the IP group rule (in CIDR format) from which web requests originate.\n* `tags` – (Optional) A map of tags assigned to the WorkSpaces directory. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Nested Blocks\n\n### `rules`\n\n#### Arguments\n\n* `source` - (Required) The IP address range, in CIDR notation, e.g., `10.0.0.0/16`\n* `description` - (Optional) The description.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The IP group identifier.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWorkSpaces IP groups can be imported using their GroupID, e.g.,\n\n```\n$ terraform import aws_workspaces_ip_group.example wsipg-488lrtl3k\n```\n\n",
    "basename": "workspaces_ip_group.html"
  },
  "workspaces_workspace.html": {
    "subcategory": "WorkSpaces",
    "layout": "aws",
    "page_title": "AWS: aws_workspaces_workspace",
    "description": "Provides a workspaces in AWS Workspaces Service.",
    "preview": "# Resource: aws_workspaces_workspace\n\nProvides a workspace in [AWS …",
    "content": "\n\n# Resource: aws_workspaces_workspace\n\nProvides a workspace in [AWS Workspaces](https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces.html) Service\n\n~> **NOTE:** AWS WorkSpaces service requires [`workspaces_DefaultRole`](https://docs.aws.amazon.com/workspaces/latest/adminguide/workspaces-access-control.html#create-default-role) IAM role to operate normally.\n\n## Example Usage\n\n```terraform\ndata \"aws_workspaces_bundle\" \"value_windows_10\" {\n  bundle_id = \"wsb-bh8rsxt14\" # Value with Windows 10 (English)\n}\n\nresource \"aws_workspaces_workspace\" \"example\" {\n  directory_id = aws_workspaces_directory.example.id\n  bundle_id    = data.aws_workspaces_bundle.value_windows_10.id\n  user_name    = \"john.doe\"\n\n  root_volume_encryption_enabled = true\n  user_volume_encryption_enabled = true\n  volume_encryption_key          = \"alias/aws/workspaces\"\n\n  workspace_properties {\n    compute_type_name                         = \"VALUE\"\n    user_volume_size_gib                      = 10\n    root_volume_size_gib                      = 80\n    running_mode                              = \"AUTO_STOP\"\n    running_mode_auto_stop_timeout_in_minutes = 60\n  }\n\n  tags = {\n    Department = \"IT\"\n  }\n}\n```\n\n## Argument Reference\n\nThe following arguments are supported:\n\n* `directory_id` - (Required) The ID of the directory for the WorkSpace.\n* `bundle_id` - (Required) The ID of the bundle for the WorkSpace.\n* `user_name` – (Required) The user name of the user for the WorkSpace. This user name must exist in the directory for the WorkSpace.\n* `root_volume_encryption_enabled` - (Optional) Indicates whether the data stored on the root volume is encrypted.\n* `user_volume_encryption_enabled` – (Optional) Indicates whether the data stored on the user volume is encrypted.\n* `volume_encryption_key` – (Optional) The symmetric AWS KMS customer master key (CMK) used to encrypt data stored on your WorkSpace. Amazon WorkSpaces does not support asymmetric CMKs.\n* `tags` - (Optional) The tags for the WorkSpace. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n* `workspace_properties` – (Optional) The WorkSpace properties.\n\n`workspace_properties` supports the following:\n\n* `compute_type_name` – (Optional) The compute type. For more information, see [Amazon WorkSpaces Bundles](http://aws.amazon.com/workspaces/details/#Amazon_WorkSpaces_Bundles). Valid values are `VALUE`, `STANDARD`, `PERFORMANCE`, `POWER`, `GRAPHICS`, `POWERPRO` and `GRAPHICSPRO`.\n* `root_volume_size_gib` – (Optional) The size of the root volume.\n* `running_mode` – (Optional) The running mode. For more information, see [Manage the WorkSpace Running Mode](https://docs.aws.amazon.com/workspaces/latest/adminguide/running-mode.html). Valid values are `AUTO_STOP` and `ALWAYS_ON`.\n* `running_mode_auto_stop_timeout_in_minutes` – (Optional) The time after a user logs off when WorkSpaces are automatically stopped. Configured in 60-minute intervals.\n* `user_volume_size_gib` – (Optional) The size of the user storage.\n\n### Timeouts\n\n`aws_workspaces_workspace` provides the following\n[Timeouts](https://www.terraform.io/docs/configuration/blocks/resources/syntax.html#operation-timeouts) configuration options:\n\n- `create` - (Default `30 minutes`) Used for WorkSpace creation.\n- `update` - (Default `10 minutes`) Used for WorkSpace updating.\n- `delete` - (Default `10 minutes`) Used for WorkSpace termination.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The workspaces ID.\n* `ip_address` - The IP address of the WorkSpace.\n* `computer_name` - The name of the WorkSpace, as seen by the operating system.\n* `state` - The operational state of the WorkSpace.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nWorkspaces can be imported using their ID, e.g.,\n\n```\n$ terraform import aws_workspaces_workspace.example ws-9z9zmbkhv\n```\n\n",
    "basename": "workspaces_workspace.html"
  },
  "xray_encryption_config.html": {
    "subcategory": "XRay",
    "layout": "aws",
    "page_title": "AWS: aws_xray_encryption_config",
    "description": "Creates and manages an AWS XRay Encryption Config.",
    "preview": "# Resource: aws_xray_encryption_config\n\nCreates and manages an AWS …",
    "content": "\n\n# Resource: aws_xray_encryption_config\n\nCreates and manages an AWS XRay Encryption Config.\n\n~> **NOTE:** Removing this resource from Terraform has no effect to the encryption configuration within X-Ray.\n\n## Example Usage\n\n```terraform\nresource \"aws_xray_encryption_config\" \"example\" {\n  type = \"NONE\"\n}\n```\n\n## Example Usage with KMS Key\n\n```terraform\nresource \"aws_kms_key\" \"example\" {\n  description             = \"Some Key\"\n  deletion_window_in_days = 7\n\n  policy = <<POLICY\n{\n  \"Version\": \"2012-10-17\",\n  \"Id\": \"kms-tf-1\",\n  \"Statement\": [\n    {\n      \"Sid\": \"Enable IAM User Permissions\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"\n      },\n      \"Action\": \"kms:*\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\nPOLICY\n}\n\nresource \"aws_xray_encryption_config\" \"example\" {\n  type   = \"KMS\"\n  key_id = aws_kms_key.example.arn\n}\n```\n\n## Argument Reference\n\n* `type` - (Required) The type of encryption. Set to `KMS` to use your own key for encryption. Set to `NONE` for default encryption.\n* `key_id` - (Optional) An AWS KMS customer master key (CMK) ARN.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - Region name.\n\n## Import\n\nXRay Encryption Config can be imported using the region name, e.g.,\n\n```\n$ terraform import aws_xray_encryption_config.example us-west-2\n```\n",
    "basename": "xray_encryption_config.html"
  },
  "xray_group.html": {
    "subcategory": "XRay",
    "layout": "aws",
    "page_title": "AWS: aws_xray_group",
    "description": "Creates and manages an AWS XRay Group.",
    "preview": "# Resource: aws_xray_group\n\nCreates and manages an AWS XRay Group.\n …",
    "content": "\n\n# Resource: aws_xray_group\n\nCreates and manages an AWS XRay Group.\n\n## Example Usage\n\n```terraform\nresource \"aws_xray_group\" \"example\" {\n  group_name        = \"example\"\n  filter_expression = \"responsetime > 5\"\n}\n```\n\n## Argument Reference\n\n* `group_name` - (Required) The name of the group.\n* `filter_expression` - (Required) The filter expression defining criteria by which to group traces. more info can be found in official [docs](https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html).\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The ARN of the Group.\n* `arn` - The ARN of the Group.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nXRay Groups can be imported using the ARN, e.g.,\n\n```\n$ terraform import aws_xray_group.example arn:aws:xray:us-west-2:1234567890:group/example-group/TNGX7SW5U6QY36T4ZMOUA3HVLBYCZTWDIOOXY3CJAXTHSS3YCWUA\n```\n",
    "basename": "xray_group.html"
  },
  "xray_sampling_rule.html": {
    "subcategory": "XRay",
    "layout": "aws",
    "page_title": "AWS: aws_xray_sampling_rule",
    "description": "Creates and manages an AWS XRay Sampling Rule.",
    "preview": "# Resource: aws_xray_sampling_rule\n\nCreates and manages an AWS XRay …",
    "content": "\n\n# Resource: aws_xray_sampling_rule\n\nCreates and manages an AWS XRay Sampling Rule.\n\n## Example Usage\n\n```terraform\nresource \"aws_xray_sampling_rule\" \"example\" {\n  rule_name      = \"example\"\n  priority       = 10000\n  version        = 1\n  reservoir_size = 1\n  fixed_rate     = 0.05\n  url_path       = \"*\"\n  host           = \"*\"\n  http_method    = \"*\"\n  service_type   = \"*\"\n  service_name   = \"*\"\n  resource_arn   = \"*\"\n\n  attributes = {\n    Hello = \"Tris\"\n  }\n}\n```\n\n## Argument Reference\n\n* `rule_name` - (Required) The name of the sampling rule.\n* `resource_arn` - (Required) Matches the ARN of the AWS resource on which the service runs.\n* `priority` - (Required) The priority of the sampling rule.\n* `fixed_rate` - (Required) The percentage of matching requests to instrument, after the reservoir is exhausted.\n* `reservoir_size` - (Required) A fixed number of matching requests to instrument per second, prior to applying the fixed rate. The reservoir is not used directly by services, but applies to all services using the rule collectively.\n* `service_name` - (Required) Matches the `name` that the service uses to identify itself in segments.\n* `service_type` - (Required) Matches the `origin` that the service uses to identify its type in segments.\n* `host` - (Required) Matches the hostname from a request URL.\n* `http_method` - (Required) Matches the HTTP method of a request.\n* `url_path` - (Required) Matches the path from a request URL.\n* `version` - (Required) The version of the sampling rule format (`1` )\n* `attributes` - (Optional) Matches attributes derived from the request.\n* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.\n\n## Attributes Reference\n\nIn addition to all arguments above, the following attributes are exported:\n\n* `id` - The name of the sampling rule.\n* `arn` - The ARN of the sampling rule.\n* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://www.terraform.io/docs/providers/aws/index.html#default_tags-configuration-block).\n\n## Import\n\nXRay Sampling Rules can be imported using the name, e.g.,\n\n```\n$ terraform import aws_xray_sampling_rule.example example\n```\n",
    "basename": "xray_sampling_rule.html"
  }
}
